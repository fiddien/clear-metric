[{"sent": "we find the optimal alignment of the original manifold and the oose manifold via procrustes analysis and apply the resulting translational , rotational , and scaling components on the oose manifold .", "tokens": ["we", "find", "the", "optimal", "alignment", "of", "the", "original", "manifold", "and", "the", "oose", "manifold", "via", "procrustes", "analysis", "and", "apply", "the", "resulting", "translational", ",", "rotational", ",", "and", "scaling", "components", "on", "the", "oose", "manifold", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "apply", "start": 105, "end": 110, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "analysis", "start": 92, "end": 100, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "apply", "start": 105, "end": 110, "i_start": 17, "i_end": 17}}], "id": 0}, {"sent": "neural machine translation has significantly improved the quality of machine translation in recent years .", "tokens": ["neural", "machine", "translation", "has", "significantly", "improved", "the", "quality", "of", "machine", "translation", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural machine translation", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "improved", "start": 45, "end": 53, "i_start": 5, "i_end": 5}}, {"subject": {"text": "neural machine translation", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "has", "start": 27, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "translation", "start": 15, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "improved", "start": 45, "end": 53, "i_start": 5, "i_end": 5}}], "id": 1}, {"sent": "based on the van emde boas tree , the sorting operation can be performed with a complexity on the order of o , .", "tokens": ["based", "on", "the", "van", "emde", "boas", "tree", ",", "the", "sorting", "operation", "can", "be", "performed", "with", "a", "complexity", "on", "the", "order", "of", "o", ",", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the sorting operation", "start": 34, "end": 55, "i_start": 8, "i_end": 10}, "verb": {"text": "can be performed", "start": 56, "end": 72, "i_start": 11, "i_end": 13}}], "id": 2}, {"sent": "we follow the recent self-localization paradigm based on a deep convolutional neural network .we find the optimal alignment of the original manifold and the oose manifold via procrustes analysis and apply the resulting translational , rotational , and scaling components on the oose manifold .neural machine translation has significantly improved the quality of machine translation in recent years .based on the van emde boas tree , the sorting operation can be performed with a complexity on the order of o , .we follow the recent self-localization paradigm based on a deep convolutional neural network .", "tokens": ["we", "follow", "the", "recent", "self", "-", "localization", "paradigm", "based", "on", "a", "deep", "convolutional", "neural", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "apply", "start": 105, "end": 110, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "analysis", "start": 92, "end": 100, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "apply", "start": 105, "end": 110, "i_start": 17, "i_end": 17}}, {"subject": {"text": "neural machine translation", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "improved", "start": 45, "end": 53, "i_start": 5, "i_end": 5}}, {"subject": {"text": "neural machine translation", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "has", "start": 27, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "translation", "start": 15, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "improved", "start": 45, "end": 53, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the sorting operation", "start": 34, "end": 55, "i_start": 8, "i_end": 10}, "verb": {"text": "can be performed", "start": 56, "end": 72, "i_start": 11, "i_end": 13}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 3}, {"sent": "the weights are initialized using the xavier initialization glorot and bengio .", "tokens": ["the", "weights", "are", "initialized", "using", "the", "xavier", "initialization", "glorot", "and", "bengio", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the weights", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "are initialized", "start": 12, "end": 27, "i_start": 2, "i_end": 3}}], "id": 4}, {"sent": "we utilize three standard citation network benchmark datasets-cora , citeseer and pubmed -and closely follow the transductive experimental setup of yang et al .", "tokens": ["we", "utilize", "three", "standard", "citation", "network", "benchmark", "datasets", "-", "cora", ",", "citeseer", "and", "pubmed", "-and", "closely", "follow", "the", "transductive", "experimental", "setup", "of", "yang", "et", "al", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "utilize", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follow", "start": 102, "end": 108, "i_start": 16, "i_end": 16}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "utilize", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 5}, {"sent": "deep neural networks have been successfully applied to many areas , including speech .", "tokens": ["deep", "neural", "networks", "have", "been", "successfully", "applied", "to", "many", "areas", ",", "including", "speech", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "applied", "start": 44, "end": 51, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}], "id": 6}, {"sent": "the camera consists of 112 ccds , each 600 2400 pixels , which are arranged in 4 rows by 28 columns .", "tokens": ["the", "camera", "consists", "of", "112", "ccds", ",", "each", "600", "2400", "pixels", ",", "which", "are", "arranged", "in", "4", "rows", "by", "28", "columns", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the camera", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}], "id": 7}, {"sent": "over the past few years , deep convolutional neural networks have been very successful in a wide range of computer vision tasks such as image classification .", "tokens": ["over", "the", "past", "few", "years", ",", "deep", "convolutional", "neural", "networks", "have", "been", "very", "successful", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 26, "end": 60, "i_start": 6, "i_end": 9}, "verb": {"text": "have been", "start": 61, "end": 70, "i_start": 10, "i_end": 11}}, {"character": {"text": "networks", "start": 52, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "successful", "start": 76, "end": 86, "i_start": 13, "i_end": 13}}], "id": 8}, {"sent": "convolutional neural networks have proved their dominating spot in various machine learning tasks , such as speech recognition .", "tokens": ["convolutional", "neural", "networks", "have", "proved", "their", "dominating", "spot", "in", "various", "machine", "learning", "tasks", ",", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have proved", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "proved", "start": 35, "end": 41, "i_start": 4, "i_end": 4}}, {"character": {"text": "spot", "start": 59, "end": 63, "i_start": 7, "i_end": 7}, "action": {"text": "dominating", "start": 48, "end": 58, "i_start": 6, "i_end": 6}}], "id": 9}, {"sent": "manual delineation is a time-consuming and tedious task that is also prone to high intra-and inter-observer variability .", "tokens": ["manual", "delineation", "is", "a", "time", "-", "consuming", "and", "tedious", "task", "that", "is", "also", "prone", "to", "high", "intra", "-", "and", "inter", "-", "observer", "variability", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "manual delineation", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "task", "start": 51, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "consuming", "start": 29, "end": 38, "i_start": 6, "i_end": 6}}], "id": 10}, {"sent": "recently , deep convolutional neural networks have led to substantial improvements for numerous computer vision tasks like object detection , often achieving human-level performance .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "led", "to", "substantial", "improvements", "for", "numerous", "computer", "vision", "tasks", "like", "object", "detection", ",", "often", "achieving", "human", "-", "level", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have led", "start": 46, "end": 54, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "led", "start": 51, "end": 54, "i_start": 7, "i_end": 7}}, {"character": {"text": "improvements", "start": 70, "end": 82, "i_start": 10, "i_end": 10}, "action": {"text": "achieving", "start": 148, "end": 157, "i_start": 21, "i_end": 21}}], "id": 11}, {"sent": "this figure shows how to implement an distributed control-control-fa gate .", "tokens": ["this", "figure", "shows", "how", "to", "implement", "an", "distributed", "control", "-", "control", "-", "fa", "gate", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this figure", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "shows", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "figure", "start": 5, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "shows", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}], "id": 12}, {"sent": "string theory is the only possibility at hand , and the transplanckian regime has been discussed in this context by several authors , see eg refs .", "tokens": ["string", "theory", "is", "the", "only", "possibility", "at", "hand", ",", "and", "the", "transplanckian", "regime", "has", "been", "discussed", "in", "this", "context", "by", "several", "authors", ",", "see", "eg", "refs", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "string theory", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the transplanckian regime", "start": 52, "end": 77, "i_start": 10, "i_end": 12}, "verb": {"text": "discussed", "start": 87, "end": 96, "i_start": 15, "i_end": 15}}, {"character": {"text": "several", "start": 116, "end": 123, "i_start": 20, "i_end": 20}, "action": {"text": "discussed", "start": 87, "end": 96, "i_start": 15, "i_end": 15}}], "id": 13}, {"sent": "in their remarkable work , spielman and srivastava analyzed a spectral sparsification algorithm based on a simple sampling procedure .", "tokens": ["in", "their", "remarkable", "work", ",", "spielman", "and", "srivastava", "analyzed", "a", "spectral", "sparsification", "algorithm", "based", "on", "a", "simple", "sampling", "procedure", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "spielman and srivastava", "start": 27, "end": 50, "i_start": 5, "i_end": 7}, "verb": {"text": "analyzed", "start": 51, "end": 59, "i_start": 8, "i_end": 8}}, {"character": {"text": "spielman", "start": 27, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "analyzed", "start": 51, "end": 59, "i_start": 8, "i_end": 8}}, {"character": {"text": "srivastava", "start": 40, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "analyzed", "start": 51, "end": 59, "i_start": 8, "i_end": 8}}, {"character": {"text": "spielman", "start": 27, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "work", "start": 20, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "srivastava", "start": 40, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "work", "start": 20, "end": 24, "i_start": 3, "i_end": 3}}], "id": 14}, {"sent": "moreover , agarwal et al provide a minimax lower bound for this model , and we match it as well .", "tokens": ["moreover", ",", "agarwal", "et", "al", "provide", "a", "minimax", "lower", "bound", "for", "this", "model", ",", "and", "we", "match", "it", "as", "well", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "agarwal et al", "start": 11, "end": 24, "i_start": 2, "i_end": 4}, "verb": {"text": "provide", "start": 25, "end": 32, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 76, "end": 78, "i_start": 15, "i_end": 15}, "verb": {"text": "match", "start": 79, "end": 84, "i_start": 16, "i_end": 16}}, {"character": {"text": "agarwal", "start": 11, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "provide", "start": 25, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 76, "end": 78, "i_start": 15, "i_end": 15}, "action": {"text": "match", "start": 79, "end": 84, "i_start": 16, "i_end": 16}}], "id": 15}, {"sent": "we use the adam optimizer and mini-batches of size 2000 during training .", "tokens": ["we", "use", "the", "adam", "optimizer", "and", "mini", "-", "batches", "of", "size", "2000", "during", "training", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 16}, {"sent": "the model was trained using mini-batch sgd , with the learning rate controlled by adam and the mini-batch size set to 32 .", "tokens": ["the", "model", "was", "trained", "using", "mini", "-", "batch", "sgd", ",", "with", "the", "learning", "rate", "controlled", "by", "adam", "and", "the", "mini", "-", "batch", "size", "set", "to", "32", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "was trained", "start": 10, "end": 21, "i_start": 2, "i_end": 3}}, {"character": {"text": "adam", "start": 82, "end": 86, "i_start": 16, "i_end": 16}, "action": {"text": "controlled", "start": 68, "end": 78, "i_start": 14, "i_end": 14}}], "id": 17}, {"sent": "all calculations were performed using dft as implemented in the vienna ab-initio simulation package .", "tokens": ["all", "calculations", "were", "performed", "using", "dft", "as", "implemented", "in", "the", "vienna", "ab", "-", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all calculations", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were performed", "start": 17, "end": 31, "i_start": 2, "i_end": 3}}], "id": 18}, {"sent": "unlike prior work with sparsityaware algorithms , the proposed si-lms and si-rls algorithms exploit the possible sparsity of the mse values associated with each of the links in a different way .", "tokens": ["unlike", "prior", "work", "with", "sparsityaware", "algorithms", ",", "the", "proposed", "si", "-", "lms", "and", "si", "-", "rls", "algorithms", "exploit", "the", "possible", "sparsity", "of", "the", "mse", "values", "associated", "with", "each", "of", "the", "links", "in", "a", "different", "way", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the proposed si-lms and si-rls algorithms", "start": 50, "end": 91, "i_start": 7, "i_end": 16}, "verb": {"text": "exploit", "start": 92, "end": 99, "i_start": 17, "i_end": 17}}, {"character": {"text": "algorithms", "start": 37, "end": 47, "i_start": 5, "i_end": 5}, "action": {"text": "exploit", "start": 92, "end": 99, "i_start": 17, "i_end": 17}}, {"character": {"text": "algorithms", "start": 81, "end": 91, "i_start": 16, "i_end": 16}, "action": {"text": "exploit", "start": 92, "end": 99, "i_start": 17, "i_end": 17}}], "id": 19}, {"sent": "the quantum unit of information is called the qubit .", "tokens": ["the", "quantum", "unit", "of", "information", "is", "called", "the", "qubit", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quantum unit of information", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "is called", "start": 32, "end": 41, "i_start": 5, "i_end": 6}}], "id": 20}, {"sent": "for example , one might respond to a particular shade of red , or a salty taste , or something that does not exactly match an established term .", "tokens": ["for", "example", ",", "one", "might", "respond", "to", "a", "particular", "shade", "of", "red", ",", "or", "a", "salty", "taste", ",", "or", "something", "that", "does", "not", "exactly", "match", "an", "established", "term", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 14, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "might respond", "start": 18, "end": 31, "i_start": 4, "i_end": 5}}, {"character": {"text": "one", "start": 14, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "respond", "start": 24, "end": 31, "i_start": 5, "i_end": 5}}], "id": 21}, {"sent": "specifically , we use the adam stochastic gradient optimizer .", "tokens": ["specifically", ",", "we", "use", "the", "adam", "stochastic", "gradient", "optimizer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "use", "start": 18, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 18, "end": 21, "i_start": 3, "i_end": 3}}], "id": 22}, {"sent": "recently , deep convolution neural networks have been applied to solve the stereo matching problem .", "tokens": ["recently", ",", "deep", "convolution", "neural", "networks", "have", "been", "applied", "to", "solve", "the", "stereo", "matching", "problem", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolution neural networks", "start": 11, "end": 43, "i_start": 2, "i_end": 5}, "verb": {"text": "have been applied", "start": 44, "end": 61, "i_start": 6, "i_end": 8}}, {"character": {"text": "networks", "start": 35, "end": 43, "i_start": 5, "i_end": 5}, "action": {"text": "solve", "start": 65, "end": 70, "i_start": 10, "i_end": 10}}], "id": 23}, {"sent": "similarly , topic features have been used with either maximum entropy models or recurrent networks .", "tokens": ["similarly", ",", "topic", "features", "have", "been", "used", "with", "either", "maximum", "entropy", "models", "or", "recurrent", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "topic features", "start": 12, "end": 26, "i_start": 2, "i_end": 3}, "verb": {"text": "have been used", "start": 27, "end": 41, "i_start": 4, "i_end": 6}}], "id": 24}, {"sent": "compressed sensing is a recently developed paradigm for the effective acquisition of sparse signals via few nonadaptive , linear measurements .", "tokens": ["compressed", "sensing", "is", "a", "recently", "developed", "paradigm", "for", "the", "effective", "acquisition", "of", "sparse", "signals", "via", "few", "nonadaptive", ",", "linear", "measurements", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "compressed sensing", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}], "id": 25}, {"sent": "finally we perform binarization operation on the saliency map with a adaptive threshold , which is obtained via otsu algorithm , and take the bounding box that covers the largest connected area as the discriminative region of object .", "tokens": ["finally", "we", "perform", "binarization", "operation", "on", "the", "saliency", "map", "with", "a", "adaptive", "threshold", ",", "which", "is", "obtained", "via", "otsu", "algorithm", ",", "and", "take", "the", "bounding", "box", "that", "covers", "the", "largest", "connected", "area", "as", "the", "discriminative", "region", "of", "object", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "perform", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "take", "start": 133, "end": 137, "i_start": 22, "i_end": 22}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "perform", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "take", "start": 133, "end": 137, "i_start": 22, "i_end": 22}}, {"character": {"text": "box", "start": 151, "end": 154, "i_start": 25, "i_end": 25}, "action": {"text": "covers", "start": 160, "end": 166, "i_start": 27, "i_end": 27}}, {"character": {"text": "region", "start": 216, "end": 222, "i_start": 35, "i_end": 35}, "action": {"text": "discriminative", "start": 201, "end": 215, "i_start": 34, "i_end": 34}}], "id": 26}, {"sent": "herner , standard model higgs searches at the tevatron , these proceedings .", "tokens": ["herner", ",", "standard", "model", "higgs", "searches", "at", "the", "tevatron", ",", "these", "proceedings", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 27}, {"sent": "distributional models of this form have been proved useful in many natural language processing tasks , but in general they do not scale up to larger text constituents such as phrases and sentences .", "tokens": ["distributional", "models", "of", "this", "form", "have", "been", "proved", "useful", "in", "many", "natural", "language", "processing", "tasks", ",", "but", "in", "general", "they", "do", "not", "scale", "up", "to", "larger", "text", "constituents", "such", "as", "phrases", "and", "sentences", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "distributional models of this form", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "have been proved", "start": 35, "end": 51, "i_start": 5, "i_end": 7}}, {"subject": {"text": "they", "start": 118, "end": 122, "i_start": 19, "i_end": 19}, "verb": {"text": "scale", "start": 130, "end": 135, "i_start": 22, "i_end": 22}}], "id": 28}, {"sent": "furthermore , the free energy is a concave function of the distance between the defects .", "tokens": ["furthermore", ",", "the", "free", "energy", "is", "a", "concave", "function", "of", "the", "distance", "between", "the", "defects", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the free energy", "start": 14, "end": 29, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "distance", "start": 59, "end": 67, "i_start": 11, "i_end": 11}, "action": {"text": "function", "start": 43, "end": 51, "i_start": 8, "i_end": 8}}], "id": 29}, {"sent": "this holds in particular for the local broadcast algorithm of censor-hillel et al , which crucially relies on a very unnatural reversal step to guarantee correctness .", "tokens": ["this", "holds", "in", "particular", "for", "the", "local", "broadcast", "algorithm", "of", "censor", "-", "hillel", "et", "al", ",", "which", "crucially", "relies", "on", "a", "very", "unnatural", "reversal", "step", "to", "guarantee", "correctness", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "holds", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "holds", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "algorithm", "start": 49, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "broadcast", "start": 39, "end": 48, "i_start": 7, "i_end": 7}}, {"character": {"text": "algorithm", "start": 49, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "relies", "start": 100, "end": 106, "i_start": 18, "i_end": 18}}, {"character": {"text": "step", "start": 136, "end": 140, "i_start": 24, "i_end": 24}, "action": {"text": "guarantee", "start": 144, "end": 153, "i_start": 26, "i_end": 26}}], "id": 30}, {"sent": "the youtube faces dataset exemplify both unconstained and controlled video settings .", "tokens": ["the", "youtube", "faces", "dataset", "exemplify", "both", "unconstained", "and", "controlled", "video", "settings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the youtube", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "faces", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "dataset", "start": 18, "end": 25, "i_start": 3, "i_end": 3}, "verb": {"text": "exemplify", "start": 26, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "dataset", "start": 18, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "exemplify", "start": 26, "end": 35, "i_start": 4, "i_end": 4}}], "id": 31}, {"sent": "for this purpose , we generalize the toric mori theory for non-q-factorial toric varieties .", "tokens": ["for", "this", "purpose", ",", "we", "generalize", "the", "toric", "mori", "theory", "for", "non", "-", "q", "-", "factorial", "toric", "varieties", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "verb": {"text": "generalize", "start": 22, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "generalize", "start": 22, "end": 32, "i_start": 5, "i_end": 5}}], "id": 32}, {"sent": "defferrard et al approximates spectral filters with chebyshev polynomials , providing a more efficient filtering algorithm , whose kernel size determines the range of aggregated local k-neighborhoods .", "tokens": ["defferrard", "et", "al", "approximates", "spectral", "filters", "with", "chebyshev", "polynomials", ",", "providing", "a", "more", "efficient", "filtering", "algorithm", ",", "whose", "kernel", "size", "determines", "the", "range", "of", "aggregated", "local", "k", "-", "neighborhoods", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "defferrard et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "approximates", "start": 17, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "defferrard", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "approximates", "start": 17, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "approximates", "start": 17, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "providing", "start": 76, "end": 85, "i_start": 10, "i_end": 10}}, {"character": {"text": "algorithm", "start": 113, "end": 122, "i_start": 15, "i_end": 15}, "action": {"text": "filtering", "start": 103, "end": 112, "i_start": 14, "i_end": 14}}, {"character": {"text": "size", "start": 138, "end": 142, "i_start": 19, "i_end": 19}, "action": {"text": "determines", "start": 143, "end": 153, "i_start": 20, "i_end": 20}}], "id": 33}, {"sent": "instead , we resort to variational inference to the intractable posterior p .", "tokens": ["instead", ",", "we", "resort", "to", "variational", "inference", "to", "the", "intractable", "posterior", "p", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "resort", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "resort", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}], "id": 34}, {"sent": "as exchange-correlation potential the generalized gradient approximation in the formulation of perdew , burke and ernzerhof has been used .", "tokens": ["as", "exchange", "-", "correlation", "potential", "the", "generalized", "gradient", "approximation", "in", "the", "formulation", "of", "perdew", ",", "burke", "and", "ernzerhof", "has", "been", "used", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "as exchange-correlation potential the generalized gradient approximation in the formulation of perdew", "start": 0, "end": 101, "i_start": 0, "i_end": 13}, "verb": {"text": "has been used", "start": 124, "end": 137, "i_start": 18, "i_end": 20}}], "id": 35}, {"sent": "its time component is a unit operator that commutes with everything .", "tokens": ["its", "time", "component", "is", "a", "unit", "operator", "that", "commutes", "with", "everything", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "its time component", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 36}, {"sent": "rapid development of deep convolutional neural networks has led to promising performance on various computer vision tasks .", "tokens": ["rapid", "development", "of", "deep", "convolutional", "neural", "networks", "has", "led", "to", "promising", "performance", "on", "various", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "rapid development of deep convolutional neural networks", "start": 0, "end": 55, "i_start": 0, "i_end": 6}, "verb": {"text": "has led", "start": 56, "end": 63, "i_start": 7, "i_end": 8}}, {"character": {"text": "development", "start": 6, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 60, "end": 63, "i_start": 8, "i_end": 8}}, {"character": {"text": "performance", "start": 77, "end": 88, "i_start": 11, "i_end": 11}, "action": {"text": "promising", "start": 67, "end": 76, "i_start": 10, "i_end": 10}}], "id": 37}, {"sent": "neural networks have become ubiquitous in applications including computer vision .", "tokens": ["neural", "networks", "have", "become", "ubiquitous", "in", "applications", "including", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have become", "start": 16, "end": 27, "i_start": 2, "i_end": 3}}], "id": 38}, {"sent": "model independent definition of disturbance in the preceding subsection , we have defined the rms disturbance of apparatus using the associated indirect measurement model .", "tokens": ["model", "independent", "definition", "of", "disturbance", "in", "the", "preceding", "subsection", ",", "we", "have", "defined", "the", "rms", "disturbance", "of", "apparatus", "using", "the", "associated", "indirect", "measurement", "model", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 74, "end": 76, "i_start": 10, "i_end": 10}, "verb": {"text": "have defined", "start": 77, "end": 89, "i_start": 11, "i_end": 12}}, {"character": {"text": "we", "start": 74, "end": 76, "i_start": 10, "i_end": 10}, "action": {"text": "defined", "start": 82, "end": 89, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 74, "end": 76, "i_start": 10, "i_end": 10}, "action": {"text": "using", "start": 123, "end": 128, "i_start": 18, "i_end": 18}}], "id": 39}, {"sent": "filled squares represent the g-sample , open circles the h-sample and arrows represent upper-limits from non-detections .", "tokens": ["filled", "squares", "represent", "the", "g", "-", "sample", ",", "open", "circles", "the", "h", "-", "sample", "and", "arrows", "represent", "upper", "-", "limits", "from", "non", "-", "detections", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "filled squares", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "represent", "start": 15, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "squares", "start": 7, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "represent", "start": 15, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "circles", "start": 45, "end": 52, "i_start": 9, "i_end": 9}, "action": {"text": "represent", "start": 77, "end": 86, "i_start": 16, "i_end": 16}}, {"character": {"text": "sample", "start": 59, "end": 65, "i_start": 13, "i_end": 13}, "action": {"text": "represent", "start": 77, "end": 86, "i_start": 16, "i_end": 16}}, {"character": {"text": "arrows", "start": 70, "end": 76, "i_start": 15, "i_end": 15}, "action": {"text": "represent", "start": 77, "end": 86, "i_start": 16, "i_end": 16}}, {"character": {"text": "upper", "start": 87, "end": 92, "i_start": 17, "i_end": 17}, "action": {"text": "represent", "start": 77, "end": 86, "i_start": 16, "i_end": 16}}], "id": 40}, {"sent": "hydrogen is a convenient , safe , versatile fuel source that can be easily converted .", "tokens": ["hydrogen", "is", "a", "convenient", ",", "safe", ",", "versatile", "fuel", "source", "that", "can", "be", "easily", "converted", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "hydrogen", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "source", "start": 49, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "safe", "start": 27, "end": 31, "i_start": 5, "i_end": 5}}], "id": 41}, {"sent": "we use a pre-trained model which is trained with imagenet-1k dataset , and then fine-tune the network .", "tokens": ["we", "use", "a", "pre", "-", "trained", "model", "which", "is", "trained", "with", "imagenet-1k", "dataset", ",", "and", "then", "fine", "-", "tune", "the", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "tune", "start": 85, "end": 89, "i_start": 18, "i_end": 18}}], "id": 42}, {"sent": "in order to boost the classification performance , we add batch normalization layer between convolutional layer and relu layer .", "tokens": ["in", "order", "to", "boost", "the", "classification", "performance", ",", "we", "add", "batch", "normalization", "layer", "between", "convolutional", "layer", "and", "relu", "layer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 51, "end": 53, "i_start": 8, "i_end": 8}, "verb": {"text": "add", "start": 54, "end": 57, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "add", "start": 54, "end": 57, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "boost", "start": 12, "end": 17, "i_start": 3, "i_end": 3}}], "id": 43}, {"sent": "we state the following interesting theorem .", "tokens": ["we", "state", "the", "following", "interesting", "theorem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "state", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "state", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "theorem", "start": 35, "end": 42, "i_start": 5, "i_end": 5}, "action": {"text": "interesting", "start": 23, "end": 34, "i_start": 4, "i_end": 4}}], "id": 44}, {"sent": "elements of the meta-meta-model layer are called meta-meta-objects .", "tokens": ["elements", "of", "the", "meta", "-", "meta", "-", "model", "layer", "are", "called", "meta", "-", "meta", "-", "objects", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "elements of the meta-meta-model layer", "start": 0, "end": 37, "i_start": 0, "i_end": 8}, "verb": {"text": "are called", "start": 38, "end": 48, "i_start": 9, "i_end": 10}}], "id": 45}, {"sent": "the space spanned by ideal boson-fermion states that are selected with the aid of the above particle number considerations is called the ideal subspace .", "tokens": ["the", "space", "spanned", "by", "ideal", "boson", "-", "fermion", "states", "that", "are", "selected", "with", "the", "aid", "of", "the", "above", "particle", "number", "considerations", "is", "called", "the", "ideal", "subspace", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the space spanned by ideal boson-fermion states that are selected with the aid of the above particle number considerations", "start": 0, "end": 122, "i_start": 0, "i_end": 20}, "verb": {"text": "is called", "start": 123, "end": 132, "i_start": 21, "i_end": 22}}, {"character": {"text": "states", "start": 41, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "spanned", "start": 10, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "considerations", "start": 108, "end": 122, "i_start": 20, "i_end": 20}, "action": {"text": "aid", "start": 75, "end": 78, "i_start": 14, "i_end": 14}}], "id": 46}, {"sent": "the electron-exchange correlation energy is described by using the functional of perdew , burke , and ernzerhof based within the generalized gradient approximation .", "tokens": ["the", "electron", "-", "exchange", "correlation", "energy", "is", "described", "by", "using", "the", "functional", "of", "perdew", ",", "burke", ",", "and", "ernzerhof", "based", "within", "the", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electron-exchange correlation energy", "start": 0, "end": 40, "i_start": 0, "i_end": 5}, "verb": {"text": "is described", "start": 41, "end": 53, "i_start": 6, "i_end": 7}}, {"character": {"text": "perdew", "start": 81, "end": 87, "i_start": 13, "i_end": 13}, "action": {"text": "functional", "start": 67, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "burke", "start": 90, "end": 95, "i_start": 15, "i_end": 15}, "action": {"text": "functional", "start": 67, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "ernzerhof", "start": 102, "end": 111, "i_start": 18, "i_end": 18}, "action": {"text": "functional", "start": 67, "end": 77, "i_start": 11, "i_end": 11}}], "id": 47}, {"sent": "an automatic binarization method for color text in video images is proposed using convolutional network .", "tokens": ["an", "automatic", "binarization", "method", "for", "color", "text", "in", "video", "images", "is", "proposed", "using", "convolutional", "network", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "an automatic binarization method for color text in video images", "start": 0, "end": 63, "i_start": 0, "i_end": 9}, "verb": {"text": "is proposed", "start": 64, "end": 75, "i_start": 10, "i_end": 11}}], "id": 48}, {"sent": "along with these moving poles , the qmf will have other singularities originating from the potential which are called fixed singularities .", "tokens": ["along", "with", "these", "moving", "poles", ",", "the", "qmf", "will", "have", "other", "singularities", "originating", "from", "the", "potential", "which", "are", "called", "fixed", "singularities", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the qmf", "start": 32, "end": 39, "i_start": 6, "i_end": 7}, "verb": {"text": "will have", "start": 40, "end": 49, "i_start": 8, "i_end": 9}}, {"character": {"text": "qmf", "start": 36, "end": 39, "i_start": 7, "i_end": 7}, "action": {"text": "have", "start": 45, "end": 49, "i_start": 9, "i_end": 9}}, {"character": {"text": "poles", "start": 24, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "have", "start": 45, "end": 49, "i_start": 9, "i_end": 9}}], "id": 49}, {"sent": "deep convolutional neural networks have been successfully applied to several pattern recognition tasks such as image recognition .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successfully", "applied", "to", "several", "pattern", "recognition", "tasks", "such", "as", "image", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "applied", "start": 58, "end": 65, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}], "id": 50}, {"sent": "in , a dynamic channel-selection for autonomous wireless users is proposed , where each user has set of actions and strategies .", "tokens": ["in", ",", "a", "dynamic", "channel", "-", "selection", "for", "autonomous", "wireless", "users", "is", "proposed", ",", "where", "each", "user", "has", "set", "of", "actions", "and", "strategies", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a dynamic channel-selection for autonomous wireless users", "start": 5, "end": 62, "i_start": 2, "i_end": 10}, "verb": {"text": "is proposed", "start": 63, "end": 74, "i_start": 11, "i_end": 12}}, {"character": {"text": "each", "start": 83, "end": 87, "i_start": 15, "i_end": 15}, "action": {"text": "has", "start": 93, "end": 96, "i_start": 17, "i_end": 17}}], "id": 51}, {"sent": "the first type of letter is called a singleton letter .", "tokens": ["the", "first", "type", "of", "letter", "is", "called", "a", "singleton", "letter", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the first type of letter", "start": 0, "end": 24, "i_start": 0, "i_end": 4}, "verb": {"text": "is called", "start": 25, "end": 34, "i_start": 5, "i_end": 6}}], "id": 52}, {"sent": "at each lattice site , there is a three-dimensional classical spin of unit length and each spin has a total of 50 interacting neighbors .", "tokens": ["at", "each", "lattice", "site", ",", "there", "is", "a", "three", "-", "dimensional", "classical", "spin", "of", "unit", "length", "and", "each", "spin", "has", "a", "total", "of", "50", "interacting", "neighbors", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 23, "end": 28, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 6, "i_end": 6}}, {"subject": {"text": "each spin", "start": 86, "end": 95, "i_start": 17, "i_end": 18}, "verb": {"text": "has", "start": 96, "end": 99, "i_start": 19, "i_end": 19}}, {"character": {"text": "spin", "start": 62, "end": 66, "i_start": 12, "i_end": 12}, "action": {"text": "has", "start": 96, "end": 99, "i_start": 19, "i_end": 19}}, {"character": {"text": "50 interacting neighbors", "start": 111, "end": 135, "i_start": 23, "i_end": 25}, "action": {"text": "interacting", "start": 114, "end": 125, "i_start": 24, "i_end": 24}}], "id": 53}, {"sent": "however , the computational complexity of this detection algorithm is high , and large number of samples are required to exploit the cyclostationarity behavior of the received signal .", "tokens": ["however", ",", "the", "computational", "complexity", "of", "this", "detection", "algorithm", "is", "high", ",", "and", "large", "number", "of", "samples", "are", "required", "to", "exploit", "the", "cyclostationarity", "behavior", "of", "the", "received", "signal", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the computational complexity of this detection algorithm", "start": 10, "end": 66, "i_start": 2, "i_end": 8}, "verb": {"text": "is", "start": 67, "end": 69, "i_start": 9, "i_end": 9}}, {"subject": {"text": "large number of samples", "start": 81, "end": 104, "i_start": 13, "i_end": 16}, "verb": {"text": "required", "start": 109, "end": 117, "i_start": 18, "i_end": 18}}, {"character": {"text": "algorithm", "start": 57, "end": 66, "i_start": 8, "i_end": 8}, "action": {"text": "detection", "start": 47, "end": 56, "i_start": 7, "i_end": 7}}, {"character": {"text": "signal", "start": 176, "end": 182, "i_start": 27, "i_end": 27}, "action": {"text": "behavior", "start": 151, "end": 159, "i_start": 23, "i_end": 23}}], "id": 54}, {"sent": "because the spin current is a function of the cavity field amplitude , the spin current also exhibits bistability as function of the amplitude of the driving laser which survives even in the presence of significant variations in the dot sizes and coupling to the cavity field .", "tokens": ["because", "the", "spin", "current", "is", "a", "function", "of", "the", "cavity", "field", "amplitude", ",", "the", "spin", "current", "also", "exhibits", "bistability", "as", "function", "of", "the", "amplitude", "of", "the", "driving", "laser", "which", "survives", "even", "in", "the", "presence", "of", "significant", "variations", "in", "the", "dot", "sizes", "and", "coupling", "to", "the", "cavity", "field", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the spin current", "start": 71, "end": 87, "i_start": 13, "i_end": 15}, "verb": {"text": "exhibits", "start": 93, "end": 101, "i_start": 17, "i_end": 17}}, {"character": {"text": "function", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "because", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}, {"character": {"text": "amplitude", "start": 59, "end": 68, "i_start": 11, "i_end": 11}, "action": {"text": "function", "start": 30, "end": 38, "i_start": 6, "i_end": 6}}], "id": 55}, {"sent": "as opposed to the reweigthed techniques , the h-method kinetic estimator is less accurate than the tmethod kinetic energy estimator .", "tokens": ["as", "opposed", "to", "the", "reweigthed", "techniques", ",", "the", "h", "-", "method", "kinetic", "estimator", "is", "less", "accurate", "than", "the", "tmethod", "kinetic", "energy", "estimator", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the h-method kinetic estimator", "start": 42, "end": 72, "i_start": 7, "i_end": 12}, "verb": {"text": "is", "start": 73, "end": 75, "i_start": 13, "i_end": 13}}], "id": 56}, {"sent": "for more details about the fractional laplacian operator , we refer the readers to , .", "tokens": ["for", "more", "details", "about", "the", "fractional", "laplacian", "operator", ",", "we", "refer", "the", "readers", "to", ",", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 59, "end": 61, "i_start": 9, "i_end": 9}, "verb": {"text": "refer", "start": 62, "end": 67, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 59, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "refer", "start": 62, "end": 67, "i_start": 10, "i_end": 10}}], "id": 57}, {"sent": "son et al showed that acoustic interference on mems gyroscopes in drones can cause them to crash .", "tokens": ["son", "et", "al", "showed", "that", "acoustic", "interference", "on", "mems", "gyroscopes", "in", "drones", "can", "cause", "them", "to", "crash", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "son et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 10, "end": 16, "i_start": 3, "i_end": 3}}, {"subject": {"text": "acoustic interference on mems gyroscopes in drones", "start": 22, "end": 72, "i_start": 5, "i_end": 11}, "verb": {"text": "cause", "start": 77, "end": 82, "i_start": 13, "i_end": 13}}, {"character": {"text": "interference", "start": 31, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "cause", "start": 77, "end": 82, "i_start": 13, "i_end": 13}}, {"character": {"text": "interference", "start": 31, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "crash", "start": 91, "end": 96, "i_start": 16, "i_end": 16}}], "id": 58}, {"sent": "one is the training set and the other is the testing set .", "tokens": ["one", "is", "the", "training", "set", "and", "the", "other", "is", "the", "testing", "set", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 4, "end": 6, "i_start": 1, "i_end": 1}}], "id": 59}, {"sent": "the average square amplitude of the island oscillations are equal for the harmonically oscillating island and the case of thermal equilibrium .", "tokens": ["the", "average", "square", "amplitude", "of", "the", "island", "oscillations", "are", "equal", "for", "the", "harmonically", "oscillating", "island", "and", "the", "case", "of", "thermal", "equilibrium", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the average square amplitude of the island oscillations", "start": 0, "end": 55, "i_start": 0, "i_end": 7}, "verb": {"text": "are", "start": 56, "end": 59, "i_start": 8, "i_end": 8}}], "id": 60}, {"sent": "deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification among many others .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "already", "achieved", "tremendous", "success", "on", "a", "variety", "of", "computer", "vision", "tasks", "such", "as", "image", "classification", "among", "many", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "achieved", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 68, "end": 75, "i_start": 8, "i_end": 8}}], "id": 61}, {"sent": "enthalpy calculations and structure relaxations were done using density functional theory within the perdew-burke-ernzerhof generalized gradient approximation .", "tokens": ["enthalpy", "calculations", "and", "structure", "relaxations", "were", "done", "using", "density", "functional", "theory", "within", "the", "perdew", "-", "burke", "-", "ernzerhof", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "enthalpy calculations and structure relaxations", "start": 0, "end": 47, "i_start": 0, "i_end": 4}, "verb": {"text": "were done", "start": 48, "end": 57, "i_start": 5, "i_end": 6}}], "id": 62}, {"sent": "improved upper bounds , breaking this barrier slightly , were given in developed a new approach for constructing ldcs that have much shorter codeword length than polynomial codes .", "tokens": ["improved", "upper", "bounds", ",", "breaking", "this", "barrier", "slightly", ",", "were", "given", "in", "developed", "a", "new", "approach", "for", "constructing", "ldcs", "that", "have", "much", "shorter", "codeword", "length", "than", "polynomial", "codes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "bounds", "start": 15, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "breaking", "start": 24, "end": 32, "i_start": 4, "i_end": 4}}], "id": 63}, {"sent": "kim et al proposed vdsr , which used cascaded filters and residual learning to obtain a larger receptive field and accelerate convergence .", "tokens": ["kim", "et", "al", "proposed", "vdsr", ",", "which", "used", "cascaded", "filters", "and", "residual", "learning", "to", "obtain", "a", "larger", "receptive", "field", "and", "accelerate", "convergence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "kim et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "kim", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}], "id": 64}, {"sent": "because the method does not involve the movement of any mechanical or optical components in the measurement process , it can be readily applied to fragile fibers .", "tokens": ["because", "the", "method", "does", "not", "involve", "the", "movement", "of", "any", "mechanical", "or", "optical", "components", "in", "the", "measurement", "process", ",", "it", "can", "be", "readily", "applied", "to", "fragile", "fibers", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 118, "end": 120, "i_start": 19, "i_end": 19}, "verb": {"text": "applied", "start": 136, "end": 143, "i_start": 23, "i_end": 23}}, {"subject": {"text": "it", "start": 118, "end": 120, "i_start": 19, "i_end": 19}, "verb": {"text": "can be", "start": 121, "end": 127, "i_start": 20, "i_end": 21}}, {"character": {"text": "not involve", "start": 24, "end": 35, "i_start": 4, "i_end": 5}, "action": {"text": "because", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}, {"character": {"text": "method", "start": 12, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "not involve", "start": 24, "end": 35, "i_start": 4, "i_end": 5}}], "id": 65}, {"sent": "we can not compute the minimum set of cut variables as this is the np-complete minimum feedback vertex set problem .", "tokens": ["we", "can", "not", "compute", "the", "minimum", "set", "of", "cut", "variables", "as", "this", "is", "the", "np", "-", "complete", "minimum", "feedback", "vertex", "set", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "can not compute", "start": 3, "end": 18, "i_start": 1, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compute", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}], "id": 66}, {"sent": "this bulging of the combined prior starts to resemble the 2 ball , and is in conflict with the geometric structures known to produce sparse solutions .", "tokens": ["this", "bulging", "of", "the", "combined", "prior", "starts", "to", "resemble", "the", "2", "ball", ",", "and", "is", "in", "conflict", "with", "the", "geometric", "structures", "known", "to", "produce", "sparse", "solutions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "bulging", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "starts", "start": 35, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "bulging", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "conflict", "start": 77, "end": 85, "i_start": 16, "i_end": 16}}, {"character": {"text": "structures", "start": 105, "end": 115, "i_start": 20, "i_end": 20}, "action": {"text": "produce", "start": 125, "end": 132, "i_start": 23, "i_end": 23}}], "id": 67}, {"sent": "it means that the approximation ignoring the turbulent fluctuation like the traditional transition theories could overestimate the range of cusp catastrophe .", "tokens": ["it", "means", "that", "the", "approximation", "ignoring", "the", "turbulent", "fluctuation", "like", "the", "traditional", "transition", "theories", "could", "overestimate", "the", "range", "of", "cusp", "catastrophe", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "means", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the approximation ignoring the turbulent fluctuation like the traditional transition theories", "start": 14, "end": 107, "i_start": 3, "i_end": 13}, "verb": {"text": "overestimate", "start": 114, "end": 126, "i_start": 15, "i_end": 15}}, {"character": {"text": "approximation", "start": 18, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "overestimate", "start": 114, "end": 126, "i_start": 15, "i_end": 15}}, {"character": {"text": "approximation", "start": 18, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "ignoring", "start": 32, "end": 40, "i_start": 5, "i_end": 5}}], "id": 68}, {"sent": "solubilization of rat brain mitochondrial hexokinase activity .", "tokens": ["solubilization", "of", "rat", "brain", "mitochondrial", "hexokinase", "activity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "brain", "start": 22, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "activity", "start": 53, "end": 61, "i_start": 6, "i_end": 6}}], "id": 69}, {"sent": "the only selection criterion adopted is the coverage parameter , defined in section 2 .", "tokens": ["the", "only", "selection", "criterion", "adopted", "is", "the", "coverage", "parameter", ",", "defined", "in", "section", "2", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the only selection criterion adopted", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 37, "end": 39, "i_start": 5, "i_end": 5}}], "id": 70}, {"sent": "when used as part of the cubetile programs , the base region is the kuhn simplex of eq .", "tokens": ["when", "used", "as", "part", "of", "the", "cubetile", "programs", ",", "the", "base", "region", "is", "the", "kuhn", "simplex", "of", "eq", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the base region", "start": 45, "end": 60, "i_start": 9, "i_end": 11}, "verb": {"text": "is", "start": 61, "end": 63, "i_start": 12, "i_end": 12}}], "id": 71}, {"sent": "convolutional neural networks have proven useful for a variety of high-level vision tasks .", "tokens": ["convolutional", "neural", "networks", "have", "proven", "useful", "for", "a", "variety", "of", "high", "-", "level", "vision", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have proven", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}], "id": 72}, {"sent": "perplexity is a standard measure within the speech recognition community for comparing language models .", "tokens": ["perplexity", "is", "a", "standard", "measure", "within", "the", "speech", "recognition", "community", "for", "comparing", "language", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "perplexity", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "community", "start": 63, "end": 72, "i_start": 9, "i_end": 9}, "action": {"text": "measure", "start": 25, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "community", "start": 63, "end": 72, "i_start": 9, "i_end": 9}, "action": {"text": "recognition", "start": 51, "end": 62, "i_start": 8, "i_end": 8}}], "id": 73}, {"sent": "jie et al developed a selftaught learning method to select more reliable seed positive proposals .", "tokens": ["jie", "et", "al", "developed", "a", "selftaught", "learning", "method", "to", "select", "more", "reliable", "seed", "positive", "proposals", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "jie et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "developed", "start": 10, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "jie", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "developed", "start": 10, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "jie", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "select", "start": 52, "end": 58, "i_start": 9, "i_end": 9}}], "id": 74}, {"sent": "other approaches in the bipartite setting include frequent closed itemset mining .", "tokens": ["other", "approaches", "in", "the", "bipartite", "setting", "include", "frequent", "closed", "itemset", "mining", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "other approaches in the bipartite setting", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "include", "start": 42, "end": 49, "i_start": 6, "i_end": 6}}], "id": 75}, {"sent": "closely related to our problem of choosing coordination leaders is leader election , where a group of agents has to jointly determine a leader .", "tokens": ["closely", "related", "to", "our", "problem", "of", "choosing", "coordination", "leaders", "is", "leader", "election", ",", "where", "a", "group", "of", "agents", "has", "to", "jointly", "determine", "a", "leader", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "group", "start": 93, "end": 98, "i_start": 15, "i_end": 15}, "action": {"text": "determine", "start": 124, "end": 133, "i_start": 21, "i_end": 21}}], "id": 76}, {"sent": "to this end , massive mimo and small cell are regarded as two key technologies for emerging 5g wireless systems .", "tokens": ["to", "this", "end", ",", "massive", "mimo", "and", "small", "cell", "are", "regarded", "as", "two", "key", "technologies", "for", "emerging", "5", "g", "wireless", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "massive mimo and small cell", "start": 14, "end": 41, "i_start": 4, "i_end": 8}, "verb": {"text": "are regarded", "start": 42, "end": 54, "i_start": 9, "i_end": 10}}, {"character": {"text": "systems", "start": 104, "end": 111, "i_start": 20, "i_end": 20}, "action": {"text": "emerging", "start": 83, "end": 91, "i_start": 16, "i_end": 16}}], "id": 77}, {"sent": "here we follow another approach and we explicitly take into account model uncertainty by combining predictions under different association structures using bayesian model averaging .", "tokens": ["here", "we", "follow", "another", "approach", "and", "we", "explicitly", "take", "into", "account", "model", "uncertainty", "by", "combining", "predictions", "under", "different", "association", "structures", "using", "bayesian", "model", "averaging", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "follow", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 36, "end": 38, "i_start": 6, "i_end": 6}, "verb": {"text": "take", "start": 50, "end": 54, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "follow", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "take", "start": 50, "end": 54, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "combining", "start": 89, "end": 98, "i_start": 14, "i_end": 14}}], "id": 78}, {"sent": "convolutional neural networks have been shown to be very successful on a variety of computer vision tasks , such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "been", "shown", "to", "be", "very", "successful", "on", "a", "variety", "of", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been shown", "start": 30, "end": 45, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 57, "end": 67, "i_start": 9, "i_end": 9}}], "id": 79}, {"sent": "large numbers of real-world systems can be described as complex networks , which are represented as undirected or directed graphs .", "tokens": ["large", "numbers", "of", "real", "-", "world", "systems", "can", "be", "described", "as", "complex", "networks", ",", "which", "are", "represented", "as", "undirected", "or", "directed", "graphs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "large numbers of real-world systems", "start": 0, "end": 35, "i_start": 0, "i_end": 6}, "verb": {"text": "can be described", "start": 36, "end": 52, "i_start": 7, "i_end": 9}}], "id": 80}, {"sent": "reid , published by the investment company institute .", "tokens": ["reid", ",", "published", "by", "the", "investment", "company", "institute", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "institute", "start": 43, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "published", "start": 7, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "company", "start": 35, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "investment", "start": 24, "end": 34, "i_start": 5, "i_end": 5}}], "id": 81}, {"sent": "backbone discovery in social networks .", "tokens": ["backbone", "discovery", "in", "social", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 82}, {"sent": "olympic sports dataset was collected from youtube sequences and contains 16 different sports categories with 50 videos per class .", "tokens": ["olympic", "sports", "dataset", "was", "collected", "from", "youtube", "sequences", "and", "contains", "16", "different", "sports", "categories", "with", "50", "videos", "per", "class", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "olympic sports dataset", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "was collected", "start": 23, "end": 36, "i_start": 3, "i_end": 4}}, {"subject": {"text": "olympic sports dataset", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "contains", "start": 64, "end": 72, "i_start": 9, "i_end": 9}}, {"character": {"text": "dataset", "start": 15, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "contains", "start": 64, "end": 72, "i_start": 9, "i_end": 9}}], "id": 83}, {"sent": "we use a gradient descent approach starting from a randomly sampled z .", "tokens": ["we", "use", "a", "gradient", "descent", "approach", "starting", "from", "a", "randomly", "sampled", "z", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 84}, {"sent": "we always add batch normalization non-linearity after each parametric layer except the output .", "tokens": ["we", "always", "add", "batch", "normalization", "non", "-", "linearity", "after", "each", "parametric", "layer", "except", "the", "output", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "add", "start": 10, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "add", "start": 10, "end": 13, "i_start": 2, "i_end": 2}}], "id": 85}, {"sent": "a batch normalization layer is added after each convolution layer .", "tokens": ["a", "batch", "normalization", "layer", "is", "added", "after", "each", "convolution", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a batch normalization layer", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "is added", "start": 28, "end": 36, "i_start": 4, "i_end": 5}}], "id": 86}, {"sent": "the crates are mounted with good thermal contact to the water cooled radial support bars .", "tokens": ["the", "crates", "are", "mounted", "with", "good", "thermal", "contact", "to", "the", "water", "cooled", "radial", "support", "bars", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the crates", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "are mounted", "start": 11, "end": 22, "i_start": 2, "i_end": 3}}, {"character": {"text": "bars", "start": 84, "end": 88, "i_start": 14, "i_end": 14}, "action": {"text": "support", "start": 76, "end": 83, "i_start": 13, "i_end": 13}}, {"character": {"text": "water", "start": 56, "end": 61, "i_start": 10, "i_end": 10}, "action": {"text": "cooled", "start": 62, "end": 68, "i_start": 11, "i_end": 11}}], "id": 87}, {"sent": "farabet et al used a multi-scale cnn trained from raw pixels to extract dense feature for assigning a label to each pixel .", "tokens": ["farabet", "et", "al", "used", "a", "multi", "-", "scale", "cnn", "trained", "from", "raw", "pixels", "to", "extract", "dense", "feature", "for", "assigning", "a", "label", "to", "each", "pixel", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "farabet et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 14, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "farabet", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 14, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "farabet", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "extract", "start": 64, "end": 71, "i_start": 14, "i_end": 14}}, {"character": {"text": "farabet", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "assigning", "start": 90, "end": 99, "i_start": 18, "i_end": 18}}], "id": 88}, {"sent": "technically , non-locality is a direct consequence of the non-triviality of elko spin sums .", "tokens": ["technically", ",", "non", "-", "locality", "is", "a", "direct", "consequence", "of", "the", "non", "-", "triviality", "of", "elko", "spin", "sums", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "non-locality", "start": 14, "end": 26, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 5, "i_end": 5}}], "id": 89}, {"sent": "the electronic exchange and correlation effects were treated by the generalized gradient approximation in the perdew , burke , and ernzerhof form .", "tokens": ["the", "electronic", "exchange", "and", "correlation", "effects", "were", "treated", "by", "the", "generalized", "gradient", "approximation", "in", "the", "perdew", ",", "burke", ",", "and", "ernzerhof", "form", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electronic exchange and correlation effects", "start": 0, "end": 47, "i_start": 0, "i_end": 5}, "verb": {"text": "were treated", "start": 48, "end": 60, "i_start": 6, "i_end": 7}}], "id": 90}, {"sent": "such a geometry is the obvious candidate to describe criticality,1 since it does admit an obvious action of the spatial part of the conformal group , which can be preserved at finite temperature .", "tokens": ["such", "a", "geometry", "is", "the", "obvious", "candidate", "to", "describe", "criticality,1", "since", "it", "does", "admit", "an", "obvious", "action", "of", "the", "spatial", "part", "of", "the", "conformal", "group", ",", "which", "can", "be", "preserved", "at", "finite", "temperature", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "such a geometry", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "candidate", "start": 31, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "describe", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "geometry", "start": 7, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "admit", "start": 81, "end": 86, "i_start": 13, "i_end": 13}}], "id": 91}, {"sent": "it should be kept in mind , however , that the interplay between lhc and lc could be qualitatively very different in different regions of the mssm parameter space .", "tokens": ["it", "should", "be", "kept", "in", "mind", ",", "however", ",", "that", "the", "interplay", "between", "lhc", "and", "lc", "could", "be", "qualitatively", "very", "different", "in", "different", "regions", "of", "the", "mssm", "parameter", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "should be kept", "start": 3, "end": 17, "i_start": 1, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "be", "start": 82, "end": 84, "i_start": 17, "i_end": 17}}], "id": 92}, {"sent": "such an invariance will guarantee the existence of massless fermions .", "tokens": ["such", "an", "invariance", "will", "guarantee", "the", "existence", "of", "massless", "fermions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "such an invariance", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "will guarantee", "start": 19, "end": 33, "i_start": 3, "i_end": 4}}, {"character": {"text": "invariance", "start": 8, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "guarantee", "start": 24, "end": 33, "i_start": 4, "i_end": 4}}], "id": 93}, {"sent": "the strongest clump is a part of the leading arm of the sgr dwarf tidal tail .", "tokens": ["the", "strongest", "clump", "is", "a", "part", "of", "the", "leading", "arm", "of", "the", "sgr", "dwarf", "tidal", "tail", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the strongest clump", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "arm", "start": 45, "end": 48, "i_start": 9, "i_end": 9}, "action": {"text": "leading", "start": 37, "end": 44, "i_start": 8, "i_end": 8}}], "id": 94}, {"sent": "deep neural networks have significantly improved the state of the art on many supervised tasks .", "tokens": ["deep", "neural", "networks", "have", "significantly", "improved", "the", "state", "of", "the", "art", "on", "many", "supervised", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}], "id": 95}, {"sent": "the ellipsis in is a shorthand expression for the full sugra action .", "tokens": ["the", "ellipsis", "in", "is", "a", "shorthand", "expression", "for", "the", "full", "sugra", "action", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ellipsis in", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 96}, {"sent": "deep neural networks are powerful models that achieve state-of-the-art performance across several domains , such as bioinformatics .", "tokens": ["deep", "neural", "networks", "are", "powerful", "models", "that", "achieve", "state", "-", "of", "-", "the", "-", "art", "performance", "across", "several", "domains", ",", "such", "as", "bioinformatics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 34, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "achieve", "start": 46, "end": 53, "i_start": 7, "i_end": 7}}], "id": 97}, {"sent": "the framework of residual learning was introduced by he et al as a strategy to cope with the challenging optimization of deep models .", "tokens": ["the", "framework", "of", "residual", "learning", "was", "introduced", "by", "he", "et", "al", "as", "a", "strategy", "to", "cope", "with", "the", "challenging", "optimization", "of", "deep", "models", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the framework of residual learning", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "was introduced", "start": 35, "end": 49, "i_start": 5, "i_end": 6}}, {"character": {"text": "he", "start": 53, "end": 55, "i_start": 8, "i_end": 8}, "action": {"text": "introduced", "start": 39, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "he", "start": 53, "end": 55, "i_start": 8, "i_end": 8}, "action": {"text": "cope", "start": 79, "end": 83, "i_start": 15, "i_end": 15}}, {"character": {"text": "optimization", "start": 105, "end": 117, "i_start": 19, "i_end": 19}, "action": {"text": "challenging", "start": 93, "end": 104, "i_start": 18, "i_end": 18}}], "id": 98}, {"sent": "these nanoblocks are composite materials which are con structed by combining dna grafted nanoparticles with specially designed dna sequences .", "tokens": ["these", "nanoblocks", "are", "composite", "materials", "which", "are", "con", "structed", "by", "combining", "dna", "grafted", "nanoparticles", "with", "specially", "designed", "dna", "sequences", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these nanoblocks", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 17, "end": 20, "i_start": 2, "i_end": 2}}], "id": 99}, {"sent": "the target space is the kk-melvin times the base space p1 of the k3 , and the modulus of the fiber corresponds to the linear combination of the dilaton and the r-r 0-form at each point of the base space .", "tokens": ["the", "target", "space", "is", "the", "kk", "-", "melvin", "times", "the", "base", "space", "p1", "of", "the", "k3", ",", "and", "the", "modulus", "of", "the", "fiber", "corresponds", "to", "the", "linear", "combination", "of", "the", "dilaton", "and", "the", "r", "-", "r", "0", "-", "form", "at", "each", "point", "of", "the", "base", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the target space", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the modulus of the fiber", "start": 74, "end": 98, "i_start": 18, "i_end": 22}, "verb": {"text": "corresponds", "start": 99, "end": 110, "i_start": 23, "i_end": 23}}], "id": 100}, {"sent": "deep convolutional neural networks have been prevailed in various computer vision tasks , such as objection classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "prevailed", "in", "various", "computer", "vision", "tasks", ",", "such", "as", "objection", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been prevailed", "start": 35, "end": 54, "i_start": 4, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "prevailed", "start": 45, "end": 54, "i_start": 6, "i_end": 6}}], "id": 101}, {"sent": "it has been proved that this approach is the only one that preserves altitudes of the passes between regions of the segmentation .", "tokens": ["it", "has", "been", "proved", "that", "this", "approach", "is", "the", "only", "one", "that", "preserves", "altitudes", "of", "the", "passes", "between", "regions", "of", "the", "segmentation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has been proved", "start": 3, "end": 18, "i_start": 1, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "approach", "start": 29, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "preserves", "start": 59, "end": 68, "i_start": 12, "i_end": 12}}], "id": 102}, {"sent": "r-c3d improves efficiency by sharing convolutional features across proposal generation and classification .", "tokens": ["r", "-", "c3d", "improves", "efficiency", "by", "sharing", "convolutional", "features", "across", "proposal", "generation", "and", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "-c3d", "start": 1, "end": 5, "i_start": 1, "i_end": 2}, "verb": {"text": "improves", "start": 6, "end": 14, "i_start": 3, "i_end": 3}}], "id": 103}, {"sent": "given these constraints on the two-photon amplitudes , we can correct ge and gm for two-photon exchange effects , with additional uncertainties associated with these corrections .", "tokens": ["given", "these", "constraints", "on", "the", "two", "-", "photon", "amplitudes", ",", "we", "can", "correct", "ge", "and", "gm", "for", "two", "-", "photon", "exchange", "effects", ",", "with", "additional", "uncertainties", "associated", "with", "these", "corrections", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 55, "end": 57, "i_start": 10, "i_end": 10}, "verb": {"text": "can correct", "start": 58, "end": 69, "i_start": 11, "i_end": 12}}, {"character": {"text": "we", "start": 55, "end": 57, "i_start": 10, "i_end": 10}, "action": {"text": "correct", "start": 62, "end": 69, "i_start": 12, "i_end": 12}}], "id": 104}, {"sent": "in recent years , convolutional neural networks have become the de facto standard in many computer vision tasks , such as image classification and object detection .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "become", "the", "de", "facto", "standard", "in", "many", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "and", "object", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have become", "start": 48, "end": 59, "i_start": 7, "i_end": 8}}], "id": 105}, {"sent": "the important objects , parafermion and paraboson fock spaces are characterized by a parameter p , and their explicit construction was given recently in and in .", "tokens": ["the", "important", "objects", ",", "parafermion", "and", "paraboson", "fock", "spaces", "are", "characterized", "by", "a", "parameter", "p", ",", "and", "their", "explicit", "construction", "was", "given", "recently", "in", "and", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the important objects", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "are characterized", "start": 62, "end": 79, "i_start": 9, "i_end": 10}}, {"subject": {"text": "their explicit construction", "start": 103, "end": 130, "i_start": 17, "i_end": 19}, "verb": {"text": "given", "start": 135, "end": 140, "i_start": 21, "i_end": 21}}], "id": 106}, {"sent": "the two most significant types are the variational auto-encoders and generative adversarial networks .", "tokens": ["the", "two", "most", "significant", "types", "are", "the", "variational", "auto", "-", "encoders", "and", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the two most significant types", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "are", "start": 31, "end": 34, "i_start": 5, "i_end": 5}}], "id": 107}, {"sent": "deep convolutional neural networks have achieved great success in various computer vision tasks such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "various", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}], "id": 108}, {"sent": "deep neural networks are powerful machine learning systems , which have been demonstrated in a variety of tasks including image classification among others .", "tokens": ["deep", "neural", "networks", "are", "powerful", "machine", "learning", "systems", ",", "which", "have", "been", "demonstrated", "in", "a", "variety", "of", "tasks", "including", "image", "classification", "among", "others", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "systems", "start": 51, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "learning", "start": 42, "end": 50, "i_start": 6, "i_end": 6}}], "id": 109}, {"sent": "the proposal by dijkgraaf and vafa , links these superpotentials with quantities in random matrix models .", "tokens": ["the", "proposal", "by", "dijkgraaf", "and", "vafa", ",", "links", "these", "superpotentials", "with", "quantities", "in", "random", "matrix", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "dijkgraaf", "start": 16, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "proposal", "start": 4, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "vafa", "start": 30, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "proposal", "start": 4, "end": 12, "i_start": 1, "i_end": 1}}], "id": 110}, {"sent": "statistical decision theory and bayesian analysis .", "tokens": ["statistical", "decision", "theory", "and", "bayesian", "analysis", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 111}, {"sent": "zou et al proposed a tree-based algorithm to detect curve-like cracks from pavement images .", "tokens": ["zou", "et", "al", "proposed", "a", "tree", "-", "based", "algorithm", "to", "detect", "curve", "-", "like", "cracks", "from", "pavement", "images", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 4, "end": 9, "i_start": 1, "i_end": 2}, "verb": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "zou", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithm", "start": 32, "end": 41, "i_start": 8, "i_end": 8}, "action": {"text": "detect", "start": 45, "end": 51, "i_start": 10, "i_end": 10}}], "id": 112}, {"sent": "by using the intersection theory on smooth divisors , we have the following corollary .", "tokens": ["by", "using", "the", "intersection", "theory", "on", "smooth", "divisors", ",", "we", "have", "the", "following", "corollary", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 54, "end": 56, "i_start": 9, "i_end": 9}, "verb": {"text": "have", "start": 57, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 54, "end": 56, "i_start": 9, "i_end": 9}, "action": {"text": "have", "start": 57, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 54, "end": 56, "i_start": 9, "i_end": 9}, "action": {"text": "using", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 113}, {"sent": "deep neural networks have shown remarkable success in many domains , such as computer vision .", "tokens": ["deep", "neural", "networks", "have", "shown", "remarkable", "success", "in", "many", "domains", ",", "such", "as", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}], "id": 114}, {"sent": "recent work includes the semantic hashing , which designs the hash function using a restricted boltzmann machine .", "tokens": ["recent", "work", "includes", "the", "semantic", "hashing", ",", "which", "designs", "the", "hash", "function", "using", "a", "restricted", "boltzmann", "machine", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "recent work", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "includes", "start": 12, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "hash", "start": 62, "end": 66, "i_start": 10, "i_end": 10}, "action": {"text": "designs", "start": 50, "end": 57, "i_start": 8, "i_end": 8}}], "id": 115}, {"sent": "dephasing is due primarily to scattering of thermally excited ripplons off an electron .", "tokens": ["dephasing", "is", "due", "primarily", "to", "scattering", "of", "thermally", "excited", "ripplons", "off", "an", "electron", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dephasing", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 1, "i_end": 1}}], "id": 116}, {"sent": "in addition , as demonstrated in , llr clipping also allows to tune the mimo detection algorithm in terms of complexity versus performance by adjusting the clipping parameter .", "tokens": ["in", "addition", ",", "as", "demonstrated", "in", ",", "llr", "clipping", "also", "allows", "to", "tune", "the", "mimo", "detection", "algorithm", "in", "terms", "of", "complexity", "versus", "performance", "by", "adjusting", "the", "clipping", "parameter", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "llr clipping", "start": 35, "end": 47, "i_start": 7, "i_end": 8}, "verb": {"text": "allows", "start": 53, "end": 59, "i_start": 10, "i_end": 10}}, {"character": {"text": "clipping", "start": 156, "end": 164, "i_start": 26, "i_end": 26}, "action": {"text": "allows", "start": 53, "end": 59, "i_start": 10, "i_end": 10}}, {"character": {"text": "algorithm", "start": 87, "end": 96, "i_start": 16, "i_end": 16}, "action": {"text": "detection", "start": 77, "end": 86, "i_start": 15, "i_end": 15}}], "id": 117}, {"sent": "sparse recovery is one of the essential issues in many fields of signal processing , including compressed sampling , which is a novel sampling theory .", "tokens": ["sparse", "recovery", "is", "one", "of", "the", "essential", "issues", "in", "many", "fields", "of", "signal", "processing", ",", "including", "compressed", "sampling", ",", "which", "is", "a", "novel", "sampling", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "sparse recovery", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 118}, {"sent": "physical layer security has been widely regarded as a promising complement to the cryptographic techniques to secure the data transmission over wireless channels .", "tokens": ["physical", "layer", "security", "has", "been", "widely", "regarded", "as", "a", "promising", "complement", "to", "the", "cryptographic", "techniques", "to", "secure", "the", "data", "transmission", "over", "wireless", "channels", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "physical layer security", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "regarded", "start": 40, "end": 48, "i_start": 6, "i_end": 6}}, {"subject": {"text": "physical layer security", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "has been", "start": 24, "end": 32, "i_start": 3, "i_end": 4}}, {"character": {"text": "complement", "start": 64, "end": 74, "i_start": 10, "i_end": 10}, "action": {"text": "promising", "start": 54, "end": 63, "i_start": 9, "i_end": 9}}], "id": 119}, {"sent": "an overview of coordinate descent algorithms for various optimization problems with different constraints is presented in .", "tokens": ["an", "overview", "of", "coordinate", "descent", "algorithms", "for", "various", "optimization", "problems", "with", "different", "constraints", "is", "presented", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "an overview of coordinate descent algorithms for various optimization problems with different constraints", "start": 0, "end": 105, "i_start": 0, "i_end": 12}, "verb": {"text": "is presented", "start": 106, "end": 118, "i_start": 13, "i_end": 14}}], "id": 120}, {"sent": "the closure a of a is a positive self-adjoint operator .", "tokens": ["the", "closure", "a", "of", "a", "is", "a", "positive", "self", "-", "adjoint", "operator", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 121}, {"sent": "deep convolutional neural networks have been proven very useful in various tasks in computer vision including classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "proven", "very", "useful", "in", "various", "tasks", "in", "computer", "vision", "including", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been proven", "start": 35, "end": 51, "i_start": 4, "i_end": 6}}], "id": 122}, {"sent": "papernot et al proposed distillation as another possible defense against adversarial examples .", "tokens": ["papernot", "et", "al", "proposed", "distillation", "as", "another", "possible", "defense", "against", "adversarial", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "papernot et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "papernot", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 123}, {"sent": "a qubit is a two-level quantum system , and possibilites include the spin states of an electron or the polarization states of a photon .", "tokens": ["a", "qubit", "is", "a", "two", "-", "level", "quantum", "system", ",", "and", "possibilites", "include", "the", "spin", "states", "of", "an", "electron", "or", "the", "polarization", "states", "of", "a", "photon", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a qubit", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 2, "i_end": 2}}, {"subject": {"text": "possibilites", "start": 44, "end": 56, "i_start": 11, "i_end": 11}, "verb": {"text": "include", "start": 57, "end": 64, "i_start": 12, "i_end": 12}}], "id": 124}, {"sent": "recently , deep learning algorithms have successfully addressed problems in various fields , such as image classification , machine translation , speech recognition , text-to-speech generation and other machine learning related areas .", "tokens": ["recently", ",", "deep", "learning", "algorithms", "have", "successfully", "addressed", "problems", "in", "various", "fields", ",", "such", "as", "image", "classification", ",", "machine", "translation", ",", "speech", "recognition", ",", "text", "-", "to", "-", "speech", "generation", "and", "other", "machine", "learning", "related", "areas", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning algorithms", "start": 11, "end": 35, "i_start": 2, "i_end": 4}, "verb": {"text": "addressed", "start": 54, "end": 63, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep learning algorithms", "start": 11, "end": 35, "i_start": 2, "i_end": 4}, "verb": {"text": "have", "start": 36, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "algorithms", "start": 25, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "addressed", "start": 54, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "algorithms", "start": 25, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "learning", "start": 211, "end": 219, "i_start": 33, "i_end": 33}}, {"character": {"text": "algorithms", "start": 25, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "successfully", "start": 41, "end": 53, "i_start": 6, "i_end": 6}}], "id": 125}, {"sent": "for the experiment , we used a visual geometry group 16-layer cnn trained using the imagenet large scale visual recognition challenge 2012 dataset .", "tokens": ["for", "the", "experiment", ",", "we", "used", "a", "visual", "geometry", "group", "16", "-", "layer", "cnn", "trained", "using", "the", "imagenet", "large", "scale", "visual", "recognition", "challenge", "2012", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "used", "start": 24, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "used", "start": 24, "end": 28, "i_start": 5, "i_end": 5}}], "id": 126}, {"sent": "projector augmentedwave pseudopotentials and perdew-burke-ernzerhof gradient approximation to the exchange-correlation functional were used .", "tokens": ["projector", "augmentedwave", "pseudopotentials", "and", "perdew", "-", "burke", "-", "ernzerhof", "gradient", "approximation", "to", "the", "exchange", "-", "correlation", "functional", "were", "used", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "projector augmentedwave pseudopotentials and perdew-burke-ernzerhof gradient approximation to the exchange-correlation functional", "start": 0, "end": 129, "i_start": 0, "i_end": 16}, "verb": {"text": "were used", "start": 130, "end": 139, "i_start": 17, "i_end": 18}}], "id": 127}, {"sent": "with this result , we show that the two functions in the previous example are indeed equivalent in linear contexts .", "tokens": ["with", "this", "result", ",", "we", "show", "that", "the", "two", "functions", "in", "the", "previous", "example", "are", "indeed", "equivalent", "in", "linear", "contexts", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "verb": {"text": "show", "start": 22, "end": 26, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "verb": {"text": "are", "start": 74, "end": 77, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "show", "start": 22, "end": 26, "i_start": 5, "i_end": 5}}], "id": 128}, {"sent": "the scalar-relativistic ab-initio dft calculations were performed using the projector augmented wave .", "tokens": ["the", "scalar", "-", "relativistic", "ab", "-", "initio", "dft", "calculations", "were", "performed", "using", "the", "projector", "augmented", "wave", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the scalar-relativistic ab-initio dft calculations", "start": 0, "end": 50, "i_start": 0, "i_end": 8}, "verb": {"text": "were performed", "start": 51, "end": 65, "i_start": 9, "i_end": 10}}, {"character": {"text": "projector", "start": 76, "end": 85, "i_start": 13, "i_end": 13}, "action": {"text": "augmented", "start": 86, "end": 95, "i_start": 14, "i_end": 14}}], "id": 129}, {"sent": "conway-gordon showed that k 6 is il , where k m denotes the complete graph on m vertices .", "tokens": ["conway", "-", "gordon", "showed", "that", "k", "6", "is", "il", ",", "where", "k", "m", "denotes", "the", "complete", "graph", "on", "m", "vertices", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "conway-gordon", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 14, "end": 20, "i_start": 3, "i_end": 3}}, {"subject": {"text": "conway-gordon", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 7, "i_end": 7}}, {"character": {"text": "conway", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 14, "end": 20, "i_start": 3, "i_end": 3}}], "id": 130}, {"sent": "the model was trained end-to-end using the adam optimizer .", "tokens": ["the", "model", "was", "trained", "end", "-", "to", "-", "end", "using", "the", "adam", "optimizer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "was trained", "start": 10, "end": 21, "i_start": 2, "i_end": 3}}], "id": 131}, {"sent": "in this way , it seems that we might be facing an intrinsically approximate feature in the description of the interaction of radiation and matter at the classical level .", "tokens": ["in", "this", "way", ",", "it", "seems", "that", "we", "might", "be", "facing", "an", "intrinsically", "approximate", "feature", "in", "the", "description", "of", "the", "interaction", "of", "radiation", "and", "matter", "at", "the", "classical", "level", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "verb": {"text": "seems", "start": 17, "end": 22, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 28, "end": 30, "i_start": 7, "i_end": 7}, "verb": {"text": "facing", "start": 40, "end": 46, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 28, "end": 30, "i_start": 7, "i_end": 7}, "action": {"text": "facing", "start": 40, "end": 46, "i_start": 10, "i_end": 10}}, {"character": {"text": "radiation", "start": 125, "end": 134, "i_start": 22, "i_end": 22}, "action": {"text": "interaction", "start": 110, "end": 121, "i_start": 20, "i_end": 20}}], "id": 132}, {"sent": "for example , the winding number has been directly measured by mean chiral displacement in the photonic quantum walk .", "tokens": ["for", "example", ",", "the", "winding", "number", "has", "been", "directly", "measured", "by", "mean", "chiral", "displacement", "in", "the", "photonic", "quantum", "walk", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the winding number", "start": 14, "end": 32, "i_start": 3, "i_end": 5}, "verb": {"text": "measured", "start": 51, "end": 59, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the winding number", "start": 14, "end": 32, "i_start": 3, "i_end": 5}, "verb": {"text": "has been", "start": 33, "end": 41, "i_start": 6, "i_end": 7}}], "id": 133}, {"sent": "one of the common techniques for finding related topics within unstructured text is the latent dirichlet allocation .", "tokens": ["one", "of", "the", "common", "techniques", "for", "finding", "related", "topics", "within", "unstructured", "text", "is", "the", "latent", "dirichlet", "allocation", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "one of the common techniques for finding related topics within unstructured text", "start": 0, "end": 80, "i_start": 0, "i_end": 11}, "verb": {"text": "is", "start": 81, "end": 83, "i_start": 12, "i_end": 12}}], "id": 134}, {"sent": "we introduce a gan like generative model to capture the distribution of the unknown adversarial perturbations .", "tokens": ["we", "introduce", "a", "gan", "like", "generative", "model", "to", "capture", "the", "distribution", "of", "the", "unknown", "adversarial", "perturbations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "introduce", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "introduce", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "capture", "start": 44, "end": 51, "i_start": 8, "i_end": 8}}], "id": 135}, {"sent": "over the past few years , neural networks has been widely used in some domains , such as large vocabulary continuous speech recognition .", "tokens": ["over", "the", "past", "few", "years", ",", "neural", "networks", "has", "been", "widely", "used", "in", "some", "domains", ",", "such", "as", "large", "vocabulary", "continuous", "speech", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 26, "end": 41, "i_start": 6, "i_end": 7}, "verb": {"text": "used", "start": 58, "end": 62, "i_start": 11, "i_end": 11}}, {"subject": {"text": "neural networks", "start": 26, "end": 41, "i_start": 6, "i_end": 7}, "verb": {"text": "has been", "start": 42, "end": 50, "i_start": 8, "i_end": 9}}], "id": 136}, {"sent": "perturbation theory is a very powerful method that allows the very precise calculation of many observables within quantum field theory for small couplings \u03bb , eg cross sections , etc .", "tokens": ["perturbation", "theory", "is", "a", "very", "powerful", "method", "that", "allows", "the", "very", "precise", "calculation", "of", "many", "observables", "within", "quantum", "field", "theory", "for", "small", "couplings", "\u03bb", ",", "eg", "cross", "sections", ",", "etc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "perturbation theory", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "method", "start": 39, "end": 45, "i_start": 6, "i_end": 6}, "action": {"text": "allows", "start": 51, "end": 57, "i_start": 8, "i_end": 8}}], "id": 137}, {"sent": "a weak galerkin finite element method for second-order elliptic problems .", "tokens": ["a", "weak", "galerkin", "finite", "element", "method", "for", "second", "-", "order", "elliptic", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 138}, {"sent": "it is well-known that \u03b3 embeds as a co-compact discrete subgroup of a simply connected nilpotent lie group g , its malcev closure .", "tokens": ["it", "is", "well", "-", "known", "that", "\u03b3", "embeds", "as", "a", "co", "-", "compact", "discrete", "subgroup", "of", "a", "simply", "connected", "nilpotent", "lie", "group", "g", ",", "its", "malcev", "closure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "\u03b3", "start": 22, "end": 23, "i_start": 6, "i_end": 6}, "verb": {"text": "embeds", "start": 24, "end": 30, "i_start": 7, "i_end": 7}}, {"character": {"text": "embeds", "start": 24, "end": 30, "i_start": 7, "i_end": 7}, "action": {"text": "closure", "start": 122, "end": 129, "i_start": 26, "i_end": 26}}], "id": 139}, {"sent": "we use the vgg-16 model in released by its authors as initialization , in order to accelerate the convergence speed .", "tokens": ["we", "use", "the", "vgg-16", "model", "in", "released", "by", "its", "authors", "as", "initialization", ",", "in", "order", "to", "accelerate", "the", "convergence", "speed", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "vgg-16", "start": 11, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "released", "start": 27, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "accelerate", "start": 83, "end": 93, "i_start": 16, "i_end": 16}}], "id": 140}, {"sent": "the inner and full error bars represent respectively the experimental and total errors .", "tokens": ["the", "inner", "and", "full", "error", "bars", "represent", "respectively", "the", "experimental", "and", "total", "errors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the inner and full error bars", "start": 0, "end": 29, "i_start": 0, "i_end": 5}, "verb": {"text": "represent", "start": 30, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "bars", "start": 25, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "represent", "start": 30, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "error", "start": 19, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "represent", "start": 30, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "inner", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "represent", "start": 30, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "error", "start": 19, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "represent", "start": 30, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "full", "start": 14, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "represent", "start": 30, "end": 39, "i_start": 6, "i_end": 6}}], "id": 141}, {"sent": "recently it was shown in a group of subjects of different age , that the bold signal variability is a better predictor of the subject age than the average .", "tokens": ["recently", "it", "was", "shown", "in", "a", "group", "of", "subjects", "of", "different", "age", ",", "that", "the", "bold", "signal", "variability", "is", "a", "better", "predictor", "of", "the", "subject", "age", "than", "the", "average", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 9, "end": 11, "i_start": 1, "i_end": 1}, "verb": {"text": "was shown", "start": 12, "end": 21, "i_start": 2, "i_end": 3}}, {"subject": {"text": "it", "start": 9, "end": 11, "i_start": 1, "i_end": 1}, "verb": {"text": "is", "start": 97, "end": 99, "i_start": 18, "i_end": 18}}, {"character": {"text": "variability", "start": 85, "end": 96, "i_start": 17, "i_end": 17}, "action": {"text": "predictor", "start": 109, "end": 118, "i_start": 21, "i_end": 21}}], "id": 142}, {"sent": "the more general notion of poisson groupoid was introduced by weinstein .", "tokens": ["the", "more", "general", "notion", "of", "poisson", "groupoid", "was", "introduced", "by", "weinstein", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the more general notion of poisson groupoid", "start": 0, "end": 43, "i_start": 0, "i_end": 6}, "verb": {"text": "was introduced", "start": 44, "end": 58, "i_start": 7, "i_end": 8}}, {"character": {"text": "weinstein", "start": 62, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "introduced", "start": 48, "end": 58, "i_start": 8, "i_end": 8}}], "id": 143}, {"sent": "we also present the corresponding analytical predictions for the unquenched theory at fixed gauge field topology .", "tokens": ["we", "also", "present", "the", "corresponding", "analytical", "predictions", "for", "the", "unquenched", "theory", "at", "fixed", "gauge", "field", "topology", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "present", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "present", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}], "id": 144}, {"sent": "calibration and imaging were done using the miriad data reduction package .", "tokens": ["calibration", "and", "imaging", "were", "done", "using", "the", "miriad", "data", "reduction", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "calibration and imaging", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "were done", "start": 24, "end": 33, "i_start": 3, "i_end": 4}}, {"character": {"text": "package", "start": 66, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "reduction", "start": 56, "end": 65, "i_start": 9, "i_end": 9}}], "id": 145}, {"sent": "the insets show the bell and zig-zag shapes of the linear modes with highest and lowest frequency , respectively .", "tokens": ["the", "insets", "show", "the", "bell", "and", "zig", "-", "zag", "shapes", "of", "the", "linear", "modes", "with", "highest", "and", "lowest", "frequency", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the insets", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "show", "start": 11, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "insets", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 11, "end": 15, "i_start": 2, "i_end": 2}}], "id": 146}, {"sent": "actually we show that the einstein equations in vacuum reduce to the trivial minkowskian electrodynamics from the static metric representing this electrostatic spacetime .", "tokens": ["actually", "we", "show", "that", "the", "einstein", "equations", "in", "vacuum", "reduce", "to", "the", "trivial", "minkowskian", "electrodynamics", "from", "the", "static", "metric", "representing", "this", "electrostatic", "spacetime", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 9, "end": 11, "i_start": 1, "i_end": 1}, "verb": {"text": "show", "start": 12, "end": 16, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the einstein equations in vacuum", "start": 22, "end": 54, "i_start": 4, "i_end": 8}, "verb": {"text": "reduce", "start": 55, "end": 61, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 9, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 12, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "electrodynamics", "start": 89, "end": 104, "i_start": 14, "i_end": 14}, "action": {"text": "representing", "start": 128, "end": 140, "i_start": 19, "i_end": 19}}], "id": 147}, {"sent": "variational inference for large-scale models of discrete choice .", "tokens": ["variational", "inference", "for", "large", "-", "scale", "models", "of", "discrete", "choice", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 148}, {"sent": "the d-brane is a non-perturbative object , but there is a well defined perturbation theory around the object itself .", "tokens": ["the", "d", "-", "brane", "is", "a", "non", "-", "perturbative", "object", ",", "but", "there", "is", "a", "well", "defined", "perturbation", "theory", "around", "the", "object", "itself", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the d-brane", "start": 0, "end": 11, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 4, "i_end": 4}}, {"subject": {"text": "there", "start": 47, "end": 52, "i_start": 12, "i_end": 12}, "verb": {"text": "is", "start": 53, "end": 55, "i_start": 13, "i_end": 13}}, {"character": {"text": "object", "start": 34, "end": 40, "i_start": 9, "i_end": 9}, "action": {"text": "-brane is a non-perturbative", "start": 5, "end": 33, "i_start": 2, "i_end": 8}}], "id": 149}, {"sent": "continuity of nonlinear monotone operators .", "tokens": ["continuity", "of", "nonlinear", "monotone", "operators", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 150}, {"sent": "it was introduced by the author in 2004 based on the joint research with steven seif on the celebrated perkins semigroup , which has played a central role in semigroup theory since 1960 , particularly as a source of examples and counterexamples .", "tokens": ["it", "was", "introduced", "by", "the", "author", "in", "2004", "based", "on", "the", "joint", "research", "with", "steven", "seif", "on", "the", "celebrated", "perkins", "semigroup", ",", "which", "has", "played", "a", "central", "role", "in", "semigroup", "theory", "since", "1960", ",", "particularly", "as", "a", "source", "of", "examples", "and", "counterexamples", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "was introduced", "start": 3, "end": 17, "i_start": 1, "i_end": 2}}, {"character": {"text": "steven seif", "start": 73, "end": 84, "i_start": 14, "i_end": 15}, "action": {"text": "research", "start": 59, "end": 67, "i_start": 12, "i_end": 12}}, {"character": {"text": "semigroup", "start": 111, "end": 120, "i_start": 20, "i_end": 20}, "action": {"text": "played", "start": 133, "end": 139, "i_start": 24, "i_end": 24}}, {"character": {"text": "semigroup", "start": 111, "end": 120, "i_start": 20, "i_end": 20}, "action": {"text": "source", "start": 206, "end": 212, "i_start": 37, "i_end": 37}}], "id": 151}, {"sent": "finally , we have discussed the universality that is observed in the persistence behavior in several systems at the directed percolation transition .", "tokens": ["finally", ",", "we", "have", "discussed", "the", "universality", "that", "is", "observed", "in", "the", "persistence", "behavior", "in", "several", "systems", "at", "the", "directed", "percolation", "transition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "have discussed", "start": 13, "end": 27, "i_start": 3, "i_end": 4}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "discussed", "start": 18, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "behavior", "start": 81, "end": 89, "i_start": 13, "i_end": 13}, "action": {"text": "observed", "start": 53, "end": 61, "i_start": 9, "i_end": 9}}, {"character": {"text": "systems", "start": 101, "end": 108, "i_start": 16, "i_end": 16}, "action": {"text": "behavior", "start": 81, "end": 89, "i_start": 13, "i_end": 13}}, {"character": {"text": "systems", "start": 101, "end": 108, "i_start": 16, "i_end": 16}, "action": {"text": "persistence", "start": 69, "end": 80, "i_start": 12, "i_end": 12}}], "id": 152}, {"sent": "cluster algebras were introduced in 2002 by fomin and zelevinsky .", "tokens": ["cluster", "algebras", "were", "introduced", "in", "2002", "by", "fomin", "and", "zelevinsky", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were introduced", "start": 17, "end": 32, "i_start": 2, "i_end": 3}}, {"character": {"text": "fomin", "start": 44, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "zelevinsky", "start": 54, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}], "id": 153}, {"sent": "in fact , very few studies include the chip package in their simulations or measurements and , those that do it , are limited to low frequencies or lack proper justifications on the antenna type and placement .", "tokens": ["in", "fact", ",", "very", "few", "studies", "include", "the", "chip", "package", "in", "their", "simulations", "or", "measurements", "and", ",", "those", "that", "do", "it", ",", "are", "limited", "to", "low", "frequencies", "or", "lack", "proper", "justifications", "on", "the", "antenna", "type", "and", "placement", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "very few studies", "start": 10, "end": 26, "i_start": 3, "i_end": 5}, "verb": {"text": "include", "start": 27, "end": 34, "i_start": 6, "i_end": 6}}, {"subject": {"text": "those that do it", "start": 95, "end": 111, "i_start": 17, "i_end": 20}, "verb": {"text": "limited", "start": 118, "end": 125, "i_start": 23, "i_end": 23}}, {"character": {"text": "studies", "start": 19, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "include", "start": 27, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "studies", "start": 19, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "simulations", "start": 61, "end": 72, "i_start": 12, "i_end": 12}}, {"character": {"text": "studies", "start": 19, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "measurements", "start": 76, "end": 88, "i_start": 14, "i_end": 14}}], "id": 154}, {"sent": "we also compare our results with the available experimental data .", "tokens": ["we", "also", "compare", "our", "results", "with", "the", "available", "experimental", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}], "id": 155}, {"sent": "we will illustrate each of them by one example .", "tokens": ["we", "will", "illustrate", "each", "of", "them", "by", "one", "example", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will illustrate", "start": 3, "end": 18, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "illustrate", "start": 8, "end": 18, "i_start": 2, "i_end": 2}}], "id": 156}, {"sent": "in their recent work , han et al propose quantization and coding techniques for compressing neural networks .", "tokens": ["in", "their", "recent", "work", ",", "han", "et", "al", "propose", "quantization", "and", "coding", "techniques", "for", "compressing", "neural", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "han et al", "start": 23, "end": 32, "i_start": 5, "i_end": 7}, "verb": {"text": "propose", "start": 33, "end": 40, "i_start": 8, "i_end": 8}}, {"subject": {"text": "han et al", "start": 23, "end": 32, "i_start": 5, "i_end": 7}, "verb": {"text": "coding", "start": 58, "end": 64, "i_start": 11, "i_end": 11}}, {"character": {"text": "han", "start": 23, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "propose", "start": 33, "end": 40, "i_start": 8, "i_end": 8}}, {"character": {"text": "han", "start": 23, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "work", "start": 16, "end": 20, "i_start": 3, "i_end": 3}}], "id": 157}, {"sent": "one of the most important extensions of the concept of chaos in sense of li and yorke is distributional chaos as introduced in .", "tokens": ["one", "of", "the", "most", "important", "extensions", "of", "the", "concept", "of", "chaos", "in", "sense", "of", "li", "and", "yorke", "is", "distributional", "chaos", "as", "introduced", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "one of the most important extensions of the concept of chaos in sense of li and yorke", "start": 0, "end": 85, "i_start": 0, "i_end": 16}, "verb": {"text": "is", "start": 86, "end": 88, "i_start": 17, "i_end": 17}}], "id": 158}, {"sent": "all the dft calculations were performed with the ab-initio simulation package vasp using the projector augmented wave method .", "tokens": ["all", "the", "dft", "calculations", "were", "performed", "with", "the", "ab", "-", "initio", "simulation", "package", "vasp", "using", "the", "projector", "augmented", "wave", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all the dft calculations", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "were performed", "start": 25, "end": 39, "i_start": 4, "i_end": 5}}, {"character": {"text": "projector", "start": 93, "end": 102, "i_start": 16, "i_end": 16}, "action": {"text": "augmented", "start": 103, "end": 112, "i_start": 17, "i_end": 17}}], "id": 159}, {"sent": "deep convolutional neural networks have made great progress in visual recognition challenges such as object classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "great", "progress", "in", "visual", "recognition", "challenges", "such", "as", "object", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}], "id": 160}, {"sent": "now we define some of the properties enjoyed by these interval matrix groupoids .", "tokens": ["now", "we", "define", "some", "of", "the", "properties", "enjoyed", "by", "these", "interval", "matrix", "groupoids", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "define", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "groupoids", "start": 70, "end": 79, "i_start": 12, "i_end": 12}, "action": {"text": "enjoyed", "start": 37, "end": 44, "i_start": 7, "i_end": 7}}], "id": 161}, {"sent": "the idea of is similar to deep domain confusion and deep adaptation network except that instead of mmd , they adopted coral loss to minimize the discrepancy .", "tokens": ["the", "idea", "of", "is", "similar", "to", "deep", "domain", "confusion", "and", "deep", "adaptation", "network", "except", "that", "instead", "of", "mmd", ",", "they", "adopted", "coral", "loss", "to", "minimize", "the", "discrepancy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the idea of", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 3, "i_end": 3}}, {"subject": {"text": "they", "start": 105, "end": 109, "i_start": 19, "i_end": 19}, "verb": {"text": "adopted", "start": 110, "end": 117, "i_start": 20, "i_end": 20}}, {"character": {"text": "they", "start": 105, "end": 109, "i_start": 19, "i_end": 19}, "action": {"text": "adopted", "start": 110, "end": 117, "i_start": 20, "i_end": 20}}, {"character": {"text": "they", "start": 105, "end": 109, "i_start": 19, "i_end": 19}, "action": {"text": "minimize", "start": 132, "end": 140, "i_start": 24, "i_end": 24}}], "id": 162}, {"sent": "in figures 5 and 6 , we provide a comparison of the estimated frames obtained by vsrresnet and the spmc-vsr for scale factors of 2 and 4 .", "tokens": ["in", "figures", "5", "and", "6", ",", "we", "provide", "a", "comparison", "of", "the", "estimated", "frames", "obtained", "by", "vsrresnet", "and", "the", "spmc", "-", "vsr", "for", "scale", "factors", "of", "2", "and", "4", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 6, "i_end": 6}, "verb": {"text": "provide", "start": 24, "end": 31, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 6, "i_end": 6}, "action": {"text": "provide", "start": 24, "end": 31, "i_start": 7, "i_end": 7}}], "id": 163}, {"sent": "in the last few years , convolutional neural networks have demonstrated outstanding performances in various applications including image recognition , object detection , and recently speech acoustic modeling .", "tokens": ["in", "the", "last", "few", "years", ",", "convolutional", "neural", "networks", "have", "demonstrated", "outstanding", "performances", "in", "various", "applications", "including", "image", "recognition", ",", "object", "detection", ",", "and", "recently", "speech", "acoustic", "modeling", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 24, "end": 53, "i_start": 6, "i_end": 8}, "verb": {"text": "have demonstrated", "start": 54, "end": 71, "i_start": 9, "i_end": 10}}, {"subject": {"text": "convolutional neural networks", "start": 24, "end": 53, "i_start": 6, "i_end": 8}, "verb": {"text": "speech", "start": 183, "end": 189, "i_start": 25, "i_end": 25}}, {"character": {"text": "networks", "start": 45, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "demonstrated", "start": 59, "end": 71, "i_start": 10, "i_end": 10}}, {"character": {"text": "networks", "start": 45, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "performances", "start": 84, "end": 96, "i_start": 12, "i_end": 12}}], "id": 164}, {"sent": "the cms particle-flow event algorithm aims to reconstruct and identify each individual particle in an event , with an optimized combination of information from the various elements of the detector .", "tokens": ["the", "cms", "particle", "-", "flow", "event", "algorithm", "aims", "to", "reconstruct", "and", "identify", "each", "individual", "particle", "in", "an", "event", ",", "with", "an", "optimized", "combination", "of", "information", "from", "the", "various", "elements", "of", "the", "detector", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the cms particle-flow event algorithm", "start": 0, "end": 37, "i_start": 0, "i_end": 6}, "verb": {"text": "aims", "start": 38, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "algorithm", "start": 28, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "aims", "start": 38, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "algorithm", "start": 28, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "reconstruct", "start": 46, "end": 57, "i_start": 9, "i_end": 9}}, {"character": {"text": "algorithm", "start": 28, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "identify", "start": 62, "end": 70, "i_start": 11, "i_end": 11}}], "id": 165}, {"sent": "the topology of torus actions on symplectic manifolds .", "tokens": ["the", "topology", "of", "torus", "actions", "on", "symplectic", "manifolds", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 166}, {"sent": "nucleus is the text span that contains essential information , in that its absence would reduce the meaningfulness of the text .", "tokens": ["nucleus", "is", "the", "text", "span", "that", "contains", "essential", "information", ",", "in", "that", "its", "absence", "would", "reduce", "the", "meaningfulness", "of", "the", "text", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "nucleus", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "span", "start": 20, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "contains", "start": 30, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "contains", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "reduce", "start": 89, "end": 95, "i_start": 15, "i_end": 15}}, {"character": {"text": "text", "start": 15, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "meaningfulness", "start": 100, "end": 114, "i_start": 17, "i_end": 17}}], "id": 167}, {"sent": "a cluster facilitated kinetic ising model for supercooled liquids .", "tokens": ["a", "cluster", "facilitated", "kinetic", "ising", "model", "for", "supercooled", "liquids", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a cluster", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "facilitated", "start": 10, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "cluster", "start": 2, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "facilitated", "start": 10, "end": 21, "i_start": 2, "i_end": 2}}], "id": 168}, {"sent": "chiral symmetry is a group of transformations which acts on the light quark fields .", "tokens": ["chiral", "symmetry", "is", "a", "group", "of", "transformations", "which", "acts", "on", "the", "light", "quark", "fields", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "chiral symmetry", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "group", "start": 21, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "acts", "start": 52, "end": 56, "i_start": 8, "i_end": 8}}], "id": 169}, {"sent": "we assume here that all relevant parameters are real quantities .", "tokens": ["we", "assume", "here", "that", "all", "relevant", "parameters", "are", "real", "quantities", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 44, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 170}, {"sent": "super-resolution from a single image has recently received a huge boost in performance using deep-learning based methods .", "tokens": ["super", "-", "resolution", "from", "a", "single", "image", "has", "recently", "received", "a", "huge", "boost", "in", "performance", "using", "deep", "-", "learning", "based", "methods", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "super-resolution from a single image", "start": 0, "end": 36, "i_start": 0, "i_end": 6}, "verb": {"text": "received", "start": 50, "end": 58, "i_start": 9, "i_end": 9}}, {"subject": {"text": "super-resolution from a single image", "start": 0, "end": 36, "i_start": 0, "i_end": 6}, "verb": {"text": "has", "start": 37, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "resolution", "start": 6, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "boost", "start": 66, "end": 71, "i_start": 12, "i_end": 12}}], "id": 171}, {"sent": "we initialise the base convolutional architecture via the pre-trained vgg16 , resnet-50 , and resnet-101 .", "tokens": ["we", "initialise", "the", "base", "convolutional", "architecture", "via", "the", "pre", "-", "trained", "vgg16", ",", "resnet-50", ",", "and", "resnet-101", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "initialise", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "initialise", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}], "id": 172}, {"sent": "the remarkable recent successes of the deep convolutional neural networks are particularly based on this ability to learn hierarchical representation for spatial data .", "tokens": ["the", "remarkable", "recent", "successes", "of", "the", "deep", "convolutional", "neural", "networks", "are", "particularly", "based", "on", "this", "ability", "to", "learn", "hierarchical", "representation", "for", "spatial", "data", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the remarkable recent successes of the deep convolutional neural networks", "start": 0, "end": 73, "i_start": 0, "i_end": 9}, "verb": {"text": "based", "start": 91, "end": 96, "i_start": 12, "i_end": 12}}, {"subject": {"text": "the remarkable recent successes of the deep convolutional neural networks", "start": 0, "end": 73, "i_start": 0, "i_end": 9}, "verb": {"text": "are", "start": 74, "end": 77, "i_start": 10, "i_end": 10}}, {"character": {"text": "networks", "start": 65, "end": 73, "i_start": 9, "i_end": 9}, "action": {"text": "successes", "start": 22, "end": 31, "i_start": 3, "i_end": 3}}], "id": 173}, {"sent": "deep convolutional neural networks have demonstrated superior performance in various computer vision tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "demonstrated", "superior", "performance", "in", "various", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have demonstrated", "start": 35, "end": 52, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "demonstrated", "start": 40, "end": 52, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 62, "end": 73, "i_start": 7, "i_end": 7}}], "id": 174}, {"sent": "deep convolutional neural networks have been successful in many computer vision tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successful", "in", "many", "computer", "vision", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "successful", "start": 45, "end": 55, "i_start": 6, "i_end": 6}}], "id": 175}, {"sent": "if the multiplication , we say that s is a semitopological semigroup .", "tokens": ["if", "the", "multiplication", ",", "we", "say", "that", "s", "is", "a", "semitopological", "semigroup", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 24, "end": 26, "i_start": 4, "i_end": 4}, "verb": {"text": "say", "start": 27, "end": 30, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 24, "end": 26, "i_start": 4, "i_end": 4}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "say", "start": 27, "end": 30, "i_start": 5, "i_end": 5}}], "id": 176}, {"sent": "subsequently , the attention mechanism gives rise to a significant performance boost to video captioning .", "tokens": ["subsequently", ",", "the", "attention", "mechanism", "gives", "rise", "to", "a", "significant", "performance", "boost", "to", "video", "captioning", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the attention mechanism", "start": 15, "end": 38, "i_start": 2, "i_end": 4}, "verb": {"text": "gives", "start": 39, "end": 44, "i_start": 5, "i_end": 5}}, {"character": {"text": "mechanism", "start": 29, "end": 38, "i_start": 4, "i_end": 4}, "action": {"text": "rise", "start": 45, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "mechanism", "start": 29, "end": 38, "i_start": 4, "i_end": 4}, "action": {"text": "boost", "start": 79, "end": 84, "i_start": 11, "i_end": 11}}], "id": 177}, {"sent": "removing optimization issues have been a reliable way of improving performance in deep neural networks .", "tokens": ["removing", "optimization", "issues", "have", "been", "a", "reliable", "way", "of", "improving", "performance", "in", "deep", "neural", "networks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "removing optimization issues", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 29, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "optimization", "start": 9, "end": 21, "i_start": 1, "i_end": 1}, "action": {"text": "issues", "start": 22, "end": 28, "i_start": 2, "i_end": 2}}, {"character": {"text": "networks", "start": 94, "end": 102, "i_start": 14, "i_end": 14}, "action": {"text": "performance", "start": 67, "end": 78, "i_start": 10, "i_end": 10}}], "id": 178}, {"sent": "then this minimal expression is the unique minimal expression of \u03bb .", "tokens": ["then", "this", "minimal", "expression", "is", "the", "unique", "minimal", "expression", "of", "\u03bb", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this minimal expression", "start": 5, "end": 28, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 4, "i_end": 4}}], "id": 179}, {"sent": "generative adversarial networks are a framework for training generative parametric models , and have been shown to produce high quality images .", "tokens": ["generative", "adversarial", "networks", "are", "a", "framework", "for", "training", "generative", "parametric", "models", ",", "and", "have", "been", "shown", "to", "produce", "high", "quality", "images", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}, {"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "shown", "start": 106, "end": 111, "i_start": 15, "i_end": 15}}], "id": 180}, {"sent": "convolutional neural networks has shown phenomenal results for many computer vision applications .", "tokens": ["convolutional", "neural", "networks", "has", "shown", "phenomenal", "results", "for", "many", "computer", "vision", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "has shown", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 34, "end": 39, "i_start": 4, "i_end": 4}}], "id": 181}, {"sent": "convolutional neural networks have shown its great effectiveness in computer vision tasks .", "tokens": ["convolutional", "neural", "networks", "have", "shown", "its", "great", "effectiveness", "in", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 35, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "effectiveness", "start": 51, "end": 64, "i_start": 7, "i_end": 7}}], "id": 182}, {"sent": "zhang et al propose a bi-directional message passing module , where messages can transmit mutually controlled by gate function .", "tokens": ["zhang", "et", "al", "propose", "a", "bi", "-", "directional", "message", "passing", "module", ",", "where", "messages", "can", "transmit", "mutually", "controlled", "by", "gate", "function", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhang et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "module", "start": 53, "end": 59, "i_start": 10, "i_end": 10}, "action": {"text": "passing", "start": 45, "end": 52, "i_start": 9, "i_end": 9}}, {"character": {"text": "function", "start": 118, "end": 126, "i_start": 20, "i_end": 20}, "action": {"text": "controlled", "start": 99, "end": 109, "i_start": 17, "i_end": 17}}], "id": 183}, {"sent": "we use the vgg16 net with only convolution layers as our architecture .", "tokens": ["we", "use", "the", "vgg16", "net", "with", "only", "convolution", "layers", "as", "our", "architecture", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 184}, {"sent": "we produce some interesting examples and counterexamples in the complex plane .", "tokens": ["we", "produce", "some", "interesting", "examples", "and", "counterexamples", "in", "the", "complex", "plane", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "produce", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "produce", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "examples", "start": 28, "end": 36, "i_start": 4, "i_end": 4}, "action": {"text": "interesting", "start": 16, "end": 27, "i_start": 3, "i_end": 3}}], "id": 185}, {"sent": "such leading-order and high-twist contributions from quark-quark double scattering essentially mix the quark and gluon fragmentation functions .", "tokens": ["such", "leading", "-", "order", "and", "high", "-", "twist", "contributions", "from", "quark", "-", "quark", "double", "scattering", "essentially", "mix", "the", "quark", "and", "gluon", "fragmentation", "functions", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "such leading-order and high-twist contributions from quark-quark double scattering", "start": 0, "end": 82, "i_start": 0, "i_end": 14}, "verb": {"text": "mix", "start": 95, "end": 98, "i_start": 16, "i_end": 16}}, {"character": {"text": "contributions", "start": 34, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "mix", "start": 95, "end": 98, "i_start": 16, "i_end": 16}}, {"character": {"text": "order", "start": 13, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "contributions", "start": 34, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "such", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "contributions", "start": 34, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "order", "start": 13, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "leading", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "quark", "start": 53, "end": 58, "i_start": 10, "i_end": 10}, "action": {"text": "scattering", "start": 72, "end": 82, "i_start": 14, "i_end": 14}}, {"character": {"text": "quark", "start": 59, "end": 64, "i_start": 12, "i_end": 12}, "action": {"text": "scattering", "start": 72, "end": 82, "i_start": 14, "i_end": 14}}, {"character": {"text": "double", "start": 65, "end": 71, "i_start": 13, "i_end": 13}, "action": {"text": "scattering", "start": 72, "end": 82, "i_start": 14, "i_end": 14}}, {"character": {"text": "quark", "start": 53, "end": 58, "i_start": 10, "i_end": 10}, "action": {"text": "functions", "start": 133, "end": 142, "i_start": 22, "i_end": 22}}], "id": 186}, {"sent": "the characteristics of the nascent star are calculated using the stellar evolution tracks obtained with the stellar code .", "tokens": ["the", "characteristics", "of", "the", "nascent", "star", "are", "calculated", "using", "the", "stellar", "evolution", "tracks", "obtained", "with", "the", "stellar", "code", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the characteristics of the nascent star", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "are calculated", "start": 40, "end": 54, "i_start": 6, "i_end": 7}}], "id": 187}, {"sent": "moreover , they presented evidence to suggest that double hurwitz numbers are equal to integrals over moduli spaces of curves equipped with a line bundle .", "tokens": ["moreover", ",", "they", "presented", "evidence", "to", "suggest", "that", "double", "hurwitz", "numbers", "are", "equal", "to", "integrals", "over", "moduli", "spaces", "of", "curves", "equipped", "with", "a", "line", "bundle", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 11, "end": 15, "i_start": 2, "i_end": 2}, "verb": {"text": "presented", "start": 16, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "they", "start": 11, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "presented", "start": 16, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "evidence", "start": 26, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "suggest", "start": 38, "end": 45, "i_start": 6, "i_end": 6}}], "id": 188}, {"sent": "recently , generative models based on deep neural networks have shown exciting new perspectives for image synthesis .", "tokens": ["recently", ",", "generative", "models", "based", "on", "deep", "neural", "networks", "have", "shown", "exciting", "new", "perspectives", "for", "image", "synthesis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "generative models based on deep neural networks", "start": 11, "end": 58, "i_start": 2, "i_end": 8}, "verb": {"text": "have shown", "start": 59, "end": 69, "i_start": 9, "i_end": 10}}, {"character": {"text": "models", "start": 22, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 64, "end": 69, "i_start": 10, "i_end": 10}}, {"character": {"text": "perspectives", "start": 83, "end": 95, "i_start": 13, "i_end": 13}, "action": {"text": "exciting", "start": 70, "end": 78, "i_start": 11, "i_end": 11}}], "id": 189}, {"sent": "in this case , \u03b3 is called a geometric mirror symmetry .", "tokens": ["in", "this", "case", ",", "\u03b3", "is", "called", "a", "geometric", "mirror", "symmetry", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "\u03b3", "start": 15, "end": 16, "i_start": 4, "i_end": 4}, "verb": {"text": "is called", "start": 17, "end": 26, "i_start": 5, "i_end": 6}}], "id": 190}, {"sent": "this is comparable to pre-processing steps , such as removing stopwords and high-and low-frequency words , that are typically carried out prior to applying topic models .", "tokens": ["this", "is", "comparable", "to", "pre", "-", "processing", "steps", ",", "such", "as", "removing", "stopwords", "and", "high", "-", "and", "low", "-", "frequency", "words", ",", "that", "are", "typically", "carried", "out", "prior", "to", "applying", "topic", "models", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "that", "start": 107, "end": 111, "i_start": 22, "i_end": 22}, "verb": {"text": "carried out", "start": 126, "end": 137, "i_start": 25, "i_end": 26}}, {"subject": {"text": "that", "start": 107, "end": 111, "i_start": 22, "i_end": 22}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "that", "start": 107, "end": 111, "i_start": 22, "i_end": 22}, "verb": {"text": "are", "start": 112, "end": 115, "i_start": 23, "i_end": 23}}], "id": 191}, {"sent": "the parasitic ringing generated by trap method can be solved either by switching to gear2 or via step no .", "tokens": ["the", "parasitic", "ringing", "generated", "by", "trap", "method", "can", "be", "solved", "either", "by", "switching", "to", "gear2", "or", "via", "step", "no", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the parasitic ringing generated by trap method", "start": 0, "end": 46, "i_start": 0, "i_end": 6}, "verb": {"text": "can be solved", "start": 47, "end": 60, "i_start": 7, "i_end": 9}}, {"character": {"text": "method", "start": 40, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "generated", "start": 22, "end": 31, "i_start": 3, "i_end": 3}}], "id": 192}, {"sent": "motivated by its relevance , literally hundreds of clustering algorithms have been developed in the past decades .", "tokens": ["motivated", "by", "its", "relevance", ",", "literally", "hundreds", "of", "clustering", "algorithms", "have", "been", "developed", "in", "the", "past", "decades", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "hundreds of clustering algorithms", "start": 39, "end": 72, "i_start": 6, "i_end": 9}, "verb": {"text": "have been developed", "start": 73, "end": 92, "i_start": 10, "i_end": 12}}, {"character": {"text": "relevance", "start": 17, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "motivated", "start": 0, "end": 9, "i_start": 0, "i_end": 0}}], "id": 193}, {"sent": "flux-flow hall effect in superconducting .", "tokens": ["flux", "-", "flow", "hall", "effect", "in", "superconducting", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "superconducting", "start": 25, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "effect", "start": 15, "end": 21, "i_start": 4, "i_end": 4}}], "id": 194}, {"sent": "tilde denotes the charge conjugate spinors .", "tokens": ["tilde", "denotes", "the", "charge", "conjugate", "spinors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "tilde", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "denotes", "start": 6, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "tilde", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "denotes", "start": 6, "end": 13, "i_start": 1, "i_end": 1}}], "id": 195}, {"sent": "many methods relatively simple are commonly used , such as measuring distance from the starting structure as a function of simulation time , and calculation of various autocorrelation functions .", "tokens": ["many", "methods", "relatively", "simple", "are", "commonly", "used", ",", "such", "as", "measuring", "distance", "from", "the", "starting", "structure", "as", "a", "function", "of", "simulation", "time", ",", "and", "calculation", "of", "various", "autocorrelation", "functions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many methods relatively simple", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "used", "start": 44, "end": 48, "i_start": 6, "i_end": 6}}, {"subject": {"text": "many methods relatively simple", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 31, "end": 34, "i_start": 4, "i_end": 4}}], "id": 196}, {"sent": "the dominant term is the first term in gmax , a .", "tokens": ["the", "dominant", "term", "is", "the", "first", "term", "in", "gmax", ",", "a", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dominant term", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "term is the first term in gmax , a", "start": 13, "end": 47, "i_start": 2, "i_end": 10}, "action": {"text": "dominant", "start": 4, "end": 12, "i_start": 1, "i_end": 1}}], "id": 197}, {"sent": "on classical yang-baxter equation for simple lie algebras .", "tokens": ["on", "classical", "yang", "-", "baxter", "equation", "for", "simple", "lie", "algebras", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 198}, {"sent": "convolutional neural networks have achieved notable successes in a variety of visual recognition tasks , such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "notable", "successes", "in", "a", "variety", "of", "visual", "recognition", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successes", "start": 52, "end": 61, "i_start": 6, "i_end": 6}}], "id": 199}, {"sent": "every eigenvector of a for which there is a non-zero expansion coefficient in this expansion must also lie in the physical subspace .", "tokens": ["every", "eigenvector", "of", "a", "for", "which", "there", "is", "a", "non", "-", "zero", "expansion", "coefficient", "in", "this", "expansion", "must", "also", "lie", "in", "the", "physical", "subspace", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "every eigenvector of a for which there is a non-zero expansion coefficient in this expansion", "start": 0, "end": 92, "i_start": 0, "i_end": 16}, "verb": {"text": "lie", "start": 103, "end": 106, "i_start": 19, "i_end": 19}}, {"subject": {"text": "every eigenvector of a for which there is a non-zero expansion coefficient in this expansion", "start": 0, "end": 92, "i_start": 0, "i_end": 16}, "verb": {"text": "must", "start": 93, "end": 97, "i_start": 17, "i_end": 17}}], "id": 200}, {"sent": "on directional regression for dimension reduction .", "tokens": ["on", "directional", "regression", "for", "dimension", "reduction", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 201}, {"sent": "convolutional neural networks have been extensively studied in the computer vision literature to tackle a variety of tasks , such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "been", "extensively", "studied", "in", "the", "computer", "vision", "literature", "to", "tackle", "a", "variety", "of", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "studied", "start": 52, "end": 59, "i_start": 6, "i_end": 6}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "tackle", "start": 97, "end": 103, "i_start": 13, "i_end": 13}}], "id": 202}, {"sent": "let us concentrate on the clock and denote its mass by m .", "tokens": ["let", "us", "concentrate", "on", "the", "clock", "and", "denote", "its", "mass", "by", "m", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "concentrate", "start": 7, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "concentrate", "start": 7, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 36, "end": 42, "i_start": 7, "i_end": 7}}], "id": 203}, {"sent": "weighted automata provide a natural and flexible framework to express quantitative 1 properties .", "tokens": ["weighted", "automata", "provide", "a", "natural", "and", "flexible", "framework", "to", "express", "quantitative", "1", "properties", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "weighted automata", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "provide", "start": 18, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "automata", "start": 9, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "provide", "start": 18, "end": 25, "i_start": 2, "i_end": 2}}], "id": 204}, {"sent": "as discussed in , this improvement can be attributed to the fact that the integration of absolute velocity measurements can provide a substitute for the otherwise lacking absolute position feedback .", "tokens": ["as", "discussed", "in", ",", "this", "improvement", "can", "be", "attributed", "to", "the", "fact", "that", "the", "integration", "of", "absolute", "velocity", "measurements", "can", "provide", "a", "substitute", "for", "the", "otherwise", "lacking", "absolute", "position", "feedback", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this improvement", "start": 18, "end": 34, "i_start": 4, "i_end": 5}, "verb": {"text": "can be attributed", "start": 35, "end": 52, "i_start": 6, "i_end": 8}}, {"character": {"text": "integration", "start": 74, "end": 85, "i_start": 14, "i_end": 14}, "action": {"text": "substitute", "start": 134, "end": 144, "i_start": 22, "i_end": 22}}], "id": 205}, {"sent": "for the cifar-10 , cifar-100 and svhn datasets , we use a resnet-110 model .", "tokens": ["for", "the", "cifar-10", ",", "cifar-100", "and", "svhn", "datasets", ",", "we", "use", "a", "resnet-110", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "verb": {"text": "use", "start": 52, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "action": {"text": "use", "start": 52, "end": 55, "i_start": 10, "i_end": 10}}], "id": 206}, {"sent": "string theory has been successful in accounting for the statistical entropy of many supersymmetric asymptotically flat black holes .", "tokens": ["string", "theory", "has", "been", "successful", "in", "accounting", "for", "the", "statistical", "entropy", "of", "many", "supersymmetric", "asymptotically", "flat", "black", "holes", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "string theory", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has been", "start": 14, "end": 22, "i_start": 2, "i_end": 3}}, {"character": {"text": "theory", "start": 7, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "successful", "start": 23, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "theory", "start": 7, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "accounting", "start": 37, "end": 47, "i_start": 6, "i_end": 6}}], "id": 207}, {"sent": "in this section , we extend the results on classical graphs in to plain algorithmically random mags .", "tokens": ["in", "this", "section", ",", "we", "extend", "the", "results", "on", "classical", "graphs", "in", "to", "plain", "algorithmically", "random", "mags", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "extend", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "extend", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 208}, {"sent": "the bogoliubov fermi surfaces are topologically protected by a z 2 invariant , which we have given explicitly in terms of the pfaffian of the bdg hamiltonian transformed into antisymmetric form .", "tokens": ["the", "bogoliubov", "fermi", "surfaces", "are", "topologically", "protected", "by", "a", "z", "2", "invariant", ",", "which", "we", "have", "given", "explicitly", "in", "terms", "of", "the", "pfaffian", "of", "the", "bdg", "hamiltonian", "transformed", "into", "antisymmetric", "form", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the bogoliubov fermi surfaces", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "protected", "start": 48, "end": 57, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the bogoliubov fermi surfaces", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "invariant", "start": 67, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "protected", "start": 48, "end": 57, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 85, "end": 87, "i_start": 14, "i_end": 14}, "action": {"text": "given", "start": 93, "end": 98, "i_start": 16, "i_end": 16}}], "id": 209}, {"sent": "specifically , we utilise a u-net architecture with skip connections .", "tokens": ["specifically", ",", "we", "utilise", "a", "u", "-", "net", "architecture", "with", "skip", "connections", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "utilise", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "utilise", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}], "id": 210}, {"sent": "wireless network densification is viewed as a promising approach to enable a 1000x improvement in wireless cellular network capacity .", "tokens": ["wireless", "network", "densification", "is", "viewed", "as", "a", "promising", "approach", "to", "enable", "a", "1000x", "improvement", "in", "wireless", "cellular", "network", "capacity", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "wireless network densification", "start": 0, "end": 30, "i_start": 0, "i_end": 2}, "verb": {"text": "is viewed", "start": 31, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "densification", "start": 17, "end": 30, "i_start": 2, "i_end": 2}, "action": {"text": "approach", "start": 56, "end": 64, "i_start": 8, "i_end": 8}}, {"character": {"text": "densification", "start": 17, "end": 30, "i_start": 2, "i_end": 2}, "action": {"text": "enable", "start": 68, "end": 74, "i_start": 10, "i_end": 10}}, {"character": {"text": "approach", "start": 56, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "promising", "start": 46, "end": 55, "i_start": 7, "i_end": 7}}], "id": 211}, {"sent": "to break this fundamental limitation , cyclegan enforces the oneto-one mapping with the help of cycle consistency loss .", "tokens": ["to", "break", "this", "fundamental", "limitation", ",", "cyclegan", "enforces", "the", "oneto", "-", "one", "mapping", "with", "the", "help", "of", "cycle", "consistency", "loss", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "cyclegan", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "verb": {"text": "enforces", "start": 48, "end": 56, "i_start": 7, "i_end": 7}}, {"character": {"text": "cyclegan", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "enforces", "start": 48, "end": 56, "i_start": 7, "i_end": 7}}, {"character": {"text": "cyclegan", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "break", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 212}, {"sent": "lda takes raw text , the number of topics and a dictionary of words as the input , and outputs the most significant topics with words from the raw data .", "tokens": ["lda", "takes", "raw", "text", ",", "the", "number", "of", "topics", "and", "a", "dictionary", "of", "words", "as", "the", "input", ",", "and", "outputs", "the", "most", "significant", "topics", "with", "words", "from", "the", "raw", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "lda", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "takes", "start": 4, "end": 9, "i_start": 1, "i_end": 1}}], "id": 213}, {"sent": "its output frequency is locked to a high finesse optical cavity by the pound-dreverhall stabilization technique .", "tokens": ["its", "output", "frequency", "is", "locked", "to", "a", "high", "finesse", "optical", "cavity", "by", "the", "pound", "-", "dreverhall", "stabilization", "technique", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "its output frequency", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "is locked", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}], "id": 214}, {"sent": "to be more precise , we may consider the ten-dimensional supergravity constructed in , where the supersymmetrisation of the anomaly-canceling trterm in the bianchi identity for the 3-form h was studied .", "tokens": ["to", "be", "more", "precise", ",", "we", "may", "consider", "the", "ten", "-", "dimensional", "supergravity", "constructed", "in", ",", "where", "the", "supersymmetrisation", "of", "the", "anomaly", "-", "canceling", "trterm", "in", "the", "bianchi", "identity", "for", "the", "3", "-", "form", "h", "was", "studied", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 5, "i_end": 5}, "verb": {"text": "may consider", "start": 24, "end": 36, "i_start": 6, "i_end": 7}}, {"subject": {"text": "the ten-dimensional supergravity", "start": 37, "end": 69, "i_start": 8, "i_end": 12}, "verb": {"text": "constructed", "start": 70, "end": 81, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 5, "i_end": 5}, "action": {"text": "consider", "start": 28, "end": 36, "i_start": 7, "i_end": 7}}], "id": 215}, {"sent": "the source of noncompactness is contained in the following lemma .", "tokens": ["the", "source", "of", "noncompactness", "is", "contained", "in", "the", "following", "lemma", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the source of noncompactness", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "is contained", "start": 29, "end": 41, "i_start": 4, "i_end": 5}}, {"character": {"text": "lemma", "start": 59, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "contained", "start": 32, "end": 41, "i_start": 5, "i_end": 5}}], "id": 216}, {"sent": "however , most of interesting distributed tasks can not be solved in a wait-free manner .", "tokens": ["however", ",", "most", "of", "interesting", "distributed", "tasks", "can", "not", "be", "solved", "in", "a", "wait", "-", "free", "manner", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "most of interesting distributed tasks", "start": 10, "end": 47, "i_start": 2, "i_end": 6}, "verb": {"text": "can not be solved", "start": 48, "end": 65, "i_start": 7, "i_end": 10}}], "id": 217}, {"sent": "the kuramoto model with inertia has been widely used for deepening the understanding of power grids .", "tokens": ["the", "kuramoto", "model", "with", "inertia", "has", "been", "widely", "used", "for", "deepening", "the", "understanding", "of", "power", "grids", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the kuramoto model with inertia", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "used", "start": 48, "end": 52, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the kuramoto model with inertia", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "has been", "start": 32, "end": 40, "i_start": 5, "i_end": 6}}], "id": 218}, {"sent": "the model was trained using adam with the batch size of 64 in all our experiments .", "tokens": ["the", "model", "was", "trained", "using", "adam", "with", "the", "batch", "size", "of", "64", "in", "all", "our", "experiments", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "was trained", "start": 10, "end": 21, "i_start": 2, "i_end": 3}}], "id": 219}, {"sent": "the initial weights throughout the network are initialized using the xavier initialization scheme .", "tokens": ["the", "initial", "weights", "throughout", "the", "network", "are", "initialized", "using", "the", "xavier", "initialization", "scheme", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the initial weights throughout the network", "start": 0, "end": 42, "i_start": 0, "i_end": 5}, "verb": {"text": "are initialized", "start": 43, "end": 58, "i_start": 6, "i_end": 7}}], "id": 220}, {"sent": "generative adversarial networks have gained significant popularity in the machine learning community recently as it provides a novel and easy way to learn generative models .", "tokens": ["generative", "adversarial", "networks", "have", "gained", "significant", "popularity", "in", "the", "machine", "learning", "community", "recently", "as", "it", "provides", "a", "novel", "and", "easy", "way", "to", "learn", "generative", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "have gained", "start": 32, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "gained", "start": 37, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "community", "start": 91, "end": 100, "i_start": 11, "i_end": 11}, "action": {"text": "learning", "start": 82, "end": 90, "i_start": 10, "i_end": 10}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "provides", "start": 116, "end": 124, "i_start": 15, "i_end": 15}}], "id": 221}, {"sent": "one degree of freedom is the size of this triangle , and in this sense the bispectrum has scale-dependence much like the power spectrum p\u03b6 .", "tokens": ["one", "degree", "of", "freedom", "is", "the", "size", "of", "this", "triangle", ",", "and", "in", "this", "sense", "the", "bispectrum", "has", "scale", "-", "dependence", "much", "like", "the", "power", "spectrum", "p\u03b6", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "one degree of freedom", "start": 0, "end": 21, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the bispectrum", "start": 71, "end": 85, "i_start": 15, "i_end": 16}, "verb": {"text": "has", "start": 86, "end": 89, "i_start": 17, "i_end": 17}}, {"character": {"text": "bispectrum", "start": 75, "end": 85, "i_start": 16, "i_end": 16}, "action": {"text": "dependence", "start": 96, "end": 106, "i_start": 20, "i_end": 20}}], "id": 222}, {"sent": "the first inequality follows from concavity of entropy .", "tokens": ["the", "first", "inequality", "follows", "from", "concavity", "of", "entropy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the first inequality", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "follows", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}], "id": 223}, {"sent": "inflation is one of the leading paradigms for explaining the physical conditions that prevailed in the very early universe .", "tokens": ["inflation", "is", "one", "of", "the", "leading", "paradigms", "for", "explaining", "the", "physical", "conditions", "that", "prevailed", "in", "the", "very", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "inflation", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "paradigms", "start": 32, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "leading", "start": 24, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "conditions", "start": 70, "end": 80, "i_start": 11, "i_end": 11}, "action": {"text": "prevailed", "start": 86, "end": 95, "i_start": 13, "i_end": 13}}], "id": 224}, {"sent": "low-density parity-check codes exhibit extraordinary performance under iterative decoding over a wide range of communication channels .", "tokens": ["low", "-", "density", "parity", "-", "check", "codes", "exhibit", "extraordinary", "performance", "under", "iterative", "decoding", "over", "a", "wide", "range", "of", "communication", "channels", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "low-density parity-check codes", "start": 0, "end": 30, "i_start": 0, "i_end": 6}, "verb": {"text": "exhibit", "start": 31, "end": 38, "i_start": 7, "i_end": 7}}, {"character": {"text": "codes", "start": 25, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "exhibit", "start": 31, "end": 38, "i_start": 7, "i_end": 7}}, {"character": {"text": "codes", "start": 25, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "check", "start": 19, "end": 24, "i_start": 5, "i_end": 5}}, {"character": {"text": "codes", "start": 25, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 9, "i_end": 9}}], "id": 225}, {"sent": "the high-level architecture for the generator network is inspired by autoencoder-like u-net models .", "tokens": ["the", "high", "-", "level", "architecture", "for", "the", "generator", "network", "is", "inspired", "by", "autoencoder", "-", "like", "u", "-", "net", "models", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the high-level architecture for the generator network", "start": 0, "end": 53, "i_start": 0, "i_end": 8}, "verb": {"text": "is inspired", "start": 54, "end": 65, "i_start": 9, "i_end": 10}}, {"character": {"text": "models", "start": 92, "end": 98, "i_start": 18, "i_end": 18}, "action": {"text": "inspired", "start": 57, "end": 65, "i_start": 10, "i_end": 10}}, {"character": {"text": "network", "start": 46, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "generator", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}], "id": 226}, {"sent": "then , computing this tree efficiently given the graph has been an important challenge of the past three decades .", "tokens": ["then", ",", "computing", "this", "tree", "efficiently", "given", "the", "graph", "has", "been", "an", "important", "challenge", "of", "the", "past", "three", "decades", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "computing this tree efficiently given the graph", "start": 7, "end": 54, "i_start": 2, "i_end": 8}, "verb": {"text": "has been", "start": 55, "end": 63, "i_start": 9, "i_end": 10}}], "id": 227}, {"sent": "the main result of gessel and reutenauer can also be stated in terms of symmetric functions .", "tokens": ["the", "main", "result", "of", "gessel", "and", "reutenauer", "can", "also", "be", "stated", "in", "terms", "of", "symmetric", "functions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the main result of gessel and reutenauer", "start": 0, "end": 40, "i_start": 0, "i_end": 6}, "verb": {"text": "be stated", "start": 50, "end": 59, "i_start": 9, "i_end": 10}}, {"subject": {"text": "the main result of gessel and reutenauer", "start": 0, "end": 40, "i_start": 0, "i_end": 6}, "verb": {"text": "can", "start": 41, "end": 44, "i_start": 7, "i_end": 7}}], "id": 228}, {"sent": "we optimize the model with adam optimizer and the learning rate is 3e-3 .", "tokens": ["we", "optimize", "the", "model", "with", "adam", "optimizer", "and", "the", "learning", "rate", "is", "3e-3", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "optimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 229}, {"sent": "at tree-level , a potent example of this is provided by a strikingly compact formula for the entire classical s-matrix of gravitons in any dimension .", "tokens": ["at", "tree", "-", "level", ",", "a", "potent", "example", "of", "this", "is", "provided", "by", "a", "strikingly", "compact", "formula", "for", "the", "entire", "classical", "s", "-", "matrix", "of", "gravitons", "in", "any", "dimension", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "a potent example of this", "start": 16, "end": 40, "i_start": 5, "i_end": 9}, "verb": {"text": "is provided", "start": 41, "end": 52, "i_start": 10, "i_end": 11}}, {"character": {"text": "formula", "start": 77, "end": 84, "i_start": 16, "i_end": 16}, "action": {"text": "provided", "start": 44, "end": 52, "i_start": 11, "i_end": 11}}], "id": 230}, {"sent": "the modulation of the fermi velocity can be obtained in graphene by placing metallic planes close to the graphene sheet , which will turn electron-electron interactions weaker and , consequently , modify the fermi velocity .", "tokens": ["the", "modulation", "of", "the", "fermi", "velocity", "can", "be", "obtained", "in", "graphene", "by", "placing", "metallic", "planes", "close", "to", "the", "graphene", "sheet", ",", "which", "will", "turn", "electron", "-", "electron", "interactions", "weaker", "and", ",", "consequently", ",", "modify", "the", "fermi", "velocity", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the modulation of the fermi velocity", "start": 0, "end": 36, "i_start": 0, "i_end": 5}, "verb": {"text": "can be obtained", "start": 37, "end": 52, "i_start": 6, "i_end": 8}}, {"subject": {"text": "the modulation of the fermi velocity", "start": 0, "end": 36, "i_start": 0, "i_end": 5}, "verb": {"text": "modify", "start": 197, "end": 203, "i_start": 33, "i_end": 33}}, {"character": {"text": "placing", "start": 68, "end": 75, "i_start": 12, "i_end": 12}, "action": {"text": "turn", "start": 133, "end": 137, "i_start": 23, "i_end": 23}}, {"character": {"text": "electron", "start": 138, "end": 146, "i_start": 24, "i_end": 24}, "action": {"text": "interactions", "start": 156, "end": 168, "i_start": 27, "i_end": 27}}, {"character": {"text": "turn", "start": 133, "end": 137, "i_start": 23, "i_end": 23}, "action": {"text": "modify", "start": 197, "end": 203, "i_start": 33, "i_end": 33}}], "id": 231}, {"sent": "arnold observed a strange duality between the 14 exceptional unimodular singularities .", "tokens": ["arnold", "observed", "a", "strange", "duality", "between", "the", "14", "exceptional", "unimodular", "singularities", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "arnold", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "observed", "start": 7, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "arnold", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "observed", "start": 7, "end": 15, "i_start": 1, "i_end": 1}}], "id": 232}, {"sent": "bayesian networks or graphical models based on directed acyclic graphs are widely used to model complex causal systems arising from a variety of research areas , including computational biology , epidemiology , sociology , and environmental management .", "tokens": ["bayesian", "networks", "or", "graphical", "models", "based", "on", "directed", "acyclic", "graphs", "are", "widely", "used", "to", "model", "complex", "causal", "systems", "arising", "from", "a", "variety", "of", "research", "areas", ",", "including", "computational", "biology", ",", "epidemiology", ",", "sociology", ",", "and", "environmental", "management", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "bayesian networks or graphical models based on directed acyclic graphs", "start": 0, "end": 70, "i_start": 0, "i_end": 9}, "verb": {"text": "used", "start": 82, "end": 86, "i_start": 12, "i_end": 12}}, {"subject": {"text": "bayesian networks or graphical models based on directed acyclic graphs", "start": 0, "end": 70, "i_start": 0, "i_end": 9}, "verb": {"text": "are", "start": 71, "end": 74, "i_start": 10, "i_end": 10}}], "id": 233}, {"sent": "in recent years , deep neural networks have led to many breakthrough results in machine learning and computer vision , and are now widely deployed in industry .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "led", "to", "many", "breakthrough", "results", "in", "machine", "learning", "and", "computer", "vision", ",", "and", "are", "now", "widely", "deployed", "in", "industry", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have led", "start": 39, "end": 47, "i_start": 7, "i_end": 8}}, {"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "deployed", "start": 138, "end": 146, "i_start": 24, "i_end": 24}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "led", "start": 44, "end": 47, "i_start": 8, "i_end": 8}}], "id": 234}, {"sent": "generative adversarial network has recently attracted great attention in the deep learning community .", "tokens": ["generative", "adversarial", "network", "has", "recently", "attracted", "great", "attention", "in", "the", "deep", "learning", "community", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial network", "start": 0, "end": 30, "i_start": 0, "i_end": 2}, "verb": {"text": "attracted", "start": 44, "end": 53, "i_start": 5, "i_end": 5}}, {"subject": {"text": "generative adversarial network", "start": 0, "end": 30, "i_start": 0, "i_end": 2}, "verb": {"text": "has", "start": 31, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "network", "start": 23, "end": 30, "i_start": 2, "i_end": 2}, "action": {"text": "attracted", "start": 44, "end": 53, "i_start": 5, "i_end": 5}}, {"character": {"text": "community", "start": 91, "end": 100, "i_start": 12, "i_end": 12}, "action": {"text": "attention", "start": 60, "end": 69, "i_start": 7, "i_end": 7}}, {"character": {"text": "community", "start": 91, "end": 100, "i_start": 12, "i_end": 12}, "action": {"text": "learning", "start": 82, "end": 90, "i_start": 11, "i_end": 11}}], "id": 235}, {"sent": "there are also other video datasets focusing on visual content recognition , video captioning , and so on , such as fcvid .", "tokens": ["there", "are", "also", "other", "video", "datasets", "focusing", "on", "visual", "content", "recognition", ",", "video", "captioning", ",", "and", "so", "on", ",", "such", "as", "fcvid", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 6, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "datasets", "start": 27, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "focusing", "start": 36, "end": 44, "i_start": 6, "i_end": 6}}], "id": 236}, {"sent": "the only modification needed is the insertion of rotation matrices from flavor eigenstates to gauge interaction eigenstates .", "tokens": ["the", "only", "modification", "needed", "is", "the", "insertion", "of", "rotation", "matrices", "from", "flavor", "eigenstates", "to", "gauge", "interaction", "eigenstates", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the only modification needed", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "matrices", "start": 58, "end": 66, "i_start": 9, "i_end": 9}, "action": {"text": "gauge", "start": 94, "end": 99, "i_start": 14, "i_end": 14}}], "id": 237}, {"sent": "we introduce \u03b4 v,0 and \u03b6 d factors , so that this operator can represent the partition function of all blocks and types .", "tokens": ["we", "introduce", "\u03b4", "v,0", "and", "\u03b6", "d", "factors", ",", "so", "that", "this", "operator", "can", "represent", "the", "partition", "function", "of", "all", "blocks", "and", "types", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "introduce", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "introduce", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 45, "end": 49, "i_start": 11, "i_end": 11}, "action": {"text": "represent", "start": 63, "end": 72, "i_start": 14, "i_end": 14}}, {"character": {"text": "blocks", "start": 103, "end": 109, "i_start": 20, "i_end": 20}, "action": {"text": "function", "start": 87, "end": 95, "i_start": 17, "i_end": 17}}, {"character": {"text": "all", "start": 99, "end": 102, "i_start": 19, "i_end": 19}, "action": {"text": "function", "start": 87, "end": 95, "i_start": 17, "i_end": 17}}, {"character": {"text": "types", "start": 114, "end": 119, "i_start": 22, "i_end": 22}, "action": {"text": "function", "start": 87, "end": 95, "i_start": 17, "i_end": 17}}], "id": 238}, {"sent": "for training image classifiers , we use the liblinear toolbox with 5-fold cross validation .", "tokens": ["for", "training", "image", "classifiers", ",", "we", "use", "the", "liblinear", "toolbox", "with", "5", "-", "fold", "cross", "validation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 33, "end": 35, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 36, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 33, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 36, "end": 39, "i_start": 6, "i_end": 6}}], "id": 239}, {"sent": "i n recent years , deep convolutional neural networks have demonstrated an outstanding capability in various computer vision tasks , such as image classification .", "tokens": ["i", "n", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "demonstrated", "an", "outstanding", "capability", "in", "various", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 19, "end": 53, "i_start": 5, "i_end": 8}, "verb": {"text": "have demonstrated", "start": 54, "end": 71, "i_start": 9, "i_end": 10}}, {"character": {"text": "networks", "start": 45, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "demonstrated", "start": 59, "end": 71, "i_start": 10, "i_end": 10}}], "id": 240}, {"sent": "deep neural networks have shown great success in computer vision and natural language processing tasks .", "tokens": ["deep", "neural", "networks", "have", "shown", "great", "success", "in", "computer", "vision", "and", "natural", "language", "processing", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 38, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "processing", "start": 86, "end": 96, "i_start": 13, "i_end": 13}}], "id": 241}, {"sent": "the schwarzschild solution is a particular case of the metric that we use , when we have a .", "tokens": ["the", "schwarzschild", "solution", "is", "a", "particular", "case", "of", "the", "metric", "that", "we", "use", ",", "when", "we", "have", "a", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the schwarzschild solution", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "solution", "start": 18, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "case", "start": 43, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 67, "end": 69, "i_start": 11, "i_end": 11}, "action": {"text": "use", "start": 70, "end": 73, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 67, "end": 69, "i_start": 11, "i_end": 11}, "action": {"text": "have", "start": 84, "end": 88, "i_start": 16, "i_end": 16}}], "id": 242}, {"sent": "the p-spectral radius has been introduced by keevash , lenz and mubayi .", "tokens": ["the", "p", "-", "spectral", "radius", "has", "been", "introduced", "by", "keevash", ",", "lenz", "and", "mubayi", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the p-spectral radius", "start": 0, "end": 21, "i_start": 0, "i_end": 4}, "verb": {"text": "has been introduced", "start": 22, "end": 41, "i_start": 5, "i_end": 7}}, {"character": {"text": "keevash", "start": 45, "end": 52, "i_start": 9, "i_end": 9}, "action": {"text": "introduced", "start": 31, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "lenz", "start": 55, "end": 59, "i_start": 11, "i_end": 11}, "action": {"text": "introduced", "start": 31, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "mubayi", "start": 64, "end": 70, "i_start": 13, "i_end": 13}, "action": {"text": "introduced", "start": 31, "end": 41, "i_start": 7, "i_end": 7}}], "id": 243}, {"sent": "however colocating different jobs on the same server could lead to lower gpu utilization due to interference in shared system resources such as pcie bus .", "tokens": ["however", "colocating", "different", "jobs", "on", "the", "same", "server", "could", "lead", "to", "lower", "gpu", "utilization", "due", "to", "interference", "in", "shared", "system", "resources", "such", "as", "pcie", "bus", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "however colocating different jobs on the same server", "start": 0, "end": 52, "i_start": 0, "i_end": 7}, "verb": {"text": "could lead", "start": 53, "end": 63, "i_start": 8, "i_end": 9}}], "id": 244}, {"sent": "it was shown in that this is an equality when the associated graded ring of i is cohen-macaulay .", "tokens": ["it", "was", "shown", "in", "that", "this", "is", "an", "equality", "when", "the", "associated", "graded", "ring", "of", "i", "is", "cohen", "-", "macaulay", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "was shown", "start": 3, "end": 12, "i_start": 1, "i_end": 2}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 6, "i_end": 6}}], "id": 245}, {"sent": "the dipolar condensate is the first example of a weakly interacting gas offering a possibility of obtaining a rotonmaxon dispersion , up to now only observed in the relatively more complicated physics of liquid he .", "tokens": ["the", "dipolar", "condensate", "is", "the", "first", "example", "of", "a", "weakly", "interacting", "gas", "offering", "a", "possibility", "of", "obtaining", "a", "rotonmaxon", "dispersion", ",", "up", "to", "now", "only", "observed", "in", "the", "relatively", "more", "complicated", "physics", "of", "liquid", "he", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dipolar condensate", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "gas", "start": 68, "end": 71, "i_start": 11, "i_end": 11}, "action": {"text": "interacting", "start": 56, "end": 67, "i_start": 10, "i_end": 10}}, {"character": {"text": "gas", "start": 68, "end": 71, "i_start": 11, "i_end": 11}, "action": {"text": "offering", "start": 72, "end": 80, "i_start": 12, "i_end": 12}}, {"character": {"text": "gas", "start": 68, "end": 71, "i_start": 11, "i_end": 11}, "action": {"text": "observed", "start": 149, "end": 157, "i_start": 25, "i_end": 25}}], "id": 246}, {"sent": "the final result for the inflow waveform has been taken from figure 3 of work .", "tokens": ["the", "final", "result", "for", "the", "inflow", "waveform", "has", "been", "taken", "from", "figure", "3", "of", "work", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 247}, {"sent": "we used the negative log likelihood loss for each classifier with the adam optimizer for training the network .", "tokens": ["we", "used", "the", "negative", "log", "likelihood", "loss", "for", "each", "classifier", "with", "the", "adam", "optimizer", "for", "training", "the", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "training", "start": 89, "end": 97, "i_start": 15, "i_end": 15}}], "id": 248}, {"sent": "indeed , it is known that neural networks with as few as one hidden layer and arbitrary nonconstant bounded activation functions can be used to approximate any continuous function on a compact subset of r n0 .", "tokens": ["indeed", ",", "it", "is", "known", "that", "neural", "networks", "with", "as", "few", "as", "one", "hidden", "layer", "and", "arbitrary", "nonconstant", "bounded", "activation", "functions", "can", "be", "used", "to", "approximate", "any", "continuous", "function", "on", "a", "compact", "subset", "of", "r", "n0", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "verb": {"text": "is known", "start": 12, "end": 20, "i_start": 3, "i_end": 4}}, {"subject": {"text": "neural networks with as few as one hidden layer and arbitrary nonconstant bounded activation functions", "start": 26, "end": 128, "i_start": 6, "i_end": 20}, "verb": {"text": "used", "start": 136, "end": 140, "i_start": 23, "i_end": 23}}, {"character": {"text": "networks", "start": 33, "end": 41, "i_start": 7, "i_end": 7}, "action": {"text": "approximate", "start": 144, "end": 155, "i_start": 25, "i_end": 25}}], "id": 249}, {"sent": "in this subsection , we recall the definitions of vertex operator algebras and modules from .", "tokens": ["in", "this", "subsection", ",", "we", "recall", "the", "definitions", "of", "vertex", "operator", "algebras", "and", "modules", "from", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "recall", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "recall", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "algebras", "start": 66, "end": 74, "i_start": 11, "i_end": 11}, "action": {"text": "operator", "start": 57, "end": 65, "i_start": 10, "i_end": 10}}, {"character": {"text": "modules", "start": 79, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "operator", "start": 57, "end": 65, "i_start": 10, "i_end": 10}}], "id": 250}, {"sent": "the notion of curling number of integer sequences is introduced in as follows .", "tokens": ["the", "notion", "of", "curling", "number", "of", "integer", "sequences", "is", "introduced", "in", "as", "follows", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the notion of curling number of integer sequences", "start": 0, "end": 49, "i_start": 0, "i_end": 7}, "verb": {"text": "is introduced in", "start": 50, "end": 66, "i_start": 8, "i_end": 10}}], "id": 251}, {"sent": "recently , deep convolutional neural networks have attracted a lot of attention in visual recognition , largely due to their excellent performance .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "attracted", "a", "lot", "of", "attention", "in", "visual", "recognition", ",", "largely", "due", "to", "their", "excellent", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have attracted", "start": 46, "end": 60, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "attracted", "start": 51, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 135, "end": 146, "i_start": 21, "i_end": 21}}], "id": 252}, {"sent": "more recent studies have fewer such limitations , and introduce useful methods customised to the task .", "tokens": ["more", "recent", "studies", "have", "fewer", "such", "limitations", ",", "and", "introduce", "useful", "methods", "customised", "to", "the", "task", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "more recent studies", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 20, "end": 24, "i_start": 3, "i_end": 3}}, {"subject": {"text": "more recent studies", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "introduce", "start": 54, "end": 63, "i_start": 9, "i_end": 9}}, {"character": {"text": "studies", "start": 12, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "limitations", "start": 36, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "studies", "start": 12, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "introduce", "start": 54, "end": 63, "i_start": 9, "i_end": 9}}], "id": 253}, {"sent": "deep neural networks have demonstrated impressive performance on many machine-learning tasks such as image recognition .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "impressive", "performance", "on", "many", "machine", "-", "learning", "tasks", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 50, "end": 61, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 50, "end": 61, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 39, "end": 49, "i_start": 5, "i_end": 5}}], "id": 254}, {"sent": "because the intersection points are primary , a resonance zone is bounded by a jordan curve and has an exit and an entry set .", "tokens": ["because", "the", "intersection", "points", "are", "primary", ",", "a", "resonance", "zone", "is", "bounded", "by", "a", "jordan", "curve", "and", "has", "an", "exit", "and", "an", "entry", "set", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a resonance zone", "start": 46, "end": 62, "i_start": 7, "i_end": 9}, "verb": {"text": "is bounded", "start": 63, "end": 73, "i_start": 10, "i_end": 11}}, {"subject": {"text": "a resonance zone", "start": 46, "end": 62, "i_start": 7, "i_end": 9}, "verb": {"text": "has", "start": 96, "end": 99, "i_start": 17, "i_end": 17}}, {"character": {"text": "primary", "start": 36, "end": 43, "i_start": 5, "i_end": 5}, "action": {"text": "because", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}, {"character": {"text": "zone", "start": 58, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "has", "start": 96, "end": 99, "i_start": 17, "i_end": 17}}], "id": 255}, {"sent": "action recognition has long been a central topic in computer vision .", "tokens": ["action", "recognition", "has", "long", "been", "a", "central", "topic", "in", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "action recognition", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "been", "start": 28, "end": 32, "i_start": 4, "i_end": 4}}, {"subject": {"text": "action recognition", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "has", "start": 19, "end": 22, "i_start": 2, "i_end": 2}}], "id": 256}, {"sent": "in recent years , rydberg atoms have emerged as leading candidates for neutral atom based quantum information processing .", "tokens": ["in", "recent", "years", ",", "rydberg", "atoms", "have", "emerged", "as", "leading", "candidates", "for", "neutral", "atom", "based", "quantum", "information", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "rydberg atoms", "start": 18, "end": 31, "i_start": 4, "i_end": 5}, "verb": {"text": "have emerged", "start": 32, "end": 44, "i_start": 6, "i_end": 7}}, {"character": {"text": "atoms", "start": 26, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "emerged", "start": 37, "end": 44, "i_start": 7, "i_end": 7}}, {"character": {"text": "candidates", "start": 56, "end": 66, "i_start": 10, "i_end": 10}, "action": {"text": "leading", "start": 48, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "atom", "start": 79, "end": 83, "i_start": 13, "i_end": 13}, "action": {"text": "neutral", "start": 71, "end": 78, "i_start": 12, "i_end": 12}}], "id": 257}, {"sent": "convolutional neural networks have greatly advanced the state of the art in all those structured output tasks .", "tokens": ["convolutional", "neural", "networks", "have", "greatly", "advanced", "the", "state", "of", "the", "art", "in", "all", "those", "structured", "output", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "advanced", "start": 43, "end": 51, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "advanced", "start": 43, "end": 51, "i_start": 5, "i_end": 5}}], "id": 258}, {"sent": "huang and wang obtained the uniqueness result of weak solution when the initial data is a radon measure .", "tokens": ["huang", "and", "wang", "obtained", "the", "uniqueness", "result", "of", "weak", "solution", "when", "the", "initial", "data", "is", "a", "radon", "measure", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "huang and wang", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "obtained", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "huang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "obtained", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "wang", "start": 10, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "obtained", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 259}, {"sent": "thus , up to isomorphism , there is a good description of the primitives of nsymm over the rationals .", "tokens": ["thus", ",", "up", "to", "isomorphism", ",", "there", "is", "a", "good", "description", "of", "the", "primitives", "of", "nsymm", "over", "the", "rationals", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 27, "end": 32, "i_start": 6, "i_end": 6}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 7, "i_end": 7}}], "id": 260}, {"sent": "the orthogonal polynomials of this matrix ensemble are the stieltjes-wigert polynomials .", "tokens": ["the", "orthogonal", "polynomials", "of", "this", "matrix", "ensemble", "are", "the", "stieltjes", "-", "wigert", "polynomials", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the orthogonal polynomials of this matrix ensemble", "start": 0, "end": 50, "i_start": 0, "i_end": 6}, "verb": {"text": "are", "start": 51, "end": 54, "i_start": 7, "i_end": 7}}], "id": 261}, {"sent": "deep neural networks have garnered interest from many researchers after being successfully applied in image classification .", "tokens": ["deep", "neural", "networks", "have", "garnered", "interest", "from", "many", "researchers", "after", "being", "successfully", "applied", "in", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have garnered", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "garnered", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successfully", "start": 78, "end": 90, "i_start": 11, "i_end": 11}}], "id": 262}, {"sent": "we use the default parameter provided by scikit-learn learning library in python .", "tokens": ["we", "use", "the", "default", "parameter", "provided", "by", "scikit", "-", "learn", "learning", "library", "in", "python", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "library", "start": 63, "end": 70, "i_start": 11, "i_end": 11}, "action": {"text": "provided", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}], "id": 263}, {"sent": "this counterterm is the fradkin-tseytlin term coupling the dilaton \u03c6 to the string worldsheet .", "tokens": ["this", "counterterm", "is", "the", "fradkin", "-", "tseytlin", "term", "coupling", "the", "dilaton", "\u03c6", "to", "the", "string", "worldsheet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this counterterm", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "term", "start": 41, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "coupling", "start": 46, "end": 54, "i_start": 8, "i_end": 8}}], "id": 264}, {"sent": "in 1984 , bennett and brassard proposed a quantum key distribution protocol which is now called as bb84 protocol .", "tokens": ["in", "1984", ",", "bennett", "and", "brassard", "proposed", "a", "quantum", "key", "distribution", "protocol", "which", "is", "now", "called", "as", "bb84", "protocol", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bennett and brassard", "start": 10, "end": 30, "i_start": 3, "i_end": 5}, "verb": {"text": "proposed", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "bennett", "start": 10, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "proposed", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "brassard", "start": 22, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "proposed", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}], "id": 265}, {"sent": "density functional theory calculations were performed using the vienna ab initio simulation package 36 , 37 .", "tokens": ["density", "functional", "theory", "calculations", "were", "performed", "using", "the", "vienna", "ab", "initio", "simulation", "package", "36", ",", "37", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "density functional theory calculations", "start": 0, "end": 38, "i_start": 0, "i_end": 3}, "verb": {"text": "were performed", "start": 39, "end": 53, "i_start": 4, "i_end": 5}}], "id": 266}, {"sent": "influence of generic scale invariance on classical critical behavior we now combine the concept of gsi with critical phenomena .", "tokens": ["influence", "of", "generic", "scale", "invariance", "on", "classical", "critical", "behavior", "we", "now", "combine", "the", "concept", "of", "gsi", "with", "critical", "phenomena", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 69, "end": 71, "i_start": 9, "i_end": 9}, "verb": {"text": "combine", "start": 76, "end": 83, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 69, "end": 71, "i_start": 9, "i_end": 9}, "action": {"text": "combine", "start": 76, "end": 83, "i_start": 11, "i_end": 11}}, {"character": {"text": "phenomena", "start": 117, "end": 126, "i_start": 18, "i_end": 18}, "action": {"text": "critical", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "invariance", "start": 27, "end": 37, "i_start": 4, "i_end": 4}, "action": {"text": "influence", "start": 0, "end": 9, "i_start": 0, "i_end": 0}}], "id": 267}, {"sent": "this makes the wigner transform a useful tool in the study of semiclassical and high frequency limits , especially in random media .", "tokens": ["this", "makes", "the", "wigner", "transform", "a", "useful", "tool", "in", "the", "study", "of", "semiclassical", "and", "high", "frequency", "limits", ",", "especially", "in", "random", "media", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "makes", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the wigner", "start": 11, "end": 21, "i_start": 2, "i_end": 3}, "verb": {"text": "transform", "start": 22, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "makes", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "wigner", "start": 15, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "transform", "start": 22, "end": 31, "i_start": 4, "i_end": 4}}], "id": 268}, {"sent": "in , it has been shown that a relaxation method is best suited to the numerical resolution of the unconstrained soh model .", "tokens": ["in", ",", "it", "has", "been", "shown", "that", "a", "relaxation", "method", "is", "best", "suited", "to", "the", "numerical", "resolution", "of", "the", "unconstrained", "soh", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "verb": {"text": "has been shown", "start": 8, "end": 22, "i_start": 3, "i_end": 5}}, {"subject": {"text": "it", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "verb": {"text": "suited", "start": 56, "end": 62, "i_start": 12, "i_end": 12}}], "id": 269}, {"sent": "the kth stream after receive beamforming at the rs can be expressed as .", "tokens": ["the", "kth", "stream", "after", "receive", "beamforming", "at", "the", "rs", "can", "be", "expressed", "as", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 270}, {"sent": "the generalized gradient approximation of perdew , burke and ernzerhof was employed for the exchange-correlation potential .", "tokens": ["the", "generalized", "gradient", "approximation", "of", "perdew", ",", "burke", "and", "ernzerhof", "was", "employed", "for", "the", "exchange", "-", "correlation", "potential", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation of perdew", "start": 0, "end": 48, "i_start": 0, "i_end": 5}, "verb": {"text": "was employed", "start": 71, "end": 83, "i_start": 10, "i_end": 11}}], "id": 271}, {"sent": "we extract image features using the pre-trained vgg16 model on the imagenet dataset .", "tokens": ["we", "extract", "image", "features", "using", "the", "pre", "-", "trained", "vgg16", "model", "on", "the", "imagenet", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "extract", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extract", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 26, "end": 31, "i_start": 4, "i_end": 4}}], "id": 272}, {"sent": "in the pure c-phase the band disperses only in the z-direction and the dos is one-dimensional .", "tokens": ["in", "the", "pure", "c", "-", "phase", "the", "band", "disperses", "only", "in", "the", "z", "-", "direction", "and", "the", "dos", "is", "one", "-", "dimensional", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the dos", "start": 67, "end": 74, "i_start": 16, "i_end": 17}, "verb": {"text": "is", "start": 75, "end": 77, "i_start": 18, "i_end": 18}}], "id": 273}, {"sent": "differential privacy is a well-established notion for privacy-preserving statistical analyses .", "tokens": ["differential", "privacy", "is", "a", "well", "-", "established", "notion", "for", "privacy", "-", "preserving", "statistical", "analyses", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "differential privacy", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 2, "i_end": 2}}], "id": 274}, {"sent": "a qubit is a two-level quantum system , and possibilites include the spin states of an electron or the polarization states of a photon .", "tokens": ["a", "qubit", "is", "a", "two", "-", "level", "quantum", "system", ",", "and", "possibilites", "include", "the", "spin", "states", "of", "an", "electron", "or", "the", "polarization", "states", "of", "a", "photon", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a qubit", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 2, "i_end": 2}}, {"subject": {"text": "possibilites", "start": 44, "end": 56, "i_start": 11, "i_end": 11}, "verb": {"text": "include", "start": 57, "end": 64, "i_start": 12, "i_end": 12}}], "id": 275}, {"sent": "deep symmetry networks generalize vanilla cnn architecture to model arbitrary symmetry groups .", "tokens": ["deep", "symmetry", "networks", "generalize", "vanilla", "cnn", "architecture", "to", "model", "arbitrary", "symmetry", "groups", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep symmetry networks", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "generalize", "start": 23, "end": 33, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 14, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "generalize", "start": 23, "end": 33, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 14, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "model", "start": 62, "end": 67, "i_start": 8, "i_end": 8}}], "id": 276}, {"sent": "the encoder and language model is one-layer gru .", "tokens": ["the", "encoder", "and", "language", "model", "is", "one", "-", "layer", "gru", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the encoder and language model", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 5, "i_end": 5}}], "id": 277}, {"sent": "we notice that axiom is the reason since catalan pairs can be represented using perfect noncrossing matchings .", "tokens": ["we", "notice", "that", "axiom", "is", "the", "reason", "since", "catalan", "pairs", "can", "be", "represented", "using", "perfect", "noncrossing", "matchings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "notice", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "notice", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 278}, {"sent": "deep learning has proven successful in many domains , such as computer vision .", "tokens": ["deep", "learning", "has", "proven", "successful", "in", "many", "domains", ",", "such", "as", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has proven", "start": 14, "end": 24, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "successful", "start": 25, "end": 35, "i_start": 4, "i_end": 4}}], "id": 279}, {"sent": "see , for example , yuan , joseph and zou , choi , li and zhu , bien , taylor and tibshirani , lim and hastie , and haris , witten and simon .", "tokens": ["see", ",", "for", "example", ",", "yuan", ",", "joseph", "and", "zou", ",", "choi", ",", "li", "and", "zhu", ",", "bien", ",", "taylor", "and", "tibshirani", ",", "lim", "and", "hastie", ",", "and", "haris", ",", "witten", "and", "simon", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 280}, {"sent": "we utilized the adadelta algorithm with gradient clipping for optimization .", "tokens": ["we", "utilized", "the", "adadelta", "algorithm", "with", "gradient", "clipping", "for", "optimization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "utilized", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "utilized", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 281}, {"sent": "in the categorification theory of cluster algebras , module categories over preprojective algebras play a central role .", "tokens": ["in", "the", "categorification", "theory", "of", "cluster", "algebras", ",", "module", "categories", "over", "preprojective", "algebras", "play", "a", "central", "role", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "module categories over preprojective algebras", "start": 53, "end": 98, "i_start": 8, "i_end": 12}, "verb": {"text": "play", "start": 99, "end": 103, "i_start": 13, "i_end": 13}}, {"character": {"text": "categories", "start": 60, "end": 70, "i_start": 9, "i_end": 9}, "action": {"text": "play", "start": 99, "end": 103, "i_start": 13, "i_end": 13}}], "id": 282}, {"sent": "the coulomb energy is a smooth function of the void displacement but not the shell energy .", "tokens": ["the", "coulomb", "energy", "is", "a", "smooth", "function", "of", "the", "void", "displacement", "but", "not", "the", "shell", "energy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the coulomb energy", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "displacement", "start": 52, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "function", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "displacement", "start": 52, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "not", "start": 69, "end": 72, "i_start": 12, "i_end": 12}}], "id": 283}, {"sent": "goodfellow et al proposed adversarial training as a regularization method which uses a mixture of clean and adversarial examples to enhance the robustness of the model .", "tokens": ["goodfellow", "et", "al", "proposed", "adversarial", "training", "as", "a", "regularization", "method", "which", "uses", "a", "mixture", "of", "clean", "and", "adversarial", "examples", "to", "enhance", "the", "robustness", "of", "the", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "goodfellow", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "method", "start": 67, "end": 73, "i_start": 9, "i_end": 9}, "action": {"text": "uses", "start": 80, "end": 84, "i_start": 11, "i_end": 11}}], "id": 284}, {"sent": "powerful deep neural networks have been created and investigated for high-level computer vision tasks such as image classification .", "tokens": ["powerful", "deep", "neural", "networks", "have", "been", "created", "and", "investigated", "for", "high", "-", "level", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "powerful deep neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "have been created", "start": 30, "end": 47, "i_start": 4, "i_end": 6}}, {"subject": {"text": "powerful deep neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "investigated", "start": 52, "end": 64, "i_start": 8, "i_end": 8}}], "id": 285}, {"sent": "large-scale multiple-input multiple-output systems are considered as one of the most promising technology for next generation wireless communication systems because of their considerable spatial multiplexing gains .", "tokens": ["large", "-", "scale", "multiple", "-", "input", "multiple", "-", "output", "systems", "are", "considered", "as", "one", "of", "the", "most", "promising", "technology", "for", "next", "generation", "wireless", "communication", "systems", "because", "of", "their", "considerable", "spatial", "multiplexing", "gains", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "large-scale multiple-input multiple-output systems", "start": 0, "end": 50, "i_start": 0, "i_end": 9}, "verb": {"text": "are considered", "start": 51, "end": 65, "i_start": 10, "i_end": 11}}, {"character": {"text": "technology", "start": 95, "end": 105, "i_start": 18, "i_end": 18}, "action": {"text": "promising", "start": 85, "end": 94, "i_start": 17, "i_end": 17}}], "id": 286}, {"sent": "convolutional neural networks have been the driving factor behind the recent advances in object detection .", "tokens": ["convolutional", "neural", "networks", "have", "been", "the", "driving", "factor", "behind", "the", "recent", "advances", "in", "object", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "factor", "start": 52, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "driving", "start": 44, "end": 51, "i_start": 6, "i_end": 6}}], "id": 287}, {"sent": "non-commutative field theories have recently received a great deal of attention .", "tokens": ["non", "-", "commutative", "field", "theories", "have", "recently", "received", "a", "great", "deal", "of", "attention", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "non-commutative field theories", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "received", "start": 45, "end": 53, "i_start": 7, "i_end": 7}}, {"subject": {"text": "non-commutative field theories", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "have", "start": 31, "end": 35, "i_start": 5, "i_end": 5}}], "id": 288}, {"sent": "the points marked on the tracks indicate the time taken in myr to reach that point from the onset of star formation .", "tokens": ["the", "points", "marked", "on", "the", "tracks", "indicate", "the", "time", "taken", "in", "myr", "to", "reach", "that", "point", "from", "the", "onset", "of", "star", "formation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the points marked on the tracks", "start": 0, "end": 31, "i_start": 0, "i_end": 5}, "verb": {"text": "indicate", "start": 32, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "points", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "indicate", "start": 32, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "reach", "start": 66, "end": 71, "i_start": 13, "i_end": 13}, "action": {"text": "taken", "start": 50, "end": 55, "i_start": 9, "i_end": 9}}], "id": 289}, {"sent": "from this dispersion relation , we calculate the eigenfrequencies and damping rates for monopole and quadrupole mode .", "tokens": ["from", "this", "dispersion", "relation", ",", "we", "calculate", "the", "eigenfrequencies", "and", "damping", "rates", "for", "monopole", "and", "quadrupole", "mode", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 32, "end": 34, "i_start": 5, "i_end": 5}, "verb": {"text": "calculate", "start": 35, "end": 44, "i_start": 6, "i_end": 6}}, {"subject": {"text": "we", "start": 32, "end": 34, "i_start": 5, "i_end": 5}, "verb": {"text": "damping", "start": 70, "end": 77, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 32, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "calculate", "start": 35, "end": 44, "i_start": 6, "i_end": 6}}], "id": 290}, {"sent": "the spectral resolution is the keck and het spectra .", "tokens": ["the", "spectral", "resolution", "is", "the", "keck", "and", "het", "spectra", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the spectral resolution", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}], "id": 291}, {"sent": "the dice factor for the proposed algorithm and the algorithms in for the second subject .", "tokens": ["the", "dice", "factor", "for", "the", "proposed", "algorithm", "and", "the", "algorithms", "in", "for", "the", "second", "subject", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 292}, {"sent": "the ordinate is the absolute value of the z-coordinate of .", "tokens": ["the", "ordinate", "is", "the", "absolute", "value", "of", "the", "z", "-", "coordinate", "of", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ordinate", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 293}, {"sent": "in fact several of the smarandache loops have classes of loops which satisfy the smarandache notions .", "tokens": ["in", "fact", "several", "of", "the", "smarandache", "loops", "have", "classes", "of", "loops", "which", "satisfy", "the", "smarandache", "notions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "several of the smarandache loops", "start": 8, "end": 40, "i_start": 2, "i_end": 6}, "verb": {"text": "have", "start": 41, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "loops", "start": 35, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "have", "start": 41, "end": 45, "i_start": 7, "i_end": 7}}], "id": 294}, {"sent": "recently , bello et al show that reinforcement learning is capable of solving combinatorial optimization problem like tsp via pointer network .", "tokens": ["recently", ",", "bello", "et", "al", "show", "that", "reinforcement", "learning", "is", "capable", "of", "solving", "combinatorial", "optimization", "problem", "like", "tsp", "via", "pointer", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bello et al", "start": 11, "end": 22, "i_start": 2, "i_end": 4}, "verb": {"text": "show", "start": 23, "end": 27, "i_start": 5, "i_end": 5}}, {"subject": {"text": "bello et al", "start": 11, "end": 22, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 56, "end": 58, "i_start": 9, "i_end": 9}}, {"character": {"text": "bello", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 23, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "learning", "start": 47, "end": 55, "i_start": 8, "i_end": 8}, "action": {"text": "solving", "start": 70, "end": 77, "i_start": 12, "i_end": 12}}], "id": 295}, {"sent": "deep convolutional neural networks have significantly improved the performance of computer vision systems .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "significantly", "improved", "the", "performance", "of", "computer", "vision", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "improved", "start": 54, "end": 62, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "improved", "start": 54, "end": 62, "i_start": 6, "i_end": 6}}, {"character": {"text": "systems", "start": 98, "end": 105, "i_start": 12, "i_end": 12}, "action": {"text": "performance", "start": 67, "end": 78, "i_start": 8, "i_end": 8}}], "id": 296}, {"sent": "convolutional neural networks become the most powerful tool for high-level computer vision tasks , such as object detection .", "tokens": ["convolutional", "neural", "networks", "become", "the", "most", "powerful", "tool", "for", "high", "-", "level", "computer", "vision", "tasks", ",", "such", "as", "object", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "become", "start": 30, "end": 36, "i_start": 3, "i_end": 3}}], "id": 297}, {"sent": "each apparatus consists of an interferometer with two outputs .", "tokens": ["each", "apparatus", "consists", "of", "an", "interferometer", "with", "two", "outputs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each apparatus", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 15, "end": 23, "i_start": 2, "i_end": 2}}], "id": 298}, {"sent": "compressed sensing is a recently developed paradigm for the effective acquisition of sparse signals via few nonadaptive , linear measurements .", "tokens": ["compressed", "sensing", "is", "a", "recently", "developed", "paradigm", "for", "the", "effective", "acquisition", "of", "sparse", "signals", "via", "few", "nonadaptive", ",", "linear", "measurements", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "compressed sensing", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}], "id": 299}, {"sent": "convolutional neural networks have recently been applied to various computer vision tasks such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "been", "applied", "to", "various", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "been applied", "start": 44, "end": 56, "i_start": 5, "i_end": 6}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}], "id": 300}, {"sent": "the success of the deep neural network architectures in image recognition .", "tokens": ["the", "success", "of", "the", "deep", "neural", "network", "architectures", "in", "image", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "network", "start": 31, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 4, "end": 11, "i_start": 1, "i_end": 1}}], "id": 301}, {"sent": "stochastic geometry is a powerful mathematical and statistical tool conceived for the modeling , analysis , and design of wireless networks relying on random topologies .", "tokens": ["stochastic", "geometry", "is", "a", "powerful", "mathematical", "and", "statistical", "tool", "conceived", "for", "the", "modeling", ",", "analysis", ",", "and", "design", "of", "wireless", "networks", "relying", "on", "random", "topologies", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "stochastic geometry", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "and", "start": 47, "end": 50, "i_start": 6, "i_end": 6}, "action": {"text": "relying", "start": 140, "end": 147, "i_start": 21, "i_end": 21}}], "id": 302}, {"sent": "bicnet uses bidirectional rnns to exchange information between agents in an actor-critic setting .", "tokens": ["bicnet", "uses", "bidirectional", "rnns", "to", "exchange", "information", "between", "agents", "in", "an", "actor", "-", "critic", "setting", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "bicnet", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "uses", "start": 7, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "agents", "start": 63, "end": 69, "i_start": 8, "i_end": 8}, "action": {"text": "exchange", "start": 34, "end": 42, "i_start": 5, "i_end": 5}}], "id": 303}, {"sent": "each convolutional layer is followed by batch normalization and relu .", "tokens": ["each", "convolutional", "layer", "is", "followed", "by", "batch", "normalization", "and", "relu", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each convolutional layer", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is followed", "start": 25, "end": 36, "i_start": 3, "i_end": 4}}], "id": 304}, {"sent": "the continuous-variable quantum key distribution protocols provide a plausible solution to practically realize an unconditional secure communication over standard , currently established telecommunication networks .", "tokens": ["the", "continuous", "-", "variable", "quantum", "key", "distribution", "protocols", "provide", "a", "plausible", "solution", "to", "practically", "realize", "an", "unconditional", "secure", "communication", "over", "standard", ",", "currently", "established", "telecommunication", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the continuous-variable quantum key distribution protocols", "start": 0, "end": 58, "i_start": 0, "i_end": 7}, "verb": {"text": "provide", "start": 59, "end": 66, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the continuous-variable quantum key distribution protocols", "start": 0, "end": 58, "i_start": 0, "i_end": 7}, "verb": {"text": "established", "start": 175, "end": 186, "i_start": 23, "i_end": 23}}, {"character": {"text": "protocols", "start": 49, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "provide", "start": 59, "end": 66, "i_start": 8, "i_end": 8}}], "id": 305}, {"sent": "the first one is the flickr material dataset , a recent benchmark containing 10 material classes .", "tokens": ["the", "first", "one", "is", "the", "flickr", "material", "dataset", ",", "a", "recent", "benchmark", "containing", "10", "material", "classes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the first one", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "benchmark", "start": 56, "end": 65, "i_start": 11, "i_end": 11}, "action": {"text": "containing", "start": 66, "end": 76, "i_start": 12, "i_end": 12}}], "id": 306}, {"sent": "deep neural networks have been found to be quite effective for solving problems in the domain of computer vision .", "tokens": ["deep", "neural", "networks", "have", "been", "found", "to", "be", "quite", "effective", "for", "solving", "problems", "in", "the", "domain", "of", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been found", "start": 21, "end": 36, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "effective", "start": 49, "end": 58, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "solving", "start": 63, "end": 70, "i_start": 11, "i_end": 11}}], "id": 307}, {"sent": "we claim that \u03b3f satisfies the composition axiom for pseudo functors .", "tokens": ["we", "claim", "that", "\u03b3f", "satisfies", "the", "composition", "axiom", "for", "pseudo", "functors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "claim", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "\u03b3f", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "satisfies", "start": 17, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "claim", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "\u03b3f", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "satisfies", "start": 17, "end": 26, "i_start": 4, "i_end": 4}}], "id": 308}, {"sent": "hyperparameters we train the proposed network using the adam optimization method with the learning rate of 1e-4 and the batch size of 4 .", "tokens": ["hyperparameters", "we", "train", "the", "proposed", "network", "using", "the", "adam", "optimization", "method", "with", "the", "learning", "rate", "of", "1e-4", "and", "the", "batch", "size", "of", "4", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 16, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "train", "start": 19, "end": 24, "i_start": 2, "i_end": 2}}], "id": 309}, {"sent": "effect of the tip-impurity coupling now we consider the effect of the tip-impurity coupling only , where the tip-host coupling is neglected .", "tokens": ["effect", "of", "the", "tip", "-", "impurity", "coupling", "now", "we", "consider", "the", "effect", "of", "the", "tip", "-", "impurity", "coupling", "only", ",", "where", "the", "tip", "-", "host", "coupling", "is", "neglected", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 40, "end": 42, "i_start": 8, "i_end": 8}, "verb": {"text": "consider", "start": 43, "end": 51, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 40, "end": 42, "i_start": 8, "i_end": 8}, "action": {"text": "consider", "start": 43, "end": 51, "i_start": 9, "i_end": 9}}], "id": 310}, {"sent": "in , goodfellow et al proposed the fast gradient sign method for generating adversarial samples .", "tokens": ["in", ",", "goodfellow", "et", "al", "proposed", "the", "fast", "gradient", "sign", "method", "for", "generating", "adversarial", "samples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 5, "end": 21, "i_start": 2, "i_end": 4}, "verb": {"text": "proposed", "start": 22, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "goodfellow", "start": 5, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "proposed", "start": 22, "end": 30, "i_start": 5, "i_end": 5}}], "id": 311}, {"sent": "dthis is the eastern of the two central cds .", "tokens": ["dthis", "is", "the", "eastern", "of", "the", "two", "central", "cds", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dthis", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}], "id": 312}, {"sent": "however , when it comes to imagenet , we use a resnet 50 architecture .", "tokens": ["however", ",", "when", "it", "comes", "to", "imagenet", ",", "we", "use", "a", "resnet", "50", "architecture", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 38, "end": 40, "i_start": 8, "i_end": 8}, "verb": {"text": "use", "start": 41, "end": 44, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 38, "end": 40, "i_start": 8, "i_end": 8}, "action": {"text": "use", "start": 41, "end": 44, "i_start": 9, "i_end": 9}}], "id": 313}, {"sent": "in parallel , deep convolutional neural networks have proven their effectiveness in many computer vision fields such as object classification .", "tokens": ["in", "parallel", ",", "deep", "convolutional", "neural", "networks", "have", "proven", "their", "effectiveness", "in", "many", "computer", "vision", "fields", "such", "as", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 14, "end": 48, "i_start": 3, "i_end": 6}, "verb": {"text": "have proven", "start": 49, "end": 60, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 40, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "proven", "start": 54, "end": 60, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 40, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "effectiveness", "start": 67, "end": 80, "i_start": 10, "i_end": 10}}], "id": 314}, {"sent": "the fitted model is a power law in the 0 3 - 8 0 kev energy range .", "tokens": ["the", "fitted", "model", "is", "a", "power", "law", "in", "the", "0", "3", "-", "8", "0", "kev", "energy", "range", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the fitted model", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 315}, {"sent": "the brout-englert-higgs mechanism is a key element of the standard model of elementary particles and their interactions , explaining the origin of mass through spontaneous breaking of electroweak symmetry .", "tokens": ["the", "brout", "-", "englert", "-", "higgs", "mechanism", "is", "a", "key", "element", "of", "the", "standard", "model", "of", "elementary", "particles", "and", "their", "interactions", ",", "explaining", "the", "origin", "of", "mass", "through", "spontaneous", "breaking", "of", "electroweak", "symmetry", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the brout-englert-higgs mechanism", "start": 0, "end": 33, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 7, "i_end": 7}}, {"character": {"text": "model", "start": 67, "end": 72, "i_start": 14, "i_end": 14}, "action": {"text": "explaining", "start": 122, "end": 132, "i_start": 22, "i_end": 22}}], "id": 316}, {"sent": "we refer the reader to for the basic properties of o-minimal structures used in this paper .", "tokens": ["we", "refer", "the", "reader", "to", "for", "the", "basic", "properties", "of", "o", "-", "minimal", "structures", "used", "in", "this", "paper", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 317}, {"sent": "efficiency is the need for frequent retrieval or replacement of tabled answers .", "tokens": ["efficiency", "is", "the", "need", "for", "frequent", "retrieval", "or", "replacement", "of", "tabled", "answers", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "efficiency", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 1, "i_end": 1}}], "id": 318}, {"sent": "ideally , the best orientation is the one which is the most efficient .", "tokens": ["ideally", ",", "the", "best", "orientation", "is", "the", "one", "which", "is", "the", "most", "efficient", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the best orientation", "start": 10, "end": 30, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 5, "i_end": 5}}], "id": 319}, {"sent": "all network architectures are trained using the tensorflow api , with the adam optimizer .", "tokens": ["all", "network", "architectures", "are", "trained", "using", "the", "tensorflow", "api", ",", "with", "the", "adam", "optimizer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all network architectures", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "are trained", "start": 26, "end": 37, "i_start": 3, "i_end": 4}}], "id": 320}, {"sent": "in recent years , deep neural networks have revolutionized machine-learning tasks such as image classification , speech recognition and language translation .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "revolutionized", "machine", "-", "learning", "tasks", "such", "as", "image", "classification", ",", "speech", "recognition", "and", "language", "translation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have revolutionized", "start": 39, "end": 58, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "revolutionized", "start": 44, "end": 58, "i_start": 8, "i_end": 8}}], "id": 321}, {"sent": "a hierarchal expansion of this type was first derived to describe the statistical physics of classical systems and is commonly referred to as the bbgky hierarchy .", "tokens": ["a", "hierarchal", "expansion", "of", "this", "type", "was", "first", "derived", "to", "describe", "the", "statistical", "physics", "of", "classical", "systems", "and", "is", "commonly", "referred", "to", "as", "the", "bbgky", "hierarchy", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a hierarchal expansion of this type", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "derived", "start": 46, "end": 53, "i_start": 8, "i_end": 8}}, {"subject": {"text": "a hierarchal expansion of this type", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "was", "start": 36, "end": 39, "i_start": 6, "i_end": 6}}, {"subject": {"text": "a hierarchal expansion of this type", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "referred", "start": 127, "end": 135, "i_start": 20, "i_end": 20}}, {"character": {"text": "expansion", "start": 13, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "describe", "start": 57, "end": 65, "i_start": 10, "i_end": 10}}], "id": 322}, {"sent": "then we introduce the definition of innerproduct hyperspace and deduce some important theorems .", "tokens": ["then", "we", "introduce", "the", "definition", "of", "innerproduct", "hyperspace", "and", "deduce", "some", "important", "theorems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "introduce", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "deduce", "start": 64, "end": 70, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "introduce", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "deduce", "start": 64, "end": 70, "i_start": 9, "i_end": 9}}], "id": 323}, {"sent": "in this paper , we use the louvain method on g to find layer communities of a multiplex network g .", "tokens": ["in", "this", "paper", ",", "we", "use", "the", "louvain", "method", "on", "g", "to", "find", "layer", "communities", "of", "a", "multiplex", "network", "g", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 19, "end": 22, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 19, "end": 22, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "find", "start": 50, "end": 54, "i_start": 12, "i_end": 12}}], "id": 324}, {"sent": "in the direction of proving the conjecture we will prove the following theorem .", "tokens": ["in", "the", "direction", "of", "proving", "the", "conjecture", "we", "will", "prove", "the", "following", "theorem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 43, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "proving", "start": 20, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 43, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "prove", "start": 51, "end": 56, "i_start": 9, "i_end": 9}}], "id": 325}, {"sent": "many mil algorithms have been successfully used for weakly-supervised learning , such as milboost .", "tokens": ["many", "mil", "algorithms", "have", "been", "successfully", "used", "for", "weakly", "-", "supervised", "learning", ",", "such", "as", "milboost", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many mil algorithms", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 43, "end": 47, "i_start": 6, "i_end": 6}}, {"subject": {"text": "many mil algorithms", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 20, "end": 29, "i_start": 3, "i_end": 4}}], "id": 326}, {"sent": "vgg13 is a convolutional neural network inspired by the network proposed for image classification of the same name .", "tokens": ["vgg13", "is", "a", "convolutional", "neural", "network", "inspired", "by", "the", "network", "proposed", "for", "image", "classification", "of", "the", "same", "name", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "vgg13", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "network", "start": 56, "end": 63, "i_start": 9, "i_end": 9}, "action": {"text": "inspired", "start": 40, "end": 48, "i_start": 6, "i_end": 6}}], "id": 327}, {"sent": "this theory is known as n very special geometry .", "tokens": ["this", "theory", "is", "known", "as", "n", "very", "special", "geometry", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this theory", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is known", "start": 12, "end": 20, "i_start": 2, "i_end": 3}}], "id": 328}, {"sent": "now we proceed on to define smarandache semivector spaces .", "tokens": ["now", "we", "proceed", "on", "to", "define", "smarandache", "semivector", "spaces", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed on", "start": 7, "end": 17, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 329}, {"sent": "it encodes the quality of coherent states of being canonical quantizers along a guideline established by klauder and berezin .", "tokens": ["it", "encodes", "the", "quality", "of", "coherent", "states", "of", "being", "canonical", "quantizers", "along", "a", "guideline", "established", "by", "klauder", "and", "berezin", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "encodes", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "encodes", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "klauder", "start": 105, "end": 112, "i_start": 16, "i_end": 16}, "action": {"text": "established", "start": 90, "end": 101, "i_start": 14, "i_end": 14}}, {"character": {"text": "berezin", "start": 117, "end": 124, "i_start": 18, "i_end": 18}, "action": {"text": "established", "start": 90, "end": 101, "i_start": 14, "i_end": 14}}], "id": 330}, {"sent": "jiang et al use easy samples to perform re-ranking of the initial video list .", "tokens": ["jiang", "et", "al", "use", "easy", "samples", "to", "perform", "re", "-", "ranking", "of", "the", "initial", "video", "list", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "jiang et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "use", "start": 12, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "jiang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 12, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "jiang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "perform", "start": 32, "end": 39, "i_start": 7, "i_end": 7}}, {"character": {"text": "jiang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "ranking", "start": 43, "end": 50, "i_start": 10, "i_end": 10}}], "id": 331}, {"sent": "early works show that such kind of identification task could greatly benefit the feature learning .", "tokens": ["early", "works", "show", "that", "such", "kind", "of", "identification", "task", "could", "greatly", "benefit", "the", "feature", "learning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "early works", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "show", "start": 12, "end": 16, "i_start": 2, "i_end": 2}}, {"subject": {"text": "such kind of identification task", "start": 22, "end": 54, "i_start": 4, "i_end": 8}, "verb": {"text": "benefit", "start": 69, "end": 76, "i_start": 11, "i_end": 11}}, {"character": {"text": "works", "start": 6, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 12, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "task", "start": 50, "end": 54, "i_start": 8, "i_end": 8}, "action": {"text": "benefit", "start": 69, "end": 76, "i_start": 11, "i_end": 11}}], "id": 332}, {"sent": "all weight matrices in the model were initialized with the fan-in trick and biases were initialized with zero .", "tokens": ["all", "weight", "matrices", "in", "the", "model", "were", "initialized", "with", "the", "fan", "-", "in", "trick", "and", "biases", "were", "initialized", "with", "zero", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all weight matrices in the model", "start": 0, "end": 32, "i_start": 0, "i_end": 5}, "verb": {"text": "were initialized", "start": 33, "end": 49, "i_start": 6, "i_end": 7}}, {"subject": {"text": "all weight matrices in the model", "start": 0, "end": 32, "i_start": 0, "i_end": 5}, "verb": {"text": "initialized", "start": 88, "end": 99, "i_start": 17, "i_end": 17}}], "id": 333}, {"sent": "prior work incorporates various visualizations in planar scatter plots of drs in order to improve the user experience .", "tokens": ["prior", "work", "incorporates", "various", "visualizations", "in", "planar", "scatter", "plots", "of", "drs", "in", "order", "to", "improve", "the", "user", "experience", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "prior work", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "incorporates", "start": 11, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "work", "start": 6, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "incorporates", "start": 11, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "work", "start": 6, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "improve", "start": 90, "end": 97, "i_start": 14, "i_end": 14}}], "id": 334}, {"sent": "wang et al employed the distance regularized level set evolution to locate the structural boundary .", "tokens": ["wang", "et", "al", "employed", "the", "distance", "regularized", "level", "set", "evolution", "to", "locate", "the", "structural", "boundary", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "wang et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "employed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "wang", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "employed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "wang", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "locate", "start": 68, "end": 74, "i_start": 11, "i_end": 11}}], "id": 335}, {"sent": "according to the agt conjecture the partition function of a 1 gaiotto theory on s 4 reduces to liouville amplitudes on the gaiotto curve .", "tokens": ["according", "to", "the", "agt", "conjecture", "the", "partition", "function", "of", "a", "1", "gaiotto", "theory", "on", "s", "4", "reduces", "to", "liouville", "amplitudes", "on", "the", "gaiotto", "curve", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the partition function of a 1 gaiotto theory on s 4", "start": 32, "end": 83, "i_start": 5, "i_end": 15}, "verb": {"text": "reduces", "start": 84, "end": 91, "i_start": 16, "i_end": 16}}, {"character": {"text": "theory", "start": 70, "end": 76, "i_start": 12, "i_end": 12}, "action": {"text": "function", "start": 46, "end": 54, "i_start": 7, "i_end": 7}}], "id": 336}, {"sent": "alternatively , the exit functions of the constituent decoders can be properly combined and projected into a two-dimensional chart .", "tokens": ["alternatively", ",", "the", "exit", "functions", "of", "the", "constituent", "decoders", "can", "be", "properly", "combined", "and", "projected", "into", "a", "two", "-", "dimensional", "chart", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exit functions of the constituent decoders", "start": 16, "end": 62, "i_start": 2, "i_end": 8}, "verb": {"text": "combined", "start": 79, "end": 87, "i_start": 12, "i_end": 12}}, {"subject": {"text": "the exit functions of the constituent decoders", "start": 16, "end": 62, "i_start": 2, "i_end": 8}, "verb": {"text": "can be", "start": 63, "end": 69, "i_start": 9, "i_end": 10}}, {"subject": {"text": "the exit functions of the constituent decoders", "start": 16, "end": 62, "i_start": 2, "i_end": 8}, "verb": {"text": "projected", "start": 92, "end": 101, "i_start": 14, "i_end": 14}}, {"character": {"text": "decoders", "start": 54, "end": 62, "i_start": 8, "i_end": 8}, "action": {"text": "functions", "start": 25, "end": 34, "i_start": 4, "i_end": 4}}], "id": 337}, {"sent": "cs is a novel theory for signal sensing and acquisition allowing to acquire signals in an already compressed fashion , using fewer coefficients than dictated by the classical nyquist-shannon theory .", "tokens": ["cs", "is", "a", "novel", "theory", "for", "signal", "sensing", "and", "acquisition", "allowing", "to", "acquire", "signals", "in", "an", "already", "compressed", "fashion", ",", "using", "fewer", "coefficients", "than", "dictated", "by", "the", "classical", "nyquist", "-", "shannon", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cs", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"character": {"text": "theory", "start": 14, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "allowing", "start": 56, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "theory", "start": 14, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "using", "start": 119, "end": 124, "i_start": 20, "i_end": 20}}, {"character": {"text": "theory", "start": 191, "end": 197, "i_start": 31, "i_end": 31}, "action": {"text": "dictated", "start": 149, "end": 157, "i_start": 24, "i_end": 24}}], "id": 338}, {"sent": "the second , and the more interesting example is that of the axially symmetric graded index medium .", "tokens": ["the", "second", ",", "and", "the", "more", "interesting", "example", "is", "that", "of", "the", "axially", "symmetric", "graded", "index", "medium", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the second , and the more interesting example is that of the axially symmetric graded index medium", "start": 0, "end": 98, "i_start": 0, "i_end": 16}, "verb": {"text": "is", "start": 46, "end": 48, "i_start": 8, "i_end": 8}}, {"character": {"text": "example", "start": 38, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "interesting", "start": 26, "end": 37, "i_start": 6, "i_end": 6}}], "id": 339}, {"sent": "in , a multitask dirty model , where each component matrix is regularized by a priori information organized in a graph , is proposed for head pose classification in an uncontrolled environment .", "tokens": ["in", ",", "a", "multitask", "dirty", "model", ",", "where", "each", "component", "matrix", "is", "regularized", "by", "a", "priori", "information", "organized", "in", "a", "graph", ",", "is", "proposed", "for", "head", "pose", "classification", "in", "an", "uncontrolled", "environment", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "a multitask dirty model", "start": 5, "end": 28, "i_start": 2, "i_end": 5}, "verb": {"text": "is proposed", "start": 121, "end": 132, "i_start": 22, "i_end": 23}}, {"character": {"text": "information", "start": 86, "end": 97, "i_start": 16, "i_end": 16}, "action": {"text": "regularized", "start": 62, "end": 73, "i_start": 12, "i_end": 12}}], "id": 340}, {"sent": "we give an analytic and geometric interpretation of our holomorphic linking following the parallel with the real case .", "tokens": ["we", "give", "an", "analytic", "and", "geometric", "interpretation", "of", "our", "holomorphic", "linking", "following", "the", "parallel", "with", "the", "real", "case", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "give", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "interpretation", "start": 34, "end": 48, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "linking", "start": 68, "end": 75, "i_start": 10, "i_end": 10}}], "id": 341}, {"sent": "one might consider trying to perform a similar analysis with the blg model .", "tokens": ["one", "might", "consider", "trying", "to", "perform", "a", "similar", "analysis", "with", "the", "blg", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "might consider", "start": 4, "end": 18, "i_start": 1, "i_end": 2}}, {"character": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "consider", "start": 10, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "trying", "start": 19, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "perform", "start": 29, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "analysis", "start": 47, "end": 55, "i_start": 8, "i_end": 8}}], "id": 342}, {"sent": "ever since the seminal work of tadmor , there has been some interest in techniques to mimic for semidiscretisations of hyperbolic conservation laws .", "tokens": ["ever", "since", "the", "seminal", "work", "of", "tadmor", ",", "there", "has", "been", "some", "interest", "in", "techniques", "to", "mimic", "for", "semidiscretisations", "of", "hyperbolic", "conservation", "laws", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 40, "end": 45, "i_start": 8, "i_end": 8}, "verb": {"text": "has been", "start": 46, "end": 54, "i_start": 9, "i_end": 10}}], "id": 343}, {"sent": "to compute semantic similarity , we rely on standard latent topic models , in particular latent semantic indexing and latent dirichlet allocation .", "tokens": ["to", "compute", "semantic", "similarity", ",", "we", "rely", "on", "standard", "latent", "topic", "models", ",", "in", "particular", "latent", "semantic", "indexing", "and", "latent", "dirichlet", "allocation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 33, "end": 35, "i_start": 5, "i_end": 5}, "verb": {"text": "rely", "start": 36, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 33, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "rely", "start": 36, "end": 40, "i_start": 6, "i_end": 6}}], "id": 344}, {"sent": "this is the second sign that rw optimal routing undo correlation between traffic load and network structure .", "tokens": ["this", "is", "the", "second", "sign", "that", "rw", "optimal", "routing", "undo", "correlation", "between", "traffic", "load", "and", "network", "structure", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "sign", "start": 19, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "routing", "start": 40, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "undo", "start": 48, "end": 52, "i_start": 9, "i_end": 9}}], "id": 345}, {"sent": "tzeng et al summarized various adversarial processes that can be used for domain adaptation and proposed a gan loss-based adaptation framework .", "tokens": ["tzeng", "et", "al", "summarized", "various", "adversarial", "processes", "that", "can", "be", "used", "for", "domain", "adaptation", "and", "proposed", "a", "gan", "loss", "-", "based", "adaptation", "framework", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "tzeng et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "summarized", "start": 12, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "tzeng", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "summarized", "start": 12, "end": 22, "i_start": 3, "i_end": 3}}], "id": 346}, {"sent": "the blue lines show the results of the simulations with the uniform foam .", "tokens": ["the", "blue", "lines", "show", "the", "results", "of", "the", "simulations", "with", "the", "uniform", "foam", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the blue lines", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "show", "start": 15, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "lines", "start": 9, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 15, "end": 19, "i_start": 3, "i_end": 3}}], "id": 347}, {"sent": "recently , deep learning models , especially convolutional neural networks , have revolutionized various machine learning tasks with gridlike input data , such as image classification .", "tokens": ["recently", ",", "deep", "learning", "models", ",", "especially", "convolutional", "neural", "networks", ",", "have", "revolutionized", "various", "machine", "learning", "tasks", "with", "gridlike", "input", "data", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep learning models", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have revolutionized", "start": 77, "end": 96, "i_start": 11, "i_end": 12}}, {"character": {"text": "models", "start": 25, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "revolutionized", "start": 82, "end": 96, "i_start": 12, "i_end": 12}}], "id": 348}, {"sent": "convolutional neural networks have achieved state-of-the-art performance on visual tasks such as image and video recognition in the last few years .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "visual", "tasks", "such", "as", "image", "and", "video", "recognition", "in", "the", "last", "few", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 61, "end": 72, "i_start": 12, "i_end": 12}}], "id": 349}, {"sent": "cosmic strings are linear topological defects that can form in the early universe as a result of symmetry-breaking phase transitions .", "tokens": ["cosmic", "strings", "are", "linear", "topological", "defects", "that", "can", "form", "in", "the", "early", "universe", "as", "a", "result", "of", "symmetry", "-", "breaking", "phase", "transitions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "transitions", "start": 121, "end": 132, "i_start": 21, "i_end": 21}, "action": {"text": "breaking", "start": 106, "end": 114, "i_start": 19, "i_end": 19}}], "id": 350}, {"sent": "recently , the use of deep convolutional neural networks has shown promising results for many vision-based tasks including image classification .", "tokens": ["recently", ",", "the", "use", "of", "deep", "convolutional", "neural", "networks", "has", "shown", "promising", "results", "for", "many", "vision", "-", "based", "tasks", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the use of deep convolutional neural networks", "start": 11, "end": 56, "i_start": 2, "i_end": 8}, "verb": {"text": "has shown", "start": 57, "end": 66, "i_start": 9, "i_end": 10}}, {"character": {"text": "use", "start": 15, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 61, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "results", "start": 77, "end": 84, "i_start": 12, "i_end": 12}, "action": {"text": "promising", "start": 67, "end": 76, "i_start": 11, "i_end": 11}}], "id": 351}, {"sent": "in the visual categorization field , convolutional neural networks were found to display intriguing vulnerabilities .", "tokens": ["in", "the", "visual", "categorization", "field", ",", "convolutional", "neural", "networks", "were", "found", "to", "display", "intriguing", "vulnerabilities", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 37, "end": 66, "i_start": 6, "i_end": 8}, "verb": {"text": "were found", "start": 67, "end": 77, "i_start": 9, "i_end": 10}}, {"character": {"text": "networks", "start": 58, "end": 66, "i_start": 8, "i_end": 8}, "action": {"text": "display", "start": 81, "end": 88, "i_start": 12, "i_end": 12}}, {"character": {"text": "networks", "start": 58, "end": 66, "i_start": 8, "i_end": 8}, "action": {"text": "vulnerabilities", "start": 100, "end": 115, "i_start": 14, "i_end": 14}}, {"character": {"text": "vulnerabilities", "start": 100, "end": 115, "i_start": 14, "i_end": 14}, "action": {"text": "intriguing", "start": 89, "end": 99, "i_start": 13, "i_end": 13}}], "id": 352}, {"sent": "one major motivation of this paper is to extend the original problem in to some general models that can be widely used in practice assuming an arbitrary number of carriers .", "tokens": ["one", "major", "motivation", "of", "this", "paper", "is", "to", "extend", "the", "original", "problem", "in", "to", "some", "general", "models", "that", "can", "be", "widely", "used", "in", "practice", "assuming", "an", "arbitrary", "number", "of", "carriers", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one major motivation of this paper", "start": 0, "end": 34, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 6, "i_end": 6}}], "id": 353}, {"sent": "from this it is evident that nearly all planetary detections in high magnification events will not involve caustic crossings .", "tokens": ["from", "this", "it", "is", "evident", "that", "nearly", "all", "planetary", "detections", "in", "high", "magnification", "events", "will", "not", "involve", "caustic", "crossings", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 3, "i_end": 3}}, {"subject": {"text": "nearly all planetary detections in high magnification events", "start": 29, "end": 89, "i_start": 6, "i_end": 13}, "verb": {"text": "involve", "start": 99, "end": 106, "i_start": 16, "i_end": 16}}, {"character": {"text": "this", "start": 5, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "evident", "start": 16, "end": 23, "i_start": 4, "i_end": 4}}], "id": 354}, {"sent": "we show that the problem is np-complete using a reduction from the known np-complete problem set cover .", "tokens": ["we", "show", "that", "the", "problem", "is", "np", "-", "complete", "using", "a", "reduction", "from", "the", "known", "np", "-", "complete", "problem", "set", "cover", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 355}, {"sent": "this is usually known as preferential attachment in the network literature .", "tokens": ["this", "is", "usually", "known", "as", "preferential", "attachment", "in", "the", "network", "literature", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "known", "start": 16, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 356}, {"sent": "one way to restrict the instances is to only allow a fixed set of constraint relations , often referred to as a constraint language or fixed template .", "tokens": ["one", "way", "to", "restrict", "the", "instances", "is", "to", "only", "allow", "a", "fixed", "set", "of", "constraint", "relations", ",", "often", "referred", "to", "as", "a", "constraint", "language", "or", "fixed", "template", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one way to restrict the instances", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 6, "i_end": 6}}], "id": 357}, {"sent": "the vertical extent of the two shaded regions indicates the values used in our analysis .", "tokens": ["the", "vertical", "extent", "of", "the", "two", "shaded", "regions", "indicates", "the", "values", "used", "in", "our", "analysis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the vertical extent of the two shaded regions", "start": 0, "end": 45, "i_start": 0, "i_end": 7}, "verb": {"text": "indicates", "start": 46, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "extent", "start": 13, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "indicates", "start": 46, "end": 55, "i_start": 8, "i_end": 8}}], "id": 358}, {"sent": "deep generative adversarial networks has enabled considerable improvements in image generation .", "tokens": ["deep", "generative", "adversarial", "networks", "has", "enabled", "considerable", "improvements", "in", "image", "generation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep generative adversarial networks", "start": 0, "end": 36, "i_start": 0, "i_end": 3}, "verb": {"text": "has enabled", "start": 37, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 28, "end": 36, "i_start": 3, "i_end": 3}, "action": {"text": "enabled", "start": 41, "end": 48, "i_start": 5, "i_end": 5}}], "id": 359}, {"sent": "spectral gap around the fermi surface is plotted in the left panel .", "tokens": ["spectral", "gap", "around", "the", "fermi", "surface", "is", "plotted", "in", "the", "left", "panel", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "spectral gap around the fermi surface", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "is plotted", "start": 38, "end": 48, "i_start": 6, "i_end": 7}}], "id": 360}, {"sent": "characterize those semigroup rings zns which are s-pseudo commutative .", "tokens": ["characterize", "those", "semigroup", "rings", "zns", "which", "are", "s", "-", "pseudo", "commutative", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 361}, {"sent": "the semigrand canonical ensemble is the best frame to investigate the phase be havior of a polydisperse hss .", "tokens": ["the", "semigrand", "canonical", "ensemble", "is", "the", "best", "frame", "to", "investigate", "the", "phase", "be", "havior", "of", "a", "polydisperse", "hss", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the semigrand canonical ensemble", "start": 0, "end": 32, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 4, "i_end": 4}}], "id": 362}, {"sent": "the availability of large-scale data is known to be one of the critical success factors of deep learning .", "tokens": ["the", "availability", "of", "large", "-", "scale", "data", "is", "known", "to", "be", "one", "of", "the", "critical", "success", "factors", "of", "deep", "learning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the availability of large-scale data", "start": 0, "end": 36, "i_start": 0, "i_end": 6}, "verb": {"text": "is known", "start": 37, "end": 45, "i_start": 7, "i_end": 8}}], "id": 363}, {"sent": "deep neural networks have been widely applied in various fields , including computer vision he et al , among many others .", "tokens": ["deep", "neural", "networks", "have", "been", "widely", "applied", "in", "various", "fields", ",", "including", "computer", "vision", "he", "et", "al", ",", "among", "many", "others", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "applied", "start": 38, "end": 45, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}], "id": 364}, {"sent": "modeling of combined thermal and mechanical action in concrete .", "tokens": ["modeling", "of", "combined", "thermal", "and", "mechanical", "action", "in", "concrete", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 365}, {"sent": "therefore the detection potential for relevant plasma physical processes and the characteristic scales of turbulent energy injection and dissipation would be increased considerably .", "tokens": ["therefore", "the", "detection", "potential", "for", "relevant", "plasma", "physical", "processes", "and", "the", "characteristic", "scales", "of", "turbulent", "energy", "injection", "and", "dissipation", "would", "be", "increased", "considerably", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the detection potential for relevant plasma physical processes and the characteristic scales of turbulent energy injection and dissipation", "start": 10, "end": 148, "i_start": 1, "i_end": 18}, "verb": {"text": "would be increased", "start": 149, "end": 167, "i_start": 19, "i_end": 21}}], "id": 366}, {"sent": "convolutional neural networks have achieved the state-of-the-art performance in many applications such as computer vision .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "many", "applications", "such", "as", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 65, "end": 76, "i_start": 13, "i_end": 13}}], "id": 367}, {"sent": "in such a continuum setting the observation that due to the crystalline structure certain crack geometries are preferred is modeled by anisotropic surface energies , see eg .", "tokens": ["in", "such", "a", "continuum", "setting", "the", "observation", "that", "due", "to", "the", "crystalline", "structure", "certain", "crack", "geometries", "are", "preferred", "is", "modeled", "by", "anisotropic", "surface", "energies", ",", "see", "eg", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "such a continuum setting the observation that due to the crystalline structure certain crack geometries are preferred", "start": 3, "end": 120, "i_start": 1, "i_end": 17}, "verb": {"text": "is modeled", "start": 121, "end": 131, "i_start": 18, "i_end": 19}}, {"character": {"text": "energies", "start": 155, "end": 163, "i_start": 23, "i_end": 23}, "action": {"text": "modeled", "start": 124, "end": 131, "i_start": 19, "i_end": 19}}], "id": 368}, {"sent": "ahn et al integrate freebase facts into a language model using a copying mechanism over fact attributes .", "tokens": ["ahn", "et", "al", "integrate", "freebase", "facts", "into", "a", "language", "model", "using", "a", "copying", "mechanism", "over", "fact", "attributes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "ahn et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "integrate", "start": 10, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "ahn", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "integrate", "start": 10, "end": 19, "i_start": 3, "i_end": 3}}], "id": 369}, {"sent": "gan is first proposed by ian goodfellow et al as a new generation model .", "tokens": ["gan", "is", "first", "proposed", "by", "ian", "goodfellow", "et", "al", "as", "a", "new", "generation", "model", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "gan", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "proposed", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "gan", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 4, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "goodfellow", "start": 29, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "proposed", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}], "id": 370}, {"sent": "recent years have witnessed an increased interest in adopting the stochastic gradient methods for solving large-scale machine learning problems .", "tokens": ["recent", "years", "have", "witnessed", "an", "increased", "interest", "in", "adopting", "the", "stochastic", "gradient", "methods", "for", "solving", "large", "-", "scale", "machine", "learning", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent years", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "have witnessed", "start": 13, "end": 27, "i_start": 2, "i_end": 3}}, {"character": {"text": "years", "start": 7, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "witnessed", "start": 18, "end": 27, "i_start": 3, "i_end": 3}}], "id": 371}, {"sent": "following this , we argue that the notion of important separators introduced by marx can be used to essentially narrow down the search space of separators where we must search for a solution variable .", "tokens": ["following", "this", ",", "we", "argue", "that", "the", "notion", "of", "important", "separators", "introduced", "by", "marx", "can", "be", "used", "to", "essentially", "narrow", "down", "the", "search", "space", "of", "separators", "where", "we", "must", "search", "for", "a", "solution", "variable", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 17, "end": 19, "i_start": 3, "i_end": 3}, "verb": {"text": "argue", "start": 20, "end": 25, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the notion of important separators introduced by marx", "start": 31, "end": 84, "i_start": 6, "i_end": 13}, "verb": {"text": "used", "start": 92, "end": 96, "i_start": 16, "i_end": 16}}, {"character": {"text": "we", "start": 17, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "argue", "start": 20, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "notion", "start": 35, "end": 41, "i_start": 7, "i_end": 7}, "action": {"text": "narrow", "start": 112, "end": 118, "i_start": 19, "i_end": 19}}, {"character": {"text": "we", "start": 17, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "search", "start": 169, "end": 175, "i_start": 29, "i_end": 29}}], "id": 372}, {"sent": "the estimation of these models is usually done using the em algorithm .", "tokens": ["the", "estimation", "of", "these", "models", "is", "usually", "done", "using", "the", "em", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the estimation of these models", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "done", "start": 42, "end": 46, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the estimation of these models", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 5, "i_end": 5}}], "id": 373}, {"sent": "since the complex above is equivariant for gl .", "tokens": ["since", "the", "complex", "above", "is", "equivariant", "for", "gl", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the complex above", "start": 6, "end": 23, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 4, "i_end": 4}}], "id": 374}, {"sent": "the stochastic block model is a special case of the latent space model .", "tokens": ["the", "stochastic", "block", "model", "is", "a", "special", "case", "of", "the", "latent", "space", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the stochastic block model", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 4, "i_end": 4}}], "id": 375}, {"sent": "an amino acid of a protein is called a residue .", "tokens": ["an", "amino", "acid", "of", "a", "protein", "is", "called", "a", "residue", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an amino acid of a protein", "start": 0, "end": 26, "i_start": 0, "i_end": 5}, "verb": {"text": "is called", "start": 27, "end": 36, "i_start": 6, "i_end": 7}}], "id": 376}, {"sent": "the authors in study a cognitive radio network where the primary and secondary networks are distributed as independent homogeneous ppps .", "tokens": ["the", "authors", "in", "study", "a", "cognitive", "radio", "network", "where", "the", "primary", "and", "secondary", "networks", "are", "distributed", "as", "independent", "homogeneous", "ppps", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "ppps", "start": 131, "end": 135, "i_start": 19, "i_end": 19}, "action": {"text": "independent", "start": 107, "end": 118, "i_start": 17, "i_end": 17}}], "id": 377}, {"sent": "many progress has been made in recent years with the rapid development of convolutional neural networks .", "tokens": ["many", "progress", "has", "been", "made", "in", "recent", "years", "with", "the", "rapid", "development", "of", "convolutional", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many progress", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has been made", "start": 14, "end": 27, "i_start": 2, "i_end": 4}}], "id": 378}, {"sent": "deep neural networks have demonstrated significant performance improvements in a wide range of computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "significant", "performance", "improvements", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improvements", "start": 63, "end": 75, "i_start": 7, "i_end": 7}}], "id": 379}, {"sent": "deep learning has brought significant breakthroughs in many computer vision tasks , including object detection .", "tokens": ["deep", "learning", "has", "brought", "significant", "breakthroughs", "in", "many", "computer", "vision", "tasks", ",", "including", "object", "detection", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has brought", "start": 14, "end": 25, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "breakthroughs", "start": 38, "end": 51, "i_start": 5, "i_end": 5}}], "id": 380}, {"sent": "neutrino is the main candidate for hot dark matter , but unable to take-up the full account .", "tokens": ["neutrino", "is", "the", "main", "candidate", "for", "hot", "dark", "matter", ",", "but", "unable", "to", "take", "-", "up", "the", "full", "account", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neutrino", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "neutrino", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "take", "start": 67, "end": 71, "i_start": 13, "i_end": 13}}], "id": 381}, {"sent": "deep convolutional neural networks have shown promising performances on various computer vision problems such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "shown", "promising", "performances", "on", "various", "computer", "vision", "problems", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have shown", "start": 35, "end": 45, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 40, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performances", "start": 56, "end": 68, "i_start": 7, "i_end": 7}}, {"character": {"text": "performances", "start": 56, "end": 68, "i_start": 7, "i_end": 7}, "action": {"text": "promising", "start": 46, "end": 55, "i_start": 6, "i_end": 6}}], "id": 382}, {"sent": "such a transformation is called a linear toral automorphism .", "tokens": ["such", "a", "transformation", "is", "called", "a", "linear", "toral", "automorphism", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such a transformation", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 22, "end": 31, "i_start": 3, "i_end": 4}}], "id": 383}, {"sent": "actually , this theorem has three forms , which are used by bayes respectively .", "tokens": ["actually", ",", "this", "theorem", "has", "three", "forms", ",", "which", "are", "used", "by", "bayes", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this theorem", "start": 11, "end": 23, "i_start": 2, "i_end": 3}, "verb": {"text": "has", "start": 24, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "theorem", "start": 16, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "has", "start": 24, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "bayes", "start": 60, "end": 65, "i_start": 12, "i_end": 12}, "action": {"text": "used", "start": 52, "end": 56, "i_start": 10, "i_end": 10}}], "id": 384}, {"sent": "biological interference should not be confused with the intersymbol interference or co-channel interference which have been already investigated in , from the aspect of mc .", "tokens": ["biological", "interference", "should", "not", "be", "confused", "with", "the", "intersymbol", "interference", "or", "co", "-", "channel", "interference", "which", "have", "been", "already", "investigated", "in", ",", "from", "the", "aspect", "of", "mc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "biological interference", "start": 0, "end": 23, "i_start": 0, "i_end": 1}, "verb": {"text": "should not be confused", "start": 24, "end": 46, "i_start": 2, "i_end": 5}}], "id": 385}, {"sent": "the exchangecorrelation functional is approximated within the local density approximation .", "tokens": ["the", "exchangecorrelation", "functional", "is", "approximated", "within", "the", "local", "density", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchangecorrelation functional", "start": 0, "end": 34, "i_start": 0, "i_end": 2}, "verb": {"text": "is approximated", "start": 35, "end": 50, "i_start": 3, "i_end": 4}}], "id": 386}, {"sent": "sauerbrei and schumacher investigated bootstrapping variable selection methods in the cox regression model .", "tokens": ["sauerbrei", "and", "schumacher", "investigated", "bootstrapping", "variable", "selection", "methods", "in", "the", "cox", "regression", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "sauerbrei", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "investigated", "start": 25, "end": 37, "i_start": 3, "i_end": 3}}, {"character": {"text": "schumacher", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "investigated", "start": 25, "end": 37, "i_start": 3, "i_end": 3}}], "id": 387}, {"sent": "compares the asrs between the proposed mmwave-noma algorithm , the mmwave-noma approach in and mmwave-oma with varying total power to noise ratio .", "tokens": ["compares", "the", "asrs", "between", "the", "proposed", "mmwave", "-", "noma", "algorithm", ",", "the", "mmwave", "-", "noma", "approach", "in", "and", "mmwave", "-", "oma", "with", "varying", "total", "power", "to", "noise", "ratio", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 388}, {"sent": "the ordinate is the radial component of the momentum and in the abscissas one has the distance of the test-particle to the central mass .", "tokens": ["the", "ordinate", "is", "the", "radial", "component", "of", "the", "momentum", "and", "in", "the", "abscissas", "one", "has", "the", "distance", "of", "the", "test", "-", "particle", "to", "the", "central", "mass", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ordinate", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"subject": {"text": "one", "start": 74, "end": 77, "i_start": 13, "i_end": 13}, "verb": {"text": "has", "start": 78, "end": 81, "i_start": 14, "i_end": 14}}, {"character": {"text": "one", "start": 74, "end": 77, "i_start": 13, "i_end": 13}, "action": {"text": "has", "start": 78, "end": 81, "i_start": 14, "i_end": 14}}], "id": 389}, {"sent": "recently , deep convolutional neural networks have attracted a lot of attention in visual recognition , largely due to their excellent performance .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "attracted", "a", "lot", "of", "attention", "in", "visual", "recognition", ",", "largely", "due", "to", "their", "excellent", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have attracted", "start": 46, "end": 60, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "attracted", "start": 51, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 135, "end": 146, "i_start": 21, "i_end": 21}}], "id": 390}, {"sent": "then the host-guest free energy is a sum of the lattice gas and elastic part f where flg .", "tokens": ["then", "the", "host", "-", "guest", "free", "energy", "is", "a", "sum", "of", "the", "lattice", "gas", "and", "elastic", "part", "f", "where", "flg", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the host-guest free energy", "start": 5, "end": 31, "i_start": 1, "i_end": 6}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 7, "i_end": 7}}], "id": 391}, {"sent": "farabet et al proposed a multiscale convolution neural network for semantic segmentation .", "tokens": ["farabet", "et", "al", "proposed", "a", "multiscale", "convolution", "neural", "network", "for", "semantic", "segmentation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "farabet et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "farabet", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}], "id": 392}, {"sent": "the perdew-burke-ernzehof form of the generalized gradient approximation is used to describe electron exchange and correlation .", "tokens": ["the", "perdew", "-", "burke", "-", "ernzehof", "form", "of", "the", "generalized", "gradient", "approximation", "is", "used", "to", "describe", "electron", "exchange", "and", "correlation", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the perdew-burke-ernzehof form of the generalized gradient approximation", "start": 0, "end": 72, "i_start": 0, "i_end": 11}, "verb": {"text": "is used", "start": 73, "end": 80, "i_start": 12, "i_end": 13}}, {"character": {"text": "form", "start": 26, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "describe", "start": 84, "end": 92, "i_start": 15, "i_end": 15}}], "id": 393}, {"sent": "each convolutional layer is followed by a batch normalization layer .", "tokens": ["each", "convolutional", "layer", "is", "followed", "by", "a", "batch", "normalization", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each convolutional layer", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is followed", "start": 25, "end": 36, "i_start": 3, "i_end": 4}}], "id": 394}, {"sent": "following the tradition of the traffic signal control study , we conduct experiments on sumo 1 .", "tokens": ["following", "the", "tradition", "of", "the", "traffic", "signal", "control", "study", ",", "we", "conduct", "experiments", "on", "sumo", "1", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 62, "end": 64, "i_start": 10, "i_end": 10}, "verb": {"text": "conduct", "start": 65, "end": 72, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 62, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "conduct", "start": 65, "end": 72, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 62, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "experiments", "start": 73, "end": 84, "i_start": 12, "i_end": 12}}], "id": 395}, {"sent": "this asymmetry is a direct manifestation of the broken time-reversal symmetry characteristic of a complex superconducting order parameter .", "tokens": ["this", "asymmetry", "is", "a", "direct", "manifestation", "of", "the", "broken", "time", "-", "reversal", "symmetry", "characteristic", "of", "a", "complex", "superconducting", "order", "parameter", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this asymmetry", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "symmetry", "start": 69, "end": 77, "i_start": 12, "i_end": 12}, "action": {"text": "manifestation", "start": 27, "end": 40, "i_start": 5, "i_end": 5}}], "id": 396}, {"sent": "collective behaviors of many-particle systems are ubiquitous in our nature , eg , flocking of birds , flashing of fireflies , swarming of fishes and herding of sheep , etc .", "tokens": ["collective", "behaviors", "of", "many", "-", "particle", "systems", "are", "ubiquitous", "in", "our", "nature", ",", "eg", ",", "flocking", "of", "birds", ",", "flashing", "of", "fireflies", ",", "swarming", "of", "fishes", "and", "herding", "of", "sheep", ",", "etc", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "collective behaviors of many-particle systems are ubiquitous in our nature , eg", "start": 0, "end": 79, "i_start": 0, "i_end": 13}, "verb": {"text": "are", "start": 46, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "systems", "start": 38, "end": 45, "i_start": 6, "i_end": 6}, "action": {"text": "behaviors", "start": 11, "end": 20, "i_start": 1, "i_end": 1}}], "id": 397}, {"sent": "over the past few years , deep convolutional neural networks have been very successful in a wide range of computer vision tasks such as image classification .", "tokens": ["over", "the", "past", "few", "years", ",", "deep", "convolutional", "neural", "networks", "have", "been", "very", "successful", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 26, "end": 60, "i_start": 6, "i_end": 9}, "verb": {"text": "have been", "start": 61, "end": 70, "i_start": 10, "i_end": 11}}, {"character": {"text": "networks", "start": 52, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "successful", "start": 76, "end": 86, "i_start": 13, "i_end": 13}}], "id": 398}, {"sent": "we train our model on the referential expressions in the flickr30k dataset using the same top-100 edgebox .", "tokens": ["we", "train", "our", "model", "on", "the", "referential", "expressions", "in", "the", "flickr30k", "dataset", "using", "the", "same", "top-100", "edgebox", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 399}, {"sent": "a vector with such a property is called a vacuum .", "tokens": ["a", "vector", "with", "such", "a", "property", "is", "called", "a", "vacuum", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a vector with such a property", "start": 0, "end": 29, "i_start": 0, "i_end": 5}, "verb": {"text": "is called", "start": 30, "end": 39, "i_start": 6, "i_end": 7}}], "id": 400}, {"sent": "in other cases , as in , direct solutions are given in closed form .", "tokens": ["in", "other", "cases", ",", "as", "in", ",", "direct", "solutions", "are", "given", "in", "closed", "form", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "direct solutions", "start": 25, "end": 41, "i_start": 7, "i_end": 8}, "verb": {"text": "are given", "start": 42, "end": 51, "i_start": 9, "i_end": 10}}], "id": 401}, {"sent": "we optimize the losses and using the adam implementation in pytorch with default parameters .", "tokens": ["we", "optimize", "the", "losses", "and", "using", "the", "adam", "implementation", "in", "pytorch", "with", "default", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "optimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "using", "start": 27, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 27, "end": 32, "i_start": 5, "i_end": 5}}], "id": 402}, {"sent": "now let us turn to the behavior of tree amplitudes at high energies .", "tokens": ["now", "let", "us", "turn", "to", "the", "behavior", "of", "tree", "amplitudes", "at", "high", "energies", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "let", "start": 4, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "us", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "turn", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "let", "start": 4, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "us", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "turn", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "amplitudes", "start": 40, "end": 50, "i_start": 9, "i_end": 9}, "action": {"text": "behavior", "start": 23, "end": 31, "i_start": 6, "i_end": 6}}], "id": 403}, {"sent": "we considered the lbp with a circular neighbourhood of radius 2 and 16 elements , and 18 uniform and rotation invariant patterns .", "tokens": ["we", "considered", "the", "lbp", "with", "a", "circular", "neighbourhood", "of", "radius", "2", "and", "16", "elements", ",", "and", "18", "uniform", "and", "rotation", "invariant", "patterns", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "considered", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "considered", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}], "id": 404}, {"sent": "quantum computers are appealing for their ability to solve certain type of problems more effectively than in the classical setting .", "tokens": ["quantum", "computers", "are", "appealing", "for", "their", "ability", "to", "solve", "certain", "type", "of", "problems", "more", "effectively", "than", "in", "the", "classical", "setting", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "quantum computers", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "are appealing", "start": 18, "end": 31, "i_start": 2, "i_end": 3}}, {"character": {"text": "computers", "start": 8, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "appealing", "start": 22, "end": 31, "i_start": 3, "i_end": 3}}, {"character": {"text": "computers", "start": 8, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "solve", "start": 53, "end": 58, "i_start": 8, "i_end": 8}}, {"character": {"text": "solve", "start": 53, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "effectively", "start": 89, "end": 100, "i_start": 14, "i_end": 14}}], "id": 405}, {"sent": "bergsma et al proposed a game ai architecture which used influence maps for a turn based strategy game .", "tokens": ["bergsma", "et", "al", "proposed", "a", "game", "ai", "architecture", "which", "used", "influence", "maps", "for", "a", "turn", "based", "strategy", "game", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 8, "end": 13, "i_start": 1, "i_end": 2}, "verb": {"text": "proposed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}, {"subject": {"text": "a game", "start": 23, "end": 29, "i_start": 4, "i_end": 5}, "verb": {"text": "ai", "start": 30, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "bergsma", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "game", "start": 25, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "used", "start": 52, "end": 56, "i_start": 9, "i_end": 9}}], "id": 406}, {"sent": "in fang , the full euler equations were studied with a uniform bernoulli constant for both weak and strong transonic shocks .", "tokens": ["in", "fang", ",", "the", "full", "euler", "equations", "were", "studied", "with", "a", "uniform", "bernoulli", "constant", "for", "both", "weak", "and", "strong", "transonic", "shocks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the full euler equations", "start": 10, "end": 34, "i_start": 3, "i_end": 6}, "verb": {"text": "were studied", "start": 35, "end": 47, "i_start": 7, "i_end": 8}}], "id": 407}, {"sent": "while any non-zero gains c ij for the distributed averaging will guarantee that the control objectives are reached , an important design question is how to choose these gains to optimize the transient performance considered herein .", "tokens": ["while", "any", "non", "-", "zero", "gains", "c", "ij", "for", "the", "distributed", "averaging", "will", "guarantee", "that", "the", "control", "objectives", "are", "reached", ",", "an", "important", "design", "question", "is", "how", "to", "choose", "these", "gains", "to", "optimize", "the", "transient", "performance", "considered", "herein", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "an important design question", "start": 117, "end": 145, "i_start": 21, "i_end": 24}, "verb": {"text": "is", "start": 146, "end": 148, "i_start": 25, "i_end": 25}}, {"character": {"text": "gains", "start": 19, "end": 24, "i_start": 5, "i_end": 5}, "action": {"text": "guarantee", "start": 65, "end": 74, "i_start": 13, "i_end": 13}}], "id": 408}, {"sent": "in this context , mimo architectures and artificial-noise -aided secure transmissions have been widely adopted to enhance the secrecy performance of wireless communications .", "tokens": ["in", "this", "context", ",", "mimo", "architectures", "and", "artificial", "-", "noise", "-aided", "secure", "transmissions", "have", "been", "widely", "adopted", "to", "enhance", "the", "secrecy", "performance", "of", "wireless", "communications", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "mimo architectures and artificial-noise -aided secure transmissions", "start": 18, "end": 85, "i_start": 4, "i_end": 12}, "verb": {"text": "adopted", "start": 103, "end": 110, "i_start": 16, "i_end": 16}}, {"subject": {"text": "mimo architectures and artificial-noise -aided secure transmissions", "start": 18, "end": 85, "i_start": 4, "i_end": 12}, "verb": {"text": "have been", "start": 86, "end": 95, "i_start": 13, "i_end": 14}}], "id": 409}, {"sent": "axions are hypothetical nambu-goldstone-bosons associated with the spontaneously broken peccei-quinn symmetry that have been suggested as a solution of the cp-violation problem in the strong interactions .", "tokens": ["axions", "are", "hypothetical", "nambu", "-", "goldstone", "-", "bosons", "associated", "with", "the", "spontaneously", "broken", "peccei", "-", "quinn", "symmetry", "that", "have", "been", "suggested", "as", "a", "solution", "of", "the", "cp", "-", "violation", "problem", "in", "the", "strong", "interactions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "axions", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 7, "end": 10, "i_start": 1, "i_end": 1}}], "id": 410}, {"sent": "the p-wave pairing state is dominant owing to the vertex correction in the intermediate density .", "tokens": ["the", "p", "-", "wave", "pairing", "state", "is", "dominant", "owing", "to", "the", "vertex", "correction", "in", "the", "intermediate", "density", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the p-wave pairing state", "start": 0, "end": 24, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 6, "i_end": 6}}, {"character": {"text": "state", "start": 19, "end": 24, "i_start": 5, "i_end": 5}, "action": {"text": "dominant", "start": 28, "end": 36, "i_start": 7, "i_end": 7}}], "id": 411}, {"sent": "nonequilibrium phase transitions in lattice models .", "tokens": ["nonequilibrium", "phase", "transitions", "in", "lattice", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 412}, {"sent": "recently , generative adversarial nets , a general framework for estimating generative models via an adversarial process , has shown outstanding performance in image-to-image translation .", "tokens": ["recently", ",", "generative", "adversarial", "nets", ",", "a", "general", "framework", "for", "estimating", "generative", "models", "via", "an", "adversarial", "process", ",", "has", "shown", "outstanding", "performance", "in", "image", "-", "to", "-", "image", "translation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "nets", "start": 34, "end": 38, "i_start": 4, "i_end": 4}, "action": {"text": "shown", "start": 127, "end": 132, "i_start": 19, "i_end": 19}}], "id": 413}, {"sent": "deep neural networks have demonstrated significant performance improvements in a wide range of computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "significant", "performance", "improvements", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improvements", "start": 63, "end": 75, "i_start": 7, "i_end": 7}}], "id": 414}, {"sent": "on a more computational perspective , studying the convergence of empirical averages is an important problem for the efficiency of monte carlo markov chain methods , large deviations theory has been given many extensions .", "tokens": ["on", "a", "more", "computational", "perspective", ",", "studying", "the", "convergence", "of", "empirical", "averages", "is", "an", "important", "problem", "for", "the", "efficiency", "of", "monte", "carlo", "markov", "chain", "methods", ",", "large", "deviations", "theory", "has", "been", "given", "many", "extensions", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "large deviations theory", "start": 166, "end": 189, "i_start": 26, "i_end": 28}, "verb": {"text": "has been given", "start": 190, "end": 204, "i_start": 29, "i_end": 31}}, {"subject": {"text": "large deviations theory", "start": 166, "end": 189, "i_start": 26, "i_end": 28}, "verb": {"text": "is", "start": 85, "end": 87, "i_start": 12, "i_end": 12}}], "id": 415}, {"sent": "in the standard dft , the generalized gradi-ent approximation of perdew-burke-ernzerhof version is adopted to describe the electronic exchange-correlation interactions .", "tokens": ["in", "the", "standard", "dft", ",", "the", "generalized", "gradi", "-", "ent", "approximation", "of", "perdew", "-", "burke", "-", "ernzerhof", "version", "is", "adopted", "to", "describe", "the", "electronic", "exchange", "-", "correlation", "interactions", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalized gradi-ent approximation of perdew-burke-ernzerhof version", "start": 22, "end": 95, "i_start": 5, "i_end": 17}, "verb": {"text": "is adopted", "start": 96, "end": 106, "i_start": 18, "i_end": 19}}, {"character": {"text": "approximation", "start": 48, "end": 61, "i_start": 10, "i_end": 10}, "action": {"text": "describe", "start": 110, "end": 118, "i_start": 21, "i_end": 21}}], "id": 416}, {"sent": "in this paper we will work with the computational model introduced by karloff , suri , and vassilvitskii .", "tokens": ["in", "this", "paper", "we", "will", "work", "with", "the", "computational", "model", "introduced", "by", "karloff", ",", "suri", ",", "and", "vassilvitskii", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "will work", "start": 17, "end": 26, "i_start": 4, "i_end": 5}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "work", "start": 22, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "karloff", "start": 70, "end": 77, "i_start": 12, "i_end": 12}, "action": {"text": "introduced", "start": 56, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "suri", "start": 80, "end": 84, "i_start": 14, "i_end": 14}, "action": {"text": "introduced", "start": 56, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "vassilvitskii", "start": 91, "end": 104, "i_start": 17, "i_end": 17}, "action": {"text": "introduced", "start": 56, "end": 66, "i_start": 10, "i_end": 10}}], "id": 417}, {"sent": "princeton university press , princeton , new jersey .", "tokens": ["princeton", "university", "press", ",", "princeton", ",", "new", "jersey", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 418}, {"sent": "huneke and sharp proved that if r is a regular ring which either contains a field or is unramified then hn i has only finitely many associated primes for any ideal i of r and any integer n .", "tokens": ["huneke", "and", "sharp", "proved", "that", "if", "r", "is", "a", "regular", "ring", "which", "either", "contains", "a", "field", "or", "is", "unramified", "then", "h"], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "huneke and sharp", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "proved", "start": 17, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "huneke", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "proved", "start": 17, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "sharp", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "proved", "start": 17, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "ring", "start": 47, "end": 51, "i_start": 10, "i_end": 10}, "action": {"text": "contains", "start": 65, "end": 73, "i_start": 13, "i_end": 13}}, {"subject": {"text": "i", "start": 2, "end": 3, "i_start": 1, "i_end": 1}, "verb": {"text": "has", "start": 4, "end": 7, "i_start": 2, "i_end": 2}}, {"character": {"text": "i", "start": 2, "end": 3, "i_start": 1, "i_end": 1}, "action": {"text": "has", "start": 4, "end": 7, "i_start": 2, "i_end": 2}}], "id": 419}, {"sent": "we have used hungarian method for matching our score matrix .", "tokens": ["we", "have", "used", "hungarian", "method", "for", "matching", "our", "score", "matrix", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have used", "start": 3, "end": 12, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "matching", "start": 34, "end": 42, "i_start": 6, "i_end": 6}}], "id": 420}, {"sent": "recently deep reinforcement learning has achieved very impressive results and beyond human performance on several complex long-horizon games such as alphago .", "tokens": ["recently", "deep", "reinforcement", "learning", "has", "achieved", "very", "impressive", "results", "and", "beyond", "human", "performance", "on", "several", "complex", "long", "-", "horizon", "games", "such", "as", "alphago", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep reinforcement learning", "start": 9, "end": 36, "i_start": 1, "i_end": 3}, "verb": {"text": "has achieved", "start": 37, "end": 49, "i_start": 4, "i_end": 5}}, {"character": {"text": "learning", "start": 28, "end": 36, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 41, "end": 49, "i_start": 5, "i_end": 5}}, {"character": {"text": "results", "start": 66, "end": 73, "i_start": 8, "i_end": 8}, "action": {"text": "impressive", "start": 55, "end": 65, "i_start": 7, "i_end": 7}}, {"character": {"text": "human", "start": 85, "end": 90, "i_start": 11, "i_end": 11}, "action": {"text": "performance", "start": 91, "end": 102, "i_start": 12, "i_end": 12}}], "id": 421}, {"sent": "deep convolutional neural networks have achieved great success in various computer vision tasks such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "various", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}], "id": 422}, {"sent": "c onvolutional neural networks have achieved state-of-the-art performance on various visual recognition tasks such as image classification .", "tokens": ["c", "onvolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "various", "visual", "recognition", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "c onvolutional neural networks", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 31, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 22, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "c onvolutional neural networks have achieved", "start": 0, "end": 44, "i_start": 0, "i_end": 5}}, {"character": {"text": "networks", "start": 22, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 62, "end": 73, "i_start": 13, "i_end": 13}}], "id": 423}, {"sent": "between these two regimes is the josephson regime , for which , in this regime , the density imbalance between the two internal states go through small oscillations , similar to the usual spatial josephson effect .", "tokens": ["between", "these", "two", "regimes", "is", "the", "josephson", "regime", ",", "for", "which", ",", "in", "this", "regime", ",", "the", "density", "imbalance", "between", "the", "two", "internal", "states", "go", "through", "small", "oscillations", ",", "similar", "to", "the", "usual", "spatial", "josephson", "effect", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "regimes", "start": 18, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "effect", "start": 206, "end": 212, "i_start": 35, "i_end": 35}}], "id": 424}, {"sent": "among these methods , the one that inspires us is , which adopted an em learning algorithm for training the model with image-level semantic labels .", "tokens": ["among", "these", "methods", ",", "the", "one", "that", "inspires", "us", "is", ",", "which", "adopted", "an", "em", "learning", "algorithm", "for", "training", "the", "model", "with", "image", "-", "level", "semantic", "labels", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the one that inspires us", "start": 22, "end": 46, "i_start": 4, "i_end": 8}, "verb": {"text": "is", "start": 47, "end": 49, "i_start": 9, "i_end": 9}}, {"subject": {"text": "which", "start": 52, "end": 57, "i_start": 11, "i_end": 11}, "verb": {"text": "adopted", "start": 58, "end": 65, "i_start": 12, "i_end": 12}}, {"character": {"text": "one", "start": 26, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "inspires", "start": 35, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "methods", "start": 12, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "adopted", "start": 58, "end": 65, "i_start": 12, "i_end": 12}}], "id": 425}, {"sent": "in constrast , a constant approximation is given in , but only when there are a constant number of different time windows .", "tokens": ["in", "constrast", ",", "a", "constant", "approximation", "is", "given", "in", ",", "but", "only", "when", "there", "are", "a", "constant", "number", "of", "different", "time", "windows", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a constant approximation", "start": 15, "end": 39, "i_start": 3, "i_end": 5}, "verb": {"text": "is given in", "start": 40, "end": 51, "i_start": 6, "i_end": 8}}, {"subject": {"text": "there", "start": 68, "end": 73, "i_start": 13, "i_end": 13}, "verb": {"text": "are", "start": 74, "end": 77, "i_start": 14, "i_end": 14}}], "id": 426}, {"sent": "because the inflaton is expected to 15 consist of one of these moduli , the threshold correction changes the dependence of the inflationary energy on the inflaton vev , altering the slow-roll parameters and creating an eta problem .", "tokens": ["because", "the", "inflaton", "is", "expected", "to", "15", "consist", "of", "one", "of", "these", "moduli", ",", "the", "threshold", "correction", "changes", "the", "dependence", "of", "the", "inflationary", "energy", "on", "the", "inflaton", "vev", ",", "altering", "the", "slow", "-", "roll", "parameters", "and", "creating", "an", "eta", "problem", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the threshold correction", "start": 72, "end": 96, "i_start": 14, "i_end": 16}, "verb": {"text": "changes", "start": 97, "end": 104, "i_start": 17, "i_end": 17}}, {"character": {"text": "expected", "start": 24, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "because", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}], "id": 427}, {"sent": "one important advancement in recent times for learning graph-based data is graph convolution networks .", "tokens": ["one", "important", "advancement", "in", "recent", "times", "for", "learning", "graph", "-", "based", "data", "is", "graph", "convolution", "networks", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "one important advancement in recent times for learning graph-based data", "start": 0, "end": 71, "i_start": 0, "i_end": 11}, "verb": {"text": "is", "start": 72, "end": 74, "i_start": 12, "i_end": 12}}], "id": 428}, {"sent": "d eep convolutional neural networks have gained much popularity in recent years for vision-related applications since they were shown to achieve some of the highest accuracies in image classification tasks .", "tokens": ["d", "eep", "convolutional", "neural", "networks", "have", "gained", "much", "popularity", "in", "recent", "years", "for", "vision", "-", "related", "applications", "since", "they", "were", "shown", "to", "achieve", "some", "of", "the", "highest", "accuracies", "in", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "d eep convolutional neural networks", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "have gained", "start": 36, "end": 47, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 27, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "gained", "start": 41, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 27, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "achieve", "start": 137, "end": 144, "i_start": 22, "i_end": 22}}], "id": 429}, {"sent": "a detailed description of the atlas and cms detectors can be found elsewhere .", "tokens": ["a", "detailed", "description", "of", "the", "atlas", "and", "cms", "detectors", "can", "be", "found", "elsewhere", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a detailed description of the atlas and cms detectors", "start": 0, "end": 53, "i_start": 0, "i_end": 8}, "verb": {"text": "can be found", "start": 54, "end": 66, "i_start": 9, "i_end": 11}}], "id": 430}, {"sent": "in weng et al , the instantaneous energy was used to solve the label ambiguity problem and a two-speaker joint-decoder with speaker switching penalty was used to separate and trace speakers .", "tokens": ["in", "weng", "et", "al", ",", "the", "instantaneous", "energy", "was", "used", "to", "solve", "the", "label", "ambiguity", "problem", "and", "a", "two", "-", "speaker", "joint", "-", "decoder", "with", "speaker", "switching", "penalty", "was", "used", "to", "separate", "and", "trace", "speakers", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the instantaneous energy", "start": 16, "end": 40, "i_start": 5, "i_end": 7}, "verb": {"text": "was used", "start": 41, "end": 49, "i_start": 8, "i_end": 9}}, {"subject": {"text": "a two-speaker joint-decoder with speaker switching penalty", "start": 91, "end": 149, "i_start": 17, "i_end": 27}, "verb": {"text": "used", "start": 154, "end": 158, "i_start": 29, "i_end": 29}}, {"character": {"text": "energy", "start": 34, "end": 40, "i_start": 7, "i_end": 7}, "action": {"text": "solve", "start": 53, "end": 58, "i_start": 11, "i_end": 11}}], "id": 431}, {"sent": "the order of appearance of hyperons is different for these models and depends strongly on the corresponding interactions .", "tokens": ["the", "order", "of", "appearance", "of", "hyperons", "is", "different", "for", "these", "models", "and", "depends", "strongly", "on", "the", "corresponding", "interactions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the order of appearance of hyperons", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 36, "end": 38, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the order of appearance of hyperons", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "depends", "start": 70, "end": 77, "i_start": 12, "i_end": 12}}, {"character": {"text": "order", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "depends", "start": 70, "end": 77, "i_start": 12, "i_end": 12}}], "id": 432}, {"sent": "the impact of the proton pdf uncertainties on the signal efficiency is evaluated with the pdf4lhc prescription pdf sets .", "tokens": ["the", "impact", "of", "the", "proton", "pdf", "uncertainties", "on", "the", "signal", "efficiency", "is", "evaluated", "with", "the", "pdf4lhc", "prescription", "pdf", "sets", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the impact of the proton pdf uncertainties on the signal efficiency", "start": 0, "end": 67, "i_start": 0, "i_end": 10}, "verb": {"text": "is evaluated", "start": 68, "end": 80, "i_start": 11, "i_end": 12}}], "id": 433}, {"sent": "improving temporal joins using histograms .", "tokens": ["improving", "temporal", "joins", "using", "histograms", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 434}, {"sent": "adversarial examples to image-based deep neural networks have been thoroughly explored in the literature .", "tokens": ["adversarial", "examples", "to", "image", "-", "based", "deep", "neural", "networks", "have", "been", "thoroughly", "explored", "in", "the", "literature", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "adversarial examples to image-based deep neural networks", "start": 0, "end": 56, "i_start": 0, "i_end": 8}, "verb": {"text": "explored", "start": 78, "end": 86, "i_start": 12, "i_end": 12}}, {"subject": {"text": "adversarial examples to image-based deep neural networks", "start": 0, "end": 56, "i_start": 0, "i_end": 8}, "verb": {"text": "have been", "start": 57, "end": 66, "i_start": 9, "i_end": 10}}], "id": 435}, {"sent": "we adopt a gated recurrent unit rnn with a 100-d hidden state as our decoder .", "tokens": ["we", "adopt", "a", "gated", "recurrent", "unit", "rnn", "with", "a", "100", "-", "d", "hidden", "state", "as", "our", "decoder", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 436}, {"sent": "calibration and image deconvolution was carried out using the miriad package .", "tokens": ["calibration", "and", "image", "deconvolution", "was", "carried", "out", "using", "the", "miriad", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "calibration and image deconvolution", "start": 0, "end": 35, "i_start": 0, "i_end": 3}, "verb": {"text": "was carried out", "start": 36, "end": 51, "i_start": 4, "i_end": 6}}], "id": 437}, {"sent": "yennie , in hadronic interactions of electrons and photons , edited by j .", "tokens": ["yennie", ",", "in", "hadronic", "interactions", "of", "electrons", "and", "photons", ",", "edited", "by", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "electrons", "start": 37, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "interactions", "start": 21, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "yennie", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "edited", "start": 61, "end": 67, "i_start": 10, "i_end": 10}}], "id": 438}, {"sent": "for training the models , we utilize the adam optimizer with a linearly decaying learning rate over time .", "tokens": ["for", "training", "the", "models", ",", "we", "utilize", "the", "adam", "optimizer", "with", "a", "linearly", "decaying", "learning", "rate", "over", "time", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "verb": {"text": "utilize", "start": 29, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "utilize", "start": 29, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "training", "start": 4, "end": 12, "i_start": 1, "i_end": 1}}], "id": 439}, {"sent": "following the setting in , we use frame 601-1400 as the training data and the remaining 1200 frames as test data .", "tokens": ["following", "the", "setting", "in", ",", "we", "use", "frame", "601", "-", "1400", "as", "the", "training", "data", "and", "the", "remaining", "1200", "frames", "as", "test", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 27, "end": 29, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 30, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 27, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 30, "end": 33, "i_start": 6, "i_end": 6}}], "id": 440}, {"sent": "the exchange correlation energy was described by the generalized gradient approximation using the perdew-burke-ernzerhof functional .", "tokens": ["the", "exchange", "correlation", "energy", "was", "described", "by", "the", "generalized", "gradient", "approximation", "using", "the", "perdew", "-", "burke", "-", "ernzerhof", "functional", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the exchange correlation energy", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "was described", "start": 32, "end": 45, "i_start": 4, "i_end": 5}}, {"character": {"text": "approximation", "start": 74, "end": 87, "i_start": 10, "i_end": 10}, "action": {"text": "described", "start": 36, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "approximation", "start": 74, "end": 87, "i_start": 10, "i_end": 10}, "action": {"text": "using", "start": 88, "end": 93, "i_start": 11, "i_end": 11}}], "id": 441}, {"sent": "such a problem can be addressed using generalized polynomial chaos expansions .", "tokens": ["such", "a", "problem", "can", "be", "addressed", "using", "generalized", "polynomial", "chaos", "expansions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such a problem", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "can be addressed", "start": 15, "end": 31, "i_start": 3, "i_end": 5}}], "id": 442}, {"sent": "the low-rank approximation technique used in this work is based on cholesky factorization and rp .", "tokens": ["the", "low", "-", "rank", "approximation", "technique", "used", "in", "this", "work", "is", "based", "on", "cholesky", "factorization", "and", "rp", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the low-rank approximation technique used in this work", "start": 0, "end": 54, "i_start": 0, "i_end": 9}, "verb": {"text": "is based", "start": 55, "end": 63, "i_start": 10, "i_end": 11}}], "id": 443}, {"sent": "in , it was shown that a state surface associated with a homogeneous , adequate state is a fiber if and only if the reduced state graph is a tree .", "tokens": ["in", ",", "it", "was", "shown", "that", "a", "state", "surface", "associated", "with", "a", "homogeneous", ",", "adequate", "state", "is", "a", "fiber", "if", "and", "only", "if", "the", "reduced", "state", "graph", "is", "a", "tree", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "verb": {"text": "was shown", "start": 8, "end": 17, "i_start": 3, "i_end": 4}}, {"subject": {"text": "it", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 86, "end": 88, "i_start": 16, "i_end": 16}}], "id": 444}, {"sent": "shou et al proposed a segment-based 3d cnn framework for action localization , and showed superior performance over other methods when using c3d .", "tokens": ["shou", "et", "al", "proposed", "a", "segment", "-", "based", "3d", "cnn", "framework", "for", "action", "localization", ",", "and", "showed", "superior", "performance", "over", "other", "methods", "when", "using", "c3d", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "shou et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "shou et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 83, "end": 89, "i_start": 16, "i_end": 16}}, {"character": {"text": "shou", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "other", "start": 116, "end": 121, "i_start": 20, "i_end": 20}, "action": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}], "id": 445}, {"sent": "the electronic noise contribution has been again subtracted , but is shown explicitly .", "tokens": ["the", "electronic", "noise", "contribution", "has", "been", "again", "subtracted", ",", "but", "is", "shown", "explicitly", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electronic noise contribution", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "subtracted", "start": 49, "end": 59, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the electronic noise contribution", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "has been", "start": 34, "end": 42, "i_start": 4, "i_end": 5}}, {"subject": {"text": "the electronic noise contribution", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "shown", "start": 69, "end": 74, "i_start": 11, "i_end": 11}}], "id": 446}, {"sent": "deep neural networks have significantly improved the performance of diverse data mining and computer vision applications .", "tokens": ["deep", "neural", "networks", "have", "significantly", "improved", "the", "performance", "of", "diverse", "data", "mining", "and", "computer", "vision", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "applications", "start": 108, "end": 120, "i_start": 15, "i_end": 15}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 7, "i_end": 7}}, {"character": {"text": "diverse", "start": 68, "end": 75, "i_start": 9, "i_end": 9}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 7, "i_end": 7}}], "id": 447}, {"sent": "the neutralino is a majorana fermion , so it coincides with its own antiparticle , and it is a weak interacting particle .", "tokens": ["the", "neutralino", "is", "a", "majorana", "fermion", ",", "so", "it", "coincides", "with", "its", "own", "antiparticle", ",", "and", "it", "is", "a", "weak", "interacting", "particle", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the neutralino", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "it", "start": 42, "end": 44, "i_start": 8, "i_end": 8}, "verb": {"text": "coincides", "start": 45, "end": 54, "i_start": 9, "i_end": 9}}, {"character": {"text": "particle", "start": 112, "end": 120, "i_start": 21, "i_end": 21}, "action": {"text": "interacting", "start": 100, "end": 111, "i_start": 20, "i_end": 20}}], "id": 448}, {"sent": "u ltra-wideband technology , which can achieve very high data rate , is a promising short-range wireless communication technique .", "tokens": ["u", "ltra", "-", "wideband", "technology", ",", "which", "can", "achieve", "very", "high", "data", "rate", ",", "is", "a", "promising", "short", "-", "range", "wireless", "communication", "technique", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "u ltra-wideband technology", "start": 0, "end": 26, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 69, "end": 71, "i_start": 14, "i_end": 14}}, {"character": {"text": "technique", "start": 119, "end": 128, "i_start": 22, "i_end": 22}, "action": {"text": "promising", "start": 74, "end": 83, "i_start": 16, "i_end": 16}}, {"character": {"text": "technology", "start": 16, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "achieve", "start": 39, "end": 46, "i_start": 8, "i_end": 8}}], "id": 449}, {"sent": "we calculate the leading order evolution kernels for the evolution equations and derive the virtual photon fragmentation functions by solving the evolution equations numerically .", "tokens": ["we", "calculate", "the", "leading", "order", "evolution", "kernels", "for", "the", "evolution", "equations", "and", "derive", "the", "virtual", "photon", "fragmentation", "functions", "by", "solving", "the", "evolution", "equations", "numerically", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "calculate", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "derive", "start": 81, "end": 87, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "calculate", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "order", "start": 25, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "leading", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "derive", "start": 81, "end": 87, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "solving", "start": 134, "end": 141, "i_start": 19, "i_end": 19}}], "id": 450}, {"sent": "however , to derive the limits from bbn and cmbwe assume that brane effects did not change physics before the recombination epoch .", "tokens": ["however", ",", "to", "derive", "the", "limits", "from", "bbn", "and", "cmb"], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "brane effects", "start": 15, "end": 28, "i_start": 3, "i_end": 4}, "verb": {"text": "change", "start": 37, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "effects", "start": 21, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "not change", "start": 33, "end": 43, "i_start": 6, "i_end": 7}}], "id": 451}, {"sent": "we also implement static channel recommendation , the optimal homogeneous channel recommendation as benchmarks .", "tokens": ["we", "also", "implement", "static", "channel", "recommendation", ",", "the", "optimal", "homogeneous", "channel", "recommendation", "as", "benchmarks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implement", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implement", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}], "id": 452}, {"sent": "introducing skip-connections allows much deeper networks to be trained .", "tokens": ["introducing", "skip", "-", "connections", "allows", "much", "deeper", "networks", "to", "be", "trained", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "introducing skip-connections", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "allows", "start": 29, "end": 35, "i_start": 4, "i_end": 4}}, {"subject": {"text": "much deeper networks", "start": 36, "end": 56, "i_start": 5, "i_end": 7}, "verb": {"text": "trained", "start": 63, "end": 70, "i_start": 10, "i_end": 10}}, {"character": {"text": "introducing", "start": 0, "end": 11, "i_start": 0, "i_end": 0}, "action": {"text": "allows", "start": 29, "end": 35, "i_start": 4, "i_end": 4}}], "id": 453}, {"sent": "we can then get the effective action of this transverse graviton by keeping terms to the second order of \u03c6 in the gravity action .", "tokens": ["we", "can", "then", "get", "the", "effective", "action", "of", "this", "transverse", "graviton", "by", "keeping", "terms", "to", "the", "second", "order", "of", "\u03c6", "in", "the", "gravity", "action", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "get", "start": 12, "end": 15, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "can", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "get", "start": 12, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "keeping", "start": 68, "end": 75, "i_start": 12, "i_end": 12}}], "id": 454}, {"sent": "convolutional neural networks have become quintessential for solving a variety of computer vision tasks such as classification .", "tokens": ["convolutional", "neural", "networks", "have", "become", "quintessential", "for", "solving", "a", "variety", "of", "computer", "vision", "tasks", "such", "as", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have become", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "solving", "start": 61, "end": 68, "i_start": 7, "i_end": 7}}], "id": 455}, {"sent": "it is an isomorphism if it consists of isomorphism of modules only .", "tokens": ["it", "is", "an", "isomorphism", "if", "it", "consists", "of", "isomorphism", "of", "modules", "only", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}], "id": 456}, {"sent": "we use resnet-50 , pre-trained for imagenet classification , to encode the image input .", "tokens": ["we", "use", "resnet-50", ",", "pre", "-", "trained", "for", "imagenet", "classification", ",", "to", "encode", "the", "image", "input", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 457}, {"sent": "the perdew-burke-ernzerhof generalized gradient approximation is used to describe the exchange and correlation functional .", "tokens": ["the", "perdew", "-", "burke", "-", "ernzerhof", "generalized", "gradient", "approximation", "is", "used", "to", "describe", "the", "exchange", "and", "correlation", "functional", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the perdew-burke-ernzerhof generalized gradient approximation", "start": 0, "end": 61, "i_start": 0, "i_end": 8}, "verb": {"text": "is used", "start": 62, "end": 69, "i_start": 9, "i_end": 10}}, {"character": {"text": "approximation", "start": 48, "end": 61, "i_start": 8, "i_end": 8}, "action": {"text": "describe", "start": 73, "end": 81, "i_start": 12, "i_end": 12}}], "id": 458}, {"sent": "deep learning is widely used in machine learning for various tasks .", "tokens": ["deep", "learning", "is", "widely", "used", "in", "machine", "learning", "for", "various", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "used", "start": 24, "end": 28, "i_start": 4, "i_end": 4}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 459}, {"sent": "mcwilliam a , preston gw , sneden c , searle l .", "tokens": ["mcwilliam", "a", ",", "preston", "gw", ",", "sneden", "c", ",", "searle", "l", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 460}, {"sent": "celeba dataset contains 202,599 face images , each annotated with 40 boolean attributes .", "tokens": ["celeba", "dataset", "contains", "202,599", "face", "images", ",", "each", "annotated", "with", "40", "boolean", "attributes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "celeba dataset", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "contains", "start": 15, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "dataset", "start": 7, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "contains", "start": 15, "end": 23, "i_start": 2, "i_end": 2}}], "id": 461}, {"sent": "but quantum mechanics is a law of thought .", "tokens": ["but", "quantum", "mechanics", "is", "a", "law", "of", "thought", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum mechanics", "start": 4, "end": 21, "i_start": 1, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 462}, {"sent": "low density parity check codes or ldpc codes were discovered by gallager in 1962 .", "tokens": ["low", "density", "parity", "check", "codes", "or", "ldpc", "codes", "were", "discovered", "by", "gallager", "in", "1962", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "low density parity check codes or ldpc codes", "start": 0, "end": 44, "i_start": 0, "i_end": 7}, "verb": {"text": "were discovered", "start": 45, "end": 60, "i_start": 8, "i_end": 9}}, {"character": {"text": "gallager", "start": 64, "end": 72, "i_start": 11, "i_end": 11}, "action": {"text": "discovered", "start": 50, "end": 60, "i_start": 9, "i_end": 9}}], "id": 463}, {"sent": "the lhcb detector is a single-arm forward spectrometer covering the pseudorapidity range between 2 and 5 , designed for the study of particles containing b or c quarks .", "tokens": ["the", "lhcb", "detector", "is", "a", "single", "-", "arm", "forward", "spectrometer", "covering", "the", "pseudorapidity", "range", "between", "2", "and", "5", ",", "designed", "for", "the", "study", "of", "particles", "containing", "b", "or", "c", "quarks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lhcb detector", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "spectrometer", "start": 42, "end": 54, "i_start": 9, "i_end": 9}, "action": {"text": "covering", "start": 55, "end": 63, "i_start": 10, "i_end": 10}}, {"character": {"text": "particles", "start": 133, "end": 142, "i_start": 24, "i_end": 24}, "action": {"text": "containing", "start": 143, "end": 153, "i_start": 25, "i_end": 25}}], "id": 464}, {"sent": "the distribution of \u03c4 is the marginal of the measure component of a cp-chain .", "tokens": ["the", "distribution", "of", "\u03c4", "is", "the", "marginal", "of", "the", "measure", "component", "of", "a", "cp", "-", "chain", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the distribution of \u03c4", "start": 0, "end": 21, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "component", "start": 53, "end": 62, "i_start": 10, "i_end": 10}, "action": {"text": "measure", "start": 45, "end": 52, "i_start": 9, "i_end": 9}}], "id": 465}, {"sent": "li et al proved that for a multicast session , symbol-wise linear algebraic coding over a finite field is always sufficient .", "tokens": ["li", "et", "al", "proved", "that", "for", "a", "multicast", "session", ",", "symbol", "-", "wise", "linear", "algebraic", "coding", "over", "a", "finite", "field", "is", "always", "sufficient", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "li et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "proved", "start": 9, "end": 15, "i_start": 3, "i_end": 3}}, {"subject": {"text": "li et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 103, "end": 105, "i_start": 20, "i_end": 20}}, {"character": {"text": "li", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proved", "start": 9, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "coding", "start": 76, "end": 82, "i_start": 15, "i_end": 15}, "action": {"text": "sufficient", "start": 113, "end": 123, "i_start": 22, "i_end": 22}}], "id": 466}, {"sent": "presented aging pattern subspace method to construct a subspace for aging patterns as a chronological sequence of face images .", "tokens": ["presented", "aging", "pattern", "subspace", "method", "to", "construct", "a", "subspace", "for", "aging", "patterns", "as", "a", "chronological", "sequence", "of", "face", "images", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 467}, {"sent": "in any spacetime for any is a conjecture .", "tokens": ["in", "any", "spacetime", "for", "any", "is", "a", "conjecture", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 468}, {"sent": "on the other hand , there is a non-constructive approach of banaszczyk that provides a bound of ousing a different type of convex geometry arguments .", "tokens": ["on", "the", "other", "hand", ",", "there", "is", "a", "non", "-", "constructive", "approach", "of", "banaszczyk", "that", "provides", "a", "bound", "of", "ousing", "a", "different", "type", "of", "convex", "geometry", "arguments", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 20, "end": 25, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 6, "i_end": 6}}, {"character": {"text": "banaszczyk", "start": 60, "end": 70, "i_start": 13, "i_end": 13}, "action": {"text": "approach", "start": 48, "end": 56, "i_start": 11, "i_end": 11}}, {"character": {"text": "approach", "start": 48, "end": 56, "i_start": 11, "i_end": 11}, "action": {"text": "provides", "start": 76, "end": 84, "i_start": 15, "i_end": 15}}], "id": 469}, {"sent": "deep convolutional neural network based object detectors have become more and more developed and achieved great success in recent years , owing to the significant progress of network architecture such as vgg .", "tokens": ["deep", "convolutional", "neural", "network", "based", "object", "detectors", "have", "become", "more", "and", "more", "developed", "and", "achieved", "great", "success", "in", "recent", "years", ",", "owing", "to", "the", "significant", "progress", "of", "network", "architecture", "such", "as", "vgg", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural network based object detectors", "start": 0, "end": 56, "i_start": 0, "i_end": 6}, "verb": {"text": "have become", "start": 57, "end": 68, "i_start": 7, "i_end": 8}}], "id": 470}, {"sent": "gradual typing allows developers to evolve their programs from the dynamic to the typed discipline , gradually .", "tokens": ["gradual", "typing", "allows", "developers", "to", "evolve", "their", "programs", "from", "the", "dynamic", "to", "the", "typed", "discipline", ",", "gradually", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "gradual typing", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "allows", "start": 15, "end": 21, "i_start": 2, "i_end": 2}}, {"subject": {"text": "developers", "start": 22, "end": 32, "i_start": 3, "i_end": 3}, "verb": {"text": "evolve", "start": 36, "end": 42, "i_start": 5, "i_end": 5}}, {"character": {"text": "typed", "start": 82, "end": 87, "i_start": 13, "i_end": 13}, "action": {"text": "allows", "start": 15, "end": 21, "i_start": 2, "i_end": 2}}], "id": 471}, {"sent": "the target space is the kk-melvin times the base space p1 of the k3 , and the modulus of the fiber corresponds to the linear combination of the dilaton and the r-r 0-form at each point of the base space .", "tokens": ["the", "target", "space", "is", "the", "kk", "-", "melvin", "times", "the", "base", "space", "p1", "of", "the", "k3", ",", "and", "the", "modulus", "of", "the", "fiber", "corresponds", "to", "the", "linear", "combination", "of", "the", "dilaton", "and", "the", "r", "-", "r", "0", "-", "form", "at", "each", "point", "of", "the", "base", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the target space", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the modulus of the fiber", "start": 74, "end": 98, "i_start": 18, "i_end": 22}, "verb": {"text": "corresponds", "start": 99, "end": 110, "i_start": 23, "i_end": 23}}], "id": 472}, {"sent": "rather than the volatility because it is a stationary quantity that provides a more fundamental description of the volatility process .", "tokens": ["rather", "than", "the", "volatility", "because", "it", "is", "a", "stationary", "quantity", "that", "provides", "a", "more", "fundamental", "description", "of", "the", "volatility", "process", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "stationary", "start": 43, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "because", "start": 27, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "quantity", "start": 54, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "provides", "start": 68, "end": 76, "i_start": 11, "i_end": 11}}, {"character": {"text": "quantity", "start": 54, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "description", "start": 96, "end": 107, "i_start": 15, "i_end": 15}}], "id": 473}, {"sent": "for explicit , implicit euler and compact finite difference schemes , see for example .", "tokens": ["for", "explicit", ",", "implicit", "euler", "and", "compact", "finite", "difference", "schemes", ",", "see", "for", "example", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 474}, {"sent": "theoretical analyses of this algorithm have been the subject of various studies .", "tokens": ["theoretical", "analyses", "of", "this", "algorithm", "have", "been", "the", "subject", "of", "various", "studies", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "theoretical analyses of this algorithm", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "have been", "start": 39, "end": 48, "i_start": 5, "i_end": 6}}], "id": 475}, {"sent": "recently generative adversarial based frameworks have also been developed for learning robust latent representation .", "tokens": ["recently", "generative", "adversarial", "based", "frameworks", "have", "also", "been", "developed", "for", "learning", "robust", "latent", "representation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "recently generative adversarial based frameworks", "start": 0, "end": 48, "i_start": 0, "i_end": 4}, "verb": {"text": "been developed", "start": 59, "end": 73, "i_start": 7, "i_end": 8}}, {"subject": {"text": "recently generative adversarial based frameworks", "start": 0, "end": 48, "i_start": 0, "i_end": 4}, "verb": {"text": "have", "start": 49, "end": 53, "i_start": 5, "i_end": 5}}], "id": 476}, {"sent": "partially represented planar graphs can be extended in linear time .", "tokens": ["partially", "represented", "planar", "graphs", "can", "be", "extended", "in", "linear", "time", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "partially represented planar graphs", "start": 0, "end": 35, "i_start": 0, "i_end": 3}, "verb": {"text": "can be extended", "start": 36, "end": 51, "i_start": 4, "i_end": 6}}], "id": 477}, {"sent": "in the bulk case , correlation functions of local operators can be computed by the form factor approach .", "tokens": ["in", "the", "bulk", "case", ",", "correlation", "functions", "of", "local", "operators", "can", "be", "computed", "by", "the", "form", "factor", "approach", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "correlation functions of local operators", "start": 19, "end": 59, "i_start": 5, "i_end": 9}, "verb": {"text": "can be computed", "start": 60, "end": 75, "i_start": 10, "i_end": 12}}], "id": 478}, {"sent": "we apply a heuristic method that uses the parallel tempering monte carlo algorithm to speed up the thermalization .", "tokens": ["we", "apply", "a", "heuristic", "method", "that", "uses", "the", "parallel", "tempering", "monte", "carlo", "algorithm", "to", "speed", "up", "the", "thermalization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "apply", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "apply", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "method", "start": 21, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "uses", "start": 33, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "algorithm", "start": 73, "end": 82, "i_start": 12, "i_end": 12}, "action": {"text": "speed", "start": 86, "end": 91, "i_start": 14, "i_end": 14}}], "id": 479}, {"sent": "in the last two years , the performance of object detection has been significantly improved with the success of novel deep convolutional neural networks .", "tokens": ["in", "the", "last", "two", "years", ",", "the", "performance", "of", "object", "detection", "has", "been", "significantly", "improved", "with", "the", "success", "of", "novel", "deep", "convolutional", "neural", "networks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the performance of object detection", "start": 24, "end": 59, "i_start": 6, "i_end": 10}, "verb": {"text": "improved", "start": 83, "end": 91, "i_start": 14, "i_end": 14}}, {"subject": {"text": "the performance of object detection", "start": 24, "end": 59, "i_start": 6, "i_end": 10}, "verb": {"text": "has been", "start": 60, "end": 68, "i_start": 11, "i_end": 12}}, {"character": {"text": "success", "start": 101, "end": 108, "i_start": 17, "i_end": 17}, "action": {"text": "improved", "start": 83, "end": 91, "i_start": 14, "i_end": 14}}, {"character": {"text": "networks", "start": 144, "end": 152, "i_start": 23, "i_end": 23}, "action": {"text": "success", "start": 101, "end": 108, "i_start": 17, "i_end": 17}}], "id": 480}, {"sent": "in more detail , the fourier-images of electric and magnetic fields are considered as quantum mechanical observables of corresponding electric and magnetic field operators .", "tokens": ["in", "more", "detail", ",", "the", "fourier", "-", "images", "of", "electric", "and", "magnetic", "fields", "are", "considered", "as", "quantum", "mechanical", "observables", "of", "corresponding", "electric", "and", "magnetic", "field", "operators", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the fourier-images of electric and magnetic fields", "start": 17, "end": 67, "i_start": 4, "i_end": 12}, "verb": {"text": "are considered", "start": 68, "end": 82, "i_start": 13, "i_end": 14}}, {"character": {"text": "fields", "start": 61, "end": 67, "i_start": 12, "i_end": 12}, "action": {"text": "observables", "start": 105, "end": 116, "i_start": 18, "i_end": 18}}, {"character": {"text": "electric", "start": 39, "end": 47, "i_start": 9, "i_end": 9}, "action": {"text": "observables", "start": 105, "end": 116, "i_start": 18, "i_end": 18}}, {"character": {"text": "field", "start": 156, "end": 161, "i_start": 24, "i_end": 24}, "action": {"text": "observables", "start": 105, "end": 116, "i_start": 18, "i_end": 18}}, {"character": {"text": "magnetic", "start": 52, "end": 60, "i_start": 11, "i_end": 11}, "action": {"text": "observables", "start": 105, "end": 116, "i_start": 18, "i_end": 18}}], "id": 481}, {"sent": "for interpreting aging , we have proposed a novel aging theory , misrepair-accumulation theory .", "tokens": ["for", "interpreting", "aging", ",", "we", "have", "proposed", "a", "novel", "aging", "theory", ",", "misrepair", "-", "accumulation", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 25, "end": 27, "i_start": 4, "i_end": 4}, "verb": {"text": "have proposed", "start": 28, "end": 41, "i_start": 5, "i_end": 6}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "proposed", "start": 33, "end": 41, "i_start": 6, "i_end": 6}}], "id": 482}, {"sent": "zhang et al proposed ffdnet to make image denoising more flexible and effective .", "tokens": ["zhang", "et", "al", "proposed", "ffdnet", "to", "make", "image", "denoising", "more", "flexible", "and", "effective", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhang et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "denoising", "start": 42, "end": 51, "i_start": 8, "i_end": 8}, "action": {"text": "effective", "start": 70, "end": 79, "i_start": 12, "i_end": 12}}], "id": 483}, {"sent": "a landmark paper has shown that certain nonlinear binary codes with excellent error-correcting capabilities can be identified as images of linear codes over z 4 under the gray map .", "tokens": ["a", "landmark", "paper", "has", "shown", "that", "certain", "nonlinear", "binary", "codes", "with", "excellent", "error", "-", "correcting", "capabilities", "can", "be", "identified", "as", "images", "of", "linear", "codes", "over", "z", "4", "under", "the", "gray", "map", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a landmark paper", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "has shown", "start": 17, "end": 26, "i_start": 3, "i_end": 4}}, {"subject": {"text": "certain nonlinear binary codes with excellent error-correcting capabilities", "start": 32, "end": 107, "i_start": 6, "i_end": 15}, "verb": {"text": "identified", "start": 115, "end": 125, "i_start": 18, "i_end": 18}}, {"character": {"text": "paper", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 21, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "codes", "start": 57, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "has", "start": 17, "end": 20, "i_start": 3, "i_end": 3}}], "id": 484}, {"sent": "faghani and his collaborators modeled the propagation of xss worms in osns .", "tokens": ["faghani", "and", "his", "collaborators", "modeled", "the", "propagation", "of", "xss", "worms", "in", "osns", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "faghani and his collaborators", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "modeled", "start": 30, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "faghani", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "modeled", "start": 30, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "faghani", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "modeled", "start": 30, "end": 37, "i_start": 4, "i_end": 4}}], "id": 485}, {"sent": "the sandwich wave solutions considered here can all be reduced to their impulsive limits .", "tokens": ["the", "sandwich", "wave", "solutions", "considered", "here", "can", "all", "be", "reduced", "to", "their", "impulsive", "limits", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the sandwich wave solutions considered here can all", "start": 0, "end": 51, "i_start": 0, "i_end": 7}, "verb": {"text": "be reduced", "start": 52, "end": 62, "i_start": 8, "i_end": 9}}, {"subject": {"text": "the sandwich wave solutions considered here can all", "start": 0, "end": 51, "i_start": 0, "i_end": 7}, "verb": {"text": "can", "start": 44, "end": 47, "i_start": 6, "i_end": 6}}], "id": 486}, {"sent": "convolutional neural networks have achieved the state-of-the-art performance in many applications such as computer vision .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "many", "applications", "such", "as", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 65, "end": 76, "i_start": 13, "i_end": 13}}], "id": 487}, {"sent": "model-free reinforcement learning is a learning paradigm which aims to maximize a cumulative reward signal based on experience gathered through interaction with an environment .", "tokens": ["model", "-", "free", "reinforcement", "learning", "is", "a", "learning", "paradigm", "which", "aims", "to", "maximize", "a", "cumulative", "reward", "signal", "based", "on", "experience", "gathered", "through", "interaction", "with", "an", "environment", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "model-free reinforcement learning", "start": 0, "end": 33, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "paradigm", "start": 48, "end": 56, "i_start": 8, "i_end": 8}, "action": {"text": "aims", "start": 63, "end": 67, "i_start": 10, "i_end": 10}}, {"character": {"text": "interaction", "start": 144, "end": 155, "i_start": 22, "i_end": 22}, "action": {"text": "gathered", "start": 127, "end": 135, "i_start": 20, "i_end": 20}}], "id": 488}, {"sent": "deep neural networks have been adopted to improve the performance of state-of-the-arts on a wide variety of tasks in computer vision , including image classification .", "tokens": ["deep", "neural", "networks", "have", "been", "adopted", "to", "improve", "the", "performance", "of", "state", "-", "of", "-", "the", "-", "arts", "on", "a", "wide", "variety", "of", "tasks", "in", "computer", "vision", ",", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been adopted", "start": 21, "end": 38, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improve", "start": 42, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "state", "start": 69, "end": 74, "i_start": 11, "i_end": 11}, "action": {"text": "performance", "start": 54, "end": 65, "i_start": 9, "i_end": 9}}], "id": 489}, {"sent": "erez and zamir dealt with the issue of the finite power constraint using nested lattice codes , where a quantization-good lattice serves as the shaping lattice while the awgn-good lattice serves as the coding lattice .", "tokens": ["erez", "and", "zamir", "dealt", "with", "the", "issue", "of", "the", "finite", "power", "constraint", "using", "nested", "lattice", "codes", ",", "where", "a", "quantization", "-", "good", "lattice", "serves", "as", "the", "shaping", "lattice", "while", "the", "awgn", "-", "good", "lattice", "serves", "as", "the", "coding", "lattice", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "erez and zamir", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "dealt", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "erez", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "dealt", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "zamir", "start": 9, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "dealt", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "constraint", "start": 56, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "issue", "start": 30, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "lattice", "start": 122, "end": 129, "i_start": 22, "i_end": 22}, "action": {"text": "serves", "start": 130, "end": 136, "i_start": 23, "i_end": 23}}, {"character": {"text": "lattice", "start": 152, "end": 159, "i_start": 27, "i_end": 27}, "action": {"text": "serves", "start": 188, "end": 194, "i_start": 34, "i_end": 34}}], "id": 490}, {"sent": "the standard adam optimizer with the default parameters is employed to train our model for 80 epoches .", "tokens": ["the", "standard", "adam", "optimizer", "with", "the", "default", "parameters", "is", "employed", "to", "train", "our", "model", "for", "80", "epoches", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the standard adam optimizer with the default parameters", "start": 0, "end": 55, "i_start": 0, "i_end": 7}, "verb": {"text": "is employed", "start": 56, "end": 67, "i_start": 8, "i_end": 9}}, {"character": {"text": "optimizer", "start": 18, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "train", "start": 71, "end": 76, "i_start": 11, "i_end": 11}}], "id": 491}, {"sent": "since the quintessence is a dynamical scalar field , its amplitude may fluctuate which can become a new source of the cosmic density fluctuations and affects the cmb angular power spectrum .", "tokens": ["since", "the", "quintessence", "is", "a", "dynamical", "scalar", "field", ",", "its", "amplitude", "may", "fluctuate", "which", "can", "become", "a", "new", "source", "of", "the", "cosmic", "density", "fluctuations", "and", "affects", "the", "cmb", "angular", "power", "spectrum", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "its amplitude may fluctuate which can become a new source of the cosmic density fluctuations and affects the cmb angular power spectrum", "start": 53, "end": 188, "i_start": 9, "i_end": 30}, "verb": {"text": "may fluctuate", "start": 67, "end": 80, "i_start": 11, "i_end": 12}}, {"character": {"text": "amplitude", "start": 57, "end": 66, "i_start": 10, "i_end": 10}, "action": {"text": "source", "start": 104, "end": 110, "i_start": 18, "i_end": 18}}, {"character": {"text": "amplitude", "start": 57, "end": 66, "i_start": 10, "i_end": 10}, "action": {"text": "affects", "start": 150, "end": 157, "i_start": 25, "i_end": 25}}], "id": 492}, {"sent": "exchange and correlation were treated within the generalized gradient approximation using the parametrization of perdew , burke , and ernzerhof .", "tokens": ["exchange", "and", "correlation", "were", "treated", "within", "the", "generalized", "gradient", "approximation", "using", "the", "parametrization", "of", "perdew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "exchange and correlation", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "were treated", "start": 25, "end": 37, "i_start": 3, "i_end": 4}}], "id": 493}, {"sent": "in addition , the input object proposals are provided by selective search .", "tokens": ["in", "addition", ",", "the", "input", "object", "proposals", "are", "provided", "by", "selective", "search", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the input object proposals", "start": 14, "end": 40, "i_start": 3, "i_end": 6}, "verb": {"text": "are provided", "start": 41, "end": 53, "i_start": 7, "i_end": 8}}], "id": 494}, {"sent": "in this limit the positions of condensed counterions on the two polyions become strongly correlated .", "tokens": ["in", "this", "limit", "the", "positions", "of", "condensed", "counterions", "on", "the", "two", "polyions", "become", "strongly", "correlated", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the positions of condensed counterions on the two polyions", "start": 14, "end": 72, "i_start": 3, "i_end": 11}, "verb": {"text": "become", "start": 73, "end": 79, "i_start": 12, "i_end": 12}}], "id": 495}, {"sent": "like many previous researches , this paper compares the performance of its proposed method with other individual clustering methods and cluster ensemble methods by using standard data sets and their real classes .", "tokens": ["like", "many", "previous", "researches", ",", "this", "paper", "compares", "the", "performance", "of", "its", "proposed", "method", "with", "other", "individual", "clustering", "methods", "and", "cluster", "ensemble", "methods", "by", "using", "standard", "data", "sets", "and", "their", "real", "classes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this paper", "start": 32, "end": 42, "i_start": 5, "i_end": 6}, "verb": {"text": "compares", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "paper", "start": 37, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "compares", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "method", "start": 84, "end": 90, "i_start": 13, "i_end": 13}, "action": {"text": "performance", "start": 56, "end": 67, "i_start": 9, "i_end": 9}}, {"character": {"text": "paper", "start": 37, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "proposed", "start": 75, "end": 83, "i_start": 12, "i_end": 12}}, {"character": {"text": "paper", "start": 37, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "using", "start": 164, "end": 169, "i_start": 24, "i_end": 24}}], "id": 496}, {"sent": "the entanglement of formation is a well-defined and important measure of quantum entanglement for bipartite systems .", "tokens": ["the", "entanglement", "of", "formation", "is", "a", "well", "-", "defined", "and", "important", "measure", "of", "quantum", "entanglement", "for", "bipartite", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the entanglement of formation", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 4, "i_end": 4}}], "id": 497}, {"sent": "but the orbit through is a torus-knot which is not taut .", "tokens": ["but", "the", "orbit", "through", "is", "a", "torus", "-", "knot", "which", "is", "not", "taut", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the orbit through", "start": 4, "end": 21, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}], "id": 498}, {"sent": "the following result says that the set db detects q-equivalences .", "tokens": ["the", "following", "result", "says", "that", "the", "set", "db", "detects", "q", "-", "equivalences", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the following result", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "says", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the set db", "start": 31, "end": 41, "i_start": 5, "i_end": 7}, "verb": {"text": "detects", "start": 42, "end": 49, "i_start": 8, "i_end": 8}}, {"character": {"text": "set", "start": 35, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "detects", "start": 42, "end": 49, "i_start": 8, "i_end": 8}}], "id": 499}, {"sent": "ashkenazi , high-temperature superconductivity , edited by s .", "tokens": ["ashkenazi", ",", "high", "-", "temperature", "superconductivity", ",", "edited", "by", "s", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "ashkenazi", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "edited", "start": 49, "end": 55, "i_start": 7, "i_end": 7}}], "id": 500}, {"sent": "lewin , genes vii , oxford university press , oxford .", "tokens": ["lewin", ",", "genes", "vii", ",", "oxford", "university", "press", ",", "oxford", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 501}, {"sent": "the most striking feature in this figure is the difference between the low depth behavior of the models .", "tokens": ["the", "most", "striking", "feature", "in", "this", "figure", "is", "the", "difference", "between", "the", "low", "depth", "behavior", "of", "the", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most striking feature in this figure", "start": 0, "end": 40, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 41, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "difference", "start": 48, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "striking", "start": 9, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "models", "start": 97, "end": 103, "i_start": 17, "i_end": 17}, "action": {"text": "behavior", "start": 81, "end": 89, "i_start": 14, "i_end": 14}}], "id": 502}, {"sent": "gordon and ono proved that the number of partitions of n into distinct parts is divisible by 2 k for almost all n .", "tokens": ["gordon", "and", "ono", "proved", "that", "the", "number", "of", "partitions", "of", "n", "into", "distinct", "parts", "is", "divisible", "by", "2", "k", "for", "almost", "all", "n", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "gordon and ono", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "proved", "start": 15, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "gordon and ono", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 77, "end": 79, "i_start": 14, "i_end": 14}}, {"character": {"text": "gordon", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "proved", "start": 15, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "ono", "start": 11, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "proved", "start": 15, "end": 21, "i_start": 3, "i_end": 3}}], "id": 503}, {"sent": "in quantum mechanics p is the derivative and m the coordinate operator .", "tokens": ["in", "quantum", "mechanics", "p", "is", "the", "derivative", "and", "m", "the", "coordinate", "operator", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 504}, {"sent": "deep neural networks have given rise to major advancements in many problems of machine intelligence .", "tokens": ["deep", "neural", "networks", "have", "given", "rise", "to", "major", "advancements", "in", "many", "problems", "of", "machine", "intelligence", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have given", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "rise", "start": 32, "end": 36, "i_start": 5, "i_end": 5}}], "id": 505}, {"sent": "recently , deep neural networks have gained the attention of numerous researchers outperforming state-of-the-art approaches on various computer vision tasks .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "gained", "the", "attention", "of", "numerous", "researchers", "outperforming", "state", "-", "of", "-", "the", "-", "art", "approaches", "on", "various", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have gained", "start": 32, "end": 43, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "gained", "start": 37, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "numerous", "start": 61, "end": 69, "i_start": 10, "i_end": 10}, "action": {"text": "attention", "start": 48, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "outperforming", "start": 82, "end": 95, "i_start": 12, "i_end": 12}}], "id": 506}, {"sent": "we use a pre-trained model which is trained with imagenet-1k dataset , and then fine-tune the network .", "tokens": ["we", "use", "a", "pre", "-", "trained", "model", "which", "is", "trained", "with", "imagenet-1k", "dataset", ",", "and", "then", "fine", "-", "tune", "the", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "tune", "start": 85, "end": 89, "i_start": 18, "i_end": 18}}], "id": 507}, {"sent": "we should note that d-dbar annihilation has played an important role in recent proposals for generating a suitable inflationary potential in models for early universe superstring cosmology .", "tokens": ["we", "should", "note", "that", "d", "-", "dbar", "annihilation", "has", "played", "an", "important", "role", "in", "recent", "proposals", "for", "generating", "a", "suitable", "inflationary", "potential", "in", "models", "for", "early", "universe", "superstring", "cosmology", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "should note", "start": 3, "end": 14, "i_start": 1, "i_end": 2}}, {"subject": {"text": "d-dbar annihilation", "start": 20, "end": 39, "i_start": 4, "i_end": 7}, "verb": {"text": "played", "start": 44, "end": 50, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "note", "start": 10, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "annihilation", "start": 27, "end": 39, "i_start": 7, "i_end": 7}, "action": {"text": "played", "start": 44, "end": 50, "i_start": 9, "i_end": 9}}], "id": 508}, {"sent": "we also simulate a recent time-domain ba algorithm based on which focuses on estimating the instantaneous channel coefficients with an orthogonal matching pursuit technique .", "tokens": ["we", "also", "simulate", "a", "recent", "time", "-", "domain", "ba", "algorithm", "based", "on", "which", "focuses", "on", "estimating", "the", "instantaneous", "channel", "coefficients", "with", "an", "orthogonal", "matching", "pursuit", "technique", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "simulate", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "simulate", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}], "id": 509}, {"sent": "deep convolutional networks have swept the field of computer vision and have produced stellar results on various recognition benchmarks in the past several years .", "tokens": ["deep", "convolutional", "networks", "have", "swept", "the", "field", "of", "computer", "vision", "and", "have", "produced", "stellar", "results", "on", "various", "recognition", "benchmarks", "in", "the", "past", "several", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional networks", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "have swept", "start": 28, "end": 38, "i_start": 3, "i_end": 4}}, {"subject": {"text": "deep convolutional networks", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "produced", "start": 77, "end": 85, "i_start": 12, "i_end": 12}}, {"character": {"text": "networks", "start": 19, "end": 27, "i_start": 2, "i_end": 2}, "action": {"text": "swept", "start": 33, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 19, "end": 27, "i_start": 2, "i_end": 2}, "action": {"text": "produced", "start": 77, "end": 85, "i_start": 12, "i_end": 12}}], "id": 510}, {"sent": "the security aspects are dealt in which discuss the research challenges for security in cognitive networks .", "tokens": ["the", "security", "aspects", "are", "dealt", "in", "which", "discuss", "the", "research", "challenges", "for", "security", "in", "cognitive", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the security aspects", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are dealt", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "dealt", "start": 25, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "discuss", "start": 40, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "security", "start": 76, "end": 84, "i_start": 12, "i_end": 12}, "action": {"text": "challenges", "start": 61, "end": 71, "i_start": 10, "i_end": 10}}], "id": 511}, {"sent": "the 122zr isotope is the last stable nucleus against two neutron emission .", "tokens": ["the", "122zr", "isotope", "is", "the", "last", "stable", "nucleus", "against", "two", "neutron", "emission", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the 122zr isotope", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}], "id": 512}, {"sent": "this leads to the concept of frames , which was introduced by duffin and schaeffer in 1952 .", "tokens": ["this", "leads", "to", "the", "concept", "of", "frames", ",", "which", "was", "introduced", "by", "duffin", "and", "schaeffer", "in", "1952", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "leads", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "leads", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "duffin", "start": 62, "end": 68, "i_start": 12, "i_end": 12}, "action": {"text": "introduced", "start": 48, "end": 58, "i_start": 10, "i_end": 10}}, {"character": {"text": "schaeffer", "start": 73, "end": 82, "i_start": 14, "i_end": 14}, "action": {"text": "introduced", "start": 48, "end": 58, "i_start": 10, "i_end": 10}}], "id": 513}, {"sent": "deep neural networks have made great strides in many computer vision tasks such as image classification .", "tokens": ["deep", "neural", "networks", "have", "made", "great", "strides", "in", "many", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have made", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "strides", "start": 37, "end": 44, "i_start": 6, "i_end": 6}}], "id": 514}, {"sent": "since the flow of the condensate is a superflow , the condensate itself can not interact with the trap anisotropy .", "tokens": ["since", "the", "flow", "of", "the", "condensate", "is", "a", "superflow", ",", "the", "condensate", "itself", "can", "not", "interact", "with", "the", "trap", "anisotropy", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "the condensate itself", "start": 50, "end": 71, "i_start": 10, "i_end": 12}, "verb": {"text": "can not interact", "start": 72, "end": 88, "i_start": 13, "i_end": 15}}, {"character": {"text": "condensate", "start": 22, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "interact", "start": 80, "end": 88, "i_start": 15, "i_end": 15}}], "id": 515}, {"sent": "a finite volume scheme for a keller-segel model with an additional cross-diffusion term satisfying the energy-stablity property has been studied in .", "tokens": ["a", "finite", "volume", "scheme", "for", "a", "keller", "-", "segel", "model", "with", "an", "additional", "cross", "-", "diffusion", "term", "satisfying", "the", "energy", "-", "stablity", "property", "has", "been", "studied", "in", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "a finite volume scheme for a keller-segel model with an additional cross-diffusion term satisfying the energy-stablity property", "start": 0, "end": 127, "i_start": 0, "i_end": 22}, "verb": {"text": "has been studied", "start": 128, "end": 144, "i_start": 23, "i_end": 25}}, {"character": {"text": "term", "start": 83, "end": 87, "i_start": 16, "i_end": 16}, "action": {"text": "satisfying", "start": 88, "end": 98, "i_start": 17, "i_end": 17}}], "id": 516}, {"sent": "oxygen is a good referent to use with carbon and nitrogen to test for the presence of cno processed material .", "tokens": ["oxygen", "is", "a", "good", "referent", "to", "use", "with", "carbon", "and", "nitrogen", "to", "test", "for", "the", "presence", "of", "cno", "processed", "material", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "oxygen", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 7, "end": 9, "i_start": 1, "i_end": 1}}], "id": 517}, {"sent": "for these reasons , the so-called fine-grained uncertainty relations have been introduced .", "tokens": ["for", "these", "reasons", ",", "the", "so", "-", "called", "fine", "-", "grained", "uncertainty", "relations", "have", "been", "introduced", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the so-called fine-grained uncertainty relations", "start": 20, "end": 68, "i_start": 4, "i_end": 12}, "verb": {"text": "have been introduced", "start": 69, "end": 89, "i_start": 13, "i_end": 15}}], "id": 518}, {"sent": "the calculations of atomic geometry and band structure were performed based on the dft approach , as implemented in the vasp code .", "tokens": ["the", "calculations", "of", "atomic", "geometry", "and", "band", "structure", "were", "performed", "based", "on", "the", "dft", "approach", ",", "as", "implemented", "in", "the", "vasp", "code", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the calculations of atomic geometry and band structure", "start": 0, "end": 54, "i_start": 0, "i_end": 7}, "verb": {"text": "were performed", "start": 55, "end": 69, "i_start": 8, "i_end": 9}}, {"character": {"text": "code", "start": 125, "end": 129, "i_start": 21, "i_end": 21}, "action": {"text": "implemented", "start": 101, "end": 112, "i_start": 17, "i_end": 17}}], "id": 519}, {"sent": "we use a variant of lstm , where the input gate and the forget gate are coupled and peephole connections are used .", "tokens": ["we", "use", "a", "variant", "of", "lstm", ",", "where", "the", "input", "gate", "and", "the", "forget", "gate", "are", "coupled", "and", "peephole", "connections", "are", "used", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 520}, {"sent": "in , authors provide algorithms that permit repair of crashed servers , while implementing consistent storage .", "tokens": ["in", ",", "authors", "provide", "algorithms", "that", "permit", "repair", "of", "crashed", "servers", ",", "while", "implementing", "consistent", "storage", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "authors", "start": 5, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "provide", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithms", "start": 21, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "permit", "start": 37, "end": 43, "i_start": 6, "i_end": 6}}], "id": 521}, {"sent": "since the seminal papers of gross , the relations among various types of contractivity properties of linear semigroups on the one hand and functional inequalities satisfied by their generators on the other hand , have been intensively investigated .", "tokens": ["since", "the", "seminal", "papers", "of", "gross", ",", "the", "relations", "among", "various", "types", "of", "contractivity", "properties", "of", "linear", "semigroups", "on", "the", "one", "hand", "and", "functional", "inequalities", "satisfied", "by", "their", "generators", "on", "the", "other", "hand", ",", "have", "been", "intensively", "investigated", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the relations among various types of contractivity properties of linear semigroups on the one hand and functional inequalities satisfied by their generators on the other hand", "start": 36, "end": 210, "i_start": 7, "i_end": 32}, "verb": {"text": "investigated", "start": 235, "end": 247, "i_start": 37, "i_end": 37}}, {"subject": {"text": "the relations among various types of contractivity properties of linear semigroups on the one hand and functional inequalities satisfied by their generators on the other hand", "start": 36, "end": 210, "i_start": 7, "i_end": 32}, "verb": {"text": "have been", "start": 213, "end": 222, "i_start": 34, "i_end": 35}}], "id": 522}, {"sent": "a saddle connection is a finite length singular geodesic .", "tokens": ["a", "saddle", "connection", "is", "a", "finite", "length", "singular", "geodesic", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a saddle connection", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 523}, {"sent": "a composite system is a system which consists of two or more parts , and the simplest one is a system consisting of two qubits .", "tokens": ["a", "composite", "system", "is", "a", "system", "which", "consists", "of", "two", "or", "more", "parts", ",", "and", "the", "simplest", "one", "is", "a", "system", "consisting", "of", "two", "qubits", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a composite system", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 524}, {"sent": "the axion is a well-known hypothetical particle which is predicted by the pecceiquinn solution to the strong cp problem .", "tokens": ["the", "axion", "is", "a", "well", "-", "known", "hypothetical", "particle", "which", "is", "predicted", "by", "the", "pecceiquinn", "solution", "to", "the", "strong", "cp", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the axion", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}], "id": 525}, {"sent": "graphene is a two-dimensional honeycomb lattice of carbon atoms , with two nonequivalent sublattices .", "tokens": ["graphene", "is", "a", "two", "-", "dimensional", "honeycomb", "lattice", "of", "carbon", "atoms", ",", "with", "two", "nonequivalent", "sublattices", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "graphene", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}], "id": 526}, {"sent": "an introduction to pseudodifferential operators .", "tokens": ["an", "introduction", "to", "pseudodifferential", "operators", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 527}, {"sent": "therefore , the shock wave stalls without driving off the stellar mantle and envelope .", "tokens": ["therefore", ",", "the", "shock", "wave", "stalls", "without", "driving", "off", "the", "stellar", "mantle", "and", "envelope", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "wave", "start": 22, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "shock", "start": 16, "end": 21, "i_start": 3, "i_end": 3}}], "id": 528}, {"sent": "deep neural networks have recently achieved great success in computer vision , speech recognition , and natural language processing .", "tokens": ["deep", "neural", "networks", "have", "recently", "achieved", "great", "success", "in", "computer", "vision", ",", "speech", "recognition", ",", "and", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 50, "end": 57, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "recognition", "start": 86, "end": 97, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "processing", "start": 121, "end": 131, "i_start": 18, "i_end": 18}}], "id": 529}, {"sent": "leung et al have shown that adjusting the propagation strength of individual nodes can improve the performance of the label propagation method in certain networks .", "tokens": ["leung", "et", "al", "have", "shown", "that", "adjusting", "the", "propagation", "strength", "of", "individual", "nodes", "can", "improve", "the", "performance", "of", "the", "label", "propagation", "method", "in", "certain", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "leung et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 12, "end": 22, "i_start": 3, "i_end": 4}}, {"subject": {"text": "adjusting the propagation strength of individual nodes", "start": 28, "end": 82, "i_start": 6, "i_end": 12}, "verb": {"text": "improve", "start": 87, "end": 94, "i_start": 14, "i_end": 14}}, {"character": {"text": "adjusting", "start": 28, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "improve", "start": 87, "end": 94, "i_start": 14, "i_end": 14}}, {"character": {"text": "nodes", "start": 77, "end": 82, "i_start": 12, "i_end": 12}, "action": {"text": "propagation", "start": 42, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "method", "start": 136, "end": 142, "i_start": 21, "i_end": 21}, "action": {"text": "performance", "start": 99, "end": 110, "i_start": 16, "i_end": 16}}], "id": 530}, {"sent": "the proof is inspired by the elegant treatment of negahban et al .", "tokens": ["the", "proof", "is", "inspired", "by", "the", "elegant", "treatment", "of", "negahban", "et", "al", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the proof", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is inspired", "start": 10, "end": 21, "i_start": 2, "i_end": 3}}, {"character": {"text": "treatment", "start": 37, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "inspired", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}], "id": 531}, {"sent": "a filtering algorithm for constraints of difference in csps .", "tokens": ["a", "filtering", "algorithm", "for", "constraints", "of", "difference", "in", "csps", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "algorithm", "start": 12, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "filtering", "start": 2, "end": 11, "i_start": 1, "i_end": 1}}], "id": 532}, {"sent": "we also use the modularity-based louvain community detection algorithm to characterize the topology of the irn .", "tokens": ["we", "also", "use", "the", "modularity", "-", "based", "louvain", "community", "detection", "algorithm", "to", "characterize", "the", "topology", "of", "the", "irn", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "characterize", "start": 74, "end": 86, "i_start": 12, "i_end": 12}}], "id": 533}, {"sent": "in recent years , deep neural networks have achieved great success in a variety of machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "achieved", "great", "success", "in", "a", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}], "id": 534}, {"sent": "as a solution to mitigate the effect of error propagation , mf strategy has been proposed in for sic based mimo detection .", "tokens": ["as", "a", "solution", "to", "mitigate", "the", "effect", "of", "error", "propagation", ",", "mf", "strategy", "has", "been", "proposed", "in", "for", "sic", "based", "mimo", "detection", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "mf strategy", "start": 60, "end": 71, "i_start": 11, "i_end": 12}, "verb": {"text": "has been proposed", "start": 72, "end": 89, "i_start": 13, "i_end": 15}}], "id": 535}, {"sent": "the matter field content consists of chiral superfields a1 , a2 and n b1 , b2 in the u isometry of the einstein metric on t 1,1 .", "tokens": ["the", "matter", "field", "content", "consists", "of", "chiral", "superfields", "a1", ",", "a2", "and", "n", "b1", ",", "b2", "in", "the", "u", "isometry", "of", "the", "einstein", "metric", "on", "t", "1,1", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the matter field content", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "consists", "start": 25, "end": 33, "i_start": 4, "i_end": 4}}], "id": 536}, {"sent": "recently , deep neural networks have achieved remarkable progress in computer vision .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "achieved", "remarkable", "progress", "in", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have achieved", "start": 32, "end": 45, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}], "id": 537}, {"sent": "studies have shown that data representations obtained from stacking up nonlinear feature extractors often yield better machine classification results .", "tokens": ["studies", "have", "shown", "that", "data", "representations", "obtained", "from", "stacking", "up", "nonlinear", "feature", "extractors", "often", "yield", "better", "machine", "classification", "results", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "studies", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "have shown", "start": 8, "end": 18, "i_start": 1, "i_end": 2}}, {"subject": {"text": "data representations obtained from stacking up nonlinear feature extractors", "start": 24, "end": 99, "i_start": 4, "i_end": 12}, "verb": {"text": "yield", "start": 106, "end": 111, "i_start": 14, "i_end": 14}}, {"character": {"text": "studies", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "shown", "start": 13, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "representations", "start": 29, "end": 44, "i_start": 5, "i_end": 5}, "action": {"text": "yield", "start": 106, "end": 111, "i_start": 14, "i_end": 14}}], "id": 538}, {"sent": "thus , the phase space consists of pairs of fields with the symplectic structure .", "tokens": ["thus", ",", "the", "phase", "space", "consists", "of", "pairs", "of", "fields", "with", "the", "symplectic", "structure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the phase space", "start": 7, "end": 22, "i_start": 2, "i_end": 4}, "verb": {"text": "consists", "start": 23, "end": 31, "i_start": 5, "i_end": 5}}], "id": 539}, {"sent": "with the rapid growth of various types of multimedia data , approximate nearest neighbor search has received broad attention for fast information retrieval .", "tokens": ["with", "the", "rapid", "growth", "of", "various", "types", "of", "multimedia", "data", ",", "approximate", "nearest", "neighbor", "search", "has", "received", "broad", "attention", "for", "fast", "information", "retrieval", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "approximate nearest neighbor search", "start": 60, "end": 95, "i_start": 11, "i_end": 14}, "verb": {"text": "has received", "start": 96, "end": 108, "i_start": 15, "i_end": 16}}, {"character": {"text": "search", "start": 89, "end": 95, "i_start": 14, "i_end": 14}, "action": {"text": "received", "start": 100, "end": 108, "i_start": 16, "i_end": 16}}], "id": 540}, {"sent": "the images were reduced using the fors pipeline .", "tokens": ["the", "images", "were", "reduced", "using", "the", "fors", "pipeline", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the images", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "were reduced", "start": 11, "end": 23, "i_start": 2, "i_end": 3}}], "id": 541}, {"sent": "the other modification is a straightforward high-energy correction of the background quantities hand \u03c1 via the modified friedmann equations .", "tokens": ["the", "other", "modification", "is", "a", "straightforward", "high", "-", "energy", "correction", "of", "the", "background", "quantities", "h"], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the other modification", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}], "id": 542}, {"sent": "finally , we show analogous formulas for iterated l-values associated to hilbert cusp forms and for multiple dedekind zeta values .", "tokens": ["finally", ",", "we", "show", "analogous", "formulas", "for", "iterated", "l", "-", "values", "associated", "to", "hilbert", "cusp", "forms", "and", "for", "multiple", "dedekind", "zeta", "values", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "show", "start": 13, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 13, "end": 17, "i_start": 3, "i_end": 3}}], "id": 543}, {"sent": "more recently , convolutional neural networks have achieved unprecedented performance in a wide range of image classification problems .", "tokens": ["more", "recently", ",", "convolutional", "neural", "networks", "have", "achieved", "unprecedented", "performance", "in", "a", "wide", "range", "of", "image", "classification", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 74, "end": 85, "i_start": 9, "i_end": 9}}], "id": 544}, {"sent": "compressed sensing is the study of taking small representations or samples of sparse signals without any loss of information .", "tokens": ["compressed", "sensing", "is", "the", "study", "of", "taking", "small", "representations", "or", "samples", "of", "sparse", "signals", "without", "any", "loss", "of", "information", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "compressed sensing", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}], "id": 545}, {"sent": "another example is the shor algorithm , which is purely quantum-mechanical , but is solving the classical factoring problem .", "tokens": ["another", "example", "is", "the", "shor", "algorithm", ",", "which", "is", "purely", "quantum", "-", "mechanical", ",", "but", "is", "solving", "the", "classical", "factoring", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another example", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "algorithm", "start": 28, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "solving", "start": 84, "end": 91, "i_start": 16, "i_end": 16}}], "id": 546}, {"sent": "we follow the approach proposed in and formulate this task as a multi-label classification problem .", "tokens": ["we", "follow", "the", "approach", "proposed", "in", "and", "formulate", "this", "task", "as", "a", "multi", "-", "label", "classification", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "formulate", "start": 39, "end": 48, "i_start": 7, "i_end": 7}}], "id": 547}, {"sent": "recently , deep neural networks achieve excellent performance on difficult problems such as speech recognition .", "tokens": ["recently", ",", "deep", "neural", "networks", "achieve", "excellent", "performance", "on", "difficult", "problems", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "achieve", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "achieve", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "performance", "start": 50, "end": 61, "i_start": 7, "i_end": 7}}], "id": 548}, {"sent": "a bernstein-markov theorem for normed spaces .", "tokens": ["a", "bernstein", "-", "markov", "theorem", "for", "normed", "spaces", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 549}, {"sent": "s upervised object detection has made great progress in recent years .", "tokens": ["s", "upervised", "object", "detection", "has", "made", "great", "progress", "in", "recent", "years", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "s upervised object detection", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "has made", "start": 29, "end": 37, "i_start": 4, "i_end": 5}}], "id": 550}, {"sent": "deep learning based models have emerged as an extremely powerful framework to deal with different kinds of vision problems including image classification .", "tokens": ["deep", "learning", "based", "models", "have", "emerged", "as", "an", "extremely", "powerful", "framework", "to", "deal", "with", "different", "kinds", "of", "vision", "problems", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning based models", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "have emerged", "start": 27, "end": 39, "i_start": 4, "i_end": 5}}, {"character": {"text": "models", "start": 20, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "emerged", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}], "id": 551}, {"sent": "we implemented the proposed approach using the pytorch framework .", "tokens": ["we", "implemented", "the", "proposed", "approach", "using", "the", "pytorch", "framework", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implemented", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implemented", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 37, "end": 42, "i_start": 5, "i_end": 5}}], "id": 552}, {"sent": "the weights were initialized using the he uniform variance scaling initializer .", "tokens": ["the", "weights", "were", "initialized", "using", "the", "he", "uniform", "variance", "scaling", "initializer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the weights", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "were initialized", "start": 12, "end": 28, "i_start": 2, "i_end": 3}}], "id": 553}, {"sent": "nsamp is the number of samples , ie , sets of disorder realizations , nsweep is the total number of sweeps simulated for each of the 2nt replicas for a single sample , and nt is the number of temperatures used in the parallel tempering method .", "tokens": ["nsamp", "is", "the", "number", "of", "samples", ",", "ie", ",", "sets", "of", "disorder", "realizations", ",", "nsweep", "is", "the", "total", "number", "of", "sweeps", "simulated", "for", "each", "of", "the", "2nt", "replicas", "for", "a", "single", "sample", ",", "and", "nt", "is", "the", "number", "of", "temperatures", "used", "in", "the", "parallel", "tempering", "method", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "nsweep", "start": 70, "end": 76, "i_start": 14, "i_end": 14}, "verb": {"text": "is", "start": 77, "end": 79, "i_start": 15, "i_end": 15}}, {"subject": {"text": "nsweep", "start": 70, "end": 76, "i_start": 14, "i_end": 14}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "replicas", "start": 137, "end": 145, "i_start": 27, "i_end": 27}, "action": {"text": "simulated", "start": 107, "end": 116, "i_start": 21, "i_end": 21}}], "id": 554}, {"sent": "again , the rectangle is a is a fundamental domain for the action of z on ed induced by \u03b3 .", "tokens": ["again", ",", "the", "rectangle", "is", "a", "is", "a", "fundamental", "domain", "for", "the", "action", "of", "z", "on", "ed", "induced", "by", "\u03b3", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the rectangle", "start": 8, "end": 21, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}], "id": 555}, {"sent": "deep convolutional neural networks have made significant breakthroughs in many visual understanding tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "significant", "breakthroughs", "in", "many", "visual", "understanding", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "breakthroughs", "start": 57, "end": 70, "i_start": 7, "i_end": 7}}], "id": 556}, {"sent": "algorithms proposed in only focus on the detection of grasps in scenes where objects are densely cluttered , rather than what the grasped objects are .", "tokens": ["algorithms", "proposed", "in", "only", "focus", "on", "the", "detection", "of", "grasps", "in", "scenes", "where", "objects", "are", "densely", "cluttered", ",", "rather", "than", "what", "the", "grasped", "objects", "are", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "algorithms", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "focus", "start": 28, "end": 33, "i_start": 4, "i_end": 4}}], "id": 557}, {"sent": "convolutional neural networks have witnessed great improvement on a series of vision tasks such as object classification .", "tokens": ["convolutional", "neural", "networks", "have", "witnessed", "great", "improvement", "on", "a", "series", "of", "vision", "tasks", "such", "as", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have witnessed", "start": 30, "end": 44, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "witnessed", "start": 35, "end": 44, "i_start": 4, "i_end": 4}}], "id": 558}, {"sent": "for applications of variance reduction techniques to kinetic equation we mention the works of homolle and hadjiconstantinou .", "tokens": ["for", "applications", "of", "variance", "reduction", "techniques", "to", "kinetic", "equation", "we", "mention", "the", "works", "of", "homolle", "and", "hadjiconstantinou", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 70, "end": 72, "i_start": 9, "i_end": 9}, "action": {"text": "mention", "start": 73, "end": 80, "i_start": 10, "i_end": 10}}, {"character": {"text": "homolle", "start": 94, "end": 101, "i_start": 14, "i_end": 14}, "action": {"text": "works", "start": 85, "end": 90, "i_start": 12, "i_end": 12}}, {"character": {"text": "hadjiconstantinou", "start": 106, "end": 123, "i_start": 16, "i_end": 16}, "action": {"text": "works", "start": 85, "end": 90, "i_start": 12, "i_end": 12}}], "id": 559}, {"sent": "deep learning has achieved great success in various artificial intelligence applications such as object detection .", "tokens": ["deep", "learning", "has", "achieved", "great", "success", "in", "various", "artificial", "intelligence", "applications", "such", "as", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has achieved", "start": 14, "end": 26, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "achieved", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "success", "start": 33, "end": 40, "i_start": 5, "i_end": 5}}], "id": 560}, {"sent": "deep neural networks have made great strides in many computer vision tasks such as image classification .", "tokens": ["deep", "neural", "networks", "have", "made", "great", "strides", "in", "many", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have made", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "strides", "start": 37, "end": 44, "i_start": 6, "i_end": 6}}], "id": 561}, {"sent": "large-scale deep convolutional neural networks have been successfully applied to a wide variety of applications such as image classification .", "tokens": ["large", "-", "scale", "deep", "convolutional", "neural", "networks", "have", "been", "successfully", "applied", "to", "a", "wide", "variety", "of", "applications", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "large-scale deep convolutional neural networks", "start": 0, "end": 46, "i_start": 0, "i_end": 6}, "verb": {"text": "applied", "start": 70, "end": 77, "i_start": 10, "i_end": 10}}, {"subject": {"text": "large-scale deep convolutional neural networks", "start": 0, "end": 46, "i_start": 0, "i_end": 6}, "verb": {"text": "have been", "start": 47, "end": 56, "i_start": 7, "i_end": 8}}], "id": 562}, {"sent": "we must consider the convolution integrals of the partonic cross sections with the altarelli-parisi kernels at each order in the perturbative expansion .", "tokens": ["we", "must", "consider", "the", "convolution", "integrals", "of", "the", "partonic", "cross", "sections", "with", "the", "altarelli", "-", "parisi", "kernels", "at", "each", "order", "in", "the", "perturbative", "expansion", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "must consider", "start": 3, "end": 16, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "consider", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "sections", "start": 65, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "cross", "start": 59, "end": 64, "i_start": 9, "i_end": 9}}], "id": 563}, {"sent": "fourthly , the difference discrete symplectic structure preserving law holds in the function space associated with the difference discrete version of the closed euler-lagrange condition in general rather than in the solution space of the canonical equations only .", "tokens": ["fourthly", ",", "the", "difference", "discrete", "symplectic", "structure", "preserving", "law", "holds", "in", "the", "function", "space", "associated", "with", "the", "difference", "discrete", "version", "of", "the", "closed", "euler", "-", "lagrange", "condition", "in", "general", "rather", "than", "in", "the", "solution", "space", "of", "the", "canonical", "equations", "only", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the difference discrete symplectic structure preserving law", "start": 11, "end": 70, "i_start": 2, "i_end": 8}, "verb": {"text": "holds", "start": 71, "end": 76, "i_start": 9, "i_end": 9}}, {"character": {"text": "law", "start": 67, "end": 70, "i_start": 8, "i_end": 8}, "action": {"text": "holds", "start": 71, "end": 76, "i_start": 9, "i_end": 9}}, {"character": {"text": "law", "start": 67, "end": 70, "i_start": 8, "i_end": 8}, "action": {"text": "preserving", "start": 56, "end": 66, "i_start": 7, "i_end": 7}}], "id": 564}, {"sent": "matsuda et al used groups to design ionic liquids based on conductivity and viscosity targets .", "tokens": ["matsuda", "et", "al", "used", "groups", "to", "design", "ionic", "liquids", "based", "on", "conductivity", "and", "viscosity", "targets", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "matsuda et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 14, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "matsuda", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 14, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "matsuda", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "design", "start": 29, "end": 35, "i_start": 6, "i_end": 6}}], "id": 565}, {"sent": "the data were reduced using the surf and kappa software packages .", "tokens": ["the", "data", "were", "reduced", "using", "the", "surf", "and", "kappa", "software", "packages", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "were reduced", "start": 9, "end": 21, "i_start": 2, "i_end": 3}}], "id": 566}, {"sent": "deep learning has obviously improved the performance of many computer vision tasks such as classification .", "tokens": ["deep", "learning", "has", "obviously", "improved", "the", "performance", "of", "many", "computer", "vision", "tasks", "such", "as", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "improved", "start": 28, "end": 36, "i_start": 4, "i_end": 4}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has", "start": 14, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "improved", "start": 28, "end": 36, "i_start": 4, "i_end": 4}}], "id": 567}, {"sent": "in , zhu and ramanan proposed the fpll model that simultaneously performs face detection , pose estimation , and landmark localization .", "tokens": ["in", ",", "zhu", "and", "ramanan", "proposed", "the", "fpll", "model", "that", "simultaneously", "performs", "face", "detection", ",", "pose", "estimation", ",", "and", "landmark", "localization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhu and ramanan", "start": 5, "end": 20, "i_start": 2, "i_end": 4}, "verb": {"text": "proposed", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}, {"subject": {"text": "zhu and ramanan", "start": 5, "end": 20, "i_start": 2, "i_end": 4}, "verb": {"text": "pose", "start": 91, "end": 95, "i_start": 15, "i_end": 15}}, {"character": {"text": "zhu", "start": 5, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "proposed", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "ramanan", "start": 13, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "proposed", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "model", "start": 39, "end": 44, "i_start": 8, "i_end": 8}, "action": {"text": "performs", "start": 65, "end": 73, "i_start": 11, "i_end": 11}}], "id": 568}, {"sent": "deep convolutional neural networks have revolutionalized the field of computer vision , achieving the best performance in a multitude of tasks such as image classification etc .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "revolutionalized", "the", "field", "of", "computer", "vision", ",", "achieving", "the", "best", "performance", "in", "a", "multitude", "of", "tasks", "such", "as", "image", "classification", "etc", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have revolutionalized", "start": 35, "end": 56, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "revolutionalized", "start": 40, "end": 56, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieving", "start": 88, "end": 97, "i_start": 12, "i_end": 12}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 107, "end": 118, "i_start": 15, "i_end": 15}}], "id": 569}, {"sent": "deep convolutional neural networks have been successful in many computer vision tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successful", "in", "many", "computer", "vision", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "successful", "start": 45, "end": 55, "i_start": 6, "i_end": 6}}], "id": 570}, {"sent": "recently , the concept of simultaneous wireless information and power transfer has drawn considerable attention .", "tokens": ["recently", ",", "the", "concept", "of", "simultaneous", "wireless", "information", "and", "power", "transfer", "has", "drawn", "considerable", "attention", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the concept of simultaneous wireless information and power transfer", "start": 11, "end": 78, "i_start": 2, "i_end": 10}, "verb": {"text": "has drawn", "start": 79, "end": 88, "i_start": 11, "i_end": 12}}, {"character": {"text": "concept", "start": 15, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "drawn", "start": 83, "end": 88, "i_start": 12, "i_end": 12}}], "id": 571}, {"sent": "let us recall some definitions for quantized universal enveloping algebras taken from .", "tokens": ["let", "us", "recall", "some", "definitions", "for", "quantized", "universal", "enveloping", "algebras", "taken", "from", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "recall", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "recall", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}], "id": 572}, {"sent": "thus , the renormalization is the most important for 1d systems .", "tokens": ["thus", ",", "the", "renormalization", "is", "the", "most", "important", "for", "1d", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the renormalization", "start": 7, "end": 26, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 4, "i_end": 4}}], "id": 573}, {"sent": "arora et al interpret over-parametrization as a means of acceleration .", "tokens": ["arora", "et", "al", "interpret", "over", "-", "parametrization", "as", "a", "means", "of", "acceleration", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 6, "end": 11, "i_start": 1, "i_end": 2}, "verb": {"text": "interpret", "start": 12, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "arora", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "interpret", "start": 12, "end": 21, "i_start": 3, "i_end": 3}}], "id": 574}, {"sent": "kurakin et al found that deep learning systems might even make mistakes on printed photos of adversarial examples .", "tokens": ["kurakin", "et", "al", "found", "that", "deep", "learning", "systems", "might", "even", "make", "mistakes", "on", "printed", "photos", "of", "adversarial", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "kurakin et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "found", "start": 14, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "deep learning systems", "start": 25, "end": 46, "i_start": 5, "i_end": 7}, "verb": {"text": "make", "start": 58, "end": 62, "i_start": 10, "i_end": 10}}, {"character": {"text": "kurakin", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "found", "start": 14, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "systems", "start": 39, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "mistakes", "start": 63, "end": 71, "i_start": 11, "i_end": 11}}, {"character": {"text": "systems", "start": 39, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "learning", "start": 30, "end": 38, "i_start": 6, "i_end": 6}}], "id": 575}, {"sent": "wanda employs two antennas to authenticate the devices in proximity according to the large rss variations between the two antennas .", "tokens": ["wanda", "employs", "two", "antennas", "to", "authenticate", "the", "devices", "in", "proximity", "according", "to", "the", "large", "rss", "variations", "between", "the", "two", "antennas", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "wanda", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "employs", "start": 6, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "two antennas", "start": 14, "end": 26, "i_start": 2, "i_end": 3}, "action": {"text": "authenticate", "start": 30, "end": 42, "i_start": 5, "i_end": 5}}], "id": 576}, {"sent": "also , ba et al presented an attention-based model to recognize multiple objects in images .", "tokens": ["also", ",", "ba", "et", "al", "presented", "an", "attention", "-", "based", "model", "to", "recognize", "multiple", "objects", "in", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "ba et al", "start": 7, "end": 15, "i_start": 2, "i_end": 4}, "verb": {"text": "presented", "start": 16, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "ba", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "presented", "start": 16, "end": 25, "i_start": 5, "i_end": 5}}], "id": 577}, {"sent": "with very deep architecture design , convolutional neural networks have achieved impressive performance on classification .", "tokens": ["with", "very", "deep", "architecture", "design", ",", "convolutional", "neural", "networks", "have", "achieved", "impressive", "performance", "on", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 37, "end": 66, "i_start": 6, "i_end": 8}, "verb": {"text": "have achieved", "start": 67, "end": 80, "i_start": 9, "i_end": 10}}, {"character": {"text": "networks", "start": 58, "end": 66, "i_start": 8, "i_end": 8}, "action": {"text": "achieved", "start": 72, "end": 80, "i_start": 10, "i_end": 10}}, {"character": {"text": "networks", "start": 58, "end": 66, "i_start": 8, "i_end": 8}, "action": {"text": "performance", "start": 92, "end": 103, "i_start": 12, "i_end": 12}}, {"character": {"text": "networks", "start": 58, "end": 66, "i_start": 8, "i_end": 8}, "action": {"text": "classification", "start": 107, "end": 121, "i_start": 14, "i_end": 14}}, {"character": {"text": "performance", "start": 92, "end": 103, "i_start": 12, "i_end": 12}, "action": {"text": "impressive", "start": 81, "end": 91, "i_start": 11, "i_end": 11}}], "id": 578}, {"sent": "pfister , local moduli and singularities , lecture notes in mathematics , vol .", "tokens": ["pfister", ",", "local", "moduli", "and", "singularities", ",", "lecture", "notes", "in", "mathematics", ",", "vol", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 579}, {"sent": "in particular , we will relate the lgw and the nl\u03c3 descriptions showing explicitly that the stable fixed points of the two models are exactly the same , as conjectured in refs .", "tokens": ["in", "particular", ",", "we", "will", "relate", "the", "lgw", "and", "the", "nl\u03c3", "descriptions", "showing", "explicitly", "that", "the", "stable", "fixed", "points", "of", "the", "two", "models", "are", "exactly", "the", "same", ",", "as", "conjectured", "in", "refs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "will relate", "start": 19, "end": 30, "i_start": 4, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "relate", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "relate", "start": 24, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "showing", "start": 64, "end": 71, "i_start": 12, "i_end": 12}}], "id": 580}, {"sent": "rosenthal , string cosmology and the dimension of space-time , nucl .", "tokens": ["rosenthal", ",", "string", "cosmology", "and", "the", "dimension", "of", "space", "-", "time", ",", "nucl", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 581}, {"sent": "then , the meissner effect corresponds to a non-zero photon mass and is also known as the higgs mechanism .", "tokens": ["then", ",", "the", "meissner", "effect", "corresponds", "to", "a", "non", "-", "zero", "photon", "mass", "and", "is", "also", "known", "as", "the", "higgs", "mechanism", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the meissner effect", "start": 7, "end": 26, "i_start": 2, "i_end": 4}, "verb": {"text": "corresponds", "start": 27, "end": 38, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the meissner effect", "start": 7, "end": 26, "i_start": 2, "i_end": 4}, "verb": {"text": "known", "start": 77, "end": 82, "i_start": 16, "i_end": 16}}], "id": 582}, {"sent": "our method is evaluated on the challenging kitti tracking benchmark .", "tokens": ["our", "method", "is", "evaluated", "on", "the", "challenging", "kitti", "tracking", "benchmark", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our method", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is evaluated", "start": 11, "end": 23, "i_start": 2, "i_end": 3}}, {"character": {"text": "benchmark", "start": 58, "end": 67, "i_start": 9, "i_end": 9}, "action": {"text": "tracking", "start": 49, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "benchmark", "start": 58, "end": 67, "i_start": 9, "i_end": 9}, "action": {"text": "challenging", "start": 31, "end": 42, "i_start": 6, "i_end": 6}}], "id": 583}, {"sent": "contextual word representations have recently been used to achieve state-of-the-art performance across a range of language understanding tasks .", "tokens": ["contextual", "word", "representations", "have", "recently", "been", "used", "to", "achieve", "state", "-", "of", "-", "the", "-", "art", "performance", "across", "a", "range", "of", "language", "understanding", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "contextual word representations", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "been used", "start": 46, "end": 55, "i_start": 5, "i_end": 6}}, {"subject": {"text": "contextual word representations", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 32, "end": 36, "i_start": 3, "i_end": 3}}], "id": 584}, {"sent": "asterisks denote simulations where the number of particles are smaller than the number of stars .", "tokens": ["asterisks", "denote", "simulations", "where", "the", "number", "of", "particles", "are", "smaller", "than", "the", "number", "of", "stars", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "asterisks", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}], "id": 585}, {"sent": "the above optimization problem can be efficiently solved by the inexact augmented lagrange multipliers method .", "tokens": ["the", "above", "optimization", "problem", "can", "be", "efficiently", "solved", "by", "the", "inexact", "augmented", "lagrange", "multipliers", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the above optimization problem", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "solved", "start": 50, "end": 56, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the above optimization problem", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "can be", "start": 31, "end": 37, "i_start": 4, "i_end": 5}}], "id": 586}, {"sent": "in recent years , reinforcement learning has achieved great breakthrough in many domains including robot controlling and game playing .", "tokens": ["in", "recent", "years", ",", "reinforcement", "learning", "has", "achieved", "great", "breakthrough", "in", "many", "domains", "including", "robot", "controlling", "and", "game", "playing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 18, "end": 40, "i_start": 4, "i_end": 5}, "verb": {"text": "has achieved", "start": 41, "end": 53, "i_start": 6, "i_end": 7}}, {"character": {"text": "learning", "start": 32, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 45, "end": 53, "i_start": 7, "i_end": 7}}, {"character": {"text": "learning", "start": 32, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "breakthrough", "start": 60, "end": 72, "i_start": 9, "i_end": 9}}], "id": 587}, {"sent": "the rf algorithm was implemented in python using the scikit-learn implementation , .", "tokens": ["the", "rf", "algorithm", "was", "implemented", "in", "python", "using", "the", "scikit", "-", "learn", "implementation", ",", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the rf algorithm", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "was implemented", "start": 17, "end": 32, "i_start": 3, "i_end": 4}}], "id": 588}, {"sent": "bryant et al find that while novice editors contribute edits to articles related to their domain of expertise , expert editors contribute towards improving the quality of wikipedia itself .", "tokens": ["bryant", "et", "al", "find", "that", "while", "novice", "editors", "contribute", "edits", "to", "articles", "related", "to", "their", "domain", "of", "expertise", ",", "expert", "editors", "contribute", "towards", "improving", "the", "quality", "of", "wikipedia", "itself", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bryant et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "find", "start": 13, "end": 17, "i_start": 3, "i_end": 3}}, {"subject": {"text": "expert editors", "start": 112, "end": 126, "i_start": 19, "i_end": 20}, "verb": {"text": "contribute", "start": 127, "end": 137, "i_start": 21, "i_end": 21}}, {"character": {"text": "bryant", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 13, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "novice", "start": 29, "end": 35, "i_start": 6, "i_end": 6}, "action": {"text": "contribute", "start": 127, "end": 137, "i_start": 21, "i_end": 21}}], "id": 589}, {"sent": "we refer the reader to for various aspects of bv functions in euclidean space .", "tokens": ["we", "refer", "the", "reader", "to", "for", "various", "aspects", "of", "bv", "functions", "in", "euclidean", "space", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 590}, {"sent": "at this scale , the cross section is positive for all pt values .", "tokens": ["at", "this", "scale", ",", "the", "cross", "section", "is", "positive", "for", "all", "pt", "values", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the cross section", "start": 16, "end": 33, "i_start": 4, "i_end": 6}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 7, "i_end": 7}}, {"character": {"text": "section", "start": 26, "end": 33, "i_start": 6, "i_end": 6}, "action": {"text": "cross", "start": 20, "end": 25, "i_start": 5, "i_end": 5}}], "id": 591}, {"sent": "this measurement period is also a lower bound for on-chip ht detection using ros , which typically require longer measurement periods .", "tokens": ["this", "measurement", "period", "is", "also", "a", "lower", "bound", "for", "on", "-", "chip", "ht", "detection", "using", "ros", ",", "which", "typically", "require", "longer", "measurement", "periods", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this measurement period", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "detection", "start": 61, "end": 70, "i_start": 13, "i_end": 13}, "action": {"text": "require", "start": 99, "end": 106, "i_start": 19, "i_end": 19}}], "id": 592}, {"sent": "in recent years , neural-based conversation models have shown great power in building dialogue systems .", "tokens": ["in", "recent", "years", ",", "neural", "-", "based", "conversation", "models", "have", "shown", "great", "power", "in", "building", "dialogue", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural-based conversation models", "start": 18, "end": 50, "i_start": 4, "i_end": 8}, "verb": {"text": "have shown", "start": 51, "end": 61, "i_start": 9, "i_end": 10}}, {"character": {"text": "models", "start": 44, "end": 50, "i_start": 8, "i_end": 8}, "action": {"text": "shown", "start": 56, "end": 61, "i_start": 10, "i_end": 10}}], "id": 593}, {"sent": "convolutional neural networks have greatly advanced the state of the art in all those structured output tasks .", "tokens": ["convolutional", "neural", "networks", "have", "greatly", "advanced", "the", "state", "of", "the", "art", "in", "all", "those", "structured", "output", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "advanced", "start": 43, "end": 51, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "advanced", "start": 43, "end": 51, "i_start": 5, "i_end": 5}}], "id": 594}, {"sent": "the hash sort is expected to remain linear , even as the bubble sort and quick sort fall apart in their worst case scenarios .", "tokens": ["the", "hash", "sort", "is", "expected", "to", "remain", "linear", ",", "even", "as", "the", "bubble", "sort", "and", "quick", "sort", "fall", "apart", "in", "their", "worst", "case", "scenarios", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the hash sort", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is expected", "start": 14, "end": 25, "i_start": 3, "i_end": 4}}], "id": 595}, {"sent": "in this case one deals with the dijkgraaf-vafa matrix model in the large n limit .", "tokens": ["in", "this", "case", "one", "deals", "with", "the", "dijkgraaf", "-", "vafa", "matrix", "model", "in", "the", "large", "n", "limit", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 13, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "deals", "start": 17, "end": 22, "i_start": 4, "i_end": 4}}, {"character": {"text": "one", "start": 13, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "deals", "start": 17, "end": 22, "i_start": 4, "i_end": 4}}], "id": 596}, {"sent": "transversity is a chiral-odd distribution function , which implies that it is not observable in an inclusive measurement , because chirality is conserved in electromagnetic and strong interactions in the limit of massless on-shell quarks .", "tokens": ["transversity", "is", "a", "chiral", "-", "odd", "distribution", "function", ",", "which", "implies", "that", "it", "is", "not", "observable", "in", "an", "inclusive", "measurement", ",", "because", "chirality", "is", "conserved", "in", "electromagnetic", "and", "strong", "interactions", "in", "the", "limit", "of", "massless", "on", "-", "shell", "quarks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "transversity", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "transversity", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "action": {"text": "function", "start": 42, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "function", "start": 42, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "implies", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "conserved", "start": 144, "end": 153, "i_start": 24, "i_end": 24}, "action": {"text": "because", "start": 123, "end": 130, "i_start": 21, "i_end": 21}}, {"character": {"text": "electromagnetic", "start": 157, "end": 172, "i_start": 26, "i_end": 26}, "action": {"text": "conserved", "start": 144, "end": 153, "i_start": 24, "i_end": 24}}, {"character": {"text": "interactions", "start": 184, "end": 196, "i_start": 29, "i_end": 29}, "action": {"text": "conserved", "start": 144, "end": 153, "i_start": 24, "i_end": 24}}, {"character": {"text": "limit", "start": 204, "end": 209, "i_start": 32, "i_end": 32}, "action": {"text": "conserved", "start": 144, "end": 153, "i_start": 24, "i_end": 24}}, {"character": {"text": "not observable in an inclusive measurement , because chirality is conserved in electromagnetic and strong interactions in the limit of massless", "start": 78, "end": 221, "i_start": 14, "i_end": 34}, "action": {"text": "conserved", "start": 144, "end": 153, "i_start": 24, "i_end": 24}}, {"character": {"text": "shell", "start": 225, "end": 230, "i_start": 37, "i_end": 37}, "action": {"text": "conserved", "start": 144, "end": 153, "i_start": 24, "i_end": 24}}], "id": 597}, {"sent": "otherwise , the orbit contains only one element and is called a fixed orbit .", "tokens": ["otherwise", ",", "the", "orbit", "contains", "only", "one", "element", "and", "is", "called", "a", "fixed", "orbit", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the orbit", "start": 12, "end": 21, "i_start": 2, "i_end": 3}, "verb": {"text": "contains", "start": 22, "end": 30, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the orbit", "start": 12, "end": 21, "i_start": 2, "i_end": 3}, "verb": {"text": "called", "start": 55, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "orbit", "start": 16, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "contains", "start": 22, "end": 30, "i_start": 4, "i_end": 4}}], "id": 598}, {"sent": "here , the physics objects are the jets clustered using the jet finding algorithm with the tracks assigned to the vertex as inputs , and the associated missing transverse momentum , taken as the negative vector p t sum of those jets .", "tokens": ["here", ",", "the", "physics", "objects", "are", "the", "jets", "clustered", "using", "the", "jet", "finding", "algorithm", "with", "the", "tracks", "assigned", "to", "the", "vertex", "as", "inputs", ",", "and", "the", "associated", "missing", "transverse", "momentum", ",", "taken", "as", "the", "negative", "vector", "p", "t", "sum", "of", "those", "jets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the physics objects", "start": 7, "end": 26, "i_start": 2, "i_end": 4}, "verb": {"text": "are", "start": 27, "end": 30, "i_start": 5, "i_end": 5}}], "id": 599}, {"sent": "another direction is to study the generalization ability based on the norms of weight matrices in neural networks .", "tokens": ["another", "direction", "is", "to", "study", "the", "generalization", "ability", "based", "on", "the", "norms", "of", "weight", "matrices", "in", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another direction", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}], "id": 600}, {"sent": "to match the predicted sequence length to the reference sequence length for all comparisons , we use the dynamic time warping algorithm .", "tokens": ["to", "match", "the", "predicted", "sequence", "length", "to", "the", "reference", "sequence", "length", "for", "all", "comparisons", ",", "we", "use", "the", "dynamic", "time", "warping", "algorithm", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 94, "end": 96, "i_start": 15, "i_end": 15}, "verb": {"text": "use", "start": 97, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "we", "start": 94, "end": 96, "i_start": 15, "i_end": 15}, "action": {"text": "use", "start": 97, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "algorithm", "start": 126, "end": 135, "i_start": 21, "i_end": 21}, "action": {"text": "warping", "start": 118, "end": 125, "i_start": 20, "i_end": 20}}, {"character": {"text": "we", "start": 94, "end": 96, "i_start": 15, "i_end": 15}, "action": {"text": "match", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 601}, {"sent": "the formal synthesis problem can be solved using principles from model checking methods .", "tokens": ["the", "formal", "synthesis", "problem", "can", "be", "solved", "using", "principles", "from", "model", "checking", "methods", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the formal synthesis problem", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "can be solved", "start": 29, "end": 42, "i_start": 4, "i_end": 6}}], "id": 602}, {"sent": "a striking example of this is an incredibly successful observation of grb080319b that was led with russian-italian experiment tortora .", "tokens": ["a", "striking", "example", "of", "this", "is", "an", "incredibly", "successful", "observation", "of", "grb080319b", "that", "was", "led", "with", "russian", "-", "italian", "experiment", "tortora", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a striking example of this", "start": 0, "end": 26, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "tortora", "start": 126, "end": 133, "i_start": 20, "i_end": 20}, "action": {"text": "led", "start": 90, "end": 93, "i_start": 14, "i_end": 14}}], "id": 603}, {"sent": "the fast basin is the union of the boundaries of the tiles of a tiling of the plane by koch snowflakes and other related tiles .", "tokens": ["the", "fast", "basin", "is", "the", "union", "of", "the", "boundaries", "of", "the", "tiles", "of", "a", "tiling", "of", "the", "plane", "by", "koch", "snowflakes", "and", "other", "related", "tiles", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the fast basin", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}], "id": 604}, {"sent": "in proceedings of the fourth international conference on ai planning systems , pp .", "tokens": ["in", "proceedings", "of", "the", "fourth", "international", "conference", "on", "ai", "planning", "systems", ",", "pp", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 605}, {"sent": "the paper by hille and perling contains the first systematic study of full exceptional collections of line bundles on surfaces .", "tokens": ["the", "paper", "by", "hille", "and", "perling", "contains", "the", "first", "systematic", "study", "of", "full", "exceptional", "collections", "of", "line", "bundles", "on", "surfaces", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the paper by hille and perling", "start": 0, "end": 30, "i_start": 0, "i_end": 5}, "verb": {"text": "contains", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "paper", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "contains", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}], "id": 606}, {"sent": "convolutional neural networks have achieved state-of-the-art accuracy in computer vision tasks such as image recognition .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "accuracy", "in", "computer", "vision", "tasks", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 607}, {"sent": "polytope is a pyramid with rectangular base and apex v , whereas the set of two faces whose intersection is v .", "tokens": ["polytope", "is", "a", "pyramid", "with", "rectangular", "base", "and", "apex", "v", ",", "whereas", "the", "set", "of", "two", "faces", "whose", "intersection", "is", "v", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "polytope", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}], "id": 608}, {"sent": "in all our experiments we are using the vgg16 models for feature extraction .", "tokens": ["in", "all", "our", "experiments", "we", "are", "using", "the", "vgg16", "models", "for", "feature", "extraction", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "verb": {"text": "are using", "start": 26, "end": 35, "i_start": 5, "i_end": 6}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "using", "start": 30, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "extraction", "start": 65, "end": 75, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "experiments", "start": 11, "end": 22, "i_start": 3, "i_end": 3}}], "id": 609}, {"sent": "fang et al proposes a fr lf-iqa method to compute the gradient magnitude similarity between original and distorted epis .", "tokens": ["fang", "et", "al", "proposes", "a", "fr", "lf", "-", "iqa", "method", "to", "compute", "the", "gradient", "magnitude", "similarity", "between", "original", "and", "distorted", "epis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "fang et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "proposes", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "fang", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proposes", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}], "id": 610}, {"sent": "mountain , local conserved charges in principal chiral models , nucl .", "tokens": ["mountain", ",", "local", "conserved", "charges", "in", "principal", "chiral", "models", ",", "nucl", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 611}, {"sent": "the other two approaches are based on fuzzy grids with homogeneous fuzzy partitions of each attribute .", "tokens": ["the", "other", "two", "approaches", "are", "based", "on", "fuzzy", "grids", "with", "homogeneous", "fuzzy", "partitions", "of", "each", "attribute", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the other two approaches", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "are based", "start": 25, "end": 34, "i_start": 4, "i_end": 5}}], "id": 612}, {"sent": "data reduction was carried out within the image reduction and analysis facility software .", "tokens": ["data", "reduction", "was", "carried", "out", "within", "the", "image", "reduction", "and", "analysis", "facility", "software", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "data reduction", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "was carried out", "start": 15, "end": 30, "i_start": 2, "i_end": 4}}], "id": 613}, {"sent": "the mathematical details appear in appendix a .", "tokens": ["the", "mathematical", "details", "appear", "in", "appendix", "a", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the mathematical details", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "appear", "start": 25, "end": 31, "i_start": 3, "i_end": 3}}], "id": 614}, {"sent": "deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification among many others .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "already", "achieved", "tremendous", "success", "on", "a", "variety", "of", "computer", "vision", "tasks", "such", "as", "image", "classification", "among", "many", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "achieved", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 68, "end": 75, "i_start": 8, "i_end": 8}}], "id": 615}, {"sent": "game theory is a field that studies this and similar problems .", "tokens": ["game", "theory", "is", "a", "field", "that", "studies", "this", "and", "similar", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "game theory", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "field", "start": 17, "end": 22, "i_start": 4, "i_end": 4}, "action": {"text": "studies", "start": 28, "end": 35, "i_start": 6, "i_end": 6}}], "id": 616}, {"sent": "the data processing was done using the gildas software and casa .", "tokens": ["the", "data", "processing", "was", "done", "using", "the", "gildas", "software", "and", "casa", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data processing", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "was done", "start": 20, "end": 28, "i_start": 3, "i_end": 4}}], "id": 617}, {"sent": "the parameters of the first five convolution blocks are initialized from the vgg-16 net .", "tokens": ["the", "parameters", "of", "the", "first", "five", "convolution", "blocks", "are", "initialized", "from", "the", "vgg-16", "net", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the parameters of the first five convolution blocks", "start": 0, "end": 51, "i_start": 0, "i_end": 7}, "verb": {"text": "are initialized", "start": 52, "end": 67, "i_start": 8, "i_end": 9}}], "id": 618}, {"sent": "hinton et al proposed the concept of capsules as an effective method of learning representations .", "tokens": ["hinton", "et", "al", "proposed", "the", "concept", "of", "capsules", "as", "an", "effective", "method", "of", "learning", "representations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hinton et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "hinton", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "method", "start": 62, "end": 68, "i_start": 11, "i_end": 11}, "action": {"text": "effective", "start": 52, "end": 61, "i_start": 10, "i_end": 10}}], "id": 619}, {"sent": "composites of carbon black and pdms are widely used , see eg .", "tokens": ["composites", "of", "carbon", "black", "and", "pdms", "are", "widely", "used", ",", "see", "eg", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "composites of carbon black and pdms", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "used", "start": 47, "end": 51, "i_start": 8, "i_end": 8}}, {"subject": {"text": "composites of carbon black and pdms", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 36, "end": 39, "i_start": 6, "i_end": 6}}], "id": 620}, {"sent": "the effectiveness of the deep convolutional neural networks has been demonstrated for various computer vision tasks such as image classification and so on .", "tokens": ["the", "effectiveness", "of", "the", "deep", "convolutional", "neural", "networks", "has", "been", "demonstrated", "for", "various", "computer", "vision", "tasks", "such", "as", "image", "classification", "and", "so", "on", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the effectiveness of the deep convolutional neural networks", "start": 0, "end": 59, "i_start": 0, "i_end": 7}, "verb": {"text": "has been demonstrated", "start": 60, "end": 81, "i_start": 8, "i_end": 10}}, {"character": {"text": "networks", "start": 51, "end": 59, "i_start": 7, "i_end": 7}, "action": {"text": "effectiveness", "start": 4, "end": 17, "i_start": 1, "i_end": 1}}], "id": 621}, {"sent": "recently , the volume p n w of the negative part of the wigner function has been suggested as a good choice for quantifying the nonclassicality .", "tokens": ["recently", ",", "the", "volume", "p", "n", "w", "of", "the", "negative", "part", "of", "the", "wigner", "function", "has", "been", "suggested", "as", "a", "good", "choice", "for", "quantifying", "the", "nonclassicality", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the volume p n w of the negative part of the wigner function", "start": 11, "end": 71, "i_start": 2, "i_end": 14}, "verb": {"text": "has been suggested", "start": 72, "end": 90, "i_start": 15, "i_end": 17}}, {"character": {"text": "part", "start": 44, "end": 48, "i_start": 10, "i_end": 10}, "action": {"text": "negative", "start": 35, "end": 43, "i_start": 9, "i_end": 9}}], "id": 622}, {"sent": "based on this observation , he et al proposed resnet which reduced optimization difficulties by introducing shortcut connections .", "tokens": ["based", "on", "this", "observation", ",", "he", "et", "al", "proposed", "resnet", "which", "reduced", "optimization", "difficulties", "by", "introducing", "shortcut", "connections", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "he et al", "start": 28, "end": 36, "i_start": 5, "i_end": 7}, "verb": {"text": "proposed", "start": 37, "end": 45, "i_start": 8, "i_end": 8}}, {"character": {"text": "he", "start": 28, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "proposed", "start": 37, "end": 45, "i_start": 8, "i_end": 8}}, {"character": {"text": "resnet", "start": 46, "end": 52, "i_start": 9, "i_end": 9}, "action": {"text": "reduced", "start": 59, "end": 66, "i_start": 11, "i_end": 11}}, {"character": {"text": "he", "start": 28, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "introducing", "start": 96, "end": 107, "i_start": 15, "i_end": 15}}], "id": 623}, {"sent": "thus , pan et al propose the l 0 -regularized prior on both image intensity and gradients for deblurring text images .", "tokens": ["thus", ",", "pan", "et", "al", "propose", "the", "l", "0", "-regularized", "prior", "on", "both", "image", "intensity", "and", "gradients", "for", "deblurring", "text", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "pan et al", "start": 7, "end": 16, "i_start": 2, "i_end": 4}, "verb": {"text": "propose", "start": 17, "end": 24, "i_start": 5, "i_end": 5}}, {"character": {"text": "pan", "start": 7, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "propose", "start": 17, "end": 24, "i_start": 5, "i_end": 5}}], "id": 624}, {"sent": "most recent works on da consider deep architectures and robust domain-invariant features are learned using either supervised neural networks .", "tokens": ["most", "recent", "works", "on", "da", "consider", "deep", "architectures", "and", "robust", "domain", "-", "invariant", "features", "are", "learned", "using", "either", "supervised", "neural", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "most recent works on da", "start": 0, "end": 23, "i_start": 0, "i_end": 4}, "verb": {"text": "consider", "start": 24, "end": 32, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep architectures and robust domain-invariant features", "start": 33, "end": 88, "i_start": 6, "i_end": 13}, "verb": {"text": "learned", "start": 93, "end": 100, "i_start": 15, "i_end": 15}}, {"character": {"text": "works", "start": 12, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "consider", "start": 24, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "features", "start": 80, "end": 88, "i_start": 13, "i_end": 13}, "action": {"text": "invariant", "start": 70, "end": 79, "i_start": 12, "i_end": 12}}], "id": 625}, {"sent": "the study of iterated brownian motion has been stimulated by the analysis of diffusions in cracks .", "tokens": ["the", "study", "of", "iterated", "brownian", "motion", "has", "been", "stimulated", "by", "the", "analysis", "of", "diffusions", "in", "cracks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the study of iterated brownian motion", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "has been stimulated", "start": 38, "end": 57, "i_start": 6, "i_end": 8}}, {"character": {"text": "analysis", "start": 65, "end": 73, "i_start": 11, "i_end": 11}, "action": {"text": "stimulated", "start": 47, "end": 57, "i_start": 8, "i_end": 8}}], "id": 626}, {"sent": "honeywell has faced this problem and uses the pvs theorem prover to analyze the deos scheduler .", "tokens": ["honeywell", "has", "faced", "this", "problem", "and", "uses", "the", "pvs", "theorem", "prover", "to", "analyze", "the", "deos", "scheduler", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "honeywell", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "has faced", "start": 10, "end": 19, "i_start": 1, "i_end": 2}}, {"subject": {"text": "honeywell", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "uses", "start": 37, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "honeywell", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "faced", "start": 14, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "honeywell", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "uses", "start": 37, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "honeywell", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "analyze", "start": 68, "end": 75, "i_start": 12, "i_end": 12}}], "id": 627}, {"sent": "such evaluation approach is regularly adopted by the relevant literature , and we also follow the same .", "tokens": ["such", "evaluation", "approach", "is", "regularly", "adopted", "by", "the", "relevant", "literature", ",", "and", "we", "also", "follow", "the", "same", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 79, "end": 81, "i_start": 12, "i_end": 12}, "verb": {"text": "adopted", "start": 38, "end": 45, "i_start": 5, "i_end": 5}}, {"subject": {"text": "such evaluation approach", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 3, "i_end": 3}}, {"subject": {"text": "such evaluation approach", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "follow", "start": 87, "end": 93, "i_start": 14, "i_end": 14}}, {"character": {"text": "literature", "start": 62, "end": 72, "i_start": 9, "i_end": 9}, "action": {"text": "adopted", "start": 38, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 79, "end": 81, "i_start": 12, "i_end": 12}, "action": {"text": "follow", "start": 87, "end": 93, "i_start": 14, "i_end": 14}}], "id": 628}, {"sent": "a widely used approach for the latter problem is the expectationmaximization algorithm .", "tokens": ["a", "widely", "used", "approach", "for", "the", "latter", "problem", "is", "the", "expectationmaximization", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a widely used approach for the latter problem", "start": 0, "end": 45, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 46, "end": 48, "i_start": 8, "i_end": 8}}], "id": 629}, {"sent": "numerical simulations show that the perturbation can effectively eliminate the spiral waves corresponding to ventricular tachycardia and turbulent states corresponding to fibrillation in the heart .", "tokens": ["numerical", "simulations", "show", "that", "the", "perturbation", "can", "effectively", "eliminate", "the", "spiral", "waves", "corresponding", "to", "ventricular", "tachycardia", "and", "turbulent", "states", "corresponding", "to", "fibrillation", "in", "the", "heart", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "numerical simulations", "start": 0, "end": 21, "i_start": 0, "i_end": 1}, "verb": {"text": "show", "start": 22, "end": 26, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the perturbation", "start": 32, "end": 48, "i_start": 4, "i_end": 5}, "verb": {"text": "eliminate", "start": 65, "end": 74, "i_start": 8, "i_end": 8}}, {"character": {"text": "simulations", "start": 10, "end": 21, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 22, "end": 26, "i_start": 2, "i_end": 2}}, {"character": {"text": "perturbation", "start": 36, "end": 48, "i_start": 5, "i_end": 5}, "action": {"text": "eliminate", "start": 65, "end": 74, "i_start": 8, "i_end": 8}}], "id": 630}, {"sent": "our approach is based on sequence-to-sequence learning .", "tokens": ["our", "approach", "is", "based", "on", "sequence", "-", "to", "-", "sequence", "learning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our approach", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is based", "start": 13, "end": 21, "i_start": 2, "i_end": 3}}], "id": 631}, {"sent": "in practice , we use levenberg-marquardt algorithm for its larger convergence domain .", "tokens": ["in", "practice", ",", "we", "use", "levenberg", "-", "marquardt", "algorithm", "for", "its", "larger", "convergence", "domain", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "use", "start": 17, "end": 20, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 17, "end": 20, "i_start": 4, "i_end": 4}}], "id": 632}, {"sent": "a small flare occurred at the beginning of the rgs observation .", "tokens": ["a", "small", "flare", "occurred", "at", "the", "beginning", "of", "the", "rgs", "observation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a small flare", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "occurred", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}], "id": 633}, {"sent": "the parameter region in which the system is satisfactorily stable can be obtained from the routh-hurwitz criteria .", "tokens": ["the", "parameter", "region", "in", "which", "the", "system", "is", "satisfactorily", "stable", "can", "be", "obtained", "from", "the", "routh", "-", "hurwitz", "criteria", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the parameter region in which the system is satisfactorily stable", "start": 0, "end": 65, "i_start": 0, "i_end": 9}, "verb": {"text": "can be obtained", "start": 66, "end": 81, "i_start": 10, "i_end": 12}}, {"character": {"text": "stable", "start": 59, "end": 65, "i_start": 9, "i_end": 9}, "action": {"text": "satisfactorily", "start": 44, "end": 58, "i_start": 8, "i_end": 8}}], "id": 634}, {"sent": "note that we assume all probabilities are stationary in time .", "tokens": ["note", "that", "we", "assume", "all", "probabilities", "are", "stationary", "in", "time", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "assume", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "assume", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}], "id": 635}, {"sent": "results for random forest are obtained with the implementation of the scikit-learn package .", "tokens": ["results", "for", "random", "forest", "are", "obtained", "with", "the", "implementation", "of", "the", "scikit", "-", "learn", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "results for random forest", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "are obtained", "start": 26, "end": 38, "i_start": 4, "i_end": 5}}], "id": 636}, {"sent": "for almost all \u03b3-energies multiplicity 2 is the most abundant .", "tokens": ["for", "almost", "all", "\u03b3", "-", "energies", "multiplicity", "2", "is", "the", "most", "abundant", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 637}, {"sent": "first let us consider the solution for the zero mode in the presence of the background solution .", "tokens": ["first", "let", "us", "consider", "the", "solution", "for", "the", "zero", "mode", "in", "the", "presence", "of", "the", "background", "solution", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "let", "start": 6, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "us", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "consider", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "consider", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}], "id": 638}, {"sent": "having today available a big number of large-scale datasets and powerful gpus , deep neural networks have become the state-of-the-art in many computer vision , and speech recognition tasks .", "tokens": ["having", "today", "available", "a", "big", "number", "of", "large", "-", "scale", "datasets", "and", "powerful", "gpus", ",", "deep", "neural", "networks", "have", "become", "the", "state", "-", "of", "-", "the", "-", "art", "in", "many", "computer", "vision", ",", "and", "speech", "recognition", "tasks", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 80, "end": 100, "i_start": 15, "i_end": 17}, "verb": {"text": "have become", "start": 101, "end": 112, "i_start": 18, "i_end": 19}}], "id": 639}, {"sent": "for generic object detection , deep learning has been a great success .", "tokens": ["for", "generic", "object", "detection", ",", "deep", "learning", "has", "been", "a", "great", "success", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 31, "end": 44, "i_start": 5, "i_end": 6}, "verb": {"text": "has been", "start": 45, "end": 53, "i_start": 7, "i_end": 8}}, {"character": {"text": "learning", "start": 36, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 62, "end": 69, "i_start": 11, "i_end": 11}}], "id": 640}, {"sent": "it is shown that the spin diffusion length in the superconducting state is equal to that in the normal state .", "tokens": ["it", "is", "shown", "that", "the", "spin", "diffusion", "length", "in", "the", "superconducting", "state", "is", "equal", "to", "that", "in", "the", "normal", "state", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is shown", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 72, "end": 74, "i_start": 12, "i_end": 12}}], "id": 641}, {"sent": "in the mathematical community they are called orbifolds .", "tokens": ["in", "the", "mathematical", "community", "they", "are", "called", "orbifolds", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 30, "end": 34, "i_start": 4, "i_end": 4}, "verb": {"text": "are called", "start": 35, "end": 45, "i_start": 5, "i_end": 6}}], "id": 642}, {"sent": "we initialize our neural network weights using xavier initialization .", "tokens": ["we", "initialize", "our", "neural", "network", "weights", "using", "xavier", "initialization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "initialize", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "initialize", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}], "id": 643}, {"sent": "note that we are using here a first-order formulation of the action as opposed to the second-order formulation used in .", "tokens": ["note", "that", "we", "are", "using", "here", "a", "first", "-", "order", "formulation", "of", "the", "action", "as", "opposed", "to", "the", "second", "-", "order", "formulation", "used", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "using", "start": 17, "end": 22, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "using", "start": 17, "end": 22, "i_start": 4, "i_end": 4}}], "id": 644}, {"sent": "such a multiplication is a single operation on a quantum computer , but an elaborate procedure on a classical computer , and therein lies the physical advantage of a quantum computer .", "tokens": ["such", "a", "multiplication", "is", "a", "single", "operation", "on", "a", "quantum", "computer", ",", "but", "an", "elaborate", "procedure", "on", "a", "classical", "computer", ",", "and", "therein", "lies", "the", "physical", "advantage", "of", "a", "quantum", "computer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such a multiplication", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 645}, {"sent": "in recent years , deep convolutional neural networks have achieved great success in object detection .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have achieved", "start": 53, "end": 66, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 58, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "success", "start": 73, "end": 80, "i_start": 11, "i_end": 11}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "detection", "start": 91, "end": 100, "i_start": 14, "i_end": 14}}], "id": 646}, {"sent": "the data reduction was performed by the sv team using the uves pipeline .", "tokens": ["the", "data", "reduction", "was", "performed", "by", "the", "sv", "team", "using", "the", "uves", "pipeline", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data reduction", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "was performed", "start": 19, "end": 32, "i_start": 3, "i_end": 4}}, {"character": {"text": "team", "start": 43, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "reduction", "start": 9, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "team", "start": 43, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "using", "start": 48, "end": 53, "i_start": 9, "i_end": 9}}], "id": 647}, {"sent": "the neutralino is a majorana fermion , which we represent with a solid fermion line without an arrow .", "tokens": ["the", "neutralino", "is", "a", "majorana", "fermion", ",", "which", "we", "represent", "with", "a", "solid", "fermion", "line", "without", "an", "arrow", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the neutralino", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 45, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "represent", "start": 48, "end": 57, "i_start": 9, "i_end": 9}}], "id": 648}, {"sent": "we therefore introduce a dropout-inspired regularization for recurrent networks .", "tokens": ["we", "therefore", "introduce", "a", "dropout", "-", "inspired", "regularization", "for", "recurrent", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "introduce", "start": 13, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "introduce", "start": 13, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "dropout", "start": 25, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "inspired", "start": 33, "end": 41, "i_start": 6, "i_end": 6}}], "id": 649}, {"sent": "this region is characterized by localized polaronic states .", "tokens": ["this", "region", "is", "characterized", "by", "localized", "polaronic", "states", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this region", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is characterized", "start": 12, "end": 28, "i_start": 2, "i_end": 3}}, {"character": {"text": "states", "start": 52, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "characterized", "start": 15, "end": 28, "i_start": 3, "i_end": 3}}], "id": 650}, {"sent": "the geometry associated with the scalars in this model is known as special geometry .", "tokens": ["the", "geometry", "associated", "with", "the", "scalars", "in", "this", "model", "is", "known", "as", "special", "geometry", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the geometry associated with the scalars in this model", "start": 0, "end": 54, "i_start": 0, "i_end": 8}, "verb": {"text": "is known", "start": 55, "end": 63, "i_start": 9, "i_end": 10}}], "id": 651}, {"sent": "if the higgs boson will be found is the mass of the lightest at the next generation of colliders , its mass will be measured with high precision .", "tokens": ["if", "the", "higgs", "boson", "will", "be", "found", "is", "the", "mass", "of", "the", "lightest", "at", "the", "next", "generation", "of", "colliders", ",", "its", "mass", "will", "be", "measured", "with", "high", "precision", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "its mass", "start": 99, "end": 107, "i_start": 20, "i_end": 21}, "verb": {"text": "will be measured", "start": 108, "end": 124, "i_start": 22, "i_end": 24}}, {"subject": {"text": "its mass", "start": 99, "end": 107, "i_start": 20, "i_end": 21}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 7, "i_end": 7}}], "id": 652}, {"sent": "our compactification consists of the embedding of re is a dense open subset of a component of this partition .", "tokens": ["our", "compactification", "consists", "of", "the", "embedding", "of", "re", "is", "a", "dense", "open", "subset", "of", "a", "component", "of", "this", "partition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our compactification", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 21, "end": 29, "i_start": 2, "i_end": 2}}, {"subject": {"text": "our compactification", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 53, "end": 55, "i_start": 8, "i_end": 8}}], "id": 653}, {"sent": "every sheaf is the direct sum of a torsion-free sheaf and a finite length sheaf .", "tokens": ["every", "sheaf", "is", "the", "direct", "sum", "of", "a", "torsion", "-", "free", "sheaf", "and", "a", "finite", "length", "sheaf", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "every sheaf", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 654}, {"sent": "recently , increasing attention has focused on deep 3d shape generation from single rgb images .", "tokens": ["recently", ",", "increasing", "attention", "has", "focused", "on", "deep", "3d", "shape", "generation", "from", "single", "rgb", "images", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "increasing attention", "start": 11, "end": 31, "i_start": 2, "i_end": 3}, "verb": {"text": "has focused", "start": 32, "end": 43, "i_start": 4, "i_end": 5}}], "id": 655}, {"sent": "cluster algebras were introduced and studied in a series of articles by fomin and zelevinsky in .", "tokens": ["cluster", "algebras", "were", "introduced", "and", "studied", "in", "a", "series", "of", "articles", "by", "fomin", "and", "zelevinsky", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were introduced", "start": 17, "end": 32, "i_start": 2, "i_end": 3}}, {"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "studied", "start": 37, "end": 44, "i_start": 5, "i_end": 5}}], "id": 656}, {"sent": "this sheaf is a free abelian sheaf which is locally constant on each stratum , and the structure of this sheaf is a topological invariant of the system .", "tokens": ["this", "sheaf", "is", "a", "free", "abelian", "sheaf", "which", "is", "locally", "constant", "on", "each", "stratum", ",", "and", "the", "structure", "of", "this", "sheaf", "is", "a", "topological", "invariant", "of", "the", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this sheaf", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}], "id": 657}, {"sent": "penrose , the nature of space and time , princeton uni versity press .", "tokens": ["penrose", ",", "the", "nature", "of", "space", "and", "time", ",", "princeton", "uni", "versity", "press", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 658}, {"sent": "recently , deep neural networks achieve excellent performance on difficult problems such as speech recognition .", "tokens": ["recently", ",", "deep", "neural", "networks", "achieve", "excellent", "performance", "on", "difficult", "problems", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "achieve", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "achieve", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "performance", "start": 50, "end": 61, "i_start": 7, "i_end": 7}}], "id": 659}, {"sent": "the beltrami-de sitter spacetime and inertial-type motion a .", "tokens": ["the", "beltrami", "-", "de", "sitter", "spacetime", "and", "inertial", "-", "type", "motion", "a", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 660}, {"sent": "here , we turn to the fluctuation spectrum on the lump .", "tokens": ["here", ",", "we", "turn", "to", "the", "fluctuation", "spectrum", "on", "the", "lump", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "turn", "start": 10, "end": 14, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "turn", "start": 10, "end": 14, "i_start": 3, "i_end": 3}}, {"character": {"text": "spectrum", "start": 34, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "fluctuation", "start": 22, "end": 33, "i_start": 6, "i_end": 6}}], "id": 661}, {"sent": "our study takes the context of a specific model , dubbed no-scale f -su , representing the merger of the f -lipped su grand unified theory .", "tokens": ["our", "study", "takes", "the", "context", "of", "a", "specific", "model", ",", "dubbed", "no", "-", "scale", "f", "-su", ",", "representing", "the", "merger", "of", "the", "f", "-lipped", "su", "grand", "unified", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our study", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "takes", "start": 10, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "study", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "takes", "start": 10, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "model", "start": 42, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "representing", "start": 74, "end": 86, "i_start": 17, "i_end": 17}}], "id": 662}, {"sent": "the models we use consist of vgg16 and resnet32 .", "tokens": ["the", "models", "we", "use", "consist", "of", "vgg16", "and", "resnet32", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 14, "end": 17, "i_start": 3, "i_end": 3}}], "id": 663}, {"sent": "recently , deep neural networks are driving advances in image recognition related tasks in computer vision .", "tokens": ["recently", ",", "deep", "neural", "networks", "are", "driving", "advances", "in", "image", "recognition", "related", "tasks", "in", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "are driving", "start": 32, "end": 43, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "driving", "start": 36, "end": 43, "i_start": 6, "i_end": 6}}], "id": 664}, {"sent": "spectral function of discrete strong-coupling polarons d .", "tokens": ["spectral", "function", "of", "discrete", "strong", "-", "coupling", "polarons", "d", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "polarons", "start": 46, "end": 54, "i_start": 7, "i_end": 7}, "action": {"text": "function of discrete strong-coupling polarons d", "start": 9, "end": 56, "i_start": 1, "i_end": 8}}], "id": 665}, {"sent": "perhaps the most well known are generative adversarial networks , which received a lot of attention recently .", "tokens": ["perhaps", "the", "most", "well", "known", "are", "generative", "adversarial", "networks", ",", "which", "received", "a", "lot", "of", "attention", "recently", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "networks", "start": 55, "end": 63, "i_start": 8, "i_end": 8}, "action": {"text": "received", "start": 72, "end": 80, "i_start": 11, "i_end": 11}}], "id": 666}, {"sent": "the effect of varying the diffusion zone width on the positron spectrum .", "tokens": ["the", "effect", "of", "varying", "the", "diffusion", "zone", "width", "on", "the", "positron", "spectrum", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 667}, {"sent": "quantum mechanics is a non-obvious mathematical form of elementary probability theory .", "tokens": ["quantum", "mechanics", "is", "a", "non", "-", "obvious", "mathematical", "form", "of", "elementary", "probability", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum mechanics", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}], "id": 668}, {"sent": "the two main styles of algorithms for the non-realizable case are disagreementbased active learning .", "tokens": ["the", "two", "main", "styles", "of", "algorithms", "for", "the", "non", "-", "realizable", "case", "are", "disagreementbased", "active", "learning", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the two main styles of algorithms for the non-realizable case", "start": 0, "end": 61, "i_start": 0, "i_end": 11}, "verb": {"text": "are disagreementbased", "start": 62, "end": 83, "i_start": 12, "i_end": 13}}], "id": 669}, {"sent": "reinforcement learning allows agents to interact with the environment by sequentially taking actions and observing rewards to maximize the cumulative reward .", "tokens": ["reinforcement", "learning", "allows", "agents", "to", "interact", "with", "the", "environment", "by", "sequentially", "taking", "actions", "and", "observing", "rewards", "to", "maximize", "the", "cumulative", "reward", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "allows", "start": 23, "end": 29, "i_start": 2, "i_end": 2}}, {"subject": {"text": "agents", "start": 30, "end": 36, "i_start": 3, "i_end": 3}, "verb": {"text": "interact", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "learning", "start": 14, "end": 22, "i_start": 1, "i_end": 1}, "action": {"text": "allows", "start": 23, "end": 29, "i_start": 2, "i_end": 2}}, {"character": {"text": "agents", "start": 30, "end": 36, "i_start": 3, "i_end": 3}, "action": {"text": "interact", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "agents", "start": 30, "end": 36, "i_start": 3, "i_end": 3}, "action": {"text": "observing", "start": 105, "end": 114, "i_start": 14, "i_end": 14}}, {"character": {"text": "agents", "start": 30, "end": 36, "i_start": 3, "i_end": 3}, "action": {"text": "maximize", "start": 126, "end": 134, "i_start": 17, "i_end": 17}}], "id": 670}, {"sent": "the computations of the entanglement entropies for locally excited states have been formulated in in the field theory side .", "tokens": ["the", "computations", "of", "the", "entanglement", "entropies", "for", "locally", "excited", "states", "have", "been", "formulated", "in", "in", "the", "field", "theory", "side", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the computations of the entanglement entropies for locally excited states", "start": 0, "end": 73, "i_start": 0, "i_end": 9}, "verb": {"text": "have been formulated", "start": 74, "end": 94, "i_start": 10, "i_end": 12}}], "id": 671}, {"sent": "adversarial learning is an increasingly popular approach for learning deep generative models .", "tokens": ["adversarial", "learning", "is", "an", "increasingly", "popular", "approach", "for", "learning", "deep", "generative", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "adversarial learning", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "learning", "start": 61, "end": 69, "i_start": 8, "i_end": 8}, "action": {"text": "approach", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}], "id": 672}, {"sent": "however , we are interested mainly in how polarization measures at large angles can improve the reconstruction of the reionization history .", "tokens": ["however", ",", "we", "are", "interested", "mainly", "in", "how", "polarization", "measures", "at", "large", "angles", "can", "improve", "the", "reconstruction", "of", "the", "reionization", "history", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "are", "start": 13, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "measures", "start": 55, "end": 63, "i_start": 9, "i_end": 9}, "action": {"text": "improve", "start": 84, "end": 91, "i_start": 14, "i_end": 14}}], "id": 673}, {"sent": "deep convolutional neural networks are powerful discriminative models that yield impressive results at object classification .", "tokens": ["deep", "convolutional", "neural", "networks", "are", "powerful", "discriminative", "models", "that", "yield", "impressive", "results", "at", "object", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 35, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "models", "start": 63, "end": 69, "i_start": 7, "i_end": 7}, "action": {"text": "discriminative", "start": 48, "end": 62, "i_start": 6, "i_end": 6}}, {"character": {"text": "models", "start": 63, "end": 69, "i_start": 7, "i_end": 7}, "action": {"text": "yield", "start": 75, "end": 80, "i_start": 9, "i_end": 9}}, {"character": {"text": "results", "start": 92, "end": 99, "i_start": 11, "i_end": 11}, "action": {"text": "impressive", "start": 81, "end": 91, "i_start": 10, "i_end": 10}}], "id": 674}, {"sent": "our key technical insight is to use a monadic structure for galois connections , following the example of moggi .", "tokens": ["our", "key", "technical", "insight", "is", "to", "use", "a", "monadic", "structure", "for", "galois", "connections", ",", "following", "the", "example", "of", "moggi", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our key technical insight", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 4, "i_end": 4}}], "id": 675}, {"sent": "such an investment is called an optimal portfolio .", "tokens": ["such", "an", "investment", "is", "called", "an", "optimal", "portfolio", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such an investment", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 19, "end": 28, "i_start": 3, "i_end": 4}}], "id": 676}, {"sent": "le and mikolov propose the paragraph vector model , which incorporates a global context vector into the log-linear neural language model , but at test time , inference needs to be performed to compute a new vector .", "tokens": ["le", "and", "mikolov", "propose", "the", "paragraph", "vector", "model", ",", "which", "incorporates", "a", "global", "context", "vector", "into", "the", "log", "-", "linear", "neural", "language", "model", ",", "but", "at", "test", "time", ",", "inference", "needs", "to", "be", "performed", "to", "compute", "a", "new", "vector", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "le and mikolov", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 15, "end": 22, "i_start": 3, "i_end": 3}}, {"subject": {"text": "inference", "start": 158, "end": 167, "i_start": 29, "i_end": 29}, "verb": {"text": "needs", "start": 168, "end": 173, "i_start": 30, "i_end": 30}}, {"character": {"text": "le", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 15, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "mikolov", "start": 7, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "propose", "start": 15, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "model", "start": 44, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "incorporates", "start": 58, "end": 70, "i_start": 10, "i_end": 10}}], "id": 677}, {"sent": "other population -a binary classification problem of distinguishing subjects with a specific syndrome from normal subjects or subjects with other syndromes .", "tokens": ["other", "population", "-a", "binary", "classification", "problem", "of", "distinguishing", "subjects", "with", "a", "specific", "syndrome", "from", "normal", "subjects", "or", "subjects", "with", "other", "syndromes", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 678}, {"sent": "staring from bucila et als work and hinton et als more general knowledge distillation approach , the knowledge transfer in learning process has gained a lot of research interest .", "tokens": ["staring", "from", "bucila", "et", "als", "work", "and", "hinton", "et", "als", "more", "general", "knowledge", "distillation", "approach", ",", "the", "knowledge", "transfer", "in", "learning", "process", "has", "gained", "a", "lot", "of", "research", "interest", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "the knowledge transfer in learning process", "start": 97, "end": 139, "i_start": 16, "i_end": 21}, "verb": {"text": "has gained", "start": 140, "end": 150, "i_start": 22, "i_end": 23}}, {"character": {"text": "transfer", "start": 111, "end": 119, "i_start": 18, "i_end": 18}, "action": {"text": "gained", "start": 144, "end": 150, "i_start": 23, "i_end": 23}}, {"character": {"text": "hinton", "start": 36, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "work", "start": 27, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "hinton", "start": 36, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "approach", "start": 86, "end": 94, "i_start": 14, "i_end": 14}}], "id": 679}, {"sent": "we compare the performance of the posefix with stateof-the-art methods , which include pafs test-dev set .", "tokens": ["we", "compare", "the", "performance", "of", "the", "posefix", "with", "stateof", "-", "the", "-", "art", "methods", ",", "which", "include", "pafs", "test", "-", "dev", "set", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 680}, {"sent": "deep convolutional neural networks are powerful discriminative models that yield impressive results at object classification .", "tokens": ["deep", "convolutional", "neural", "networks", "are", "powerful", "discriminative", "models", "that", "yield", "impressive", "results", "at", "object", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 35, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "models", "start": 63, "end": 69, "i_start": 7, "i_end": 7}, "action": {"text": "discriminative", "start": 48, "end": 62, "i_start": 6, "i_end": 6}}, {"character": {"text": "models", "start": 63, "end": 69, "i_start": 7, "i_end": 7}, "action": {"text": "yield", "start": 75, "end": 80, "i_start": 9, "i_end": 9}}, {"character": {"text": "results", "start": 92, "end": 99, "i_start": 11, "i_end": 11}, "action": {"text": "impressive", "start": 81, "end": 91, "i_start": 10, "i_end": 10}}], "id": 681}, {"sent": "we can also notice that route length optimization has no impact on delivery ratio .", "tokens": ["we", "can", "also", "notice", "that", "route", "length", "optimization", "has", "no", "impact", "on", "delivery", "ratio", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "route length optimization", "start": 24, "end": 49, "i_start": 5, "i_end": 7}, "verb": {"text": "notice", "start": 12, "end": 18, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "can", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has", "start": 50, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "notice", "start": 12, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "optimization", "start": 37, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "no impact", "start": 54, "end": 63, "i_start": 9, "i_end": 10}}], "id": 682}, {"sent": "convolutional neural networks have achieved tremendous progress on many pattern recognition tasks , especially large-scale images recognition problems .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "tremendous", "progress", "on", "many", "pattern", "recognition", "tasks", ",", "especially", "large", "-", "scale", "images", "recognition", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 683}, {"sent": "deep neural networks have achieved impressive performance in supervised classification and structured prediction tasks such as speech recognition , machine translation and more .", "tokens": ["deep", "neural", "networks", "have", "achieved", "impressive", "performance", "in", "supervised", "classification", "and", "structured", "prediction", "tasks", "such", "as", "speech", "recognition", ",", "machine", "translation", "and", "more", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 46, "end": 57, "i_start": 6, "i_end": 6}}, {"character": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "impressive", "start": 35, "end": 45, "i_start": 5, "i_end": 5}}], "id": 684}, {"sent": "this limitation is countered by the generalized dof framework , which inherits the tractability of the dof framework while capturing the diversity in channel strengths .", "tokens": ["this", "limitation", "is", "countered", "by", "the", "generalized", "dof", "framework", ",", "which", "inherits", "the", "tractability", "of", "the", "dof", "framework", "while", "capturing", "the", "diversity", "in", "channel", "strengths", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this limitation", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is countered", "start": 16, "end": 28, "i_start": 2, "i_end": 3}}, {"character": {"text": "framework", "start": 52, "end": 61, "i_start": 8, "i_end": 8}, "action": {"text": "countered", "start": 19, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "framework", "start": 52, "end": 61, "i_start": 8, "i_end": 8}, "action": {"text": "inherits", "start": 70, "end": 78, "i_start": 11, "i_end": 11}}, {"character": {"text": "framework", "start": 52, "end": 61, "i_start": 8, "i_end": 8}, "action": {"text": "capturing", "start": 123, "end": 132, "i_start": 19, "i_end": 19}}], "id": 685}, {"sent": "the network is trained using adam optimizer as a supervision signal .", "tokens": ["the", "network", "is", "trained", "using", "adam", "optimizer", "as", "a", "supervision", "signal", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the network", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is trained", "start": 12, "end": 22, "i_start": 2, "i_end": 3}}, {"character": {"text": "signal", "start": 61, "end": 67, "i_start": 10, "i_end": 10}, "action": {"text": "supervision", "start": 49, "end": 60, "i_start": 9, "i_end": 9}}], "id": 686}, {"sent": "recently , it has been applied to medical imaging , such as image denoising , chen et al 2017 , image reconstruction .", "tokens": ["recently", ",", "it", "has", "been", "applied", "to", "medical", "imaging", ",", "such", "as", "image", "denoising", ",", "chen", "et", "al", "2017", ",", "image", "reconstruction", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "verb": {"text": "has been applied", "start": 14, "end": 30, "i_start": 3, "i_end": 5}}], "id": 687}, {"sent": "the o-module scheme alt when s is the spectrum of a complete local noetherian o-algebra .", "tokens": ["the", "o", "-", "module", "scheme", "alt", "when", "s", "is", "the", "spectrum", "of", "a", "complete", "local", "noetherian", "o", "-", "algebra", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 688}, {"sent": "two states that are not equivalent are called distinct .", "tokens": ["two", "states", "that", "are", "not", "equivalent", "are", "called", "distinct", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "two states that are not equivalent", "start": 0, "end": 34, "i_start": 0, "i_end": 5}, "verb": {"text": "are called", "start": 35, "end": 45, "i_start": 6, "i_end": 7}}], "id": 689}, {"sent": "the recent development of deep learning has boosted the performance of image classification tasks .", "tokens": ["the", "recent", "development", "of", "deep", "learning", "has", "boosted", "the", "performance", "of", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the recent development of deep learning", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "has boosted", "start": 40, "end": 51, "i_start": 6, "i_end": 7}}, {"character": {"text": "development", "start": 11, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "boosted", "start": 44, "end": 51, "i_start": 7, "i_end": 7}}], "id": 690}, {"sent": "recurrent neural networks , as a class of deep convolutional networks , have recently shown great promise in tackling many sequence modelling tasks in machine learning , such as automatic speech recognition .", "tokens": ["recurrent", "neural", "networks", ",", "as", "a", "class", "of", "deep", "convolutional", "networks", ",", "have", "recently", "shown", "great", "promise", "in", "tackling", "many", "sequence", "modelling", "tasks", "in", "machine", "learning", ",", "such", "as", "automatic", "speech", "recognition", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "recurrent neural networks", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "shown", "start": 86, "end": 91, "i_start": 14, "i_end": 14}}, {"subject": {"text": "recurrent neural networks", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 72, "end": 76, "i_start": 12, "i_end": 12}}, {"character": {"text": "networks", "start": 17, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "tackling", "start": 109, "end": 117, "i_start": 18, "i_end": 18}}], "id": 691}, {"sent": "then we use the expectation maximization algorithm to fit a gaussian mixture of 100 components .", "tokens": ["then", "we", "use", "the", "expectation", "maximization", "algorithm", "to", "fit", "a", "gaussian", "mixture", "of", "100", "components", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}], "id": 692}, {"sent": "fomin and zelevinsky have defined cluster algebras , and developed an interesting and influential theory about this class of algebras .", "tokens": ["fomin", "and", "zelevinsky", "have", "defined", "cluster", "algebras", ",", "and", "developed", "an", "interesting", "and", "influential", "theory", "about", "this", "class", "of", "algebras", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "fomin and zelevinsky", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have defined", "start": 21, "end": 33, "i_start": 3, "i_end": 4}}, {"subject": {"text": "fomin and zelevinsky", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "developed", "start": 57, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "fomin", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "defined", "start": 26, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "zelevinsky", "start": 10, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "defined", "start": 26, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "fomin", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "developed", "start": 57, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "zelevinsky", "start": 10, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "developed", "start": 57, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "theory", "start": 98, "end": 104, "i_start": 14, "i_end": 14}, "action": {"text": "interesting", "start": 70, "end": 81, "i_start": 11, "i_end": 11}}, {"character": {"text": "theory", "start": 98, "end": 104, "i_start": 14, "i_end": 14}, "action": {"text": "influential", "start": 86, "end": 97, "i_start": 13, "i_end": 13}}], "id": 693}, {"sent": "in contrast , our key idea is to leverage denoising autoencoder networks as natural image priors .", "tokens": ["in", "contrast", ",", "our", "key", "idea", "is", "to", "leverage", "denoising", "autoencoder", "networks", "as", "natural", "image", "priors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our key idea", "start": 14, "end": 26, "i_start": 3, "i_end": 5}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 6, "i_end": 6}}], "id": 694}, {"sent": "unlike the alexnet architecture , each convolution block is constructed from a conventional 2d convolution layer followed by a batch normalisation layer .", "tokens": ["unlike", "the", "alexnet", "architecture", ",", "each", "convolution", "block", "is", "constructed", "from", "a", "conventional", "2d", "convolution", "layer", "followed", "by", "a", "batch", "normalisation", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each convolution block", "start": 34, "end": 56, "i_start": 5, "i_end": 7}, "verb": {"text": "is constructed", "start": 57, "end": 71, "i_start": 8, "i_end": 9}}], "id": 695}, {"sent": "to find the complete set of constraints we use the general lagrangian scheme 16 which is equivalent to the dirac-bergmann procedure in hamiltonian formalism but for our purposes is simpler .", "tokens": ["to", "find", "the", "complete", "set", "of", "constraints", "we", "use", "the", "general", "lagrangian", "scheme", "16", "which", "is", "equivalent", "to", "the", "dirac", "-", "bergmann", "procedure", "in", "hamiltonian", "formalism", "but", "for", "our", "purposes", "is", "simpler", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 40, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "use", "start": 43, "end": 46, "i_start": 8, "i_end": 8}}], "id": 696}, {"sent": "we collect most of the real-world datasets from stanford large network dataset collection .", "tokens": ["we", "collect", "most", "of", "the", "real", "-", "world", "datasets", "from", "stanford", "large", "network", "dataset", "collection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "collect", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "collect", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 697}, {"sent": "deep neural networks have demonstrated dramatically accurate results for challenging tasks .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "dramatically", "accurate", "results", "for", "challenging", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}], "id": 698}, {"sent": "deep learning has obviously improved the performance of many computer vision tasks such as classification .", "tokens": ["deep", "learning", "has", "obviously", "improved", "the", "performance", "of", "many", "computer", "vision", "tasks", "such", "as", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "improved", "start": 28, "end": 36, "i_start": 4, "i_end": 4}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has", "start": 14, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "improved", "start": 28, "end": 36, "i_start": 4, "i_end": 4}}], "id": 699}, {"sent": "to solve the linearized problem in , we use the augmented lagrange multiplier method .", "tokens": ["to", "solve", "the", "linearized", "problem", "in", ",", "we", "use", "the", "augmented", "lagrange", "multiplier", "method", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 37, "end": 39, "i_start": 7, "i_end": 7}, "verb": {"text": "use", "start": 40, "end": 43, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 37, "end": 39, "i_start": 7, "i_end": 7}, "action": {"text": "use", "start": 40, "end": 43, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 37, "end": 39, "i_start": 7, "i_end": 7}, "action": {"text": "solve", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 700}, {"sent": "an example table of the the catalogue of high probability members of alpha per .", "tokens": ["an", "example", "table", "of", "the", "the", "catalogue", "of", "high", "probability", "members", "of", "alpha", "per", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 701}, {"sent": "cnns have been widely used and have achieved exciting performance in the fields of image classification , object recognition and object detection and tracking due to their powerful ability to learn deep features .", "tokens": ["cnns", "have", "been", "widely", "used", "and", "have", "achieved", "exciting", "performance", "in", "the", "fields", "of", "image", "classification", ",", "object", "recognition", "and", "object", "detection", "and", "tracking", "due", "to", "their", "powerful", "ability", "to", "learn", "deep", "features", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cnns", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 22, "end": 26, "i_start": 4, "i_end": 4}}, {"subject": {"text": "cnns", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "have been", "start": 5, "end": 14, "i_start": 1, "i_end": 2}}, {"subject": {"text": "cnns", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "achieved", "start": 36, "end": 44, "i_start": 7, "i_end": 7}}, {"character": {"text": "performance", "start": 54, "end": 65, "i_start": 9, "i_end": 9}, "action": {"text": "exciting", "start": 45, "end": 53, "i_start": 8, "i_end": 8}}], "id": 702}, {"sent": "entanglement is perhaps one of the most fundamental and non-classical features exhibited by quantum systems .", "tokens": ["entanglement", "is", "perhaps", "one", "of", "the", "most", "fundamental", "and", "non", "-", "classical", "features", "exhibited", "by", "quantum", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "entanglement", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "systems", "start": 100, "end": 107, "i_start": 16, "i_end": 16}, "action": {"text": "exhibited", "start": 79, "end": 88, "i_start": 13, "i_end": 13}}], "id": 703}, {"sent": "in recent years , deep neural networks have led to many breakthrough results in machine learning and computer vision , and are now widely deployed in industry .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "led", "to", "many", "breakthrough", "results", "in", "machine", "learning", "and", "computer", "vision", ",", "and", "are", "now", "widely", "deployed", "in", "industry", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have led", "start": 39, "end": 47, "i_start": 7, "i_end": 8}}, {"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "deployed", "start": 138, "end": 146, "i_start": 24, "i_end": 24}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "led", "start": 44, "end": 47, "i_start": 8, "i_end": 8}}], "id": 704}, {"sent": "fault-tolerant topological one-way quantum computation with probabilistic two-qubit gates .", "tokens": ["fault", "-", "tolerant", "topological", "one", "-", "way", "quantum", "computation", "with", "probabilistic", "two", "-", "qubit", "gates", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "computation", "start": 43, "end": 54, "i_start": 8, "i_end": 8}, "action": {"text": "tolerant", "start": 6, "end": 14, "i_start": 2, "i_end": 2}}], "id": 705}, {"sent": "people interact with computers and intelligent systems in ways that mirror how they interact with other people .", "tokens": ["people", "interact", "with", "computers", "and", "intelligent", "systems", "in", "ways", "that", "mirror", "how", "they", "interact", "with", "other", "people", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "people", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "interact", "start": 7, "end": 15, "i_start": 1, "i_end": 1}}], "id": 706}, {"sent": "indeed , for previous cases like the sutherland gl-spin model whose the symmetry is the yangian of gl , the algebra symmetry is crucial to find the spectrum .", "tokens": ["indeed", ",", "for", "previous", "cases", "like", "the", "sutherland", "gl", "-", "spin", "model", "whose", "the", "symmetry", "is", "the", "yangian", "of", "gl", ",", "the", "algebra", "symmetry", "is", "crucial", "to", "find", "the", "spectrum", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the algebra symmetry", "start": 104, "end": 124, "i_start": 21, "i_end": 23}, "verb": {"text": "is", "start": 125, "end": 127, "i_start": 24, "i_end": 24}}], "id": 707}, {"sent": "consequently , a variety of degenerate training behaviors has been observed-eg , mode collapse .", "tokens": ["consequently", ",", "a", "variety", "of", "degenerate", "training", "behaviors", "has", "been", "observed", "-", "eg", ",", "mode", "collapse", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 708}, {"sent": "inflation is a powerful framework for addressing the cosmological flatness and horizon puzzles , and for generating the primordial seeds of structure .", "tokens": ["inflation", "is", "a", "powerful", "framework", "for", "addressing", "the", "cosmological", "flatness", "and", "horizon", "puzzles", ",", "and", "for", "generating", "the", "primordial", "seeds", "of", "structure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "inflation", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "flatness", "start": 66, "end": 74, "i_start": 9, "i_end": 9}, "action": {"text": "puzzles", "start": 87, "end": 94, "i_start": 12, "i_end": 12}}, {"character": {"text": "horizon", "start": 79, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "puzzles", "start": 87, "end": 94, "i_start": 12, "i_end": 12}}], "id": 709}, {"sent": "as a noncommutative analogue of cluster algebras , quantum cluster algebras were defined by berenstein and zelevinsky in .", "tokens": ["as", "a", "noncommutative", "analogue", "of", "cluster", "algebras", ",", "quantum", "cluster", "algebras", "were", "defined", "by", "berenstein", "and", "zelevinsky", "in", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "quantum cluster algebras", "start": 51, "end": 75, "i_start": 8, "i_end": 10}, "verb": {"text": "were defined", "start": 76, "end": 88, "i_start": 11, "i_end": 12}}, {"character": {"text": "berenstein", "start": 92, "end": 102, "i_start": 14, "i_end": 14}, "action": {"text": "defined", "start": 81, "end": 88, "i_start": 12, "i_end": 12}}, {"character": {"text": "zelevinsky", "start": 107, "end": 117, "i_start": 16, "i_end": 16}, "action": {"text": "defined", "start": 81, "end": 88, "i_start": 12, "i_end": 12}}], "id": 710}, {"sent": "we fitted the different spectral features needed for our analysis using the idl-based routine mpfitexpr .", "tokens": ["we", "fitted", "the", "different", "spectral", "features", "needed", "for", "our", "analysis", "using", "the", "idl", "-", "based", "routine", "mpfitexpr", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "fitted", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "fitted", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "analysis", "start": 57, "end": 65, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 66, "end": 71, "i_start": 10, "i_end": 10}}], "id": 711}, {"sent": "any gate capable of entangling two qubits , together with a minimal set of one-qubit gates form such a universal set .", "tokens": ["any", "gate", "capable", "of", "entangling", "two", "qubits", ",", "together", "with", "a", "minimal", "set", "of", "one", "-", "qubit", "gates", "form", "such", "a", "universal", "set", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "any gate capable of entangling two qubits", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "form", "start": 91, "end": 95, "i_start": 18, "i_end": 18}}, {"character": {"text": "gate", "start": 4, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "form", "start": 91, "end": 95, "i_start": 18, "i_end": 18}}, {"character": {"text": "gate", "start": 4, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "entangling", "start": 20, "end": 30, "i_start": 4, "i_end": 4}}], "id": 712}, {"sent": "convolutional neural networks have been successfully applied to several diverse classification problems including speech and image recognition .", "tokens": ["convolutional", "neural", "networks", "have", "been", "successfully", "applied", "to", "several", "diverse", "classification", "problems", "including", "speech", "and", "image", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "applied", "start": 53, "end": 60, "i_start": 6, "i_end": 6}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}], "id": 713}, {"sent": "marra , the navier-stokes limit of stationary solutions of the nonlinear boltzmann equation , j .", "tokens": ["marra", ",", "the", "navier", "-", "stokes", "limit", "of", "stationary", "solutions", "of", "the", "nonlinear", "boltzmann", "equation", ",", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "limit", "start": 26, "end": 31, "i_start": 6, "i_end": 6}, "action": {"text": "stokes", "start": 19, "end": 25, "i_start": 5, "i_end": 5}}], "id": 714}, {"sent": "deep convolutional neural networks have improved performance of many tasks in computer vision , such as image recognition .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "improved", "performance", "of", "many", "tasks", "in", "computer", "vision", ",", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have improved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 49, "end": 60, "i_start": 6, "i_end": 6}}], "id": 715}, {"sent": "convolutional neural networks have successfully tackled classic computer vision problems such as image classification , where the input image has a grid-like structure .", "tokens": ["convolutional", "neural", "networks", "have", "successfully", "tackled", "classic", "computer", "vision", "problems", "such", "as", "image", "classification", ",", "where", "the", "input", "image", "has", "a", "grid", "-", "like", "structure", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "tackled", "start": 48, "end": 55, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "tackled", "start": 48, "end": 55, "i_start": 5, "i_end": 5}}], "id": 716}, {"sent": "in multi-carrier transmission , however , it is shown in that non-zero mean gaussian input distributions lead to an enlarged rate-power region compared to cscg input distributions .", "tokens": ["in", "multi", "-", "carrier", "transmission", ",", "however", ",", "it", "is", "shown", "in", "that", "non", "-", "zero", "mean", "gaussian", "input", "distributions", "lead", "to", "an", "enlarged", "rate", "-", "power", "region", "compared", "to", "cscg", "input", "distributions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 42, "end": 44, "i_start": 8, "i_end": 8}, "verb": {"text": "is shown", "start": 45, "end": 53, "i_start": 9, "i_end": 10}}, {"subject": {"text": "that non-zero mean gaussian input distributions", "start": 57, "end": 104, "i_start": 12, "i_end": 19}, "verb": {"text": "lead", "start": 105, "end": 109, "i_start": 20, "i_end": 20}}, {"character": {"text": "distributions", "start": 91, "end": 104, "i_start": 19, "i_end": 19}, "action": {"text": "lead", "start": 105, "end": 109, "i_start": 20, "i_end": 20}}], "id": 717}, {"sent": "specifications that are not realisable are called unrealisable in the respective semantics .", "tokens": ["specifications", "that", "are", "not", "realisable", "are", "called", "unrealisable", "in", "the", "respective", "semantics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "specifications that are not realisable", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "are called", "start": 39, "end": 49, "i_start": 5, "i_end": 6}}], "id": 718}, {"sent": "the elements of this subset will be called generators of the language .", "tokens": ["the", "elements", "of", "this", "subset", "will", "be", "called", "generators", "of", "the", "language", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the elements of this subset", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "will be called", "start": 28, "end": 42, "i_start": 5, "i_end": 7}}], "id": 719}, {"sent": "in , a fast explicit operator splitting method based on the strang splitting schemes is constructed to simulate the mbe equations for both one-and two-dimensional cases .", "tokens": ["in", ",", "a", "fast", "explicit", "operator", "splitting", "method", "based", "on", "the", "strang", "splitting", "schemes", "is", "constructed", "to", "simulate", "the", "mbe", "equations", "for", "both", "one", "-", "and", "two", "-", "dimensional", "cases", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a fast explicit operator splitting method based on the strang splitting schemes", "start": 5, "end": 84, "i_start": 2, "i_end": 13}, "verb": {"text": "is constructed", "start": 85, "end": 99, "i_start": 14, "i_end": 15}}], "id": 720}, {"sent": "hence directed cyclic graphs are more appropriate to model such feedback .", "tokens": ["hence", "directed", "cyclic", "graphs", "are", "more", "appropriate", "to", "model", "such", "feedback", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "hence directed cyclic graphs", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 29, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "graphs", "start": 22, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "model", "start": 53, "end": 58, "i_start": 8, "i_end": 8}}], "id": 721}, {"sent": "the absorption line profiles were fit with gaussian components using the iraf task specfit .", "tokens": ["the", "absorption", "line", "profiles", "were", "fit", "with", "gaussian", "components", "using", "the", "iraf", "task", "specfit", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the absorption line profiles", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "were", "start": 29, "end": 33, "i_start": 4, "i_end": 4}}], "id": 722}, {"sent": "in attractiveness assessment of 5 levels , the cumulative score , measured in recognition , is also used to evaluate the proposed methods .", "tokens": ["in", "attractiveness", "assessment", "of", "5", "levels", ",", "the", "cumulative", "score", ",", "measured", "in", "recognition", ",", "is", "also", "used", "to", "evaluate", "the", "proposed", "methods", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the cumulative score", "start": 43, "end": 63, "i_start": 7, "i_end": 9}, "verb": {"text": "used", "start": 100, "end": 104, "i_start": 17, "i_end": 17}}, {"subject": {"text": "the cumulative score", "start": 43, "end": 63, "i_start": 7, "i_end": 9}, "verb": {"text": "is", "start": 92, "end": 94, "i_start": 15, "i_end": 15}}], "id": 723}, {"sent": "multi-task learninghas been successfully applied to various problems .", "tokens": ["multi", "-", "task", "learninghas", "been", "successfully", "applied", "to", "various", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "multi-task learninghas", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "applied", "start": 41, "end": 48, "i_start": 6, "i_end": 6}}, {"subject": {"text": "multi-task learninghas", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "been", "start": 23, "end": 27, "i_start": 4, "i_end": 4}}], "id": 724}, {"sent": "recently , visual recognition tasks such as image classification , have been widely studied .", "tokens": ["recently", ",", "visual", "recognition", "tasks", "such", "as", "image", "classification", ",", "have", "been", "widely", "studied", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "visual recognition tasks such as image classification", "start": 11, "end": 64, "i_start": 2, "i_end": 8}, "verb": {"text": "studied", "start": 84, "end": 91, "i_start": 13, "i_end": 13}}, {"subject": {"text": "visual recognition tasks such as image classification", "start": 11, "end": 64, "i_start": 2, "i_end": 8}, "verb": {"text": "have been", "start": 67, "end": 76, "i_start": 10, "i_end": 11}}], "id": 725}, {"sent": "for all dimensions , we have constructed the permutations with minimum entangling power .", "tokens": ["for", "all", "dimensions", ",", "we", "have", "constructed", "the", "permutations", "with", "minimum", "entangling", "power", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "have constructed", "start": 24, "end": 40, "i_start": 5, "i_end": 6}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "constructed", "start": 29, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "power", "start": 82, "end": 87, "i_start": 12, "i_end": 12}, "action": {"text": "entangling", "start": 71, "end": 81, "i_start": 11, "i_end": 11}}], "id": 726}, {"sent": "to define density matrices on general spacelike slices , we will need to consider partial tracing operations .", "tokens": ["to", "define", "density", "matrices", "on", "general", "spacelike", "slices", ",", "we", "will", "need", "to", "consider", "partial", "tracing", "operations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 57, "end": 59, "i_start": 9, "i_end": 9}, "verb": {"text": "will need", "start": 60, "end": 69, "i_start": 10, "i_end": 11}}, {"character": {"text": "we", "start": 57, "end": 59, "i_start": 9, "i_end": 9}, "action": {"text": "need", "start": 65, "end": 69, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 57, "end": 59, "i_start": 9, "i_end": 9}, "action": {"text": "consider", "start": 73, "end": 81, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 57, "end": 59, "i_start": 9, "i_end": 9}, "action": {"text": "define", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 727}, {"sent": "in , li et al propose to increment the receptive field size in cnn to better leverage multi-scale information .", "tokens": ["in", ",", "li", "et", "al", "propose", "to", "increment", "the", "receptive", "field", "size", "in", "cnn", "to", "better", "leverage", "multi", "-", "scale", "information", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "li et al", "start": 5, "end": 13, "i_start": 2, "i_end": 4}, "verb": {"text": "propose", "start": 14, "end": 21, "i_start": 5, "i_end": 5}}, {"character": {"text": "li", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "action": {"text": "propose", "start": 14, "end": 21, "i_start": 5, "i_end": 5}}, {"character": {"text": "li", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "action": {"text": "increment", "start": 25, "end": 34, "i_start": 7, "i_end": 7}}, {"character": {"text": "field", "start": 49, "end": 54, "i_start": 10, "i_end": 10}, "action": {"text": "receptive", "start": 39, "end": 48, "i_start": 9, "i_end": 9}}, {"character": {"text": "li", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "action": {"text": "leverage", "start": 77, "end": 85, "i_start": 16, "i_end": 16}}], "id": 728}, {"sent": "in recent years , deep neural networks have demonstrated impressive performance improvements on a wide range of challenging machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "demonstrated", "impressive", "performance", "improvements", "on", "a", "wide", "range", "of", "challenging", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have demonstrated", "start": 39, "end": 56, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "demonstrated", "start": 44, "end": 56, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "improvements", "start": 80, "end": 92, "i_start": 11, "i_end": 11}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 68, "end": 79, "i_start": 10, "i_end": 10}}, {"character": {"text": "tasks", "start": 141, "end": 146, "i_start": 20, "i_end": 20}, "action": {"text": "challenging", "start": 112, "end": 123, "i_start": 17, "i_end": 17}}, {"character": {"text": "improvements", "start": 80, "end": 92, "i_start": 11, "i_end": 11}, "action": {"text": "impressive", "start": 57, "end": 67, "i_start": 9, "i_end": 9}}], "id": 729}, {"sent": "wz sge is a dwarf novawhose outbursts occur on timescales of tens of years and with amplitudes of 7-8 magnitudes .", "tokens": ["wz", "sge", "is", "a", "dwarf", "nova"], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "wz sge", "start": 0, "end": 6, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 7, "end": 9, "i_start": 2, "i_end": 2}}, {"subject": {"text": "whose outbursts", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "occur", "start": 16, "end": 21, "i_start": 2, "i_end": 2}}], "id": 730}, {"sent": "we postulate that there is a region of long timescale stability at large separations .", "tokens": ["we", "postulate", "that", "there", "is", "a", "region", "of", "long", "timescale", "stability", "at", "large", "separations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "postulate", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"subject": {"text": "there", "start": 18, "end": 23, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 4, "i_end": 4}}], "id": 731}, {"sent": "specifically , for visual feature representation , we use the resnet .", "tokens": ["specifically", ",", "for", "visual", "feature", "representation", ",", "we", "use", "the", "resnet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 51, "end": 53, "i_start": 7, "i_end": 7}, "verb": {"text": "use", "start": 54, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "use", "start": 54, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "representation", "start": 34, "end": 48, "i_start": 5, "i_end": 5}}], "id": 732}, {"sent": "deep learning has had a tremendous impact in several fields , such as image processing and natural language processing .", "tokens": ["deep", "learning", "has", "had", "a", "tremendous", "impact", "in", "several", "fields", ",", "such", "as", "image", "processing", "and", "natural", "language", "processing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has had", "start": 14, "end": 21, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "impact", "start": 35, "end": 41, "i_start": 6, "i_end": 6}}], "id": 733}, {"sent": "deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification among many others .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "already", "achieved", "tremendous", "success", "on", "a", "variety", "of", "computer", "vision", "tasks", "such", "as", "image", "classification", "among", "many", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "achieved", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 68, "end": 75, "i_start": 8, "i_end": 8}}], "id": 734}, {"sent": "this can be achieved by the well-known expectation-maximization algorithm .", "tokens": ["this", "can", "be", "achieved", "by", "the", "well", "-", "known", "expectation", "-", "maximization", "algorithm", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "can be achieved", "start": 5, "end": 20, "i_start": 1, "i_end": 3}}, {"character": {"text": "algorithm", "start": 64, "end": 73, "i_start": 12, "i_end": 12}, "action": {"text": "achieved", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}], "id": 735}, {"sent": "large scale annotated visual datasets have boosted performance of deep learning methods on many challenging computer vision problems .", "tokens": ["large", "scale", "annotated", "visual", "datasets", "have", "boosted", "performance", "of", "deep", "learning", "methods", "on", "many", "challenging", "computer", "vision", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "large scale annotated visual datasets", "start": 0, "end": 37, "i_start": 0, "i_end": 4}, "verb": {"text": "have boosted", "start": 38, "end": 50, "i_start": 5, "i_end": 6}}, {"character": {"text": "datasets", "start": 29, "end": 37, "i_start": 4, "i_end": 4}, "action": {"text": "boosted", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}, {"character": {"text": "methods", "start": 80, "end": 87, "i_start": 11, "i_end": 11}, "action": {"text": "performance", "start": 51, "end": 62, "i_start": 7, "i_end": 7}}, {"character": {"text": "problems", "start": 124, "end": 132, "i_start": 17, "i_end": 17}, "action": {"text": "challenging", "start": 96, "end": 107, "i_start": 14, "i_end": 14}}], "id": 736}, {"sent": "since string theory is a consistent theory of quantum gravity , we can study strings on black hole backgrounds that are asymptotically ads to try and realize that hope .", "tokens": ["since", "string", "theory", "is", "a", "consistent", "theory", "of", "quantum", "gravity", ",", "we", "can", "study", "strings", "on", "black", "hole", "backgrounds", "that", "are", "asymptotically", "ads", "to", "try", "and", "realize", "that", "hope", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 64, "end": 66, "i_start": 11, "i_end": 11}, "verb": {"text": "can study", "start": 67, "end": 76, "i_start": 12, "i_end": 13}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "study", "start": 71, "end": 76, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "try", "start": 142, "end": 145, "i_start": 24, "i_end": 24}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "realize", "start": 150, "end": 157, "i_start": 26, "i_end": 26}}], "id": 737}, {"sent": "recently , generative adversarial networks were used to generate realistic and novel images .", "tokens": ["recently", ",", "generative", "adversarial", "networks", "were", "used", "to", "generate", "realistic", "and", "novel", "images", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 11, "end": 42, "i_start": 2, "i_end": 4}, "verb": {"text": "were used", "start": 43, "end": 52, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 34, "end": 42, "i_start": 4, "i_end": 4}, "action": {"text": "generate", "start": 56, "end": 64, "i_start": 8, "i_end": 8}}], "id": 738}, {"sent": "in recent years , alternative solutions have been proposed to make use of a tactile modality to enhance brain-computer interfacing efficiency .", "tokens": ["in", "recent", "years", ",", "alternative", "solutions", "have", "been", "proposed", "to", "make", "use", "of", "a", "tactile", "modality", "to", "enhance", "brain", "-", "computer", "interfacing", "efficiency", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "alternative solutions", "start": 18, "end": 39, "i_start": 4, "i_end": 5}, "verb": {"text": "have been proposed", "start": 40, "end": 58, "i_start": 6, "i_end": 8}}], "id": 739}, {"sent": "deep convolutional neural networks achieve impressive performance on many computer vision tasks , including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "achieve", "impressive", "performance", "on", "many", "computer", "vision", "tasks", ",", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "achieve", "start": 35, "end": 42, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieve", "start": 35, "end": 42, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 54, "end": 65, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 54, "end": 65, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 43, "end": 53, "i_start": 5, "i_end": 5}}], "id": 740}, {"sent": "precisely , by the trace formula , we can give an estimation for the upper bound such that the non-degeneracy preserves .", "tokens": ["precisely", ",", "by", "the", "trace", "formula", ",", "we", "can", "give", "an", "estimation", "for", "the", "upper", "bound", "such", "that", "the", "non", "-", "degeneracy", "preserves", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 35, "end": 37, "i_start": 7, "i_end": 7}, "verb": {"text": "can give", "start": 38, "end": 46, "i_start": 8, "i_end": 9}}, {"character": {"text": "we", "start": 35, "end": 37, "i_start": 7, "i_end": 7}, "action": {"text": "estimation", "start": 50, "end": 60, "i_start": 11, "i_end": 11}}, {"character": {"text": "-", "start": 98, "end": 99, "i_start": 20, "i_end": 20}, "action": {"text": "preserves", "start": 110, "end": 119, "i_start": 22, "i_end": 22}}], "id": 741}, {"sent": "recent breakthroughs in generative adversarial networks have further improved the quality and photorealism of generated images .", "tokens": ["recent", "breakthroughs", "in", "generative", "adversarial", "networks", "have", "further", "improved", "the", "quality", "and", "photorealism", "of", "generated", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent breakthroughs in generative adversarial networks", "start": 0, "end": 55, "i_start": 0, "i_end": 5}, "verb": {"text": "improved", "start": 69, "end": 77, "i_start": 8, "i_end": 8}}, {"subject": {"text": "recent breakthroughs in generative adversarial networks", "start": 0, "end": 55, "i_start": 0, "i_end": 5}, "verb": {"text": "have", "start": 56, "end": 60, "i_start": 6, "i_end": 6}}, {"character": {"text": "breakthroughs", "start": 7, "end": 20, "i_start": 1, "i_end": 1}, "action": {"text": "improved", "start": 69, "end": 77, "i_start": 8, "i_end": 8}}], "id": 742}, {"sent": "the field \u03c8\u00b5 is then the supersymmetric partner of the graviton , and for this reason it is called gravitino .", "tokens": ["the", "field", "\u03c8\u00b5", "is", "then", "the", "supersymmetric", "partner", "of", "the", "graviton", ",", "and", "for", "this", "reason", "it", "is", "called", "gravitino", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the field", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 86, "end": 88, "i_start": 16, "i_end": 16}, "verb": {"text": "called", "start": 92, "end": 98, "i_start": 18, "i_end": 18}}, {"character": {"text": "field", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "partner", "start": 40, "end": 47, "i_start": 7, "i_end": 7}}], "id": 743}, {"sent": "rsm , a probabilistic undirected topic model , is a generalization of the energy-based restricted boltzmann machines rbm that can be used to model word counts .", "tokens": ["rsm", ",", "a", "probabilistic", "undirected", "topic", "model", ",", "is", "a", "generalization", "of", "the", "energy", "-", "based", "restricted", "boltzmann", "machines", "rbm", "that", "can", "be", "used", "to", "model", "word", "counts", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "rsm", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 47, "end": 49, "i_start": 8, "i_end": 8}}], "id": 744}, {"sent": "and the number of abc blocks generated by each miner in previous 100 blocks , respectively .", "tokens": ["and", "the", "number", "of", "abc", "blocks", "generated", "by", "each", "miner", "in", "previous", "100", "blocks", ",", "respectively", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "each", "start": 42, "end": 46, "i_start": 8, "i_end": 8}, "action": {"text": "generated", "start": 29, "end": 38, "i_start": 6, "i_end": 6}}], "id": 745}, {"sent": "we use adam optimizer in the stochastic gradient descent setting to train all models .", "tokens": ["we", "use", "adam", "optimizer", "in", "the", "stochastic", "gradient", "descent", "setting", "to", "train", "all", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 68, "end": 73, "i_start": 11, "i_end": 11}}], "id": 746}, {"sent": "consider the notations of the second point in the above example .", "tokens": ["consider", "the", "notations", "of", "the", "second", "point", "in", "the", "above", "example", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 747}, {"sent": "advances in deep convolutional networks have led to systems rivaling human accuracy in basic object recognition tasks .", "tokens": ["advances", "in", "deep", "convolutional", "networks", "have", "led", "to", "systems", "rivaling", "human", "accuracy", "in", "basic", "object", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "advances in deep convolutional networks", "start": 0, "end": 39, "i_start": 0, "i_end": 4}, "verb": {"text": "have led", "start": 40, "end": 48, "i_start": 5, "i_end": 6}}, {"character": {"text": "advances", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "led", "start": 45, "end": 48, "i_start": 6, "i_end": 6}}, {"character": {"text": "systems", "start": 52, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "rivaling", "start": 60, "end": 68, "i_start": 9, "i_end": 9}}], "id": 748}, {"sent": "consequently , by , each simple transitive 2-representation of q 3 is equivalent to a cell 2-representation .", "tokens": ["consequently", ",", "by", ",", "each", "simple", "transitive", "2", "-", "representation", "of", "q", "3", "is", "equivalent", "to", "a", "cell", "2", "-", "representation", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "each simple transitive 2-representation of q 3", "start": 20, "end": 66, "i_start": 4, "i_end": 12}, "verb": {"text": "is", "start": 67, "end": 69, "i_start": 13, "i_end": 13}}, {"character": {"text": "transitive", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "2-representation", "start": 43, "end": 59, "i_start": 7, "i_end": 9}}, {"character": {"text": "cell 2", "start": 86, "end": 92, "i_start": 17, "i_end": 18}, "action": {"text": "representation", "start": 93, "end": 107, "i_start": 20, "i_end": 20}}], "id": 749}, {"sent": "the underlying code optimization techniques in the compilers to auto-vectorize the loop nests require careful analysis of data dependences , memory access patterns , etc .", "tokens": ["the", "underlying", "code", "optimization", "techniques", "in", "the", "compilers", "to", "auto", "-", "vectorize", "the", "loop", "nests", "require", "careful", "analysis", "of", "data", "dependences", ",", "memory", "access", "patterns", ",", "etc", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the underlying code optimization techniques in the compilers to auto-vectorize the loop nests", "start": 0, "end": 93, "i_start": 0, "i_end": 14}, "verb": {"text": "require", "start": 94, "end": 101, "i_start": 15, "i_end": 15}}, {"character": {"text": "techniques", "start": 33, "end": 43, "i_start": 4, "i_end": 4}, "action": {"text": "require", "start": 94, "end": 101, "i_start": 15, "i_end": 15}}, {"character": {"text": "techniques", "start": 33, "end": 43, "i_start": 4, "i_end": 4}, "action": {"text": "underlying", "start": 4, "end": 14, "i_start": 1, "i_end": 1}}], "id": 750}, {"sent": "such a spacetime is a solution without any source but with a universal curvature encapsulated in a cosmological constant .", "tokens": ["such", "a", "spacetime", "is", "a", "solution", "without", "any", "source", "but", "with", "a", "universal", "curvature", "encapsulated", "in", "a", "cosmological", "constant", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such a spacetime", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 751}, {"sent": "it has been theoretically proven that an object image under lambertian reflections belongs to a low dimensional subspace .", "tokens": ["it", "has", "been", "theoretically", "proven", "that", "an", "object", "image", "under", "lambertian", "reflections", "belongs", "to", "a", "low", "dimensional", "subspace", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "an object image under lambertian reflections", "start": 38, "end": 82, "i_start": 6, "i_end": 11}, "verb": {"text": "proven", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has been", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "belongs", "start": 83, "end": 90, "i_start": 12, "i_end": 12}}, {"character": {"text": "image", "start": 48, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "belongs", "start": 83, "end": 90, "i_start": 12, "i_end": 12}}], "id": 752}, {"sent": "belyavskaya are not isotopi to quasigroups obtained by the onstru tions proposed by r .", "tokens": ["belyavskaya", "are", "not", "isotopi", "to", "quasigroups", "obtained", "by", "the", "onstru", "tions", "proposed", "by", "r", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "belyavskaya", "start": 0, "end": 11, "i_start": 0, "i_end": 0}, "verb": {"text": "are not", "start": 12, "end": 19, "i_start": 1, "i_end": 2}}], "id": 753}, {"sent": "all convolutional layers are followed by an elu activation and batch normalization .", "tokens": ["all", "convolutional", "layers", "are", "followed", "by", "an", "elu", "activation", "and", "batch", "normalization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all convolutional layers", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "are followed", "start": 25, "end": 37, "i_start": 3, "i_end": 4}}], "id": 754}, {"sent": "neural network-based architectures have recently had great success in significantly advancing the state of the art on challenging image classification and object detection datasets .", "tokens": ["neural", "network", "-", "based", "architectures", "have", "recently", "had", "great", "success", "in", "significantly", "advancing", "the", "state", "of", "the", "art", "on", "challenging", "image", "classification", "and", "object", "detection", "datasets", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural network-based architectures", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "had", "start": 49, "end": 52, "i_start": 7, "i_end": 7}}, {"subject": {"text": "neural network-based architectures", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "architectures", "start": 21, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "architectures", "start": 21, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "advancing", "start": 84, "end": 93, "i_start": 12, "i_end": 12}}, {"character": {"text": "architectures", "start": 21, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "challenging", "start": 118, "end": 129, "i_start": 19, "i_end": 19}}, {"character": {"text": "datasets", "start": 172, "end": 180, "i_start": 25, "i_end": 25}, "action": {"text": "classification", "start": 136, "end": 150, "i_start": 21, "i_end": 21}}], "id": 755}, {"sent": "deep neural networks have set new standards of performance in many machine learning areas such as image classification .", "tokens": ["deep", "neural", "networks", "have", "set", "new", "standards", "of", "performance", "in", "many", "machine", "learning", "areas", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have set", "start": 21, "end": 29, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "set", "start": 26, "end": 29, "i_start": 4, "i_end": 4}}], "id": 756}, {"sent": "we use a similar method as to stitch the two images , and use surf instead of sift to do the feature matching since surf is more efficient than sift .", "tokens": ["we", "use", "a", "similar", "method", "as", "to", "stitch", "the", "two", "images", ",", "and", "use", "surf", "instead", "of", "sift", "to", "do", "the", "feature", "matching", "since", "surf", "is", "more", "efficient", "than", "sift", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 58, "end": 61, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "stitch", "start": 30, "end": 36, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "surf", "start": 62, "end": 66, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "matching", "start": 101, "end": 109, "i_start": 22, "i_end": 22}}], "id": 757}, {"sent": "we showed that the sufficient conditions are indeed necessary conditions for some classes of deterministic networks including aref networks and the linear finite-field deterministic networks .", "tokens": ["we", "showed", "that", "the", "sufficient", "conditions", "are", "indeed", "necessary", "conditions", "for", "some", "classes", "of", "deterministic", "networks", "including", "aref", "networks", "and", "the", "linear", "finite", "-", "field", "deterministic", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "showed", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 41, "end": 44, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "conditions", "start": 30, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "sufficient", "start": 19, "end": 29, "i_start": 4, "i_end": 4}}], "id": 758}, {"sent": "in this section , we review the details of the definitions of multi-context systems presented by brewka and eiter .", "tokens": ["in", "this", "section", ",", "we", "review", "the", "details", "of", "the", "definitions", "of", "multi", "-", "context", "systems", "presented", "by", "brewka", "and", "eiter", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "review", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "review", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "brewka", "start": 97, "end": 103, "i_start": 18, "i_end": 18}, "action": {"text": "presented", "start": 84, "end": 93, "i_start": 16, "i_end": 16}}, {"character": {"text": "eiter", "start": 108, "end": 113, "i_start": 20, "i_end": 20}, "action": {"text": "presented", "start": 84, "end": 93, "i_start": 16, "i_end": 16}}], "id": 759}, {"sent": "this invariance is a left over of the diffeomorphism invariance of the continuous formulation .", "tokens": ["this", "invariance", "is", "a", "left", "over", "of", "the", "diffeomorphism", "invariance", "of", "the", "continuous", "formulation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this invariance", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 760}, {"sent": "a solution pioneered by john von neumann and collaborators and reintroduced by steve smale is to assume a probability measure on the space of data and to study the condition number at data f as a random variable .", "tokens": ["a", "solution", "pioneered", "by", "john", "von", "neumann", "and", "collaborators", "and", "reintroduced", "by", "steve", "smale", "is", "to", "assume", "a", "probability", "measure", "on", "the", "space", "of", "data", "and", "to", "study", "the", "condition", "number", "at", "data", "f", "as", "a", "random", "variable", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "a solution pioneered by john von neumann and collaborators and reintroduced by steve smale", "start": 0, "end": 90, "i_start": 0, "i_end": 13}, "verb": {"text": "is", "start": 91, "end": 93, "i_start": 14, "i_end": 14}}, {"character": {"text": "john von neumann", "start": 24, "end": 40, "i_start": 4, "i_end": 6}, "action": {"text": "pioneered", "start": 11, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "steve smale", "start": 79, "end": 90, "i_start": 12, "i_end": 13}, "action": {"text": "reintroduced", "start": 63, "end": 75, "i_start": 10, "i_end": 10}}], "id": 761}, {"sent": "for textual entailment , we use the stanford natural language inference dataset .", "tokens": ["for", "textual", "entailment", ",", "we", "use", "the", "stanford", "natural", "language", "inference", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 25, "end": 27, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 28, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 28, "end": 31, "i_start": 5, "i_end": 5}}], "id": 762}, {"sent": "naturally , the stable solution is the one that minimizes the grand-canonical free energy .", "tokens": ["naturally", ",", "the", "stable", "solution", "is", "the", "one", "that", "minimizes", "the", "grand", "-", "canonical", "free", "energy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the stable solution", "start": 12, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 5, "i_end": 5}}, {"character": {"text": "one", "start": 39, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "minimizes", "start": 48, "end": 57, "i_start": 9, "i_end": 9}}], "id": 763}, {"sent": "whittle proposed a gittins-like heuristic index policy for restless bandit problems .", "tokens": ["whittle", "proposed", "a", "gittins", "-", "like", "heuristic", "index", "policy", "for", "restless", "bandit", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "whittle", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 8, "end": 16, "i_start": 1, "i_end": 1}}], "id": 764}, {"sent": "pioneering work in this direction has been done by hong and li , who coined the name laplace spectrum .", "tokens": ["pioneering", "work", "in", "this", "direction", "has", "been", "done", "by", "hong", "and", "li", ",", "who", "coined", "the", "name", "laplace", "spectrum", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "pioneering work in this direction", "start": 0, "end": 33, "i_start": 0, "i_end": 4}, "verb": {"text": "has been done", "start": 34, "end": 47, "i_start": 5, "i_end": 7}}, {"character": {"text": "li", "start": 60, "end": 62, "i_start": 11, "i_end": 11}, "action": {"text": "work", "start": 11, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "laplace", "start": 85, "end": 92, "i_start": 17, "i_end": 17}, "action": {"text": "work", "start": 11, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "and", "start": 56, "end": 59, "i_start": 10, "i_end": 10}, "action": {"text": "coined", "start": 69, "end": 75, "i_start": 14, "i_end": 14}}, {"character": {"text": "work", "start": 11, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "pioneering", "start": 0, "end": 10, "i_start": 0, "i_end": 0}}], "id": 765}, {"sent": "abelian extensions having characterised suitable module categories , we may now study extensions of racks and quandles by these objects .", "tokens": ["abelian", "extensions", "having", "characterised", "suitable", "module", "categories", ",", "we", "may", "now", "study", "extensions", "of", "racks", "and", "quandles", "by", "these", "objects", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "abelian extensions having characterised suitable module categories , we", "start": 0, "end": 71, "i_start": 0, "i_end": 8}, "verb": {"text": "study", "start": 80, "end": 85, "i_start": 11, "i_end": 11}}, {"subject": {"text": "abelian extensions having characterised suitable module categories , we", "start": 0, "end": 71, "i_start": 0, "i_end": 8}, "verb": {"text": "may", "start": 72, "end": 75, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 69, "end": 71, "i_start": 8, "i_end": 8}, "action": {"text": "study", "start": 80, "end": 85, "i_start": 11, "i_end": 11}}, {"character": {"text": "objects", "start": 128, "end": 135, "i_start": 19, "i_end": 19}, "action": {"text": "extensions", "start": 8, "end": 18, "i_start": 1, "i_end": 1}}], "id": 766}, {"sent": "from early hugo , the past few years witnessed the flourish of additive schemes in spatial domain .", "tokens": ["from", "early", "hugo", ",", "the", "past", "few", "years", "witnessed", "the", "flourish", "of", "additive", "schemes", "in", "spatial", "domain", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the past few years", "start": 18, "end": 36, "i_start": 4, "i_end": 7}, "verb": {"text": "witnessed", "start": 37, "end": 46, "i_start": 8, "i_end": 8}}, {"character": {"text": "few", "start": 27, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "witnessed", "start": 37, "end": 46, "i_start": 8, "i_end": 8}}, {"character": {"text": "schemes", "start": 72, "end": 79, "i_start": 13, "i_end": 13}, "action": {"text": "flourish", "start": 51, "end": 59, "i_start": 10, "i_end": 10}}], "id": 767}, {"sent": "multitaper methods involve the use of multiple data tapers for spectral estimation .", "tokens": ["multitaper", "methods", "involve", "the", "use", "of", "multiple", "data", "tapers", "for", "spectral", "estimation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "multitaper methods", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "involve", "start": 19, "end": 26, "i_start": 2, "i_end": 2}}], "id": 768}, {"sent": "we will see that this index indeed counts the number of zero-modes .", "tokens": ["we", "will", "see", "that", "this", "index", "indeed", "counts", "the", "number", "of", "zero", "-", "modes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will see", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"subject": {"text": "this index", "start": 17, "end": 27, "i_start": 4, "i_end": 5}, "verb": {"text": "counts", "start": 35, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "see", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "index", "start": 22, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "counts", "start": 35, "end": 41, "i_start": 7, "i_end": 7}}], "id": 769}, {"sent": "the ion channels are formed by special membrane proteins which undergo spontaneous , but voltage-sensitive conformational transitions between open and closed states .", "tokens": ["the", "ion", "channels", "are", "formed", "by", "special", "membrane", "proteins", "which", "undergo", "spontaneous", ",", "but", "voltage", "-", "sensitive", "conformational", "transitions", "between", "open", "and", "closed", "states", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ion channels", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "are formed", "start": 17, "end": 27, "i_start": 3, "i_end": 4}}, {"character": {"text": "proteins", "start": 48, "end": 56, "i_start": 8, "i_end": 8}, "action": {"text": "formed", "start": 21, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "transitions", "start": 122, "end": 133, "i_start": 18, "i_end": 18}, "action": {"text": "sensitive", "start": 97, "end": 106, "i_start": 16, "i_end": 16}}], "id": 770}, {"sent": "in other words , the set sw is the structure space of the generalized simple lie algebras of witt type in the form .", "tokens": ["in", "other", "words", ",", "the", "set", "sw", "is", "the", "structure", "space", "of", "the", "generalized", "simple", "lie", "algebras", "of", "witt", "type", "in", "the", "form", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the set sw", "start": 17, "end": 27, "i_start": 4, "i_end": 6}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 7, "i_end": 7}}], "id": 771}, {"sent": "the usage of dropout in the network reduces the overfitting of the model over training samples .", "tokens": ["the", "usage", "of", "dropout", "in", "the", "network", "reduces", "the", "overfitting", "of", "the", "model", "over", "training", "samples", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the usage of dropout in the network", "start": 0, "end": 35, "i_start": 0, "i_end": 6}, "verb": {"text": "reduces", "start": 36, "end": 43, "i_start": 7, "i_end": 7}}], "id": 772}, {"sent": "however , again the chemical potential is a valuable source of information .", "tokens": ["however", ",", "again", "the", "chemical", "potential", "is", "a", "valuable", "source", "of", "information", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the chemical potential", "start": 16, "end": 38, "i_start": 3, "i_end": 5}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "potential", "start": 29, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "source", "start": 53, "end": 59, "i_start": 9, "i_end": 9}}], "id": 773}, {"sent": "indeed , as shown in , they can always be written as the direct sum of abelian lie 3-algebras plus multiple copies of the unique simple euclidean lie 3-algebra s 0,4 considered by bagger and lambert in their original construction .", "tokens": ["indeed", ",", "as", "shown", "in", ",", "they", "can", "always", "be", "written", "as", "the", "direct", "sum", "of", "abelian", "lie", "3", "-", "algebras", "plus", "multiple", "copies", "of", "the", "unique", "simple", "euclidean", "lie", "3", "-", "algebra", "s", "0,4", "considered", "by", "bagger", "and", "lambert", "in", "their", "original", "construction", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 23, "end": 27, "i_start": 6, "i_end": 6}, "verb": {"text": "be written", "start": 39, "end": 49, "i_start": 9, "i_end": 10}}, {"subject": {"text": "they", "start": 23, "end": 27, "i_start": 6, "i_end": 6}, "verb": {"text": "can", "start": 28, "end": 31, "i_start": 7, "i_end": 7}}, {"character": {"text": "bagger", "start": 180, "end": 186, "i_start": 37, "i_end": 37}, "action": {"text": "considered", "start": 166, "end": 176, "i_start": 35, "i_end": 35}}, {"character": {"text": "lambert", "start": 191, "end": 198, "i_start": 39, "i_end": 39}, "action": {"text": "considered", "start": 166, "end": 176, "i_start": 35, "i_end": 35}}], "id": 774}, {"sent": "convolutional neural networks have achieved impressive state-of-the-art results on image classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "impressive", "state", "-", "of", "-", "the", "-", "art", "results", "on", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "results", "start": 72, "end": 79, "i_start": 13, "i_end": 13}, "action": {"text": "impressive", "start": 44, "end": 54, "i_start": 5, "i_end": 5}}], "id": 775}, {"sent": "deep neural networks have significantly improved the state of the art on many supervised tasks .", "tokens": ["deep", "neural", "networks", "have", "significantly", "improved", "the", "state", "of", "the", "art", "on", "many", "supervised", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}], "id": 776}, {"sent": "generative adversarial networks are a subclass of generative models that have received a lot of attention because of their ability to generate realistic high quality images .", "tokens": ["generative", "adversarial", "networks", "are", "a", "subclass", "of", "generative", "models", "that", "have", "received", "a", "lot", "of", "attention", "because", "of", "their", "ability", "to", "generate", "realistic", "high", "quality", "images", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "received", "start": 78, "end": 86, "i_start": 11, "i_end": 11}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "generate", "start": 134, "end": 142, "i_start": 21, "i_end": 21}}], "id": 777}, {"sent": "several sophisticated cnn architectures have been proposed in the last decade , for example alexnet , etc .", "tokens": ["several", "sophisticated", "cnn", "architectures", "have", "been", "proposed", "in", "the", "last", "decade", ",", "for", "example", "alexnet", ",", "etc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "several sophisticated cnn architectures", "start": 0, "end": 39, "i_start": 0, "i_end": 3}, "verb": {"text": "have been proposed", "start": 40, "end": 58, "i_start": 4, "i_end": 6}}], "id": 778}, {"sent": "along with the success of cnns in classification , cnnbased approaches have shown remarkable improvements in various computer vision applications .", "tokens": ["along", "with", "the", "success", "of", "cnns", "in", "classification", ",", "cnnbased", "approaches", "have", "shown", "remarkable", "improvements", "in", "various", "computer", "vision", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "cnnbased approaches", "start": 51, "end": 70, "i_start": 9, "i_end": 10}, "verb": {"text": "have shown", "start": 71, "end": 81, "i_start": 11, "i_end": 12}}, {"character": {"text": "approaches", "start": 60, "end": 70, "i_start": 10, "i_end": 10}, "action": {"text": "shown", "start": 76, "end": 81, "i_start": 12, "i_end": 12}}], "id": 779}, {"sent": "convolutional neural networks have shown its great effectiveness in computer vision tasks .", "tokens": ["convolutional", "neural", "networks", "have", "shown", "its", "great", "effectiveness", "in", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 35, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "effectiveness", "start": 51, "end": 64, "i_start": 7, "i_end": 7}}], "id": 780}, {"sent": "a non-parametric approach using kernel density estimation technique was proposed in , which estimates the probability density function at each pixel from many samples without any prior assumptions .", "tokens": ["a", "non", "-", "parametric", "approach", "using", "kernel", "density", "estimation", "technique", "was", "proposed", "in", ",", "which", "estimates", "the", "probability", "density", "function", "at", "each", "pixel", "from", "many", "samples", "without", "any", "prior", "assumptions", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "a non-parametric approach using kernel density estimation technique", "start": 0, "end": 67, "i_start": 0, "i_end": 9}, "verb": {"text": "was proposed", "start": 68, "end": 80, "i_start": 10, "i_end": 11}}, {"character": {"text": "approach", "start": 17, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "using", "start": 26, "end": 31, "i_start": 5, "i_end": 5}}], "id": 781}, {"sent": "nevertheless , all evaluations of the shear and bulk viscosities obtained in the framework of the relaxation time approximation can be considered only as rough estimations .", "tokens": ["nevertheless", ",", "all", "evaluations", "of", "the", "shear", "and", "bulk", "viscosities", "obtained", "in", "the", "framework", "of", "the", "relaxation", "time", "approximation", "can", "be", "considered", "only", "as", "rough", "estimations", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "all evaluations of the shear and bulk viscosities obtained in the framework of the relaxation time approximation", "start": 15, "end": 127, "i_start": 2, "i_end": 18}, "verb": {"text": "can be considered", "start": 128, "end": 145, "i_start": 19, "i_end": 21}}], "id": 782}, {"sent": "the exchange-correlation was treated in the generalized gradient approximation after perdew-burke-ernzerhof .", "tokens": ["the", "exchange", "-", "correlation", "was", "treated", "in", "the", "generalized", "gradient", "approximation", "after", "perdew", "-", "burke", "-", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange-correlation", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "was treated", "start": 25, "end": 36, "i_start": 4, "i_end": 5}}], "id": 783}, {"sent": "the electron-electron interaction was treated with a generalized gradient approximation proposed by perdew , burke , and ernzerhof .", "tokens": ["the", "electron", "-", "electron", "interaction", "was", "treated", "with", "a", "generalized", "gradient", "approximation", "proposed", "by", "perdew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electron-electron interaction", "start": 0, "end": 33, "i_start": 0, "i_end": 4}, "verb": {"text": "was treated", "start": 34, "end": 45, "i_start": 5, "i_end": 6}}, {"character": {"text": "electron", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "interaction", "start": 22, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "perdew", "start": 100, "end": 106, "i_start": 14, "i_end": 14}, "action": {"text": "proposed", "start": 88, "end": 96, "i_start": 12, "i_end": 12}}, {"character": {"text": "burke", "start": 109, "end": 114, "i_start": 16, "i_end": 16}, "action": {"text": "proposed", "start": 88, "end": 96, "i_start": 12, "i_end": 12}}, {"character": {"text": "ernzerhof", "start": 121, "end": 130, "i_start": 19, "i_end": 19}, "action": {"text": "proposed", "start": 88, "end": 96, "i_start": 12, "i_end": 12}}], "id": 784}, {"sent": "lately , a large body of successful deep generative models have emerged , especially generative adversarial networks .", "tokens": ["lately", ",", "a", "large", "body", "of", "successful", "deep", "generative", "models", "have", "emerged", ",", "especially", "generative", "adversarial", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a large body of successful deep generative models", "start": 9, "end": 58, "i_start": 2, "i_end": 9}, "verb": {"text": "have emerged", "start": 59, "end": 71, "i_start": 10, "i_end": 11}}, {"character": {"text": "body", "start": 17, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "emerged", "start": 64, "end": 71, "i_start": 11, "i_end": 11}}], "id": 785}, {"sent": "d eep convolutional neural networks have achieved great success in many computer vision tasks , especially in visual recognition .", "tokens": ["d", "eep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "many", "computer", "vision", "tasks", ",", "especially", "in", "visual", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "d eep convolutional neural networks", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "have achieved", "start": 36, "end": 49, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 27, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 41, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 27, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "success", "start": 56, "end": 63, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 27, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "recognition", "start": 117, "end": 128, "i_start": 18, "i_end": 18}}], "id": 786}, {"sent": "liu et al proposed the nonparanormal distribution , which is a nonparametric extension of the normal distribution .", "tokens": ["liu", "et", "al", "proposed", "the", "nonparanormal", "distribution", ",", "which", "is", "a", "nonparametric", "extension", "of", "the", "normal", "distribution", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "liu et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "liu", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}], "id": 787}, {"sent": "a case study shows that google developers perform an average of 12 code search queries each weekday .", "tokens": ["a", "case", "study", "shows", "that", "google", "developers", "perform", "an", "average", "of", "12", "code", "search", "queries", "each", "weekday", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a case study", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "shows", "start": 13, "end": 18, "i_start": 3, "i_end": 3}}, {"subject": {"text": "google developers", "start": 24, "end": 41, "i_start": 5, "i_end": 6}, "verb": {"text": "perform", "start": 42, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "study", "start": 7, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "shows", "start": 13, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "google", "start": 24, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "perform", "start": 42, "end": 49, "i_start": 7, "i_end": 7}}], "id": 788}, {"sent": "hansen , cummings , and clements employed speech under simulated and actual stress database in which eight talking conditions are used to simulate speech uttered under real stressful talking conditions and three real talking conditions .", "tokens": ["hansen", ",", "cummings", ",", "and", "clements", "employed", "speech", "under", "simulated", "and", "actual", "stress", "database", "in", "which", "eight", "talking", "conditions", "are", "used", "to", "simulate", "speech", "uttered", "under", "real", "stressful", "talking", "conditions", "and", "three", "real", "talking", "conditions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hansen", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "employed", "start": 33, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "hansen", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "employed", "start": 33, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "cummings", "start": 9, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "employed", "start": 33, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "clements", "start": 24, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "employed", "start": 33, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "eight talking conditions", "start": 101, "end": 125, "i_start": 16, "i_end": 18}, "action": {"text": "simulate", "start": 138, "end": 146, "i_start": 22, "i_end": 22}}, {"character": {"text": "conditions", "start": 191, "end": 201, "i_start": 29, "i_end": 29}, "action": {"text": "stressful", "start": 173, "end": 182, "i_start": 27, "i_end": 27}}], "id": 789}, {"sent": "convolutional neural networks have achieved superior performance in many visual tasks , such as object detection and segmentation .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "detection", "and", "segmentation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 6, "i_end": 6}}], "id": 790}, {"sent": "finally , several techniques for creating more efficient neural network models have previously been proposed , such as quantization .", "tokens": ["finally", ",", "several", "techniques", "for", "creating", "more", "efficient", "neural", "network", "models", "have", "previously", "been", "proposed", ",", "such", "as", "quantization", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "several techniques for creating more efficient neural network models", "start": 10, "end": 78, "i_start": 2, "i_end": 10}, "verb": {"text": "been proposed", "start": 95, "end": 108, "i_start": 13, "i_end": 14}}, {"subject": {"text": "several techniques for creating more efficient neural network models", "start": 10, "end": 78, "i_start": 2, "i_end": 10}, "verb": {"text": "have", "start": 79, "end": 83, "i_start": 11, "i_end": 11}}], "id": 791}, {"sent": "chpt derivations of gp in the years since the original derivations of the goldberger-treiman relation there have been major advances in our understanding of the way to include chiral symmetry in such analyses , particularly in the framework of what is known as chiral perturbation theory .", "tokens": ["chpt", "derivations", "of", "gp", "in", "the", "years", "since", "the", "original", "derivations", "of", "the", "goldberger", "-", "treiman", "relation", "there", "have", "been", "major", "advances", "in", "our", "understanding", "of", "the", "way", "to", "include", "chiral", "symmetry", "in", "such", "analyses", ",", "particularly", "in", "the", "framework", "of", "what", "is", "known", "as", "chiral", "perturbation", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 792}, {"sent": "the generalized gradient approximation parameterized by perdew-burke-ernzerhof is utilized to describe exchange-correlation functional .", "tokens": ["the", "generalized", "gradient", "approximation", "parameterized", "by", "perdew", "-", "burke", "-", "ernzerhof", "is", "utilized", "to", "describe", "exchange", "-", "correlation", "functional", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation parameterized by perdew-burke-ernzerhof", "start": 0, "end": 78, "i_start": 0, "i_end": 10}, "verb": {"text": "is utilized", "start": 79, "end": 90, "i_start": 11, "i_end": 12}}, {"character": {"text": "perdew", "start": 56, "end": 62, "i_start": 6, "i_end": 6}, "action": {"text": "parameterized", "start": 39, "end": 52, "i_start": 4, "i_end": 4}}, {"character": {"text": "approximation", "start": 25, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "describe", "start": 94, "end": 102, "i_start": 14, "i_end": 14}}, {"character": {"text": "exchange", "start": 103, "end": 111, "i_start": 15, "i_end": 15}, "action": {"text": "functional", "start": 124, "end": 134, "i_start": 18, "i_end": 18}}], "id": 793}, {"sent": "the present experiments thus show that the oxygen-isotope effects observed in the argon annealed samples are not reliable , and that the normal isotope exchange procedure can ensure the same oxygen content for two isotope samples .", "tokens": ["the", "present", "experiments", "thus", "show", "that", "the", "oxygen", "-", "isotope", "effects", "observed", "in", "the", "argon", "annealed", "samples", "are", "not", "reliable", ",", "and", "that", "the", "normal", "isotope", "exchange", "procedure", "can", "ensure", "the", "same", "oxygen", "content", "for", "two", "isotope", "samples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the present experiments", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "show", "start": 29, "end": 33, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the present experiments", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 105, "end": 108, "i_start": 17, "i_end": 17}}, {"character": {"text": "experiments", "start": 12, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 29, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "samples", "start": 97, "end": 104, "i_start": 16, "i_end": 16}, "action": {"text": "observed", "start": 66, "end": 74, "i_start": 11, "i_end": 11}}, {"character": {"text": "procedure", "start": 161, "end": 170, "i_start": 27, "i_end": 27}, "action": {"text": "ensure", "start": 175, "end": 181, "i_start": 29, "i_end": 29}}], "id": 794}, {"sent": "in 1931 , dirac showed that electric charge quantisation could be explained as a natural consequence of angular momentum quantisation if one assumes the existence of magnetic monopoles .", "tokens": ["in", "1931", ",", "dirac", "showed", "that", "electric", "charge", "quantisation", "could", "be", "explained", "as", "a", "natural", "consequence", "of", "angular", "momentum", "quantisation", "if", "one", "assumes", "the", "existence", "of", "magnetic", "monopoles", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "dirac", "start": 10, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "showed", "start": 16, "end": 22, "i_start": 4, "i_end": 4}}, {"subject": {"text": "electric charge quantisation", "start": 28, "end": 56, "i_start": 6, "i_end": 8}, "verb": {"text": "explained", "start": 66, "end": 75, "i_start": 11, "i_end": 11}}, {"character": {"text": "dirac", "start": 10, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "showed", "start": 16, "end": 22, "i_start": 4, "i_end": 4}}, {"character": {"text": "one", "start": 137, "end": 140, "i_start": 21, "i_end": 21}, "action": {"text": "assumes", "start": 141, "end": 148, "i_start": 22, "i_end": 22}}], "id": 795}, {"sent": "the right column provides four rotation-curve mass decompositions .", "tokens": ["the", "right", "column", "provides", "four", "rotation", "-", "curve", "mass", "decompositions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the right column", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "provides", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "column", "start": 10, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "provides", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}], "id": 796}, {"sent": "it is thus of great interest whether the additivity principles can be extended to higher dimensions .", "tokens": ["it", "is", "thus", "of", "great", "interest", "whether", "the", "additivity", "principles", "can", "be", "extended", "to", "higher", "dimensions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the additivity principles", "start": 37, "end": 62, "i_start": 7, "i_end": 9}, "verb": {"text": "extended", "start": 70, "end": 78, "i_start": 12, "i_end": 12}}], "id": 797}, {"sent": "then the proof can be reduced to the case with a bounded domain , which was considered in .", "tokens": ["then", "the", "proof", "can", "be", "reduced", "to", "the", "case", "with", "a", "bounded", "domain", ",", "which", "was", "considered", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the proof", "start": 5, "end": 14, "i_start": 1, "i_end": 2}, "verb": {"text": "can be reduced", "start": 15, "end": 29, "i_start": 3, "i_end": 5}}], "id": 798}, {"sent": "in fact , in densely deployed networks , the data transmit power may be only a small part of the total power consumption according to 5g visions .", "tokens": ["in", "fact", ",", "in", "densely", "deployed", "networks", ",", "the", "data", "transmit", "power", "may", "be", "only", "a", "small", "part", "of", "the", "total", "power", "consumption", "according", "to", "5", "g", "visions", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "in densely deployed networks", "start": 10, "end": 38, "i_start": 3, "i_end": 6}, "verb": {"text": "may be", "start": 65, "end": 71, "i_start": 12, "i_end": 13}}, {"character": {"text": "power", "start": 59, "end": 64, "i_start": 11, "i_end": 11}, "action": {"text": "transmit", "start": 50, "end": 58, "i_start": 10, "i_end": 10}}], "id": 799}, {"sent": "gong et al proposed a selfsupervised structure-sensitive learning approach , which imposes human pose structures to parsing results without resorting to extra supervision .", "tokens": ["gong", "et", "al", "proposed", "a", "selfsupervised", "structure", "-", "sensitive", "learning", "approach", ",", "which", "imposes", "human", "pose", "structures", "to", "parsing", "results", "without", "resorting", "to", "extra", "supervision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "gong et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "gong", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "approach", "start": 66, "end": 74, "i_start": 10, "i_end": 10}, "action": {"text": "sensitive", "start": 47, "end": 56, "i_start": 8, "i_end": 8}}, {"character": {"text": "selfsupervised", "start": 22, "end": 36, "i_start": 5, "i_end": 5}, "action": {"text": "supervision", "start": 159, "end": 170, "i_start": 24, "i_end": 24}}, {"character": {"text": "approach", "start": 66, "end": 74, "i_start": 10, "i_end": 10}, "action": {"text": "imposes", "start": 83, "end": 90, "i_start": 13, "i_end": 13}}], "id": 800}, {"sent": "the effects of nonlinear non-gaussian inhomogeneities and primordial black hole formation .", "tokens": ["the", "effects", "of", "nonlinear", "non", "-", "gaussian", "inhomogeneities", "and", "primordial", "black", "hole", "formation", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 801}, {"sent": "the evolution equations for the spacetime and the fluid are described in our previous paper .", "tokens": ["the", "evolution", "equations", "for", "the", "spacetime", "and", "the", "fluid", "are", "described", "in", "our", "previous", "paper", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "the evolution equations for the spacetime and the fluid", "start": 0, "end": 55, "i_start": 0, "i_end": 8}, "verb": {"text": "are described", "start": 56, "end": 69, "i_start": 9, "i_end": 10}}, {"character": {"text": "paper", "start": 86, "end": 91, "i_start": 14, "i_end": 14}, "action": {"text": "described", "start": 60, "end": 69, "i_start": 10, "i_end": 10}}], "id": 802}, {"sent": "we use large-scale celebfaces attributes dataset for facial attribute estimation , which contains 202 , 599 images and 10 , 177 identities .", "tokens": ["we", "use", "large", "-", "scale", "celebfaces", "attributes", "dataset", "for", "facial", "attribute", "estimation", ",", "which", "contains", "202", ",", "599", "images", "and", "10", ",", "177", "identities", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "attributes", "start": 30, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "dataset", "start": 41, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "contains", "start": 89, "end": 97, "i_start": 14, "i_end": 14}}], "id": 803}, {"sent": "we use magnetotunneling spectroscopy to observe the spin splitting of the ground state of an x-valley-related si-donor impurity in an alas barrier .", "tokens": ["we", "use", "magnetotunneling", "spectroscopy", "to", "observe", "the", "spin", "splitting", "of", "the", "ground", "state", "of", "an", "x", "-", "valley", "-", "related", "si", "-", "donor", "impurity", "in", "an", "alas", "barrier", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "observe", "start": 40, "end": 47, "i_start": 5, "i_end": 5}}], "id": 804}, {"sent": "neural network learning has become a key practical machine learning approach and has achieved remarkable success in a wide range of real-world domains , such as computer vision , speech recognition , and game playing .", "tokens": ["neural", "network", "learning", "has", "become", "a", "key", "practical", "machine", "learning", "approach", "and", "has", "achieved", "remarkable", "success", "in", "a", "wide", "range", "of", "real", "-", "world", "domains", ",", "such", "as", "computer", "vision", ",", "speech", "recognition", ",", "and", "game", "playing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural network learning", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "has become", "start": 24, "end": 34, "i_start": 3, "i_end": 4}}, {"subject": {"text": "neural network learning", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 85, "end": 93, "i_start": 13, "i_end": 13}}, {"character": {"text": "learning", "start": 15, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 105, "end": 112, "i_start": 15, "i_end": 15}}], "id": 805}, {"sent": "the packing chromatic number was introduced by goddard et al in 2008 under the name broadcast chromatic number , and has been investigated by a number of authors .", "tokens": ["the", "packing", "chromatic", "number", "was", "introduced", "by", "goddard", "et", "al", "in", "2008", "under", "the", "name", "broadcast", "chromatic", "number", ",", "and", "has", "been", "investigated", "by", "a", "number", "of", "authors", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the packing chromatic number", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "was introduced", "start": 29, "end": 43, "i_start": 4, "i_end": 5}}, {"subject": {"text": "the packing chromatic number", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "investigated", "start": 126, "end": 138, "i_start": 22, "i_end": 22}}, {"character": {"text": "goddard", "start": 47, "end": 54, "i_start": 7, "i_end": 7}, "action": {"text": "introduced", "start": 33, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "number", "start": 144, "end": 150, "i_start": 25, "i_end": 25}, "action": {"text": "investigated", "start": 126, "end": 138, "i_start": 22, "i_end": 22}}], "id": 806}, {"sent": "deep learning has brought significant breakthroughs in many computer vision tasks , including object detection .", "tokens": ["deep", "learning", "has", "brought", "significant", "breakthroughs", "in", "many", "computer", "vision", "tasks", ",", "including", "object", "detection", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has brought", "start": 14, "end": 25, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "breakthroughs", "start": 38, "end": 51, "i_start": 5, "i_end": 5}}], "id": 807}, {"sent": "those if a markov chain consist of a single chains can be studied separately .", "tokens": ["those", "if", "a", "markov", "chain", "consist", "of", "a", "single", "chains", "can", "be", "studied", "separately", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "those if a markov chain consist of a single chains", "start": 0, "end": 50, "i_start": 0, "i_end": 9}, "verb": {"text": "can be studied", "start": 51, "end": 65, "i_start": 10, "i_end": 12}}], "id": 808}, {"sent": "a palette is a finite set of tiles with copies of which one can tile the plane so that adjacent edges match in colors .", "tokens": ["a", "palette", "is", "a", "finite", "set", "of", "tiles", "with", "copies", "of", "which", "one", "can", "tile", "the", "plane", "so", "that", "adjacent", "edges", "match", "in", "colors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a palette", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "one", "start": 56, "end": 59, "i_start": 12, "i_end": 12}, "action": {"text": "tile", "start": 64, "end": 68, "i_start": 14, "i_end": 14}}], "id": 809}, {"sent": "mean transverse freeze-out radii for different hadron species at sps , rhic and lhc .", "tokens": ["mean", "transverse", "freeze", "-", "out", "radii", "for", "different", "hadron", "species", "at", "sps", ",", "rhic", "and", "lhc", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 810}, {"sent": "preliminaries an alphabet a is a finite set of symbols , called letters .", "tokens": ["preliminaries", "an", "alphabet", "a", "is", "a", "finite", "set", "of", "symbols", ",", "called", "letters", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "preliminaries an alphabet a", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 4, "i_end": 4}}], "id": 811}, {"sent": "particles carrying the new forms of quantum statistics , are called generically anyons .", "tokens": ["particles", "carrying", "the", "new", "forms", "of", "quantum", "statistics", ",", "are", "called", "generically", "anyons", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "particles carrying the new forms of quantum statistics", "start": 0, "end": 54, "i_start": 0, "i_end": 7}, "verb": {"text": "are called", "start": 57, "end": 67, "i_start": 9, "i_end": 10}}, {"character": {"text": "particles", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "carrying", "start": 10, "end": 18, "i_start": 1, "i_end": 1}}], "id": 812}, {"sent": "however , the behavior of the charge conjugation symmetry is the same as that at zero temperature .", "tokens": ["however", ",", "the", "behavior", "of", "the", "charge", "conjugation", "symmetry", "is", "the", "same", "as", "that", "at", "zero", "temperature", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the behavior of the charge conjugation symmetry", "start": 10, "end": 57, "i_start": 2, "i_end": 8}, "verb": {"text": "is", "start": 58, "end": 60, "i_start": 9, "i_end": 9}}, {"character": {"text": "symmetry", "start": 49, "end": 57, "i_start": 8, "i_end": 8}, "action": {"text": "behavior", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}], "id": 813}, {"sent": "deep neural networks , particularly deep convolutional neural networks , have provided significant improvement in visual tasks such as face recognition , attribute prediction and image classification .", "tokens": ["deep", "neural", "networks", ",", "particularly", "deep", "convolutional", "neural", "networks", ",", "have", "provided", "significant", "improvement", "in", "visual", "tasks", "such", "as", "face", "recognition", ",", "attribute", "prediction", "and", "image", "classification", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have provided", "start": 73, "end": 86, "i_start": 10, "i_end": 11}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "attribute", "start": 154, "end": 163, "i_start": 22, "i_end": 22}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improvement", "start": 99, "end": 110, "i_start": 13, "i_end": 13}}], "id": 814}, {"sent": "for convenience of notation , we shall denote a section of v and set if a metric extension has been chosen then .", "tokens": ["for", "convenience", "of", "notation", ",", "we", "shall", "denote", "a", "section", "of", "v", "and", "set", "if", "a", "metric", "extension", "has", "been", "chosen", "then", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "verb": {"text": "shall denote", "start": 33, "end": 45, "i_start": 6, "i_end": 7}}, {"subject": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "verb": {"text": "set", "start": 65, "end": 68, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "denote", "start": 39, "end": 45, "i_start": 7, "i_end": 7}}], "id": 815}, {"sent": "in the decoding module , we use a fully convolutional network with residual connections .", "tokens": ["in", "the", "decoding", "module", ",", "we", "use", "a", "fully", "convolutional", "network", "with", "residual", "connections", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 28, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 28, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "module", "start": 16, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "decoding", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}], "id": 816}, {"sent": "all phase transition lines are of second order .", "tokens": ["all", "phase", "transition", "lines", "are", "of", "second", "order", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all phase transition lines", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 27, "end": 30, "i_start": 4, "i_end": 4}}], "id": 817}, {"sent": "a schematic outline of the relationship between univariate eof and climate network analysis in the spirit of the diagrams in bretherton et al .", "tokens": ["a", "schematic", "outline", "of", "the", "relationship", "between", "univariate", "eof", "and", "climate", "network", "analysis", "in", "the", "spirit", "of", "the", "diagrams", "in", "bretherton", "et", "al", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "analysis", "start": 83, "end": 91, "i_start": 12, "i_end": 12}, "action": {"text": "relationship", "start": 27, "end": 39, "i_start": 5, "i_end": 5}}], "id": 818}, {"sent": "in this section , we consider the contribution to the photocurrent arising from this change in fnk .", "tokens": ["in", "this", "section", ",", "we", "consider", "the", "contribution", "to", "the", "photocurrent", "arising", "from", "this", "change", "in", "fnk", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "consider", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the contribution to the photocurrent", "start": 30, "end": 66, "i_start": 6, "i_end": 10}, "verb": {"text": "arising", "start": 67, "end": 74, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "consider", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "change", "start": 85, "end": 91, "i_start": 14, "i_end": 14}, "action": {"text": "arising", "start": 67, "end": 74, "i_start": 11, "i_end": 11}}], "id": 819}, {"sent": "for these two image datasets , we use the fc8 layer of the vgg-19 network pretrained on the imagenet dataset as the feature extractor .", "tokens": ["for", "these", "two", "image", "datasets", ",", "we", "use", "the", "fc8", "layer", "of", "the", "vgg-19", "network", "pretrained", "on", "the", "imagenet", "dataset", "as", "the", "feature", "extractor", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 31, "end": 33, "i_start": 6, "i_end": 6}, "verb": {"text": "use", "start": 34, "end": 37, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 6, "i_end": 6}, "action": {"text": "use", "start": 34, "end": 37, "i_start": 7, "i_end": 7}}, {"character": {"text": "layer", "start": 46, "end": 51, "i_start": 10, "i_end": 10}, "action": {"text": "extractor", "start": 124, "end": 133, "i_start": 23, "i_end": 23}}], "id": 820}, {"sent": "1the submillimeter array is a joint project between the smithsonian astrophysical observatory and the academia sinica institute of astronomy and astrophysics , and is funded by the smithsonian institution and the academia sinica .", "tokens": ["1the", "submillimeter", "array", "is", "a", "joint", "project", "between", "the", "smithsonian", "astrophysical", "observatory", "and", "the", "academia", "sinica", "institute", "of", "astronomy", "and", "astrophysics", ",", "and", "is", "funded", "by", "the", "smithsonian", "institution", "and", "the", "academia", "sinica", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "1the submillimeter array", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 3, "i_end": 3}}, {"subject": {"text": "1the submillimeter array", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "funded", "start": 167, "end": 173, "i_start": 24, "i_end": 24}}, {"character": {"text": "institution", "start": 193, "end": 204, "i_start": 28, "i_end": 28}, "action": {"text": "funded", "start": 167, "end": 173, "i_start": 24, "i_end": 24}}, {"character": {"text": "smithsonian", "start": 56, "end": 67, "i_start": 9, "i_end": 9}, "action": {"text": "funded", "start": 167, "end": 173, "i_start": 24, "i_end": 24}}, {"character": {"text": "institute", "start": 118, "end": 127, "i_start": 16, "i_end": 16}, "action": {"text": "funded", "start": 167, "end": 173, "i_start": 24, "i_end": 24}}, {"character": {"text": "academia sinica institute of astronomy and astrophysics", "start": 102, "end": 157, "i_start": 14, "i_end": 20}, "action": {"text": "funded", "start": 167, "end": 173, "i_start": 24, "i_end": 24}}], "id": 821}, {"sent": "his research interests include computer networks design and architecture , routing protocols optimizations , parallel and distributed computing , cryptography and network security , data compression , software and web engineering .", "tokens": ["his", "research", "interests", "include", "computer", "networks", "design", "and", "architecture", ",", "routing", "protocols", "optimizations", ",", "parallel", "and", "distributed", "computing", ",", "cryptography", "and", "network", "security", ",", "data", "compression", ",", "software", "and", "web", "engineering", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "his research interests", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "include", "start": 23, "end": 30, "i_start": 3, "i_end": 3}}], "id": 822}, {"sent": "deep convolutional networks made great progress in recent years in the field of computer vision .", "tokens": ["deep", "convolutional", "networks", "made", "great", "progress", "in", "recent", "years", "in", "the", "field", "of", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional networks", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "made", "start": 28, "end": 32, "i_start": 3, "i_end": 3}}], "id": 823}, {"sent": "for adapting detector weights , tang et al gradually update the weights of web-trained detectors as they are applied to videos .", "tokens": ["for", "adapting", "detector", "weights", ",", "tang", "et", "al", "gradually", "update", "the", "weights", "of", "web", "-", "trained", "detectors", "as", "they", "are", "applied", "to", "videos", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "tang et al", "start": 32, "end": 42, "i_start": 5, "i_end": 7}, "verb": {"text": "update", "start": 53, "end": 59, "i_start": 9, "i_end": 9}}, {"character": {"text": "tang", "start": 32, "end": 36, "i_start": 5, "i_end": 5}, "action": {"text": "update", "start": 53, "end": 59, "i_start": 9, "i_end": 9}}], "id": 824}, {"sent": "wakimoto , modular invariant representations of infinite-dimensional lie algebras and superalgebras , proc .", "tokens": ["wakimoto", ",", "modular", "invariant", "representations", "of", "infinite", "-", "dimensional", "lie", "algebras", "and", "superalgebras", ",", "proc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "wakimoto", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "representations", "start": 29, "end": 44, "i_start": 4, "i_end": 4}}, {"character": {"text": "proc", "start": 102, "end": 106, "i_start": 14, "i_end": 14}, "action": {"text": "representations", "start": 29, "end": 44, "i_start": 4, "i_end": 4}}], "id": 825}, {"sent": "quantum phase diagram in this section we discuss the ground state of the tetrahedral chain .", "tokens": ["quantum", "phase", "diagram", "in", "this", "section", "we", "discuss", "the", "ground", "state", "of", "the", "tetrahedral", "chain", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 38, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "discuss", "start": 41, "end": 48, "i_start": 7, "i_end": 7}}], "id": 826}, {"sent": "the vacuum is defined by is the factorizable two-particle scattering matrix of the integrable quantum field theory .", "tokens": ["the", "vacuum", "is", "defined", "by", "is", "the", "factorizable", "two", "-", "particle", "scattering", "matrix", "of", "the", "integrable", "quantum", "field", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the vacuum", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is defined", "start": 11, "end": 21, "i_start": 2, "i_end": 3}}], "id": 827}, {"sent": "a major practical appeal of this approach stems from the availability of modern numerical tools , which can compute various definitions of reachable sets .", "tokens": ["a", "major", "practical", "appeal", "of", "this", "approach", "stems", "from", "the", "availability", "of", "modern", "numerical", "tools", ",", "which", "can", "compute", "various", "definitions", "of", "reachable", "sets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a major practical appeal of this approach", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "stems", "start": 42, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "tools", "start": 90, "end": 95, "i_start": 14, "i_end": 14}, "action": {"text": "compute", "start": 108, "end": 115, "i_start": 18, "i_end": 18}}], "id": 828}, {"sent": "massive multiple-input multiple-output is a key enabler of the fifth-generation and future mobile communication networks .", "tokens": ["massive", "multiple", "-", "input", "multiple", "-", "output", "is", "a", "key", "enabler", "of", "the", "fifth", "-", "generation", "and", "future", "mobile", "communication", "networks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "massive multiple-input multiple-output", "start": 0, "end": 38, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "input", "start": 17, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "enabler", "start": 48, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "multiple", "start": 8, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "enabler", "start": 48, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "massive", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "enabler", "start": 48, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "output", "start": 32, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "enabler", "start": 48, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "multiple", "start": 8, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "enabler", "start": 48, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "massive", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "enabler", "start": 48, "end": 55, "i_start": 10, "i_end": 10}}], "id": 829}, {"sent": "deep learning is a subset of machine learning approaches where input features are transformed through multiple layers of nonlinear interactions in a neural network with multiple hidden layers .", "tokens": ["deep", "learning", "is", "a", "subset", "of", "machine", "learning", "approaches", "where", "input", "features", "are", "transformed", "through", "multiple", "layers", "of", "nonlinear", "interactions", "in", "a", "neural", "network", "with", "multiple", "hidden", "layers", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 830}, {"sent": "between each two layers we apply batch normalization followed by a relu non-linearity .", "tokens": ["between", "each", "two", "layers", "we", "apply", "batch", "normalization", "followed", "by", "a", "relu", "non", "-", "linearity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 24, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "apply", "start": 27, "end": 32, "i_start": 5, "i_end": 5}}], "id": 831}, {"sent": "conjectures 2 and 3 have also been verified for outerplanar graphs , .", "tokens": ["conjectures", "2", "and", "3", "have", "also", "been", "verified", "for", "outerplanar", "graphs", ",", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "conjectures 2 and 3", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "been verified", "start": 30, "end": 43, "i_start": 6, "i_end": 7}}, {"subject": {"text": "conjectures 2 and 3", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 20, "end": 24, "i_start": 4, "i_end": 4}}], "id": 832}, {"sent": "let us concentrate on the region when we have moved the seven branes far away .", "tokens": ["let", "us", "concentrate", "on", "the", "region", "when", "we", "have", "moved", "the", "seven", "branes", "far", "away", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "concentrate", "start": 7, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "concentrate", "start": 7, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "moved", "start": 46, "end": 51, "i_start": 9, "i_end": 9}}], "id": 833}, {"sent": "in recent years , deep convolutional neural networks have set the state-of-the-art on a broad range of computer vision tasks .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "set", "the", "state", "-", "of", "-", "the", "-", "art", "on", "a", "broad", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have set", "start": 53, "end": 61, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "set", "start": 58, "end": 61, "i_start": 9, "i_end": 9}}], "id": 834}, {"sent": "the model weights are trained with the adam algorithm via multiclass cross-entropy minimization .", "tokens": ["the", "model", "weights", "are", "trained", "with", "the", "adam", "algorithm", "via", "multiclass", "cross", "-", "entropy", "minimization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model weights", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "are trained", "start": 18, "end": 29, "i_start": 3, "i_end": 4}}, {"character": {"text": "minimization", "start": 83, "end": 95, "i_start": 14, "i_end": 14}, "action": {"text": "cross", "start": 69, "end": 74, "i_start": 11, "i_end": 11}}], "id": 835}, {"sent": "we further tested our predictions by observing the prevalence of messages in an organization and also by numerical experiments that take into consideration the organizational distance among individuals .", "tokens": ["we", "further", "tested", "our", "predictions", "by", "observing", "the", "prevalence", "of", "messages", "in", "an", "organization", "and", "also", "by", "numerical", "experiments", "that", "take", "into", "consideration", "the", "organizational", "distance", "among", "individuals", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "tested", "start": 11, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "tested", "start": 11, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "predictions", "start": 22, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "observing", "start": 37, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "experiments", "start": 115, "end": 126, "i_start": 18, "i_end": 18}, "action": {"text": "take", "start": 132, "end": 136, "i_start": 20, "i_end": 20}}], "id": 836}, {"sent": "deep learning has achieved great success in many research fields such as computer vision .", "tokens": ["deep", "learning", "has", "achieved", "great", "success", "in", "many", "research", "fields", "such", "as", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has achieved", "start": 14, "end": 26, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "achieved", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "success", "start": 33, "end": 40, "i_start": 5, "i_end": 5}}], "id": 837}, {"sent": "an example of a novel process that benefits from the robots and cad versatility is the so-called incremental forming process of metal sheets .", "tokens": ["an", "example", "of", "a", "novel", "process", "that", "benefits", "from", "the", "robots", "and", "cad", "versatility", "is", "the", "so", "-", "called", "incremental", "forming", "process", "of", "metal", "sheets", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "an example of a novel process that benefits from the robots and cad versatility", "start": 0, "end": 79, "i_start": 0, "i_end": 13}, "verb": {"text": "is", "start": 80, "end": 82, "i_start": 14, "i_end": 14}}, {"character": {"text": "process", "start": 22, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "benefits", "start": 35, "end": 43, "i_start": 7, "i_end": 7}}], "id": 838}, {"sent": "creation of polar and nonpolar ultra-long-range rydberg molecules .", "tokens": ["creation", "of", "polar", "and", "nonpolar", "ultra", "-", "long", "-", "range", "rydberg", "molecules", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 839}, {"sent": "the different behaviour for small and large layer thicknesses can be explained by the amount of overlap of the dws .", "tokens": ["the", "different", "behaviour", "for", "small", "and", "large", "layer", "thicknesses", "can", "be", "explained", "by", "the", "amount", "of", "overlap", "of", "the", "dws", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "the different behaviour for small and large layer thicknesses", "start": 0, "end": 61, "i_start": 0, "i_end": 8}, "verb": {"text": "can be explained", "start": 62, "end": 78, "i_start": 9, "i_end": 11}}, {"character": {"text": "amount", "start": 86, "end": 92, "i_start": 14, "i_end": 14}, "action": {"text": "explained", "start": 69, "end": 78, "i_start": 11, "i_end": 11}}, {"character": {"text": "dws", "start": 111, "end": 114, "i_start": 19, "i_end": 19}, "action": {"text": "overlap", "start": 96, "end": 103, "i_start": 16, "i_end": 16}}], "id": 840}, {"sent": "since deuteron is the unique stable nucleus consisting of a proton and a neutron , no other bound state has been experimentally observed , it implies that the bound state of higher eigen-energy is unstable and easy to dissociate , so does not exist in the nature .", "tokens": ["since", "deuteron", "is", "the", "unique", "stable", "nucleus", "consisting", "of", "a", "proton", "and", "a", "neutron", ",", "no", "other", "bound", "state", "has", "been", "experimentally", "observed", ",", "it", "implies", "that", "the", "bound", "state", "of", "higher", "eigen", "-", "energy", "is", "unstable", "and", "easy", "to", "dissociate", ",", "so", "does", "not", "exist", "in", "the", "nature", "."], "score": [1, 1, 0, 1, 1], "labels": [{"subject": {"text": "it", "start": 139, "end": 141, "i_start": 24, "i_end": 24}, "verb": {"text": "does not exist", "start": 234, "end": 248, "i_start": 43, "i_end": 45}}, {"subject": {"text": "it", "start": 139, "end": 141, "i_start": 24, "i_end": 24}, "verb": {"text": "implies", "start": 142, "end": 149, "i_start": 25, "i_end": 25}}], "id": 841}, {"sent": "deep neural networks have been highly successful at recognition tasks , such as image and speech recognition , and natural language processing .", "tokens": ["deep", "neural", "networks", "have", "been", "highly", "successful", "at", "recognition", "tasks", ",", "such", "as", "image", "and", "speech", "recognition", ",", "and", "natural", "language", "processing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 38, "end": 48, "i_start": 6, "i_end": 6}}], "id": 842}, {"sent": "the following result can be easily proved by the reader .", "tokens": ["the", "following", "result", "can", "be", "easily", "proved", "by", "the", "reader", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the following result", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "proved", "start": 35, "end": 41, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the following result", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "can be", "start": 21, "end": 27, "i_start": 3, "i_end": 4}}], "id": 843}, {"sent": "recently , deep learning and cnns have gained the center stage for various classification problems .", "tokens": ["recently", ",", "deep", "learning", "and", "cnns", "have", "gained", "the", "center", "stage", "for", "various", "classification", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning and cnns", "start": 11, "end": 33, "i_start": 2, "i_end": 5}, "verb": {"text": "have gained", "start": 34, "end": 45, "i_start": 6, "i_end": 7}}, {"character": {"text": "learning", "start": 16, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "gained", "start": 39, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "center", "start": 50, "end": 56, "i_start": 9, "i_end": 9}, "action": {"text": "gained", "start": 39, "end": 45, "i_start": 7, "i_end": 7}}], "id": 844}, {"sent": "we focus on the system architecture and assumptions that are the same as those assumed in .", "tokens": ["we", "focus", "on", "the", "system", "architecture", "and", "assumptions", "that", "are", "the", "same", "as", "those", "assumed", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "focus", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "focus", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 845}, {"sent": "convolutional neural networks have shown extraordinary success in a large variety of computer vision tasks , such as image recognition .", "tokens": ["convolutional", "neural", "networks", "have", "shown", "extraordinary", "success", "in", "a", "large", "variety", "of", "computer", "vision", "tasks", ",", "such", "as", "image", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 6, "i_end": 6}}], "id": 846}, {"sent": "in recent years , deep neural networks have achieved great success in a variety of machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "achieved", "great", "success", "in", "a", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}], "id": 847}, {"sent": "planck is the third generation of mm-wave instruments designed for space observations of the cosmic microwave background key words .", "tokens": ["planck", "is", "the", "third", "generation", "of", "mm", "-", "wave", "instruments", "designed", "for", "space", "observations", "of", "the", "cosmic", "microwave", "background", "key", "words", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "planck", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 7, "end": 9, "i_start": 1, "i_end": 1}}], "id": 848}, {"sent": "the left panel shows the ghost dressing function , the right panel the gluon dressing function .", "tokens": ["the", "left", "panel", "shows", "the", "ghost", "dressing", "function", ",", "the", "right", "panel", "the", "gluon", "dressing", "function", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the left panel", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "shows", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "panel", "start": 9, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "shows", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}], "id": 849}, {"sent": "convolutional neural networks can be used to better model the spatial relationships between voxels .", "tokens": ["convolutional", "neural", "networks", "can", "be", "used", "to", "better", "model", "the", "spatial", "relationships", "between", "voxels", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "can be used", "start": 30, "end": 41, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "model", "start": 52, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "voxels", "start": 92, "end": 98, "i_start": 13, "i_end": 13}, "action": {"text": "relationships", "start": 70, "end": 83, "i_start": 11, "i_end": 11}}], "id": 850}, {"sent": "an inverse limit of nilpotent k-algebras is called a formal k-algebra .", "tokens": ["an", "inverse", "limit", "of", "nilpotent", "k", "-", "algebras", "is", "called", "a", "formal", "k", "-", "algebra", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an inverse limit of nilpotent k-algebras", "start": 0, "end": 40, "i_start": 0, "i_end": 7}, "verb": {"text": "is called", "start": 41, "end": 50, "i_start": 8, "i_end": 9}}], "id": 851}, {"sent": "in this paper , we want to investigate the constraints on n reh and t reh as functions of the scalar spectral index , n s , focusing on the class of the so-called string fibre inflation models .", "tokens": ["in", "this", "paper", ",", "we", "want", "to", "investigate", "the", "constraints", "on", "n", "reh", "and", "t", "reh", "as", "functions", "of", "the", "scalar", "spectral", "index", ",", "n", "s", ",", "focusing", "on", "the", "class", "of", "the", "so", "-", "called", "string", "fibre", "inflation", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "want", "start": 19, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "want", "start": 19, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "investigate", "start": 27, "end": 38, "i_start": 7, "i_end": 7}}, {"character": {"text": "index", "start": 110, "end": 115, "i_start": 22, "i_end": 22}, "action": {"text": "functions", "start": 77, "end": 86, "i_start": 17, "i_end": 17}}, {"character": {"text": "want", "start": 19, "end": 23, "i_start": 5, "i_end": 5}, "action": {"text": "focusing", "start": 124, "end": 132, "i_start": 27, "i_end": 27}}], "id": 852}, {"sent": "deep neural networks have achieved state-of-the-art performance on a wide variety of machine learning tasks .", "tokens": ["deep", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "a", "wide", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 52, "end": 63, "i_start": 12, "i_end": 12}}], "id": 853}, {"sent": "adversarial networks have achieved much success in various studies , especially in image and text generation .", "tokens": ["adversarial", "networks", "have", "achieved", "much", "success", "in", "various", "studies", ",", "especially", "in", "image", "and", "text", "generation", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "adversarial networks", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 2, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 1, "i_end": 1}, "action": {"text": "success", "start": 40, "end": 47, "i_start": 5, "i_end": 5}}], "id": 854}, {"sent": "we also derive approximate analytical expression for the stationary optomechanical entanglement illustrating how laser phase noise affects its experimental realization .", "tokens": ["we", "also", "derive", "approximate", "analytical", "expression", "for", "the", "stationary", "optomechanical", "entanglement", "illustrating", "how", "laser", "phase", "noise", "affects", "its", "experimental", "realization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "derive", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "derive", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "expression", "start": 38, "end": 48, "i_start": 5, "i_end": 5}, "action": {"text": "illustrating", "start": 96, "end": 108, "i_start": 11, "i_end": 11}}, {"character": {"text": "noise", "start": 125, "end": 130, "i_start": 15, "i_end": 15}, "action": {"text": "affects", "start": 131, "end": 138, "i_start": 16, "i_end": 16}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "realization", "start": 156, "end": 167, "i_start": 19, "i_end": 19}}], "id": 855}, {"sent": "supervised hashing with kernels is a kernel-based supervised method which learns to hash the data points to compact binary codes whose hamming distances are minimized on similar pairs and maximized on dissimilar pairs .", "tokens": ["supervised", "hashing", "with", "kernels", "is", "a", "kernel", "-", "based", "supervised", "method", "which", "learns", "to", "hash", "the", "data", "points", "to", "compact", "binary", "codes", "whose", "hamming", "distances", "are", "minimized", "on", "similar", "pairs", "and", "maximized", "on", "dissimilar", "pairs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "supervised hashing with kernels", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "method", "start": 61, "end": 67, "i_start": 10, "i_end": 10}, "action": {"text": "supervised", "start": 0, "end": 10, "i_start": 0, "i_end": 0}}, {"character": {"text": "method", "start": 61, "end": 67, "i_start": 10, "i_end": 10}, "action": {"text": "learns", "start": 74, "end": 80, "i_start": 12, "i_end": 12}}], "id": 856}, {"sent": "hu et al proposed a method that combines knowledge distillation and pr for incorporating fuzzy knowledge into dnns .", "tokens": ["hu", "et", "al", "proposed", "a", "method", "that", "combines", "knowledge", "distillation", "and", "pr", "for", "incorporating", "fuzzy", "knowledge", "into", "dnns", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "hu et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "method", "start": 20, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "combines", "start": 32, "end": 40, "i_start": 7, "i_end": 7}}], "id": 857}, {"sent": "there are many interesting phenomena when allowing p to grow with n , see eg , but in this paper we consider the sparse case where p is fixed and does not depend on n .", "tokens": ["there", "are", "many", "interesting", "phenomena", "when", "allowing", "p", "to", "grow", "with", "n", ",", "see", "eg", ",", "but", "in", "this", "paper", "we", "consider", "the", "sparse", "case", "where", "p", "is", "fixed", "and", "does", "not", "depend", "on", "n", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 6, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 97, "end": 99, "i_start": 20, "i_end": 20}, "verb": {"text": "consider", "start": 100, "end": 108, "i_start": 21, "i_end": 21}}], "id": 858}, {"sent": "with these considerations , it becomes reasonable to conjecture that there should exist an alternative new regularization scheme that can realize the above mentioned attractive properties .", "tokens": ["with", "these", "considerations", ",", "it", "becomes", "reasonable", "to", "conjecture", "that", "there", "should", "exist", "an", "alternative", "new", "regularization", "scheme", "that", "can", "realize", "the", "above", "mentioned", "attractive", "properties", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 28, "end": 30, "i_start": 4, "i_end": 4}, "verb": {"text": "becomes", "start": 31, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "scheme", "start": 122, "end": 128, "i_start": 17, "i_end": 17}, "action": {"text": "realize", "start": 138, "end": 145, "i_start": 20, "i_end": 20}}, {"character": {"text": "properties", "start": 177, "end": 187, "i_start": 25, "i_end": 25}, "action": {"text": "attractive", "start": 166, "end": 176, "i_start": 24, "i_end": 24}}], "id": 859}, {"sent": "so this stencil is a projection of a good deformation .", "tokens": ["so", "this", "stencil", "is", "a", "projection", "of", "a", "good", "deformation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this stencil", "start": 3, "end": 15, "i_start": 1, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 860}, {"sent": "another class of approaches adopts a nonlinear model to map noisy speech signals to clean ones .", "tokens": ["another", "class", "of", "approaches", "adopts", "a", "nonlinear", "model", "to", "map", "noisy", "speech", "signals", "to", "clean", "ones", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "another class of approaches", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "adopts", "start": 28, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "class", "start": 8, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "adopts", "start": 28, "end": 34, "i_start": 4, "i_end": 4}}], "id": 861}, {"sent": "the vacuum is the quantum state which consists of the product of terms of the form .", "tokens": ["the", "vacuum", "is", "the", "quantum", "state", "which", "consists", "of", "the", "product", "of", "terms", "of", "the", "form", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the vacuum", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "terms", "start": 65, "end": 70, "i_start": 12, "i_end": 12}, "action": {"text": "product", "start": 54, "end": 61, "i_start": 10, "i_end": 10}}], "id": 862}, {"sent": "the duality is a tool that untangles the mutual connection , the mutual changeability and the transitions between different objects .", "tokens": ["the", "duality", "is", "a", "tool", "that", "untangles", "the", "mutual", "connection", ",", "the", "mutual", "changeability", "and", "the", "transitions", "between", "different", "objects", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the duality", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "tool", "start": 17, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "untangles", "start": 27, "end": 36, "i_start": 6, "i_end": 6}}], "id": 863}, {"sent": "deep learning has attracted attention in recent years in the machine learning field because of its high performance in areas such as image recognition and speech recognition .", "tokens": ["deep", "learning", "has", "attracted", "attention", "in", "recent", "years", "in", "the", "machine", "learning", "field", "because", "of", "its", "high", "performance", "in", "areas", "such", "as", "image", "recognition", "and", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has attracted", "start": 14, "end": 27, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "attracted", "start": 18, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "performance", "start": 104, "end": 115, "i_start": 17, "i_end": 17}, "action": {"text": "because", "start": 84, "end": 91, "i_start": 13, "i_end": 13}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "performance", "start": 104, "end": 115, "i_start": 17, "i_end": 17}}], "id": 864}, {"sent": "the concept of noncommutative geometry has nowadays acquired a central role in the study of possible extensions of gauge theories .", "tokens": ["the", "concept", "of", "noncommutative", "geometry", "has", "nowadays", "acquired", "a", "central", "role", "in", "the", "study", "of", "possible", "extensions", "of", "gauge", "theories", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the concept of noncommutative geometry", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "acquired", "start": 52, "end": 60, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the concept of noncommutative geometry", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "has", "start": 39, "end": 42, "i_start": 5, "i_end": 5}}, {"character": {"text": "concept", "start": 4, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "acquired", "start": 52, "end": 60, "i_start": 7, "i_end": 7}}], "id": 865}, {"sent": "we now color x 0 x 1 , x 2 x 3 , x 3 x 4 , x 4 x 0 with 3 , 4 , 1 , 5 , respectively , and color x 1 x 2 from with respect to 4 and u \u03c6 .", "tokens": ["we", "now", "color", "x", "0", "x", "1", ",", "x", "2", "x", "3", ",", "x", "3", "x", "4", ",", "x", "4", "x", "0", "with", "3", ",", "4", ",", "1", ",", "5", ",", "respectively", ",", "and", "color", "x", "1", "x", "2", "from", "with", "respect", "to", "4", "and", "u", "\u03c6", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "color", "start": 7, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "color", "start": 7, "end": 12, "i_start": 2, "i_end": 2}}], "id": 866}, {"sent": "cluster algebras , introduced in , are commutative algebras equipped with a distinguished set of generators , the cluster variables .", "tokens": ["cluster", "algebras", ",", "introduced", "in", ",", "are", "commutative", "algebras", "equipped", "with", "a", "distinguished", "set", "of", "generators", ",", "the", "cluster", "variables", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 35, "end": 38, "i_start": 6, "i_end": 6}}], "id": 867}, {"sent": "this principle is therefore also called observer invariance .", "tokens": ["this", "principle", "is", "therefore", "also", "called", "observer", "invariance", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this principle", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "called", "start": 33, "end": 39, "i_start": 5, "i_end": 5}}, {"subject": {"text": "this principle", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 868}, {"sent": "supergravity is a motivation because its minimal multiplet has barely the number of degrees of freedom to store the information of the supersymmetric standard model , except for the higgs .", "tokens": ["supergravity", "is", "a", "motivation", "because", "its", "minimal", "multiplet", "has", "barely", "the", "number", "of", "degrees", "of", "freedom", "to", "store", "the", "information", "of", "the", "supersymmetric", "standard", "model", ",", "except", "for", "the", "higgs", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "supergravity", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "supergravity", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "action": {"text": "motivation", "start": 18, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "has", "start": 59, "end": 62, "i_start": 8, "i_end": 8}, "action": {"text": "because", "start": 29, "end": 36, "i_start": 4, "i_end": 4}}, {"character": {"text": "multiplet", "start": 49, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "has", "start": 59, "end": 62, "i_start": 8, "i_end": 8}}, {"character": {"text": "multiplet", "start": 49, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "store", "start": 106, "end": 111, "i_start": 17, "i_end": 17}}], "id": 869}, {"sent": "today , the concept of convex geometry appears in many fields of mathematics such as formal language theory among others .", "tokens": ["today", ",", "the", "concept", "of", "convex", "geometry", "appears", "in", "many", "fields", "of", "mathematics", "such", "as", "formal", "language", "theory", "among", "others", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the concept of convex geometry", "start": 8, "end": 38, "i_start": 2, "i_end": 6}, "verb": {"text": "appears", "start": 39, "end": 46, "i_start": 7, "i_end": 7}}], "id": 870}, {"sent": "as for phase error correction , we design a procedure using the idea of gottesman and lo as shown in fig .", "tokens": ["as", "for", "phase", "error", "correction", ",", "we", "design", "a", "procedure", "using", "the", "idea", "of", "gottesman", "and", "lo", "as", "shown", "in", "fig", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 32, "end": 34, "i_start": 6, "i_end": 6}, "verb": {"text": "design", "start": 35, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 32, "end": 34, "i_start": 6, "i_end": 6}, "action": {"text": "design", "start": 35, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "procedure", "start": 44, "end": 53, "i_start": 9, "i_end": 9}, "action": {"text": "using", "start": 54, "end": 59, "i_start": 10, "i_end": 10}}, {"character": {"text": "fig", "start": 101, "end": 104, "i_start": 20, "i_end": 20}, "action": {"text": "shown", "start": 92, "end": 97, "i_start": 18, "i_end": 18}}], "id": 871}, {"sent": "the rf energy source antenna gain and the sensors antenna gain are set at 6 dbi as in .", "tokens": ["the", "rf", "energy", "source", "antenna", "gain", "and", "the", "sensors", "antenna", "gain", "are", "set", "at", "6", "dbi", "as", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the rf energy source antenna gain and the sensors antenna gain", "start": 0, "end": 62, "i_start": 0, "i_end": 10}, "verb": {"text": "are set", "start": 63, "end": 70, "i_start": 11, "i_end": 12}}], "id": 872}, {"sent": "in the decoding module , we use a fully convolutional network with residual connections .", "tokens": ["in", "the", "decoding", "module", ",", "we", "use", "a", "fully", "convolutional", "network", "with", "residual", "connections", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 28, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 28, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "module", "start": 16, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "decoding", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}], "id": 873}, {"sent": "for policy-gradient , we use the clipped-surrogate based ppo algorithm .", "tokens": ["for", "policy", "-", "gradient", ",", "we", "use", "the", "clipped", "-", "surrogate", "based", "ppo", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 22, "end": 24, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 25, "end": 28, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 25, "end": 28, "i_start": 6, "i_end": 6}}], "id": 874}, {"sent": "in recent years , deep learning techniques have achieved exceptional results in many domains such as computer vision and natural language processing .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "techniques", "have", "achieved", "exceptional", "results", "in", "many", "domains", "such", "as", "computer", "vision", "and", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning techniques", "start": 18, "end": 42, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 43, "end": 56, "i_start": 7, "i_end": 8}}, {"character": {"text": "techniques", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 48, "end": 56, "i_start": 8, "i_end": 8}}], "id": 875}, {"sent": "we also calculate the rf-tunneling current , which can be used to probe the spectrum of the single-particle excitations .", "tokens": ["we", "also", "calculate", "the", "rf", "-", "tunneling", "current", ",", "which", "can", "be", "used", "to", "probe", "the", "spectrum", "of", "the", "single", "-", "particle", "excitations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "calculate", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "calculate", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}], "id": 876}, {"sent": "danelljan et al proposed learning multi-resolution feature maps , which they name as continuous convolutional operators for tracking .", "tokens": ["danelljan", "et", "al", "proposed", "learning", "multi", "-", "resolution", "feature", "maps", ",", "which", "they", "name", "as", "continuous", "convolutional", "operators", "for", "tracking", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 10, "end": 15, "i_start": 1, "i_end": 2}, "verb": {"text": "proposed", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "danelljan", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}], "id": 877}, {"sent": "we see that classically the shell has two allowed regions .", "tokens": ["we", "see", "that", "classically", "the", "shell", "has", "two", "allowed", "regions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "see", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the shell", "start": 24, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "has", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "see", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "shell", "start": 28, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "has", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}], "id": 878}, {"sent": "is the derivative according to the tangential direction which is perpendicular to the vector .", "tokens": ["is", "the", "derivative", "according", "to", "the", "tangential", "direction", "which", "is", "perpendicular", "to", "the", "vector", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the derivative", "start": 3, "end": 17, "i_start": 1, "i_end": 2}, "verb": {"text": "is", "start": 0, "end": 2, "i_start": 0, "i_end": 0}}], "id": 879}, {"sent": "a quantum dot is a collection of electrons within a small space and can be considered as an artificial atom .", "tokens": ["a", "quantum", "dot", "is", "a", "collection", "of", "electrons", "within", "a", "small", "space", "and", "can", "be", "considered", "as", "an", "artificial", "atom", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a quantum dot", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 3, "i_end": 3}}, {"subject": {"text": "a quantum dot", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "considered", "start": 75, "end": 85, "i_start": 15, "i_end": 15}}], "id": 880}, {"sent": "the discrepancy is a little more than a factor of two but this is acceptable for our quite simple modeling .", "tokens": ["the", "discrepancy", "is", "a", "little", "more", "than", "a", "factor", "of", "two", "but", "this", "is", "acceptable", "for", "our", "quite", "simple", "modeling", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the discrepancy", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "modeling", "start": 98, "end": 106, "i_start": 19, "i_end": 19}, "action": {"text": "acceptable", "start": 66, "end": 76, "i_start": 14, "i_end": 14}}], "id": 881}, {"sent": "we use batch normalization and exponential linear unitfunction after each convolutional layer .", "tokens": ["we", "use", "batch", "normalization", "and", "exponential", "linear", "unitfunction", "after", "each", "convolutional", "layer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 882}, {"sent": "in addition , there are several slsne ic that do not show hydrogen features near the lc peak but hydrogen emission lines start to appear about 1 year after the lc peak , yan et al 2015 , yan et al , 2017a .", "tokens": ["in", "addition", ",", "there", "are", "several", "slsne", "ic", "that", "do", "not", "show", "hydrogen", "features", "near", "the", "lc", "peak", "but", "hydrogen", "emission", "lines", "start", "to", "appear", "about", "1", "year", "after", "the", "lc", "peak", ",", "yan", "et", "al", "2015", ",", "yan", "et", "al", ",", "2017a", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 14, "end": 19, "i_start": 3, "i_end": 3}, "verb": {"text": "are", "start": 20, "end": 23, "i_start": 4, "i_end": 4}}, {"subject": {"text": "hydrogen emission lines", "start": 97, "end": 120, "i_start": 19, "i_end": 21}, "verb": {"text": "start", "start": 121, "end": 126, "i_start": 22, "i_end": 22}}], "id": 883}, {"sent": "deep learning approaches , in particularly deep convolutional neural networks , have achieved tremendous successes in various visual recognition tasks .", "tokens": ["deep", "learning", "approaches", ",", "in", "particularly", "deep", "convolutional", "neural", "networks", ",", "have", "achieved", "tremendous", "successes", "in", "various", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep learning approaches", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 80, "end": 93, "i_start": 11, "i_end": 12}}, {"character": {"text": "approaches", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 85, "end": 93, "i_start": 12, "i_end": 12}}], "id": 884}, {"sent": "dropout is the technique of randomly dropping neural nodes along with their connections from the neural network during training .", "tokens": ["dropout", "is", "the", "technique", "of", "randomly", "dropping", "neural", "nodes", "along", "with", "their", "connections", "from", "the", "neural", "network", "during", "training", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dropout", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}], "id": 885}, {"sent": "we test the accuracy of our irr-pwc on the public sintel benchmarks .", "tokens": ["we", "test", "the", "accuracy", "of", "our", "irr", "-", "pwc", "on", "the", "public", "sintel", "benchmarks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "test", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "test", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 886}, {"sent": "in 1984 , bennett and brassard proposed a quantum key distribution scheme via a quantum communication channel .", "tokens": ["in", "1984", ",", "bennett", "and", "brassard", "proposed", "a", "quantum", "key", "distribution", "scheme", "via", "a", "quantum", "communication", "channel", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bennett and brassard", "start": 10, "end": 30, "i_start": 3, "i_end": 5}, "verb": {"text": "proposed", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "bennett", "start": 10, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "proposed", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "brassard", "start": 22, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "proposed", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}], "id": 887}, {"sent": "the analysis of paraconsistent events is called paraconsistent statistics .", "tokens": ["the", "analysis", "of", "paraconsistent", "events", "is", "called", "paraconsistent", "statistics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the analysis of paraconsistent events", "start": 0, "end": 37, "i_start": 0, "i_end": 4}, "verb": {"text": "is called", "start": 38, "end": 47, "i_start": 5, "i_end": 6}}], "id": 888}, {"sent": "in their seminal work , knill , laflamme , and milburn showed that such a quantum processor could be constructed using only linear optical elements , at the expense of rendering each quantum logic gate probabilistic .", "tokens": ["in", "their", "seminal", "work", ",", "knill", ",", "laflamme", ",", "and", "milburn", "showed", "that", "such", "a", "quantum", "processor", "could", "be", "constructed", "using", "only", "linear", "optical", "elements", ",", "at", "the", "expense", "of", "rendering", "each", "quantum", "logic", "gate", "probabilistic", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "such a quantum processor", "start": 67, "end": 91, "i_start": 13, "i_end": 16}, "verb": {"text": "showed", "start": 55, "end": 61, "i_start": 11, "i_end": 11}}, {"subject": {"text": "such a quantum processor", "start": 67, "end": 91, "i_start": 13, "i_end": 16}, "verb": {"text": "constructed", "start": 101, "end": 112, "i_start": 19, "i_end": 19}}, {"character": {"text": "knill", "start": 24, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "showed", "start": 55, "end": 61, "i_start": 11, "i_end": 11}}, {"character": {"text": "laflamme", "start": 32, "end": 40, "i_start": 7, "i_end": 7}, "action": {"text": "showed", "start": 55, "end": 61, "i_start": 11, "i_end": 11}}, {"character": {"text": "milburn", "start": 47, "end": 54, "i_start": 10, "i_end": 10}, "action": {"text": "showed", "start": 55, "end": 61, "i_start": 11, "i_end": 11}}, {"character": {"text": "knill", "start": 24, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "work", "start": 17, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "laflamme", "start": 32, "end": 40, "i_start": 7, "i_end": 7}, "action": {"text": "work", "start": 17, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "milburn", "start": 47, "end": 54, "i_start": 10, "i_end": 10}, "action": {"text": "work", "start": 17, "end": 21, "i_start": 3, "i_end": 3}}], "id": 889}, {"sent": "deep neural networks have shown remarkable success in many computer vision tasks such as image classification .", "tokens": ["deep", "neural", "networks", "have", "shown", "remarkable", "success", "in", "many", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}], "id": 890}, {"sent": "convolutional neural networks have achieved exceptional results in many large-scale computer vision applications , particularly in image recognition task .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "exceptional", "results", "in", "many", "large", "-", "scale", "computer", "vision", "applications", ",", "particularly", "in", "image", "recognition", "task", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 891}, {"sent": "all models overestimate observational precipitation amount over southern chile .", "tokens": ["all", "models", "overestimate", "observational", "precipitation", "amount", "over", "southern", "chile", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "all models", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "overestimate", "start": 11, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "models", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "overestimate", "start": 11, "end": 23, "i_start": 2, "i_end": 2}}], "id": 892}, {"sent": "recently , the icecube collaboration has also reported the first observation of a cosmic diffuse neutrino flux which lies in the 100 tev to pev range .", "tokens": ["recently", ",", "the", "icecube", "collaboration", "has", "also", "reported", "the", "first", "observation", "of", "a", "cosmic", "diffuse", "neutrino", "flux", "which", "lies", "in", "the", "100", "tev", "to", "pev", "range", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the icecube collaboration", "start": 11, "end": 36, "i_start": 2, "i_end": 4}, "verb": {"text": "reported", "start": 46, "end": 54, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the icecube collaboration", "start": 11, "end": 36, "i_start": 2, "i_end": 4}, "verb": {"text": "has", "start": 37, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "collaboration", "start": 23, "end": 36, "i_start": 4, "i_end": 4}, "action": {"text": "reported", "start": 46, "end": 54, "i_start": 7, "i_end": 7}}], "id": 893}, {"sent": "kiros et al proposed a similar joint multi-modal embedding model by using a powerful cnn and a lstm that encodes text .", "tokens": ["kiros", "et", "al", "proposed", "a", "similar", "joint", "multi", "-", "modal", "embedding", "model", "by", "using", "a", "powerful", "cnn", "and", "a", "lstm", "that", "encodes", "text", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "kiros et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "kiros", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "kiros", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 68, "end": 73, "i_start": 13, "i_end": 13}}], "id": 894}, {"sent": "note that the prds assumption is closely related to the assumption of logsupermodularity , or equivalently multivariate total positivity of order two , as studied by karlin and rinott .", "tokens": ["note", "that", "the", "prds", "assumption", "is", "closely", "related", "to", "the", "assumption", "of", "logsupermodularity", ",", "or", "equivalently", "multivariate", "total", "positivity", "of", "order", "two", ",", "as", "studied", "by", "karlin", "and", "rinott", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "prds", "start": 14, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "assumption", "start": 19, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "karlin", "start": 166, "end": 172, "i_start": 26, "i_end": 26}, "action": {"text": "studied", "start": 155, "end": 162, "i_start": 24, "i_end": 24}}, {"character": {"text": "rinott", "start": 177, "end": 183, "i_start": 28, "i_end": 28}, "action": {"text": "studied", "start": 155, "end": 162, "i_start": 24, "i_end": 24}}], "id": 895}, {"sent": "around each vortex is a flow of the superfluid neutrons .", "tokens": ["around", "each", "vortex", "is", "a", "flow", "of", "the", "superfluid", "neutrons", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a flow of the superfluid neutrons", "start": 22, "end": 55, "i_start": 4, "i_end": 9}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 896}, {"sent": "we use the powerful technique of exchangeable pairs as introduced by chatterjee and employed by chatterjee and dembo .", "tokens": ["we", "use", "the", "powerful", "technique", "of", "exchangeable", "pairs", "as", "introduced", "by", "chatterjee", "and", "employed", "by", "chatterjee", "and", "dembo", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "chatterjee", "start": 69, "end": 79, "i_start": 11, "i_end": 11}, "action": {"text": "introduced", "start": 55, "end": 65, "i_start": 9, "i_end": 9}}, {"character": {"text": "dembo", "start": 111, "end": 116, "i_start": 17, "i_end": 17}, "action": {"text": "introduced", "start": 55, "end": 65, "i_start": 9, "i_end": 9}}, {"character": {"text": "chatterjee", "start": 69, "end": 79, "i_start": 11, "i_end": 11}, "action": {"text": "employed", "start": 84, "end": 92, "i_start": 13, "i_end": 13}}, {"character": {"text": "dembo", "start": 111, "end": 116, "i_start": 17, "i_end": 17}, "action": {"text": "employed", "start": 84, "end": 92, "i_start": 13, "i_end": 13}}], "id": 897}, {"sent": "convolutional neural networks have recently been very successful on a variety of recognition and classification tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "been", "very", "successful", "on", "a", "variety", "of", "recognition", "and", "classification", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "been", "start": 44, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 54, "end": 64, "i_start": 7, "i_end": 7}}], "id": 898}, {"sent": "proof is left as an exercise for the reader .", "tokens": ["proof", "is", "left", "as", "an", "exercise", "for", "the", "reader", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "proof", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is left", "start": 6, "end": 13, "i_start": 1, "i_end": 2}}], "id": 899}, {"sent": "moreover , under mild transversality assumptions , the set of partly smooth functions is closed under addition and pre-composition by a linear operator .", "tokens": ["moreover", ",", "under", "mild", "transversality", "assumptions", ",", "the", "set", "of", "partly", "smooth", "functions", "is", "closed", "under", "addition", "and", "pre", "-", "composition", "by", "a", "linear", "operator", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the set of partly smooth functions", "start": 51, "end": 85, "i_start": 7, "i_end": 12}, "verb": {"text": "is closed", "start": 86, "end": 95, "i_start": 13, "i_end": 14}}], "id": 900}, {"sent": "moreover , methods based on convolutional neural networks have been broadly applied .", "tokens": ["moreover", ",", "methods", "based", "on", "convolutional", "neural", "networks", "have", "been", "broadly", "applied", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "methods based on convolutional neural networks", "start": 11, "end": 57, "i_start": 2, "i_end": 7}, "verb": {"text": "applied", "start": 76, "end": 83, "i_start": 11, "i_end": 11}}, {"subject": {"text": "methods based on convolutional neural networks", "start": 11, "end": 57, "i_start": 2, "i_end": 7}, "verb": {"text": "have been", "start": 58, "end": 67, "i_start": 8, "i_end": 9}}], "id": 901}, {"sent": "the vgg16 model that is pre-trained on imagenet is used to initialize our network .", "tokens": ["the", "vgg16", "model", "that", "is", "pre", "-", "trained", "on", "imagenet", "is", "used", "to", "initialize", "our", "network", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the vgg16 model that is pre-trained on imagenet", "start": 0, "end": 47, "i_start": 0, "i_end": 9}, "verb": {"text": "is used", "start": 48, "end": 55, "i_start": 10, "i_end": 11}}, {"character": {"text": "model", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "initialize", "start": 59, "end": 69, "i_start": 13, "i_end": 13}}], "id": 902}, {"sent": "deep convolutional neural networks have been successful in many computer vision tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successful", "in", "many", "computer", "vision", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "successful", "start": 45, "end": 55, "i_start": 6, "i_end": 6}}], "id": 903}, {"sent": "one has to regulate these divergences and remove them , this process is called renormalization .", "tokens": ["one", "has", "to", "regulate", "these", "divergences", "and", "remove", "them", ",", "this", "process", "is", "called", "renormalization", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "has", "start": 4, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "this process", "start": 56, "end": 68, "i_start": 10, "i_end": 11}, "verb": {"text": "called", "start": 72, "end": 78, "i_start": 13, "i_end": 13}}, {"character": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "regulate", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "remove", "start": 42, "end": 48, "i_start": 7, "i_end": 7}}], "id": 904}, {"sent": "in this section , we recall the definition of a regularized petersson inner product of a cusp form and a meromorphic modular form with the same weight by following .", "tokens": ["in", "this", "section", ",", "we", "recall", "the", "definition", "of", "a", "regularized", "petersson", "inner", "product", "of", "a", "cusp", "form", "and", "a", "meromorphic", "modular", "form", "with", "the", "same", "weight", "by", "following", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "recall", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "recall", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 905}, {"sent": "deep neural networks have been shown to be very efficient in image processing tasks such as content classification .", "tokens": ["deep", "neural", "networks", "have", "been", "shown", "to", "be", "very", "efficient", "in", "image", "processing", "tasks", "such", "as", "content", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been shown", "start": 21, "end": 36, "i_start": 3, "i_end": 5}}], "id": 906}, {"sent": "for example , the expansions of the polynomial chaos can be used , see .", "tokens": ["for", "example", ",", "the", "expansions", "of", "the", "polynomial", "chaos", "can", "be", "used", ",", "see", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the expansions of the polynomial chaos", "start": 14, "end": 52, "i_start": 3, "i_end": 8}, "verb": {"text": "can be used", "start": 53, "end": 64, "i_start": 9, "i_end": 11}}], "id": 907}, {"sent": "the potential between monopole and anti-monopole can be used to find the mass spectrum of the glueballs .", "tokens": ["the", "potential", "between", "monopole", "and", "anti", "-", "monopole", "can", "be", "used", "to", "find", "the", "mass", "spectrum", "of", "the", "glueballs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the potential between monopole and anti-monopole", "start": 0, "end": 48, "i_start": 0, "i_end": 7}, "verb": {"text": "can be used", "start": 49, "end": 60, "i_start": 8, "i_end": 10}}], "id": 908}, {"sent": "obtained results allow us to predict the behaviour of excitable systems with two pacemakers depending on the type and intensity of their interaction and the initial phase .", "tokens": ["obtained", "results", "allow", "us", "to", "predict", "the", "behaviour", "of", "excitable", "systems", "with", "two", "pacemakers", "depending", "on", "the", "type", "and", "intensity", "of", "their", "interaction", "and", "the", "initial", "phase", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "us", "start": 23, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "predict", "start": 29, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "systems", "start": 64, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "behaviour", "start": 41, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "behaviour", "start": 41, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "depending", "start": 92, "end": 101, "i_start": 14, "i_end": 14}}, {"character": {"text": "systems", "start": 64, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "interaction", "start": 137, "end": 148, "i_start": 22, "i_end": 22}}], "id": 909}, {"sent": "similarly , the u-net apply multiple skip-connections to construct a contracting path to capture context and a symmetric expanding path that enables precise localization .", "tokens": ["similarly", ",", "the", "u", "-", "net", "apply", "multiple", "skip", "-", "connections", "to", "construct", "a", "contracting", "path", "to", "capture", "context", "and", "a", "symmetric", "expanding", "path", "that", "enables", "precise", "localization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the u-net", "start": 12, "end": 21, "i_start": 2, "i_end": 5}, "verb": {"text": "apply", "start": 22, "end": 27, "i_start": 6, "i_end": 6}}, {"character": {"text": "path", "start": 81, "end": 85, "i_start": 15, "i_end": 15}, "action": {"text": "contracting", "start": 69, "end": 80, "i_start": 14, "i_end": 14}}, {"character": {"text": "path", "start": 131, "end": 135, "i_start": 23, "i_end": 23}, "action": {"text": "enables", "start": 141, "end": 148, "i_start": 25, "i_end": 25}}], "id": 910}, {"sent": "the advances in convolutional neural networks have successfully pushed the limits and improved the stateof-the-art technologies of image and video understanding .", "tokens": ["the", "advances", "in", "convolutional", "neural", "networks", "have", "successfully", "pushed", "the", "limits", "and", "improved", "the", "stateof", "-", "the", "-", "art", "technologies", "of", "image", "and", "video", "understanding", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the advances in convolutional neural networks", "start": 0, "end": 45, "i_start": 0, "i_end": 5}, "verb": {"text": "pushed", "start": 64, "end": 70, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the advances in convolutional neural networks", "start": 0, "end": 45, "i_start": 0, "i_end": 5}, "verb": {"text": "have", "start": 46, "end": 50, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the advances in convolutional neural networks", "start": 0, "end": 45, "i_start": 0, "i_end": 5}, "verb": {"text": "improved", "start": 86, "end": 94, "i_start": 12, "i_end": 12}}, {"character": {"text": "advances", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "pushed", "start": 64, "end": 70, "i_start": 8, "i_end": 8}}, {"character": {"text": "advances", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "improved", "start": 86, "end": 94, "i_start": 12, "i_end": 12}}], "id": 911}, {"sent": "convolutional neural networks have achieved significant progress in computer vision tasks such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "significant", "progress", "in", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 912}, {"sent": "the network model is pre-trained under the imagenet 2012 dataset .", "tokens": ["the", "network", "model", "is", "pre", "-", "trained", "under", "the", "imagenet", "2012", "dataset", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the network model", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}], "id": 913}, {"sent": "we compare our vital tracker with state-of-the-art trackers on the vot-2016 benchmark , including staple .", "tokens": ["we", "compare", "our", "vital", "tracker", "with", "state", "-", "of", "-", "the", "-", "art", "trackers", "on", "the", "vot-2016", "benchmark", ",", "including", "staple", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 914}, {"sent": "defferrard et al proposed an efficient filtering scheme using recurrent chebyshev polynomials applied on the laplacian operator .", "tokens": ["defferrard", "et", "al", "proposed", "an", "efficient", "filtering", "scheme", "using", "recurrent", "chebyshev", "polynomials", "applied", "on", "the", "laplacian", "operator", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "defferrard et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "defferrard", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "scheme", "start": 49, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "filtering", "start": 39, "end": 48, "i_start": 6, "i_end": 6}}, {"character": {"text": "scheme", "start": 49, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "using", "start": 56, "end": 61, "i_start": 8, "i_end": 8}}], "id": 915}, {"sent": "deep convolutional neural networks have made significant breakthroughs in many visual understanding tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "significant", "breakthroughs", "in", "many", "visual", "understanding", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "breakthroughs", "start": 57, "end": 70, "i_start": 7, "i_end": 7}}], "id": 916}, {"sent": "locality sensitive hashing is a well studied computational primitive for efficient nearest neighbor search in highdimensional spaces .", "tokens": ["locality", "sensitive", "hashing", "is", "a", "well", "studied", "computational", "primitive", "for", "efficient", "nearest", "neighbor", "search", "in", "highdimensional", "spaces", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "locality sensitive hashing", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "hashing", "start": 19, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "sensitive", "start": 9, "end": 18, "i_start": 1, "i_end": 1}}], "id": 917}, {"sent": "the dashed curve separates the region on the left where the kozai resonance exists from that on the right where general relativistic precession destroys the eccentricity oscillations .", "tokens": ["the", "dashed", "curve", "separates", "the", "region", "on", "the", "left", "where", "the", "kozai", "resonance", "exists", "from", "that", "on", "the", "right", "where", "general", "relativistic", "precession", "destroys", "the", "eccentricity", "oscillations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the dashed curve", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "separates", "start": 17, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "curve", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "separates", "start": 17, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "precession", "start": 133, "end": 143, "i_start": 22, "i_end": 22}, "action": {"text": "destroys", "start": 144, "end": 152, "i_start": 23, "i_end": 23}}], "id": 918}, {"sent": "renormalization is the procedure of cancelling the divergences from these shifts by introducing counterterms into the lagrangian .", "tokens": ["renormalization", "is", "the", "procedure", "of", "cancelling", "the", "divergences", "from", "these", "shifts", "by", "introducing", "counterterms", "into", "the", "lagrangian", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "renormalization", "start": 0, "end": 15, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 1, "i_end": 1}}], "id": 919}, {"sent": "the toric code model is just a special case of a more general construction by levin and wen .", "tokens": ["the", "toric", "code", "model", "is", "just", "a", "special", "case", "of", "a", "more", "general", "construction", "by", "levin", "and", "wen", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the toric code model", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "wen", "start": 88, "end": 91, "i_start": 17, "i_end": 17}, "action": {"text": "construction", "start": 62, "end": 74, "i_start": 13, "i_end": 13}}], "id": 920}, {"sent": "from the transmission and phase data , the anisotropy of the optical response is evident .", "tokens": ["from", "the", "transmission", "and", "phase", "data", ",", "the", "anisotropy", "of", "the", "optical", "response", "is", "evident", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the anisotropy of the optical response", "start": 39, "end": 77, "i_start": 7, "i_end": 12}, "verb": {"text": "is", "start": 78, "end": 80, "i_start": 13, "i_end": 13}}], "id": 921}, {"sent": "borodin proved that every planar graph is acyclically 5-colourable .", "tokens": ["borodin", "proved", "that", "every", "planar", "graph", "is", "acyclically", "5", "-", "colourable", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 922}, {"sent": "dropout is a popular method to deal with overfitting for neural networks .", "tokens": ["dropout", "is", "a", "popular", "method", "to", "deal", "with", "overfitting", "for", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dropout", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}], "id": 923}, {"sent": "the advantages for policy gradient calculations are computed using the generalized advantage estimator gae .", "tokens": ["the", "advantages", "for", "policy", "gradient", "calculations", "are", "computed", "using", "the", "generalized", "advantage", "estimator", "gae", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the advantages for policy gradient calculations", "start": 0, "end": 47, "i_start": 0, "i_end": 5}, "verb": {"text": "are computed", "start": 48, "end": 60, "i_start": 6, "i_end": 7}}], "id": 924}, {"sent": "to detect entanglement we apply the peres-horodecki separability criterion .", "tokens": ["to", "detect", "entanglement", "we", "apply", "the", "peres", "-", "horodecki", "separability", "criterion", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 23, "end": 25, "i_start": 3, "i_end": 3}, "verb": {"text": "apply", "start": 26, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "apply", "start": 26, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "detect", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 925}, {"sent": "the capacitive coupling of qubits to the tlr in dispersive mode will cause the phase randomization of the qubit states .", "tokens": ["the", "capacitive", "coupling", "of", "qubits", "to", "the", "tlr", "in", "dispersive", "mode", "will", "cause", "the", "phase", "randomization", "of", "the", "qubit", "states", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the capacitive coupling of qubits to the tlr in dispersive mode", "start": 0, "end": 63, "i_start": 0, "i_end": 10}, "verb": {"text": "will cause", "start": 64, "end": 74, "i_start": 11, "i_end": 12}}, {"character": {"text": "coupling", "start": 15, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "cause", "start": 69, "end": 74, "i_start": 12, "i_end": 12}}], "id": 926}, {"sent": "the strongest model is the fully synchronised model where each stage of each cycle is performed simultaneously by all robots .", "tokens": ["the", "strongest", "model", "is", "the", "fully", "synchronised", "model", "where", "each", "stage", "of", "each", "cycle", "is", "performed", "simultaneously", "by", "all", "robots", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the strongest model", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "robots", "start": 118, "end": 124, "i_start": 19, "i_end": 19}, "action": {"text": "performed", "start": 86, "end": 95, "i_start": 15, "i_end": 15}}], "id": 927}, {"sent": "statistics for the results based on the solovay-strassen probabilistic primality test .", "tokens": ["statistics", "for", "the", "results", "based", "on", "the", "solovay", "-", "strassen", "probabilistic", "primality", "test", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 928}, {"sent": "recent development of deep convolutional neural networks has led to great success in a variety of tasks including image classfication and others .", "tokens": ["recent", "development", "of", "deep", "convolutional", "neural", "networks", "has", "led", "to", "great", "success", "in", "a", "variety", "of", "tasks", "including", "image", "classfication", "and", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent development of deep convolutional neural networks", "start": 0, "end": 56, "i_start": 0, "i_end": 6}, "verb": {"text": "has led", "start": 57, "end": 64, "i_start": 7, "i_end": 8}}, {"character": {"text": "development", "start": 7, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 61, "end": 64, "i_start": 8, "i_end": 8}}], "id": 929}, {"sent": "we will specialise to non-commutative smooth proper surfaces later .", "tokens": ["we", "will", "specialise", "to", "non", "-", "commutative", "smooth", "proper", "surfaces", "later", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will specialise", "start": 3, "end": 18, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "specialise", "start": 8, "end": 18, "i_start": 2, "i_end": 2}}], "id": 930}, {"sent": "this in turn implies that , locally , y is the graph of x .", "tokens": ["this", "in", "turn", "implies", "that", ",", "locally", ",", "y", "is", "the", "graph", "of", "x", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "implies", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 40, "end": 42, "i_start": 9, "i_end": 9}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "implies", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}], "id": 931}, {"sent": "the feature extraction network is composed of a fully convolutional resnet-18 architecture .", "tokens": ["the", "feature", "extraction", "network", "is", "composed", "of", "a", "fully", "convolutional", "resnet-18", "architecture", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the feature extraction network", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "is composed", "start": 31, "end": 42, "i_start": 4, "i_end": 5}}], "id": 932}, {"sent": "the problem above is equivalent to a henchman problem , in which eavesdropper reconstructs a single sequence with the help of a rate-limited henchman who can access to the source s n and the wiretapped signal z n .", "tokens": ["the", "problem", "above", "is", "equivalent", "to", "a", "henchman", "problem", ",", "in", "which", "eavesdropper", "reconstructs", "a", "single", "sequence", "with", "the", "help", "of", "a", "rate", "-", "limited", "henchman", "who", "can", "access", "to", "the", "source", "s", "n", "and", "the", "wiretapped", "signal", "z", "n", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the problem above", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "henchman", "start": 37, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "help", "start": 118, "end": 122, "i_start": 19, "i_end": 19}}, {"character": {"text": "henchman", "start": 37, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "access", "start": 158, "end": 164, "i_start": 28, "i_end": 28}}], "id": 933}, {"sent": "pompili , charm mixing and lifetimes at babar , paper presented at this conference .", "tokens": ["pompili", ",", "charm", "mixing", "and", "lifetimes", "at", "babar", ",", "paper", "presented", "at", "this", "conference", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 934}, {"sent": "locc is the local part of tip-surface capacitance gradient and .", "tokens": ["locc", "is", "the", "local", "part", "of", "tip", "-", "surface", "capacitance", "gradient", "and", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "locc", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 935}, {"sent": "rapid development of deep convolutional neural networks has led to promising performance on various computer vision tasks .", "tokens": ["rapid", "development", "of", "deep", "convolutional", "neural", "networks", "has", "led", "to", "promising", "performance", "on", "various", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "rapid development of deep convolutional neural networks", "start": 0, "end": 55, "i_start": 0, "i_end": 6}, "verb": {"text": "has led", "start": 56, "end": 63, "i_start": 7, "i_end": 8}}, {"character": {"text": "development", "start": 6, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 60, "end": 63, "i_start": 8, "i_end": 8}}, {"character": {"text": "performance", "start": 77, "end": 88, "i_start": 11, "i_end": 11}, "action": {"text": "promising", "start": 67, "end": 76, "i_start": 10, "i_end": 10}}], "id": 936}, {"sent": "bekenstein , in proceedings of the sixth marcel grossman meeting on general relativity , h .", "tokens": ["bekenstein", ",", "in", "proceedings", "of", "the", "sixth", "marcel", "grossman", "meeting", "on", "general", "relativity", ",", "h", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 937}, {"sent": "therefore , each polyhedron is a tetrahedron that is preserved by the involution .", "tokens": ["therefore", ",", "each", "polyhedron", "is", "a", "tetrahedron", "that", "is", "preserved", "by", "the", "involution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each polyhedron", "start": 12, "end": 27, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "involution", "start": 70, "end": 80, "i_start": 12, "i_end": 12}, "action": {"text": "preserved", "start": 53, "end": 62, "i_start": 9, "i_end": 9}}], "id": 938}, {"sent": "in recent years , convolutional neural networks have achieved superior performance in many visual tasks , such as object classification and detection .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "classification", "and", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 48, "end": 61, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 53, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 71, "end": 82, "i_start": 10, "i_end": 10}}], "id": 939}, {"sent": "convolutional neural networks have achieved significant progress in computer vision tasks such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "significant", "progress", "in", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 940}, {"sent": "we follow the evaluation of the standard pck metric , which measures the percentage of keypoints close to the ground truth in different thresholds of distance .", "tokens": ["we", "follow", "the", "evaluation", "of", "the", "standard", "pck", "metric", ",", "which", "measures", "the", "percentage", "of", "keypoints", "close", "to", "the", "ground", "truth", "in", "different", "thresholds", "of", "distance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "metric", "start": 45, "end": 51, "i_start": 8, "i_end": 8}, "action": {"text": "measures", "start": 60, "end": 68, "i_start": 11, "i_end": 11}}], "id": 941}, {"sent": "the formula in this section we present the formula for massless qcd .", "tokens": ["the", "formula", "in", "this", "section", "we", "present", "the", "formula", "for", "massless", "qcd", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 28, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "present", "start": 31, "end": 38, "i_start": 6, "i_end": 6}}], "id": 942}, {"sent": "we recall the definition of the weighted ricci curvature on finsler manifolds , which was introduced by ohta in on metric measure space .", "tokens": ["we", "recall", "the", "definition", "of", "the", "weighted", "ricci", "curvature", "on", "finsler", "manifolds", ",", "which", "was", "introduced", "by", "ohta", "in", "on", "metric", "measure", "space", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "recall", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "recall", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "ohta", "start": 104, "end": 108, "i_start": 17, "i_end": 17}, "action": {"text": "introduced", "start": 90, "end": 100, "i_start": 15, "i_end": 15}}], "id": 943}, {"sent": "compressed sensing is a collection of signal processing techniques that compress sparse analog vectors by means of linear transformations .", "tokens": ["compressed", "sensing", "is", "a", "collection", "of", "signal", "processing", "techniques", "that", "compress", "sparse", "analog", "vectors", "by", "means", "of", "linear", "transformations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "compressed sensing", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "techniques", "start": 56, "end": 66, "i_start": 8, "i_end": 8}, "action": {"text": "processing", "start": 45, "end": 55, "i_start": 7, "i_end": 7}}, {"character": {"text": "techniques", "start": 56, "end": 66, "i_start": 8, "i_end": 8}, "action": {"text": "compress", "start": 72, "end": 80, "i_start": 10, "i_end": 10}}], "id": 944}, {"sent": "then by construction we have that \u03c1 is a set of weak identities in the group g .", "tokens": ["then", "by", "construction", "we", "have", "that", "\u03c1", "is", "a", "set", "of", "weak", "identities", "in", "the", "group", "g", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 3, "i_end": 3}, "verb": {"text": "have", "start": 24, "end": 28, "i_start": 4, "i_end": 4}}, {"subject": {"text": "we", "start": 21, "end": 23, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 36, "end": 38, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "have", "start": 24, "end": 28, "i_start": 4, "i_end": 4}}], "id": 945}, {"sent": "performance-centric task scheduling algorithms take the scheduling performance as the ultimate goal such as the shortest completion time , including min-min , max-min algorithm , genetic algorithm , ant colony algorithm .", "tokens": ["performance", "-", "centric", "task", "scheduling", "algorithms", "take", "the", "scheduling", "performance", "as", "the", "ultimate", "goal", "such", "as", "the", "shortest", "completion", "time", ",", "including", "min", "-", "min", ",", "max", "-", "min", "algorithm", ",", "genetic", "algorithm", ",", "ant", "colony", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "performance-centric task scheduling algorithms", "start": 0, "end": 46, "i_start": 0, "i_end": 5}, "verb": {"text": "take", "start": 47, "end": 51, "i_start": 6, "i_end": 6}}, {"character": {"text": "algorithms", "start": 36, "end": 46, "i_start": 5, "i_end": 5}, "action": {"text": "take", "start": 47, "end": 51, "i_start": 6, "i_end": 6}}], "id": 946}, {"sent": "the projector augmented wave method is used to calculate the wave functions , and the generalized gradient approximation formulated by perdew , burke and ernzerhof is taken into account for the exchange-correlation functional .", "tokens": ["the", "projector", "augmented", "wave", "method", "is", "used", "to", "calculate", "the", "wave", "functions", ",", "and", "the", "generalized", "gradient", "approximation", "formulated", "by", "perdew", ",", "burke", "and", "ernzerhof", "is", "taken", "into", "account", "for", "the", "exchange", "-", "correlation", "functional", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the projector augmented wave method", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "is used", "start": 36, "end": 43, "i_start": 5, "i_end": 6}}, {"subject": {"text": "the generalized gradient approximation formulated by perdew", "start": 82, "end": 141, "i_start": 14, "i_end": 20}, "verb": {"text": "taken", "start": 167, "end": 172, "i_start": 26, "i_end": 26}}, {"character": {"text": "projector", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "augmented", "start": 14, "end": 23, "i_start": 2, "i_end": 2}}], "id": 947}, {"sent": "cnns have received considerable attention from the advent of alexnet .", "tokens": ["cnns", "have", "received", "considerable", "attention", "from", "the", "advent", "of", "alexnet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cnns", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "have received", "start": 5, "end": 18, "i_start": 1, "i_end": 2}}], "id": 948}, {"sent": "we reduced the data using standard procedures within the common astronomy software application .", "tokens": ["we", "reduced", "the", "data", "using", "standard", "procedures", "within", "the", "common", "astronomy", "software", "application", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "reduced", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "reduced", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 949}, {"sent": "deep neural networks have recently achieved huge success in various machine learning tasks .", "tokens": ["deep", "neural", "networks", "have", "recently", "achieved", "huge", "success", "in", "various", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 49, "end": 56, "i_start": 7, "i_end": 7}}], "id": 950}, {"sent": "we use the standard 300-hour switchboard corpus which consists of 2,430 two-sided telephonic conversations between 500 different speakers and contains 3 million words of text .", "tokens": ["we", "use", "the", "standard", "300", "-", "hour", "switchboard", "corpus", "which", "consists", "of", "2,430", "two", "-", "sided", "telephonic", "conversations", "between", "500", "different", "speakers", "and", "contains", "3", "million", "words", "of", "text", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "500", "start": 115, "end": 118, "i_start": 19, "i_end": 19}, "action": {"text": "speakers", "start": 129, "end": 137, "i_start": 21, "i_end": 21}}, {"character": {"text": "corpus", "start": 41, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "contains", "start": 142, "end": 150, "i_start": 23, "i_end": 23}}], "id": 951}, {"sent": "by doing this , we obtain the following petrosyan has proven this conjecture in the case of lhf -group provided m is also orientable and in the case where n is 1-dimensional .", "tokens": ["by", "doing", "this", ",", "we", "obtain", "the", "following", "petrosyan", "has", "proven", "this", "conjecture", "in", "the", "case", "of", "lhf", "-group", "provided", "m", "is", "also", "orientable", "and", "in", "the", "case", "where", "n", "is", "1", "-", "dimensional", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "obtain", "start": 19, "end": 25, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "proven", "start": 54, "end": 60, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "obtain", "start": 19, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "petrosyan", "start": 40, "end": 49, "i_start": 8, "i_end": 8}, "action": {"text": "proven", "start": 54, "end": 60, "i_start": 10, "i_end": 10}}], "id": 952}, {"sent": "we use the pre-trained oxford vgg 16-layer cnn for feature extraction .", "tokens": ["we", "use", "the", "pre", "-", "trained", "oxford", "vgg", "16", "-", "layer", "cnn", "for", "feature", "extraction", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extraction", "start": 59, "end": 69, "i_start": 14, "i_end": 14}}], "id": 953}, {"sent": "recent advances in generative models have mostly been driven by generative adversarial networks .", "tokens": ["recent", "advances", "in", "generative", "models", "have", "mostly", "been", "driven", "by", "generative", "adversarial", "networks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent advances in generative models", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "been driven", "start": 49, "end": 60, "i_start": 7, "i_end": 8}}, {"subject": {"text": "recent advances in generative models", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "have", "start": 37, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 87, "end": 95, "i_start": 12, "i_end": 12}, "action": {"text": "driven", "start": 54, "end": 60, "i_start": 8, "i_end": 8}}], "id": 954}, {"sent": "the asterisks denote the final value from the simulation rather than a minimum .", "tokens": ["the", "asterisks", "denote", "the", "final", "value", "from", "the", "simulation", "rather", "than", "a", "minimum", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the asterisks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "denote", "start": 14, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "asterisks", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 14, "end": 20, "i_start": 2, "i_end": 2}}], "id": 955}, {"sent": "nonlinear dynamics tells us that at low p most of the motion takes place on what is called the primary zone of phase space .", "tokens": ["nonlinear", "dynamics", "tells", "us", "that", "at", "low", "p", "most", "of", "the", "motion", "takes", "place", "on", "what", "is", "called", "the", "primary", "zone", "of", "phase", "space", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "nonlinear dynamics", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "tells", "start": 19, "end": 24, "i_start": 2, "i_end": 2}}, {"subject": {"text": "most of the motion", "start": 42, "end": 60, "i_start": 8, "i_end": 11}, "verb": {"text": "takes", "start": 61, "end": 66, "i_start": 12, "i_end": 12}}, {"character": {"text": "dynamics", "start": 10, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "tells", "start": 19, "end": 24, "i_start": 2, "i_end": 2}}], "id": 956}, {"sent": "string theory is a promising candidate for a fundamental theory , but there are significant obstacles to deriving convincing models of inflation from string theory .", "tokens": ["string", "theory", "is", "a", "promising", "candidate", "for", "a", "fundamental", "theory", ",", "but", "there", "are", "significant", "obstacles", "to", "deriving", "convincing", "models", "of", "inflation", "from", "string", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "string theory", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"subject": {"text": "there", "start": 70, "end": 75, "i_start": 12, "i_end": 12}, "verb": {"text": "are", "start": 76, "end": 79, "i_start": 13, "i_end": 13}}, {"character": {"text": "candidate", "start": 29, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "promising", "start": 19, "end": 28, "i_start": 4, "i_end": 4}}], "id": 957}, {"sent": "an important difference between network generation models and ergms is that network models try to explain how a network evolves whereas ergms do not explicitly explain network generation process .", "tokens": ["an", "important", "difference", "between", "network", "generation", "models", "and", "ergms", "is", "that", "network", "models", "try", "to", "explain", "how", "a", "network", "evolves", "whereas", "ergms", "do", "not", "explicitly", "explain", "network", "generation", "process", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "an important difference between network generation models and ergms", "start": 0, "end": 67, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 68, "end": 70, "i_start": 9, "i_end": 9}}, {"subject": {"text": "network models", "start": 76, "end": 90, "i_start": 11, "i_end": 12}, "verb": {"text": "try", "start": 91, "end": 94, "i_start": 13, "i_end": 13}}, {"character": {"text": "models", "start": 51, "end": 57, "i_start": 6, "i_end": 6}, "action": {"text": "try", "start": 91, "end": 94, "i_start": 13, "i_end": 13}}, {"character": {"text": "models", "start": 51, "end": 57, "i_start": 6, "i_end": 6}, "action": {"text": "explain", "start": 98, "end": 105, "i_start": 15, "i_end": 15}}, {"character": {"text": "ergms", "start": 62, "end": 67, "i_start": 8, "i_end": 8}, "action": {"text": "not explicitly explain", "start": 145, "end": 167, "i_start": 23, "i_end": 25}}], "id": 958}, {"sent": "finally , a linear combination of exponential functions , with complex bases , is known to be very expressive in representing other functions .", "tokens": ["finally", ",", "a", "linear", "combination", "of", "exponential", "functions", ",", "with", "complex", "bases", ",", "is", "known", "to", "be", "very", "expressive", "in", "representing", "other", "functions", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a linear combination of exponential functions", "start": 10, "end": 55, "i_start": 2, "i_end": 7}, "verb": {"text": "is known", "start": 79, "end": 87, "i_start": 13, "i_end": 14}}, {"character": {"text": "combination", "start": 19, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "expressive", "start": 99, "end": 109, "i_start": 18, "i_end": 18}}, {"character": {"text": "combination", "start": 19, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "representing", "start": 113, "end": 125, "i_start": 20, "i_end": 20}}], "id": 959}, {"sent": "dark energy is a cosmological constant as a stationary value of a potential of self-interaction of \u03c8 field .", "tokens": ["dark", "energy", "is", "a", "cosmological", "constant", "as", "a", "stationary", "value", "of", "a", "potential", "of", "self", "-", "interaction", "of", "\u03c8", "field", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dark energy", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "field", "start": 101, "end": 106, "i_start": 19, "i_end": 19}, "action": {"text": "interaction", "start": 84, "end": 95, "i_start": 16, "i_end": 16}}], "id": 960}, {"sent": "the source size is in turn constrained by the optically thick lines .", "tokens": ["the", "source", "size", "is", "in", "turn", "constrained", "by", "the", "optically", "thick", "lines", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the source size", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "lines", "start": 62, "end": 67, "i_start": 11, "i_end": 11}, "action": {"text": "constrained", "start": 27, "end": 38, "i_start": 6, "i_end": 6}}], "id": 961}, {"sent": "kamilov et al have taken the first step towards a theoretical understanding of such algorithms .", "tokens": ["kamilov", "et", "al", "have", "taken", "the", "first", "step", "towards", "a", "theoretical", "understanding", "of", "such", "algorithms", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "kamilov et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "have taken", "start": 14, "end": 24, "i_start": 3, "i_end": 4}}], "id": 962}, {"sent": "batch normalization is used to make the training stable and fast to converge .", "tokens": ["batch", "normalization", "is", "used", "to", "make", "the", "training", "stable", "and", "fast", "to", "converge", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "batch normalization", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is used", "start": 20, "end": 27, "i_start": 2, "i_end": 3}}, {"character": {"text": "normalization", "start": 6, "end": 19, "i_start": 1, "i_end": 1}, "action": {"text": "make", "start": 31, "end": 35, "i_start": 5, "i_end": 5}}], "id": 963}, {"sent": "duality is a general concept relating physical quantities in different regions of the parameter space .", "tokens": ["duality", "is", "a", "general", "concept", "relating", "physical", "quantities", "in", "different", "regions", "of", "the", "parameter", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "duality", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "concept", "start": 21, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "relating", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}], "id": 964}, {"sent": "first-principles calculations were carried out with the vienna ab initio simulation package 26 , 27 , which makes use of the projector augmented wave method 28 , 29 .", "tokens": ["first", "-", "principles", "calculations", "were", "carried", "out", "with", "the", "vienna", "ab", "initio", "simulation", "package", "26", ",", "27", ",", "which", "makes", "use", "of", "the", "projector", "augmented", "wave", "method", "28", ",", "29", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "first-principles calculations", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "were carried out", "start": 30, "end": 46, "i_start": 4, "i_end": 6}}], "id": 965}, {"sent": "for the continuous case we justify the choice of the gaussian distribution as the one yielding the maximum rate function that can be defined by second order moments .", "tokens": ["for", "the", "continuous", "case", "we", "justify", "the", "choice", "of", "the", "gaussian", "distribution", "as", "the", "one", "yielding", "the", "maximum", "rate", "function", "that", "can", "be", "defined", "by", "second", "order", "moments", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 24, "end": 26, "i_start": 4, "i_end": 4}, "verb": {"text": "justify", "start": 27, "end": 34, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "justify", "start": 27, "end": 34, "i_start": 5, "i_end": 5}}, {"character": {"text": "one", "start": 82, "end": 85, "i_start": 14, "i_end": 14}, "action": {"text": "yielding", "start": 86, "end": 94, "i_start": 15, "i_end": 15}}, {"character": {"text": "moments", "start": 157, "end": 164, "i_start": 27, "i_end": 27}, "action": {"text": "defined", "start": 133, "end": 140, "i_start": 23, "i_end": 23}}], "id": 966}, {"sent": "the special form of this integral representation of an instrument , corresponding to the invariant class , is called quantum stochastic .", "tokens": ["the", "special", "form", "of", "this", "integral", "representation", "of", "an", "instrument", ",", "corresponding", "to", "the", "invariant", "class", ",", "is", "called", "quantum", "stochastic", "."], "score": [1, 1, 1, 0, 1], "labels": [{"subject": {"text": "the special form of this integral representation of an instrument", "start": 0, "end": 65, "i_start": 0, "i_end": 9}, "verb": {"text": "is called", "start": 107, "end": 116, "i_start": 17, "i_end": 18}}], "id": 967}, {"sent": "the total variation regularisation is a well-known edge-preserving approach , first introduced by rudin , osher and fatemi in for image denoising .", "tokens": ["the", "total", "variation", "regularisation", "is", "a", "well", "-", "known", "edge", "-", "preserving", "approach", ",", "first", "introduced", "by", "rudin", ",", "osher", "and", "fatemi", "in", "for", "image", "denoising", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the total variation regularisation", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "rudin", "start": 98, "end": 103, "i_start": 17, "i_end": 17}, "action": {"text": "introduced", "start": 84, "end": 94, "i_start": 15, "i_end": 15}}, {"character": {"text": "osher", "start": 106, "end": 111, "i_start": 19, "i_end": 19}, "action": {"text": "introduced", "start": 84, "end": 94, "i_start": 15, "i_end": 15}}, {"character": {"text": "fatemi", "start": 116, "end": 122, "i_start": 21, "i_end": 21}, "action": {"text": "introduced", "start": 84, "end": 94, "i_start": 15, "i_end": 15}}], "id": 968}, {"sent": "on euler products and the classification of automorphic representations .", "tokens": ["on", "euler", "products", "and", "the", "classification", "of", "automorphic", "representations", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 969}, {"sent": "deep neural networks are used in many recent applications such as image recognition .", "tokens": ["deep", "neural", "networks", "are", "used", "in", "many", "recent", "applications", "such", "as", "image", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are used", "start": 21, "end": 29, "i_start": 3, "i_end": 4}}], "id": 970}, {"sent": "convolutional neural networks , as one of the widely used deep learning methods , have been proven to be very successful for object recognition in images .", "tokens": ["convolutional", "neural", "networks", ",", "as", "one", "of", "the", "widely", "used", "deep", "learning", "methods", ",", "have", "been", "proven", "to", "be", "very", "successful", "for", "object", "recognition", "in", "images", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been proven", "start": 82, "end": 98, "i_start": 14, "i_end": 16}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 110, "end": 120, "i_start": 20, "i_end": 20}}], "id": 971}, {"sent": "when kf is self-dual , the conventional lower bound argument involving the action fails and the equations of motion must be solved directly .", "tokens": ["when", "kf", "is", "self", "-", "dual", ",", "the", "conventional", "lower", "bound", "argument", "involving", "the", "action", "fails", "and", "the", "equations", "of", "motion", "must", "be", "solved", "directly", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the conventional lower bound argument involving the action", "start": 23, "end": 81, "i_start": 7, "i_end": 14}, "verb": {"text": "fails", "start": 82, "end": 87, "i_start": 15, "i_end": 15}}, {"subject": {"text": "the equations of motion", "start": 92, "end": 115, "i_start": 17, "i_end": 20}, "verb": {"text": "solved", "start": 124, "end": 130, "i_start": 23, "i_end": 23}}], "id": 972}, {"sent": "convolutional neural networks have achieved state-of-the-art accuracy in computer vision tasks such as image recognition .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "accuracy", "in", "computer", "vision", "tasks", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 973}, {"sent": "it has been shown that essentially these same results are reproduced by the anderson model in the j-j coupling scheme .", "tokens": ["it", "has", "been", "shown", "that", "essentially", "these", "same", "results", "are", "reproduced", "by", "the", "anderson", "model", "in", "the", "j", "-", "j", "coupling", "scheme", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has been shown", "start": 3, "end": 17, "i_start": 1, "i_end": 3}}, {"subject": {"text": "these same results", "start": 35, "end": 53, "i_start": 6, "i_end": 8}, "verb": {"text": "reproduced", "start": 58, "end": 68, "i_start": 10, "i_end": 10}}, {"character": {"text": "model", "start": 85, "end": 90, "i_start": 14, "i_end": 14}, "action": {"text": "reproduced", "start": 58, "end": 68, "i_start": 10, "i_end": 10}}], "id": 974}, {"sent": "reinforcement learning is a framework that enables an agent to learn through interactions with the environment .", "tokens": ["reinforcement", "learning", "is", "a", "framework", "that", "enables", "an", "agent", "to", "learn", "through", "interactions", "with", "the", "environment", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "framework", "start": 28, "end": 37, "i_start": 4, "i_end": 4}, "action": {"text": "enables", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}, {"character": {"text": "agent", "start": 54, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "learning", "start": 14, "end": 22, "i_start": 1, "i_end": 1}}, {"character": {"text": "agent", "start": 54, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "interactions", "start": 77, "end": 89, "i_start": 12, "i_end": 12}}], "id": 975}, {"sent": "an invariance principle for weakly dependent stationary general models .", "tokens": ["an", "invariance", "principle", "for", "weakly", "dependent", "stationary", "general", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "models", "start": 64, "end": 70, "i_start": 8, "i_end": 8}, "action": {"text": "dependent", "start": 35, "end": 44, "i_start": 5, "i_end": 5}}], "id": 976}, {"sent": "the functions b are called the coefficients of h .", "tokens": ["the", "functions", "b", "are", "called", "the", "coefficients", "of", "h", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the functions b", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "are called", "start": 16, "end": 26, "i_start": 3, "i_end": 4}}], "id": 977}, {"sent": "we optimize the elbo via stochastic gradient descent , using a customized version of adam .", "tokens": ["we", "optimize", "the", "elbo", "via", "stochastic", "gradient", "descent", ",", "using", "a", "customized", "version", "of", "adam", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "optimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 55, "end": 60, "i_start": 9, "i_end": 9}}], "id": 978}, {"sent": "deep convolutional neural networks have been prevailed in various computer vision tasks , such as objection classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "prevailed", "in", "various", "computer", "vision", "tasks", ",", "such", "as", "objection", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been prevailed", "start": 35, "end": 54, "i_start": 4, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "prevailed", "start": 45, "end": 54, "i_start": 6, "i_end": 6}}], "id": 979}, {"sent": "the time intervals between pulses and pulse amplitudes are correlated with each other .", "tokens": ["the", "time", "intervals", "between", "pulses", "and", "pulse", "amplitudes", "are", "correlated", "with", "each", "other", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the time intervals between pulses and pulse amplitudes", "start": 0, "end": 54, "i_start": 0, "i_end": 7}, "verb": {"text": "are correlated", "start": 55, "end": 69, "i_start": 8, "i_end": 9}}], "id": 980}, {"sent": "in this paper , we consider a wireless broadcast problem where a sender wishes to broadcast a block of k data packets to a set of n receivers using linear network coding .", "tokens": ["in", "this", "paper", ",", "we", "consider", "a", "wireless", "broadcast", "problem", "where", "a", "sender", "wishes", "to", "broadcast", "a", "block", "of", "k", "data", "packets", "to", "a", "set", "of", "n", "receivers", "using", "linear", "network", "coding", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "consider", "start": 19, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "consider", "start": 19, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "set", "start": 123, "end": 126, "i_start": 24, "i_end": 24}, "action": {"text": "using", "start": 142, "end": 147, "i_start": 28, "i_end": 28}}], "id": 981}, {"sent": "in recent years , deep neural networks have demonstrated impressive performance improvements on a wide range of challenging machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "demonstrated", "impressive", "performance", "improvements", "on", "a", "wide", "range", "of", "challenging", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have demonstrated", "start": 39, "end": 56, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "demonstrated", "start": 44, "end": 56, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "improvements", "start": 80, "end": 92, "i_start": 11, "i_end": 11}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 68, "end": 79, "i_start": 10, "i_end": 10}}, {"character": {"text": "tasks", "start": 141, "end": 146, "i_start": 20, "i_end": 20}, "action": {"text": "challenging", "start": 112, "end": 123, "i_start": 17, "i_end": 17}}, {"character": {"text": "improvements", "start": 80, "end": 92, "i_start": 11, "i_end": 11}, "action": {"text": "impressive", "start": 57, "end": 67, "i_start": 9, "i_end": 9}}], "id": 982}, {"sent": "we evaluate matrix elements of the conservation equations between the vacuum and an on-shell supergravity state .", "tokens": ["we", "evaluate", "matrix", "elements", "of", "the", "conservation", "equations", "between", "the", "vacuum", "and", "an", "on", "-", "shell", "supergravity", "state", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 983}, {"sent": "goodfellow et al validate that practical attack in deep neural networks is possible because these models are locally linear .", "tokens": ["goodfellow", "et", "al", "validate", "that", "practical", "attack", "in", "deep", "neural", "networks", "is", "possible", "because", "these", "models", "are", "locally", "linear", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "validate", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"subject": {"text": "goodfellow et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 72, "end": 74, "i_start": 11, "i_end": 11}}, {"character": {"text": "goodfellow", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "validate", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "linear", "start": 117, "end": 123, "i_start": 18, "i_end": 18}, "action": {"text": "because", "start": 84, "end": 91, "i_start": 13, "i_end": 13}}], "id": 984}, {"sent": "we use the well accepted -differential privacy concept as the measure of privacy .", "tokens": ["we", "use", "the", "well", "accepted", "-differential", "privacy", "concept", "as", "the", "measure", "of", "privacy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "measure", "start": 62, "end": 69, "i_start": 10, "i_end": 10}}], "id": 985}, {"sent": "liu et al use a cnn to learn unary and pairwise potentials for a continuous crf for depth estimation .", "tokens": ["liu", "et", "al", "use", "a", "cnn", "to", "learn", "unary", "and", "pairwise", "potentials", "for", "a", "continuous", "crf", "for", "depth", "estimation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "liu et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "use", "start": 10, "end": 13, "i_start": 3, "i_end": 3}}, {"character": {"text": "liu", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 10, "end": 13, "i_start": 3, "i_end": 3}}, {"character": {"text": "liu", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "learn", "start": 23, "end": 28, "i_start": 7, "i_end": 7}}], "id": 986}, {"sent": "this automatically implies that the spacetime is kundt .", "tokens": ["this", "automatically", "implies", "that", "the", "spacetime", "is", "kundt", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "implies", "start": 19, "end": 26, "i_start": 2, "i_end": 2}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 46, "end": 48, "i_start": 6, "i_end": 6}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "implies", "start": 19, "end": 26, "i_start": 2, "i_end": 2}}], "id": 987}, {"sent": "it was illustrated by ding et al that the complete weight enumerator can be applied to calculate the deception probabilities of certain authentication codes .", "tokens": ["it", "was", "illustrated", "by", "ding", "et", "al", "that", "the", "complete", "weight", "enumerator", "can", "be", "applied", "to", "calculate", "the", "deception", "probabilities", "of", "certain", "authentication", "codes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "was illustrated", "start": 3, "end": 18, "i_start": 1, "i_end": 2}}, {"subject": {"text": "the complete weight enumerator", "start": 38, "end": 68, "i_start": 8, "i_end": 11}, "verb": {"text": "applied", "start": 76, "end": 83, "i_start": 14, "i_end": 14}}, {"character": {"text": "ding", "start": 22, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "illustrated", "start": 7, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "enumerator", "start": 58, "end": 68, "i_start": 11, "i_end": 11}, "action": {"text": "calculate", "start": 87, "end": 96, "i_start": 16, "i_end": 16}}, {"character": {"text": "codes", "start": 151, "end": 156, "i_start": 23, "i_end": 23}, "action": {"text": "authentication", "start": 136, "end": 150, "i_start": 22, "i_end": 22}}], "id": 988}, {"sent": "in recent years , deep neural networks , especially convolutional neural networks , have demonstrated highly competitive results on object recognition and image classification .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", ",", "especially", "convolutional", "neural", "networks", ",", "have", "demonstrated", "highly", "competitive", "results", "on", "object", "recognition", "and", "image", "classification", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have demonstrated", "start": 84, "end": 101, "i_start": 13, "i_end": 14}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "demonstrated", "start": 89, "end": 101, "i_start": 14, "i_end": 14}}], "id": 989}, {"sent": "the interfaces will not show what the organization believes in and does not .", "tokens": ["the", "interfaces", "will", "not", "show", "what", "the", "organization", "believes", "in", "and", "does", "not", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the interfaces", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "will not show", "start": 15, "end": 28, "i_start": 2, "i_end": 4}}, {"subject": {"text": "the organization", "start": 34, "end": 50, "i_start": 6, "i_end": 7}, "verb": {"text": "believes", "start": 51, "end": 59, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the interfaces", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "does", "start": 67, "end": 71, "i_start": 11, "i_end": 11}}, {"character": {"text": "interfaces", "start": 4, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "not show", "start": 20, "end": 28, "i_start": 3, "i_end": 4}}, {"character": {"text": "organization", "start": 38, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "believes", "start": 51, "end": 59, "i_start": 8, "i_end": 8}}, {"character": {"text": "organization", "start": 38, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "not", "start": 72, "end": 75, "i_start": 12, "i_end": 12}}], "id": 990}, {"sent": "unsupervised pretraining models , such as gpt and gpt-2 , and bert yield state-of-the-art performance on a wide range of natural language processing tasks .", "tokens": ["unsupervised", "pretraining", "models", ",", "such", "as", "gpt", "and", "gpt-2", ",", "and", "bert", "yield", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "a", "wide", "range", "of", "natural", "language", "processing", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "models", "start": 25, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "yield", "start": 67, "end": 72, "i_start": 12, "i_end": 12}}], "id": 991}, {"sent": "although not all of these symmetries are integrable , usually some integrable symmetries exist for such equations .", "tokens": ["although", "not", "all", "of", "these", "symmetries", "are", "integrable", ",", "usually", "some", "integrable", "symmetries", "exist", "for", "such", "equations", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "some integrable symmetries", "start": 62, "end": 88, "i_start": 10, "i_end": 12}, "verb": {"text": "exist", "start": 89, "end": 94, "i_start": 13, "i_end": 13}}], "id": 992}, {"sent": "recently , deep neural network based methods have lead to breakthroughs in several vision tasks , such as classification .", "tokens": ["recently", ",", "deep", "neural", "network", "based", "methods", "have", "lead", "to", "breakthroughs", "in", "several", "vision", "tasks", ",", "such", "as", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural network based methods", "start": 11, "end": 44, "i_start": 2, "i_end": 6}, "verb": {"text": "have lead", "start": 45, "end": 54, "i_start": 7, "i_end": 8}}, {"character": {"text": "methods", "start": 37, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "lead", "start": 50, "end": 54, "i_start": 8, "i_end": 8}}], "id": 993}, {"sent": "in recent years , deep convolutional neural networks have been widely used in a variety of computer vision tasks and have achieved unprecedented progress .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "been", "widely", "used", "in", "a", "variety", "of", "computer", "vision", "tasks", "and", "have", "achieved", "unprecedented", "progress", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "used", "start": 70, "end": 74, "i_start": 11, "i_end": 11}}, {"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have been", "start": 53, "end": 62, "i_start": 8, "i_end": 9}}, {"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "achieved", "start": 122, "end": 130, "i_start": 21, "i_end": 21}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 122, "end": 130, "i_start": 21, "i_end": 21}}], "id": 994}, {"sent": "using this fact we are able to prove that specializations preserve basic operations on modules including the tor and ext functors .", "tokens": ["using", "this", "fact", "we", "are", "able", "to", "prove", "that", "specializations", "preserve", "basic", "operations", "on", "modules", "including", "the", "tor", "and", "ext", "functors", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "are", "start": 19, "end": 22, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "prove", "start": 31, "end": 36, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "using", "start": 0, "end": 5, "i_start": 0, "i_end": 0}}], "id": 995}, {"sent": "this essentially quantum property is usually named entanglement .", "tokens": ["this", "essentially", "quantum", "property", "is", "usually", "named", "entanglement", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this essentially quantum property", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "named", "start": 45, "end": 50, "i_start": 6, "i_end": 6}}, {"subject": {"text": "this essentially quantum property", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 4, "i_end": 4}}], "id": 996}, {"sent": "according to ref , the local clustering coefficient of a node i is given by where t i is the number of triangles incident to the node i , a is the adjacency matrix of the network , and k i is the degree of the node i .", "tokens": ["according", "to", "ref", ",", "the", "local", "clustering", "coefficient", "of", "a", "node", "i", "is", "given", "by", "where", "t", "i", "is", "the", "number", "of", "triangles", "incident", "to", "the", "node", "i", ",", "a", "is", "the", "adjacency", "matrix", "of", "the", "network", ",", "and", "k", "i", "is", "the", "degree", "of", "the", "node", "i", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the local clustering coefficient of a node i", "start": 19, "end": 63, "i_start": 4, "i_end": 11}, "verb": {"text": "is given", "start": 64, "end": 72, "i_start": 12, "i_end": 13}}, {"character": {"text": "node", "start": 57, "end": 61, "i_start": 10, "i_end": 10}, "action": {"text": "incident", "start": 113, "end": 121, "i_start": 23, "i_end": 23}}], "id": 997}, {"sent": "we use a standard data augmentation strategy with an exception to color-based normalization .", "tokens": ["we", "use", "a", "standard", "data", "augmentation", "strategy", "with", "an", "exception", "to", "color", "-", "based", "normalization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 998}, {"sent": "now let us assume that the plasma consists of nested flux surfaced labeled by a radial coordinate , and let us take \u03c6 to be a flux function .", "tokens": ["now", "let", "us", "assume", "that", "the", "plasma", "consists", "of", "nested", "flux", "surfaced", "labeled", "by", "a", "radial", "coordinate", ",", "and", "let", "us", "take", "\u03c6", "to", "be", "a", "flux", "function", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "let", "start": 4, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "us", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "assume", "start": 11, "end": 17, "i_start": 3, "i_end": 3}}, {"subject": {"text": "us", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "let", "start": 104, "end": 107, "i_start": 19, "i_end": 19}}, {"character": {"text": "us", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "let", "start": 4, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "us", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "assume", "start": 11, "end": 17, "i_start": 3, "i_end": 3}}], "id": 999}, {"sent": "in the standard dft , the generalized gradi-ent approximation of perdew-burke-ernzerhof version is adopted to describe the electronic exchange-correlation interactions .", "tokens": ["in", "the", "standard", "dft", ",", "the", "generalized", "gradi", "-", "ent", "approximation", "of", "perdew", "-", "burke", "-", "ernzerhof", "version", "is", "adopted", "to", "describe", "the", "electronic", "exchange", "-", "correlation", "interactions", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalized gradi-ent approximation of perdew-burke-ernzerhof version", "start": 22, "end": 95, "i_start": 5, "i_end": 17}, "verb": {"text": "is adopted", "start": 96, "end": 106, "i_start": 18, "i_end": 19}}, {"character": {"text": "approximation", "start": 48, "end": 61, "i_start": 10, "i_end": 10}, "action": {"text": "describe", "start": 110, "end": 118, "i_start": 21, "i_end": 21}}], "id": 1000}, {"sent": "differential privacy provides a well-tested formalization for the release of information derived from private data .", "tokens": ["differential", "privacy", "provides", "a", "well", "-", "tested", "formalization", "for", "the", "release", "of", "information", "derived", "from", "private", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "differential privacy", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "provides", "start": 21, "end": 29, "i_start": 2, "i_end": 2}}, {"character": {"text": "privacy", "start": 13, "end": 20, "i_start": 1, "i_end": 1}, "action": {"text": "provides", "start": 21, "end": 29, "i_start": 2, "i_end": 2}}], "id": 1001}, {"sent": "the 300wlp is generated from 300w , in which it establishes a 3d morphable model and reconstruct the face appearance with varying head poses .", "tokens": ["the", "300wlp", "is", "generated", "from", "300w", ",", "in", "which", "it", "establishes", "a", "3d", "morphable", "model", "and", "reconstruct", "the", "face", "appearance", "with", "varying", "head", "poses", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the 300wlp", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is generated", "start": 11, "end": 23, "i_start": 2, "i_end": 3}}], "id": 1002}, {"sent": "statistical modeling techniques have been widely investigated in the context of multivariate time series either in the multiple linear regression setup .", "tokens": ["statistical", "modeling", "techniques", "have", "been", "widely", "investigated", "in", "the", "context", "of", "multivariate", "time", "series", "either", "in", "the", "multiple", "linear", "regression", "setup", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "statistical modeling techniques", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "investigated", "start": 49, "end": 61, "i_start": 6, "i_end": 6}}, {"subject": {"text": "statistical modeling techniques", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 32, "end": 41, "i_start": 3, "i_end": 4}}], "id": 1003}, {"sent": "rowson , experimental issues at giga-z , these proceedings .", "tokens": ["rowson", ",", "experimental", "issues", "at", "giga", "-", "z", ",", "these", "proceedings", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "experimental", "start": 9, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "issues", "start": 22, "end": 28, "i_start": 3, "i_end": 3}}], "id": 1004}, {"sent": "deep learning algorithms have yielded impressive performance across a range of tasks , including object and voice recognition .", "tokens": ["deep", "learning", "algorithms", "have", "yielded", "impressive", "performance", "across", "a", "range", "of", "tasks", ",", "including", "object", "and", "voice", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning algorithms", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "have yielded", "start": 25, "end": 37, "i_start": 3, "i_end": 4}}, {"character": {"text": "algorithms", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "yielded", "start": 30, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "algorithms", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "algorithms", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 49, "end": 60, "i_start": 6, "i_end": 6}}, {"character": {"text": "yielded", "start": 30, "end": 37, "i_start": 4, "i_end": 4}, "action": {"text": "impressive", "start": 38, "end": 48, "i_start": 5, "i_end": 5}}], "id": 1005}, {"sent": "deep neural networks have garnered interest from many researchers after being successfully applied in image classification .", "tokens": ["deep", "neural", "networks", "have", "garnered", "interest", "from", "many", "researchers", "after", "being", "successfully", "applied", "in", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have garnered", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "garnered", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successfully", "start": 78, "end": 90, "i_start": 11, "i_end": 11}}], "id": 1006}, {"sent": "in this section , we explain the algorithm of the sat problem which has been introduced by ohya-masuda .", "tokens": ["in", "this", "section", ",", "we", "explain", "the", "algorithm", "of", "the", "sat", "problem", "which", "has", "been", "introduced", "by", "ohya", "-", "masuda", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "explain", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "explain", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "ohya", "start": 91, "end": 95, "i_start": 17, "i_end": 17}, "action": {"text": "introduced", "start": 77, "end": 87, "i_start": 15, "i_end": 15}}], "id": 1007}, {"sent": "in literature , there are a few studies on clustering using deep neural networks .", "tokens": ["in", "literature", ",", "there", "are", "a", "few", "studies", "on", "clustering", "using", "deep", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 16, "end": 21, "i_start": 3, "i_end": 3}, "verb": {"text": "are", "start": 22, "end": 25, "i_start": 4, "i_end": 4}}], "id": 1008}, {"sent": "recently , there has seen a significant performance improvement in the field of face recognition since the emergence of deep convolution neural networks .", "tokens": ["recently", ",", "there", "has", "seen", "a", "significant", "performance", "improvement", "in", "the", "field", "of", "face", "recognition", "since", "the", "emergence", "of", "deep", "convolution", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "has seen", "start": 17, "end": 25, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 144, "end": 152, "i_start": 22, "i_end": 22}, "action": {"text": "emergence", "start": 107, "end": 116, "i_start": 17, "i_end": 17}}], "id": 1009}, {"sent": "convolutional neural networks are very effective techniques for image classification for various important real-world applications .", "tokens": ["convolutional", "neural", "networks", "are", "very", "effective", "techniques", "for", "image", "classification", "for", "various", "important", "real", "-", "world", "applications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 3, "i_end": 3}}, {"character": {"text": "techniques", "start": 49, "end": 59, "i_start": 6, "i_end": 6}, "action": {"text": "effective", "start": 39, "end": 48, "i_start": 5, "i_end": 5}}], "id": 1010}, {"sent": "for gravity it is the speed of gravitational waves .", "tokens": ["for", "gravity", "it", "is", "the", "speed", "of", "gravitational", "waves", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}], "id": 1011}, {"sent": "in particular , there is a maximal temperature for a gas of strings in thermal equilibrium , the so-called hagedorn temperature t h .", "tokens": ["in", "particular", ",", "there", "is", "a", "maximal", "temperature", "for", "a", "gas", "of", "strings", "in", "thermal", "equilibrium", ",", "the", "so", "-", "called", "hagedorn", "temperature", "t", "h", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 16, "end": 21, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}], "id": 1012}, {"sent": "nevertheless , one can discuss the scale of fermion mass generation in specific models .", "tokens": ["nevertheless", ",", "one", "can", "discuss", "the", "scale", "of", "fermion", "mass", "generation", "in", "specific", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 15, "end": 18, "i_start": 2, "i_end": 2}, "verb": {"text": "can discuss", "start": 19, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "one", "start": 15, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "discuss", "start": 23, "end": 30, "i_start": 4, "i_end": 4}}], "id": 1013}, {"sent": "deep convolutional neural networks have emerged as highly effective models for these large-scale visual recognition tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "emerged", "as", "highly", "effective", "models", "for", "these", "large", "-", "scale", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have emerged", "start": 35, "end": 47, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "emerged", "start": 40, "end": 47, "i_start": 5, "i_end": 5}}, {"character": {"text": "models", "start": 68, "end": 74, "i_start": 9, "i_end": 9}, "action": {"text": "effective", "start": 58, "end": 67, "i_start": 8, "i_end": 8}}], "id": 1014}, {"sent": "hilbert space frames were introduced by duffin and schaeffer in 1952 to address some deep questions in non-harmonic fourier series .", "tokens": ["hilbert", "space", "frames", "were", "introduced", "by", "duffin", "and", "schaeffer", "in", "1952", "to", "address", "some", "deep", "questions", "in", "non", "-", "harmonic", "fourier", "series", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hilbert space frames", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "were introduced", "start": 21, "end": 36, "i_start": 3, "i_end": 4}}, {"character": {"text": "duffin", "start": 40, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "introduced", "start": 26, "end": 36, "i_start": 4, "i_end": 4}}, {"character": {"text": "schaeffer", "start": 51, "end": 60, "i_start": 8, "i_end": 8}, "action": {"text": "introduced", "start": 26, "end": 36, "i_start": 4, "i_end": 4}}, {"character": {"text": "frames", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "address", "start": 72, "end": 79, "i_start": 12, "i_end": 12}}], "id": 1015}, {"sent": "the original gan paper used minimization of jenson-shannon divergence .", "tokens": ["the", "original", "gan", "paper", "used", "minimization", "of", "jenson", "-", "shannon", "divergence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the original gan paper", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "used", "start": 23, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "paper", "start": 17, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "used", "start": 23, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "jenson", "start": 44, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "divergence", "start": 59, "end": 69, "i_start": 10, "i_end": 10}}], "id": 1016}, {"sent": "binder , in phase transitions and critical phenomena , edited by c .", "tokens": ["binder", ",", "in", "phase", "transitions", "and", "critical", "phenomena", ",", "edited", "by", "c", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "phenomena", "start": 43, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "critical", "start": 34, "end": 42, "i_start": 6, "i_end": 6}}], "id": 1017}, {"sent": "the ordinate is the log of the number of survey pixels having that brightness temperature .", "tokens": ["the", "ordinate", "is", "the", "log", "of", "the", "number", "of", "survey", "pixels", "having", "that", "brightness", "temperature", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ordinate", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "pixels", "start": 48, "end": 54, "i_start": 10, "i_end": 10}, "action": {"text": "survey", "start": 41, "end": 47, "i_start": 9, "i_end": 9}}, {"character": {"text": "pixels", "start": 48, "end": 54, "i_start": 10, "i_end": 10}, "action": {"text": "having", "start": 55, "end": 61, "i_start": 11, "i_end": 11}}], "id": 1018}, {"sent": "each convolutional layer is followed by a batch normalization operation .", "tokens": ["each", "convolutional", "layer", "is", "followed", "by", "a", "batch", "normalization", "operation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each convolutional layer", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is followed", "start": 25, "end": 36, "i_start": 3, "i_end": 4}}], "id": 1019}, {"sent": "in , he et al firstly proposed the residual learning strategy to address the performance degradation problem caused by the increase of network depth .", "tokens": ["in", ",", "he", "et", "al", "firstly", "proposed", "the", "residual", "learning", "strategy", "to", "address", "the", "performance", "degradation", "problem", "caused", "by", "the", "increase", "of", "network", "depth", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "he et al", "start": 5, "end": 13, "i_start": 2, "i_end": 4}, "verb": {"text": "proposed", "start": 22, "end": 30, "i_start": 6, "i_end": 6}}, {"character": {"text": "he", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "action": {"text": "proposed", "start": 22, "end": 30, "i_start": 6, "i_end": 6}}, {"character": {"text": "he", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "action": {"text": "address", "start": 65, "end": 72, "i_start": 12, "i_end": 12}}, {"character": {"text": "increase", "start": 123, "end": 131, "i_start": 20, "i_end": 20}, "action": {"text": "caused", "start": 109, "end": 115, "i_start": 17, "i_end": 17}}], "id": 1020}, {"sent": "periwall , d-brane charges and k-homology , j .", "tokens": ["periwall", ",", "d", "-", "brane", "charges", "and", "k", "-", "homology", ",", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1021}, {"sent": "we find that the splitting between the two dominant peaks in the trilayer system is smaller than the bilayer splitting .", "tokens": ["we", "find", "that", "the", "splitting", "between", "the", "two", "dominant", "peaks", "in", "the", "trilayer", "system", "is", "smaller", "than", "the", "bilayer", "splitting", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 81, "end": 83, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "two dominant peaks", "start": 39, "end": 57, "i_start": 7, "i_end": 9}, "action": {"text": "dominant", "start": 43, "end": 51, "i_start": 8, "i_end": 8}}], "id": 1022}, {"sent": "deep convolutional neural networks have seen great success in a range of computer vision tasks , including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "seen", "great", "success", "in", "a", "range", "of", "computer", "vision", "tasks", ",", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have seen", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "seen", "start": 40, "end": 44, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 51, "end": 58, "i_start": 7, "i_end": 7}}], "id": 1023}, {"sent": "let us therefore begin by examining the brane conditions .", "tokens": ["let", "us", "therefore", "begin", "by", "examining", "the", "brane", "conditions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "begin", "start": 17, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "begin", "start": 17, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "examining", "start": 26, "end": 35, "i_start": 5, "i_end": 5}}], "id": 1024}, {"sent": "moreover , there is a negative result by goodman and leveque that a tvd scheme can be at most first order accurate in more than one spatial dimension .", "tokens": ["moreover", ",", "there", "is", "a", "negative", "result", "by", "goodman", "and", "leveque", "that", "a", "tvd", "scheme", "can", "be", "at", "most", "first", "order", "accurate", "in", "more", "than", "one", "spatial", "dimension", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "there", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "leveque", "start": 53, "end": 60, "i_start": 10, "i_end": 10}}], "id": 1025}, {"sent": "convolutional neural networks have been the driving reason behind recent advances in object detection .", "tokens": ["convolutional", "neural", "networks", "have", "been", "the", "driving", "reason", "behind", "recent", "advances", "in", "object", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "reason", "start": 52, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "driving", "start": 44, "end": 51, "i_start": 6, "i_end": 6}}], "id": 1026}, {"sent": "another option is to use the expectation conditional maximization algorithm .", "tokens": ["another", "option", "is", "to", "use", "the", "expectation", "conditional", "maximization", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another option", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 1027}, {"sent": "topological defects produced at phase transition are known to play an important role in early universe cosmology .", "tokens": ["topological", "defects", "produced", "at", "phase", "transition", "are", "known", "to", "play", "an", "important", "role", "in", "early", "universe", "cosmology", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "topological defects produced at phase transition", "start": 0, "end": 48, "i_start": 0, "i_end": 5}, "verb": {"text": "are known", "start": 49, "end": 58, "i_start": 6, "i_end": 7}}, {"character": {"text": "defects", "start": 12, "end": 19, "i_start": 1, "i_end": 1}, "action": {"text": "play", "start": 62, "end": 66, "i_start": 9, "i_end": 9}}], "id": 1028}, {"sent": "in the right panel , the solid and dashed lines represent the results obtained from the integration of the gpe and odes , respectively .", "tokens": ["in", "the", "right", "panel", ",", "the", "solid", "and", "dashed", "lines", "represent", "the", "results", "obtained", "from", "the", "integration", "of", "the", "gpe", "and", "odes", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the solid and dashed lines", "start": 21, "end": 47, "i_start": 5, "i_end": 9}, "verb": {"text": "represent", "start": 48, "end": 57, "i_start": 10, "i_end": 10}}, {"character": {"text": "lines", "start": 42, "end": 47, "i_start": 9, "i_end": 9}, "action": {"text": "represent", "start": 48, "end": 57, "i_start": 10, "i_end": 10}}, {"character": {"text": "integration", "start": 88, "end": 99, "i_start": 16, "i_end": 16}, "action": {"text": "obtained", "start": 70, "end": 78, "i_start": 13, "i_end": 13}}], "id": 1029}, {"sent": "in recent years , deep convolutional neural networks have been widely used in a variety of computer vision tasks and have achieved unprecedented progress .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "been", "widely", "used", "in", "a", "variety", "of", "computer", "vision", "tasks", "and", "have", "achieved", "unprecedented", "progress", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "used", "start": 70, "end": 74, "i_start": 11, "i_end": 11}}, {"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have been", "start": 53, "end": 62, "i_start": 8, "i_end": 9}}, {"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "achieved", "start": 122, "end": 130, "i_start": 21, "i_end": 21}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 122, "end": 130, "i_start": 21, "i_end": 21}}], "id": 1030}, {"sent": "exchangecorrelation effects were described using the perdew-burke-ernzerhof generalised gradient approximation .", "tokens": ["exchangecorrelation", "effects", "were", "described", "using", "the", "perdew", "-", "burke", "-", "ernzerhof", "generalised", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "exchangecorrelation effects", "start": 0, "end": 27, "i_start": 0, "i_end": 1}, "verb": {"text": "were described", "start": 28, "end": 42, "i_start": 2, "i_end": 3}}], "id": 1031}, {"sent": "advanced machine learning techniques , and in particular deep neural networks , have been applied with great success to a variety of areas , including speech processing .", "tokens": ["advanced", "machine", "learning", "techniques", ",", "and", "in", "particular", "deep", "neural", "networks", ",", "have", "been", "applied", "with", "great", "success", "to", "a", "variety", "of", "areas", ",", "including", "speech", "processing", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1032}, {"sent": "in recent years , methods using convolution neural network have been successful in the classification of image recognition .", "tokens": ["in", "recent", "years", ",", "methods", "using", "convolution", "neural", "network", "have", "been", "successful", "in", "the", "classification", "of", "image", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "methods using convolution neural network", "start": 18, "end": 58, "i_start": 4, "i_end": 8}, "verb": {"text": "have been", "start": 59, "end": 68, "i_start": 9, "i_end": 10}}, {"character": {"text": "methods", "start": 18, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "successful", "start": 69, "end": 79, "i_start": 11, "i_end": 11}}, {"character": {"text": "methods", "start": 18, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "using", "start": 26, "end": 31, "i_start": 5, "i_end": 5}}], "id": 1033}, {"sent": "this fractional order integration is the building block of the riemann-liouville calculus , the most popular formulation of fractional calculus , as well as for several other approaches .", "tokens": ["this", "fractional", "order", "integration", "is", "the", "building", "block", "of", "the", "riemann", "-", "liouville", "calculus", ",", "the", "most", "popular", "formulation", "of", "fractional", "calculus", ",", "as", "well", "as", "for", "several", "other", "approaches", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this fractional order integration", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 4, "i_end": 4}}], "id": 1034}, {"sent": "moreover , there exists some psychological evidence which indicates that human similarity ratings are reflected better by the manhattan metric than by the euclidean metric if different domains are involved .", "tokens": ["moreover", ",", "there", "exists", "some", "psychological", "evidence", "which", "indicates", "that", "human", "similarity", "ratings", "are", "reflected", "better", "by", "the", "manhattan", "metric", "than", "by", "the", "euclidean", "metric", "if", "different", "domains", "are", "involved", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "exists", "start": 17, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "evidence", "start": 43, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "indicates", "start": 58, "end": 67, "i_start": 8, "i_end": 8}}], "id": 1035}, {"sent": "in this way , upper bounds at a particular cl can be compared to a confidence band at a particular cl to assess if they are compatible .", "tokens": ["in", "this", "way", ",", "upper", "bounds", "at", "a", "particular", "cl", "can", "be", "compared", "to", "a", "confidence", "band", "at", "a", "particular", "cl", "to", "assess", "if", "they", "are", "compatible", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "upper bounds at a particular cl", "start": 14, "end": 45, "i_start": 4, "i_end": 9}, "verb": {"text": "can be compared", "start": 46, "end": 61, "i_start": 10, "i_end": 12}}], "id": 1036}, {"sent": "the group ring kg has no nontrivial super idempotents .", "tokens": ["the", "group", "ring", "kg", "has", "no", "nontrivial", "super", "idempotents", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the group ring kg", "start": 0, "end": 17, "i_start": 0, "i_end": 3}, "verb": {"text": "has", "start": 18, "end": 21, "i_start": 4, "i_end": 4}}], "id": 1037}, {"sent": "a conceptual solution to these problems is given by the expectation maximization algorithm .", "tokens": ["a", "conceptual", "solution", "to", "these", "problems", "is", "given", "by", "the", "expectation", "maximization", "algorithm", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "a conceptual solution to these problems", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "is given", "start": 40, "end": 48, "i_start": 6, "i_end": 7}}, {"character": {"text": "algorithm", "start": 81, "end": 90, "i_start": 12, "i_end": 12}, "action": {"text": "given", "start": 43, "end": 48, "i_start": 7, "i_end": 7}}, {"character": {"text": "algorithm", "start": 81, "end": 90, "i_start": 12, "i_end": 12}, "action": {"text": "maximization", "start": 68, "end": 80, "i_start": 11, "i_end": 11}}], "id": 1038}, {"sent": "however aliasing corrupts the edge channels so they usually have to be excluded from the data set .", "tokens": ["however", "aliasing", "corrupts", "the", "edge", "channels", "so", "they", "usually", "have", "to", "be", "excluded", "from", "the", "data", "set", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "however aliasing", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "corrupts", "start": 17, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "aliasing", "start": 8, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "corrupts", "start": 17, "end": 25, "i_start": 2, "i_end": 2}}], "id": 1039}, {"sent": "this foliation is the well-known horosphere foliation .", "tokens": ["this", "foliation", "is", "the", "well", "-", "known", "horosphere", "foliation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this foliation", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 1040}, {"sent": "the kinetic energy is the volume integral of the kinetic energy density , and the potential energy is the volume integral of the potential energy available in the system .", "tokens": ["the", "kinetic", "energy", "is", "the", "volume", "integral", "of", "the", "kinetic", "energy", "density", ",", "and", "the", "potential", "energy", "is", "the", "volume", "integral", "of", "the", "potential", "energy", "available", "in", "the", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the kinetic energy", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 1041}, {"sent": "when the gravitino is the lsp and the nlsp is long lived , the lhc works as the machine for precision studies .", "tokens": ["when", "the", "gravitino", "is", "the", "lsp", "and", "the", "nlsp", "is", "long", "lived", ",", "the", "lhc", "works", "as", "the", "machine", "for", "precision", "studies", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "the lhc", "start": 59, "end": 66, "i_start": 13, "i_end": 14}, "verb": {"text": "works", "start": 67, "end": 72, "i_start": 15, "i_end": 15}}, {"subject": {"text": "the lhc", "start": 59, "end": 66, "i_start": 13, "i_end": 14}, "verb": {"text": "lived", "start": 51, "end": 56, "i_start": 11, "i_end": 11}}, {"character": {"text": "machine", "start": 80, "end": 87, "i_start": 18, "i_end": 18}, "action": {"text": "works", "start": 67, "end": 72, "i_start": 15, "i_end": 15}}, {"character": {"text": "nlsp", "start": 38, "end": 42, "i_start": 8, "i_end": 8}, "action": {"text": "lived", "start": 51, "end": 56, "i_start": 11, "i_end": 11}}], "id": 1042}, {"sent": "previous studies have shown that poor technical skill is associated with an increased risk of adverse patient outcomes .", "tokens": ["previous", "studies", "have", "shown", "that", "poor", "technical", "skill", "is", "associated", "with", "an", "increased", "risk", "of", "adverse", "patient", "outcomes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "previous studies", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "have shown", "start": 17, "end": 27, "i_start": 2, "i_end": 3}}, {"subject": {"text": "poor technical skill", "start": 33, "end": 53, "i_start": 5, "i_end": 7}, "verb": {"text": "associated", "start": 57, "end": 67, "i_start": 9, "i_end": 9}}, {"character": {"text": "studies", "start": 9, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "shown", "start": 22, "end": 27, "i_start": 3, "i_end": 3}}], "id": 1043}, {"sent": "reinforcement learning has shown impressive results in a plethora of simulated tasks , ranging from attaining super-human performance in video-games .", "tokens": ["reinforcement", "learning", "has", "shown", "impressive", "results", "in", "a", "plethora", "of", "simulated", "tasks", ",", "ranging", "from", "attaining", "super", "-", "human", "performance", "in", "video", "-", "games", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "has shown", "start": 23, "end": 32, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 14, "end": 22, "i_start": 1, "i_end": 1}, "action": {"text": "shown", "start": 27, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "human", "start": 116, "end": 121, "i_start": 18, "i_end": 18}, "action": {"text": "performance", "start": 122, "end": 133, "i_start": 19, "i_end": 19}}, {"character": {"text": "results", "start": 44, "end": 51, "i_start": 5, "i_end": 5}, "action": {"text": "impressive", "start": 33, "end": 43, "i_start": 4, "i_end": 4}}], "id": 1044}, {"sent": "yosinski et al showed that features in shallow layers are more general and effective when transferred to other specific problem .", "tokens": ["yosinski", "et", "al", "showed", "that", "features", "in", "shallow", "layers", "are", "more", "general", "and", "effective", "when", "transferred", "to", "other", "specific", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "yosinski et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 15, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "yosinski et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 54, "end": 57, "i_start": 9, "i_end": 9}}, {"character": {"text": "yosinski", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 15, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "other", "start": 105, "end": 110, "i_start": 17, "i_end": 17}, "action": {"text": "showed", "start": 15, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "features", "start": 27, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "effective", "start": 75, "end": 84, "i_start": 13, "i_end": 13}}], "id": 1045}, {"sent": "both criteria have been previously employed in the scientific literature to evaluate single-photon implementations of qkd .", "tokens": ["both", "criteria", "have", "been", "previously", "employed", "in", "the", "scientific", "literature", "to", "evaluate", "single", "-", "photon", "implementations", "of", "qkd", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "both criteria", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "employed", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"subject": {"text": "both criteria", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "have been", "start": 14, "end": 23, "i_start": 2, "i_end": 3}}, {"character": {"text": "criteria", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "evaluate", "start": 76, "end": 84, "i_start": 11, "i_end": 11}}], "id": 1046}, {"sent": "this has coefficients in the universal algebra a aut constructed by wang in .", "tokens": ["this", "has", "coefficients", "in", "the", "universal", "algebra", "a", "aut", "constructed", "by", "wang", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "has", "start": 5, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "has", "start": 5, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "wang", "start": 68, "end": 72, "i_start": 11, "i_end": 11}, "action": {"text": "constructed", "start": 53, "end": 64, "i_start": 9, "i_end": 9}}], "id": 1047}, {"sent": "the widely-used bleu metrics are reported in our quantitative evaluation of the performance of the proposed schemes .", "tokens": ["the", "widely", "-", "used", "bleu", "metrics", "are", "reported", "in", "our", "quantitative", "evaluation", "of", "the", "performance", "of", "the", "proposed", "schemes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the widely-used bleu metrics", "start": 0, "end": 28, "i_start": 0, "i_end": 5}, "verb": {"text": "are reported", "start": 29, "end": 41, "i_start": 6, "i_end": 7}}, {"character": {"text": "schemes", "start": 108, "end": 115, "i_start": 18, "i_end": 18}, "action": {"text": "performance", "start": 80, "end": 91, "i_start": 14, "i_end": 14}}], "id": 1048}, {"sent": "the pascal-sr dataset includes 850 natural images with multiple complex objects derived from the pascal voc 2012 validation set .", "tokens": ["the", "pascal", "-", "sr", "dataset", "includes", "850", "natural", "images", "with", "multiple", "complex", "objects", "derived", "from", "the", "pascal", "voc", "2012", "validation", "set", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the pascal-sr dataset", "start": 0, "end": 21, "i_start": 0, "i_end": 4}, "verb": {"text": "includes", "start": 22, "end": 30, "i_start": 5, "i_end": 5}}], "id": 1049}, {"sent": "this exponentiation is a resummation of the perturbative series .", "tokens": ["this", "exponentiation", "is", "a", "resummation", "of", "the", "perturbative", "series", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this exponentiation", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "exponentiation", "start": 5, "end": 19, "i_start": 1, "i_end": 1}, "action": {"text": "resummation", "start": 25, "end": 36, "i_start": 4, "i_end": 4}}], "id": 1050}, {"sent": "recent studies explored the interpretability of recurrent neural networks for text-based tasks .", "tokens": ["recent", "studies", "explored", "the", "interpretability", "of", "recurrent", "neural", "networks", "for", "text", "-", "based", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent studies", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "explored", "start": 15, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "studies", "start": 7, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "explored", "start": 15, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "studies", "start": 7, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "interpretability", "start": 28, "end": 44, "i_start": 4, "i_end": 4}}], "id": 1051}, {"sent": "likewise , donahue et al also use lstms as the sequential model to generate sentence .", "tokens": ["likewise", ",", "donahue", "et", "al", "also", "use", "lstms", "as", "the", "sequential", "model", "to", "generate", "sentence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "donahue et al", "start": 11, "end": 24, "i_start": 2, "i_end": 4}, "verb": {"text": "use", "start": 30, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "donahue", "start": 11, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 30, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "donahue", "start": 11, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "generate", "start": 67, "end": 75, "i_start": 13, "i_end": 13}}], "id": 1052}, {"sent": "the recent emergence of software-defined networking has led to the development of a number of domain-specific programming languages for networks .", "tokens": ["the", "recent", "emergence", "of", "software", "-", "defined", "networking", "has", "led", "to", "the", "development", "of", "a", "number", "of", "domain", "-", "specific", "programming", "languages", "for", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the recent emergence of software-defined networking", "start": 0, "end": 51, "i_start": 0, "i_end": 7}, "verb": {"text": "has led", "start": 52, "end": 59, "i_start": 8, "i_end": 9}}, {"character": {"text": "emergence", "start": 11, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "led", "start": 56, "end": 59, "i_start": 9, "i_end": 9}}, {"character": {"text": "software", "start": 24, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "defined", "start": 33, "end": 40, "i_start": 6, "i_end": 6}}], "id": 1053}, {"sent": "previous research that addresses mimo settings with a large number of antennas has focused on hard decision algorithms .", "tokens": ["previous", "research", "that", "addresses", "mimo", "settings", "with", "a", "large", "number", "of", "antennas", "has", "focused", "on", "hard", "decision", "algorithms", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "previous research that addresses mimo settings with a large number of antennas", "start": 0, "end": 78, "i_start": 0, "i_end": 11}, "verb": {"text": "has focused", "start": 79, "end": 90, "i_start": 12, "i_end": 13}}, {"character": {"text": "research", "start": 9, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "focused", "start": 83, "end": 90, "i_start": 13, "i_end": 13}}, {"character": {"text": "research", "start": 9, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "addresses", "start": 23, "end": 32, "i_start": 3, "i_end": 3}}], "id": 1054}, {"sent": "in , zhu et al studied using multiple nearby vehicles to collaboratively download data from a rsu and analyzed the average download time using network coding techniques .", "tokens": ["in", ",", "zhu", "et", "al", "studied", "using", "multiple", "nearby", "vehicles", "to", "collaboratively", "download", "data", "from", "a", "rsu", "and", "analyzed", "the", "average", "download", "time", "using", "network", "coding", "techniques", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhu et al", "start": 5, "end": 14, "i_start": 2, "i_end": 4}, "verb": {"text": "studied", "start": 15, "end": 22, "i_start": 5, "i_end": 5}}, {"character": {"text": "zhu", "start": 5, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "studied", "start": 15, "end": 22, "i_start": 5, "i_end": 5}}, {"character": {"text": "zhu", "start": 5, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "using", "start": 23, "end": 28, "i_start": 6, "i_end": 6}}, {"character": {"text": "zhu", "start": 5, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "download", "start": 73, "end": 81, "i_start": 12, "i_end": 12}}], "id": 1055}, {"sent": "mikolov et al introduced an efficient way of representing words in vector space by predicting the current word given context and by predicting surrounding words given current word .", "tokens": ["mikolov", "et", "al", "introduced", "an", "efficient", "way", "of", "representing", "words", "in", "vector", "space", "by", "predicting", "the", "current", "word", "given", "context", "and", "by", "predicting", "surrounding", "words", "given", "current", "word", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 8, "end": 13, "i_start": 1, "i_end": 2}, "verb": {"text": "introduced", "start": 14, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "mikolov", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 14, "end": 24, "i_start": 3, "i_end": 3}}], "id": 1056}, {"sent": "also we have yet to discover the higgs which is the cornerstone of the standard model .", "tokens": ["also", "we", "have", "yet", "to", "discover", "the", "higgs", "which", "is", "the", "cornerstone", "of", "the", "standard", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "have", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "have", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "discover", "start": 20, "end": 28, "i_start": 5, "i_end": 5}}], "id": 1057}, {"sent": "in particular , a substantial amount of work has focused on the study of asymptotic limits of computational complexity of quantile estimation algorithms .", "tokens": ["in", "particular", ",", "a", "substantial", "amount", "of", "work", "has", "focused", "on", "the", "study", "of", "asymptotic", "limits", "of", "computational", "complexity", "of", "quantile", "estimation", "algorithms", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a substantial amount of work", "start": 16, "end": 44, "i_start": 3, "i_end": 7}, "verb": {"text": "has focused", "start": 45, "end": 56, "i_start": 8, "i_end": 9}}], "id": 1058}, {"sent": "historically , many of the se processes application were in the aerospace industry and the defence industry .", "tokens": ["historically", ",", "many", "of", "the", "se", "processes", "application", "were", "in", "the", "aerospace", "industry", "and", "the", "defence", "industry", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many of the se processes application", "start": 15, "end": 51, "i_start": 2, "i_end": 7}, "verb": {"text": "were", "start": 52, "end": 56, "i_start": 8, "i_end": 8}}], "id": 1059}, {"sent": "deep convolutional neural networks have gained tremendous attention recently due to their great success in boosting the performance of image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "gained", "tremendous", "attention", "recently", "due", "to", "their", "great", "success", "in", "boosting", "the", "performance", "of", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have gained", "start": 35, "end": 46, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "gained", "start": 40, "end": 46, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 96, "end": 103, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "boosting", "start": 107, "end": 115, "i_start": 15, "i_end": 15}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 120, "end": 131, "i_start": 17, "i_end": 17}}], "id": 1060}, {"sent": "especially , directed percolation is the most common universality class of absorbing phase transitions .", "tokens": ["especially", ",", "directed", "percolation", "is", "the", "most", "common", "universality", "class", "of", "absorbing", "phase", "transitions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "directed percolation", "start": 13, "end": 33, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 4, "i_end": 4}}], "id": 1061}, {"sent": "direct simulations in the small rms regime suggest quadratic speed enhancement law for non-kpp nonlinearities .", "tokens": ["direct", "simulations", "in", "the", "small", "rms", "regime", "suggest", "quadratic", "speed", "enhancement", "law", "for", "non", "-", "kpp", "nonlinearities", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "direct simulations in the small rms regime", "start": 0, "end": 42, "i_start": 0, "i_end": 6}, "verb": {"text": "suggest", "start": 43, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "simulations", "start": 7, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "suggest", "start": 43, "end": 50, "i_start": 7, "i_end": 7}}], "id": 1062}, {"sent": "recently , a particular class of nonlinear methods , deep neural networks , revolutionized the field of automated image classification by demonstrating impressive performance on large benchmark data sets .", "tokens": ["recently", ",", "a", "particular", "class", "of", "nonlinear", "methods", ",", "deep", "neural", "networks", ",", "revolutionized", "the", "field", "of", "automated", "image", "classification", "by", "demonstrating", "impressive", "performance", "on", "large", "benchmark", "data", "sets", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "a particular class of nonlinear methods", "start": 11, "end": 50, "i_start": 2, "i_end": 7}, "verb": {"text": "revolutionized", "start": 76, "end": 90, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 65, "end": 73, "i_start": 11, "i_end": 11}, "action": {"text": "revolutionized", "start": 76, "end": 90, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 65, "end": 73, "i_start": 11, "i_end": 11}, "action": {"text": "demonstrating", "start": 138, "end": 151, "i_start": 21, "i_end": 21}}, {"character": {"text": "networks", "start": 65, "end": 73, "i_start": 11, "i_end": 11}, "action": {"text": "performance", "start": 163, "end": 174, "i_start": 23, "i_end": 23}}, {"character": {"text": "performance", "start": 163, "end": 174, "i_start": 23, "i_end": 23}, "action": {"text": "impressive", "start": 152, "end": 162, "i_start": 22, "i_end": 22}}], "id": 1063}, {"sent": "this decrease is the consequence of the decay of the bipolar outflow phenomenum during the protostellar evolution .", "tokens": ["this", "decrease", "is", "the", "consequence", "of", "the", "decay", "of", "the", "bipolar", "outflow", "phenomenum", "during", "the", "protostellar", "evolution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this decrease", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1064}, {"sent": "we also obtained the solution to the non-relativistic schroedinger equation as the expected payoff for both the call and put options .", "tokens": ["we", "also", "obtained", "the", "solution", "to", "the", "non", "-", "relativistic", "schroedinger", "equation", "as", "the", "expected", "payoff", "for", "both", "the", "call", "and", "put", "options", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "obtained", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "obtained", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1065}, {"sent": "an important benchmark , for testing community detection algorithms , is the model proposed by girvan and newman , see figure 5 .", "tokens": ["an", "important", "benchmark", ",", "for", "testing", "community", "detection", "algorithms", ",", "is", "the", "model", "proposed", "by", "girvan", "and", "newman", ",", "see", "figure", "5", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "an important benchmark", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 70, "end": 72, "i_start": 10, "i_end": 10}}, {"character": {"text": "girvan", "start": 95, "end": 101, "i_start": 15, "i_end": 15}, "action": {"text": "proposed", "start": 83, "end": 91, "i_start": 13, "i_end": 13}}, {"character": {"text": "newman", "start": 106, "end": 112, "i_start": 17, "i_end": 17}, "action": {"text": "proposed", "start": 83, "end": 91, "i_start": 13, "i_end": 13}}, {"character": {"text": "algorithms", "start": 57, "end": 67, "i_start": 8, "i_end": 8}, "action": {"text": "detection", "start": 47, "end": 56, "i_start": 7, "i_end": 7}}], "id": 1066}, {"sent": "convolutional neural networks have recently achieved great success on various visual recognition tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "achieved", "great", "success", "on", "various", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 7, "i_end": 7}}], "id": 1067}, {"sent": "for the convolutional part that extracts the image features , we used resnet .", "tokens": ["for", "the", "convolutional", "part", "that", "extracts", "the", "image", "features", ",", "we", "used", "resnet", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 62, "end": 64, "i_start": 10, "i_end": 10}, "verb": {"text": "used", "start": 65, "end": 69, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 62, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "used", "start": 65, "end": 69, "i_start": 11, "i_end": 11}}, {"character": {"text": "part", "start": 22, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "extracts", "start": 32, "end": 40, "i_start": 5, "i_end": 5}}], "id": 1068}, {"sent": "sg has only interval subsemirings and no ideals .", "tokens": ["sg", "has", "only", "interval", "subsemirings", "and", "no", "ideals", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "sg", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 1069}, {"sent": "to counter these attacks , approaches based on ubiquitous system monitoring have emerged as an important solution for monitoring system activities and actively detecting possible abnormal system behaviors .", "tokens": ["to", "counter", "these", "attacks", ",", "approaches", "based", "on", "ubiquitous", "system", "monitoring", "have", "emerged", "as", "an", "important", "solution", "for", "monitoring", "system", "activities", "and", "actively", "detecting", "possible", "abnormal", "system", "behaviors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "approaches based on ubiquitous system monitoring", "start": 27, "end": 75, "i_start": 5, "i_end": 10}, "verb": {"text": "have emerged", "start": 76, "end": 88, "i_start": 11, "i_end": 12}}, {"character": {"text": "approaches", "start": 27, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "emerged", "start": 81, "end": 88, "i_start": 12, "i_end": 12}}], "id": 1070}, {"sent": "the toroidal grating spatially disperses the harmonics and re-focuses the selected 38 th harmonic onto the sample .", "tokens": ["the", "toroidal", "grating", "spatially", "disperses", "the", "harmonics", "and", "re", "-", "focuses", "the", "selected", "38", "th", "harmonic", "onto", "the", "sample", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the toroidal grating", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "disperses", "start": 31, "end": 40, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the toroidal grating", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "focuses", "start": 62, "end": 69, "i_start": 10, "i_end": 10}}, {"character": {"text": "grating", "start": 13, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "disperses", "start": 31, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "grating", "start": 13, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "focuses", "start": 62, "end": 69, "i_start": 10, "i_end": 10}}], "id": 1071}, {"sent": "qqqqqqq qqqqqqqq qqqqqqqqq qqqqqqq qqqqqqqq qqqqqqqqq qqqqqqq qqqqqqqq .", "tokens": ["qqqqqqq", "qqqqqqqq", "qqqqqqqqq", "qqqqqqq", "qqqqqqqq", "qqqqqqqqq", "qqqqqqq", "qqqqqqqq", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1072}, {"sent": "for strong enough disorder , multiscaling of the crack front is observed for scales below \u03be .", "tokens": ["for", "strong", "enough", "disorder", ",", "multiscaling", "of", "the", "crack", "front", "is", "observed", "for", "scales", "below", "\u03be", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "multiscaling of the crack front", "start": 29, "end": 60, "i_start": 5, "i_end": 9}, "verb": {"text": "is observed", "start": 61, "end": 72, "i_start": 10, "i_end": 11}}], "id": 1073}, {"sent": "for the discriminator , we use patchgan proposed in and training settings are the same as the generator .", "tokens": ["for", "the", "discriminator", ",", "we", "use", "patchgan", "proposed", "in", "and", "training", "settings", "are", "the", "same", "as", "the", "generator", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 24, "end": 26, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 27, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 27, "end": 30, "i_start": 5, "i_end": 5}}], "id": 1074}, {"sent": "the 3lp model is composed of three linear pendulums to simulate falling , swing and torso dynamics in walking .", "tokens": ["the", "3lp", "model", "is", "composed", "of", "three", "linear", "pendulums", "to", "simulate", "falling", ",", "swing", "and", "torso", "dynamics", "in", "walking", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the 3lp model", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is composed", "start": 14, "end": 25, "i_start": 3, "i_end": 4}}, {"character": {"text": "model", "start": 8, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "simulate", "start": 55, "end": 63, "i_start": 10, "i_end": 10}}], "id": 1075}, {"sent": "thus , we adopt the gated recurrent unit model , a simplified variant of lstm .", "tokens": ["thus", ",", "we", "adopt", "the", "gated", "recurrent", "unit", "model", ",", "a", "simplified", "variant", "of", "lstm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "adopt", "start": 10, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "adopt", "start": 10, "end": 15, "i_start": 3, "i_end": 3}}], "id": 1076}, {"sent": "edge computing is an emerging paradigm which proposes to move cloud services closer to the users and to the devices that produce data , at the edge of the network .", "tokens": ["edge", "computing", "is", "an", "emerging", "paradigm", "which", "proposes", "to", "move", "cloud", "services", "closer", "to", "the", "users", "and", "to", "the", "devices", "that", "produce", "data", ",", "at", "the", "edge", "of", "the", "network", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "edge computing", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "computing", "start": 5, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "proposes", "start": 45, "end": 53, "i_start": 7, "i_end": 7}}, {"character": {"text": "paradigm", "start": 30, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "emerging", "start": 21, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "devices", "start": 108, "end": 115, "i_start": 19, "i_end": 19}, "action": {"text": "produce", "start": 121, "end": 128, "i_start": 21, "i_end": 21}}], "id": 1077}, {"sent": "the colorspin-colorspin interaction potential is introduced in the nuclear local central potential as the major contribution and the colorspin-orbit coupling potential and isospin-orbit coupling potential as non-local potentials are suggested in addition to the spin-orbit coupling potential .", "tokens": ["the", "colorspin", "-", "colorspin", "interaction", "potential", "is", "introduced", "in", "the", "nuclear", "local", "central", "potential", "as", "the", "major", "contribution", "and", "the", "colorspin", "-", "orbit", "coupling", "potential", "and", "isospin", "-", "orbit", "coupling", "potential", "as", "non", "-", "local", "potentials", "are", "suggested", "in", "addition", "to", "the", "spin", "-", "orbit", "coupling", "potential", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the colorspin-colorspin interaction potential", "start": 0, "end": 45, "i_start": 0, "i_end": 5}, "verb": {"text": "is introduced", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "colorspin", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "interaction", "start": 24, "end": 35, "i_start": 4, "i_end": 4}}], "id": 1078}, {"sent": "generative adversarial networks are able to generate high-quality images based on adversarial training .", "tokens": ["generative", "adversarial", "networks", "are", "able", "to", "generate", "high", "-", "quality", "images", "based", "on", "adversarial", "training", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "generate", "start": 44, "end": 52, "i_start": 6, "i_end": 6}}], "id": 1079}, {"sent": "however , at finite temperature , there is a relatively slow escape from this metastable state whose rate we now determine by a simple geometric approach .", "tokens": ["however", ",", "at", "finite", "temperature", ",", "there", "is", "a", "relatively", "slow", "escape", "from", "this", "metastable", "state", "whose", "rate", "we", "now", "determine", "by", "a", "simple", "geometric", "approach", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 34, "end": 39, "i_start": 6, "i_end": 6}, "verb": {"text": "is", "start": 40, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 106, "end": 108, "i_start": 18, "i_end": 18}, "action": {"text": "determine", "start": 113, "end": 122, "i_start": 20, "i_end": 20}}], "id": 1080}, {"sent": "this geometry is a direct higher-dimensional generalization of conifold .", "tokens": ["this", "geometry", "is", "a", "direct", "higher", "-", "dimensional", "generalization", "of", "conifold", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this geometry", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1081}, {"sent": "following it is convenient to write a permutation by putting a vertical bar after each element of e \u03c3 .", "tokens": ["following", "it", "is", "convenient", "to", "write", "a", "permutation", "by", "putting", "a", "vertical", "bar", "after", "each", "element", "of", "e", "\u03c3", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "following it", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 1082}, {"sent": "zhang et al propose to build a multi-column cnn to extract multi-scale features and fuse them together for density map estimation .", "tokens": ["zhang", "et", "al", "propose", "to", "build", "a", "multi", "-", "column", "cnn", "to", "extract", "multi", "-", "scale", "features", "and", "fuse", "them", "together", "for", "density", "map", "estimation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhang et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "build", "start": 23, "end": 28, "i_start": 5, "i_end": 5}}], "id": 1083}, {"sent": "such a protocol of probing the ensemble is known as quantum tomography .", "tokens": ["such", "a", "protocol", "of", "probing", "the", "ensemble", "is", "known", "as", "quantum", "tomography", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such a protocol of probing the ensemble", "start": 0, "end": 39, "i_start": 0, "i_end": 6}, "verb": {"text": "is known", "start": 40, "end": 48, "i_start": 7, "i_end": 8}}], "id": 1084}, {"sent": "in the case of neural networks , typically some form of gradient descent is used , where the gradients are calculated via backpropagation .", "tokens": ["in", "the", "case", "of", "neural", "networks", ",", "typically", "some", "form", "of", "gradient", "descent", "is", "used", ",", "where", "the", "gradients", "are", "calculated", "via", "backpropagation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "some form of gradient descent", "start": 43, "end": 72, "i_start": 8, "i_end": 12}, "verb": {"text": "is used", "start": 73, "end": 80, "i_start": 13, "i_end": 14}}, {"subject": {"text": "the gradients", "start": 89, "end": 102, "i_start": 17, "i_end": 18}, "verb": {"text": "calculated", "start": 107, "end": 117, "i_start": 20, "i_end": 20}}], "id": 1085}, {"sent": "yamashita a , kunimatsu t , yamamoto t , yoshida k .", "tokens": ["yamashita", "a", ",", "kunimatsu", "t", ",", "yamamoto", "t", ",", "yoshida", "k", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1086}, {"sent": "no correlation with the sunspot activity was observed .", "tokens": ["no", "correlation", "with", "the", "sunspot", "activity", "was", "observed", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "no correlation with the sunspot activity", "start": 0, "end": 40, "i_start": 0, "i_end": 5}, "verb": {"text": "was observed", "start": 41, "end": 53, "i_start": 6, "i_end": 7}}, {"character": {"text": "sunspot", "start": 24, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "activity", "start": 32, "end": 40, "i_start": 5, "i_end": 5}}], "id": 1087}, {"sent": "deep convolutional neural networks have recently shown immense success for various image recognition tasks , such as object recognition .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "recently", "shown", "immense", "success", "for", "various", "image", "recognition", "tasks", ",", "such", "as", "object", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "shown", "start": 49, "end": 54, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 63, "end": 70, "i_start": 8, "i_end": 8}}], "id": 1088}, {"sent": "non-locality is another of the most intrinsic features of quantum mechanics .", "tokens": ["non", "-", "locality", "is", "another", "of", "the", "most", "intrinsic", "features", "of", "quantum", "mechanics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "non-locality", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 3, "i_end": 3}}], "id": 1089}, {"sent": "in the following sections , we evaluate our nst on several standard datasets , including cifar-10 , cifar-100 .", "tokens": ["in", "the", "following", "sections", ",", "we", "evaluate", "our", "nst", "on", "several", "standard", "datasets", ",", "including", "cifar-10", ",", "cifar-100", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 28, "end": 30, "i_start": 5, "i_end": 5}, "verb": {"text": "evaluate", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 28, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "evaluate", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}], "id": 1090}, {"sent": "after alexnet achieving the best performance in imagenet large-scale visual recognition challenge , deep convolutional neural network has been applied to various vision tasks , including image classification .", "tokens": ["after", "alexnet", "achieving", "the", "best", "performance", "in", "imagenet", "large", "-", "scale", "visual", "recognition", "challenge", ",", "deep", "convolutional", "neural", "network", "has", "been", "applied", "to", "various", "vision", "tasks", ",", "including", "image", "classification", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "deep convolutional neural network", "start": 100, "end": 133, "i_start": 15, "i_end": 18}, "verb": {"text": "has been applied", "start": 134, "end": 150, "i_start": 19, "i_end": 21}}], "id": 1091}, {"sent": "the solid squares denote nl agns and the open circles denote bl quasars .", "tokens": ["the", "solid", "squares", "denote", "nl", "agns", "and", "the", "open", "circles", "denote", "bl", "quasars", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "squares", "start": 10, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "denote", "start": 18, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "circles", "start": 46, "end": 53, "i_start": 9, "i_end": 9}, "action": {"text": "denote", "start": 54, "end": 60, "i_start": 10, "i_end": 10}}], "id": 1092}, {"sent": "quantum teleportation is a process that can transfer an arbitrary quantum state from a system held by one party , usually called alice , to a system held by a second party , usually called bob .", "tokens": ["quantum", "teleportation", "is", "a", "process", "that", "can", "transfer", "an", "arbitrary", "quantum", "state", "from", "a", "system", "held", "by", "one", "party", ",", "usually", "called", "alice", ",", "to", "a", "system", "held", "by", "a", "second", "party", ",", "usually", "called", "bob", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum teleportation", "start": 0, "end": 21, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "teleportation", "start": 8, "end": 21, "i_start": 1, "i_end": 1}, "action": {"text": "transfer", "start": 44, "end": 52, "i_start": 7, "i_end": 7}}, {"character": {"text": "one party", "start": 102, "end": 111, "i_start": 17, "i_end": 18}, "action": {"text": "held", "start": 94, "end": 98, "i_start": 15, "i_end": 15}}, {"character": {"text": "party", "start": 166, "end": 171, "i_start": 31, "i_end": 31}, "action": {"text": "held", "start": 149, "end": 153, "i_start": 27, "i_end": 27}}], "id": 1093}, {"sent": "connes gave an asymptotic trace formula that is equivalent to the riemann hypothesis .", "tokens": ["connes", "gave", "an", "asymptotic", "trace", "formula", "that", "is", "equivalent", "to", "the", "riemann", "hypothesis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "connes", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "gave", "start": 7, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "connes", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "gave", "start": 7, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "riemann", "start": 66, "end": 73, "i_start": 11, "i_end": 11}, "action": {"text": "hypothesis", "start": 74, "end": 84, "i_start": 12, "i_end": 12}}], "id": 1094}, {"sent": "since electromagnetism is a non-metric aspect of the universal connection , given a stellar object , such as magnetar , with an immense magnetic field that is comparable in curvature to its gravitational field , bending of light should be significantly different than that predicted by general relativity .", "tokens": ["since", "electromagnetism", "is", "a", "non", "-", "metric", "aspect", "of", "the", "universal", "connection", ",", "given", "a", "stellar", "object", ",", "such", "as", "magnetar", ",", "with", "an", "immense", "magnetic", "field", "that", "is", "comparable", "in", "curvature", "to", "its", "gravitational", "field", ",", "bending", "of", "light", "should", "be", "significantly", "different", "than", "that", "predicted", "by", "general", "relativity", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "bending of light", "start": 212, "end": 228, "i_start": 37, "i_end": 39}, "verb": {"text": "should be", "start": 229, "end": 238, "i_start": 40, "i_end": 41}}, {"character": {"text": "relativity", "start": 294, "end": 304, "i_start": 49, "i_end": 49}, "action": {"text": "predicted", "start": 273, "end": 282, "i_start": 46, "i_end": 46}}], "id": 1095}, {"sent": "deep learning has demonstrated superior performance on many traditional computer vision tasks such as classification .", "tokens": ["deep", "learning", "has", "demonstrated", "superior", "performance", "on", "many", "traditional", "computer", "vision", "tasks", "such", "as", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has demonstrated", "start": 14, "end": 30, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "demonstrated", "start": 18, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "performance", "start": 40, "end": 51, "i_start": 5, "i_end": 5}}], "id": 1096}, {"sent": "as follows from , we can construct a smooth nonnegative cutoff function for this haar system .", "tokens": ["as", "follows", "from", ",", "we", "can", "construct", "a", "smooth", "nonnegative", "cutoff", "function", "for", "this", "haar", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "can construct", "start": 21, "end": 34, "i_start": 5, "i_end": 6}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "construct", "start": 25, "end": 34, "i_start": 6, "i_end": 6}}], "id": 1097}, {"sent": "for the totally degenerate case is settled in without any requirements on the chern class for rational manifolds .", "tokens": ["for", "the", "totally", "degenerate", "case", "is", "settled", "in", "without", "any", "requirements", "on", "the", "chern", "class", "for", "rational", "manifolds", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the totally degenerate case", "start": 4, "end": 31, "i_start": 1, "i_end": 4}, "verb": {"text": "is settled in", "start": 32, "end": 45, "i_start": 5, "i_end": 7}}, {"character": {"text": "class", "start": 84, "end": 89, "i_start": 14, "i_end": 14}, "action": {"text": "requirements", "start": 58, "end": 70, "i_start": 10, "i_end": 10}}], "id": 1098}, {"sent": "he et al eased the training of a 152 layers deep cnn by presenting a residual learning framework .", "tokens": ["he", "et", "al", "eased", "the", "training", "of", "a", "152", "layers", "deep", "cnn", "by", "presenting", "a", "residual", "learning", "framework", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "he et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "eased", "start": 9, "end": 14, "i_start": 3, "i_end": 3}}, {"character": {"text": "he", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "eased", "start": 9, "end": 14, "i_start": 3, "i_end": 3}}, {"character": {"text": "he", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "presenting", "start": 56, "end": 66, "i_start": 13, "i_end": 13}}], "id": 1099}, {"sent": "in recent years , convolutional neural networks have achieved superior performance in many visual tasks , such as object classification and detection .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "classification", "and", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 48, "end": 61, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 53, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 71, "end": 82, "i_start": 10, "i_end": 10}}], "id": 1100}, {"sent": "it is originally derived from the large margin nearest neighbor method .", "tokens": ["it", "is", "originally", "derived", "from", "the", "large", "margin", "nearest", "neighbor", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "derived", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}], "id": 1101}, {"sent": "cluster algebras were introduced by fomin-zelevinsky whose original motivation comes from the study of total positivity in algebraic groups and canonical bases in quantum groups .", "tokens": ["cluster", "algebras", "were", "introduced", "by", "fomin", "-", "zelevinsky", "whose", "original", "motivation", "comes", "from", "the", "study", "of", "total", "positivity", "in", "algebraic", "groups", "and", "canonical", "bases", "in", "quantum", "groups", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were introduced", "start": 17, "end": 32, "i_start": 2, "i_end": 3}}, {"subject": {"text": "whose original motivation", "start": 53, "end": 78, "i_start": 8, "i_end": 10}, "verb": {"text": "comes", "start": 79, "end": 84, "i_start": 11, "i_end": 11}}, {"character": {"text": "fomin", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "positivity", "start": 109, "end": 119, "i_start": 17, "i_end": 17}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "total", "start": 103, "end": 108, "i_start": 16, "i_end": 16}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "groups", "start": 133, "end": 139, "i_start": 20, "i_end": 20}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "algebras", "start": 8, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "bases", "start": 154, "end": 159, "i_start": 23, "i_end": 23}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "canonical", "start": 144, "end": 153, "i_start": 22, "i_end": 22}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "groups", "start": 171, "end": 177, "i_start": 26, "i_end": 26}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "quantum", "start": 163, "end": 170, "i_start": 25, "i_end": 25}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "original", "start": 59, "end": 67, "i_start": 9, "i_end": 9}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}], "id": 1102}, {"sent": "the measurements of various hyperfine transitions are listed in table i .", "tokens": ["the", "measurements", "of", "various", "hyperfine", "transitions", "are", "listed", "in", "table", "i", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the measurements of various hyperfine transitions", "start": 0, "end": 49, "i_start": 0, "i_end": 5}, "verb": {"text": "are listed", "start": 50, "end": 60, "i_start": 6, "i_end": 7}}], "id": 1103}, {"sent": "although many studies analysed editing and commenting activity on wikipedia , eg , there are not many quantitative works focusing on the wikipedia usage by the internet users .", "tokens": ["although", "many", "studies", "analysed", "editing", "and", "commenting", "activity", "on", "wikipedia", ",", "eg", ",", "there", "are", "not", "many", "quantitative", "works", "focusing", "on", "the", "wikipedia", "usage", "by", "the", "internet", "users", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "there", "start": 83, "end": 88, "i_start": 13, "i_end": 13}, "verb": {"text": "are not", "start": 89, "end": 96, "i_start": 14, "i_end": 15}}, {"character": {"text": "works", "start": 115, "end": 120, "i_start": 18, "i_end": 18}, "action": {"text": "focusing", "start": 121, "end": 129, "i_start": 19, "i_end": 19}}], "id": 1104}, {"sent": "the prevalent notion of privacy adopted by the privacy research community is differential privacy .", "tokens": ["the", "prevalent", "notion", "of", "privacy", "adopted", "by", "the", "privacy", "research", "community", "is", "differential", "privacy", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the prevalent notion of privacy adopted by the privacy research community", "start": 0, "end": 73, "i_start": 0, "i_end": 10}, "verb": {"text": "is", "start": 74, "end": 76, "i_start": 11, "i_end": 11}}, {"character": {"text": "community", "start": 64, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "adopted", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "community", "start": 64, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "research", "start": 55, "end": 63, "i_start": 9, "i_end": 9}}], "id": 1105}, {"sent": "in this subsection we briefly review some basic notions and facts in the theory of vertex operator algebras from .", "tokens": ["in", "this", "subsection", "we", "briefly", "review", "some", "basic", "notions", "and", "facts", "in", "the", "theory", "of", "vertex", "operator", "algebras", "from", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 3, "i_end": 3}, "verb": {"text": "review", "start": 30, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "review", "start": 30, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "algebras", "start": 99, "end": 107, "i_start": 17, "i_end": 17}, "action": {"text": "operator", "start": 90, "end": 98, "i_start": 16, "i_end": 16}}], "id": 1106}, {"sent": "generative models such as variational autoencoders and generative adversarial networks have emerged as popular techniques for unsupervised learning of intractable distributions .", "tokens": ["generative", "models", "such", "as", "variational", "autoencoders", "and", "generative", "adversarial", "networks", "have", "emerged", "as", "popular", "techniques", "for", "unsupervised", "learning", "of", "intractable", "distributions", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "generative models such as variational autoencoders and generative adversarial networks", "start": 0, "end": 86, "i_start": 0, "i_end": 9}, "verb": {"text": "have emerged", "start": 87, "end": 99, "i_start": 10, "i_end": 11}}, {"character": {"text": "models", "start": 11, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "emerged", "start": 92, "end": 99, "i_start": 11, "i_end": 11}}], "id": 1107}, {"sent": "it was later generalized to the dispersion force between dielectric half spaces .", "tokens": ["it", "was", "later", "generalized", "to", "the", "dispersion", "force", "between", "dielectric", "half", "spaces", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "generalized", "start": 13, "end": 24, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "was", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "force", "start": 43, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "dispersion", "start": 32, "end": 42, "i_start": 6, "i_end": 6}}], "id": 1108}, {"sent": "cosmic strings are predicted , within a wide class of elementary particle models , to form at phase transitions in the early universe .", "tokens": ["cosmic", "strings", "are", "predicted", ",", "within", "a", "wide", "class", "of", "elementary", "particle", "models", ",", "to", "form", "at", "phase", "transitions", "in", "the", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are predicted", "start": 15, "end": 28, "i_start": 2, "i_end": 3}}], "id": 1109}, {"sent": "the properties of riemannian manifolds with semisymmetric and non-metric connection have been studied by many authors .", "tokens": ["the", "properties", "of", "riemannian", "manifolds", "with", "semisymmetric", "and", "non", "-", "metric", "connection", "have", "been", "studied", "by", "many", "authors", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the properties of riemannian manifolds with semisymmetric and non-metric connection", "start": 0, "end": 83, "i_start": 0, "i_end": 11}, "verb": {"text": "have been studied", "start": 84, "end": 101, "i_start": 12, "i_end": 14}}, {"character": {"text": "many", "start": 105, "end": 109, "i_start": 16, "i_end": 16}, "action": {"text": "studied", "start": 94, "end": 101, "i_start": 14, "i_end": 14}}, {"character": {"text": "manifolds", "start": 29, "end": 38, "i_start": 4, "i_end": 4}, "action": {"text": "have", "start": 84, "end": 88, "i_start": 12, "i_end": 12}}], "id": 1110}, {"sent": "we use the expectation-maximization algorithm to learn the distribution parameters from data .", "tokens": ["we", "use", "the", "expectation", "-", "maximization", "algorithm", "to", "learn", "the", "distribution", "parameters", "from", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "learn", "start": 49, "end": 54, "i_start": 8, "i_end": 8}}], "id": 1111}, {"sent": "in fact , by using contraction theory , 54 , 62 we can prove global exponential synchronization of the coupled hopf oscillators .", "tokens": ["in", "fact", ",", "by", "using", "contraction", "theory", ",", "54", ",", "62", "we", "can", "prove", "global", "exponential", "synchronization", "of", "the", "coupled", "hopf", "oscillators", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 48, "end": 50, "i_start": 11, "i_end": 11}, "verb": {"text": "can prove", "start": 51, "end": 60, "i_start": 12, "i_end": 13}}, {"character": {"text": "we", "start": 48, "end": 50, "i_start": 11, "i_end": 11}, "action": {"text": "prove", "start": 55, "end": 60, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 48, "end": 50, "i_start": 11, "i_end": 11}, "action": {"text": "using", "start": 13, "end": 18, "i_start": 4, "i_end": 4}}], "id": 1112}, {"sent": "in recent years , convolutional neural networks have achieved significant success in many computer vision tasks , including the super-resolution problem .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "achieved", "significant", "success", "in", "many", "computer", "vision", "tasks", ",", "including", "the", "super", "-", "resolution", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 48, "end": 61, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 53, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 74, "end": 81, "i_start": 10, "i_end": 10}}], "id": 1113}, {"sent": "the data were calibrated and reduced using the miriad 2 software package .", "tokens": ["the", "data", "were", "calibrated", "and", "reduced", "using", "the", "miriad", "2", "software", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "were calibrated", "start": 9, "end": 24, "i_start": 2, "i_end": 3}}, {"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "reduced", "start": 29, "end": 36, "i_start": 5, "i_end": 5}}], "id": 1114}, {"sent": "the continuous time version of the theorem was recently proved in and we loosely follow the same lines in our proof for the discrete time version .", "tokens": ["the", "continuous", "time", "version", "of", "the", "theorem", "was", "recently", "proved", "in", "and", "we", "loosely", "follow", "the", "same", "lines", "in", "our", "proof", "for", "the", "discrete", "time", "version", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 70, "end": 72, "i_start": 12, "i_end": 12}, "verb": {"text": "proved in", "start": 56, "end": 65, "i_start": 9, "i_end": 10}}, {"subject": {"text": "the continuous time version of the theorem", "start": 0, "end": 42, "i_start": 0, "i_end": 6}, "verb": {"text": "was", "start": 43, "end": 46, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the continuous time version of the theorem", "start": 0, "end": 42, "i_start": 0, "i_end": 6}, "verb": {"text": "follow", "start": 81, "end": 87, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 70, "end": 72, "i_start": 12, "i_end": 12}, "action": {"text": "follow", "start": 81, "end": 87, "i_start": 14, "i_end": 14}}], "id": 1115}, {"sent": "now , we can apply the max-combination property to characterize intermittent observability .", "tokens": ["now", ",", "we", "can", "apply", "the", "max", "-", "combination", "property", "to", "characterize", "intermittent", "observability", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "verb": {"text": "can apply", "start": 9, "end": 18, "i_start": 3, "i_end": 4}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "apply", "start": 13, "end": 18, "i_start": 4, "i_end": 4}}, {"character": {"text": "property", "start": 39, "end": 47, "i_start": 9, "i_end": 9}, "action": {"text": "characterize", "start": 51, "end": 63, "i_start": 11, "i_end": 11}}], "id": 1116}, {"sent": "theory for current transport in superconducting point contacts a .", "tokens": ["theory", "for", "current", "transport", "in", "superconducting", "point", "contacts", "a", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1117}, {"sent": "sakamoto et al propose a stroke-based interface on a tablet pc to control the workspace of a vacuum cleaning robot .", "tokens": ["sakamoto", "et", "al", "propose", "a", "stroke", "-", "based", "interface", "on", "a", "tablet", "pc", "to", "control", "the", "workspace", "of", "a", "vacuum", "cleaning", "robot", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "sakamoto et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 15, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "sakamoto", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 15, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "sakamoto", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "control", "start": 66, "end": 73, "i_start": 14, "i_end": 14}}, {"character": {"text": "robot", "start": 109, "end": 114, "i_start": 21, "i_end": 21}, "action": {"text": "cleaning", "start": 100, "end": 108, "i_start": 20, "i_end": 20}}], "id": 1118}, {"sent": "the standard choice is the ms mass definition .", "tokens": ["the", "standard", "choice", "is", "the", "ms", "mass", "definition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the standard choice", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 1119}, {"sent": "primitive predicates for encoding the usual arithmetic operations over r .", "tokens": ["primitive", "predicates", "for", "encoding", "the", "usual", "arithmetic", "operations", "over", "r", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1120}, {"sent": "this geometry is a simplified representation of a connecting rod , which is a component of an internal combustion engine , and represents a classic linear case in the stress-strain static analysis .", "tokens": ["this", "geometry", "is", "a", "simplified", "representation", "of", "a", "connecting", "rod", ",", "which", "is", "a", "component", "of", "an", "internal", "combustion", "engine", ",", "and", "represents", "a", "classic", "linear", "case", "in", "the", "stress", "-", "strain", "static", "analysis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this geometry", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"subject": {"text": "this geometry", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "represents", "start": 127, "end": 137, "i_start": 22, "i_end": 22}}, {"character": {"text": "geometry", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "represents", "start": 127, "end": 137, "i_start": 22, "i_end": 22}}, {"character": {"text": "rod", "start": 61, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "representation", "start": 30, "end": 44, "i_start": 5, "i_end": 5}}], "id": 1121}, {"sent": "depending on the coupling of the field s to matter , these fluctuations may lead to dangerous isocurvature perturbations of the metric , or to non-gaussian adiabatic perturbations , as in the theory of the curvaton field .", "tokens": ["depending", "on", "the", "coupling", "of", "the", "field", "s", "to", "matter", ",", "these", "fluctuations", "may", "lead", "to", "dangerous", "isocurvature", "perturbations", "of", "the", "metric", ",", "or", "to", "non", "-", "gaussian", "adiabatic", "perturbations", ",", "as", "in", "the", "theory", "of", "the", "curvaton", "field", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "these fluctuations", "start": 53, "end": 71, "i_start": 11, "i_end": 12}, "verb": {"text": "may lead", "start": 72, "end": 80, "i_start": 13, "i_end": 14}}, {"character": {"text": "fluctuations", "start": 59, "end": 71, "i_start": 12, "i_end": 12}, "action": {"text": "lead", "start": 76, "end": 80, "i_start": 14, "i_end": 14}}], "id": 1122}, {"sent": "following the general protocol of , we say this environment is completely under the control of the eavesdropper .", "tokens": ["following", "the", "general", "protocol", "of", ",", "we", "say", "this", "environment", "is", "completely", "under", "the", "control", "of", "the", "eavesdropper", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 36, "end": 38, "i_start": 6, "i_end": 6}, "verb": {"text": "say", "start": 39, "end": 42, "i_start": 7, "i_end": 7}}, {"subject": {"text": "we", "start": 36, "end": 38, "i_start": 6, "i_end": 6}, "verb": {"text": "is", "start": 60, "end": 62, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 36, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "say", "start": 39, "end": 42, "i_start": 7, "i_end": 7}}], "id": 1123}, {"sent": "as quoted in the introduction , the categorical smash product we consider in this paper is an alternative approach to the ring without identity defined by m .", "tokens": ["as", "quoted", "in", "the", "introduction", ",", "the", "categorical", "smash", "product", "we", "consider", "in", "this", "paper", "is", "an", "alternative", "approach", "to", "the", "ring", "without", "identity", "defined", "by", "m", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the categorical smash product we consider in this paper", "start": 32, "end": 87, "i_start": 6, "i_end": 14}, "verb": {"text": "is", "start": 88, "end": 90, "i_start": 15, "i_end": 15}}, {"character": {"text": "product", "start": 54, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "approach", "start": 106, "end": 114, "i_start": 18, "i_end": 18}}, {"character": {"text": "we", "start": 62, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "consider", "start": 65, "end": 73, "i_start": 11, "i_end": 11}}], "id": 1124}, {"sent": "since 2012 , neural networks and deep architectures have proven very effective in application areas such as computer vision .", "tokens": ["since", "2012", ",", "neural", "networks", "and", "deep", "architectures", "have", "proven", "very", "effective", "in", "application", "areas", "such", "as", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks and deep architectures", "start": 13, "end": 51, "i_start": 3, "i_end": 7}, "verb": {"text": "have proven", "start": 52, "end": 63, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 20, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "effective", "start": 69, "end": 78, "i_start": 11, "i_end": 11}}, {"character": {"text": "architectures", "start": 38, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "effective", "start": 69, "end": 78, "i_start": 11, "i_end": 11}}], "id": 1125}, {"sent": "the ucf101 dataset contains 13,320 videos from 101 action categories .", "tokens": ["the", "ucf101", "dataset", "contains", "13,320", "videos", "from", "101", "action", "categories", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ucf101 dataset", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "contains", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "dataset", "start": 11, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "contains", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}], "id": 1126}, {"sent": "we begin with a brief review of aspects of vertex operator algebras and their modules , see refsfor more details .", "tokens": ["we", "begin", "with", "a", "brief", "review", "of", "aspects", "of", "vertex", "operator", "algebras", "and", "their", "modules", ",", "see", "refsfor", "more", "details", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "begin", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "begin", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "review", "start": 22, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "algebras", "start": 59, "end": 67, "i_start": 11, "i_end": 11}, "action": {"text": "operator", "start": 50, "end": 58, "i_start": 10, "i_end": 10}}], "id": 1127}, {"sent": "in recent years , deep convolutional neural networks have set the state-of-the-art on a broad range of computer vision tasks .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "set", "the", "state", "-", "of", "-", "the", "-", "art", "on", "a", "broad", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have set", "start": 53, "end": 61, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "set", "start": 58, "end": 61, "i_start": 9, "i_end": 9}}], "id": 1128}, {"sent": "the generalized gradient approximation of perdew-burke-ernzerhof type is used to deal with the exchange and correlation potential .", "tokens": ["the", "generalized", "gradient", "approximation", "of", "perdew", "-", "burke", "-", "ernzerhof", "type", "is", "used", "to", "deal", "with", "the", "exchange", "and", "correlation", "potential", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation of perdew-burke-ernzerhof type", "start": 0, "end": 69, "i_start": 0, "i_end": 10}, "verb": {"text": "is used", "start": 70, "end": 77, "i_start": 11, "i_end": 12}}], "id": 1129}, {"sent": "an alternative explicit algebraic solution to the coupled differential equations is possible using the quasi-steady-state approximations developed by mott and collaborators .", "tokens": ["an", "alternative", "explicit", "algebraic", "solution", "to", "the", "coupled", "differential", "equations", "is", "possible", "using", "the", "quasi", "-", "steady", "-", "state", "approximations", "developed", "by", "mott", "and", "collaborators", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "an alternative explicit algebraic solution to the coupled differential equations", "start": 0, "end": 80, "i_start": 0, "i_end": 9}, "verb": {"text": "is", "start": 81, "end": 83, "i_start": 10, "i_end": 10}}, {"character": {"text": "mott", "start": 150, "end": 154, "i_start": 22, "i_end": 22}, "action": {"text": "developed", "start": 137, "end": 146, "i_start": 20, "i_end": 20}}], "id": 1130}, {"sent": "the distance dependence of tip-surface capacitance and surface potential directly .", "tokens": ["the", "distance", "dependence", "of", "tip", "-", "surface", "capacitance", "and", "surface", "potential", "directly", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "capacitance", "start": 39, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "dependence", "start": 13, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "potential", "start": 63, "end": 72, "i_start": 10, "i_end": 10}, "action": {"text": "dependence", "start": 13, "end": 23, "i_start": 2, "i_end": 2}}], "id": 1131}, {"sent": "a monopole is a connection a and a higgs field \u03c6 satisfying the bogomolny equations and some particular boundary conditions .", "tokens": ["a", "monopole", "is", "a", "connection", "a", "and", "a", "higgs", "field", "\u03c6", "satisfying", "the", "bogomolny", "equations", "and", "some", "particular", "boundary", "conditions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a monopole", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}], "id": 1132}, {"sent": "physically , string theory is a two-dimensional conformal field theory on a riemannian surface .", "tokens": ["physically", ",", "string", "theory", "is", "a", "two", "-", "dimensional", "conformal", "field", "theory", "on", "a", "riemannian", "surface", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "string theory", "start": 13, "end": 26, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 4, "i_end": 4}}], "id": 1133}, {"sent": "the algorithm exploits the relationship between the curvatures and torsions of two similar space curves and extends the results of , where the problem of detecting the symmetries of rational space curves was addressed .", "tokens": ["the", "algorithm", "exploits", "the", "relationship", "between", "the", "curvatures", "and", "torsions", "of", "two", "similar", "space", "curves", "and", "extends", "the", "results", "of", ",", "where", "the", "problem", "of", "detecting", "the", "symmetries", "of", "rational", "space", "curves", "was", "addressed", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the algorithm", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "exploits", "start": 14, "end": 22, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the algorithm", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "extends", "start": 108, "end": 115, "i_start": 16, "i_end": 16}}, {"character": {"text": "algorithm", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "exploits", "start": 14, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "two similar space curves", "start": 79, "end": 103, "i_start": 11, "i_end": 14}, "action": {"text": "relationship", "start": 27, "end": 39, "i_start": 4, "i_end": 4}}], "id": 1134}, {"sent": "we therefore use the conjugate gradient algorithm to compute the solution to the linear systems .", "tokens": ["we", "therefore", "use", "the", "conjugate", "gradient", "algorithm", "to", "compute", "the", "solution", "to", "the", "linear", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 13, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 13, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compute", "start": 53, "end": 60, "i_start": 8, "i_end": 8}}], "id": 1135}, {"sent": "in parallel , deep convolutional neural networks have proven their effectiveness in many computer vision fields such as object classification .", "tokens": ["in", "parallel", ",", "deep", "convolutional", "neural", "networks", "have", "proven", "their", "effectiveness", "in", "many", "computer", "vision", "fields", "such", "as", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 14, "end": 48, "i_start": 3, "i_end": 6}, "verb": {"text": "have proven", "start": 49, "end": 60, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 40, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "proven", "start": 54, "end": 60, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 40, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "effectiveness", "start": 67, "end": 80, "i_start": 10, "i_end": 10}}], "id": 1136}, {"sent": "a specification is a state machine with a supplementary property .", "tokens": ["a", "specification", "is", "a", "state", "machine", "with", "a", "supplementary", "property", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a specification", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 1137}, {"sent": "entropy , as a measure of information content and complexity , was first introduced by shannon .", "tokens": ["entropy", ",", "as", "a", "measure", "of", "information", "content", "and", "complexity", ",", "was", "first", "introduced", "by", "shannon", "."], "score": [1, 0, 0, 0, 1], "labels": [{"subject": {"text": "entropy", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "introduced", "start": 73, "end": 83, "i_start": 13, "i_end": 13}}, {"subject": {"text": "entropy", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "was", "start": 63, "end": 66, "i_start": 11, "i_end": 11}}, {"character": {"text": "shannon", "start": 87, "end": 94, "i_start": 15, "i_end": 15}, "action": {"text": "introduced", "start": 73, "end": 83, "i_start": 13, "i_end": 13}}], "id": 1138}, {"sent": "the classical morrey spaces m p , \u03bb have been introduced by morrey in to study the local behavior of solutions of second order elliptic partial differential equations .", "tokens": ["the", "classical", "morrey", "spaces", "m", "p", ",", "\u03bb", "have", "been", "introduced", "by", "morrey", "in", "to", "study", "the", "local", "behavior", "of", "solutions", "of", "second", "order", "elliptic", "partial", "differential", "equations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the classical morrey spaces m p , \u03bb", "start": 0, "end": 35, "i_start": 0, "i_end": 7}, "verb": {"text": "have been introduced", "start": 36, "end": 56, "i_start": 8, "i_end": 10}}, {"character": {"text": "morrey", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 46, "end": 56, "i_start": 10, "i_end": 10}}, {"character": {"text": "morrey", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "study", "start": 73, "end": 78, "i_start": 15, "i_end": 15}}], "id": 1139}, {"sent": "asterisks denote fr i sources , diamonds are fr ii sources , and the solid line shows the best fit to the fr i luminosity correlation .", "tokens": ["asterisks", "denote", "fr", "i", "sources", ",", "diamonds", "are", "fr", "ii", "sources", ",", "and", "the", "solid", "line", "shows", "the", "best", "fit", "to", "the", "fr", "i", "luminosity", "correlation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "asterisks", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "line", "start": 75, "end": 79, "i_start": 15, "i_end": 15}, "action": {"text": "shows", "start": 80, "end": 85, "i_start": 16, "i_end": 16}}], "id": 1140}, {"sent": "in particular , due to the ekc mechanism , the superhorizon modes could bring modifications at observational scales , which is expected as an approximately linear function of positions .", "tokens": ["in", "particular", ",", "due", "to", "the", "ekc", "mechanism", ",", "the", "superhorizon", "modes", "could", "bring", "modifications", "at", "observational", "scales", ",", "which", "is", "expected", "as", "an", "approximately", "linear", "function", "of", "positions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the superhorizon modes", "start": 43, "end": 65, "i_start": 9, "i_end": 11}, "verb": {"text": "could bring", "start": 66, "end": 77, "i_start": 12, "i_end": 13}}, {"character": {"text": "modes", "start": 60, "end": 65, "i_start": 11, "i_end": 11}, "action": {"text": "bring", "start": 72, "end": 77, "i_start": 13, "i_end": 13}}, {"character": {"text": "positions", "start": 175, "end": 184, "i_start": 28, "i_end": 28}, "action": {"text": "function", "start": 163, "end": 171, "i_start": 26, "i_end": 26}}], "id": 1141}, {"sent": "let a be a cocommutative ordinary bialgebra in characteristic zero .", "tokens": ["let", "a", "be", "a", "cocommutative", "ordinary", "bialgebra", "in", "characteristic", "zero", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1142}, {"sent": "in recent months it has been shown that many field theory results for strongly interacting gauge theories can be derived from string theory .", "tokens": ["in", "recent", "months", "it", "has", "been", "shown", "that", "many", "field", "theory", "results", "for", "strongly", "interacting", "gauge", "theories", "can", "be", "derived", "from", "string", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 17, "end": 19, "i_start": 3, "i_end": 3}, "verb": {"text": "has been shown", "start": 20, "end": 34, "i_start": 4, "i_end": 6}}, {"subject": {"text": "many field theory", "start": 40, "end": 57, "i_start": 8, "i_end": 10}, "verb": {"text": "results", "start": 58, "end": 65, "i_start": 11, "i_end": 11}}, {"character": {"text": "theories", "start": 97, "end": 105, "i_start": 16, "i_end": 16}, "action": {"text": "interacting", "start": 79, "end": 90, "i_start": 14, "i_end": 14}}], "id": 1143}, {"sent": "density-functional theory calculations were performed using the vienna ab initio simulation package with plane-wave basis set .", "tokens": ["density", "-", "functional", "theory", "calculations", "were", "performed", "using", "the", "vienna", "ab", "initio", "simulation", "package", "with", "plane", "-", "wave", "basis", "set", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "density-functional theory calculations", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "were performed", "start": 39, "end": 53, "i_start": 5, "i_end": 6}}], "id": 1144}, {"sent": "the generalized gradient approximation was used in conjunction with the perdew , burke , and ernzerhof density functional .", "tokens": ["the", "generalized", "gradient", "approximation", "was", "used", "in", "conjunction", "with", "the", "perdew", ",", "burke", ",", "and", "ernzerhof", "density", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation", "start": 0, "end": 38, "i_start": 0, "i_end": 3}, "verb": {"text": "was used", "start": 39, "end": 47, "i_start": 4, "i_end": 5}}], "id": 1145}, {"sent": "the representation can be further improved by compensating for unwanted camera motions .", "tokens": ["the", "representation", "can", "be", "further", "improved", "by", "compensating", "for", "unwanted", "camera", "motions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the representation", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "improved", "start": 34, "end": 42, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the representation", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "can be", "start": 19, "end": 25, "i_start": 2, "i_end": 3}}], "id": 1146}, {"sent": "convolutional neural networks have significantly boosted the performance of a variety of visual analysis tasks , such as image classification in recent years due to its high capacity in learning discriminative features .", "tokens": ["convolutional", "neural", "networks", "have", "significantly", "boosted", "the", "performance", "of", "a", "variety", "of", "visual", "analysis", "tasks", ",", "such", "as", "image", "classification", "in", "recent", "years", "due", "to", "its", "high", "capacity", "in", "learning", "discriminative", "features", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "boosted", "start": 49, "end": 56, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "boosted", "start": 49, "end": 56, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 61, "end": 72, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "learning", "start": 186, "end": 194, "i_start": 29, "i_end": 29}}, {"character": {"text": "features", "start": 210, "end": 218, "i_start": 31, "i_end": 31}, "action": {"text": "discriminative", "start": 195, "end": 209, "i_start": 30, "i_end": 30}}], "id": 1147}, {"sent": "in recent years , convolutional neural networks have made great achievements in various tasks .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "made", "great", "achievements", "in", "various", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have made", "start": 48, "end": 57, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achievements", "start": 64, "end": 76, "i_start": 10, "i_end": 10}}], "id": 1148}, {"sent": "in recent years , the accuracy of object detection has been dramatically improved thanks to the advance of deep convolutional neural network .", "tokens": ["in", "recent", "years", ",", "the", "accuracy", "of", "object", "detection", "has", "been", "dramatically", "improved", "thanks", "to", "the", "advance", "of", "deep", "convolutional", "neural", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the accuracy of object detection", "start": 18, "end": 50, "i_start": 4, "i_end": 8}, "verb": {"text": "improved", "start": 73, "end": 81, "i_start": 12, "i_end": 12}}, {"subject": {"text": "the accuracy of object detection", "start": 18, "end": 50, "i_start": 4, "i_end": 8}, "verb": {"text": "has been", "start": 51, "end": 59, "i_start": 9, "i_end": 10}}], "id": 1149}, {"sent": "such effective coupling of two qubits via a resonator has been first proposed with superconducting qubits .", "tokens": ["such", "effective", "coupling", "of", "two", "qubits", "via", "a", "resonator", "has", "been", "first", "proposed", "with", "superconducting", "qubits", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "such effective coupling of two qubits via a resonator", "start": 0, "end": 53, "i_start": 0, "i_end": 8}, "verb": {"text": "proposed", "start": 69, "end": 77, "i_start": 12, "i_end": 12}}, {"subject": {"text": "such effective coupling of two qubits via a resonator", "start": 0, "end": 53, "i_start": 0, "i_end": 8}, "verb": {"text": "has been", "start": 54, "end": 62, "i_start": 9, "i_end": 10}}, {"character": {"text": "coupling", "start": 15, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "effective", "start": 5, "end": 14, "i_start": 1, "i_end": 1}}], "id": 1150}, {"sent": "in our context , these policies are motivated by the risk of cache pollution in small dynamically instantiated caches , and more generally by the long tail of one-timers observed in edge networks .", "tokens": ["in", "our", "context", ",", "these", "policies", "are", "motivated", "by", "the", "risk", "of", "cache", "pollution", "in", "small", "dynamically", "instantiated", "caches", ",", "and", "more", "generally", "by", "the", "long", "tail", "of", "one", "-", "timers", "observed", "in", "edge", "networks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "these policies", "start": 17, "end": 31, "i_start": 4, "i_end": 5}, "verb": {"text": "are motivated", "start": 32, "end": 45, "i_start": 6, "i_end": 7}}, {"character": {"text": "risk", "start": 53, "end": 57, "i_start": 10, "i_end": 10}, "action": {"text": "motivated", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "caches", "start": 111, "end": 117, "i_start": 18, "i_end": 18}, "action": {"text": "motivated", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "dynamically", "start": 86, "end": 97, "i_start": 16, "i_end": 16}, "action": {"text": "motivated", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "small", "start": 80, "end": 85, "i_start": 15, "i_end": 15}, "action": {"text": "motivated", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "tail", "start": 151, "end": 155, "i_start": 26, "i_end": 26}, "action": {"text": "motivated", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 187, "end": 195, "i_start": 34, "i_end": 34}, "action": {"text": "motivated", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "edge", "start": 182, "end": 186, "i_start": 33, "i_end": 33}, "action": {"text": "motivated", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 187, "end": 195, "i_start": 34, "i_end": 34}, "action": {"text": "motivated", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "edge", "start": 182, "end": 186, "i_start": 33, "i_end": 33}, "action": {"text": "motivated", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 187, "end": 195, "i_start": 34, "i_end": 34}, "action": {"text": "motivated", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "edge", "start": 182, "end": 186, "i_start": 33, "i_end": 33}, "action": {"text": "motivated", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 187, "end": 195, "i_start": 34, "i_end": 34}, "action": {"text": "motivated", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "edge", "start": 182, "end": 186, "i_start": 33, "i_end": 33}, "action": {"text": "motivated", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 187, "end": 195, "i_start": 34, "i_end": 34}, "action": {"text": "motivated", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "edge", "start": 182, "end": 186, "i_start": 33, "i_end": 33}, "action": {"text": "motivated", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "cache", "start": 61, "end": 66, "i_start": 12, "i_end": 12}, "action": {"text": "pollution", "start": 67, "end": 76, "i_start": 13, "i_end": 13}}], "id": 1151}, {"sent": "in particular , convolutional neural networks has been popular in vision and audio recognition areas .", "tokens": ["in", "particular", ",", "convolutional", "neural", "networks", "has", "been", "popular", "in", "vision", "and", "audio", "recognition", "areas", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "has been", "start": 46, "end": 54, "i_start": 6, "i_end": 7}}], "id": 1152}, {"sent": "avila proved , among other results , that the le is positive for a dense subset of smooth quasi-periodic cocycles .", "tokens": ["avila", "proved", ",", "among", "other", "results", ",", "that", "the", "le", "is", "positive", "for", "a", "dense", "subset", "of", "smooth", "quasi", "-", "periodic", "cocycles", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "avila", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "proved", "start": 6, "end": 12, "i_start": 1, "i_end": 1}}, {"subject": {"text": "avila", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 49, "end": 51, "i_start": 10, "i_end": 10}}, {"character": {"text": "avila", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proved", "start": 6, "end": 12, "i_start": 1, "i_end": 1}}], "id": 1153}, {"sent": "for the individual classifiers , we used linearsvc , 2 an svm implementation based on the liblinear library , with a linear kernel .", "tokens": ["for", "the", "individual", "classifiers", ",", "we", "used", "linearsvc", ",", "2", "an", "svm", "implementation", "based", "on", "the", "liblinear", "library", ",", "with", "a", "linear", "kernel", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 33, "end": 35, "i_start": 5, "i_end": 5}, "verb": {"text": "used", "start": 36, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 33, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "used", "start": 36, "end": 40, "i_start": 6, "i_end": 6}}], "id": 1154}, {"sent": "at the other end of the spectrum is the special case of only human agents .", "tokens": ["at", "the", "other", "end", "of", "the", "spectrum", "is", "the", "special", "case", "of", "only", "human", "agents", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1155}, {"sent": "their filtration is the same as that of x , y .", "tokens": ["their", "filtration", "is", "the", "same", "as", "that", "of", "x", ",", "y", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "their filtration", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}], "id": 1156}, {"sent": "self-similarity is a strong geometric condition on the space-time .", "tokens": ["self", "-", "similarity", "is", "a", "strong", "geometric", "condition", "on", "the", "space", "-", "time", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "self-similarity", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 1157}, {"sent": "goodfellow et al proposed an easy and effective framework of generative models based on an adversarial process .", "tokens": ["goodfellow", "et", "al", "proposed", "an", "easy", "and", "effective", "framework", "of", "generative", "models", "based", "on", "an", "adversarial", "process", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "goodfellow", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "framework", "start": 48, "end": 57, "i_start": 8, "i_end": 8}, "action": {"text": "effective", "start": 38, "end": 47, "i_start": 7, "i_end": 7}}], "id": 1158}, {"sent": "while the lightest neutralino is the lsp , which is stable and candidate to dark matter in this r-parity conserving model , the heavier neutralinos will decay into it .", "tokens": ["while", "the", "lightest", "neutralino", "is", "the", "lsp", ",", "which", "is", "stable", "and", "candidate", "to", "dark", "matter", "in", "this", "r", "-", "parity", "conserving", "model", ",", "the", "heavier", "neutralinos", "will", "decay", "into", "it", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the heavier neutralinos", "start": 124, "end": 147, "i_start": 24, "i_end": 26}, "verb": {"text": "will decay", "start": 148, "end": 158, "i_start": 27, "i_end": 28}}, {"character": {"text": "lsp", "start": 37, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "candidate", "start": 63, "end": 72, "i_start": 12, "i_end": 12}}, {"character": {"text": "model", "start": 116, "end": 121, "i_start": 22, "i_end": 22}, "action": {"text": "conserving", "start": 105, "end": 115, "i_start": 21, "i_end": 21}}], "id": 1159}, {"sent": "in the geometric limit the yukawa couplings automatically vanish for supersymmetric brane configurations .", "tokens": ["in", "the", "geometric", "limit", "the", "yukawa", "couplings", "automatically", "vanish", "for", "supersymmetric", "brane", "configurations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the yukawa couplings", "start": 23, "end": 43, "i_start": 4, "i_end": 6}, "verb": {"text": "vanish", "start": 58, "end": 64, "i_start": 8, "i_end": 8}}], "id": 1160}, {"sent": "the polynomials are dual to the big q-jacobi polynomials .", "tokens": ["the", "polynomials", "are", "dual", "to", "the", "big", "q", "-", "jacobi", "polynomials", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the polynomials", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 16, "end": 19, "i_start": 2, "i_end": 2}}], "id": 1161}, {"sent": "the example of a characteristically nilpotent lie algebra , given in , is 3-step nilpotent .", "tokens": ["the", "example", "of", "a", "characteristically", "nilpotent", "lie", "algebra", ",", "given", "in", ",", "is", "3", "-", "step", "nilpotent", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the example of a characteristically nilpotent lie algebra", "start": 0, "end": 57, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 71, "end": 73, "i_start": 12, "i_end": 12}}], "id": 1162}, {"sent": "deep neural networks have recently achieved performance breakthroughs in many of computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "recently", "achieved", "performance", "breakthroughs", "in", "many", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "breakthroughs", "start": 56, "end": 69, "i_start": 7, "i_end": 7}}], "id": 1163}, {"sent": "at the first stage , we fine-tune the regionnet using weights pre-trained on imagenet .", "tokens": ["at", "the", "first", "stage", ",", "we", "fine", "-", "tune", "the", "regionnet", "using", "weights", "pre", "-", "trained", "on", "imagenet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 21, "end": 23, "i_start": 5, "i_end": 5}, "action": {"text": "tune", "start": 29, "end": 33, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 5, "i_end": 5}, "action": {"text": "using", "start": 48, "end": 53, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 5, "i_end": 5}, "action": {"text": "trained", "start": 66, "end": 73, "i_start": 15, "i_end": 15}}], "id": 1164}, {"sent": "we compare our system for uav racing to the two most related and recent network architectures , the first denoted as nvidia and the second as mav .", "tokens": ["we", "compare", "our", "system", "for", "uav", "racing", "to", "the", "two", "most", "related", "and", "recent", "network", "architectures", ",", "the", "first", "denoted", "as", "nvidia", "and", "the", "second", "as", "mav", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 1165}, {"sent": "quantum mechanics is a positive definite one but we shall also show that our is not hermitian under this scalar product differently than what happens in susy qm .", "tokens": ["quantum", "mechanics", "is", "a", "positive", "definite", "one", "but", "we", "shall", "also", "show", "that", "our", "is", "not", "hermitian", "under", "this", "scalar", "product", "differently", "than", "what", "happens", "in", "susy", "qm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "quantum mechanics", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 49, "end": 51, "i_start": 8, "i_end": 8}, "verb": {"text": "show", "start": 63, "end": 67, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 8, "i_end": 8}, "action": {"text": "show", "start": 63, "end": 67, "i_start": 11, "i_end": 11}}], "id": 1166}, {"sent": "deep learning has been used as a dramatically powerful tool in computer vision tasks such as image recognition .", "tokens": ["deep", "learning", "has", "been", "used", "as", "a", "dramatically", "powerful", "tool", "in", "computer", "vision", "tasks", "such", "as", "image", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has been used", "start": 14, "end": 27, "i_start": 2, "i_end": 4}}], "id": 1167}, {"sent": "prove all chain lattices are distributive .", "tokens": ["prove", "all", "chain", "lattices", "are", "distributive", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "lattices", "start": 16, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "distributive", "start": 29, "end": 41, "i_start": 5, "i_end": 5}}], "id": 1168}, {"sent": "deep neural networks have seen great success in many cognitive applications such as image classification .", "tokens": ["deep", "neural", "networks", "have", "seen", "great", "success", "in", "many", "cognitive", "applications", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have seen", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 37, "end": 44, "i_start": 6, "i_end": 6}}], "id": 1169}, {"sent": "to be specific , we build a u-net like model with only 6 convolutions and 2 poolings .", "tokens": ["to", "be", "specific", ",", "we", "build", "a", "u", "-", "net", "like", "model", "with", "only", "6", "convolutions", "and", "2", "poolings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 17, "end": 19, "i_start": 4, "i_end": 4}, "verb": {"text": "build", "start": 20, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 17, "end": 19, "i_start": 4, "i_end": 4}, "action": {"text": "build", "start": 20, "end": 25, "i_start": 5, "i_end": 5}}], "id": 1170}, {"sent": "the only modification is the introduction 2 matrix structure due to the tensor coupling of the 3p2 and 3f2 channels .", "tokens": ["the", "only", "modification", "is", "the", "introduction", "2", "matrix", "structure", "due", "to", "the", "tensor", "coupling", "of", "the", "3p2", "and", "3f2", "channels", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the only modification", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 1171}, {"sent": "according to the minicolumn hypothesis , brain cells should have a columnar arrangement perpendicular to the pial surface of the brain , and this should be highly pronounced in brodmann area 4 .", "tokens": ["according", "to", "the", "minicolumn", "hypothesis", ",", "brain", "cells", "should", "have", "a", "columnar", "arrangement", "perpendicular", "to", "the", "pial", "surface", "of", "the", "brain", ",", "and", "this", "should", "be", "highly", "pronounced", "in", "brodmann", "area", "4", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "brain cells", "start": 41, "end": 52, "i_start": 6, "i_end": 7}, "verb": {"text": "should have", "start": 53, "end": 64, "i_start": 8, "i_end": 9}}, {"subject": {"text": "brain cells", "start": 41, "end": 52, "i_start": 6, "i_end": 7}, "verb": {"text": "pronounced", "start": 163, "end": 173, "i_start": 27, "i_end": 27}}, {"character": {"text": "minicolumn", "start": 17, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "hypothesis", "start": 28, "end": 38, "i_start": 4, "i_end": 4}}], "id": 1172}, {"sent": "in these calculations , the generalized-gradient approximation with the perdew-burke-ernzerhof exchange-correlation functional were used .", "tokens": ["in", "these", "calculations", ",", "the", "generalized", "-", "gradient", "approximation", "with", "the", "perdew", "-", "burke", "-", "ernzerhof", "exchange", "-", "correlation", "functional", "were", "used", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalized-gradient approximation with the perdew-burke-ernzerhof exchange-correlation functional", "start": 24, "end": 126, "i_start": 4, "i_end": 19}, "verb": {"text": "were used", "start": 127, "end": 136, "i_start": 20, "i_end": 21}}], "id": 1173}, {"sent": "there is a natural equivalence relation on central s 1 -extensions , whose equivalence classes are classified by the cohomology group h 3 .", "tokens": ["there", "is", "a", "natural", "equivalence", "relation", "on", "central", "s", "1", "-extensions", ",", "whose", "equivalence", "classes", "are", "classified", "by", "the", "cohomology", "group", "h", "3", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "group", "start": 128, "end": 133, "i_start": 20, "i_end": 20}, "action": {"text": "classified", "start": 99, "end": 109, "i_start": 16, "i_end": 16}}], "id": 1174}, {"sent": "on top of that , we use atrous spatial pyramid pooling module proposed in deeplab v3 to capture multi-scale information .", "tokens": ["on", "top", "of", "that", ",", "we", "use", "atrous", "spatial", "pyramid", "pooling", "module", "proposed", "in", "deeplab", "v3", "to", "capture", "multi", "-", "scale", "information", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 17, "end": 19, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 20, "end": 23, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 17, "end": 19, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 20, "end": 23, "i_start": 6, "i_end": 6}}, {"character": {"text": "module", "start": 55, "end": 61, "i_start": 11, "i_end": 11}, "action": {"text": "capture", "start": 88, "end": 95, "i_start": 17, "i_end": 17}}], "id": 1175}, {"sent": "central limit theorems for nonlinear fun tionals of stationary gaussian pro esses .", "tokens": ["central", "limit", "theorems", "for", "nonlinear", "fun", "tionals", "of", "stationary", "gaussian", "pro", "esses", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1176}, {"sent": "then we show how we can estimate the error rate in the code bits based on that in the checked bits in the proposed protocol , that is the central point of the proof .", "tokens": ["then", "we", "show", "how", "we", "can", "estimate", "the", "error", "rate", "in", "the", "code", "bits", "based", "on", "that", "in", "the", "checked", "bits", "in", "the", "proposed", "protocol", ",", "that", "is", "the", "central", "point", "of", "the", "proof", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 17, "end": 19, "i_start": 4, "i_end": 4}, "verb": {"text": "estimate", "start": 24, "end": 32, "i_start": 6, "i_end": 6}}, {"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "is", "start": 131, "end": 133, "i_start": 27, "i_end": 27}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "estimate", "start": 24, "end": 32, "i_start": 6, "i_end": 6}}], "id": 1177}, {"sent": "polar codes are the first codes with an explicit construction to asymptotically achieve the symmetric capacity of memoryless channels using a low-complexity , successive-cancellation , decoding algorithm .", "tokens": ["polar", "codes", "are", "the", "first", "codes", "with", "an", "explicit", "construction", "to", "asymptotically", "achieve", "the", "symmetric", "capacity", "of", "memoryless", "channels", "using", "a", "low", "-", "complexity", ",", "successive", "-", "cancellation", ",", "decoding", "algorithm", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "polar codes", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 12, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "codes", "start": 6, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "achieve", "start": 80, "end": 87, "i_start": 12, "i_end": 12}}, {"character": {"text": "channels", "start": 125, "end": 133, "i_start": 18, "i_end": 18}, "action": {"text": "-", "start": 145, "end": 146, "i_start": 22, "i_end": 22}}, {"character": {"text": "codes", "start": 6, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "using", "start": 134, "end": 139, "i_start": 19, "i_end": 19}}], "id": 1178}, {"sent": "separation logic is a well-established approach for deductive verification of programs that manipulate dynamic data structures .", "tokens": ["separation", "logic", "is", "a", "well", "-", "established", "approach", "for", "deductive", "verification", "of", "programs", "that", "manipulate", "dynamic", "data", "structures", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "separation logic", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "logic", "start": 11, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "approach", "start": 39, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "programs", "start": 78, "end": 86, "i_start": 12, "i_end": 12}, "action": {"text": "manipulate", "start": 92, "end": 102, "i_start": 14, "i_end": 14}}, {"character": {"text": "verification", "start": 62, "end": 74, "i_start": 10, "i_end": 10}, "action": {"text": "deductive", "start": 52, "end": 61, "i_start": 9, "i_end": 9}}], "id": 1179}, {"sent": "as a common practice , we use the resnet-50 as the backbone for prm and mask r-cnn .", "tokens": ["as", "a", "common", "practice", ",", "we", "use", "the", "resnet-50", "as", "the", "backbone", "for", "prm", "and", "mask", "r", "-", "cnn", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 26, "end": 29, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 26, "end": 29, "i_start": 6, "i_end": 6}}], "id": 1180}, {"sent": "over the past few years , there has been an intense research interest , not only theoretically , but also experimentally , in the physics of atomic bose-einstein condensates .", "tokens": ["over", "the", "past", "few", "years", ",", "there", "has", "been", "an", "intense", "research", "interest", ",", "not", "only", "theoretically", ",", "but", "also", "experimentally", ",", "in", "the", "physics", "of", "atomic", "bose", "-", "einstein", "condensates", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 26, "end": 31, "i_start": 6, "i_end": 6}, "verb": {"text": "has been", "start": 32, "end": 40, "i_start": 7, "i_end": 8}}], "id": 1181}, {"sent": "results of the black hole mass estimation procedures .", "tokens": ["results", "of", "the", "black", "hole", "mass", "estimation", "procedures", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1182}, {"sent": "in the recent years the reinforcement learning approach has experienced unprecedented success , reaching human-level performance in several domains , including atari video-games or the ancient game of go .", "tokens": ["in", "the", "recent", "years", "the", "reinforcement", "learning", "approach", "has", "experienced", "unprecedented", "success", ",", "reaching", "human", "-", "level", "performance", "in", "several", "domains", ",", "including", "atari", "video", "-", "games", "or", "the", "ancient", "game", "of", "go", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the reinforcement learning approach", "start": 20, "end": 55, "i_start": 4, "i_end": 7}, "verb": {"text": "has experienced", "start": 56, "end": 71, "i_start": 8, "i_end": 9}}, {"character": {"text": "approach", "start": 47, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "experienced", "start": 60, "end": 71, "i_start": 9, "i_end": 9}}, {"character": {"text": "approach", "start": 47, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "success", "start": 86, "end": 93, "i_start": 11, "i_end": 11}}, {"character": {"text": "approach", "start": 47, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "reaching", "start": 96, "end": 104, "i_start": 13, "i_end": 13}}, {"character": {"text": "approach", "start": 47, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "performance", "start": 117, "end": 128, "i_start": 17, "i_end": 17}}], "id": 1183}, {"sent": "convolutional neural networks have achieved significant progress in computer vision tasks such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "significant", "progress", "in", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 1184}, {"sent": "carter et al , the opal vertex drift chamber , nucl .", "tokens": ["carter", "et", "al", ",", "the", "opal", "vertex", "drift", "chamber", ",", "nucl", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1185}, {"sent": "they showed in particular classified polar actions on the compact symmetric spaces of rank one .", "tokens": ["they", "showed", "in", "particular", "classified", "polar", "actions", "on", "the", "compact", "symmetric", "spaces", "of", "rank", "one", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "showed", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "classified", "start": 26, "end": 36, "i_start": 4, "i_end": 4}}], "id": 1186}, {"sent": "smirnov , the fourloop planar amplitude and cusp anomalous dimension in maximally supersymmetric yang-mills theory , phys .", "tokens": ["smirnov", ",", "the", "fourloop", "planar", "amplitude", "and", "cusp", "anomalous", "dimension", "in", "maximally", "supersymmetric", "yang", "-", "mills", "theory", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1187}, {"sent": "deep convolutional neural networks have been successfully used in various computer vision applications such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successfully", "used", "in", "various", "computer", "vision", "applications", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "used", "start": 58, "end": 62, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}], "id": 1188}, {"sent": "the numbers of atoms in the two condensates vs .", "tokens": ["the", "numbers", "of", "atoms", "in", "the", "two", "condensates", "vs", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1189}, {"sent": "this omplex solution is obviously quite di erent from the orresponding dbb solution .", "tokens": ["this", "omplex", "solution", "is", "obviously", "quite", "di", "erent", "from", "the", "orresponding", "dbb", "solution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this omplex solution", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 3, "i_end": 3}}], "id": 1190}, {"sent": "the hardening of the g mode is due to nonadiabatic removal of a kohn anomaly at \u03b3 .", "tokens": ["the", "hardening", "of", "the", "g", "mode", "is", "due", "to", "nonadiabatic", "removal", "of", "a", "kohn", "anomaly", "at", "\u03b3", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the hardening of the g mode", "start": 0, "end": 27, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 6, "i_end": 6}}], "id": 1191}, {"sent": "this dispersion relation is the same as the classic bcs relation \u03bei , k .", "tokens": ["this", "dispersion", "relation", "is", "the", "same", "as", "the", "classic", "bcs", "relation", "\u03bei", ",", "k", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this dispersion relation", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 3, "i_end": 3}}], "id": 1192}, {"sent": "recent works such as propose more sophisticated sampling techniques that reduce variance of aggregate estimation .", "tokens": ["recent", "works", "such", "as", "propose", "more", "sophisticated", "sampling", "techniques", "that", "reduce", "variance", "of", "aggregate", "estimation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "recent works such as", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "propose", "start": 21, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "techniques", "start": 57, "end": 67, "i_start": 8, "i_end": 8}, "action": {"text": "reduce", "start": 73, "end": 79, "i_start": 10, "i_end": 10}}], "id": 1193}, {"sent": "the coupling between random walk and alignment in model gives rise to interesting phenomena which were little explored so far , cf .", "tokens": ["the", "coupling", "between", "random", "walk", "and", "alignment", "in", "model", "gives", "rise", "to", "interesting", "phenomena", "which", "were", "little", "explored", "so", "far", ",", "cf", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the coupling between random walk and alignment in model", "start": 0, "end": 55, "i_start": 0, "i_end": 8}, "verb": {"text": "gives", "start": 56, "end": 61, "i_start": 9, "i_end": 9}}, {"character": {"text": "coupling", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "rise", "start": 62, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "phenomena", "start": 82, "end": 91, "i_start": 13, "i_end": 13}, "action": {"text": "interesting", "start": 70, "end": 81, "i_start": 12, "i_end": 12}}], "id": 1194}, {"sent": "therefore , wireless energy transfer techniques have attracted increasing research interests to prolong the battery lifetime of energy-constrained wireless networks .", "tokens": ["therefore", ",", "wireless", "energy", "transfer", "techniques", "have", "attracted", "increasing", "research", "interests", "to", "prolong", "the", "battery", "lifetime", "of", "energy", "-", "constrained", "wireless", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "wireless energy transfer techniques", "start": 12, "end": 47, "i_start": 2, "i_end": 5}, "verb": {"text": "have attracted", "start": 48, "end": 62, "i_start": 6, "i_end": 7}}, {"character": {"text": "techniques", "start": 37, "end": 47, "i_start": 5, "i_end": 5}, "action": {"text": "attracted", "start": 53, "end": 62, "i_start": 7, "i_end": 7}}, {"character": {"text": "techniques", "start": 37, "end": 47, "i_start": 5, "i_end": 5}, "action": {"text": "prolong", "start": 96, "end": 103, "i_start": 12, "i_end": 12}}], "id": 1195}, {"sent": "the problem is inspired by the structural risk minimization in machine learning .", "tokens": ["the", "problem", "is", "inspired", "by", "the", "structural", "risk", "minimization", "in", "machine", "learning", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the problem", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is inspired", "start": 12, "end": 23, "i_start": 2, "i_end": 3}}, {"character": {"text": "minimization", "start": 47, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "inspired", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "learning", "start": 71, "end": 79, "i_start": 11, "i_end": 11}, "action": {"text": "minimization", "start": 47, "end": 59, "i_start": 8, "i_end": 8}}], "id": 1196}, {"sent": "lefever , spatial dissipative structures in passive optical systems , phys .", "tokens": ["lefever", ",", "spatial", "dissipative", "structures", "in", "passive", "optical", "systems", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "structures", "start": 30, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "dissipative", "start": 18, "end": 29, "i_start": 3, "i_end": 3}}], "id": 1197}, {"sent": "we shall use this type of associativity and routine extensions of the principle without further comment .", "tokens": ["we", "shall", "use", "this", "type", "of", "associativity", "and", "routine", "extensions", "of", "the", "principle", "without", "further", "comment", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "shall use", "start": 3, "end": 12, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 9, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "comment", "start": 96, "end": 103, "i_start": 15, "i_end": 15}}], "id": 1198}, {"sent": "here , we want to extend these results to the case when the energy levels of the system are almost degenerate .", "tokens": ["here", ",", "we", "want", "to", "extend", "these", "results", "to", "the", "case", "when", "the", "energy", "levels", "of", "the", "system", "are", "almost", "degenerate", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "want", "start": 10, "end": 14, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "want", "start": 10, "end": 14, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "extend", "start": 18, "end": 24, "i_start": 5, "i_end": 5}}], "id": 1199}, {"sent": "in recent years , deep convolutional neural networks have set the state-of-the-art on a broad range of computer vision tasks .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "set", "the", "state", "-", "of", "-", "the", "-", "art", "on", "a", "broad", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have set", "start": 53, "end": 61, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "set", "start": 58, "end": 61, "i_start": 9, "i_end": 9}}], "id": 1200}, {"sent": "ideally , the best orientation is the one which is the most efficient .", "tokens": ["ideally", ",", "the", "best", "orientation", "is", "the", "one", "which", "is", "the", "most", "efficient", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the best orientation", "start": 10, "end": 30, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 5, "i_end": 5}}], "id": 1201}, {"sent": "renormalization group analysis of turbulence .", "tokens": ["renormalization", "group", "analysis", "of", "turbulence", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "group", "start": 16, "end": 21, "i_start": 1, "i_end": 1}, "action": {"text": "analysis", "start": 22, "end": 30, "i_start": 2, "i_end": 2}}], "id": 1202}, {"sent": "in computer vision tasks , convolutional neural network is one of the most widely used models .", "tokens": ["in", "computer", "vision", "tasks", ",", "convolutional", "neural", "network", "is", "one", "of", "the", "most", "widely", "used", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural network", "start": 27, "end": 55, "i_start": 5, "i_end": 7}, "verb": {"text": "is", "start": 56, "end": 58, "i_start": 8, "i_end": 8}}], "id": 1203}, {"sent": "the calculation of the gravitational force uses a combination of the particle mesh algorithm for large separations and the hierarchical tree algorithm at small distances .", "tokens": ["the", "calculation", "of", "the", "gravitational", "force", "uses", "a", "combination", "of", "the", "particle", "mesh", "algorithm", "for", "large", "separations", "and", "the", "hierarchical", "tree", "algorithm", "at", "small", "distances", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the calculation of the gravitational force", "start": 0, "end": 42, "i_start": 0, "i_end": 5}, "verb": {"text": "uses", "start": 43, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "calculation", "start": 4, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "uses", "start": 43, "end": 47, "i_start": 6, "i_end": 6}}], "id": 1204}, {"sent": "this profile is the phase of the polyakov loop as a function of its distance to the minimal surface .", "tokens": ["this", "profile", "is", "the", "phase", "of", "the", "polyakov", "loop", "as", "a", "function", "of", "its", "distance", "to", "the", "minimal", "surface", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this profile", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "distance", "start": 68, "end": 76, "i_start": 14, "i_end": 14}, "action": {"text": "function", "start": 52, "end": 60, "i_start": 11, "i_end": 11}}], "id": 1205}, {"sent": "reinforcement learning has achieved significant success in domains such as game-playing .", "tokens": ["reinforcement", "learning", "has", "achieved", "significant", "success", "in", "domains", "such", "as", "game", "-", "playing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "has achieved", "start": 23, "end": 35, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 14, "end": 22, "i_start": 1, "i_end": 1}, "action": {"text": "success", "start": 48, "end": 55, "i_start": 5, "i_end": 5}}], "id": 1206}, {"sent": "deep convolutional neural networks have achieved state-of-the-art performance on several image processing and computer vision tasks like image classification , object detection , and segmentation .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "several", "image", "processing", "and", "computer", "vision", "tasks", "like", "image", "classification", ",", "object", "detection", ",", "and", "segmentation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 66, "end": 77, "i_start": 13, "i_end": 13}}], "id": 1207}, {"sent": "deep convolutional neural networks have successfully revolutionized various challenging tasks , eg , image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "successfully", "revolutionized", "various", "challenging", "tasks", ",", "eg", ",", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "revolutionized", "start": 53, "end": 67, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "revolutionized", "start": 53, "end": 67, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "successfully", "start": 40, "end": 52, "i_start": 5, "i_end": 5}}], "id": 1208}, {"sent": "the exchange correlation functional was approximated by gga-pbe functional .", "tokens": ["the", "exchange", "correlation", "functional", "was", "approximated", "by", "gga", "-", "pbe", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange correlation functional", "start": 0, "end": 35, "i_start": 0, "i_end": 3}, "verb": {"text": "was approximated", "start": 36, "end": 52, "i_start": 4, "i_end": 5}}], "id": 1209}, {"sent": "khimshiashvili , complex geometry of quadrilateral linkages , proc .", "tokens": ["khimshiashvili", ",", "complex", "geometry", "of", "quadrilateral", "linkages", ",", "proc", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1210}, {"sent": "the proposed method is compared against several state-of-the-art supervised hashing methods including bre .", "tokens": ["the", "proposed", "method", "is", "compared", "against", "several", "state", "-", "of", "-", "the", "-", "art", "supervised", "hashing", "methods", "including", "bre", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the proposed method", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is compared", "start": 20, "end": 31, "i_start": 3, "i_end": 4}}], "id": 1211}, {"sent": "select a subset is called the integral polytope .", "tokens": ["select", "a", "subset", "is", "called", "the", "integral", "polytope", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a subset", "start": 7, "end": 15, "i_start": 1, "i_end": 2}, "verb": {"text": "is called", "start": 16, "end": 25, "i_start": 3, "i_end": 4}}], "id": 1212}, {"sent": "neural machine translation has recently become the stateof-the-art approach to machine translation .", "tokens": ["neural", "machine", "translation", "has", "recently", "become", "the", "stateof", "-", "the", "-", "art", "approach", "to", "machine", "translation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural machine translation", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "become", "start": 40, "end": 46, "i_start": 5, "i_end": 5}}, {"subject": {"text": "neural machine translation", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "has", "start": 27, "end": 30, "i_start": 3, "i_end": 3}}], "id": 1213}, {"sent": "in geometry optimization , van der waals interactions were considered at the van der waals density functional level with the optb86b functional for the exchange potential .", "tokens": ["in", "geometry", "optimization", ",", "van", "der", "waals", "interactions", "were", "considered", "at", "the", "van", "der", "waals", "density", "functional", "level", "with", "the", "optb86b", "functional", "for", "the", "exchange", "potential", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "van der waals interactions", "start": 27, "end": 53, "i_start": 4, "i_end": 7}, "verb": {"text": "were considered", "start": 54, "end": 69, "i_start": 8, "i_end": 9}}, {"subject": {"text": "van der waals interactions", "start": 27, "end": 53, "i_start": 4, "i_end": 7}, "verb": {"text": "density", "start": 91, "end": 98, "i_start": 15, "i_end": 15}}], "id": 1214}, {"sent": "using the triangularshaped cloud method , we assign the particles onto n 2 g grids in lens planes , then compute the projected density contrast at each plane .", "tokens": ["using", "the", "triangularshaped", "cloud", "method", ",", "we", "assign", "the", "particles", "onto", "n", "2", "g", "grids", "in", "lens", "planes", ",", "then", "compute", "the", "projected", "density", "contrast", "at", "each", "plane", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "we", "start": 42, "end": 44, "i_start": 6, "i_end": 6}, "verb": {"text": "compute", "start": 105, "end": 112, "i_start": 20, "i_end": 20}}, {"subject": {"text": "we", "start": 42, "end": 44, "i_start": 6, "i_end": 6}, "verb": {"text": "assign", "start": 45, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 42, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "assign", "start": 45, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 42, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "compute", "start": 105, "end": 112, "i_start": 20, "i_end": 20}}], "id": 1215}, {"sent": "aytar et al pioneered the idea of using video as a form of supervision in order to learn salient sound representations .", "tokens": ["aytar", "et", "al", "pioneered", "the", "idea", "of", "using", "video", "as", "a", "form", "of", "supervision", "in", "order", "to", "learn", "salient", "sound", "representations", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 6, "end": 11, "i_start": 1, "i_end": 2}, "verb": {"text": "pioneered", "start": 12, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "aytar", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "pioneered", "start": 12, "end": 21, "i_start": 3, "i_end": 3}}], "id": 1216}, {"sent": "al proposed an hourglass structure where feature maps are passed with skip connections through stacks for pose estimation .", "tokens": ["al", "proposed", "an", "hourglass", "structure", "where", "feature", "maps", "are", "passed", "with", "skip", "connections", "through", "stacks", "for", "pose", "estimation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "al", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "proposed", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "al", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 1217}, {"sent": "we evaluate our method on the pascal voc 2007 and 2010 datasets , as they are the most widely-used benchmark in weakly supervised object detection .", "tokens": ["we", "evaluate", "our", "method", "on", "the", "pascal", "voc", "2007", "and", "2010", "datasets", ",", "as", "they", "are", "the", "most", "widely", "-", "used", "benchmark", "in", "weakly", "supervised", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 1218}, {"sent": "here , we make use of an extensive open source machine learning library in python called scikit-learn .", "tokens": ["here", ",", "we", "make", "use", "of", "an", "extensive", "open", "source", "machine", "learning", "library", "in", "python", "called", "scikit", "-", "learn", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "make", "start": 10, "end": 14, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 15, "end": 18, "i_start": 4, "i_end": 4}}], "id": 1219}, {"sent": "hsia et al , further extends tron and uses preconditioned conjugate gradient which uses weighted average of identity matrix and diagonal matrix as a preconditioner , to solve the trust region subproblem .", "tokens": ["hsia", "et", "al", ",", "further", "extends", "tron", "and", "uses", "preconditioned", "conjugate", "gradient", "which", "uses", "weighted", "average", "of", "identity", "matrix", "and", "diagonal", "matrix", "as", "a", "preconditioner", ",", "to", "solve", "the", "trust", "region", "subproblem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hsia et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "extends", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"subject": {"text": "hsia et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "uses", "start": 38, "end": 42, "i_start": 8, "i_end": 8}}, {"character": {"text": "hsia", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "extends", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "hsia", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "uses", "start": 38, "end": 42, "i_start": 8, "i_end": 8}}, {"character": {"text": "gradient", "start": 68, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "uses", "start": 83, "end": 87, "i_start": 13, "i_end": 13}}, {"character": {"text": "hsia", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "solve", "start": 169, "end": 174, "i_start": 27, "i_end": 27}}], "id": 1220}, {"sent": "convolutional neural networks have proven useful for a variety of high-level vision tasks .", "tokens": ["convolutional", "neural", "networks", "have", "proven", "useful", "for", "a", "variety", "of", "high", "-", "level", "vision", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have proven", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}], "id": 1221}, {"sent": "generalization performance and versatility of deep learning models are highly dependent on availability of abundant data .", "tokens": ["generalization", "performance", "and", "versatility", "of", "deep", "learning", "models", "are", "highly", "dependent", "on", "availability", "of", "abundant", "data", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "generalization performance and versatility of deep learning models", "start": 0, "end": 66, "i_start": 0, "i_end": 7}, "verb": {"text": "are", "start": 67, "end": 70, "i_start": 8, "i_end": 8}}, {"character": {"text": "performance", "start": 15, "end": 26, "i_start": 1, "i_end": 1}, "action": {"text": "dependent", "start": 78, "end": 87, "i_start": 10, "i_end": 10}}, {"character": {"text": "versatility", "start": 31, "end": 42, "i_start": 3, "i_end": 3}, "action": {"text": "dependent", "start": 78, "end": 87, "i_start": 10, "i_end": 10}}, {"character": {"text": "models", "start": 60, "end": 66, "i_start": 7, "i_end": 7}, "action": {"text": "dependent", "start": 78, "end": 87, "i_start": 10, "i_end": 10}}, {"character": {"text": "models", "start": 60, "end": 66, "i_start": 7, "i_end": 7}, "action": {"text": "performance", "start": 15, "end": 26, "i_start": 1, "i_end": 1}}, {"character": {"text": "models", "start": 60, "end": 66, "i_start": 7, "i_end": 7}, "action": {"text": "learning", "start": 51, "end": 59, "i_start": 6, "i_end": 6}}], "id": 1222}, {"sent": "however , we can still obtain non-trivial upper bounds on the payments in nash equilibria .", "tokens": ["however", ",", "we", "can", "still", "obtain", "non", "-", "trivial", "upper", "bounds", "on", "the", "payments", "in", "nash", "equilibria", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "obtain", "start": 23, "end": 29, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "can", "start": 13, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "obtain", "start": 23, "end": 29, "i_start": 5, "i_end": 5}}], "id": 1223}, {"sent": "he et al presented a residual learning framework in which inputs are added to the output of the stacked layers , thus asymptotically approximating the desired underlying mapping function .", "tokens": ["he", "et", "al", "presented", "a", "residual", "learning", "framework", "in", "which", "inputs", "are", "added", "to", "the", "output", "of", "the", "stacked", "layers", ",", "thus", "asymptotically", "approximating", "the", "desired", "underlying", "mapping", "function", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "he et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "presented", "start": 9, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "he", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "presented", "start": 9, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "added", "start": 69, "end": 74, "i_start": 12, "i_end": 12}, "action": {"text": "approximating", "start": 133, "end": 146, "i_start": 23, "i_end": 23}}, {"character": {"text": "function", "start": 178, "end": 186, "i_start": 28, "i_end": 28}, "action": {"text": "underlying", "start": 159, "end": 169, "i_start": 26, "i_end": 26}}], "id": 1224}, {"sent": "chen and geelen conjecture that the class of quasi-graphic matroids has only finitely many excluded minors .", "tokens": ["chen", "and", "geelen", "conjecture", "that", "the", "class", "of", "quasi", "-", "graphic", "matroids", "has", "only", "finitely", "many", "excluded", "minors", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "chen and geelen conjecture that the class of quasi-graphic matroids has only finitely many", "start": 0, "end": 90, "i_start": 0, "i_end": 15}, "verb": {"text": "excluded", "start": 91, "end": 99, "i_start": 16, "i_end": 16}}, {"subject": {"text": "chen and geelen conjecture that the class of quasi-graphic matroids has only finitely many", "start": 0, "end": 90, "i_start": 0, "i_end": 15}, "verb": {"text": "has", "start": 68, "end": 71, "i_start": 12, "i_end": 12}}, {"character": {"text": "chen", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "conjecture", "start": 16, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "geelen", "start": 9, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "conjecture", "start": 16, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "class", "start": 36, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "has", "start": 68, "end": 71, "i_start": 12, "i_end": 12}}], "id": 1225}, {"sent": "to prove the theorem , we use the following lemma .", "tokens": ["to", "prove", "the", "theorem", ",", "we", "use", "the", "following", "lemma", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 26, "end": 29, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 26, "end": 29, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "action": {"text": "prove", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 1226}, {"sent": "in this paper , we focus on applications of operadic cobar constructions to the homotopy categories of algebras over operads .", "tokens": ["in", "this", "paper", ",", "we", "focus", "on", "applications", "of", "operadic", "cobar", "constructions", "to", "the", "homotopy", "categories", "of", "algebras", "over", "operads", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "focus", "start": 19, "end": 24, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "focus", "start": 19, "end": 24, "i_start": 5, "i_end": 5}}], "id": 1227}, {"sent": "we need to prepare some more for our next theorem .", "tokens": ["we", "need", "to", "prepare", "some", "more", "for", "our", "next", "theorem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "need", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "need", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "prepare", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}], "id": 1228}, {"sent": "di erent variants of distributed gradient methods under quantized communication have been studied in .", "tokens": ["di", "erent", "variants", "of", "distributed", "gradient", "methods", "under", "quantized", "communication", "have", "been", "studied", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "di erent variants of distributed gradient methods under quantized communication", "start": 0, "end": 79, "i_start": 0, "i_end": 9}, "verb": {"text": "have been studied", "start": 80, "end": 97, "i_start": 10, "i_end": 12}}], "id": 1229}, {"sent": "deep neural networks have achieved state-of-the-art performance on tasks such as image recognition in the last few years .", "tokens": ["deep", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "tasks", "such", "as", "image", "recognition", "in", "the", "last", "few", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 52, "end": 63, "i_start": 12, "i_end": 12}}], "id": 1230}, {"sent": "we use the result from because the assumptions entering the calculation are clearer .", "tokens": ["we", "use", "the", "result", "from", "because", "the", "assumptions", "entering", "the", "calculation", "are", "clearer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 1231}, {"sent": "convolutional neural networks have achieved great success in many fields , such as object classification , face recognition .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "many", "fields", ",", "such", "as", "object", "classification", ",", "face", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "face", "start": 107, "end": 111, "i_start": 16, "i_end": 16}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}], "id": 1232}, {"sent": "this will be very important in the next section .", "tokens": ["this", "will", "be", "very", "important", "in", "the", "next", "section", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "will be", "start": 5, "end": 12, "i_start": 1, "i_end": 2}}], "id": 1233}, {"sent": "in quantum mechanics it consists of choosing a 6 gaussian wave function which has the lowest energy expectation value .", "tokens": ["in", "quantum", "mechanics", "it", "consists", "of", "choosing", "a", "6", "gaussian", "wave", "function", "which", "has", "the", "lowest", "energy", "expectation", "value", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1234}, {"sent": "dixon et al introduced a xor fragment of ltl and showed its tractability .", "tokens": ["dixon", "et", "al", "introduced", "a", "xor", "fragment", "of", "ltl", "and", "showed", "its", "tractability", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "dixon et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "introduced", "start": 12, "end": 22, "i_start": 3, "i_end": 3}}, {"subject": {"text": "dixon et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 49, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "dixon", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 12, "end": 22, "i_start": 3, "i_end": 3}}], "id": 1235}, {"sent": "recently , deep convolutional neural network based approaches have been setting new state-of-the-art results not only for high-level computer vision tasks such as image classification , but also for low-level tasks such as image super-resolution .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "network", "based", "approaches", "have", "been", "setting", "new", "state", "-", "of", "-", "the", "-", "art", "results", "not", "only", "for", "high", "-", "level", "computer", "vision", "tasks", "such", "as", "image", "classification", ",", "but", "also", "for", "low", "-", "level", "tasks", "such", "as", "image", "super", "-", "resolution", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural network based approaches", "start": 11, "end": 61, "i_start": 2, "i_end": 7}, "verb": {"text": "have been setting", "start": 62, "end": 79, "i_start": 8, "i_end": 10}}, {"character": {"text": "approaches", "start": 51, "end": 61, "i_start": 7, "i_end": 7}, "action": {"text": "setting", "start": 72, "end": 79, "i_start": 10, "i_end": 10}}], "id": 1236}, {"sent": "in section 3 , we prove the dissipation formula of the boltzmann-shannon entropy for the heat equation of the witten laplacian on compact manifolds with time dependent metrics and potentials .", "tokens": ["in", "section", "3", ",", "we", "prove", "the", "dissipation", "formula", "of", "the", "boltzmann", "-", "shannon", "entropy", "for", "the", "heat", "equation", "of", "the", "witten", "laplacian", "on", "compact", "manifolds", "with", "time", "dependent", "metrics", "and", "potentials", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "prove", "start": 18, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "prove", "start": 18, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "metrics", "start": 168, "end": 175, "i_start": 29, "i_end": 29}, "action": {"text": "dependent", "start": 158, "end": 167, "i_start": 28, "i_end": 28}}, {"character": {"text": "potentials", "start": 180, "end": 190, "i_start": 31, "i_end": 31}, "action": {"text": "dependent", "start": 158, "end": 167, "i_start": 28, "i_end": 28}}], "id": 1237}, {"sent": "here we show that also the notions of commutativity and so-called semi-commutativity are important .", "tokens": ["here", "we", "show", "that", "also", "the", "notions", "of", "commutativity", "and", "so", "-", "called", "semi", "-", "commutativity", "are", "important", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "are", "start": 85, "end": 88, "i_start": 16, "i_end": 16}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}], "id": 1238}, {"sent": "topological defects are high-energy relics which could be formed at symmetry-breaking phase transitions in the early universe .", "tokens": ["topological", "defects", "are", "high", "-", "energy", "relics", "which", "could", "be", "formed", "at", "symmetry", "-", "breaking", "phase", "transitions", "in", "the", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "topological defects", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 20, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "transitions", "start": 92, "end": 103, "i_start": 16, "i_end": 16}, "action": {"text": "breaking", "start": 77, "end": 85, "i_start": 14, "i_end": 14}}], "id": 1239}, {"sent": "where ellipses denote higher-twist contributions , \u03c8 is a quark field and m is the nucleon mass .", "tokens": ["where", "ellipses", "denote", "higher", "-", "twist", "contributions", ",", "\u03c8", "is", "a", "quark", "field", "and", "m", "is", "the", "nucleon", "mass", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "\u03c8", "start": 51, "end": 52, "i_start": 8, "i_end": 8}, "verb": {"text": "is", "start": 53, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "ellipses", "start": 6, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 15, "end": 21, "i_start": 2, "i_end": 2}}], "id": 1240}, {"sent": "is often called the displacement vector in the material representation .", "tokens": ["is", "often", "called", "the", "displacement", "vector", "in", "the", "material", "representation", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1241}, {"sent": "the ldg method was introduced by cockburn and shu in for the compressible navier-stokes equations .", "tokens": ["the", "ldg", "method", "was", "introduced", "by", "cockburn", "and", "shu", "in", "for", "the", "compressible", "navier", "-", "stokes", "equations", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ldg method", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "was introduced", "start": 15, "end": 29, "i_start": 3, "i_end": 4}}, {"character": {"text": "cockburn", "start": 33, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "introduced", "start": 19, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "shu in", "start": 46, "end": 52, "i_start": 8, "i_end": 9}, "action": {"text": "introduced", "start": 19, "end": 29, "i_start": 4, "i_end": 4}}], "id": 1242}, {"sent": "we use the gradient boosting classifier implemented in the scikit-learn toolkit .", "tokens": ["we", "use", "the", "gradient", "boosting", "classifier", "implemented", "in", "the", "scikit", "-", "learn", "toolkit", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "classifier", "start": 29, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "boosting", "start": 20, "end": 28, "i_start": 4, "i_end": 4}}], "id": 1243}, {"sent": "for example , various types of side information have been incorporated into mf to alleviate the cold-start problem , such as tags .", "tokens": ["for", "example", ",", "various", "types", "of", "side", "information", "have", "been", "incorporated", "into", "mf", "to", "alleviate", "the", "cold", "-", "start", "problem", ",", "such", "as", "tags", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "various types of side information", "start": 14, "end": 47, "i_start": 3, "i_end": 7}, "verb": {"text": "have been incorporated", "start": 48, "end": 70, "i_start": 8, "i_end": 10}}, {"character": {"text": "information", "start": 36, "end": 47, "i_start": 7, "i_end": 7}, "action": {"text": "alleviate", "start": 82, "end": 91, "i_start": 14, "i_end": 14}}], "id": 1244}, {"sent": "sun et al studied the clustering problem and top-k similarity problem in heterogeneous information networks .", "tokens": ["sun", "et", "al", "studied", "the", "clustering", "problem", "and", "top", "-", "k", "similarity", "problem", "in", "heterogeneous", "information", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "sun et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "studied", "start": 10, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "sun", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "studied", "start": 10, "end": 17, "i_start": 3, "i_end": 3}}], "id": 1245}, {"sent": "we used the adam optimizer with a learning-rate of 1e-08 to update the parameters .", "tokens": ["we", "used", "the", "adam", "optimizer", "with", "a", "learning", "-", "rate", "of", "1e-08", "to", "update", "the", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "update", "start": 60, "end": 66, "i_start": 13, "i_end": 13}}], "id": 1246}, {"sent": "each ll in graphene consists of four sublevels , due to spin and valley splitting .", "tokens": ["each", "ll", "in", "graphene", "consists", "of", "four", "sublevels", ",", "due", "to", "spin", "and", "valley", "splitting", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each ll in graphene", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "consists", "start": 20, "end": 28, "i_start": 4, "i_end": 4}}], "id": 1247}, {"sent": "this self duality constraint together with the bianchi identities imply the full equations of motion .", "tokens": ["this", "self", "duality", "constraint", "together", "with", "the", "bianchi", "identities", "imply", "the", "full", "equations", "of", "motion", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "this self duality constraint together with the bianchi identities", "start": 0, "end": 65, "i_start": 0, "i_end": 8}, "verb": {"text": "imply", "start": 66, "end": 71, "i_start": 9, "i_end": 9}}, {"character": {"text": "constraint", "start": 18, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "imply", "start": 66, "end": 71, "i_start": 9, "i_end": 9}}, {"character": {"text": "duality", "start": 10, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "imply", "start": 66, "end": 71, "i_start": 9, "i_end": 9}}, {"character": {"text": "self", "start": 5, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "imply", "start": 66, "end": 71, "i_start": 9, "i_end": 9}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "imply", "start": 66, "end": 71, "i_start": 9, "i_end": 9}}, {"character": {"text": "identities", "start": 55, "end": 65, "i_start": 8, "i_end": 8}, "action": {"text": "imply", "start": 66, "end": 71, "i_start": 9, "i_end": 9}}, {"character": {"text": "bianchi", "start": 47, "end": 54, "i_start": 7, "i_end": 7}, "action": {"text": "imply", "start": 66, "end": 71, "i_start": 9, "i_end": 9}}], "id": 1248}, {"sent": "to this end , we generalize the wilsonian rg theory for point-like bosons to the more complicated case of cooper pairs .", "tokens": ["to", "this", "end", ",", "we", "generalize", "the", "wilsonian", "rg", "theory", "for", "point", "-", "like", "bosons", "to", "the", "more", "complicated", "case", "of", "cooper", "pairs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "verb": {"text": "generalize", "start": 17, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "generalize", "start": 17, "end": 27, "i_start": 5, "i_end": 5}}], "id": 1249}, {"sent": "in the next section we apply the above ideas to mixed quantal states .", "tokens": ["in", "the", "next", "section", "we", "apply", "the", "above", "ideas", "to", "mixed", "quantal", "states", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 20, "end": 22, "i_start": 4, "i_end": 4}, "verb": {"text": "apply", "start": 23, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 20, "end": 22, "i_start": 4, "i_end": 4}, "action": {"text": "apply", "start": 23, "end": 28, "i_start": 5, "i_end": 5}}], "id": 1250}, {"sent": "here , we formulate the constrained inference problem .", "tokens": ["here", ",", "we", "formulate", "the", "constrained", "inference", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "formulate", "start": 10, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "formulate", "start": 10, "end": 19, "i_start": 3, "i_end": 3}}], "id": 1251}, {"sent": "this equality clearly shows that the right hand side does not depend on the choice of z .", "tokens": ["this", "equality", "clearly", "shows", "that", "the", "right", "hand", "side", "does", "not", "depend", "on", "the", "choice", "of", "z", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this equality", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "shows", "start": 22, "end": 27, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the right hand side", "start": 33, "end": 52, "i_start": 5, "i_end": 8}, "verb": {"text": "depend", "start": 62, "end": 68, "i_start": 11, "i_end": 11}}, {"character": {"text": "equality", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "shows", "start": 22, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "side", "start": 48, "end": 52, "i_start": 8, "i_end": 8}, "action": {"text": "not depend", "start": 58, "end": 68, "i_start": 10, "i_end": 11}}], "id": 1252}, {"sent": "first , in qualitative results are provided for the scalability of the trickle algorithm , but a complete analysis is not given .", "tokens": ["first", ",", "in", "qualitative", "results", "are", "provided", "for", "the", "scalability", "of", "the", "trickle", "algorithm", ",", "but", "a", "complete", "analysis", "is", "not", "given", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "qualitative results", "start": 11, "end": 30, "i_start": 3, "i_end": 4}, "verb": {"text": "are provided", "start": 31, "end": 43, "i_start": 5, "i_end": 6}}, {"subject": {"text": "a complete analysis", "start": 95, "end": 114, "i_start": 16, "i_end": 18}, "verb": {"text": "given", "start": 122, "end": 127, "i_start": 21, "i_end": 21}}], "id": 1253}, {"sent": "a random walk is a special case of a discrete time markov process , but does not have a stationary distribution 1 queueing model is a system to transform an arrival stream to a departure stream .", "tokens": ["a", "random", "walk", "is", "a", "special", "case", "of", "a", "discrete", "time", "markov", "process", ",", "but", "does", "not", "have", "a", "stationary", "distribution", "1", "queueing", "model", "is", "a", "system", "to", "transform", "an", "arrival", "stream", "to", "a", "departure", "stream", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a random walk", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 3, "i_end": 3}}, {"subject": {"text": "a random walk", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 81, "end": 85, "i_start": 17, "i_end": 17}}, {"character": {"text": "walk", "start": 9, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "case", "start": 27, "end": 31, "i_start": 6, "i_end": 6}}], "id": 1254}, {"sent": "much progress has been made in this field based on the recent developments in convolutional neural networks .", "tokens": ["much", "progress", "has", "been", "made", "in", "this", "field", "based", "on", "the", "recent", "developments", "in", "convolutional", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "much progress", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has been made", "start": 14, "end": 27, "i_start": 2, "i_end": 4}}], "id": 1255}, {"sent": "convolutional neural networks have become a highly active area of research due to strong results in areas such as image classification , among others .", "tokens": ["convolutional", "neural", "networks", "have", "become", "a", "highly", "active", "area", "of", "research", "due", "to", "strong", "results", "in", "areas", "such", "as", "image", "classification", ",", "among", "others", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have become", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "active", "start": 51, "end": 57, "i_start": 7, "i_end": 7}}], "id": 1256}, {"sent": "we choose liblinear to learn a linear svm classifier for classification .", "tokens": ["we", "choose", "liblinear", "to", "learn", "a", "linear", "svm", "classifier", "for", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "choose", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "choose", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "learn", "start": 23, "end": 28, "i_start": 4, "i_end": 4}}], "id": 1257}, {"sent": "the physical systems composed of cavities and superconducting qubits have been considered to be one of the most promising candidates for quantum information processing .", "tokens": ["the", "physical", "systems", "composed", "of", "cavities", "and", "superconducting", "qubits", "have", "been", "considered", "to", "be", "one", "of", "the", "most", "promising", "candidates", "for", "quantum", "information", "processing", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the physical systems composed of cavities and superconducting qubits", "start": 0, "end": 68, "i_start": 0, "i_end": 8}, "verb": {"text": "have been considered", "start": 69, "end": 89, "i_start": 9, "i_end": 11}}, {"character": {"text": "candidates", "start": 122, "end": 132, "i_start": 19, "i_end": 19}, "action": {"text": "promising", "start": 112, "end": 121, "i_start": 18, "i_end": 18}}], "id": 1258}, {"sent": "we use the peak signal-to-noise ratio , the structural similarity index and information fidelity criterion as metrics for evaluation .", "tokens": ["we", "use", "the", "peak", "signal", "-", "to", "-", "noise", "ratio", ",", "the", "structural", "similarity", "index", "and", "information", "fidelity", "criterion", "as", "metrics", "for", "evaluation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 1259}, {"sent": "convolutional neural networks have shown significant success in challenging tasks in image classification and recognition .", "tokens": ["convolutional", "neural", "networks", "have", "shown", "significant", "success", "in", "challenging", "tasks", "in", "image", "classification", "and", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 53, "end": 60, "i_start": 6, "i_end": 6}}, {"character": {"text": "tasks", "start": 76, "end": 81, "i_start": 9, "i_end": 9}, "action": {"text": "challenging", "start": 64, "end": 75, "i_start": 8, "i_end": 8}}], "id": 1260}, {"sent": "recent advances in image understanding have been driven by the success of convolutional neural networks .", "tokens": ["recent", "advances", "in", "image", "understanding", "have", "been", "driven", "by", "the", "success", "of", "convolutional", "neural", "networks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent advances in image understanding", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "have been driven", "start": 39, "end": 55, "i_start": 5, "i_end": 7}}, {"character": {"text": "success", "start": 63, "end": 70, "i_start": 10, "i_end": 10}, "action": {"text": "driven", "start": 49, "end": 55, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 95, "end": 103, "i_start": 14, "i_end": 14}, "action": {"text": "success", "start": 63, "end": 70, "i_start": 10, "i_end": 10}}], "id": 1261}, {"sent": "deep neural networks have achieved remarkable results in computer vision , natural language processing , and speech recognition areas .", "tokens": ["deep", "neural", "networks", "have", "achieved", "remarkable", "results", "in", "computer", "vision", ",", "natural", "language", "processing", ",", "and", "speech", "recognition", "areas", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}], "id": 1262}, {"sent": "the resnet50 pretrained on imagenet is employed as our initialized model .", "tokens": ["the", "resnet50", "pretrained", "on", "imagenet", "is", "employed", "as", "our", "initialized", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the resnet50 pretrained on imagenet", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "is employed", "start": 36, "end": 47, "i_start": 5, "i_end": 6}}], "id": 1263}, {"sent": "a model of the electrophysiological properties of thalamocortical relay neurons .", "tokens": ["a", "model", "of", "the", "electrophysiological", "properties", "of", "thalamocortical", "relay", "neurons", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "neurons", "start": 72, "end": 79, "i_start": 9, "i_end": 9}, "action": {"text": "relay", "start": 66, "end": 71, "i_start": 8, "i_end": 8}}], "id": 1264}, {"sent": "this object is isomorphic to k 2 by the map .", "tokens": ["this", "object", "is", "isomorphic", "to", "k", "2", "by", "the", "map", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this object", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 1265}, {"sent": "indeed , noncommutative field theories can be derived from string theory by the seiberg-witten limit .", "tokens": ["indeed", ",", "noncommutative", "field", "theories", "can", "be", "derived", "from", "string", "theory", "by", "the", "seiberg", "-", "witten", "limit", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "noncommutative field theories", "start": 9, "end": 38, "i_start": 2, "i_end": 4}, "verb": {"text": "can be derived", "start": 39, "end": 53, "i_start": 5, "i_end": 7}}], "id": 1266}, {"sent": "besides joint power and detection optimization , we can also try to apply the technique to jointly design with precoder .", "tokens": ["besides", "joint", "power", "and", "detection", "optimization", ",", "we", "can", "also", "try", "to", "apply", "the", "technique", "to", "jointly", "design", "with", "precoder", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 49, "end": 51, "i_start": 7, "i_end": 7}, "verb": {"text": "try", "start": 61, "end": 64, "i_start": 10, "i_end": 10}}, {"subject": {"text": "we", "start": 49, "end": 51, "i_start": 7, "i_end": 7}, "verb": {"text": "can", "start": 52, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "try", "start": 61, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "apply", "start": 68, "end": 73, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "design", "start": 99, "end": 105, "i_start": 17, "i_end": 17}}], "id": 1267}, {"sent": "one can clearly see the collapse of the field lines in the cmt .", "tokens": ["one", "can", "clearly", "see", "the", "collapse", "of", "the", "field", "lines", "in", "the", "cmt", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "see", "start": 16, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "can", "start": 4, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "see", "start": 16, "end": 19, "i_start": 3, "i_end": 3}}], "id": 1268}, {"sent": "in the field of systems and control , recent work on privacy includes , among others , filtering of streaming data .", "tokens": ["in", "the", "field", "of", "systems", "and", "control", ",", "recent", "work", "on", "privacy", "includes", ",", "among", "others", ",", "filtering", "of", "streaming", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "recent work on privacy", "start": 38, "end": 60, "i_start": 8, "i_end": 11}, "verb": {"text": "includes", "start": 61, "end": 69, "i_start": 12, "i_end": 12}}], "id": 1269}, {"sent": "the mathematical description leading up to the measurement is completely independent of the last instant choice of what to measure .", "tokens": ["the", "mathematical", "description", "leading", "up", "to", "the", "measurement", "is", "completely", "independent", "of", "the", "last", "instant", "choice", "of", "what", "to", "measure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the mathematical description leading up to the measurement", "start": 0, "end": 58, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 59, "end": 61, "i_start": 8, "i_end": 8}}], "id": 1270}, {"sent": "szegedy et al first demonstrated that neural networks are vulnerable to adversarial examples .", "tokens": ["szegedy", "et", "al", "first", "demonstrated", "that", "neural", "networks", "are", "vulnerable", "to", "adversarial", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "szegedy et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "demonstrated", "start": 20, "end": 32, "i_start": 4, "i_end": 4}}, {"subject": {"text": "szegedy et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 54, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "szegedy", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "demonstrated", "start": 20, "end": 32, "i_start": 4, "i_end": 4}}], "id": 1271}, {"sent": "however , recent research has shown that well-trained deep neural networks are rather vulnerable to adversarial examples .", "tokens": ["however", ",", "recent", "research", "has", "shown", "that", "well", "-", "trained", "deep", "neural", "networks", "are", "rather", "vulnerable", "to", "adversarial", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent research", "start": 10, "end": 25, "i_start": 2, "i_end": 3}, "verb": {"text": "has shown", "start": 26, "end": 35, "i_start": 4, "i_end": 5}}, {"subject": {"text": "recent research", "start": 10, "end": 25, "i_start": 2, "i_end": 3}, "verb": {"text": "are", "start": 75, "end": 78, "i_start": 13, "i_end": 13}}, {"character": {"text": "research", "start": 17, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 30, "end": 35, "i_start": 5, "i_end": 5}}], "id": 1272}, {"sent": "the cms detector , definitions of angular and spatial coordinates , and its performance can be found in ref .", "tokens": ["the", "cms", "detector", ",", "definitions", "of", "angular", "and", "spatial", "coordinates", ",", "and", "its", "performance", "can", "be", "found", "in", "ref", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the cms detector , definitions of angular and spatial coordinates , and its performance", "start": 0, "end": 87, "i_start": 0, "i_end": 13}, "verb": {"text": "can be found", "start": 88, "end": 100, "i_start": 14, "i_end": 16}}], "id": 1273}, {"sent": "given a degraded matrix y , low rank matrix recovery aims to recover its underlying low-dimensional structure x , which has a wide range of applications in computer vision and machine learning .", "tokens": ["given", "a", "degraded", "matrix", "y", ",", "low", "rank", "matrix", "recovery", "aims", "to", "recover", "its", "underlying", "low", "-", "dimensional", "structure", "x", ",", "which", "has", "a", "wide", "range", "of", "applications", "in", "computer", "vision", "and", "machine", "learning", "."], "score": [1, 0, 0, 0, 1], "labels": [{"subject": {"text": "a degraded matrix y", "start": 6, "end": 25, "i_start": 1, "i_end": 4}, "verb": {"text": "aims", "start": 53, "end": 57, "i_start": 10, "i_end": 10}}, {"character": {"text": "recover", "start": 61, "end": 68, "i_start": 12, "i_end": 12}, "action": {"text": "aims", "start": 53, "end": 57, "i_start": 10, "i_end": 10}}, {"character": {"text": "recover", "start": 61, "end": 68, "i_start": 12, "i_end": 12}, "action": {"text": "recovery", "start": 44, "end": 52, "i_start": 9, "i_end": 9}}, {"character": {"text": "structure", "start": 100, "end": 109, "i_start": 18, "i_end": 18}, "action": {"text": "has", "start": 120, "end": 123, "i_start": 22, "i_end": 22}}], "id": 1274}, {"sent": "advances in deep convolutional networks have led to systems rivaling human accuracy in basic object recognition tasks .", "tokens": ["advances", "in", "deep", "convolutional", "networks", "have", "led", "to", "systems", "rivaling", "human", "accuracy", "in", "basic", "object", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "advances in deep convolutional networks", "start": 0, "end": 39, "i_start": 0, "i_end": 4}, "verb": {"text": "have led", "start": 40, "end": 48, "i_start": 5, "i_end": 6}}, {"character": {"text": "advances", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "led", "start": 45, "end": 48, "i_start": 6, "i_end": 6}}, {"character": {"text": "systems", "start": 52, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "rivaling", "start": 60, "end": 68, "i_start": 9, "i_end": 9}}], "id": 1275}, {"sent": "recently , deep neural networks have led to significant improvement in several machine learning domains , from speech recognition to computer vision and machine translation .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "led", "to", "significant", "improvement", "in", "several", "machine", "learning", "domains", ",", "from", "speech", "recognition", "to", "computer", "vision", "and", "machine", "translation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have led", "start": 32, "end": 40, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "led", "start": 37, "end": 40, "i_start": 6, "i_end": 6}}], "id": 1276}, {"sent": "choy et al used a recurrent network and a cnn to reconstruct 3d models from a sequence of multi-view images .", "tokens": ["choy", "et", "al", "used", "a", "recurrent", "network", "and", "a", "cnn", "to", "reconstruct", "3d", "models", "from", "a", "sequence", "of", "multi", "-", "view", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "choy et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "choy", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "choy", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "reconstruct", "start": 49, "end": 60, "i_start": 11, "i_end": 11}}], "id": 1277}, {"sent": "r egion-based approaches with convolutional neural networks have achieved great success in object detection .", "tokens": ["r", "egion", "-", "based", "approaches", "with", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "object", "detection", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "r egion-based approaches with convolutional neural networks", "start": 0, "end": 59, "i_start": 0, "i_end": 8}, "verb": {"text": "have achieved", "start": 60, "end": 73, "i_start": 9, "i_end": 10}}, {"character": {"text": "approaches", "start": 14, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 65, "end": 73, "i_start": 10, "i_end": 10}}], "id": 1278}, {"sent": "the problem can be solved in polynomial time for interval graphs .", "tokens": ["the", "problem", "can", "be", "solved", "in", "polynomial", "time", "for", "interval", "graphs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the problem", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "can be solved", "start": 12, "end": 25, "i_start": 2, "i_end": 4}}], "id": 1279}, {"sent": "moreover , fgvc datasets have minute inter-class visual differences in addition to the variations in pose , lighting and viewpoint found in lsvc .", "tokens": ["moreover", ",", "fgvc", "datasets", "have", "minute", "inter", "-", "class", "visual", "differences", "in", "addition", "to", "the", "variations", "in", "pose", ",", "lighting", "and", "viewpoint", "found", "in", "lsvc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "datasets", "start": 16, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "have", "start": 25, "end": 29, "i_start": 4, "i_end": 4}}], "id": 1280}, {"sent": "despite the existence of efficient branch-and-bound methods , mixed-integer programming techniques suffer from poor computational complexity .", "tokens": ["despite", "the", "existence", "of", "efficient", "branch", "-", "and", "-", "bound", "methods", ",", "mixed", "-", "integer", "programming", "techniques", "suffer", "from", "poor", "computational", "complexity", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "mixed-integer programming techniques", "start": 62, "end": 98, "i_start": 12, "i_end": 16}, "verb": {"text": "suffer", "start": 99, "end": 105, "i_start": 17, "i_end": 17}}, {"character": {"text": "techniques", "start": 88, "end": 98, "i_start": 16, "i_end": 16}, "action": {"text": "suffer", "start": 99, "end": 105, "i_start": 17, "i_end": 17}}], "id": 1281}, {"sent": "closed linkages with smooth moduli spaces are called non-degenerate .", "tokens": ["closed", "linkages", "with", "smooth", "moduli", "spaces", "are", "called", "non", "-", "degenerate", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "closed linkages with smooth moduli spaces", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "are called", "start": 42, "end": 52, "i_start": 6, "i_end": 7}}], "id": 1282}, {"sent": "therefore , we will mainly concentrate on this theory .", "tokens": ["therefore", ",", "we", "will", "mainly", "concentrate", "on", "this", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "concentrate", "start": 27, "end": 38, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "will", "start": 15, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "concentrate", "start": 27, "end": 38, "i_start": 5, "i_end": 5}}], "id": 1283}, {"sent": "the point is that the effective four-dimensional theory obtained after dimensional reduction need not respect su invariance .", "tokens": ["the", "point", "is", "that", "the", "effective", "four", "-", "dimensional", "theory", "obtained", "after", "dimensional", "reduction", "need", "not", "respect", "su", "invariance", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the point is that", "start": 0, "end": 17, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "theory", "start": 49, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "-dimensional theory obtained after dimensional reduction need", "start": 36, "end": 97, "i_start": 7, "i_end": 14}}, {"character": {"text": "theory", "start": 49, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "effective", "start": 22, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "theory", "start": 49, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "respect", "start": 102, "end": 109, "i_start": 16, "i_end": 16}}], "id": 1284}, {"sent": "however , robust baseline correction is a challenging problem , especially for a fully automatic system .", "tokens": ["however", ",", "robust", "baseline", "correction", "is", "a", "challenging", "problem", ",", "especially", "for", "a", "fully", "automatic", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "robust baseline correction", "start": 10, "end": 36, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 37, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "problem", "start": 54, "end": 61, "i_start": 8, "i_end": 8}, "action": {"text": "challenging", "start": 42, "end": 53, "i_start": 7, "i_end": 7}}], "id": 1285}, {"sent": "the physics objects considered are those returned by a jet finding algorithm applied to all charged particle tracks associated with the vertex , and the associated p miss t , taken as the negative vector sum of the p t of those physics objects .", "tokens": ["the", "physics", "objects", "considered", "are", "those", "returned", "by", "a", "jet", "finding", "algorithm", "applied", "to", "all", "charged", "particle", "tracks", "associated", "with", "the", "vertex", ",", "and", "the", "associated", "p", "miss", "t", ",", "taken", "as", "the", "negative", "vector", "sum", "of", "the", "p", "t", "of", "those", "physics", "objects", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the physics objects considered", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 31, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "algorithm", "start": 67, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "returned", "start": 41, "end": 49, "i_start": 6, "i_end": 6}}], "id": 1286}, {"sent": "here we just recall the concepts and define smarandache marot loop rings .", "tokens": ["here", "we", "just", "recall", "the", "concepts", "and", "define", "smarandache", "marot", "loop", "rings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "recall", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "define", "start": 37, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "recall", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 37, "end": 43, "i_start": 7, "i_end": 7}}], "id": 1287}, {"sent": "the separation performance is evaluated using the signal to interference ratio and signal to distortion ratio measures , evaluated using the bss-eval toolbox .", "tokens": ["the", "separation", "performance", "is", "evaluated", "using", "the", "signal", "to", "interference", "ratio", "and", "signal", "to", "distortion", "ratio", "measures", ",", "evaluated", "using", "the", "bss", "-", "eval", "toolbox", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the separation performance", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "is evaluated", "start": 27, "end": 39, "i_start": 3, "i_end": 4}}], "id": 1288}, {"sent": "we also implemented batch normalization layer before the recurrent layer to reduce internal co-variance shift .", "tokens": ["we", "also", "implemented", "batch", "normalization", "layer", "before", "the", "recurrent", "layer", "to", "reduce", "internal", "co", "-", "variance", "shift", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implemented", "start": 8, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implemented", "start": 8, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "reduce", "start": 76, "end": 82, "i_start": 11, "i_end": 11}}], "id": 1289}, {"sent": "this dataset consists of 100 subset classes of imagenet , with 600 images per class .", "tokens": ["this", "dataset", "consists", "of", "100", "subset", "classes", "of", "imagenet", ",", "with", "600", "images", "per", "class", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this dataset", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 13, "end": 21, "i_start": 2, "i_end": 2}}], "id": 1290}, {"sent": "deep neural networks , if trained properly , have been demonstrated to significantly improve the benchmark performances in a wide range of application domains .", "tokens": ["deep", "neural", "networks", ",", "if", "trained", "properly", ",", "have", "been", "demonstrated", "to", "significantly", "improve", "the", "benchmark", "performances", "in", "a", "wide", "range", "of", "application", "domains", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been demonstrated", "start": 45, "end": 67, "i_start": 8, "i_end": 10}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improve", "start": 85, "end": 92, "i_start": 13, "i_end": 13}}], "id": 1291}, {"sent": "the functorial properties are easily checked .", "tokens": ["the", "functorial", "properties", "are", "easily", "checked", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the functorial properties", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "checked", "start": 37, "end": 44, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the functorial properties", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 26, "end": 29, "i_start": 3, "i_end": 3}}], "id": 1292}, {"sent": "to evaluate the performance of downlink noma , the closed-form expressions of outage probability and ergodic rate for noma were derived in by use of the bounded path loss model .", "tokens": ["to", "evaluate", "the", "performance", "of", "downlink", "noma", ",", "the", "closed", "-", "form", "expressions", "of", "outage", "probability", "and", "ergodic", "rate", "for", "noma", "were", "derived", "in", "by", "use", "of", "the", "bounded", "path", "loss", "model", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "ergodic rate for noma", "start": 101, "end": 122, "i_start": 17, "i_end": 20}, "verb": {"text": "were derived", "start": 123, "end": 135, "i_start": 21, "i_end": 22}}], "id": 1293}, {"sent": "finally , we identify the function qu for almost every point in the reduced free boundary .", "tokens": ["finally", ",", "we", "identify", "the", "function", "qu", "for", "almost", "every", "point", "in", "the", "reduced", "free", "boundary", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "identify", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "identify", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}], "id": 1294}, {"sent": "and 6 show that the finite length performance of our codes is equal to or slightly better than the codes in .", "tokens": ["and", "6", "show", "that", "the", "finite", "length", "performance", "of", "our", "codes", "is", "equal", "to", "or", "slightly", "better", "than", "the", "codes", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "codes", "start": 53, "end": 58, "i_start": 10, "i_end": 10}, "action": {"text": "performance", "start": 34, "end": 45, "i_start": 7, "i_end": 7}}], "id": 1295}, {"sent": "since the opacity is a function of the photon energy , the size of the observable gamma-ray photosphere will also depend on the observing energy .", "tokens": ["since", "the", "opacity", "is", "a", "function", "of", "the", "photon", "energy", ",", "the", "size", "of", "the", "observable", "gamma", "-", "ray", "photosphere", "will", "also", "depend", "on", "the", "observing", "energy", "."], "score": [0, 0, 1, 1, 0], "labels": [{"subject": {"text": "the size of the observable gamma-ray photosphere", "start": 55, "end": 103, "i_start": 11, "i_end": 19}, "verb": {"text": "depend", "start": 114, "end": 120, "i_start": 22, "i_end": 22}}, {"subject": {"text": "the size of the observable gamma-ray photosphere", "start": 55, "end": 103, "i_start": 11, "i_end": 19}, "verb": {"text": "will", "start": 104, "end": 108, "i_start": 20, "i_end": 20}}, {"character": {"text": "energy", "start": 46, "end": 52, "i_start": 9, "i_end": 9}, "action": {"text": "function", "start": 23, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "size", "start": 59, "end": 63, "i_start": 12, "i_end": 12}, "action": {"text": "depend", "start": 114, "end": 120, "i_start": 22, "i_end": 22}}], "id": 1296}, {"sent": "all algorithms and models were implemented using the jump modeling language .", "tokens": ["all", "algorithms", "and", "models", "were", "implemented", "using", "the", "jump", "modeling", "language", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all algorithms and models", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "were implemented", "start": 26, "end": 42, "i_start": 4, "i_end": 5}}], "id": 1297}, {"sent": "borel test of normality the results of the kolmogorov-smirnov test are presented in table vi .", "tokens": ["borel", "test", "of", "normality", "the", "results", "of", "the", "kolmogorov", "-", "smirnov", "test", "are", "presented", "in", "table", "vi", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "borel test of normality the results of the kolmogorov-smirnov test", "start": 0, "end": 66, "i_start": 0, "i_end": 11}, "verb": {"text": "are presented", "start": 67, "end": 80, "i_start": 12, "i_end": 13}}], "id": 1298}, {"sent": "in recent years , deep neural networks have led to many breakthrough results in machine learning and computer vision , and are now widely deployed in industry .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "led", "to", "many", "breakthrough", "results", "in", "machine", "learning", "and", "computer", "vision", ",", "and", "are", "now", "widely", "deployed", "in", "industry", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have led", "start": 39, "end": 47, "i_start": 7, "i_end": 8}}, {"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "deployed", "start": 138, "end": 146, "i_start": 24, "i_end": 24}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "led", "start": 44, "end": 47, "i_start": 8, "i_end": 8}}], "id": 1299}, {"sent": "in fact , the change of variable was introduced by faccanoni and mangeney to study the shock and rarefaction waves of the riemann problem for the shallow water equations with a with coulomb-like friction .", "tokens": ["in", "fact", ",", "the", "change", "of", "variable", "was", "introduced", "by", "faccanoni", "and", "mangeney", "to", "study", "the", "shock", "and", "rarefaction", "waves", "of", "the", "riemann", "problem", "for", "the", "shallow", "water", "equations", "with", "a", "with", "coulomb", "-", "like", "friction", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the change of variable", "start": 10, "end": 32, "i_start": 3, "i_end": 6}, "verb": {"text": "was introduced", "start": 33, "end": 47, "i_start": 7, "i_end": 8}}, {"character": {"text": "faccanoni", "start": 51, "end": 60, "i_start": 10, "i_end": 10}, "action": {"text": "introduced", "start": 37, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "mangeney", "start": 65, "end": 73, "i_start": 12, "i_end": 12}, "action": {"text": "introduced", "start": 37, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "faccanoni", "start": 51, "end": 60, "i_start": 10, "i_end": 10}, "action": {"text": "study", "start": 77, "end": 82, "i_start": 14, "i_end": 14}}, {"character": {"text": "mangeney", "start": 65, "end": 73, "i_start": 12, "i_end": 12}, "action": {"text": "study", "start": 77, "end": 82, "i_start": 14, "i_end": 14}}, {"character": {"text": "problem", "start": 130, "end": 137, "i_start": 23, "i_end": 23}, "action": {"text": "shock", "start": 87, "end": 92, "i_start": 16, "i_end": 16}}], "id": 1300}, {"sent": "expectation-maximization is a traditional algorithm for learning finite mixtures .", "tokens": ["expectation", "-", "maximization", "is", "a", "traditional", "algorithm", "for", "learning", "finite", "mixtures", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "expectation-maximization", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 3, "i_end": 3}}], "id": 1301}, {"sent": "we directly adopt a pre-trained vgg-16 as the base model of the hashing network .", "tokens": ["we", "directly", "adopt", "a", "pre", "-", "trained", "vgg-16", "as", "the", "base", "model", "of", "the", "hashing", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "adopt", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adopt", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}], "id": 1302}, {"sent": "the yellow band in the lower plots represents the experimental uncertainties on the thrust measurement .", "tokens": ["the", "yellow", "band", "in", "the", "lower", "plots", "represents", "the", "experimental", "uncertainties", "on", "the", "thrust", "measurement", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the yellow band in the lower plots", "start": 0, "end": 34, "i_start": 0, "i_end": 6}, "verb": {"text": "represents", "start": 35, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "band", "start": 11, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "represents", "start": 35, "end": 45, "i_start": 7, "i_end": 7}}], "id": 1303}, {"sent": "since the tachyon condensation is the off-shell phenomenon , the theoretical framework to deal with it should be the second quantized string theory .", "tokens": ["since", "the", "tachyon", "condensation", "is", "the", "off", "-", "shell", "phenomenon", ",", "the", "theoretical", "framework", "to", "deal", "with", "it", "should", "be", "the", "second", "quantized", "string", "theory", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "the theoretical framework to deal with it", "start": 61, "end": 102, "i_start": 11, "i_end": 17}, "verb": {"text": "should be", "start": 103, "end": 112, "i_start": 18, "i_end": 19}}, {"character": {"text": "framework", "start": 77, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "deal", "start": 90, "end": 94, "i_start": 15, "i_end": 15}}], "id": 1304}, {"sent": "to meet these different goals , we can initialize our weights by adding these variances , while others take the arithmetic mean of these variances or ignore the backpropagation variance altogether .", "tokens": ["to", "meet", "these", "different", "goals", ",", "we", "can", "initialize", "our", "weights", "by", "adding", "these", "variances", ",", "while", "others", "take", "the", "arithmetic", "mean", "of", "these", "variances", "or", "ignore", "the", "backpropagation", "variance", "altogether", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 32, "end": 34, "i_start": 6, "i_end": 6}, "verb": {"text": "can initialize", "start": 35, "end": 49, "i_start": 7, "i_end": 8}}, {"character": {"text": "we", "start": 32, "end": 34, "i_start": 6, "i_end": 6}, "action": {"text": "initialize", "start": 39, "end": 49, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 32, "end": 34, "i_start": 6, "i_end": 6}, "action": {"text": "adding", "start": 65, "end": 71, "i_start": 12, "i_end": 12}}, {"character": {"text": "others", "start": 96, "end": 102, "i_start": 17, "i_end": 17}, "action": {"text": "take", "start": 103, "end": 107, "i_start": 18, "i_end": 18}}, {"character": {"text": "others", "start": 96, "end": 102, "i_start": 17, "i_end": 17}, "action": {"text": "ignore", "start": 150, "end": 156, "i_start": 26, "i_end": 26}}, {"character": {"text": "we", "start": 32, "end": 34, "i_start": 6, "i_end": 6}, "action": {"text": "meet", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 1305}, {"sent": "in particular , convolutional neural networks has been popular in vision and audio recognition areas .", "tokens": ["in", "particular", ",", "convolutional", "neural", "networks", "has", "been", "popular", "in", "vision", "and", "audio", "recognition", "areas", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "has been", "start": 46, "end": 54, "i_start": 6, "i_end": 7}}], "id": 1306}, {"sent": "each qubit consists of a single-cooperpair box with two ultrasmall josephson junctions of capacitance c0 j forming a dc-squid ring and a gate electrode with capacitance cg .", "tokens": ["each", "qubit", "consists", "of", "a", "single", "-", "cooperpair", "box", "with", "two", "ultrasmall", "josephson", "junctions", "of", "capacitance", "c0", "j", "forming", "a", "dc", "-", "squid", "ring", "and", "a", "gate", "electrode", "with", "capacitance", "cg", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each qubit", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "two ultrasmall josephson junctions", "start": 52, "end": 86, "i_start": 10, "i_end": 13}, "action": {"text": "forming", "start": 107, "end": 114, "i_start": 18, "i_end": 18}}], "id": 1307}, {"sent": "later on , several other types of solutions for these theories have been proposed and they have been investigated with respect to various aspects .", "tokens": ["later", "on", ",", "several", "other", "types", "of", "solutions", "for", "these", "theories", "have", "been", "proposed", "and", "they", "have", "been", "investigated", "with", "respect", "to", "various", "aspects", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "several other types of solutions for these theories", "start": 11, "end": 62, "i_start": 3, "i_end": 10}, "verb": {"text": "have been proposed", "start": 63, "end": 81, "i_start": 11, "i_end": 13}}, {"subject": {"text": "they", "start": 86, "end": 90, "i_start": 15, "i_end": 15}, "verb": {"text": "investigated", "start": 101, "end": 113, "i_start": 18, "i_end": 18}}], "id": 1308}, {"sent": "in the last decade , convolutional neural networks have shown state of the art accuracy on a variety of visual recognition tasks such as image classification .", "tokens": ["in", "the", "last", "decade", ",", "convolutional", "neural", "networks", "have", "shown", "state", "of", "the", "art", "accuracy", "on", "a", "variety", "of", "visual", "recognition", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 21, "end": 50, "i_start": 5, "i_end": 7}, "verb": {"text": "have shown", "start": 51, "end": 61, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 42, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "shown", "start": 56, "end": 61, "i_start": 9, "i_end": 9}}], "id": 1309}, {"sent": "modern deep learning models , such as convolutional neural networks , have achieved notable successes in a wide spectrum of machine learning tasks , including speech recognition .", "tokens": ["modern", "deep", "learning", "models", ",", "such", "as", "convolutional", "neural", "networks", ",", "have", "achieved", "notable", "successes", "in", "a", "wide", "spectrum", "of", "machine", "learning", "tasks", ",", "including", "speech", "recognition", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "modern deep learning models", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 70, "end": 83, "i_start": 11, "i_end": 12}}, {"character": {"text": "models", "start": 21, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 75, "end": 83, "i_start": 12, "i_end": 12}}], "id": 1310}, {"sent": "once per ms , and with this channel estimation at the same rate is available .", "tokens": ["once", "per", "ms", ",", "and", "with", "this", "channel", "estimation", "at", "the", "same", "rate", "is", "available", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1311}, {"sent": "answer-set programming is a popular framework to describe concisely search and combinatorial problems .", "tokens": ["answer", "-", "set", "programming", "is", "a", "popular", "framework", "to", "describe", "concisely", "search", "and", "combinatorial", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "answer-set programming", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 4, "i_end": 4}}], "id": 1312}, {"sent": "transfer learning is one of the approaches to address this problem and help feature learning in the datascarce target domain by transferring knowledge from datarich source domain .", "tokens": ["transfer", "learning", "is", "one", "of", "the", "approaches", "to", "address", "this", "problem", "and", "help", "feature", "learning", "in", "the", "datascarce", "target", "domain", "by", "transferring", "knowledge", "from", "datarich", "source", "domain", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "transfer learning", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}], "id": 1313}, {"sent": "the gmm method uses the expectation maximization algorithm to maximize the likelihood function over the given parameter space .", "tokens": ["the", "gmm", "method", "uses", "the", "expectation", "maximization", "algorithm", "to", "maximize", "the", "likelihood", "function", "over", "the", "given", "parameter", "space", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the gmm method", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "uses", "start": 15, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "method", "start": 8, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "uses", "start": 15, "end": 19, "i_start": 3, "i_end": 3}}], "id": 1314}, {"sent": "convolutional neural networks , as one of the widely used deep learning methods , have been proven to be very successful for object recognition in images .", "tokens": ["convolutional", "neural", "networks", ",", "as", "one", "of", "the", "widely", "used", "deep", "learning", "methods", ",", "have", "been", "proven", "to", "be", "very", "successful", "for", "object", "recognition", "in", "images", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been proven", "start": 82, "end": 98, "i_start": 14, "i_end": 16}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 110, "end": 120, "i_start": 20, "i_end": 20}}], "id": 1315}, {"sent": "convolutional neural networks have shown their efficiency for a wide range of tasks .", "tokens": ["convolutional", "neural", "networks", "have", "shown", "their", "efficiency", "for", "a", "wide", "range", "of", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 35, "end": 40, "i_start": 4, "i_end": 4}}], "id": 1316}, {"sent": "a bose-einstein condensate is a delicate quantum fluid that is easily influenced by optical forces .", "tokens": ["a", "bose", "-", "einstein", "condensate", "is", "a", "delicate", "quantum", "fluid", "that", "is", "easily", "influenced", "by", "optical", "forces", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a bose-einstein condensate", "start": 0, "end": 26, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "forces", "start": 92, "end": 98, "i_start": 16, "i_end": 16}, "action": {"text": "influenced", "start": 70, "end": 80, "i_start": 13, "i_end": 13}}, {"character": {"text": "optical", "start": 84, "end": 91, "i_start": 15, "i_end": 15}, "action": {"text": "forces", "start": 92, "end": 98, "i_start": 16, "i_end": 16}}], "id": 1317}, {"sent": "isola et al propose an image-to-image translation framework that can learn the mapping from input image to output image , but requires paired data .", "tokens": ["isola", "et", "al", "propose", "an", "image", "-", "to", "-", "image", "translation", "framework", "that", "can", "learn", "the", "mapping", "from", "input", "image", "to", "output", "image", ",", "but", "requires", "paired", "data", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 6, "end": 11, "i_start": 1, "i_end": 2}, "verb": {"text": "propose", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "isola", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "framework", "start": 50, "end": 59, "i_start": 11, "i_end": 11}, "action": {"text": "translation", "start": 38, "end": 49, "i_start": 10, "i_end": 10}}, {"character": {"text": "framework", "start": 50, "end": 59, "i_start": 11, "i_end": 11}, "action": {"text": "learn", "start": 69, "end": 74, "i_start": 14, "i_end": 14}}, {"character": {"text": "framework", "start": 50, "end": 59, "i_start": 11, "i_end": 11}, "action": {"text": "requires", "start": 126, "end": 134, "i_start": 25, "i_end": 25}}], "id": 1318}, {"sent": "in addition , the wightman function determines the response of the particle detector of unruhdewitt type , moving through the vacuum under consideration .", "tokens": ["in", "addition", ",", "the", "wightman", "function", "determines", "the", "response", "of", "the", "particle", "detector", "of", "unruhdewitt", "type", ",", "moving", "through", "the", "vacuum", "under", "consideration", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the wightman function", "start": 14, "end": 35, "i_start": 3, "i_end": 5}, "verb": {"text": "determines", "start": 36, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "function", "start": 27, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "determines", "start": 36, "end": 46, "i_start": 6, "i_end": 6}}], "id": 1319}, {"sent": "simon et al discovered objects in an unsupervised manner from cnn feature maps , and learned part concepts in a supervised fashion .", "tokens": ["simon", "et", "al", "discovered", "objects", "in", "an", "unsupervised", "manner", "from", "cnn", "feature", "maps", ",", "and", "learned", "part", "concepts", "in", "a", "supervised", "fashion", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "simon et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "discovered", "start": 12, "end": 22, "i_start": 3, "i_end": 3}}, {"subject": {"text": "simon et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "learned", "start": 85, "end": 92, "i_start": 15, "i_end": 15}}, {"character": {"text": "simon", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "discovered", "start": 12, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "simon", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "learned", "start": 85, "end": 92, "i_start": 15, "i_end": 15}}], "id": 1320}, {"sent": "let s be the subspace of t which is the union of all arcs joining postcritical points .", "tokens": ["let", "s", "be", "the", "subspace", "of", "t", "which", "is", "the", "union", "of", "all", "arcs", "joining", "postcritical", "points", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "arcs", "start": 53, "end": 57, "i_start": 13, "i_end": 13}, "action": {"text": "joining", "start": 58, "end": 65, "i_start": 14, "i_end": 14}}], "id": 1321}, {"sent": "recently , deep convolutional neural network have received great success in image classification and so on .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "network", "have", "received", "great", "success", "in", "image", "classification", "and", "so", "on", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural network", "start": 11, "end": 44, "i_start": 2, "i_end": 5}, "verb": {"text": "have received", "start": 45, "end": 58, "i_start": 6, "i_end": 7}}, {"character": {"text": "network", "start": 37, "end": 44, "i_start": 5, "i_end": 5}, "action": {"text": "received", "start": 50, "end": 58, "i_start": 7, "i_end": 7}}, {"character": {"text": "network", "start": 37, "end": 44, "i_start": 5, "i_end": 5}, "action": {"text": "success", "start": 65, "end": 72, "i_start": 9, "i_end": 9}}], "id": 1322}, {"sent": "in this paper , we focus attention to the method for preparing initial data of black hole systems in gb gravity .", "tokens": ["in", "this", "paper", ",", "we", "focus", "attention", "to", "the", "method", "for", "preparing", "initial", "data", "of", "black", "hole", "systems", "in", "gb", "gravity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "focus", "start": 19, "end": 24, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "focus", "start": 19, "end": 24, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "attention", "start": 25, "end": 34, "i_start": 6, "i_end": 6}}], "id": 1323}, {"sent": "the cosmological constant is a peculiar quantity .", "tokens": ["the", "cosmological", "constant", "is", "a", "peculiar", "quantity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the cosmological constant", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 3, "i_end": 3}}], "id": 1324}, {"sent": "propagation of the wavefront arrival time to the gravitational wave detector requires knowledge of the position of the detector on the earth relative to the geocenter as well .", "tokens": ["propagation", "of", "the", "wavefront", "arrival", "time", "to", "the", "gravitational", "wave", "detector", "requires", "knowledge", "of", "the", "position", "of", "the", "detector", "on", "the", "earth", "relative", "to", "the", "geocenter", "as", "well", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "propagation of the wavefront arrival time to the gravitational wave detector", "start": 0, "end": 76, "i_start": 0, "i_end": 10}, "verb": {"text": "requires", "start": 77, "end": 85, "i_start": 11, "i_end": 11}}, {"character": {"text": "propagation", "start": 0, "end": 11, "i_start": 0, "i_end": 0}, "action": {"text": "requires", "start": 77, "end": 85, "i_start": 11, "i_end": 11}}], "id": 1325}, {"sent": "the inflaton is a gauge singlet and it couples only to the radial two scalar particle species with electroweak-scale masses .", "tokens": ["the", "inflaton", "is", "a", "gauge", "singlet", "and", "it", "couples", "only", "to", "the", "radial", "two", "scalar", "particle", "species", "with", "electroweak", "-", "scale", "masses", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the inflaton", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"subject": {"text": "it", "start": 36, "end": 38, "i_start": 7, "i_end": 7}, "verb": {"text": "couples", "start": 39, "end": 46, "i_start": 8, "i_end": 8}}], "id": 1326}, {"sent": "we optimize the model with the adam optimizer with a batch size of 128 for 30 epochs .", "tokens": ["we", "optimize", "the", "model", "with", "the", "adam", "optimizer", "with", "a", "batch", "size", "of", "128", "for", "30", "epochs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "optimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 1327}, {"sent": "deep learning has demonstrated superior performance on many traditional computer vision tasks such as classification .", "tokens": ["deep", "learning", "has", "demonstrated", "superior", "performance", "on", "many", "traditional", "computer", "vision", "tasks", "such", "as", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has demonstrated", "start": 14, "end": 30, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "demonstrated", "start": 18, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "performance", "start": 40, "end": 51, "i_start": 5, "i_end": 5}}], "id": 1328}, {"sent": "in the past few years , deep convolutional neural networks have shown promising results on object detection .", "tokens": ["in", "the", "past", "few", "years", ",", "deep", "convolutional", "neural", "networks", "have", "shown", "promising", "results", "on", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 24, "end": 58, "i_start": 6, "i_end": 9}, "verb": {"text": "have shown", "start": 59, "end": 69, "i_start": 10, "i_end": 11}}, {"character": {"text": "networks", "start": 50, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "shown", "start": 64, "end": 69, "i_start": 11, "i_end": 11}}, {"character": {"text": "results", "start": 80, "end": 87, "i_start": 13, "i_end": 13}, "action": {"text": "promising", "start": 70, "end": 79, "i_start": 12, "i_end": 12}}], "id": 1329}, {"sent": "following , we use 1,000 images for validation and 1,000 images for testing .", "tokens": ["following", ",", "we", "use", "1,000", "images", "for", "validation", "and", "1,000", "images", "for", "testing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "use", "start": 15, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 15, "end": 18, "i_start": 3, "i_end": 3}}], "id": 1330}, {"sent": "recently , convolutional neural networks have been proved to be capable of dramatically boosting the performance of many mainstream computer vision problems .", "tokens": ["recently", ",", "convolutional", "neural", "networks", "have", "been", "proved", "to", "be", "capable", "of", "dramatically", "boosting", "the", "performance", "of", "many", "mainstream", "computer", "vision", "problems", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 11, "end": 40, "i_start": 2, "i_end": 4}, "verb": {"text": "have been proved", "start": 41, "end": 57, "i_start": 5, "i_end": 7}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "boosting", "start": 88, "end": 96, "i_start": 13, "i_end": 13}}, {"character": {"text": "problems", "start": 148, "end": 156, "i_start": 21, "i_end": 21}, "action": {"text": "performance", "start": 101, "end": 112, "i_start": 15, "i_end": 15}}], "id": 1331}, {"sent": "social network analysis for routing in disconnected delay-tolerant manets .", "tokens": ["social", "network", "analysis", "for", "routing", "in", "disconnected", "delay", "-", "tolerant", "manets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "manets", "start": 67, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "tolerant", "start": 58, "end": 66, "i_start": 9, "i_end": 9}}], "id": 1332}, {"sent": "bacteria can exchange dna through diverse mechanisms including transformation , transduction , conjugation , gene transfer agents , and nanotubes .", "tokens": ["bacteria", "can", "exchange", "dna", "through", "diverse", "mechanisms", "including", "transformation", ",", "transduction", ",", "conjugation", ",", "gene", "transfer", "agents", ",", "and", "nanotubes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bacteria", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "can exchange", "start": 9, "end": 21, "i_start": 1, "i_end": 2}}, {"character": {"text": "bacteria", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "exchange", "start": 13, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "agents", "start": 123, "end": 129, "i_start": 16, "i_end": 16}, "action": {"text": "transfer", "start": 114, "end": 122, "i_start": 15, "i_end": 15}}], "id": 1333}, {"sent": "also , we describe the curves obtained by the application of these methods to several types of plane curves .", "tokens": ["also", ",", "we", "describe", "the", "curves", "obtained", "by", "the", "application", "of", "these", "methods", "to", "several", "types", "of", "plane", "curves", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "describe", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "describe", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "application", "start": 46, "end": 57, "i_start": 9, "i_end": 9}, "action": {"text": "obtained", "start": 30, "end": 38, "i_start": 6, "i_end": 6}}], "id": 1334}, {"sent": "the positive samples are all types of vehicles from the detrac-train dataset , while the kitti-mod dataset is included for hard negative mining .", "tokens": ["the", "positive", "samples", "are", "all", "types", "of", "vehicles", "from", "the", "detrac", "-", "train", "dataset", ",", "while", "the", "kitti", "-", "mod", "dataset", "is", "included", "for", "hard", "negative", "mining", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the positive samples", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}], "id": 1335}, {"sent": "this allows us to empirically establish the ionization states of these elements within the lic .", "tokens": ["this", "allows", "us", "to", "empirically", "establish", "the", "ionization", "states", "of", "these", "elements", "within", "the", "lic", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "allows", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}, {"subject": {"text": "us", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "establish", "start": 30, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "allows", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "us", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "establish", "start": 30, "end": 39, "i_start": 5, "i_end": 5}}], "id": 1336}, {"sent": "fernandez de la vega and lueker proposed the first polynomial-time approximation scheme for 1-dimensional bin-packing problems and proved that no such polynomial-time approximation scheme is possible for 2-dimensional packing problems .", "tokens": ["fernandez", "de", "la", "vega", "and", "lueker", "proposed", "the", "first", "polynomial", "-", "time", "approximation", "scheme", "for", "1", "-", "dimensional", "bin", "-", "packing", "problems", "and", "proved", "that", "no", "such", "polynomial", "-", "time", "approximation", "scheme", "is", "possible", "for", "2", "-", "dimensional", "packing", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "fernandez de la vega and lueker", "start": 0, "end": 31, "i_start": 0, "i_end": 5}, "verb": {"text": "proposed", "start": 32, "end": 40, "i_start": 6, "i_end": 6}}, {"subject": {"text": "fernandez de la vega and lueker", "start": 0, "end": 31, "i_start": 0, "i_end": 5}, "verb": {"text": "proved", "start": 131, "end": 137, "i_start": 23, "i_end": 23}}, {"character": {"text": "fernandez de la vega", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "action": {"text": "proposed", "start": 32, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "lueker", "start": 25, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "proposed", "start": 32, "end": 40, "i_start": 6, "i_end": 6}}], "id": 1337}, {"sent": "in the bulk-driven critical curve , the surfaces are less ordered than the layers in the bulk .", "tokens": ["in", "the", "bulk", "-", "driven", "critical", "curve", ",", "the", "surfaces", "are", "less", "ordered", "than", "the", "layers", "in", "the", "bulk", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the surfaces", "start": 36, "end": 48, "i_start": 8, "i_end": 9}, "verb": {"text": "are", "start": 49, "end": 52, "i_start": 10, "i_end": 10}}, {"character": {"text": "bulk", "start": 7, "end": 11, "i_start": 2, "i_end": 2}, "action": {"text": "driven", "start": 12, "end": 18, "i_start": 4, "i_end": 4}}], "id": 1338}, {"sent": "at high energies , the hadron appears as if it is a gluon wall .", "tokens": ["at", "high", "energies", ",", "the", "hadron", "appears", "as", "if", "it", "is", "a", "gluon", "wall", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the hadron", "start": 19, "end": 29, "i_start": 4, "i_end": 5}, "verb": {"text": "appears", "start": 30, "end": 37, "i_start": 6, "i_end": 6}}], "id": 1339}, {"sent": "convolutional neural networks have recently been shown to perform well on large scale visual recognition tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "been", "shown", "to", "perform", "well", "on", "large", "scale", "visual", "recognition", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "been shown", "start": 44, "end": 54, "i_start": 5, "i_end": 6}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "perform", "start": 58, "end": 65, "i_start": 8, "i_end": 8}}], "id": 1340}, {"sent": "deep neural networks have achieved impressive performance on tasks across a variety of domains , including vision .", "tokens": ["deep", "neural", "networks", "have", "achieved", "impressive", "performance", "on", "tasks", "across", "a", "variety", "of", "domains", ",", "including", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 46, "end": 57, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 46, "end": 57, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 35, "end": 45, "i_start": 5, "i_end": 5}}], "id": 1341}, {"sent": "in , it is shown that any action of a semisimple hopf algebra h on a commutative domain over k factors through a group action .", "tokens": ["in", ",", "it", "is", "shown", "that", "any", "action", "of", "a", "semisimple", "hopf", "algebra", "h", "on", "a", "commutative", "domain", "over", "k", "factors", "through", "a", "group", "action", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "verb": {"text": "is shown", "start": 8, "end": 16, "i_start": 3, "i_end": 4}}], "id": 1342}, {"sent": "the rotation number is the sum of the rotations of the omponents .", "tokens": ["the", "rotation", "number", "is", "the", "sum", "of", "the", "rotations", "of", "the", "omponents", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the rotation number", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 1343}, {"sent": "the reader interested in more details is also referred to the paper by el karoui , peng and quenez and the references therein .", "tokens": ["the", "reader", "interested", "in", "more", "details", "is", "also", "referred", "to", "the", "paper", "by", "el", "karoui", ",", "peng", "and", "quenez", "and", "the", "references", "therein", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the reader interested in more details", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "referred", "start": 46, "end": 54, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the reader interested in more details", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 6, "i_end": 6}}], "id": 1344}, {"sent": "further , kiros et al propose to construct a joint multimodal embedding space by using a powerful computer vision model and an lstm that encodes text .", "tokens": ["further", ",", "kiros", "et", "al", "propose", "to", "construct", "a", "joint", "multimodal", "embedding", "space", "by", "using", "a", "powerful", "computer", "vision", "model", "and", "an", "lstm", "that", "encodes", "text", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "kiros et al", "start": 10, "end": 21, "i_start": 2, "i_end": 4}, "verb": {"text": "propose", "start": 22, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "kiros", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "propose", "start": 22, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "kiros", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "construct", "start": 33, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "kiros", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "using", "start": 81, "end": 86, "i_start": 14, "i_end": 14}}], "id": 1345}, {"sent": "in addition , the response of particle detectors in an arbitrary state of motion is determined by this function .", "tokens": ["in", "addition", ",", "the", "response", "of", "particle", "detectors", "in", "an", "arbitrary", "state", "of", "motion", "is", "determined", "by", "this", "function", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "the response of particle detectors in an arbitrary state of motion", "start": 14, "end": 80, "i_start": 3, "i_end": 13}, "verb": {"text": "is determined", "start": 81, "end": 94, "i_start": 14, "i_end": 15}}, {"character": {"text": "function", "start": 103, "end": 111, "i_start": 18, "i_end": 18}, "action": {"text": "determined", "start": 84, "end": 94, "i_start": 15, "i_end": 15}}], "id": 1346}, {"sent": "we develop most of this section in much greater generality for coherent sheaves on algebraic stacks .", "tokens": ["we", "develop", "most", "of", "this", "section", "in", "much", "greater", "generality", "for", "coherent", "sheaves", "on", "algebraic", "stacks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "develop", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "develop", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 1347}, {"sent": "the superscripts denote the components of the spin operators and finally the represent the standard symbol .", "tokens": ["the", "superscripts", "denote", "the", "components", "of", "the", "spin", "operators", "and", "finally", "the", "represent", "the", "standard", "symbol", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the superscripts", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "denote", "start": 17, "end": 23, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the superscripts", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "represent", "start": 77, "end": 86, "i_start": 12, "i_end": 12}}, {"character": {"text": "superscripts", "start": 4, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 17, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "superscripts", "start": 4, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "represent", "start": 77, "end": 86, "i_start": 12, "i_end": 12}}], "id": 1348}, {"sent": "faraday rotation is a physical phenomenon where the position angle of linearly polarized radiation propagating through a magneto-ionic medium is rotated as a function of frequency .", "tokens": ["faraday", "rotation", "is", "a", "physical", "phenomenon", "where", "the", "position", "angle", "of", "linearly", "polarized", "radiation", "propagating", "through", "a", "magneto", "-", "ionic", "medium", "is", "rotated", "as", "a", "function", "of", "frequency", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "faraday rotation", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}], "id": 1349}, {"sent": "convolutional neural networks have been instrumental to the recent breakthroughs in computer vision .", "tokens": ["convolutional", "neural", "networks", "have", "been", "instrumental", "to", "the", "recent", "breakthroughs", "in", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}], "id": 1350}, {"sent": "in addition to this data we make use of the annotations provided by hariharan et al , resulting in a total of 10582 training instances .", "tokens": ["in", "addition", "to", "this", "data", "we", "make", "use", "of", "the", "annotations", "provided", "by", "hariharan", "et", "al", ",", "resulting", "in", "a", "total", "of", "10582", "training", "instances", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 33, "end": 36, "i_start": 7, "i_end": 7}}, {"character": {"text": "hariharan", "start": 68, "end": 77, "i_start": 13, "i_end": 13}, "action": {"text": "provided", "start": 56, "end": 64, "i_start": 11, "i_end": 11}}], "id": 1351}, {"sent": "convolutional neural networks have witnessed great improvement on a series of vision tasks such as object classification .", "tokens": ["convolutional", "neural", "networks", "have", "witnessed", "great", "improvement", "on", "a", "series", "of", "vision", "tasks", "such", "as", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have witnessed", "start": 30, "end": 44, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "witnessed", "start": 35, "end": 44, "i_start": 4, "i_end": 4}}], "id": 1352}, {"sent": "significant improvements have been obtained in various computer vision tasks by applying deep learning techniques , including image classification .", "tokens": ["significant", "improvements", "have", "been", "obtained", "in", "various", "computer", "vision", "tasks", "by", "applying", "deep", "learning", "techniques", ",", "including", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "significant improvements", "start": 0, "end": 24, "i_start": 0, "i_end": 1}, "verb": {"text": "have been obtained", "start": 25, "end": 43, "i_start": 2, "i_end": 4}}], "id": 1353}, {"sent": "recently , convolutional neural network methods demonstrated highly accurate results , especially in the field of long-term vpr .", "tokens": ["recently", ",", "convolutional", "neural", "network", "methods", "demonstrated", "highly", "accurate", "results", ",", "especially", "in", "the", "field", "of", "long", "-", "term", "vpr", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural network methods", "start": 11, "end": 47, "i_start": 2, "i_end": 5}, "verb": {"text": "demonstrated", "start": 48, "end": 60, "i_start": 6, "i_end": 6}}, {"character": {"text": "methods", "start": 40, "end": 47, "i_start": 5, "i_end": 5}, "action": {"text": "demonstrated", "start": 48, "end": 60, "i_start": 6, "i_end": 6}}], "id": 1354}, {"sent": "the theory of complex networks has recently produced a great deal of interest in a very multidisciplinary community .", "tokens": ["the", "theory", "of", "complex", "networks", "has", "recently", "produced", "a", "great", "deal", "of", "interest", "in", "a", "very", "multidisciplinary", "community", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the theory of complex networks", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "produced", "start": 44, "end": 52, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the theory of complex networks", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "has", "start": 31, "end": 34, "i_start": 5, "i_end": 5}}, {"character": {"text": "theory", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "produced", "start": 44, "end": 52, "i_start": 7, "i_end": 7}}], "id": 1355}, {"sent": "mezic et al propose metrics of dynamcal systems in the context of ergodic theory via koopman operators on l 2 -spaces .", "tokens": ["mezic", "et", "al", "propose", "metrics", "of", "dynamcal", "systems", "in", "the", "context", "of", "ergodic", "theory", "via", "koopman", "operators", "on", "l", "2", "-spaces", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 6, "end": 11, "i_start": 1, "i_end": 2}, "verb": {"text": "propose", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "mezic", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}], "id": 1356}, {"sent": "the neural language models have achieved great success in many speech and language processing applications .", "tokens": ["the", "neural", "language", "models", "have", "achieved", "great", "success", "in", "many", "speech", "and", "language", "processing", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the neural language models", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 27, "end": 40, "i_start": 4, "i_end": 5}}, {"character": {"text": "models", "start": 20, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 32, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "models", "start": 20, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 47, "end": 54, "i_start": 7, "i_end": 7}}], "id": 1357}, {"sent": "the solutions to the type of differential equations mentioned above can typically be written in terms of harmonic polylogarithms of argument x .", "tokens": ["the", "solutions", "to", "the", "type", "of", "differential", "equations", "mentioned", "above", "can", "typically", "be", "written", "in", "terms", "of", "harmonic", "polylogarithms", "of", "argument", "x", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the solutions to the type of differential equations mentioned above", "start": 0, "end": 67, "i_start": 0, "i_end": 9}, "verb": {"text": "be written", "start": 82, "end": 92, "i_start": 12, "i_end": 13}}, {"subject": {"text": "the solutions to the type of differential equations mentioned above", "start": 0, "end": 67, "i_start": 0, "i_end": 9}, "verb": {"text": "can", "start": 68, "end": 71, "i_start": 10, "i_end": 10}}], "id": 1358}, {"sent": "the apparatus consists of two laser cooled and trapped sources of cs atoms .", "tokens": ["the", "apparatus", "consists", "of", "two", "laser", "cooled", "and", "trapped", "sources", "of", "cs", "atoms", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the apparatus", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 14, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "laser", "start": 30, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "cooled", "start": 36, "end": 42, "i_start": 6, "i_end": 6}}, {"character": {"text": "laser", "start": 30, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "trapped", "start": 47, "end": 54, "i_start": 8, "i_end": 8}}], "id": 1359}, {"sent": "the extremely tiny mixing with the fundamental sector accounts for the preservation of lepton number symmetry at low energies .", "tokens": ["the", "extremely", "tiny", "mixing", "with", "the", "fundamental", "sector", "accounts", "for", "the", "preservation", "of", "lepton", "number", "symmetry", "at", "low", "energies", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the extremely tiny mixing with the fundamental sector", "start": 0, "end": 53, "i_start": 0, "i_end": 7}, "verb": {"text": "accounts", "start": 54, "end": 62, "i_start": 8, "i_end": 8}}], "id": 1360}, {"sent": "convolutional neural networks have proven to be effective feature extractors for many computer vision tasks .", "tokens": ["convolutional", "neural", "networks", "have", "proven", "to", "be", "effective", "feature", "extractors", "for", "many", "computer", "vision", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have proven", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "effective", "start": 48, "end": 57, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "extractors", "start": 66, "end": 76, "i_start": 9, "i_end": 9}}], "id": 1361}, {"sent": "koh et al used influence functions as an indicator to track the behavior from the training data to the models prediction .", "tokens": ["koh", "et", "al", "used", "influence", "functions", "as", "an", "indicator", "to", "track", "the", "behavior", "from", "the", "training", "data", "to", "the", "models", "prediction", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "koh et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 10, "end": 14, "i_start": 3, "i_end": 3}}, {"character": {"text": "koh", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 10, "end": 14, "i_start": 3, "i_end": 3}}, {"character": {"text": "koh", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "track", "start": 54, "end": 59, "i_start": 10, "i_end": 10}}], "id": 1362}, {"sent": "assuming that filters in later layers of a fcn are responsive to object parts and other high-level features , then the feature space gcn captures correlations between more abstract features in the image like object parts .", "tokens": ["assuming", "that", "filters", "in", "later", "layers", "of", "a", "fcn", "are", "responsive", "to", "object", "parts", "and", "other", "high", "-", "level", "features", ",", "then", "the", "feature", "space", "gcn", "captures", "correlations", "between", "more", "abstract", "features", "in", "the", "image", "like", "object", "parts", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the feature space gcn", "start": 115, "end": 136, "i_start": 22, "i_end": 25}, "verb": {"text": "captures", "start": 137, "end": 145, "i_start": 26, "i_end": 26}}], "id": 1363}, {"sent": "the convolutional neural network in particular is a deep learning architecture which has shown its promise for image classification tasks .", "tokens": ["the", "convolutional", "neural", "network", "in", "particular", "is", "a", "deep", "learning", "architecture", "which", "has", "shown", "its", "promise", "for", "image", "classification", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the convolutional neural network in particular", "start": 0, "end": 46, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 47, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "architecture", "start": 66, "end": 78, "i_start": 10, "i_end": 10}, "action": {"text": "shown", "start": 89, "end": 94, "i_start": 13, "i_end": 13}}], "id": 1364}, {"sent": "we introduce extended generalized disjunctive paraconsistent relations , which are the fundamental structures underlying our model .", "tokens": ["we", "introduce", "extended", "generalized", "disjunctive", "paraconsistent", "relations", ",", "which", "are", "the", "fundamental", "structures", "underlying", "our", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "introduce", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "introduce", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "relations", "start": 61, "end": 70, "i_start": 6, "i_end": 6}, "action": {"text": "underlying", "start": 110, "end": 120, "i_start": 13, "i_end": 13}}], "id": 1365}, {"sent": "on irreducible representations of compact p-adic analytic groups .", "tokens": ["on", "irreducible", "representations", "of", "compact", "p", "-", "adic", "analytic", "groups", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1366}, {"sent": "it is worth noting that branes with both electric and magnetic charges may exist in any space-time with electric and magnetic branes having different dimensions , branes within branes of the type of ref .", "tokens": ["it", "is", "worth", "noting", "that", "branes", "with", "both", "electric", "and", "magnetic", "charges", "may", "exist", "in", "any", "space", "-", "time", "with", "electric", "and", "magnetic", "branes", "having", "different", "dimensions", ",", "branes", "within", "branes", "of", "the", "type", "of", "ref", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"character": {"text": "branes", "start": 24, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "having", "start": 133, "end": 139, "i_start": 24, "i_end": 24}}], "id": 1367}, {"sent": "deep neural networks have recently achieved huge success in various machine learning tasks .", "tokens": ["deep", "neural", "networks", "have", "recently", "achieved", "huge", "success", "in", "various", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 49, "end": 56, "i_start": 7, "i_end": 7}}], "id": 1368}, {"sent": "the energy to materialize and accelerate the pair comes from the positive cosmological constant and from the string tension .", "tokens": ["the", "energy", "to", "materialize", "and", "accelerate", "the", "pair", "comes", "from", "the", "positive", "cosmological", "constant", "and", "from", "the", "string", "tension", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the energy to materialize and accelerate the pair", "start": 0, "end": 49, "i_start": 0, "i_end": 7}, "verb": {"text": "comes", "start": 50, "end": 55, "i_start": 8, "i_end": 8}}], "id": 1369}, {"sent": "at this point , we are interested to comment some consistency for the gauge invariant version of the bosonized csm .", "tokens": ["at", "this", "point", ",", "we", "are", "interested", "to", "comment", "some", "consistency", "for", "the", "gauge", "invariant", "version", "of", "the", "bosonized", "csm", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "are", "start": 19, "end": 22, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "comment", "start": 37, "end": 44, "i_start": 8, "i_end": 8}}], "id": 1370}, {"sent": "the first-principles calculations were carried in the framework of the projector augmented-wave formalism as implemented in the vienna ab initio simulation package .", "tokens": ["the", "first", "-", "principles", "calculations", "were", "carried", "in", "the", "framework", "of", "the", "projector", "augmented", "-", "wave", "formalism", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the first-principles calculations", "start": 0, "end": 33, "i_start": 0, "i_end": 4}, "verb": {"text": "were carried", "start": 34, "end": 46, "i_start": 5, "i_end": 6}}], "id": 1371}, {"sent": "it suffices to prove that a is a subalgebra .", "tokens": ["it", "suffices", "to", "prove", "that", "a", "is", "a", "subalgebra", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "suffices", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "prove", "start": 15, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "suffices", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 1372}, {"sent": "in recent years , deep convolutional neural networks have become the state-of-the-art solution for many computer vision applications and are ripe for real-world deployment .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "become", "the", "state", "-", "of", "-", "the", "-", "art", "solution", "for", "many", "computer", "vision", "applications", "and", "are", "ripe", "for", "real", "-", "world", "deployment", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have become", "start": 53, "end": 64, "i_start": 8, "i_end": 9}}], "id": 1373}, {"sent": "kipf et al propose the graph convolutional networks to define convolutions on the non-grid structures .", "tokens": ["kipf", "et", "al", "propose", "the", "graph", "convolutional", "networks", "to", "define", "convolutions", "on", "the", "non", "-", "grid", "structures", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 5, "end": 10, "i_start": 1, "i_end": 2}, "verb": {"text": "propose", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "kipf", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "kipf", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "define", "start": 55, "end": 61, "i_start": 9, "i_end": 9}}], "id": 1374}, {"sent": "the architecture of the landmark detection network is based on a resnet-152 model .", "tokens": ["the", "architecture", "of", "the", "landmark", "detection", "network", "is", "based", "on", "a", "resnet-152", "model", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the architecture of the landmark detection network", "start": 0, "end": 50, "i_start": 0, "i_end": 6}, "verb": {"text": "is based", "start": 51, "end": 59, "i_start": 7, "i_end": 8}}, {"character": {"text": "network", "start": 43, "end": 50, "i_start": 6, "i_end": 6}, "action": {"text": "detection", "start": 33, "end": 42, "i_start": 5, "i_end": 5}}], "id": 1375}, {"sent": "for example , synergies can be used in the planning or control algorithms for robotic hands .", "tokens": ["for", "example", ",", "synergies", "can", "be", "used", "in", "the", "planning", "or", "control", "algorithms", "for", "robotic", "hands", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "synergies", "start": 14, "end": 23, "i_start": 3, "i_end": 3}, "verb": {"text": "can be used", "start": 24, "end": 35, "i_start": 4, "i_end": 6}}, {"subject": {"text": "synergies", "start": 14, "end": 23, "i_start": 3, "i_end": 3}, "verb": {"text": "control", "start": 55, "end": 62, "i_start": 11, "i_end": 11}}], "id": 1376}, {"sent": "deep auto encoders and deep generative adversarial networks are two of the most popular approaches to generative learning .", "tokens": ["deep", "auto", "encoders", "and", "deep", "generative", "adversarial", "networks", "are", "two", "of", "the", "most", "popular", "approaches", "to", "generative", "learning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep auto encoders and deep generative adversarial networks", "start": 0, "end": 59, "i_start": 0, "i_end": 7}, "verb": {"text": "are", "start": 60, "end": 63, "i_start": 8, "i_end": 8}}], "id": 1377}, {"sent": "for this simple strategy of y , that takes no memory into account , but also for all other possible strategies of y , total cooperation always leads to the maximum reward .", "tokens": ["for", "this", "simple", "strategy", "of", "y", ",", "that", "takes", "no", "memory", "into", "account", ",", "but", "also", "for", "all", "other", "possible", "strategies", "of", "y", ",", "total", "cooperation", "always", "leads", "to", "the", "maximum", "reward", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "that", "start": 32, "end": 36, "i_start": 7, "i_end": 7}, "verb": {"text": "takes", "start": 37, "end": 42, "i_start": 8, "i_end": 8}}, {"subject": {"text": "total cooperation", "start": 118, "end": 135, "i_start": 24, "i_end": 25}, "verb": {"text": "leads", "start": 143, "end": 148, "i_start": 27, "i_end": 27}}, {"character": {"text": "cooperation", "start": 124, "end": 135, "i_start": 25, "i_end": 25}, "action": {"text": "leads", "start": 143, "end": 148, "i_start": 27, "i_end": 27}}], "id": 1378}, {"sent": "we also show that the off diagonal matrix elements of the observables vanish in this limit .", "tokens": ["we", "also", "show", "that", "the", "off", "diagonal", "matrix", "elements", "of", "the", "observables", "vanish", "in", "this", "limit", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the off diagonal matrix elements of the observables", "start": 18, "end": 69, "i_start": 4, "i_end": 11}, "verb": {"text": "vanish", "start": 70, "end": 76, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}], "id": 1379}, {"sent": "we apply van to optimize the parameters of variational auto-encoder .", "tokens": ["we", "apply", "van", "to", "optimize", "the", "parameters", "of", "variational", "auto", "-", "encoder", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "apply", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "apply", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimize", "start": 16, "end": 24, "i_start": 4, "i_end": 4}}], "id": 1380}, {"sent": "the refinement consists of the signs associated to the components of the resolution .", "tokens": ["the", "refinement", "consists", "of", "the", "signs", "associated", "to", "the", "components", "of", "the", "resolution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the refinement", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 15, "end": 23, "i_start": 2, "i_end": 2}}], "id": 1381}, {"sent": "its expression has been derived under the assumption that , over the bandwidth of the signal , the spectral density of the noise can be considered constant .", "tokens": ["its", "expression", "has", "been", "derived", "under", "the", "assumption", "that", ",", "over", "the", "bandwidth", "of", "the", "signal", ",", "the", "spectral", "density", "of", "the", "noise", "can", "be", "considered", "constant", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "its expression", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "has been derived", "start": 15, "end": 31, "i_start": 2, "i_end": 4}}], "id": 1382}, {"sent": "the planck scale is the ultimate ultaviolet regulator .", "tokens": ["the", "planck", "scale", "is", "the", "ultimate", "ultaviolet", "regulator", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the planck scale", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "scale", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "regulator", "start": 44, "end": 53, "i_start": 7, "i_end": 7}}], "id": 1383}, {"sent": "these methods date back to , and have later been denoted as iterative quadratic maximum likelihood methods , with applications to filter design .", "tokens": ["these", "methods", "date", "back", "to", ",", "and", "have", "later", "been", "denoted", "as", "iterative", "quadratic", "maximum", "likelihood", "methods", ",", "with", "applications", "to", "filter", "design", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these methods", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "date", "start": 14, "end": 18, "i_start": 2, "i_end": 2}}, {"subject": {"text": "these methods", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "denoted", "start": 49, "end": 56, "i_start": 10, "i_end": 10}}], "id": 1384}, {"sent": "zhou et al propose to synthesize novel views of the same object or scene corresponding by learning appearance flows .", "tokens": ["zhou", "et", "al", "propose", "to", "synthesize", "novel", "views", "of", "the", "same", "object", "or", "scene", "corresponding", "by", "learning", "appearance", "flows", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 5, "end": 10, "i_start": 1, "i_end": 2}, "verb": {"text": "propose", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhou", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhou", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "synthesize", "start": 22, "end": 32, "i_start": 5, "i_end": 5}}], "id": 1385}, {"sent": "whereas , weaker gra dients result in later onset of the saturation , and in turn , higher saturation levels .", "tokens": ["whereas", ",", "weaker", "gra", "dients", "result", "in", "later", "onset", "of", "the", "saturation", ",", "and", "in", "turn", ",", "higher", "saturation", "levels", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "weaker gra dients", "start": 10, "end": 27, "i_start": 2, "i_end": 4}, "verb": {"text": "result", "start": 28, "end": 34, "i_start": 5, "i_end": 5}}], "id": 1386}, {"sent": "well known members of this family are the unscented kalman filter , the divided difference filter and the cubature kalman filter .", "tokens": ["well", "known", "members", "of", "this", "family", "are", "the", "unscented", "kalman", "filter", ",", "the", "divided", "difference", "filter", "and", "the", "cubature", "kalman", "filter", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "well known members of this family", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}], "id": 1387}, {"sent": "it appears that the derived a posteriori bounds and the respective adaptive algorithms can be modified in a straightforward fashion to include the original dg method of baker .", "tokens": ["it", "appears", "that", "the", "derived", "a", "posteriori", "bounds", "and", "the", "respective", "adaptive", "algorithms", "can", "be", "modified", "in", "a", "straightforward", "fashion", "to", "include", "the", "original", "dg", "method", "of", "baker", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "appears", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the", "start": 16, "end": 19, "i_start": 3, "i_end": 3}, "verb": {"text": "derived", "start": 20, "end": 27, "i_start": 4, "i_end": 4}}, {"subject": {"text": "a posteriori bounds and the respective adaptive algorithms", "start": 28, "end": 86, "i_start": 5, "i_end": 12}, "verb": {"text": "modified", "start": 94, "end": 102, "i_start": 15, "i_end": 15}}, {"character": {"text": "algorithms", "start": 76, "end": 86, "i_start": 12, "i_end": 12}, "action": {"text": "adaptive", "start": 67, "end": 75, "i_start": 11, "i_end": 11}}], "id": 1388}, {"sent": "the following formalism will become useful .", "tokens": ["the", "following", "formalism", "will", "become", "useful", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the following formalism", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "will become", "start": 24, "end": 35, "i_start": 3, "i_end": 4}}], "id": 1389}, {"sent": "the exponential factor is again the same as for the interaction with the surface .", "tokens": ["the", "exponential", "factor", "is", "again", "the", "same", "as", "for", "the", "interaction", "with", "the", "surface", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exponential factor", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}], "id": 1390}, {"sent": "differential privacy constitutes a strong standard for privacy guarantees in statistical databases .", "tokens": ["differential", "privacy", "constitutes", "a", "strong", "standard", "for", "privacy", "guarantees", "in", "statistical", "databases", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "differential privacy", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "constitutes", "start": 21, "end": 32, "i_start": 2, "i_end": 2}}, {"character": {"text": "privacy", "start": 13, "end": 20, "i_start": 1, "i_end": 1}, "action": {"text": "constitutes", "start": 21, "end": 32, "i_start": 2, "i_end": 2}}], "id": 1391}, {"sent": "the class of iterative methods known as krylov subspace methods are often considered as the methods of choice for solving large scale linear systems due to their computational efficiency .", "tokens": ["the", "class", "of", "iterative", "methods", "known", "as", "krylov", "subspace", "methods", "are", "often", "considered", "as", "the", "methods", "of", "choice", "for", "solving", "large", "scale", "linear", "systems", "due", "to", "their", "computational", "efficiency", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the class of iterative methods known as krylov subspace methods", "start": 0, "end": 63, "i_start": 0, "i_end": 9}, "verb": {"text": "considered", "start": 74, "end": 84, "i_start": 12, "i_end": 12}}, {"subject": {"text": "the class of iterative methods known as krylov subspace methods", "start": 0, "end": 63, "i_start": 0, "i_end": 9}, "verb": {"text": "are", "start": 64, "end": 67, "i_start": 10, "i_end": 10}}], "id": 1392}, {"sent": "the interested reader is referred to for a detailed description of the svr .", "tokens": ["the", "interested", "reader", "is", "referred", "to", "for", "a", "detailed", "description", "of", "the", "svr", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the interested reader", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is referred", "start": 22, "end": 33, "i_start": 3, "i_end": 4}}], "id": 1393}, {"sent": "nevertheless , the fact that this phenomenological theory could provide an accurate approximation has been evidenced in the isotropic cosmology .", "tokens": ["nevertheless", ",", "the", "fact", "that", "this", "phenomenological", "theory", "could", "provide", "an", "accurate", "approximation", "has", "been", "evidenced", "in", "the", "isotropic", "cosmology", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the fact that this phenomenological theory could provide an accurate approximation", "start": 15, "end": 97, "i_start": 2, "i_end": 12}, "verb": {"text": "has been evidenced", "start": 98, "end": 116, "i_start": 13, "i_end": 15}}, {"character": {"text": "theory", "start": 51, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "provide", "start": 64, "end": 71, "i_start": 9, "i_end": 9}}], "id": 1394}, {"sent": "the expectation-maximization algorithm introduced by dempster et al in 1977 is a very general method to solve maximum likelihood estimation problems .", "tokens": ["the", "expectation", "-", "maximization", "algorithm", "introduced", "by", "dempster", "et", "al", "in", "1977", "is", "a", "very", "general", "method", "to", "solve", "maximum", "likelihood", "estimation", "problems", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the expectation-maximization algorithm introduced by dempster et al in 1977", "start": 0, "end": 75, "i_start": 0, "i_end": 11}, "verb": {"text": "is", "start": 76, "end": 78, "i_start": 12, "i_end": 12}}, {"character": {"text": "dempster", "start": 53, "end": 61, "i_start": 7, "i_end": 7}, "action": {"text": "introduced", "start": 39, "end": 49, "i_start": 5, "i_end": 5}}], "id": 1395}, {"sent": "every countable graph admits an unfriendly partition of its vertex set .", "tokens": ["every", "countable", "graph", "admits", "an", "unfriendly", "partition", "of", "its", "vertex", "set", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "every countable graph", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "admits", "start": 22, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "graph", "start": 16, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "admits", "start": 22, "end": 28, "i_start": 3, "i_end": 3}}], "id": 1396}, {"sent": "neural network models are examples of deep learning algorithms , which have been successfully applied in many areas with large data sets .", "tokens": ["neural", "network", "models", "are", "examples", "of", "deep", "learning", "algorithms", ",", "which", "have", "been", "successfully", "applied", "in", "many", "areas", "with", "large", "data", "sets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural network models", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 22, "end": 25, "i_start": 3, "i_end": 3}}], "id": 1397}, {"sent": "methods based on deep neural networks have achieved stateof-the-art performance on a variety of computer vision tasks , such as scene recognition .", "tokens": ["methods", "based", "on", "deep", "neural", "networks", "have", "achieved", "stateof", "-", "the", "-", "art", "performance", "on", "a", "variety", "of", "computer", "vision", "tasks", ",", "such", "as", "scene", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "methods based on deep neural networks", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "have achieved", "start": 38, "end": 51, "i_start": 6, "i_end": 7}}, {"character": {"text": "methods", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "achieved", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}], "id": 1398}, {"sent": "for the convolutional layers , we use the vgg16 model pre-trained on imagenet data .", "tokens": ["for", "the", "convolutional", "layers", ",", "we", "use", "the", "vgg16", "model", "pre", "-", "trained", "on", "imagenet", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}], "id": 1399}, {"sent": "this extends the result presented in , which only applies to synchronous failure-free systems , to failure-prone asynchronous systems .", "tokens": ["this", "extends", "the", "result", "presented", "in", ",", "which", "only", "applies", "to", "synchronous", "failure", "-", "free", "systems", ",", "to", "failure", "-", "prone", "asynchronous", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "extends", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "extends", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}], "id": 1400}, {"sent": "note how it completely captures the behavior of the degree distribution .", "tokens": ["note", "how", "it", "completely", "captures", "the", "behavior", "of", "the", "degree", "distribution", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "it", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "verb": {"text": "captures", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "it", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "action": {"text": "captures", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "distribution", "start": 59, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "behavior", "start": 36, "end": 44, "i_start": 6, "i_end": 6}}], "id": 1401}, {"sent": "in order to apply such approaches to large state spaces , we propose using a deep q-network as the reinforcement learning step .", "tokens": ["in", "order", "to", "apply", "such", "approaches", "to", "large", "state", "spaces", ",", "we", "propose", "using", "a", "deep", "q", "-", "network", "as", "the", "reinforcement", "learning", "step", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 58, "end": 60, "i_start": 11, "i_end": 11}, "verb": {"text": "propose", "start": 61, "end": 68, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 58, "end": 60, "i_start": 11, "i_end": 11}, "action": {"text": "propose", "start": 61, "end": 68, "i_start": 12, "i_end": 12}}], "id": 1402}, {"sent": "convolutional neural networks have achieved state-of-the-art accuracy in computer vision tasks such as image recognition .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "accuracy", "in", "computer", "vision", "tasks", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 1403}, {"sent": "sardanashvily , geometric quantization of mechanical systems with time-dependent parameters , j .", "tokens": ["sardanashvily", ",", "geometric", "quantization", "of", "mechanical", "systems", "with", "time", "-", "dependent", "parameters", ",", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "parameters", "start": 81, "end": 91, "i_start": 11, "i_end": 11}, "action": {"text": "dependent", "start": 71, "end": 80, "i_start": 10, "i_end": 10}}], "id": 1404}, {"sent": "deep neural networks have exhibited great performance in computer vision tasks in recent years .", "tokens": ["deep", "neural", "networks", "have", "exhibited", "great", "performance", "in", "computer", "vision", "tasks", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have exhibited", "start": 21, "end": 35, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "exhibited", "start": 26, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 42, "end": 53, "i_start": 6, "i_end": 6}}], "id": 1405}, {"sent": "the superscripts i and m denote insertions or monomorphisms for the domain and codomain .", "tokens": ["the", "superscripts", "i", "and", "m", "denote", "insertions", "or", "monomorphisms", "for", "the", "domain", "and", "codomain", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "superscripts", "start": 4, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 25, "end": 31, "i_start": 5, "i_end": 5}}], "id": 1406}, {"sent": "deep neural networks have become the standard building block in numerous machine learning applications , including computer vision , achieving state-of-the-art performance on extremely difficult tasks .", "tokens": ["deep", "neural", "networks", "have", "become", "the", "standard", "building", "block", "in", "numerous", "machine", "learning", "applications", ",", "including", "computer", "vision", ",", "achieving", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "extremely", "difficult", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have become", "start": 21, "end": 32, "i_start": 3, "i_end": 4}}], "id": 1407}, {"sent": "c ompressive sensing is a recently developed and fast growing field of research as a novel sampling paradigm .", "tokens": ["c", "ompressive", "sensing", "is", "a", "recently", "developed", "and", "fast", "growing", "field", "of", "research", "as", "a", "novel", "sampling", "paradigm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "ompressive sensing", "start": 2, "end": 20, "i_start": 1, "i_end": 2}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 3, "i_end": 3}}], "id": 1408}, {"sent": "cosmic strings are stable linear defects that potentially arise in a symmetry breaking phase transition in the early universe or in brane inflation models of string theory .", "tokens": ["cosmic", "strings", "are", "stable", "linear", "defects", "that", "potentially", "arise", "in", "a", "symmetry", "breaking", "phase", "transition", "in", "the", "early", "universe", "or", "in", "brane", "inflation", "models", "of", "string", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "or", "start": 126, "end": 128, "i_start": 19, "i_end": 19}, "action": {"text": "arise", "start": 58, "end": 63, "i_start": 8, "i_end": 8}}, {"character": {"text": "transition", "start": 93, "end": 103, "i_start": 14, "i_end": 14}, "action": {"text": "breaking", "start": 78, "end": 86, "i_start": 12, "i_end": 12}}], "id": 1409}, {"sent": "when the space k is a discreet space , we consider the point p instead of the ball let k denote a 2-dimensional adjacent to it , the brownian motion is transient .", "tokens": ["when", "the", "space", "k", "is", "a", "discreet", "space", ",", "we", "consider", "the", "point", "p", "instead", "of", "the", "ball", "let", "k", "denote", "a", "2", "-", "dimensional", "adjacent", "to", "it", ",", "the", "brownian", "motion", "is", "transient", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "the brownian motion", "start": 129, "end": 148, "i_start": 29, "i_end": 31}, "verb": {"text": "is", "start": 149, "end": 151, "i_start": 32, "i_end": 32}}, {"subject": {"text": "we", "start": 39, "end": 41, "i_start": 9, "i_end": 9}, "verb": {"text": "consider", "start": 42, "end": 50, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 39, "end": 41, "i_start": 9, "i_end": 9}, "action": {"text": "consider", "start": 42, "end": 50, "i_start": 10, "i_end": 10}}, {"character": {"text": "point", "start": 55, "end": 60, "i_start": 12, "i_end": 12}, "action": {"text": "denote", "start": 89, "end": 95, "i_start": 20, "i_end": 20}}], "id": 1410}, {"sent": "we now turn to some of the issues faced in the lattice determinations of the matrix elements .", "tokens": ["we", "now", "turn", "to", "some", "of", "the", "issues", "faced", "in", "the", "lattice", "determinations", "of", "the", "matrix", "elements", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "turn", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "turn", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "determinations", "start": 55, "end": 69, "i_start": 12, "i_end": 12}, "action": {"text": "faced", "start": 34, "end": 39, "i_start": 8, "i_end": 8}}], "id": 1411}, {"sent": "the dft calculations are done within the generalized gradient approximation and the perdewburke-ernzerhof exchange correlation function .", "tokens": ["the", "dft", "calculations", "are", "done", "within", "the", "generalized", "gradient", "approximation", "and", "the", "perdewburke", "-", "ernzerhof", "exchange", "correlation", "function", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dft calculations", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are done", "start": 21, "end": 29, "i_start": 3, "i_end": 4}}, {"character": {"text": "perdewburke", "start": 84, "end": 95, "i_start": 12, "i_end": 12}, "action": {"text": "exchange", "start": 106, "end": 114, "i_start": 15, "i_end": 15}}], "id": 1412}, {"sent": "the phase space is the cotangent bundle over it with conjugate momenta denoted by pi .", "tokens": ["the", "phase", "space", "is", "the", "cotangent", "bundle", "over", "it", "with", "conjugate", "momenta", "denoted", "by", "pi", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the phase space", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 1413}, {"sent": "the second step of our approach comprises of solving iteratively the two-dimensional problems by using data received from other two-dimensional problems .", "tokens": ["the", "second", "step", "of", "our", "approach", "comprises", "of", "solving", "iteratively", "the", "two", "-", "dimensional", "problems", "by", "using", "data", "received", "from", "other", "two", "-", "dimensional", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the second step of our approach", "start": 0, "end": 31, "i_start": 0, "i_end": 5}, "verb": {"text": "comprises", "start": 32, "end": 41, "i_start": 6, "i_end": 6}}], "id": 1414}, {"sent": "deep neural networks have powered many research areas from computer vision , natural language processing to biology and e-commerce .", "tokens": ["deep", "neural", "networks", "have", "powered", "many", "research", "areas", "from", "computer", "vision", ",", "natural", "language", "processing", "to", "biology", "and", "e", "-", "commerce", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have powered", "start": 21, "end": 33, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "powered", "start": 26, "end": 33, "i_start": 4, "i_end": 4}}], "id": 1415}, {"sent": "deep neural networks have been shown to be effective for solving many computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "been", "shown", "to", "be", "effective", "for", "solving", "many", "computer", "vision", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been shown", "start": 21, "end": 36, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "effective", "start": 43, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "solving", "start": 57, "end": 64, "i_start": 10, "i_end": 10}}], "id": 1416}, {"sent": "we follow the grouped gaussian process approach of , where groups of latent functions may covary arbitrarily with a separable kernel structure .", "tokens": ["we", "follow", "the", "grouped", "gaussian", "process", "approach", "of", ",", "where", "groups", "of", "latent", "functions", "may", "covary", "arbitrarily", "with", "a", "separable", "kernel", "structure", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 1417}, {"sent": "overlaid is the simple line fit discussed in the text .", "tokens": ["overlaid", "is", "the", "simple", "line", "fit", "discussed", "in", "the", "text", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1418}, {"sent": "all known ds critical points develop some instability in the scalar spectrum .", "tokens": ["all", "known", "ds", "critical", "points", "develop", "some", "instability", "in", "the", "scalar", "spectrum", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "points", "start": 22, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "develop", "start": 29, "end": 36, "i_start": 5, "i_end": 5}}], "id": 1419}, {"sent": "we believe the most plausible explanation is the conventional one that late-types are destroyed during transit through the cluster core and that mid-types are converted into early-types through a similar process , which destroys the outer disk and results in a more tightly bound population of core ellipticals .", "tokens": ["we", "believe", "the", "most", "plausible", "explanation", "is", "the", "conventional", "one", "that", "late", "-", "types", "are", "destroyed", "during", "transit", "through", "the", "cluster", "core", "and", "that", "mid", "-", "types", "are", "converted", "into", "early", "-", "types", "through", "a", "similar", "process", ",", "which", "destroys", "the", "outer", "disk", "and", "results", "in", "a", "more", "tightly", "bound", "population", "of", "core", "ellipticals", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "believe", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 42, "end": 44, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "believe", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "process", "start": 204, "end": 211, "i_start": 36, "i_end": 36}, "action": {"text": "destroys", "start": 220, "end": 228, "i_start": 39, "i_end": 39}}], "id": 1420}, {"sent": "in this section , we describe the k-lines clustering , a 1-d subspace clustering procedure proposed in , which forms a building block of the proposed dictionary learning algorithm .", "tokens": ["in", "this", "section", ",", "we", "describe", "the", "k", "-", "lines", "clustering", ",", "a", "1", "-", "d", "subspace", "clustering", "procedure", "proposed", "in", ",", "which", "forms", "a", "building", "block", "of", "the", "proposed", "dictionary", "learning", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "describe", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "describe", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}], "id": 1421}, {"sent": "we use stochastic gradient descent with adam updates for optimization .", "tokens": ["we", "use", "stochastic", "gradient", "descent", "with", "adam", "updates", "for", "optimization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 1422}, {"sent": "one type of the state-of-the-art deep learning methods for object detection is r-cnn .", "tokens": ["one", "type", "of", "the", "state", "-", "of", "-", "the", "-", "art", "deep", "learning", "methods", "for", "object", "detection", "is", "r", "-", "cnn", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "one type of the state-of-the-art deep learning methods for object detection", "start": 0, "end": 75, "i_start": 0, "i_end": 16}, "verb": {"text": "is", "start": 76, "end": 78, "i_start": 17, "i_end": 17}}], "id": 1423}, {"sent": "we refer the reader to for technical background to this section , in which we describe a standard metropolis-hastings mcmc approach to replicating pds .", "tokens": ["we", "refer", "the", "reader", "to", "for", "technical", "background", "to", "this", "section", ",", "in", "which", "we", "describe", "a", "standard", "metropolis", "-", "hastings", "mcmc", "approach", "to", "replicating", "pds", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "describe", "start": 78, "end": 86, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "approach", "start": 123, "end": 131, "i_start": 22, "i_end": 22}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "replicating", "start": 135, "end": 146, "i_start": 24, "i_end": 24}}, {"character": {"text": "mcmc", "start": 118, "end": 122, "i_start": 21, "i_end": 21}, "action": {"text": "hastings", "start": 109, "end": 117, "i_start": 20, "i_end": 20}}], "id": 1424}, {"sent": "neural machine translation using a sequence-to-sequence model has achieved stateof-the-art performance for several language pairs .", "tokens": ["neural", "machine", "translation", "using", "a", "sequence", "-", "to", "-", "sequence", "model", "has", "achieved", "stateof", "-", "the", "-", "art", "performance", "for", "several", "language", "pairs", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "neural machine translation using a sequence-to-sequence model", "start": 0, "end": 61, "i_start": 0, "i_end": 10}, "verb": {"text": "has achieved", "start": 62, "end": 74, "i_start": 11, "i_end": 12}}, {"character": {"text": "translation", "start": 15, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 66, "end": 74, "i_start": 12, "i_end": 12}}], "id": 1425}, {"sent": "for a nonlinear and bounded process such as wind generation , probability distributions of future wind power for instance may be skewed and heavy-tailed distributed .", "tokens": ["for", "a", "nonlinear", "and", "bounded", "process", "such", "as", "wind", "generation", ",", "probability", "distributions", "of", "future", "wind", "power", "for", "instance", "may", "be", "skewed", "and", "heavy", "-", "tailed", "distributed", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1426}, {"sent": "significant improvements have been obtained in various computer vision tasks by applying deep learning techniques , including image classification .", "tokens": ["significant", "improvements", "have", "been", "obtained", "in", "various", "computer", "vision", "tasks", "by", "applying", "deep", "learning", "techniques", ",", "including", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "significant improvements", "start": 0, "end": 24, "i_start": 0, "i_end": 1}, "verb": {"text": "have been obtained", "start": 25, "end": 43, "i_start": 2, "i_end": 4}}], "id": 1427}, {"sent": "cosmic strings are linear topological defects that can form in the early universe as a result of symmetry-breaking phase transitions .", "tokens": ["cosmic", "strings", "are", "linear", "topological", "defects", "that", "can", "form", "in", "the", "early", "universe", "as", "a", "result", "of", "symmetry", "-", "breaking", "phase", "transitions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "transitions", "start": 121, "end": 132, "i_start": 21, "i_end": 21}, "action": {"text": "breaking", "start": 106, "end": 114, "i_start": 19, "i_end": 19}}], "id": 1428}, {"sent": "thus , our system naturally supports methods of organization that emphasize incentives for high availability , such as mutual storage contracts .", "tokens": ["thus", ",", "our", "system", "naturally", "supports", "methods", "of", "organization", "that", "emphasize", "incentives", "for", "high", "availability", ",", "such", "as", "mutual", "storage", "contracts", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our system", "start": 7, "end": 17, "i_start": 2, "i_end": 3}, "verb": {"text": "supports", "start": 28, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "system", "start": 11, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "supports", "start": 28, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "methods", "start": 37, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "emphasize", "start": 66, "end": 75, "i_start": 10, "i_end": 10}}], "id": 1429}, {"sent": "dickman , time-dependent perturbation theory for nonequilibrium lattice models , j .", "tokens": ["dickman", ",", "time", "-", "dependent", "perturbation", "theory", "for", "nonequilibrium", "lattice", "models", ",", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "time", "start": 10, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "dependent", "start": 15, "end": 24, "i_start": 4, "i_end": 4}}], "id": 1430}, {"sent": "for example , we are not going to establish any limit on the accuracy required for a potential energy function to successfully predict the folding of proteins .", "tokens": ["for", "example", ",", "we", "are", "not", "going", "to", "establish", "any", "limit", "on", "the", "accuracy", "required", "for", "a", "potential", "energy", "function", "to", "successfully", "predict", "the", "folding", "of", "proteins", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "are not going", "start": 17, "end": 30, "i_start": 4, "i_end": 6}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "not going to establish", "start": 21, "end": 43, "i_start": 5, "i_end": 8}}, {"character": {"text": "function", "start": 102, "end": 110, "i_start": 19, "i_end": 19}, "action": {"text": "required", "start": 70, "end": 78, "i_start": 14, "i_end": 14}}, {"character": {"text": "function", "start": 102, "end": 110, "i_start": 19, "i_end": 19}, "action": {"text": "predict", "start": 127, "end": 134, "i_start": 22, "i_end": 22}}], "id": 1431}, {"sent": "the prediction is really in terms of an idealized measurement , one in which the perturbation caused by the experiment is so small that it can be neglected .", "tokens": ["the", "prediction", "is", "really", "in", "terms", "of", "an", "idealized", "measurement", ",", "one", "in", "which", "the", "perturbation", "caused", "by", "the", "experiment", "is", "so", "small", "that", "it", "can", "be", "neglected", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the prediction", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "experiment", "start": 108, "end": 118, "i_start": 19, "i_end": 19}, "action": {"text": "caused", "start": 94, "end": 100, "i_start": 16, "i_end": 16}}], "id": 1432}, {"sent": "hd 194280 hd 194280 is a member of cyg ob1 , lying at some distance from ngc 6913 .", "tokens": ["hd", "194280", "hd", "194280", "is", "a", "member", "of", "cyg", "ob1", ",", "lying", "at", "some", "distance", "from", "ngc", "6913", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "hd 194280 hd 194280", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 4, "i_end": 4}}], "id": 1433}, {"sent": "we use resnet models for cifar10 classification .", "tokens": ["we", "use", "resnet", "models", "for", "cifar10", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 1434}, {"sent": "we have used adam optimizer for training our model parameters .", "tokens": ["we", "have", "used", "adam", "optimizer", "for", "training", "our", "model", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have used", "start": 3, "end": 12, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "training", "start": 32, "end": 40, "i_start": 6, "i_end": 6}}], "id": 1435}, {"sent": "machine learning is being used in a number of essential applications such as image recognition .", "tokens": ["machine", "learning", "is", "being", "used", "in", "a", "number", "of", "essential", "applications", "such", "as", "image", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "machine learning", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is being used", "start": 17, "end": 30, "i_start": 2, "i_end": 4}}], "id": 1436}, {"sent": "the most common criteria are capacity maximization and data mean-square-error minimization .", "tokens": ["the", "most", "common", "criteria", "are", "capacity", "maximization", "and", "data", "mean", "-", "square", "-", "error", "minimization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most common criteria", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 25, "end": 28, "i_start": 4, "i_end": 4}}], "id": 1437}, {"sent": "deep neural networks have seen great success in many cognitive applications such as image classification .", "tokens": ["deep", "neural", "networks", "have", "seen", "great", "success", "in", "many", "cognitive", "applications", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have seen", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 37, "end": 44, "i_start": 6, "i_end": 6}}], "id": 1438}, {"sent": "the spin-polarized density functional theory calculations were carried out by using the projector augmented wave method 26 , 27 as implemented in the vienna ab initio simulation package .", "tokens": ["the", "spin", "-", "polarized", "density", "functional", "theory", "calculations", "were", "carried", "out", "by", "using", "the", "projector", "augmented", "wave", "method", "26", ",", "27", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the spin-polarized density functional theory calculations", "start": 0, "end": 57, "i_start": 0, "i_end": 7}, "verb": {"text": "were carried out", "start": 58, "end": 74, "i_start": 8, "i_end": 10}}, {"character": {"text": "projector", "start": 88, "end": 97, "i_start": 14, "i_end": 14}, "action": {"text": "augmented", "start": 98, "end": 107, "i_start": 15, "i_end": 15}}], "id": 1439}, {"sent": "the jet axis is indicated by the dotted arrow and makes an angle \u03b8dj with the z-axis and an azimuthal angle \u03c6dj with the x-axis .", "tokens": ["the", "jet", "axis", "is", "indicated", "by", "the", "dotted", "arrow", "and", "makes", "an", "angle", "\u03b8dj", "with", "the", "z", "-", "axis", "and", "an", "azimuthal", "angle", "\u03c6dj", "with", "the", "x", "-", "axis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the jet axis", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "is indicated", "start": 13, "end": 25, "i_start": 3, "i_end": 4}}, {"subject": {"text": "the jet axis", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "makes", "start": 50, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "arrow", "start": 40, "end": 45, "i_start": 8, "i_end": 8}, "action": {"text": "indicated", "start": 16, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "axis", "start": 8, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "makes", "start": 50, "end": 55, "i_start": 10, "i_end": 10}}], "id": 1440}, {"sent": "the shaded band indicates the experimental error .", "tokens": ["the", "shaded", "band", "indicates", "the", "experimental", "error", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the shaded band", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "indicates", "start": 16, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "band", "start": 11, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "indicates", "start": 16, "end": 25, "i_start": 3, "i_end": 3}}], "id": 1441}, {"sent": "as a result , almost all the public face alignment databases such as afw are collected in medium poses .", "tokens": ["as", "a", "result", ",", "almost", "all", "the", "public", "face", "alignment", "databases", "such", "as", "afw", "are", "collected", "in", "medium", "poses", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "almost all the public face alignment databases such as afw", "start": 14, "end": 72, "i_start": 4, "i_end": 13}, "verb": {"text": "are collected", "start": 73, "end": 86, "i_start": 14, "i_end": 15}}], "id": 1442}, {"sent": "quantum teleportation are fundamental elements of quantum communication protocols and thus play an important role in a number of applications .", "tokens": ["quantum", "teleportation", "are", "fundamental", "elements", "of", "quantum", "communication", "protocols", "and", "thus", "play", "an", "important", "role", "in", "a", "number", "of", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "quantum teleportation", "start": 0, "end": 21, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 22, "end": 25, "i_start": 2, "i_end": 2}}, {"subject": {"text": "quantum teleportation", "start": 0, "end": 21, "i_start": 0, "i_end": 1}, "verb": {"text": "play", "start": 91, "end": 95, "i_start": 11, "i_end": 11}}, {"character": {"text": "teleportation", "start": 8, "end": 21, "i_start": 1, "i_end": 1}, "action": {"text": "play", "start": 91, "end": 95, "i_start": 11, "i_end": 11}}], "id": 1443}, {"sent": "mf-based methods are perhaps the most popular class of model-based cf approaches .", "tokens": ["mf", "-", "based", "methods", "are", "perhaps", "the", "most", "popular", "class", "of", "model", "-", "based", "cf", "approaches", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "mf-based methods", "start": 0, "end": 16, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 17, "end": 20, "i_start": 4, "i_end": 4}}], "id": 1444}, {"sent": "using this model , the authors of derive an mle for the pass rate of a path connecting the source to a node .", "tokens": ["using", "this", "model", ",", "the", "authors", "of", "derive", "an", "mle", "for", "the", "pass", "rate", "of", "a", "path", "connecting", "the", "source", "to", "a", "node", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the authors of", "start": 19, "end": 33, "i_start": 4, "i_end": 6}, "verb": {"text": "derive", "start": 34, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "this", "start": 6, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "derive", "start": 34, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "path", "start": 71, "end": 75, "i_start": 16, "i_end": 16}, "action": {"text": "connecting", "start": 76, "end": 86, "i_start": 17, "i_end": 17}}, {"character": {"text": "this", "start": 6, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "using", "start": 0, "end": 5, "i_start": 0, "i_end": 0}}], "id": 1445}, {"sent": "for example , the travel industry now has a well-defined and documented , set of both services and data , sufficient to allow any competent software engineer to create travel agency software using entirely off-the-shelf software services .", "tokens": ["for", "example", ",", "the", "travel", "industry", "now", "has", "a", "well", "-", "defined", "and", "documented", ",", "set", "of", "both", "services", "and", "data", ",", "sufficient", "to", "allow", "any", "competent", "software", "engineer", "to", "create", "travel", "agency", "software", "using", "entirely", "off", "-", "the", "-", "shelf", "software", "services", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the travel industry", "start": 14, "end": 33, "i_start": 3, "i_end": 5}, "verb": {"text": "has", "start": 38, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "industry", "start": 25, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "has", "start": 38, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "set", "start": 74, "end": 77, "i_start": 15, "i_end": 15}, "action": {"text": "sufficient", "start": 106, "end": 116, "i_start": 22, "i_end": 22}}, {"character": {"text": "set", "start": 74, "end": 77, "i_start": 15, "i_end": 15}, "action": {"text": "allow", "start": 120, "end": 125, "i_start": 24, "i_end": 24}}, {"character": {"text": "any", "start": 126, "end": 129, "i_start": 25, "i_end": 25}, "action": {"text": "create", "start": 161, "end": 167, "i_start": 30, "i_end": 30}}], "id": 1446}, {"sent": "fomin and zelevinsky have introduced cluster algebras in an impactful article .", "tokens": ["fomin", "and", "zelevinsky", "have", "introduced", "cluster", "algebras", "in", "an", "impactful", "article", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "fomin and zelevinsky", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have introduced", "start": 21, "end": 36, "i_start": 3, "i_end": 4}}, {"character": {"text": "fomin", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 26, "end": 36, "i_start": 4, "i_end": 4}}, {"character": {"text": "zelevinsky", "start": 10, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 26, "end": 36, "i_start": 4, "i_end": 4}}, {"character": {"text": "article", "start": 70, "end": 77, "i_start": 10, "i_end": 10}, "action": {"text": "impactful", "start": 60, "end": 69, "i_start": 9, "i_end": 9}}], "id": 1447}, {"sent": "the underlying ab initio structural relaxations were carried out using density functional theory within the perdew-burke-ernzerhof exchange-correlation as implemented in the vienna ab initio simulation package code .", "tokens": ["the", "underlying", "ab", "initio", "structural", "relaxations", "were", "carried", "out", "using", "density", "functional", "theory", "within", "the", "perdew", "-", "burke", "-", "ernzerhof", "exchange", "-", "correlation", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "code", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the underlying ab initio structural relaxations", "start": 0, "end": 47, "i_start": 0, "i_end": 5}, "verb": {"text": "were carried out", "start": 48, "end": 64, "i_start": 6, "i_end": 8}}, {"character": {"text": "relaxations", "start": 36, "end": 47, "i_start": 5, "i_end": 5}, "action": {"text": "underlying", "start": 4, "end": 14, "i_start": 1, "i_end": 1}}], "id": 1448}, {"sent": "three-wave interaction in two-component quadratic nonlinear lattices , phys .", "tokens": ["three", "-", "wave", "interaction", "in", "two", "-", "component", "quadratic", "nonlinear", "lattices", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "three-wave", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "action": {"text": "interaction", "start": 11, "end": 22, "i_start": 3, "i_end": 3}}], "id": 1449}, {"sent": "the 2d and 3d maxwell points in the band structures that have related topological phase transition can be detected by the bragg spectroscopy or bloch-zener oscillations , similar to the methods used for detecting dirac and weyl points in optical lattices .", "tokens": ["the", "2d", "and", "3d", "maxwell", "points", "in", "the", "band", "structures", "that", "have", "related", "topological", "phase", "transition", "can", "be", "detected", "by", "the", "bragg", "spectroscopy", "or", "bloch", "-", "zener", "oscillations", ",", "similar", "to", "the", "methods", "used", "for", "detecting", "dirac", "and", "weyl", "points", "in", "optical", "lattices", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "the 2d and 3d maxwell points in the band structures that have related topological phase transition", "start": 0, "end": 98, "i_start": 0, "i_end": 15}, "verb": {"text": "can be detected", "start": 99, "end": 114, "i_start": 16, "i_end": 18}}, {"character": {"text": "or", "start": 141, "end": 143, "i_start": 23, "i_end": 23}, "action": {"text": "detected", "start": 106, "end": 114, "i_start": 18, "i_end": 18}}], "id": 1450}, {"sent": "all measured critical exponents are listed in table ii .", "tokens": ["all", "measured", "critical", "exponents", "are", "listed", "in", "table", "ii", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all measured critical exponents", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "are listed", "start": 32, "end": 42, "i_start": 4, "i_end": 5}}], "id": 1451}, {"sent": "now we proceed to the continuous dependence result .", "tokens": ["now", "we", "proceed", "to", "the", "continuous", "dependence", "result", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}], "id": 1452}, {"sent": "in this approximation , sdisplays only the spw peak , though an additional broad peak due to vpws has been seen in numerous scattering experiments 14 , 83 .", "tokens": ["in", "this", "approximation", ",", "sdisplays", "only", "the", "spw", "peak", ",", "though", "an", "additional", "broad", "peak", "due", "to", "vpws", "has", "been", "seen", "in", "numerous", "scattering", "experiments", "14", ",", "83", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1453}, {"sent": "a smooth orbifold together with a riemannian metric is called a riemannian orbifold .", "tokens": ["a", "smooth", "orbifold", "together", "with", "a", "riemannian", "metric", "is", "called", "a", "riemannian", "orbifold", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a smooth orbifold together with a riemannian metric", "start": 0, "end": 51, "i_start": 0, "i_end": 7}, "verb": {"text": "is called", "start": 52, "end": 61, "i_start": 8, "i_end": 9}}], "id": 1454}, {"sent": "the wave front is the eikonal surface , ie the surface with a conservative quantity .", "tokens": ["the", "wave", "front", "is", "the", "eikonal", "surface", ",", "ie", "the", "surface", "with", "a", "conservative", "quantity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the wave front", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}], "id": 1455}, {"sent": "the set-to-set few-shot learning setting has been vital in framing few-shot learning as a meta-learning problem .", "tokens": ["the", "set", "-", "to", "-", "set", "few", "-", "shot", "learning", "setting", "has", "been", "vital", "in", "framing", "few", "-", "shot", "learning", "as", "a", "meta", "-", "learning", "problem", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the set-to-set few-shot learning setting", "start": 0, "end": 40, "i_start": 0, "i_end": 10}, "verb": {"text": "has been", "start": 41, "end": 49, "i_start": 11, "i_end": 12}}], "id": 1456}, {"sent": "another modification is the reduction of the compton cross section in the klein-nishina regime .", "tokens": ["another", "modification", "is", "the", "reduction", "of", "the", "compton", "cross", "section", "in", "the", "klein", "-", "nishina", "regime", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another modification", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 2, "i_end": 2}}], "id": 1457}, {"sent": "let us prove the identity by the induction on n .", "tokens": ["let", "us", "prove", "the", "identity", "by", "the", "induction", "on", "n", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "prove", "start": 7, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "prove", "start": 7, "end": 12, "i_start": 2, "i_end": 2}}], "id": 1458}, {"sent": "the analytical performance derivation of dcsk communication systems has been presented in for cooperative and multipleinput multiple-output schemes .", "tokens": ["the", "analytical", "performance", "derivation", "of", "dcsk", "communication", "systems", "has", "been", "presented", "in", "for", "cooperative", "and", "multipleinput", "multiple", "-", "output", "schemes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the analytical performance derivation of dcsk communication systems", "start": 0, "end": 67, "i_start": 0, "i_end": 7}, "verb": {"text": "has been presented", "start": 68, "end": 86, "i_start": 8, "i_end": 10}}], "id": 1459}, {"sent": "the crystal was found to consist of a single ferroelectric domain in thz wave emission experiments27 , in which the orientation of the ferroelectric c axis was also determined .", "tokens": ["the", "crystal", "was", "found", "to", "consist", "of", "a", "single", "ferroelectric", "domain", "in", "thz", "wave", "emission", "experiments27", ",", "in", "which", "the", "orientation", "of", "the", "ferroelectric", "c", "axis", "was", "also", "determined", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the crystal", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "was found", "start": 12, "end": 21, "i_start": 2, "i_end": 3}}], "id": 1460}, {"sent": "nicolussi , gk , pellin , mj , lewis , rs , davis , am , amari , s .", "tokens": ["nicolussi", ",", "gk", ",", "pellin", ",", "mj", ",", "lewis", ",", "rs", ",", "davis", ",", "am", ",", "amari", ",", "s", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "nicolussi", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "am", "start": 52, "end": 54, "i_start": 14, "i_end": 14}}], "id": 1461}, {"sent": "we adopt the activation map from the mean pooling layer of resnet50 .", "tokens": ["we", "adopt", "the", "activation", "map", "from", "the", "mean", "pooling", "layer", "of", "resnet50", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "layer", "start": 50, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "mean", "start": 37, "end": 41, "i_start": 7, "i_end": 7}}], "id": 1462}, {"sent": "the entanglement issues in two-mode squeezed states can therefore be added to the physics of coupled harmonic oscillators .", "tokens": ["the", "entanglement", "issues", "in", "two", "-", "mode", "squeezed", "states", "can", "therefore", "be", "added", "to", "the", "physics", "of", "coupled", "harmonic", "oscillators", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the entanglement issues in two-mode squeezed states", "start": 0, "end": 51, "i_start": 0, "i_end": 8}, "verb": {"text": "be added", "start": 66, "end": 74, "i_start": 11, "i_end": 12}}, {"subject": {"text": "the entanglement issues in two-mode squeezed states", "start": 0, "end": 51, "i_start": 0, "i_end": 8}, "verb": {"text": "can", "start": 52, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "entanglement", "start": 4, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "issues", "start": 17, "end": 23, "i_start": 2, "i_end": 2}}], "id": 1463}, {"sent": "the trainable variables were initialized with glorot and bengio method .", "tokens": ["the", "trainable", "variables", "were", "initialized", "with", "glorot", "and", "bengio", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the trainable variables", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "were initialized", "start": 24, "end": 40, "i_start": 3, "i_end": 4}}], "id": 1464}, {"sent": "deep convolutional neural networks have been successfully used in various computer vision applications such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successfully", "used", "in", "various", "computer", "vision", "applications", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "used", "start": 58, "end": 62, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}], "id": 1465}, {"sent": "the triplet potential vt is indicated by the thick dashed line .", "tokens": ["the", "triplet", "potential", "vt", "is", "indicated", "by", "the", "thick", "dashed", "line", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the triplet potential vt", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "is indicated", "start": 25, "end": 37, "i_start": 4, "i_end": 5}}, {"character": {"text": "line", "start": 58, "end": 62, "i_start": 10, "i_end": 10}, "action": {"text": "indicated", "start": 28, "end": 37, "i_start": 5, "i_end": 5}}], "id": 1466}, {"sent": "all spectral fitting was performed with the software package xspec .", "tokens": ["all", "spectral", "fitting", "was", "performed", "with", "the", "software", "package", "xspec", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all spectral fitting", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "was performed", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}], "id": 1467}, {"sent": "markov chain is defined as a process in which probability of transition from one state to another is determined only by the present state of the system .", "tokens": ["markov", "chain", "is", "defined", "as", "a", "process", "in", "which", "probability", "of", "transition", "from", "one", "state", "to", "another", "is", "determined", "only", "by", "the", "present", "state", "of", "the", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "markov chain", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is defined", "start": 13, "end": 23, "i_start": 2, "i_end": 3}}, {"character": {"text": "state", "start": 81, "end": 86, "i_start": 14, "i_end": 14}, "action": {"text": "determined", "start": 101, "end": 111, "i_start": 18, "i_end": 18}}], "id": 1468}, {"sent": "these models when trained joint with image encoders are also shown to learn good feature representations .", "tokens": ["these", "models", "when", "trained", "joint", "with", "image", "encoders", "are", "also", "shown", "to", "learn", "good", "feature", "representations", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "these models when trained joint with image encoders", "start": 0, "end": 51, "i_start": 0, "i_end": 7}, "verb": {"text": "shown", "start": 61, "end": 66, "i_start": 10, "i_end": 10}}, {"subject": {"text": "these models when trained joint with image encoders", "start": 0, "end": 51, "i_start": 0, "i_end": 7}, "verb": {"text": "are", "start": 52, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "models", "start": 6, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "learn", "start": 70, "end": 75, "i_start": 12, "i_end": 12}}], "id": 1469}, {"sent": "recently , region-based convolutional neural networks have achieved state-of-the-art performance on generic object detection .", "tokens": ["recently", ",", "region", "-", "based", "convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "generic", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "region-based convolutional neural networks", "start": 11, "end": 53, "i_start": 2, "i_end": 7}, "verb": {"text": "have achieved", "start": 54, "end": 67, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 45, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 59, "end": 67, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 45, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "performance", "start": 85, "end": 96, "i_start": 17, "i_end": 17}}], "id": 1470}, {"sent": "recently , representation learning via deep cnns has obtained great success in various of computer vision tasks , such as image classification .", "tokens": ["recently", ",", "representation", "learning", "via", "deep", "cnns", "has", "obtained", "great", "success", "in", "various", "of", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "representation learning via deep cnns", "start": 11, "end": 48, "i_start": 2, "i_end": 6}, "verb": {"text": "has obtained", "start": 49, "end": 61, "i_start": 7, "i_end": 8}}, {"character": {"text": "learning", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "obtained", "start": 53, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "learning", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 68, "end": 75, "i_start": 10, "i_end": 10}}], "id": 1471}, {"sent": "seesaw models offer an attractive possibility for explaining the observed baryon asymmetry of the universe by leptogenesis .", "tokens": ["seesaw", "models", "offer", "an", "attractive", "possibility", "for", "explaining", "the", "observed", "baryon", "asymmetry", "of", "the", "universe", "by", "leptogenesis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "seesaw models", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "offer", "start": 14, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "models", "start": 7, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "offer", "start": 14, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "models", "start": 7, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "explaining", "start": 50, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "possibility", "start": 34, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "attractive", "start": 23, "end": 33, "i_start": 4, "i_end": 4}}], "id": 1472}, {"sent": "in recent years , neural networks have been effectively applied in various problems such as voice recognition .", "tokens": ["in", "recent", "years", ",", "neural", "networks", "have", "been", "effectively", "applied", "in", "various", "problems", "such", "as", "voice", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 18, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "applied", "start": 56, "end": 63, "i_start": 9, "i_end": 9}}, {"subject": {"text": "neural networks", "start": 18, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "have been", "start": 34, "end": 43, "i_start": 6, "i_end": 7}}], "id": 1473}, {"sent": "in recent years , convolutional neural networks have become the de facto standard in many computer vision tasks , such as image classification and object detection .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "become", "the", "de", "facto", "standard", "in", "many", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "and", "object", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have become", "start": 48, "end": 59, "i_start": 7, "i_end": 8}}], "id": 1474}, {"sent": "we use the adam optimizer and a constant batch size of 128 .", "tokens": ["we", "use", "the", "adam", "optimizer", "and", "a", "constant", "batch", "size", "of", "128", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 1475}, {"sent": "reinforcement learning is a goal-oriented learning tool wherein an agent or a decision maker learns a policy to optimize a long-term reward by interacting with the environment .", "tokens": ["reinforcement", "learning", "is", "a", "goal", "-", "oriented", "learning", "tool", "wherein", "an", "agent", "or", "a", "decision", "maker", "learns", "a", "policy", "to", "optimize", "a", "long", "-", "term", "reward", "by", "interacting", "with", "the", "environment", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "or", "start": 73, "end": 75, "i_start": 12, "i_end": 12}, "action": {"text": "learning", "start": 42, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "or", "start": 73, "end": 75, "i_start": 12, "i_end": 12}, "action": {"text": "optimize", "start": 112, "end": 120, "i_start": 20, "i_end": 20}}, {"character": {"text": "or", "start": 73, "end": 75, "i_start": 12, "i_end": 12}, "action": {"text": "interacting", "start": 143, "end": 154, "i_start": 27, "i_end": 27}}], "id": 1476}, {"sent": "modern deep learning models , such as convolutional neural networks , have achieved notable successes in a wide spectrum of machine learning tasks , including speech recognition .", "tokens": ["modern", "deep", "learning", "models", ",", "such", "as", "convolutional", "neural", "networks", ",", "have", "achieved", "notable", "successes", "in", "a", "wide", "spectrum", "of", "machine", "learning", "tasks", ",", "including", "speech", "recognition", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "modern deep learning models", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 70, "end": 83, "i_start": 11, "i_end": 12}}, {"character": {"text": "models", "start": 21, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 75, "end": 83, "i_start": 12, "i_end": 12}}], "id": 1477}, {"sent": "carefully analyzing the situation one concludes that the correct condition is given by the analytical continuation of the minimal solutions from the upper half-plane to the lower one .", "tokens": ["carefully", "analyzing", "the", "situation", "one", "concludes", "that", "the", "correct", "condition", "is", "given", "by", "the", "analytical", "continuation", "of", "the", "minimal", "solutions", "from", "the", "upper", "half", "-", "plane", "to", "the", "lower", "one", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 34, "end": 37, "i_start": 4, "i_end": 4}, "verb": {"text": "concludes", "start": 38, "end": 47, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the correct condition", "start": 53, "end": 74, "i_start": 7, "i_end": 9}, "verb": {"text": "given", "start": 78, "end": 83, "i_start": 11, "i_end": 11}}, {"character": {"text": "one", "start": 34, "end": 37, "i_start": 4, "i_end": 4}, "action": {"text": "concludes", "start": 38, "end": 47, "i_start": 5, "i_end": 5}}, {"character": {"text": "continuation", "start": 102, "end": 114, "i_start": 15, "i_end": 15}, "action": {"text": "given", "start": 78, "end": 83, "i_start": 11, "i_end": 11}}], "id": 1478}, {"sent": "deep convolutional neural networks have made significant breakthroughs in many visual understanding tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "significant", "breakthroughs", "in", "many", "visual", "understanding", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "breakthroughs", "start": 57, "end": 70, "i_start": 7, "i_end": 7}}], "id": 1479}, {"sent": "we want to obtain the several expressions for these variables in terms of the return characteristic function .", "tokens": ["we", "want", "to", "obtain", "the", "several", "expressions", "for", "these", "variables", "in", "terms", "of", "the", "return", "characteristic", "function", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "want", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "want", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "obtain", "start": 11, "end": 17, "i_start": 3, "i_end": 3}}], "id": 1480}, {"sent": "the tv method was solved by alternating direction method of multipliers optimizer .", "tokens": ["the", "tv", "method", "was", "solved", "by", "alternating", "direction", "method", "of", "multipliers", "optimizer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the tv method", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "was solved", "start": 14, "end": 24, "i_start": 3, "i_end": 4}}], "id": 1481}, {"sent": "dropout is a popular and effective heuristic for preventing large neural networks from overfitting .", "tokens": ["dropout", "is", "a", "popular", "and", "effective", "heuristic", "for", "preventing", "large", "neural", "networks", "from", "overfitting", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dropout", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}], "id": 1482}, {"sent": "our results are consistent across physical networks which follow both waxman and barabasialbert models .", "tokens": ["our", "results", "are", "consistent", "across", "physical", "networks", "which", "follow", "both", "waxman", "and", "barabasialbert", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our results", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 12, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "networks", "start": 43, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "follow", "start": 58, "end": 64, "i_start": 8, "i_end": 8}}], "id": 1483}, {"sent": "we also show that this renormalization prescrip tion is enough to render the energy-momentum tensor finite in our approximation without the introduction of further geometrical counter-terms .", "tokens": ["we", "also", "show", "that", "this", "renormalization", "prescrip", "tion", "is", "enough", "to", "render", "the", "energy", "-", "momentum", "tensor", "finite", "in", "our", "approximation", "without", "the", "introduction", "of", "further", "geometrical", "counter", "-", "terms", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 53, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "prescrip", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "render", "start": 66, "end": 72, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "approximation", "start": 114, "end": 127, "i_start": 20, "i_end": 20}}], "id": 1484}, {"sent": "huisken showed that if the initial hypersurface in the euclidean space is compact and uniformly convex , then the mean curvature flow converges to a round point in a finite time .", "tokens": ["huisken", "showed", "that", "if", "the", "initial", "hypersurface", "in", "the", "euclidean", "space", "is", "compact", "and", "uniformly", "convex", ",", "then", "the", "mean", "curvature", "flow", "converges", "to", "a", "round", "point", "in", "a", "finite", "time", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "huisken", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "showed", "start": 8, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "huisken", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 8, "end": 14, "i_start": 1, "i_end": 1}}], "id": 1485}, {"sent": "the smallest known non-shellable 3-sphere s 3 13 56 has 13 vertices .", "tokens": ["the", "smallest", "known", "non", "-", "shellable", "3", "-", "sphere", "s", "3", "13", "56", "has", "13", "vertices", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the smallest known non-shellable 3-sphere s 3 13 56", "start": 0, "end": 51, "i_start": 0, "i_end": 12}, "verb": {"text": "has", "start": 52, "end": 55, "i_start": 13, "i_end": 13}}, {"character": {"text": "3-sphere", "start": 33, "end": 41, "i_start": 6, "i_end": 8}, "action": {"text": "has", "start": 52, "end": 55, "i_start": 13, "i_end": 13}}], "id": 1486}, {"sent": "convolutional neural networks have seen tremendous success across different problems including image classification .", "tokens": ["convolutional", "neural", "networks", "have", "seen", "tremendous", "success", "across", "different", "problems", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have seen", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "seen", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 51, "end": 58, "i_start": 6, "i_end": 6}}], "id": 1487}, {"sent": "massive mimo millimeterwave systems have recently emerged as the main key player in the future wireless networks .", "tokens": ["massive", "mimo", "millimeterwave", "systems", "have", "recently", "emerged", "as", "the", "main", "key", "player", "in", "the", "future", "wireless", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "massive mimo millimeterwave systems", "start": 0, "end": 35, "i_start": 0, "i_end": 3}, "verb": {"text": "emerged", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}, {"subject": {"text": "massive mimo millimeterwave systems", "start": 0, "end": 35, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 36, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "systems", "start": 28, "end": 35, "i_start": 3, "i_end": 3}, "action": {"text": "emerged", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}, {"character": {"text": "systems", "start": 28, "end": 35, "i_start": 3, "i_end": 3}, "action": {"text": "player", "start": 74, "end": 80, "i_start": 11, "i_end": 11}}], "id": 1488}, {"sent": "sachkov , control theory from the geometric viewpoint .", "tokens": ["sachkov", ",", "control", "theory", "from", "the", "geometric", "viewpoint", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1489}, {"sent": "this time delay is the result of the lower amplitude of the poisson fluctuations that seed the bar .", "tokens": ["this", "time", "delay", "is", "the", "result", "of", "the", "lower", "amplitude", "of", "the", "poisson", "fluctuations", "that", "seed", "the", "bar", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "delay", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "fluctuations", "start": 68, "end": 80, "i_start": 13, "i_end": 13}, "action": {"text": "seed", "start": 86, "end": 90, "i_start": 15, "i_end": 15}}], "id": 1490}, {"sent": "for visual applications , the convolutional neural networks represent one of the most utilised approaches for a number of continuously increasing large-scale machine vision tasks .", "tokens": ["for", "visual", "applications", ",", "the", "convolutional", "neural", "networks", "represent", "one", "of", "the", "most", "utilised", "approaches", "for", "a", "number", "of", "continuously", "increasing", "large", "-", "scale", "machine", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the convolutional neural networks", "start": 26, "end": 59, "i_start": 4, "i_end": 7}, "verb": {"text": "represent", "start": 60, "end": 69, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 51, "end": 59, "i_start": 7, "i_end": 7}, "action": {"text": "represent", "start": 60, "end": 69, "i_start": 8, "i_end": 8}}], "id": 1491}, {"sent": "for a recent survey on synchronizing automata we refer the reader to .", "tokens": ["for", "a", "recent", "survey", "on", "synchronizing", "automata", "we", "refer", "the", "reader", "to", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 46, "end": 48, "i_start": 7, "i_end": 7}, "verb": {"text": "refer", "start": 49, "end": 54, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 46, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "refer", "start": 49, "end": 54, "i_start": 8, "i_end": 8}}], "id": 1492}, {"sent": "deep learning has also been incorporated as the underlying framework behind powerful generative models such as variational autoencoders and generative adversarial networks .", "tokens": ["deep", "learning", "has", "also", "been", "incorporated", "as", "the", "underlying", "framework", "behind", "powerful", "generative", "models", "such", "as", "variational", "autoencoders", "and", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "been incorporated", "start": 23, "end": 40, "i_start": 4, "i_end": 5}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has", "start": 14, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "framework", "start": 59, "end": 68, "i_start": 9, "i_end": 9}, "action": {"text": "underlying", "start": 48, "end": 58, "i_start": 8, "i_end": 8}}], "id": 1493}, {"sent": "all the convolution layers are followed by batch normalization and relu .", "tokens": ["all", "the", "convolution", "layers", "are", "followed", "by", "batch", "normalization", "and", "relu", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all the convolution layers", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "are followed", "start": 27, "end": 39, "i_start": 4, "i_end": 5}}], "id": 1494}, {"sent": "in ion , bell et al proposed to use spatial recurrent neural networks to explore contextual information across the entire image .", "tokens": ["in", "ion", ",", "bell", "et", "al", "proposed", "to", "use", "spatial", "recurrent", "neural", "networks", "to", "explore", "contextual", "information", "across", "the", "entire", "image", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bell et al", "start": 9, "end": 19, "i_start": 3, "i_end": 5}, "verb": {"text": "proposed", "start": 20, "end": 28, "i_start": 6, "i_end": 6}}, {"character": {"text": "bell", "start": 9, "end": 13, "i_start": 3, "i_end": 3}, "action": {"text": "proposed", "start": 20, "end": 28, "i_start": 6, "i_end": 6}}, {"character": {"text": "bell", "start": 9, "end": 13, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 32, "end": 35, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 61, "end": 69, "i_start": 12, "i_end": 12}, "action": {"text": "explore", "start": 73, "end": 80, "i_start": 14, "i_end": 14}}], "id": 1495}, {"sent": "string theory is a candidate for a unified quantum theory of space-time and matter .", "tokens": ["string", "theory", "is", "a", "candidate", "for", "a", "unified", "quantum", "theory", "of", "space", "-", "time", "and", "matter", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "string theory", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1496}, {"sent": "for instance , the convolutional neural network is a kind of deep learning model that is typically applied towards learning the features in the computer vision domain .", "tokens": ["for", "instance", ",", "the", "convolutional", "neural", "network", "is", "a", "kind", "of", "deep", "learning", "model", "that", "is", "typically", "applied", "towards", "learning", "the", "features", "in", "the", "computer", "vision", "domain", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the convolutional neural network", "start": 15, "end": 47, "i_start": 3, "i_end": 6}, "verb": {"text": "is", "start": 48, "end": 50, "i_start": 7, "i_end": 7}}], "id": 1497}, {"sent": "the last term is the new anomalous precession due to dgp brane effects .", "tokens": ["the", "last", "term", "is", "the", "new", "anomalous", "precession", "due", "to", "dgp", "brane", "effects", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the last term", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 3, "i_end": 3}}], "id": 1498}, {"sent": "deep neural networks have achieved great success in recent years on many applications .", "tokens": ["deep", "neural", "networks", "have", "achieved", "great", "success", "in", "recent", "years", "on", "many", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 41, "end": 48, "i_start": 6, "i_end": 6}}], "id": 1499}, {"sent": "we minimize the cross entropy loss using gradient-based optimization , with mini-batches of size 10 and the adam update rule .", "tokens": ["we", "minimize", "the", "cross", "entropy", "loss", "using", "gradient", "-", "based", "optimization", ",", "with", "mini", "-", "batches", "of", "size", "10", "and", "the", "adam", "update", "rule", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "minimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "minimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 1500}, {"sent": "in particular , non-orthogonal multiple access has been advocated as a key enabler for spectrally efficient and fair cellular communication in 5g networks .", "tokens": ["in", "particular", ",", "non", "-", "orthogonal", "multiple", "access", "has", "been", "advocated", "as", "a", "key", "enabler", "for", "spectrally", "efficient", "and", "fair", "cellular", "communication", "in", "5", "g", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "access", "start": 40, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "enabler", "start": 75, "end": 82, "i_start": 14, "i_end": 14}}], "id": 1501}, {"sent": "overfeat is one of the first single-stage detectors based on convolutional neural networks .", "tokens": ["overfeat", "is", "one", "of", "the", "first", "single", "-", "stage", "detectors", "based", "on", "convolutional", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "overfeat", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}], "id": 1502}, {"sent": "this way part of the real part of the nonperturbative amplitude , which usually includes the leading term in weak coupling expansion , can be calculated from borel resummation of the perturbation theory .", "tokens": ["this", "way", "part", "of", "the", "real", "part", "of", "the", "nonperturbative", "amplitude", ",", "which", "usually", "includes", "the", "leading", "term", "in", "weak", "coupling", "expansion", ",", "can", "be", "calculated", "from", "borel", "resummation", "of", "the", "perturbation", "theory", "."], "score": [1, 1, 1, 0, 1], "labels": [{"subject": {"text": "part of the real part of the nonperturbative amplitude", "start": 9, "end": 63, "i_start": 2, "i_end": 10}, "verb": {"text": "can be calculated", "start": 135, "end": 152, "i_start": 23, "i_end": 25}}, {"character": {"text": "term", "start": 101, "end": 105, "i_start": 17, "i_end": 17}, "action": {"text": "leading", "start": 93, "end": 100, "i_start": 16, "i_end": 16}}], "id": 1503}, {"sent": "vanishing of renormalized charge in quantum electrodynamics .", "tokens": ["vanishing", "of", "renormalized", "charge", "in", "quantum", "electrodynamics", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1504}, {"sent": "the seminal work of wyner introduced the degraded wiretap channel and the fundamental notion of secrecy capacity .", "tokens": ["the", "seminal", "work", "of", "wyner", "introduced", "the", "degraded", "wiretap", "channel", "and", "the", "fundamental", "notion", "of", "secrecy", "capacity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the seminal work of wyner", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "introduced", "start": 26, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "work", "start": 12, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 26, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "wyner", "start": 20, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "work", "start": 12, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1505}, {"sent": "the algorithm can actually be applied to a wider class of problems and it is based on representing any given instance on an exponential sized network , as first suggested in .", "tokens": ["the", "algorithm", "can", "actually", "be", "applied", "to", "a", "wider", "class", "of", "problems", "and", "it", "is", "based", "on", "representing", "any", "given", "instance", "on", "an", "exponential", "sized", "network", ",", "as", "first", "suggested", "in", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 71, "end": 73, "i_start": 13, "i_end": 13}, "verb": {"text": "be applied", "start": 27, "end": 37, "i_start": 4, "i_end": 5}}, {"subject": {"text": "the algorithm", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "can", "start": 14, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the algorithm", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "based", "start": 77, "end": 82, "i_start": 15, "i_end": 15}}], "id": 1506}, {"sent": "deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification among many others .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "already", "achieved", "tremendous", "success", "on", "a", "variety", "of", "computer", "vision", "tasks", "such", "as", "image", "classification", "among", "many", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "achieved", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 68, "end": 75, "i_start": 8, "i_end": 8}}], "id": 1507}, {"sent": "the mean squared error loss , along with the adam optimizer , was used for training .", "tokens": ["the", "mean", "squared", "error", "loss", ",", "along", "with", "the", "adam", "optimizer", ",", "was", "used", "for", "training", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the mean squared error loss", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "was used", "start": 62, "end": 70, "i_start": 12, "i_end": 13}}], "id": 1508}, {"sent": "we apply the alexnet architecture for the convnet here and concatenate the 3 f c7 outputs .", "tokens": ["we", "apply", "the", "alexnet", "architecture", "for", "the", "convnet", "here", "and", "concatenate", "the", "3", "f", "c7", "outputs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "apply", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "concatenate", "start": 59, "end": 70, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "apply", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "concatenate", "start": 59, "end": 70, "i_start": 10, "i_end": 10}}], "id": 1509}, {"sent": "hence , we use the toyota camry dataset to compare the ntp-based ids against the state-of-the-art ids in terms of estimation consistency .", "tokens": ["hence", ",", "we", "use", "the", "toyota", "camry", "dataset", "to", "compare", "the", "ntp", "-", "based", "ids", "against", "the", "state", "-", "of", "-", "the", "-", "art", "ids", "in", "terms", "of", "estimation", "consistency", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "use", "start": 11, "end": 14, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 11, "end": 14, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "compare", "start": 43, "end": 50, "i_start": 9, "i_end": 9}}], "id": 1510}, {"sent": "for instance , simulated annealing and genetic algorithms both use randomized search directions to determine their next search direction .", "tokens": ["for", "instance", ",", "simulated", "annealing", "and", "genetic", "algorithms", "both", "use", "randomized", "search", "directions", "to", "determine", "their", "next", "search", "direction", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "algorithms", "start": 47, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "use", "start": 63, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "annealing", "start": 25, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 63, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "genetic", "start": 39, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "use", "start": 63, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "both", "start": 58, "end": 62, "i_start": 8, "i_end": 8}, "action": {"text": "use", "start": 63, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "algorithms", "start": 47, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "determine", "start": 99, "end": 108, "i_start": 14, "i_end": 14}}, {"character": {"text": "annealing", "start": 25, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "determine", "start": 99, "end": 108, "i_start": 14, "i_end": 14}}, {"character": {"text": "genetic", "start": 39, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "determine", "start": 99, "end": 108, "i_start": 14, "i_end": 14}}, {"character": {"text": "both", "start": 58, "end": 62, "i_start": 8, "i_end": 8}, "action": {"text": "determine", "start": 99, "end": 108, "i_start": 14, "i_end": 14}}], "id": 1511}, {"sent": "we will discuss his point further in sections vi and viii .", "tokens": ["we", "will", "discuss", "his", "point", "further", "in", "sections", "vi", "and", "viii", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will discuss", "start": 3, "end": 15, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "discuss", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}], "id": 1512}, {"sent": "as a nucleon is a color singlet , any combination of quark or gluon field strength insertions in a nucleon state must itself be restricted to a color singlet combination .", "tokens": ["as", "a", "nucleon", "is", "a", "color", "singlet", ",", "any", "combination", "of", "quark", "or", "gluon", "field", "strength", "insertions", "in", "a", "nucleon", "state", "must", "itself", "be", "restricted", "to", "a", "color", "singlet", "combination", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "any combination of quark or gluon field strength insertions in a nucleon state must itself", "start": 34, "end": 124, "i_start": 8, "i_end": 22}, "verb": {"text": "be restricted", "start": 125, "end": 138, "i_start": 23, "i_end": 24}}, {"subject": {"text": "any combination of quark or gluon field strength insertions in a nucleon state must itself", "start": 34, "end": 124, "i_start": 8, "i_end": 22}, "verb": {"text": "must", "start": 113, "end": 117, "i_start": 21, "i_end": 21}}], "id": 1513}, {"sent": "next , let us go to the partition of \u03b3 into half-spaces .", "tokens": ["next", ",", "let", "us", "go", "to", "the", "partition", "of", "\u03b3", "into", "half", "-", "spaces", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 11, "end": 13, "i_start": 3, "i_end": 3}, "verb": {"text": "let", "start": 7, "end": 10, "i_start": 2, "i_end": 2}}, {"subject": {"text": "us", "start": 11, "end": 13, "i_start": 3, "i_end": 3}, "verb": {"text": "go", "start": 14, "end": 16, "i_start": 4, "i_end": 4}}], "id": 1514}, {"sent": "in the effective action light charged matter states arise from m2-branes wrapping suitable fibral curves .", "tokens": ["in", "the", "effective", "action", "light", "charged", "matter", "states", "arise", "from", "m2", "-", "branes", "wrapping", "suitable", "fibral", "curves", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "matter states", "start": 38, "end": 51, "i_start": 6, "i_end": 7}, "verb": {"text": "arise", "start": 52, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "branes", "start": 66, "end": 72, "i_start": 12, "i_end": 12}, "action": {"text": "wrapping", "start": 73, "end": 81, "i_start": 13, "i_end": 13}}, {"character": {"text": "action", "start": 17, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "effective", "start": 7, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1515}, {"sent": "in particular , convolutional neural network architectures have enabled superior performance over alternative approaches in classification and pattern recognition problems in computer vision .", "tokens": ["in", "particular", ",", "convolutional", "neural", "network", "architectures", "have", "enabled", "superior", "performance", "over", "alternative", "approaches", "in", "classification", "and", "pattern", "recognition", "problems", "in", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural network architectures", "start": 16, "end": 58, "i_start": 3, "i_end": 6}, "verb": {"text": "have enabled", "start": 59, "end": 71, "i_start": 7, "i_end": 8}}, {"character": {"text": "architectures", "start": 45, "end": 58, "i_start": 6, "i_end": 6}, "action": {"text": "enabled", "start": 64, "end": 71, "i_start": 8, "i_end": 8}}], "id": 1516}, {"sent": "these node embeddings have been used as features for various tasks on networks , such as node classification .", "tokens": ["these", "node", "embeddings", "have", "been", "used", "as", "features", "for", "various", "tasks", "on", "networks", ",", "such", "as", "node", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these node embeddings", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "have been used", "start": 22, "end": 36, "i_start": 3, "i_end": 5}}], "id": 1517}, {"sent": "in the smooth setting , one can allow non-zero order \u03c8dos .", "tokens": ["in", "the", "smooth", "setting", ",", "one", "can", "allow", "non", "-", "zero", "order", "\u03c8dos", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 24, "end": 27, "i_start": 5, "i_end": 5}, "verb": {"text": "can allow", "start": 28, "end": 37, "i_start": 6, "i_end": 7}}, {"character": {"text": "one", "start": 24, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "allow", "start": 32, "end": 37, "i_start": 7, "i_end": 7}}], "id": 1518}, {"sent": "this stochastic cellular automaton type of updating is not expected to affect the dynamical scaling behavior and provides a possibility for network-wise parallel algorithms .", "tokens": ["this", "stochastic", "cellular", "automaton", "type", "of", "updating", "is", "not", "expected", "to", "affect", "the", "dynamical", "scaling", "behavior", "and", "provides", "a", "possibility", "for", "network", "-", "wise", "parallel", "algorithms", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this stochastic cellular automaton type of updating", "start": 0, "end": 51, "i_start": 0, "i_end": 6}, "verb": {"text": "is not expected", "start": 52, "end": 67, "i_start": 7, "i_end": 9}}, {"subject": {"text": "this stochastic cellular automaton type of updating", "start": 0, "end": 51, "i_start": 0, "i_end": 6}, "verb": {"text": "provides", "start": 113, "end": 121, "i_start": 17, "i_end": 17}}, {"character": {"text": "updating", "start": 43, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "affect", "start": 71, "end": 77, "i_start": 11, "i_end": 11}}], "id": 1519}, {"sent": "convolutional neural networks have achieved superior performance in many visual tasks , such as object classification and detection .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "classification", "and", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 6, "i_end": 6}}], "id": 1520}, {"sent": "it is presently understood , in both the nonlinear optics and bec contexts , that the nonlinear dynamics described by gp equation is typically chaotic and often non-equilibrium .", "tokens": ["it", "is", "presently", "understood", ",", "in", "both", "the", "nonlinear", "optics", "and", "bec", "contexts", ",", "that", "the", "nonlinear", "dynamics", "described", "by", "gp", "equation", "is", "typically", "chaotic", "and", "often", "non", "-", "equilibrium", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "understood", "start": 16, "end": 26, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 130, "end": 132, "i_start": 22, "i_end": 22}}, {"character": {"text": "equation", "start": 121, "end": 129, "i_start": 21, "i_end": 21}, "action": {"text": "described", "start": 105, "end": 114, "i_start": 18, "i_end": 18}}], "id": 1521}, {"sent": "quenched qcd is a model , so the associated uncertainty is difficult to estimate .", "tokens": ["quenched", "qcd", "is", "a", "model", ",", "so", "the", "associated", "uncertainty", "is", "difficult", "to", "estimate", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the associated uncertainty", "start": 29, "end": 55, "i_start": 7, "i_end": 9}, "verb": {"text": "is", "start": 56, "end": 58, "i_start": 10, "i_end": 10}}], "id": 1522}, {"sent": "the global methodology we applied for ae-based analysis-transformation-synthesis of audio signals is in line with previous works .", "tokens": ["the", "global", "methodology", "we", "applied", "for", "ae", "-", "based", "analysis", "-", "transformation", "-", "synthesis", "of", "audio", "signals", "is", "in", "line", "with", "previous", "works", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the global methodology we applied for ae-based analysis-transformation-synthesis of audio signals", "start": 0, "end": 97, "i_start": 0, "i_end": 16}, "verb": {"text": "is", "start": 98, "end": 100, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "applied", "start": 26, "end": 33, "i_start": 4, "i_end": 4}}], "id": 1523}, {"sent": "these two states are separated by an energy shift which is nonperturbative and nonanalytic in the coupling , ie vanishing to any order in perturbation theory .", "tokens": ["these", "two", "states", "are", "separated", "by", "an", "energy", "shift", "which", "is", "nonperturbative", "and", "nonanalytic", "in", "the", "coupling", ",", "ie", "vanishing", "to", "any", "order", "in", "perturbation", "theory", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "these two states", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "are separated", "start": 17, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "shift", "start": 44, "end": 49, "i_start": 8, "i_end": 8}, "action": {"text": "separated", "start": 21, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "shift", "start": 44, "end": 49, "i_start": 8, "i_end": 8}, "action": {"text": "perturbation", "start": 138, "end": 150, "i_start": 24, "i_end": 24}}], "id": 1524}, {"sent": "over the past two decades , such a decomposition has found many applications in independent component analysis and semidefinite programming .", "tokens": ["over", "the", "past", "two", "decades", ",", "such", "a", "decomposition", "has", "found", "many", "applications", "in", "independent", "component", "analysis", "and", "semidefinite", "programming", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "such a decomposition", "start": 28, "end": 48, "i_start": 6, "i_end": 8}, "verb": {"text": "has found", "start": 49, "end": 58, "i_start": 9, "i_end": 10}}, {"character": {"text": "decomposition", "start": 35, "end": 48, "i_start": 8, "i_end": 8}, "action": {"text": "found", "start": 53, "end": 58, "i_start": 10, "i_end": 10}}, {"character": {"text": "component", "start": 92, "end": 101, "i_start": 15, "i_end": 15}, "action": {"text": "independent", "start": 80, "end": 91, "i_start": 14, "i_end": 14}}], "id": 1525}, {"sent": "minimally invasive surgery is now being widely used as one of the most preferred choices for various types of operations .", "tokens": ["minimally", "invasive", "surgery", "is", "now", "being", "widely", "used", "as", "one", "of", "the", "most", "preferred", "choices", "for", "various", "types", "of", "operations", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "minimally invasive surgery", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 47, "end": 51, "i_start": 7, "i_end": 7}}, {"subject": {"text": "minimally invasive surgery", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 3, "i_end": 3}}, {"subject": {"text": "minimally invasive surgery", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "being", "start": 34, "end": 39, "i_start": 5, "i_end": 5}}], "id": 1526}, {"sent": "jaynes , in physics and probability , edited by w .", "tokens": ["jaynes", ",", "in", "physics", "and", "probability", ",", "edited", "by", "w", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "jaynes", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "edited", "start": 38, "end": 44, "i_start": 7, "i_end": 7}}], "id": 1527}, {"sent": "no apparent mr is seen in normal state ie above tc onset .", "tokens": ["no", "apparent", "mr", "is", "seen", "in", "normal", "state", "ie", "above", "tc", "onset", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "mr", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "is seen", "start": 15, "end": 22, "i_start": 3, "i_end": 4}}], "id": 1528}, {"sent": "an invariant measure is called ergodic if .", "tokens": ["an", "invariant", "measure", "is", "called", "ergodic", "if", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an invariant measure", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}], "id": 1529}, {"sent": "standard calibration techniques were employed using the miriad software .", "tokens": ["standard", "calibration", "techniques", "were", "employed", "using", "the", "miriad", "software", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "standard calibration techniques", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "were employed", "start": 32, "end": 45, "i_start": 3, "i_end": 4}}], "id": 1530}, {"sent": "it is well understood that if both fields get very large values the concurrence is zero .", "tokens": ["it", "is", "well", "understood", "that", "if", "both", "fields", "get", "very", "large", "values", "the", "concurrence", "is", "zero", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "understood", "start": 11, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 80, "end": 82, "i_start": 14, "i_end": 14}}, {"character": {"text": "fields", "start": 35, "end": 41, "i_start": 7, "i_end": 7}, "action": {"text": "get", "start": 42, "end": 45, "i_start": 8, "i_end": 8}}], "id": 1531}, {"sent": "using the derived formula , we estimate the .", "tokens": ["using", "the", "derived", "formula", ",", "we", "estimate", "the", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 28, "end": 30, "i_start": 5, "i_end": 5}, "verb": {"text": "estimate", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 28, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "estimate", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 28, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "using", "start": 0, "end": 5, "i_start": 0, "i_end": 0}}], "id": 1532}, {"sent": "in , only the most frequent words in the training set were used as output targets whereas the remaining words were lumped together as oovs .", "tokens": ["in", ",", "only", "the", "most", "frequent", "words", "in", "the", "training", "set", "were", "used", "as", "output", "targets", "whereas", "the", "remaining", "words", "were", "lumped", "together", "as", "oovs", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "only the most frequent words in the training set", "start": 5, "end": 53, "i_start": 2, "i_end": 10}, "verb": {"text": "were used", "start": 54, "end": 63, "i_start": 11, "i_end": 12}}], "id": 1533}, {"sent": "this energy scale is the natural one for spin waves in a system of antiferromagnetically ordered spins residing in the vortex cores of the superconductor .", "tokens": ["this", "energy", "scale", "is", "the", "natural", "one", "for", "spin", "waves", "in", "a", "system", "of", "antiferromagnetically", "ordered", "spins", "residing", "in", "the", "vortex", "cores", "of", "the", "superconductor", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this energy scale", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "spins", "start": 97, "end": 102, "i_start": 16, "i_end": 16}, "action": {"text": "residing", "start": 103, "end": 111, "i_start": 17, "i_end": 17}}], "id": 1534}, {"sent": "ramanathan , multicones over schubert varieties , invent .", "tokens": ["ramanathan", ",", "multicones", "over", "schubert", "varieties", ",", "invent", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "ramanathan", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "verb": {"text": "invent", "start": 50, "end": 56, "i_start": 7, "i_end": 7}}, {"character": {"text": "ramanathan", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "invent", "start": 50, "end": 56, "i_start": 7, "i_end": 7}}], "id": 1535}, {"sent": "fan and li and fan and peng further prove the oracle properties of penalized likelihood estimators under some additional regularity conditions .", "tokens": ["fan", "and", "li", "and", "fan", "and", "peng", "further", "prove", "the", "oracle", "properties", "of", "penalized", "likelihood", "estimators", "under", "some", "additional", "regularity", "conditions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "fan and li and fan and peng", "start": 0, "end": 27, "i_start": 0, "i_end": 6}, "verb": {"text": "prove", "start": 36, "end": 41, "i_start": 8, "i_end": 8}}, {"character": {"text": "fan", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "prove", "start": 36, "end": 41, "i_start": 8, "i_end": 8}}, {"character": {"text": "li", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "prove", "start": 36, "end": 41, "i_start": 8, "i_end": 8}}, {"character": {"text": "fan", "start": 15, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "prove", "start": 36, "end": 41, "i_start": 8, "i_end": 8}}, {"character": {"text": "peng", "start": 23, "end": 27, "i_start": 6, "i_end": 6}, "action": {"text": "prove", "start": 36, "end": 41, "i_start": 8, "i_end": 8}}], "id": 1536}, {"sent": "a lamination of m 3 is a disjoint union of surfaces which are locally homeomorphic to the product of d2 and a closed subset of i .", "tokens": ["a", "lamination", "of", "m", "3", "is", "a", "disjoint", "union", "of", "surfaces", "which", "are", "locally", "homeomorphic", "to", "the", "product", "of", "d2", "and", "a", "closed", "subset", "of", "i", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a lamination of m 3", "start": 0, "end": 19, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 5, "i_end": 5}}], "id": 1537}, {"sent": "recently , millimeter-wave communication has gained considerable attention as a candidate technology for 5g mobile communication systems and beyond .", "tokens": ["recently", ",", "millimeter", "-", "wave", "communication", "has", "gained", "considerable", "attention", "as", "a", "candidate", "technology", "for", "5", "g", "mobile", "communication", "systems", "and", "beyond", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "millimeter-wave communication", "start": 11, "end": 40, "i_start": 2, "i_end": 5}, "verb": {"text": "has gained", "start": 41, "end": 51, "i_start": 6, "i_end": 7}}, {"character": {"text": "communication", "start": 27, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "gained", "start": 45, "end": 51, "i_start": 7, "i_end": 7}}], "id": 1538}, {"sent": "next , we consider the ground state problem for .", "tokens": ["next", ",", "we", "consider", "the", "ground", "state", "problem", "for", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "consider", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "consider", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}], "id": 1539}, {"sent": "following each convolutional layer is a batch normalization layer and a rectified linear unit .", "tokens": ["following", "each", "convolutional", "layer", "is", "a", "batch", "normalization", "layer", "and", "a", "rectified", "linear", "unit", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "following each convolutional layer", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "layer", "start": 29, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "normalization", "start": 46, "end": 59, "i_start": 7, "i_end": 7}}], "id": 1540}, {"sent": "related ideas are pursued by ma et al and , who add terms to their models enforcing homophily between friends with regard to their preferences .", "tokens": ["related", "ideas", "are", "pursued", "by", "ma", "et", "al", "and", ",", "who", "add", "terms", "to", "their", "models", "enforcing", "homophily", "between", "friends", "with", "regard", "to", "their", "preferences", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "related ideas are pursued by ma et al and , who add terms to their models enforcing homophily between friends with regard to their preferences", "start": 0, "end": 142, "i_start": 0, "i_end": 24}, "verb": {"text": "are pursued", "start": 14, "end": 25, "i_start": 2, "i_end": 3}}, {"character": {"text": "ma", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "pursued", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "add", "start": 48, "end": 51, "i_start": 11, "i_end": 11}, "action": {"text": "pursued", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "between", "start": 94, "end": 101, "i_start": 18, "i_end": 18}, "action": {"text": "pursued", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "ma", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "add", "start": 48, "end": 51, "i_start": 11, "i_end": 11}}, {"character": {"text": "add", "start": 48, "end": 51, "i_start": 11, "i_end": 11}, "action": {"text": "add", "start": 48, "end": 51, "i_start": 11, "i_end": 11}}, {"character": {"text": "between", "start": 94, "end": 101, "i_start": 18, "i_end": 18}, "action": {"text": "add", "start": 48, "end": 51, "i_start": 11, "i_end": 11}}, {"character": {"text": "ma", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "models", "start": 67, "end": 73, "i_start": 15, "i_end": 15}}, {"character": {"text": "add", "start": 48, "end": 51, "i_start": 11, "i_end": 11}, "action": {"text": "models", "start": 67, "end": 73, "i_start": 15, "i_end": 15}}, {"character": {"text": "between", "start": 94, "end": 101, "i_start": 18, "i_end": 18}, "action": {"text": "models", "start": 67, "end": 73, "i_start": 15, "i_end": 15}}, {"character": {"text": "models", "start": 67, "end": 73, "i_start": 15, "i_end": 15}, "action": {"text": "enforcing", "start": 74, "end": 83, "i_start": 16, "i_end": 16}}, {"character": {"text": "ma", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "preferences", "start": 131, "end": 142, "i_start": 24, "i_end": 24}}, {"character": {"text": "add", "start": 48, "end": 51, "i_start": 11, "i_end": 11}, "action": {"text": "preferences", "start": 131, "end": 142, "i_start": 24, "i_end": 24}}, {"character": {"text": "between", "start": 94, "end": 101, "i_start": 18, "i_end": 18}, "action": {"text": "preferences", "start": 131, "end": 142, "i_start": 24, "i_end": 24}}], "id": 1541}, {"sent": "now we shall use more realistic monodisperse approximation .", "tokens": ["now", "we", "shall", "use", "more", "realistic", "monodisperse", "approximation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "shall use", "start": 7, "end": 16, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "use", "start": 13, "end": 16, "i_start": 3, "i_end": 3}}], "id": 1542}, {"sent": "differential privacy is an appealing privacy notion which provides worst-case privacy guarantees .", "tokens": ["differential", "privacy", "is", "an", "appealing", "privacy", "notion", "which", "provides", "worst", "-", "case", "privacy", "guarantees", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "differential privacy", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "notion", "start": 45, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "appealing", "start": 27, "end": 36, "i_start": 4, "i_end": 4}}, {"character": {"text": "notion", "start": 45, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "provides", "start": 58, "end": 66, "i_start": 8, "i_end": 8}}], "id": 1543}, {"sent": "recently , dramatic success has been made through big data supervised deep neural network approaches which advance prediction accuracy of visual recognition significantly .", "tokens": ["recently", ",", "dramatic", "success", "has", "been", "made", "through", "big", "data", "supervised", "deep", "neural", "network", "approaches", "which", "advance", "prediction", "accuracy", "of", "visual", "recognition", "significantly", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dramatic success", "start": 11, "end": 27, "i_start": 2, "i_end": 3}, "verb": {"text": "has been made", "start": 28, "end": 41, "i_start": 4, "i_end": 6}}, {"character": {"text": "data", "start": 54, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "supervised", "start": 59, "end": 69, "i_start": 10, "i_end": 10}}, {"character": {"text": "approaches", "start": 90, "end": 100, "i_start": 14, "i_end": 14}, "action": {"text": "advance", "start": 107, "end": 114, "i_start": 16, "i_end": 16}}], "id": 1544}, {"sent": "while the deuteron is a very dilute system , the 4he nucleus is the nucleus with largest density .", "tokens": ["while", "the", "deuteron", "is", "a", "very", "dilute", "system", ",", "the", "4he", "nucleus", "is", "the", "nucleus", "with", "largest", "density", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the 4he nucleus", "start": 45, "end": 60, "i_start": 9, "i_end": 11}, "verb": {"text": "is", "start": 61, "end": 63, "i_start": 12, "i_end": 12}}], "id": 1545}, {"sent": "however , the convergence result of baouendi-ebenfelt-rothschild implies that all formal invertible transformations within the class of real-analytic finite type hypersurfaces are convergent .", "tokens": ["however", ",", "the", "convergence", "result", "of", "baouendi", "-", "ebenfelt", "-", "rothschild", "implies", "that", "all", "formal", "invertible", "transformations", "within", "the", "class", "of", "real", "-", "analytic", "finite", "type", "hypersurfaces", "are", "convergent", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the convergence result of baouendi-ebenfelt-rothschild", "start": 10, "end": 64, "i_start": 2, "i_end": 10}, "verb": {"text": "implies", "start": 65, "end": 72, "i_start": 11, "i_end": 11}}, {"subject": {"text": "the convergence result of baouendi-ebenfelt-rothschild", "start": 10, "end": 64, "i_start": 2, "i_end": 10}, "verb": {"text": "are", "start": 176, "end": 179, "i_start": 27, "i_end": 27}}, {"character": {"text": "result", "start": 26, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "implies", "start": 65, "end": 72, "i_start": 11, "i_end": 11}}], "id": 1546}, {"sent": "the fast solar wind is a collisionless plasma permeated by plasma waves on many different scales .", "tokens": ["the", "fast", "solar", "wind", "is", "a", "collisionless", "plasma", "permeated", "by", "plasma", "waves", "on", "many", "different", "scales", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the fast solar wind", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 4, "i_end": 4}}, {"character": {"text": "waves", "start": 66, "end": 71, "i_start": 11, "i_end": 11}, "action": {"text": "permeated", "start": 46, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "plasma", "start": 39, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "collisionless", "start": 25, "end": 38, "i_start": 6, "i_end": 6}}], "id": 1547}, {"sent": "first-principles calculations were performed using the vienna ab initio package with the projector augmented wave method 34 , 35 .", "tokens": ["first", "-", "principles", "calculations", "were", "performed", "using", "the", "vienna", "ab", "initio", "package", "with", "the", "projector", "augmented", "wave", "method", "34", ",", "35", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "first-principles calculations", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "were performed", "start": 30, "end": 44, "i_start": 4, "i_end": 5}}], "id": 1548}, {"sent": "the interest started with the seminal paper by lebowitz , rose and speer among others .", "tokens": ["the", "interest", "started", "with", "the", "seminal", "paper", "by", "lebowitz", ",", "rose", "and", "speer", "among", "others", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the interest", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "started", "start": 13, "end": 20, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the interest", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "rose", "start": 58, "end": 62, "i_start": 10, "i_end": 10}}], "id": 1549}, {"sent": "we implemented our architecture in pytorch inside the opennmtpy toolkit .", "tokens": ["we", "implemented", "our", "architecture", "in", "pytorch", "inside", "the", "opennmtpy", "toolkit", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implemented", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implemented", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}], "id": 1550}, {"sent": "in order to train the cnn model , we employ the adam optimizer , a commonly used type of stochastic gradient descent .", "tokens": ["in", "order", "to", "train", "the", "cnn", "model", ",", "we", "employ", "the", "adam", "optimizer", ",", "a", "commonly", "used", "type", "of", "stochastic", "gradient", "descent", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 34, "end": 36, "i_start": 8, "i_end": 8}, "verb": {"text": "employ", "start": 37, "end": 43, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 8, "i_end": 8}, "action": {"text": "employ", "start": 37, "end": 43, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 8, "i_end": 8}, "action": {"text": "train", "start": 12, "end": 17, "i_start": 3, "i_end": 3}}], "id": 1551}, {"sent": "in a previous paper we have shown that , given an integrable real function on the unit circle , one can define from it a unique inner analytic function whose real part reproduces that real function when restricted to the unit circle .", "tokens": ["in", "a", "previous", "paper", "we", "have", "shown", "that", ",", "given", "an", "integrable", "real", "function", "on", "the", "unit", "circle", ",", "one", "can", "define", "from", "it", "a", "unique", "inner", "analytic", "function", "whose", "real", "part", "reproduces", "that", "real", "function", "when", "restricted", "to", "the", "unit", "circle", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 20, "end": 22, "i_start": 4, "i_end": 4}, "verb": {"text": "have shown", "start": 23, "end": 33, "i_start": 5, "i_end": 6}}, {"subject": {"text": "one", "start": 96, "end": 99, "i_start": 19, "i_end": 19}, "verb": {"text": "define", "start": 104, "end": 110, "i_start": 21, "i_end": 21}}, {"character": {"text": "we", "start": 20, "end": 22, "i_start": 4, "i_end": 4}, "action": {"text": "shown", "start": 28, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "one", "start": 96, "end": 99, "i_start": 19, "i_end": 19}, "action": {"text": "define", "start": 104, "end": 110, "i_start": 21, "i_end": 21}}, {"character": {"text": "part", "start": 163, "end": 167, "i_start": 31, "i_end": 31}, "action": {"text": "reproduces", "start": 168, "end": 178, "i_start": 32, "i_end": 32}}], "id": 1552}, {"sent": "we choose a keyword extraction framework known as textrank .", "tokens": ["we", "choose", "a", "keyword", "extraction", "framework", "known", "as", "textrank", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "choose", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "choose", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 1553}, {"sent": "since the supergravity background of also has this symmetry , it is natural to identify the dual of this background with the baryonic branch of the cascading theory .", "tokens": ["since", "the", "supergravity", "background", "of", "also", "has", "this", "symmetry", ",", "it", "is", "natural", "to", "identify", "the", "dual", "of", "this", "background", "with", "the", "baryonic", "branch", "of", "the", "cascading", "theory", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 62, "end": 64, "i_start": 10, "i_end": 10}, "verb": {"text": "is", "start": 65, "end": 67, "i_start": 11, "i_end": 11}}], "id": 1554}, {"sent": "this similarity is a universal result of the density-functional theory .", "tokens": ["this", "similarity", "is", "a", "universal", "result", "of", "the", "density", "-", "functional", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this similarity", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 1555}, {"sent": "in the recent years , deep convolutional networks have achieved remarkable results in a wide array of computer vision tasks .", "tokens": ["in", "the", "recent", "years", ",", "deep", "convolutional", "networks", "have", "achieved", "remarkable", "results", "in", "a", "wide", "array", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional networks", "start": 22, "end": 49, "i_start": 5, "i_end": 7}, "verb": {"text": "have achieved", "start": 50, "end": 63, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 41, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 55, "end": 63, "i_start": 9, "i_end": 9}}], "id": 1556}, {"sent": "an example is tora , or temporally ordered routing algorithm .", "tokens": ["an", "example", "is", "tora", ",", "or", "temporally", "ordered", "routing", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an example", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}, {"subject": {"text": "an example", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "ordered", "start": 35, "end": 42, "i_start": 7, "i_end": 7}}], "id": 1557}, {"sent": "let p be a regular end of a complete flat front .", "tokens": ["let", "p", "be", "a", "regular", "end", "of", "a", "complete", "flat", "front", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "p", "start": 4, "end": 5, "i_start": 1, "i_end": 1}, "action": {"text": "end", "start": 19, "end": 22, "i_start": 5, "i_end": 5}}], "id": 1558}, {"sent": "this dataset consists of 100 subset classes of imagenet , with 600 images per class .", "tokens": ["this", "dataset", "consists", "of", "100", "subset", "classes", "of", "imagenet", ",", "with", "600", "images", "per", "class", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this dataset", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 13, "end": 21, "i_start": 2, "i_end": 2}}], "id": 1559}, {"sent": "this technique was introduced by rudin , osher , and fatemi in the seminal paper for the denoising of digital images , leading to a broad literature on variational methods over functions of bounded variations .", "tokens": ["this", "technique", "was", "introduced", "by", "rudin", ",", "osher", ",", "and", "fatemi", "in", "the", "seminal", "paper", "for", "the", "denoising", "of", "digital", "images", ",", "leading", "to", "a", "broad", "literature", "on", "variational", "methods", "over", "functions", "of", "bounded", "variations", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this technique", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "was introduced", "start": 15, "end": 29, "i_start": 2, "i_end": 3}}, {"character": {"text": "rudin", "start": 33, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 19, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "osher", "start": 41, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "introduced", "start": 19, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "fatemi", "start": 53, "end": 59, "i_start": 10, "i_end": 10}, "action": {"text": "introduced", "start": 19, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "introduced", "start": 19, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "leading", "start": 119, "end": 126, "i_start": 22, "i_end": 22}}], "id": 1560}, {"sent": "maximum matching and minimum vertex cover are among the most studied problems in the context of massive graphs including in mpc model and mapreduce-style computation .", "tokens": ["maximum", "matching", "and", "minimum", "vertex", "cover", "are", "among", "the", "most", "studied", "problems", "in", "the", "context", "of", "massive", "graphs", "including", "in", "mpc", "model", "and", "mapreduce", "-", "style", "computation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "maximum matching and minimum vertex cover", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 42, "end": 45, "i_start": 6, "i_end": 6}}], "id": 1561}, {"sent": "the integer deg is is covered when all the points in also called winding number .", "tokens": ["the", "integer", "deg", "is", "is", "covered", "when", "all", "the", "points", "in", "also", "called", "winding", "number", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1562}, {"sent": "the potential of convolutional neural networks on images was demonstrated with its success in the imagenet classification task .", "tokens": ["the", "potential", "of", "convolutional", "neural", "networks", "on", "images", "was", "demonstrated", "with", "its", "success", "in", "the", "imagenet", "classification", "task", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the potential of convolutional neural networks on images", "start": 0, "end": 56, "i_start": 0, "i_end": 7}, "verb": {"text": "was demonstrated", "start": 57, "end": 73, "i_start": 8, "i_end": 9}}, {"character": {"text": "success", "start": 83, "end": 90, "i_start": 12, "i_end": 12}, "action": {"text": "demonstrated", "start": 61, "end": 73, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 38, "end": 46, "i_start": 5, "i_end": 5}, "action": {"text": "success", "start": 83, "end": 90, "i_start": 12, "i_end": 12}}], "id": 1563}, {"sent": "for hypermultiplets , the supersymmetry transformation rules and the fermion-terms in the lagrangian are known in general .", "tokens": ["for", "hypermultiplets", ",", "the", "supersymmetry", "transformation", "rules", "and", "the", "fermion", "-", "terms", "in", "the", "lagrangian", "are", "known", "in", "general", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the supersymmetry transformation rules and the fermion-terms in the lagrangian", "start": 22, "end": 100, "i_start": 3, "i_end": 14}, "verb": {"text": "are known", "start": 101, "end": 110, "i_start": 15, "i_end": 16}}], "id": 1564}, {"sent": "ellipses denote 1 point 5\u03c3 confidence contours .", "tokens": ["ellipses", "denote", "1", "point", "5\u03c3", "confidence", "contours", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "ellipses", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "denote", "start": 9, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "ellipses", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 9, "end": 15, "i_start": 1, "i_end": 1}}], "id": 1565}, {"sent": "shows the corner area with the walls only on the left and the bottom of the image .", "tokens": ["shows", "the", "corner", "area", "with", "the", "walls", "only", "on", "the", "left", "and", "the", "bottom", "of", "the", "image", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1566}, {"sent": "success of convolutional neural networks over the past several years has lead to their extensive deployment in a wide range of computer vision tasks .", "tokens": ["success", "of", "convolutional", "neural", "networks", "over", "the", "past", "several", "years", "has", "lead", "to", "their", "extensive", "deployment", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "success of convolutional neural networks over the past several years", "start": 0, "end": 68, "i_start": 0, "i_end": 9}, "verb": {"text": "has lead", "start": 69, "end": 77, "i_start": 10, "i_end": 11}}, {"character": {"text": "success", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "lead", "start": 73, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "success", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}], "id": 1567}, {"sent": "model-based clustering is a well-established method for cluster analysis and unsupervised learning .", "tokens": ["model", "-", "based", "clustering", "is", "a", "well", "-", "established", "method", "for", "cluster", "analysis", "and", "unsupervised", "learning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "model-based clustering", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 4, "i_end": 4}}], "id": 1568}, {"sent": "an exciton consists of a pair of an electron and a hole inside a semiconductor , which are bound together by their mutual coulomb atin electraction , forming a boson-like quasi particle .", "tokens": ["an", "exciton", "consists", "of", "a", "pair", "of", "an", "electron", "and", "a", "hole", "inside", "a", "semiconductor", ",", "which", "are", "bound", "together", "by", "their", "mutual", "coulomb", "atin", "electraction", ",", "forming", "a", "boson", "-", "like", "quasi", "particle", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an exciton", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "bound", "start": 91, "end": 96, "i_start": 18, "i_end": 18}, "action": {"text": "forming", "start": 150, "end": 157, "i_start": 27, "i_end": 27}}], "id": 1569}, {"sent": "batch renormalization has shown to improve trainability of very deep networks .", "tokens": ["batch", "renormalization", "has", "shown", "to", "improve", "trainability", "of", "very", "deep", "networks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "batch renormalization", "start": 0, "end": 21, "i_start": 0, "i_end": 1}, "verb": {"text": "has shown", "start": 22, "end": 31, "i_start": 2, "i_end": 3}}, {"character": {"text": "renormalization", "start": 6, "end": 21, "i_start": 1, "i_end": 1}, "action": {"text": "improve", "start": 35, "end": 42, "i_start": 5, "i_end": 5}}], "id": 1570}, {"sent": "then we extend two irl 1 methods proposed in to solve , and the resulting irsvm methods per iteration solve a weighted singular value minimization subproblem which has a closedform solution .", "tokens": ["then", "we", "extend", "two", "irl", "1", "methods", "proposed", "in", "to", "solve", ",", "and", "the", "resulting", "irsvm", "methods", "per", "iteration", "solve", "a", "weighted", "singular", "value", "minimization", "subproblem", "which", "has", "a", "closedform", "solution", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "extend", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the resulting irsvm methods per iteration", "start": 60, "end": 101, "i_start": 13, "i_end": 18}, "verb": {"text": "solve", "start": 102, "end": 107, "i_start": 19, "i_end": 19}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "extend", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "two irl 1 methods", "start": 15, "end": 32, "i_start": 3, "i_end": 6}, "action": {"text": "solve", "start": 48, "end": 53, "i_start": 10, "i_end": 10}}, {"character": {"text": "methods", "start": 80, "end": 87, "i_start": 16, "i_end": 16}, "action": {"text": "solve", "start": 102, "end": 107, "i_start": 19, "i_end": 19}}, {"character": {"text": "subproblem", "start": 147, "end": 157, "i_start": 25, "i_end": 25}, "action": {"text": "has", "start": 164, "end": 167, "i_start": 27, "i_end": 27}}], "id": 1571}, {"sent": "algorithms like cbsc by jain and murthy are invariant to distance preserving transform on a conceptual level but as with other density based methods , actual outcome depends on selected parameters .", "tokens": ["algorithms", "like", "cbsc", "by", "jain", "and", "murthy", "are", "invariant", "to", "distance", "preserving", "transform", "on", "a", "conceptual", "level", "but", "as", "with", "other", "density", "based", "methods", ",", "actual", "outcome", "depends", "on", "selected", "parameters", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "algorithms like cbsc by jain and murthy", "start": 0, "end": 39, "i_start": 0, "i_end": 6}, "verb": {"text": "are", "start": 40, "end": 43, "i_start": 7, "i_end": 7}}, {"subject": {"text": "actual outcome", "start": 151, "end": 165, "i_start": 25, "i_end": 26}, "verb": {"text": "depends", "start": 166, "end": 173, "i_start": 27, "i_end": 27}}], "id": 1572}, {"sent": "field , phenix collaboration , in this proceedings .", "tokens": ["field", ",", "phenix", "collaboration", ",", "in", "this", "proceedings", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1573}, {"sent": "the fuzzy-ga hybridization was implemented by the authors onto two levels .", "tokens": ["the", "fuzzy", "-", "ga", "hybridization", "was", "implemented", "by", "the", "authors", "onto", "two", "levels", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the fuzzy-ga hybridization", "start": 0, "end": 26, "i_start": 0, "i_end": 4}, "verb": {"text": "was implemented", "start": 27, "end": 42, "i_start": 5, "i_end": 6}}], "id": 1574}, {"sent": "on em algorithms and their proximal generalizations .", "tokens": ["on", "em", "algorithms", "and", "their", "proximal", "generalizations", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1575}, {"sent": "and , bohmian mechanics is the best way to make sense out of quantum mechanics .", "tokens": ["and", ",", "bohmian", "mechanics", "is", "the", "best", "way", "to", "make", "sense", "out", "of", "quantum", "mechanics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "bohmian mechanics", "start": 6, "end": 23, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 4, "i_end": 4}}], "id": 1576}, {"sent": "tzeng et al proposed a unified framework for unsupervised domain adaptation based on adversarial learning objectives .", "tokens": ["tzeng", "et", "al", "proposed", "a", "unified", "framework", "for", "unsupervised", "domain", "adaptation", "based", "on", "adversarial", "learning", "objectives", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "tzeng et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "tzeng", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}], "id": 1577}, {"sent": "moreover , all the groups and equations which occur above can be found effectively .", "tokens": ["moreover", ",", "all", "the", "groups", "and", "equations", "which", "occur", "above", "can", "be", "found", "effectively", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all the groups and equations which occur above", "start": 11, "end": 57, "i_start": 2, "i_end": 9}, "verb": {"text": "can be found", "start": 58, "end": 70, "i_start": 10, "i_end": 12}}], "id": 1578}, {"sent": "our analysis and calculation are performed on the noncommutative phase space straightforwardly , without depending on any variables on the commutative space .", "tokens": ["our", "analysis", "and", "calculation", "are", "performed", "on", "the", "noncommutative", "phase", "space", "straightforwardly", ",", "without", "depending", "on", "any", "variables", "on", "the", "commutative", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our analysis and calculation", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "are performed", "start": 29, "end": 42, "i_start": 4, "i_end": 5}}, {"character": {"text": "performed", "start": 33, "end": 42, "i_start": 5, "i_end": 5}, "action": {"text": "depending", "start": 105, "end": 114, "i_start": 14, "i_end": 14}}], "id": 1579}, {"sent": "it is analogous to the density imbalance measured in experiments with cold atoms .", "tokens": ["it", "is", "analogous", "to", "the", "density", "imbalance", "measured", "in", "experiments", "with", "cold", "atoms", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"character": {"text": "experiments", "start": 53, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "measured", "start": 41, "end": 49, "i_start": 7, "i_end": 7}}], "id": 1580}, {"sent": "all the models are trained for 20 epochs with a batch size of 1 using adam with default beta parameters .", "tokens": ["all", "the", "models", "are", "trained", "for", "20", "epochs", "with", "a", "batch", "size", "of", "1", "using", "adam", "with", "default", "beta", "parameters", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all the models", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "are trained", "start": 15, "end": 26, "i_start": 3, "i_end": 4}}], "id": 1581}, {"sent": "we have shown , in our isca 2014 paper , the existence of disturbance errors in commodity dram chips that are sold and used in the field .", "tokens": ["we", "have", "shown", ",", "in", "our", "isca", "2014", "paper", ",", "the", "existence", "of", "disturbance", "errors", "in", "commodity", "dram", "chips", "that", "are", "sold", "and", "used", "in", "the", "field", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have shown", "start": 3, "end": 13, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "shown", "start": 8, "end": 13, "i_start": 2, "i_end": 2}}], "id": 1582}, {"sent": "instead , we formulate a variational approximation following ideas from .", "tokens": ["instead", ",", "we", "formulate", "a", "variational", "approximation", "following", "ideas", "from", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "formulate", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "formulate", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}], "id": 1583}, {"sent": "this allowed an impressive improvement in the performance of image classification approaches and many others computer vision problems .", "tokens": ["this", "allowed", "an", "impressive", "improvement", "in", "the", "performance", "of", "image", "classification", "approaches", "and", "many", "others", "computer", "vision", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "allowed", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "allowed", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "improvement", "start": 27, "end": 38, "i_start": 4, "i_end": 4}, "action": {"text": "impressive", "start": 16, "end": 26, "i_start": 3, "i_end": 3}}], "id": 1584}, {"sent": "so , we expect that string theory is the best of candidates for consistent quantum gravity theory since string theory is free of the ultraviolet divergences .", "tokens": ["so", ",", "we", "expect", "that", "string", "theory", "is", "the", "best", "of", "candidates", "for", "consistent", "quantum", "gravity", "theory", "since", "string", "theory", "is", "free", "of", "the", "ultraviolet", "divergences", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "verb": {"text": "expect", "start": 8, "end": 14, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "action": {"text": "expect", "start": 8, "end": 14, "i_start": 3, "i_end": 3}}], "id": 1585}, {"sent": "in another approach , convolutional neural networks were employed for background subtraction by braham and droogenbroeck .", "tokens": ["in", "another", "approach", ",", "convolutional", "neural", "networks", "were", "employed", "for", "background", "subtraction", "by", "braham", "and", "droogenbroeck", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 22, "end": 51, "i_start": 4, "i_end": 6}, "verb": {"text": "were employed", "start": 52, "end": 65, "i_start": 7, "i_end": 8}}, {"character": {"text": "braham", "start": 96, "end": 102, "i_start": 13, "i_end": 13}, "action": {"text": "employed", "start": 57, "end": 65, "i_start": 8, "i_end": 8}}, {"character": {"text": "droogenbroeck", "start": 107, "end": 120, "i_start": 15, "i_end": 15}, "action": {"text": "employed", "start": 57, "end": 65, "i_start": 8, "i_end": 8}}], "id": 1586}, {"sent": "the minimization of the objective function f is carried out using the simplex method .", "tokens": ["the", "minimization", "of", "the", "objective", "function", "f", "is", "carried", "out", "using", "the", "simplex", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the minimization of the objective function f", "start": 0, "end": 44, "i_start": 0, "i_end": 6}, "verb": {"text": "is carried out", "start": 45, "end": 59, "i_start": 7, "i_end": 9}}], "id": 1587}, {"sent": "ma et al took full advantages of features from different cnn layers and used an adaptive hedge method to hedge several cnn trackers into a stronger one .", "tokens": ["ma", "et", "al", "took", "full", "advantages", "of", "features", "from", "different", "cnn", "layers", "and", "used", "an", "adaptive", "hedge", "method", "to", "hedge", "several", "cnn", "trackers", "into", "a", "stronger", "one", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "ma et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "took", "start": 9, "end": 13, "i_start": 3, "i_end": 3}}, {"subject": {"text": "ma et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 72, "end": 76, "i_start": 13, "i_end": 13}}, {"character": {"text": "ma", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "took", "start": 9, "end": 13, "i_start": 3, "i_end": 3}}], "id": 1588}, {"sent": "generalized gradient approximation with the perdew , burke and ernzerhof exchange correlation functional is used for estimating the exchange correlation energy .", "tokens": ["generalized", "gradient", "approximation", "with", "the", "perdew", ",", "burke", "and", "ernzerhof", "exchange", "correlation", "functional", "is", "used", "for", "estimating", "the", "exchange", "correlation", "energy", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "generalized gradient approximation with the perdew", "start": 0, "end": 50, "i_start": 0, "i_end": 5}, "verb": {"text": "is used", "start": 105, "end": 112, "i_start": 13, "i_end": 14}}], "id": 1589}, {"sent": "a hopf algebra is a bialgebra h with an antipode s .", "tokens": ["a", "hopf", "algebra", "is", "a", "bialgebra", "h", "with", "an", "antipode", "s", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a hopf algebra", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}], "id": 1590}, {"sent": "generalized gradient approximation of perdew-burke-ernzehrof as well as hybrid functionals are used to include exchangecorrelations .", "tokens": ["generalized", "gradient", "approximation", "of", "perdew", "-", "burke", "-", "ernzehrof", "as", "well", "as", "hybrid", "functionals", "are", "used", "to", "include", "exchangecorrelations", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "generalized gradient approximation of perdew-burke-ernzehrof as well as hybrid functionals", "start": 0, "end": 90, "i_start": 0, "i_end": 13}, "verb": {"text": "are used", "start": 91, "end": 99, "i_start": 14, "i_end": 15}}], "id": 1591}, {"sent": "the kuramoto model is a mean-field model of coupled oscillators , proposed by kuramoto to describe synchronization phenomena .", "tokens": ["the", "kuramoto", "model", "is", "a", "mean", "-", "field", "model", "of", "coupled", "oscillators", ",", "proposed", "by", "kuramoto", "to", "describe", "synchronization", "phenomena", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the kuramoto model", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "field", "start": 29, "end": 34, "i_start": 7, "i_end": 7}, "action": {"text": "mean", "start": 24, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "kuramoto", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "proposed", "start": 66, "end": 74, "i_start": 13, "i_end": 13}}, {"character": {"text": "kuramoto", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "describe", "start": 90, "end": 98, "i_start": 17, "i_end": 17}}], "id": 1592}, {"sent": "we have also demonstrated that a very simple user-level program can reliably and consistently induce rowhammer errors in three commodity amd and intel systems using vulnerable dram modules .", "tokens": ["we", "have", "also", "demonstrated", "that", "a", "very", "simple", "user", "-", "level", "program", "can", "reliably", "and", "consistently", "induce", "rowhammer", "errors", "in", "three", "commodity", "amd", "and", "intel", "systems", "using", "vulnerable", "dram", "modules", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a very simple user-level program", "start": 31, "end": 63, "i_start": 5, "i_end": 11}, "verb": {"text": "demonstrated", "start": 13, "end": 25, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "induce", "start": 94, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "demonstrated", "start": 13, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "program", "start": 56, "end": 63, "i_start": 11, "i_end": 11}, "action": {"text": "induce", "start": 94, "end": 100, "i_start": 16, "i_end": 16}}], "id": 1593}, {"sent": "for the fcn-8 , we make use of batch normalization after each layer .", "tokens": ["for", "the", "fcn-8", ",", "we", "make", "use", "of", "batch", "normalization", "after", "each", "layer", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "make", "start": 19, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 24, "end": 27, "i_start": 6, "i_end": 6}}], "id": 1594}, {"sent": "the random forest analysis was performed using the default settings of the scikit-learn api .", "tokens": ["the", "random", "forest", "analysis", "was", "performed", "using", "the", "default", "settings", "of", "the", "scikit", "-", "learn", "api", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the random forest analysis", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "was performed", "start": 27, "end": 40, "i_start": 4, "i_end": 5}}], "id": 1595}, {"sent": "graphene is a zero band gap material that has a linear dispersion in the chiral electronic bands near the fermi level , which causes some of its extraordinary properties such as high electron mobility .", "tokens": ["graphene", "is", "a", "zero", "band", "gap", "material", "that", "has", "a", "linear", "dispersion", "in", "the", "chiral", "electronic", "bands", "near", "the", "fermi", "level", ",", "which", "causes", "some", "of", "its", "extraordinary", "properties", "such", "as", "high", "electron", "mobility", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "graphene", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "material", "start": 28, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "has", "start": 42, "end": 45, "i_start": 8, "i_end": 8}}, {"character": {"text": "dispersion", "start": 55, "end": 65, "i_start": 11, "i_end": 11}, "action": {"text": "causes", "start": 126, "end": 132, "i_start": 23, "i_end": 23}}], "id": 1596}, {"sent": "the free energy consists of the two main contributions , the interaction energy of the collapsed h-blocks do not contribute to the total elastic energy .", "tokens": ["the", "free", "energy", "consists", "of", "the", "two", "main", "contributions", ",", "the", "interaction", "energy", "of", "the", "collapsed", "h", "-", "blocks", "do", "not", "contribute", "to", "the", "total", "elastic", "energy", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the free energy", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the interaction energy of the collapsed h-blocks", "start": 57, "end": 105, "i_start": 10, "i_end": 18}, "verb": {"text": "contribute", "start": 113, "end": 123, "i_start": 21, "i_end": 21}}, {"character": {"text": "energy", "start": 73, "end": 79, "i_start": 12, "i_end": 12}, "action": {"text": "-", "start": 98, "end": 99, "i_start": 17, "i_end": 17}}], "id": 1597}, {"sent": "we consider various sgd variants and adam for the pool of optimizers .", "tokens": ["we", "consider", "various", "sgd", "variants", "and", "adam", "for", "the", "pool", "of", "optimizers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "consider", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "consider", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 1598}, {"sent": "the exchange-correlation energy was approximated by the scheme of perdew , burke , and ernzerhof .", "tokens": ["the", "exchange", "-", "correlation", "energy", "was", "approximated", "by", "the", "scheme", "of", "perdew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the exchange-correlation energy", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "was approximated", "start": 32, "end": 48, "i_start": 5, "i_end": 6}}, {"character": {"text": "scheme", "start": 56, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "approximated", "start": 36, "end": 48, "i_start": 6, "i_end": 6}}], "id": 1599}, {"sent": "we make the above interpretations clearer through the following examples .", "tokens": ["we", "make", "the", "above", "interpretations", "clearer", "through", "the", "following", "examples", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "make", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "clearer", "start": 34, "end": 41, "i_start": 5, "i_end": 5}}], "id": 1600}, {"sent": "recurrent neural networks are widely used for sequence modelling tasks in domains such as natural language processing , speech recognition , and reinforcement learning .", "tokens": ["recurrent", "neural", "networks", "are", "widely", "used", "for", "sequence", "modelling", "tasks", "in", "domains", "such", "as", "natural", "language", "processing", ",", "speech", "recognition", ",", "and", "reinforcement", "learning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "recurrent neural networks", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 37, "end": 41, "i_start": 5, "i_end": 5}}, {"subject": {"text": "recurrent neural networks", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 26, "end": 29, "i_start": 3, "i_end": 3}}], "id": 1601}, {"sent": "the perdew-burke-ernzerhof functional within the generalized gradient approximation is used for the exchange-correlation interaction between valence electrons .", "tokens": ["the", "perdew", "-", "burke", "-", "ernzerhof", "functional", "within", "the", "generalized", "gradient", "approximation", "is", "used", "for", "the", "exchange", "-", "correlation", "interaction", "between", "valence", "electrons", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the perdew-burke-ernzerhof functional within the generalized gradient approximation", "start": 0, "end": 83, "i_start": 0, "i_end": 11}, "verb": {"text": "is used", "start": 84, "end": 91, "i_start": 12, "i_end": 13}}, {"character": {"text": "electrons", "start": 149, "end": 158, "i_start": 22, "i_end": 22}, "action": {"text": "interaction", "start": 121, "end": 132, "i_start": 19, "i_end": 19}}], "id": 1602}, {"sent": "tian , higher genus symplectic invariants and sigma models coupled with gravity , invent .", "tokens": ["tian", ",", "higher", "genus", "symplectic", "invariants", "and", "sigma", "models", "coupled", "with", "gravity", ",", "invent", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1603}, {"sent": "thinner disks tend to exhibit more steeply truncated disk edges .", "tokens": ["thinner", "disks", "tend", "to", "exhibit", "more", "steeply", "truncated", "disk", "edges", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "thinner disks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "tend", "start": 14, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "disks", "start": 8, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "exhibit", "start": 22, "end": 29, "i_start": 4, "i_end": 4}}], "id": 1604}, {"sent": "convolutional neural networks have achieved superior performance in many visual tasks , such as object detection and segmentation .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "detection", "and", "segmentation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 6, "i_end": 6}}], "id": 1605}, {"sent": "deep convolutional neural networks have been prevailed in various computer vision tasks , such as objection classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "prevailed", "in", "various", "computer", "vision", "tasks", ",", "such", "as", "objection", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been prevailed", "start": 35, "end": 54, "i_start": 4, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "prevailed", "start": 45, "end": 54, "i_start": 6, "i_end": 6}}], "id": 1606}, {"sent": "we compare the results with the available data and make predictions for future experiments .", "tokens": ["we", "compare", "the", "results", "with", "the", "available", "data", "and", "make", "predictions", "for", "future", "experiments", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "make", "start": 51, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "predictions", "start": 56, "end": 67, "i_start": 10, "i_end": 10}}], "id": 1607}, {"sent": "a polytope is a point set - a bounded intersection of finitely many closed halfspaces in some r d , - a convex hull of a finite set of points in some r d .", "tokens": ["a", "polytope", "is", "a", "point", "set", "-", "a", "bounded", "intersection", "of", "finitely", "many", "closed", "halfspaces", "in", "some", "r", "d", ",", "-", "a", "convex", "hull", "of", "a", "finite", "set", "of", "points", "in", "some", "r", "d", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a polytope", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}], "id": 1608}, {"sent": "with a given orbifold structure , x is called an orbifold .", "tokens": ["with", "a", "given", "orbifold", "structure", ",", "x", "is", "called", "an", "orbifold", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1609}, {"sent": "convolutional neural networks have been extensively used in different image and video processing applications .", "tokens": ["convolutional", "neural", "networks", "have", "been", "extensively", "used", "in", "different", "image", "and", "video", "processing", "applications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 52, "end": 56, "i_start": 6, "i_end": 6}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}], "id": 1610}, {"sent": "the space-time m is a compact , oriented and even-dimensional riemannian spin manifold without boundary .", "tokens": ["the", "space", "-", "time", "m", "is", "a", "compact", ",", "oriented", "and", "even", "-", "dimensional", "riemannian", "spin", "manifold", "without", "boundary", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the space-time m", "start": 0, "end": 16, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 5, "i_end": 5}}], "id": 1611}, {"sent": "moreover , b is a trivial extension of k by c to b .", "tokens": ["moreover", ",", "b", "is", "a", "trivial", "extension", "of", "k", "by", "c", "to", "b", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "b", "start": 11, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 3, "i_end": 3}}], "id": 1612}, {"sent": "we used the generating function in scikitlearn package to make data .", "tokens": ["we", "used", "the", "generating", "function", "in", "scikitlearn", "package", "to", "make", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "package", "start": 47, "end": 54, "i_start": 7, "i_end": 7}, "action": {"text": "function", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "make", "start": 58, "end": 62, "i_start": 9, "i_end": 9}}], "id": 1613}, {"sent": "experimentally , superconductivity often is the strongest when the two competing states are nearly degenerate , near quantum critical points .", "tokens": ["experimentally", ",", "superconductivity", "often", "is", "the", "strongest", "when", "the", "two", "competing", "states", "are", "nearly", "degenerate", ",", "near", "quantum", "critical", "points", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "superconductivity", "start": 17, "end": 34, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 41, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "two competing states", "start": 67, "end": 87, "i_start": 9, "i_end": 11}, "action": {"text": "competing", "start": 71, "end": 80, "i_start": 10, "i_end": 10}}], "id": 1614}, {"sent": "over the past few years , deep convolutional neural networks have been very successful in a wide range of computer vision tasks such as image classification .", "tokens": ["over", "the", "past", "few", "years", ",", "deep", "convolutional", "neural", "networks", "have", "been", "very", "successful", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 26, "end": 60, "i_start": 6, "i_end": 9}, "verb": {"text": "have been", "start": 61, "end": 70, "i_start": 10, "i_end": 11}}, {"character": {"text": "networks", "start": 52, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "successful", "start": 76, "end": 86, "i_start": 13, "i_end": 13}}], "id": 1615}, {"sent": "the potential energy felt by the electrons inside the dot is vd .", "tokens": ["the", "potential", "energy", "felt", "by", "the", "electrons", "inside", "the", "dot", "is", "vd", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the potential energy", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "felt", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "electrons", "start": 33, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "felt", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}], "id": 1616}, {"sent": "the tools are available since masas of eand ehave already been studied .", "tokens": ["the", "tools", "are", "available", "since", "masas", "of", "eand", "ehave", "already", "been", "studied", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the tools", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 10, "end": 13, "i_start": 2, "i_end": 2}}], "id": 1617}, {"sent": "these transformations between equivalent theories generally define a discrete group and are called dualities .", "tokens": ["these", "transformations", "between", "equivalent", "theories", "generally", "define", "a", "discrete", "group", "and", "are", "called", "dualities", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "these transformations between equivalent theories", "start": 0, "end": 49, "i_start": 0, "i_end": 4}, "verb": {"text": "define", "start": 60, "end": 66, "i_start": 6, "i_end": 6}}, {"subject": {"text": "these transformations between equivalent theories", "start": 0, "end": 49, "i_start": 0, "i_end": 4}, "verb": {"text": "called", "start": 92, "end": 98, "i_start": 12, "i_end": 12}}, {"character": {"text": "transformations", "start": 6, "end": 21, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 60, "end": 66, "i_start": 6, "i_end": 6}}], "id": 1618}, {"sent": "recently , it was shown that deep learning algorithms outperformed the state-of-the-art methods in various research areas including bioinformatics and cheminformatics .", "tokens": ["recently", ",", "it", "was", "shown", "that", "deep", "learning", "algorithms", "outperformed", "the", "state", "-", "of", "-", "the", "-", "art", "methods", "in", "various", "research", "areas", "including", "bioinformatics", "and", "cheminformatics", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "verb": {"text": "was shown", "start": 14, "end": 23, "i_start": 3, "i_end": 4}}, {"subject": {"text": "deep learning algorithms", "start": 29, "end": 53, "i_start": 6, "i_end": 8}, "verb": {"text": "outperformed", "start": 54, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "algorithms", "start": 43, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "outperformed", "start": 54, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "algorithms", "start": 43, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "learning", "start": 34, "end": 42, "i_start": 7, "i_end": 7}}], "id": 1619}, {"sent": "the errors reflect the monte carlo statistics only .", "tokens": ["the", "errors", "reflect", "the", "monte", "carlo", "statistics", "only", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the errors", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "reflect", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}], "id": 1620}, {"sent": "the structure relaxations used the all-electron-projector augmented wave method as implemented in the vienna ab initio simulation package .", "tokens": ["the", "structure", "relaxations", "used", "the", "all", "-", "electron", "-", "projector", "augmented", "wave", "method", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the structure relaxations", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 26, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "relaxations", "start": 14, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "used", "start": 26, "end": 30, "i_start": 3, "i_end": 3}}], "id": 1621}, {"sent": "the inflaton is a gauge singlet and it couples only to the radial two scalar particle species with electroweak-scale masses .", "tokens": ["the", "inflaton", "is", "a", "gauge", "singlet", "and", "it", "couples", "only", "to", "the", "radial", "two", "scalar", "particle", "species", "with", "electroweak", "-", "scale", "masses", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the inflaton", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"subject": {"text": "it", "start": 36, "end": 38, "i_start": 7, "i_end": 7}, "verb": {"text": "couples", "start": 39, "end": 46, "i_start": 8, "i_end": 8}}], "id": 1622}, {"sent": "then the right analogue of the fischer decomposition for the h-action reads as follows .", "tokens": ["then", "the", "right", "analogue", "of", "the", "fischer", "decomposition", "for", "the", "h", "-", "action", "reads", "as", "follows", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the right analogue of the fischer decomposition for the h-action", "start": 5, "end": 69, "i_start": 1, "i_end": 12}, "verb": {"text": "reads", "start": 70, "end": 75, "i_start": 13, "i_end": 13}}], "id": 1623}, {"sent": "recent works prove that cnns achieve advanced performance on visual relationship reasoning .", "tokens": ["recent", "works", "prove", "that", "cnns", "achieve", "advanced", "performance", "on", "visual", "relationship", "reasoning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "recent works", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "prove", "start": 13, "end": 18, "i_start": 2, "i_end": 2}}, {"subject": {"text": "cnns", "start": 24, "end": 28, "i_start": 4, "i_end": 4}, "verb": {"text": "achieve", "start": 29, "end": 36, "i_start": 5, "i_end": 5}}], "id": 1624}, {"sent": "recent advances with deep residual learning have resulted in 101 layer deep residual networks that deliver superior performance .", "tokens": ["recent", "advances", "with", "deep", "residual", "learning", "have", "resulted", "in", "101", "layer", "deep", "residual", "networks", "that", "deliver", "superior", "performance", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "recent advances with deep residual learning", "start": 0, "end": 43, "i_start": 0, "i_end": 5}, "verb": {"text": "have resulted", "start": 44, "end": 57, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 85, "end": 93, "i_start": 13, "i_end": 13}, "action": {"text": "deliver", "start": 99, "end": 106, "i_start": 15, "i_end": 15}}], "id": 1625}, {"sent": "deep learning or deep neural networks have achieved extraordinary performance in many application domains such as image classification .", "tokens": ["deep", "learning", "or", "deep", "neural", "networks", "have", "achieved", "extraordinary", "performance", "in", "many", "application", "domains", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning or deep neural networks", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "have achieved", "start": 38, "end": 51, "i_start": 6, "i_end": 7}}, {"character": {"text": "or", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}], "id": 1626}, {"sent": "deep neural networks have recently been achieved breakthroughs in several domains such as computer vision .", "tokens": ["deep", "neural", "networks", "have", "recently", "been", "achieved", "breakthroughs", "in", "several", "domains", "such", "as", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "been achieved", "start": 35, "end": 48, "i_start": 5, "i_end": 6}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "breakthroughs", "start": 49, "end": 62, "i_start": 7, "i_end": 7}}], "id": 1627}, {"sent": "quantum algorithms can solve certain computational problems much faster than classical computers , and most likely will be of great impact once quantum computers are available .", "tokens": ["quantum", "algorithms", "can", "solve", "certain", "computational", "problems", "much", "faster", "than", "classical", "computers", ",", "and", "most", "likely", "will", "be", "of", "great", "impact", "once", "quantum", "computers", "are", "available", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "quantum algorithms", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "can solve", "start": 19, "end": 28, "i_start": 2, "i_end": 3}}, {"character": {"text": "algorithms", "start": 8, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "solve", "start": 23, "end": 28, "i_start": 3, "i_end": 3}}], "id": 1628}, {"sent": "we trained the network using adam and a standard cross-entropy loss .", "tokens": ["we", "trained", "the", "network", "using", "adam", "and", "a", "standard", "cross", "-", "entropy", "loss", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "trained", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "trained", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 1629}, {"sent": "the dashed curves correspond to the high temperature behaviour obtained in .", "tokens": ["the", "dashed", "curves", "correspond", "to", "the", "high", "temperature", "behaviour", "obtained", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dashed curves", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "correspond", "start": 18, "end": 28, "i_start": 3, "i_end": 3}}], "id": 1630}, {"sent": "the blobs denote an insertion of the operator \u03c82 2 .", "tokens": ["the", "blobs", "denote", "an", "insertion", "of", "the", "operator", "\u03c82", "2", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the blobs", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "denote", "start": 10, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "blobs", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 10, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1631}, {"sent": "phd thesis , department of electrical engineering , stanford university .", "tokens": ["phd", "thesis", ",", "department", "of", "electrical", "engineering", ",", "stanford", "university", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1632}, {"sent": "in , stanley introduced a generalization of the chromatic polynomial for graphs , called the chromatic symmetric function , given as a sum over all proper colorings of the graph .", "tokens": ["in", ",", "stanley", "introduced", "a", "generalization", "of", "the", "chromatic", "polynomial", "for", "graphs", ",", "called", "the", "chromatic", "symmetric", "function", ",", "given", "as", "a", "sum", "over", "all", "proper", "colorings", "of", "the", "graph", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "stanley", "start": 5, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "introduced", "start": 13, "end": 23, "i_start": 3, "i_end": 3}}, {"subject": {"text": "stanley", "start": 5, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "called", "start": 82, "end": 88, "i_start": 13, "i_end": 13}}, {"character": {"text": "stanley", "start": 5, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 13, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "stanley", "start": 5, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "generalization", "start": 26, "end": 40, "i_start": 5, "i_end": 5}}], "id": 1633}, {"sent": "from the mathematical view , the analog precoders in mm-wave massive mimo with lens antenna array have stronger constraint .", "tokens": ["from", "the", "mathematical", "view", ",", "the", "analog", "precoders", "in", "mm", "-", "wave", "massive", "mimo", "with", "lens", "antenna", "array", "have", "stronger", "constraint", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the analog precoders in mm-wave massive mimo with lens antenna array", "start": 29, "end": 97, "i_start": 5, "i_end": 17}, "verb": {"text": "have", "start": 98, "end": 102, "i_start": 18, "i_end": 18}}], "id": 1634}, {"sent": "deep neural networks achieve excellent performance at various artificial intelligence tasks , such as speech recognition .", "tokens": ["deep", "neural", "networks", "achieve", "excellent", "performance", "at", "various", "artificial", "intelligence", "tasks", ",", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "achieve", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 39, "end": 50, "i_start": 5, "i_end": 5}}], "id": 1635}, {"sent": "in figure 3 we simulate the si and sir models on the us airline network for 500 of the busiest airports .", "tokens": ["in", "figure", "3", "we", "simulate", "the", "si", "and", "sir", "models", "on", "the", "us", "airline", "network", "for", "500", "of", "the", "busiest", "airports", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 12, "end": 14, "i_start": 3, "i_end": 3}, "verb": {"text": "simulate", "start": 15, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 12, "end": 14, "i_start": 3, "i_end": 3}, "action": {"text": "simulate", "start": 15, "end": 23, "i_start": 4, "i_end": 4}}], "id": 1636}, {"sent": "now the notions of s-zero divisors , s-units and s-idempotents are defined in semirings as in case of rings .", "tokens": ["now", "the", "notions", "of", "s", "-", "zero", "divisors", ",", "s", "-", "units", "and", "s", "-", "idempotents", "are", "defined", "in", "semirings", "as", "in", "case", "of", "rings", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the notions of s-zero divisors , s-units and s-idempotents", "start": 4, "end": 62, "i_start": 1, "i_end": 15}, "verb": {"text": "are defined", "start": 63, "end": 74, "i_start": 16, "i_end": 17}}], "id": 1637}, {"sent": "d eep neural networks have advanced to show the state-of-the-art performance in many of computer vision applications , such as image classification .", "tokens": ["d", "eep", "neural", "networks", "have", "advanced", "to", "show", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "many", "of", "computer", "vision", "applications", ",", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 6, "end": 21, "i_start": 2, "i_end": 3}, "verb": {"text": "have advanced", "start": 22, "end": 35, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 13, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "show", "start": 39, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 13, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 65, "end": 76, "i_start": 16, "i_end": 16}}], "id": 1638}, {"sent": "convolutional neural networks have achieved state-of-the-art performance on visual tasks such as image and video recognition in the last few years .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "visual", "tasks", "such", "as", "image", "and", "video", "recognition", "in", "the", "last", "few", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 61, "end": 72, "i_start": 12, "i_end": 12}}], "id": 1639}, {"sent": "monti et al propose mixture model and provide a unified generalization of cnn architectures on graphs .", "tokens": ["monti", "et", "al", "propose", "mixture", "model", "and", "provide", "a", "unified", "generalization", "of", "cnn", "architectures", "on", "graphs", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "al", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "verb": {"text": "propose", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "al", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "verb": {"text": "provide", "start": 38, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "monti", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}], "id": 1640}, {"sent": "the recent works adopted the deep networks as the feature embedding function , and used triplet losses instead of pairwise constraints to learn the metric .", "tokens": ["the", "recent", "works", "adopted", "the", "deep", "networks", "as", "the", "feature", "embedding", "function", ",", "and", "used", "triplet", "losses", "instead", "of", "pairwise", "constraints", "to", "learn", "the", "metric", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the recent works", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "adopted", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the recent works", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 83, "end": 87, "i_start": 14, "i_end": 14}}, {"character": {"text": "works", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "adopted", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 34, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "function", "start": 68, "end": 76, "i_start": 11, "i_end": 11}}], "id": 1641}, {"sent": "deep neural networks have demonstrated significant performance improvements in a wide range of computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "significant", "performance", "improvements", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improvements", "start": 63, "end": 75, "i_start": 7, "i_end": 7}}], "id": 1642}, {"sent": "both the maximum and the average radius are shown .", "tokens": ["both", "the", "maximum", "and", "the", "average", "radius", "are", "shown", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "both the maximum and the average radius", "start": 0, "end": 39, "i_start": 0, "i_end": 6}, "verb": {"text": "are shown", "start": 40, "end": 49, "i_start": 7, "i_end": 8}}], "id": 1643}, {"sent": "the exchange-correlation functional was treated using the generalized gradient approximation parametrized by perdew , burke , and ernzerhof .", "tokens": ["the", "exchange", "-", "correlation", "functional", "was", "treated", "using", "the", "generalized", "gradient", "approximation", "parametrized", "by", "perdew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange-correlation functional", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "was treated", "start": 36, "end": 47, "i_start": 5, "i_end": 6}}, {"character": {"text": "perdew", "start": 109, "end": 115, "i_start": 14, "i_end": 14}, "action": {"text": "parametrized", "start": 93, "end": 105, "i_start": 12, "i_end": 12}}, {"character": {"text": "burke", "start": 118, "end": 123, "i_start": 16, "i_end": 16}, "action": {"text": "parametrized", "start": 93, "end": 105, "i_start": 12, "i_end": 12}}, {"character": {"text": "ernzerhof", "start": 130, "end": 139, "i_start": 19, "i_end": 19}, "action": {"text": "parametrized", "start": 93, "end": 105, "i_start": 12, "i_end": 12}}], "id": 1644}, {"sent": "the deuteron is a well-known example of hadronic molecule , and the approximate 105 known nuclear levels are all hadronic molecule .", "tokens": ["the", "deuteron", "is", "a", "well", "-", "known", "example", "of", "hadronic", "molecule", ",", "and", "the", "approximate", "105", "known", "nuclear", "levels", "are", "all", "hadronic", "molecule", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the deuteron", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 1645}, {"sent": "we find that the latest-type spirals closely follow the correlation between molecular gas content and galaxy luminosity established for earlier hubble types .", "tokens": ["we", "find", "that", "the", "latest", "-", "type", "spirals", "closely", "follow", "the", "correlation", "between", "molecular", "gas", "content", "and", "galaxy", "luminosity", "established", "for", "earlier", "hubble", "types", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the latest-type spirals", "start": 13, "end": 36, "i_start": 3, "i_end": 7}, "verb": {"text": "follow", "start": 45, "end": 51, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "spirals", "start": 29, "end": 36, "i_start": 7, "i_end": 7}, "action": {"text": "follow", "start": 45, "end": 51, "i_start": 9, "i_end": 9}}, {"character": {"text": "types", "start": 151, "end": 156, "i_start": 23, "i_end": 23}, "action": {"text": "established", "start": 120, "end": 131, "i_start": 19, "i_end": 19}}], "id": 1646}, {"sent": "convolutional neural networks have achieved tremendous progress on many pattern recognition tasks , especially large-scale images recognition problems .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "tremendous", "progress", "on", "many", "pattern", "recognition", "tasks", ",", "especially", "large", "-", "scale", "images", "recognition", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 1647}, {"sent": "now we proceed onto define the notion of interval subgroupoid of level three .", "tokens": ["now", "we", "proceed", "onto", "define", "the", "notion", "of", "interval", "subgroupoid", "of", "level", "three", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 20, "end": 26, "i_start": 4, "i_end": 4}}], "id": 1648}, {"sent": "deep convolutional neural networks have rapidly matured as an effective tool for almost all computer vision tasks , including object recognition , classification , segmentation , superresolution , etc .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "rapidly", "matured", "as", "an", "effective", "tool", "for", "almost", "all", "computer", "vision", "tasks", ",", "including", "object", "recognition", ",", "classification", ",", "segmentation", ",", "superresolution", ",", "etc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "matured", "start": 48, "end": 55, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "tool", "start": 72, "end": 76, "i_start": 10, "i_end": 10}, "action": {"text": "effective", "start": 62, "end": 71, "i_start": 9, "i_end": 9}}], "id": 1649}, {"sent": "the normalization operation is introduced to accelerate deep network training .", "tokens": ["the", "normalization", "operation", "is", "introduced", "to", "accelerate", "deep", "network", "training", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the normalization operation", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "is introduced", "start": 28, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "operation", "start": 18, "end": 27, "i_start": 2, "i_end": 2}, "action": {"text": "accelerate", "start": 45, "end": 55, "i_start": 6, "i_end": 6}}], "id": 1650}, {"sent": "pre serving supersymmetry will require additionally that the pair is also invariant under \u03b3 .", "tokens": ["pre", "serving", "supersymmetry", "will", "require", "additionally", "that", "the", "pair", "is", "also", "invariant", "under", "\u03b3", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "supersymmetry", "start": 12, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "require", "start": 31, "end": 38, "i_start": 4, "i_end": 4}}], "id": 1651}, {"sent": "deep neural networks have demonstrated extraordinary success in a variety of fields such as computer vision .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "extraordinary", "success", "in", "a", "variety", "of", "fields", "such", "as", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 53, "end": 60, "i_start": 6, "i_end": 6}}], "id": 1652}, {"sent": "convolutional neural networks have recently been very successful on a variety of recognition and classification tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "been", "very", "successful", "on", "a", "variety", "of", "recognition", "and", "classification", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "been", "start": 44, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 54, "end": 64, "i_start": 7, "i_end": 7}}], "id": 1653}, {"sent": "in recent years , the phenomenon of bose-einstein condensation has received much attention , both experimentally and theoretically .", "tokens": ["in", "recent", "years", ",", "the", "phenomenon", "of", "bose", "-", "einstein", "condensation", "has", "received", "much", "attention", ",", "both", "experimentally", "and", "theoretically", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the phenomenon of bose-einstein condensation", "start": 18, "end": 62, "i_start": 4, "i_end": 10}, "verb": {"text": "has received", "start": 63, "end": 75, "i_start": 11, "i_end": 12}}], "id": 1654}, {"sent": "deep neural networks achieve excellent performance at various artificial intelligence tasks , such as speech recognition .", "tokens": ["deep", "neural", "networks", "achieve", "excellent", "performance", "at", "various", "artificial", "intelligence", "tasks", ",", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "achieve", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 39, "end": 50, "i_start": 5, "i_end": 5}}], "id": 1655}, {"sent": "in figure3 , we compare our method with previous state-of-the-art methods lapsrn .", "tokens": ["in", "figure3", ",", "we", "compare", "our", "method", "with", "previous", "state", "-", "of", "-", "the", "-", "art", "methods", "lapsrn", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "compare", "start": 16, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "compare", "start": 16, "end": 23, "i_start": 4, "i_end": 4}}], "id": 1656}, {"sent": "these methods are gradient-based saliency maps , class activation mapping , gradient-weighted class activation mapping , and excitation back-propagation .", "tokens": ["these", "methods", "are", "gradient", "-", "based", "saliency", "maps", ",", "class", "activation", "mapping", ",", "gradient", "-", "weighted", "class", "activation", "mapping", ",", "and", "excitation", "back", "-", "propagation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these methods", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 14, "end": 17, "i_start": 2, "i_end": 2}}], "id": 1657}, {"sent": "deep neural networks have demonstrated to be effective models for solving a large variety of problems in several domains , including image , to name a few .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "to", "be", "effective", "models", "for", "solving", "a", "large", "variety", "of", "problems", "in", "several", "domains", ",", "including", "image", ",", "to", "name", "a", "few", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "models", "start": 55, "end": 61, "i_start": 8, "i_end": 8}, "action": {"text": "effective", "start": 45, "end": 54, "i_start": 7, "i_end": 7}}], "id": 1658}, {"sent": "spin modulation originates from the rotating partially optically thick accretion funnels at both poles of the white dwarf .", "tokens": ["spin", "modulation", "originates", "from", "the", "rotating", "partially", "optically", "thick", "accretion", "funnels", "at", "both", "poles", "of", "the", "white", "dwarf", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "spin modulation", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "originates", "start": 16, "end": 26, "i_start": 2, "i_end": 2}}], "id": 1659}, {"sent": "deep learning has recently vastly improved the performance of many related fields such as compute vision and speech recognition .", "tokens": ["deep", "learning", "has", "recently", "vastly", "improved", "the", "performance", "of", "many", "related", "fields", "such", "as", "compute", "vision", "and", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "improved", "start": 34, "end": 42, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has", "start": 14, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "improved", "start": 34, "end": 42, "i_start": 5, "i_end": 5}}, {"character": {"text": "fields", "start": 75, "end": 81, "i_start": 11, "i_end": 11}, "action": {"text": "performance", "start": 47, "end": 58, "i_start": 7, "i_end": 7}}], "id": 1660}, {"sent": "in recent years , deep neural networks have led to many breakthrough results in machine learning and computer vision , and are now widely deployed in industry .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "led", "to", "many", "breakthrough", "results", "in", "machine", "learning", "and", "computer", "vision", ",", "and", "are", "now", "widely", "deployed", "in", "industry", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have led", "start": 39, "end": 47, "i_start": 7, "i_end": 8}}, {"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "deployed", "start": 138, "end": 146, "i_start": 24, "i_end": 24}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "led", "start": 44, "end": 47, "i_start": 8, "i_end": 8}}], "id": 1661}, {"sent": "we say that a foliation is a flat foliation if its leaves are flat submanifolds , and we say that a foliation is a totally geodesic foliation if its leaves are totally geodesic submanifolds .", "tokens": ["we", "say", "that", "a", "foliation", "is", "a", "flat", "foliation", "if", "its", "leaves", "are", "flat", "submanifolds", ",", "and", "we", "say", "that", "a", "foliation", "is", "a", "totally", "geodesic", "foliation", "if", "its", "leaves", "are", "totally", "geodesic", "submanifolds", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "say", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 86, "end": 88, "i_start": 17, "i_end": 17}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "say", "start": 89, "end": 92, "i_start": 18, "i_end": 18}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "say", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 1662}, {"sent": "prager , universally optimal approximation of functionals .", "tokens": ["prager", ",", "universally", "optimal", "approximation", "of", "functionals", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "prager", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "approximation", "start": 29, "end": 42, "i_start": 4, "i_end": 4}}], "id": 1663}, {"sent": "in this model the channel is assumed to remain constant over a block and to change in an independent fashion from block to block .", "tokens": ["in", "this", "model", "the", "channel", "is", "assumed", "to", "remain", "constant", "over", "a", "block", "and", "to", "change", "in", "an", "independent", "fashion", "from", "block", "to", "block", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the channel", "start": 14, "end": 25, "i_start": 3, "i_end": 4}, "verb": {"text": "is assumed", "start": 26, "end": 36, "i_start": 5, "i_end": 6}}], "id": 1664}, {"sent": "the solution to this problem is provided by kaming he et al who proposed the deep residual learning approach .", "tokens": ["the", "solution", "to", "this", "problem", "is", "provided", "by", "kaming", "he", "et", "al", "who", "proposed", "the", "deep", "residual", "learning", "approach", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the solution to this problem", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "is provided", "start": 29, "end": 40, "i_start": 5, "i_end": 6}}, {"character": {"text": "kaming he", "start": 44, "end": 53, "i_start": 8, "i_end": 9}, "action": {"text": "provided", "start": 32, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "residual", "start": 82, "end": 90, "i_start": 16, "i_end": 16}, "action": {"text": "provided", "start": 32, "end": 40, "i_start": 6, "i_end": 6}}], "id": 1665}, {"sent": "the ellipsis denotes other terms coming from the time derivative that not contribute to the diffusive effects .", "tokens": ["the", "ellipsis", "denotes", "other", "terms", "coming", "from", "the", "time", "derivative", "that", "not", "contribute", "to", "the", "diffusive", "effects", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ellipsis", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "denotes", "start": 13, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "ellipsis", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denotes", "start": 13, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "terms", "start": 27, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "not contribute", "start": 70, "end": 84, "i_start": 11, "i_end": 12}}], "id": 1666}, {"sent": "parameter values are same as those in figure .", "tokens": ["parameter", "values", "are", "same", "as", "those", "in", "figure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "parameter values", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 17, "end": 20, "i_start": 2, "i_end": 2}}], "id": 1667}, {"sent": "defferrard et al presented a cnn formulation using spectral graph theoretic methods to design fast localized convolutional filters .", "tokens": ["defferrard", "et", "al", "presented", "a", "cnn", "formulation", "using", "spectral", "graph", "theoretic", "methods", "to", "design", "fast", "localized", "convolutional", "filters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "defferrard et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "presented", "start": 17, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "defferrard", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "presented", "start": 17, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "defferrard", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "formulation", "start": 33, "end": 44, "i_start": 6, "i_end": 6}}, {"character": {"text": "defferrard", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 45, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "defferrard", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "design", "start": 87, "end": 93, "i_start": 13, "i_end": 13}}], "id": 1668}, {"sent": "thus there is no upper bound on the scale of fermion mass generation .", "tokens": ["thus", "there", "is", "no", "upper", "bound", "on", "the", "scale", "of", "fermion", "mass", "generation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 5, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}], "id": 1669}, {"sent": "the left panel shows the result from the ppm solver and the right panel shows the result from the mhd solver .", "tokens": ["the", "left", "panel", "shows", "the", "result", "from", "the", "ppm", "solver", "and", "the", "right", "panel", "shows", "the", "result", "from", "the", "mhd", "solver", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the left panel", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "shows", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the right panel", "start": 56, "end": 71, "i_start": 11, "i_end": 13}, "verb": {"text": "shows", "start": 72, "end": 77, "i_start": 14, "i_end": 14}}, {"character": {"text": "panel", "start": 9, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "shows", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "panel", "start": 66, "end": 71, "i_start": 13, "i_end": 13}, "action": {"text": "shows", "start": 72, "end": 77, "i_start": 14, "i_end": 14}}], "id": 1670}, {"sent": "in the degraded relay channel , channel outputs obtained by the relay are less noisy than those obtained by the receiver .", "tokens": ["in", "the", "degraded", "relay", "channel", ",", "channel", "outputs", "obtained", "by", "the", "relay", "are", "less", "noisy", "than", "those", "obtained", "by", "the", "receiver", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "channel outputs obtained by the relay", "start": 32, "end": 69, "i_start": 6, "i_end": 11}, "verb": {"text": "are", "start": 70, "end": 73, "i_start": 12, "i_end": 12}}, {"character": {"text": "relay", "start": 16, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "obtained", "start": 48, "end": 56, "i_start": 8, "i_end": 8}}, {"character": {"text": "receiver", "start": 112, "end": 120, "i_start": 20, "i_end": 20}, "action": {"text": "obtained", "start": 96, "end": 104, "i_start": 17, "i_end": 17}}], "id": 1671}, {"sent": "data reduction was performed using the miriad package .", "tokens": ["data", "reduction", "was", "performed", "using", "the", "miriad", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "data reduction", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "was performed", "start": 15, "end": 28, "i_start": 2, "i_end": 3}}], "id": 1672}, {"sent": "the trade-off is a small reduction in the probability of success .", "tokens": ["the", "trade", "-", "off", "is", "a", "small", "reduction", "in", "the", "probability", "of", "success", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the trade-off", "start": 0, "end": 13, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 4, "i_end": 4}}], "id": 1673}, {"sent": "the common framework for the decision making process is reinforcement learning .", "tokens": ["the", "common", "framework", "for", "the", "decision", "making", "process", "is", "reinforcement", "learning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the common framework for the decision making process", "start": 0, "end": 52, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 53, "end": 55, "i_start": 8, "i_end": 8}}], "id": 1674}, {"sent": "nevertheless , the normalization factor will not influence the non-gaussianity measures .", "tokens": ["nevertheless", ",", "the", "normalization", "factor", "will", "not", "influence", "the", "non", "-", "gaussianity", "measures", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the normalization factor", "start": 15, "end": 39, "i_start": 2, "i_end": 4}, "verb": {"text": "will not influence", "start": 40, "end": 58, "i_start": 5, "i_end": 7}}, {"character": {"text": "factor", "start": 33, "end": 39, "i_start": 4, "i_end": 4}, "action": {"text": "not influence", "start": 45, "end": 58, "i_start": 6, "i_end": 7}}], "id": 1675}, {"sent": "convolutional neural networks have achieved remarkable success in many computer vision domains such as classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "remarkable", "success", "in", "many", "computer", "vision", "domains", "such", "as", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 6, "i_end": 6}}], "id": 1676}, {"sent": "firstly , we consider the superconductor with the spin singlet copper pairs .", "tokens": ["firstly", ",", "we", "consider", "the", "superconductor", "with", "the", "spin", "singlet", "copper", "pairs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "consider", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "consider", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}], "id": 1677}, {"sent": "in recent years , deep learning technology has attracted considerable interest in the computer vision and machine learning community .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "technology", "has", "attracted", "considerable", "interest", "in", "the", "computer", "vision", "and", "machine", "learning", "community", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning technology", "start": 18, "end": 42, "i_start": 4, "i_end": 6}, "verb": {"text": "has attracted", "start": 43, "end": 56, "i_start": 7, "i_end": 8}}, {"character": {"text": "technology", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "attracted", "start": 47, "end": 56, "i_start": 8, "i_end": 8}}], "id": 1678}, {"sent": "in particular , bregler et al presented an image-based approach called video rewrite to automatically create a new video of a person with generated mouth movements .", "tokens": ["in", "particular", ",", "bregler", "et", "al", "presented", "an", "image", "-", "based", "approach", "called", "video", "rewrite", "to", "automatically", "create", "a", "new", "video", "of", "a", "person", "with", "generated", "mouth", "movements", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bregler et al", "start": 16, "end": 29, "i_start": 3, "i_end": 5}, "verb": {"text": "presented", "start": 30, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "person", "start": 126, "end": 132, "i_start": 23, "i_end": 23}, "action": {"text": "presented", "start": 30, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "bregler", "start": 16, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "presented", "start": 30, "end": 39, "i_start": 6, "i_end": 6}}], "id": 1679}, {"sent": "as in the -supersymmetric gauge theory , the gauge multiplet is determined by scalar superfields .", "tokens": ["as", "in", "the", "-supersymmetric", "gauge", "theory", ",", "the", "gauge", "multiplet", "is", "determined", "by", "scalar", "superfields", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the gauge multiplet", "start": 41, "end": 60, "i_start": 7, "i_end": 9}, "verb": {"text": "is determined", "start": 61, "end": 74, "i_start": 10, "i_end": 11}}, {"character": {"text": "superfields", "start": 85, "end": 96, "i_start": 14, "i_end": 14}, "action": {"text": "determined", "start": 64, "end": 74, "i_start": 11, "i_end": 11}}], "id": 1680}, {"sent": "the binding energy is the minimal energy required in ionizing the atom .", "tokens": ["the", "binding", "energy", "is", "the", "minimal", "energy", "required", "in", "ionizing", "the", "atom", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the binding energy", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "energy", "start": 12, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "binding", "start": 4, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "ionizing", "start": 53, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "required", "start": 41, "end": 49, "i_start": 7, "i_end": 7}}], "id": 1681}, {"sent": "general brane cosmologies and their global space time structure .", "tokens": ["general", "brane", "cosmologies", "and", "their", "global", "space", "time", "structure", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1682}, {"sent": "the neural language models have achieved great success in many speech and language processing applications .", "tokens": ["the", "neural", "language", "models", "have", "achieved", "great", "success", "in", "many", "speech", "and", "language", "processing", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the neural language models", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 27, "end": 40, "i_start": 4, "i_end": 5}}, {"character": {"text": "models", "start": 20, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 32, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "models", "start": 20, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 47, "end": 54, "i_start": 7, "i_end": 7}}], "id": 1683}, {"sent": "large and well-annotated datasets such as imagenet are considered crucial to advancing computer vision research .", "tokens": ["large", "and", "well", "-", "annotated", "datasets", "such", "as", "imagenet", "are", "considered", "crucial", "to", "advancing", "computer", "vision", "research", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "large and well-annotated datasets such as imagenet", "start": 0, "end": 50, "i_start": 0, "i_end": 8}, "verb": {"text": "are considered", "start": 51, "end": 65, "i_start": 9, "i_end": 10}}], "id": 1684}, {"sent": "our approach shows performance comparable to state-of-the-art l0 minimization .", "tokens": ["our", "approach", "shows", "performance", "comparable", "to", "state", "-", "of", "-", "the", "-", "art", "l0", "minimization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our approach", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "shows", "start": 13, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "approach", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "shows", "start": 13, "end": 18, "i_start": 2, "i_end": 2}}], "id": 1685}, {"sent": "bayesian optimization is a powerful framework for global optimization of black-box functions .", "tokens": ["bayesian", "optimization", "is", "a", "powerful", "framework", "for", "global", "optimization", "of", "black", "-", "box", "functions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "bayesian optimization", "start": 0, "end": 21, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 2, "i_end": 2}}], "id": 1686}, {"sent": "millimeter wave communication has drawn extensive attention as a promising technology for 5g cellular systems .", "tokens": ["millimeter", "wave", "communication", "has", "drawn", "extensive", "attention", "as", "a", "promising", "technology", "for", "5", "g", "cellular", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "millimeter wave communication", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "has drawn", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "communication", "start": 16, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "drawn", "start": 34, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "technology", "start": 75, "end": 85, "i_start": 10, "i_end": 10}, "action": {"text": "promising", "start": 65, "end": 74, "i_start": 9, "i_end": 9}}], "id": 1687}, {"sent": "since teleportation is a linear process it may also be used for entanglement swapping .", "tokens": ["since", "teleportation", "is", "a", "linear", "process", "it", "may", "also", "be", "used", "for", "entanglement", "swapping", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "teleportation", "start": 6, "end": 19, "i_start": 1, "i_end": 1}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 2, "i_end": 2}}], "id": 1688}, {"sent": "we show that when including such dominant thermal corrections , the ew symmetry gets restored .", "tokens": ["we", "show", "that", "when", "including", "such", "dominant", "thermal", "corrections", ",", "the", "ew", "symmetry", "gets", "restored", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the ew symmetry", "start": 64, "end": 79, "i_start": 10, "i_end": 12}, "verb": {"text": "restored", "start": 85, "end": 93, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "corrections", "start": 50, "end": 61, "i_start": 8, "i_end": 8}, "action": {"text": "dominant", "start": 33, "end": 41, "i_start": 6, "i_end": 6}}], "id": 1689}, {"sent": "these results were generalized in , where the authors proved independently that every outerplanar graph is 2-defective 2-choosable and every planar graph is 2-defective 3-choosable .", "tokens": ["these", "results", "were", "generalized", "in", ",", "where", "the", "authors", "proved", "independently", "that", "every", "outerplanar", "graph", "is", "2", "-", "defective", "2", "-", "choosable", "and", "every", "planar", "graph", "is", "2", "-", "defective", "3", "-", "choosable", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these results", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "were generalized", "start": 14, "end": 30, "i_start": 2, "i_end": 3}}], "id": 1690}, {"sent": "due to that the dispersion is close to zero in the main lobe of fbg reflectivity spectrum , the laser spectrum needs to be tuned to edges of the main lobe to find a minimal tds by optimizing the laser frequency detuning and the feedback strength .", "tokens": ["due", "to", "that", "the", "dispersion", "is", "close", "to", "zero", "in", "the", "main", "lobe", "of", "fbg", "reflectivity", "spectrum", ",", "the", "laser", "spectrum", "needs", "to", "be", "tuned", "to", "edges", "of", "the", "main", "lobe", "to", "find", "a", "minimal", "tds", "by", "optimizing", "the", "laser", "frequency", "detuning", "and", "the", "feedback", "strength", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the laser spectrum", "start": 92, "end": 110, "i_start": 18, "i_end": 20}, "verb": {"text": "needs", "start": 111, "end": 116, "i_start": 21, "i_end": 21}}, {"subject": {"text": "the laser spectrum", "start": 92, "end": 110, "i_start": 18, "i_end": 20}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 5, "i_end": 5}}], "id": 1691}, {"sent": "here the superscripts denote p2 and p4 eigenvalues .", "tokens": ["here", "the", "superscripts", "denote", "p2", "and", "p4", "eigenvalues", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "superscripts", "start": 9, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "denote", "start": 22, "end": 28, "i_start": 3, "i_end": 3}}], "id": 1692}, {"sent": "convolutional neural networks have shown their efficiency for a wide range of tasks .", "tokens": ["convolutional", "neural", "networks", "have", "shown", "their", "efficiency", "for", "a", "wide", "range", "of", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 35, "end": 40, "i_start": 4, "i_end": 4}}], "id": 1693}, {"sent": "we use the adam gradient optimization method with the categorical cross-entropy loss function .", "tokens": ["we", "use", "the", "adam", "gradient", "optimization", "method", "with", "the", "categorical", "cross", "-", "entropy", "loss", "function", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "function", "start": 85, "end": 93, "i_start": 14, "i_end": 14}, "action": {"text": "cross", "start": 66, "end": 71, "i_start": 10, "i_end": 10}}], "id": 1694}, {"sent": "in , iterative sparse beamforming algorithms were proposed to reduce the load of the backhaul links while providing reliable communication to the users .", "tokens": ["in", ",", "iterative", "sparse", "beamforming", "algorithms", "were", "proposed", "to", "reduce", "the", "load", "of", "the", "backhaul", "links", "while", "providing", "reliable", "communication", "to", "the", "users", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "iterative sparse beamforming algorithms", "start": 5, "end": 44, "i_start": 2, "i_end": 5}, "verb": {"text": "were proposed", "start": 45, "end": 58, "i_start": 6, "i_end": 7}}, {"character": {"text": "algorithms", "start": 34, "end": 44, "i_start": 5, "i_end": 5}, "action": {"text": "reduce", "start": 62, "end": 68, "i_start": 9, "i_end": 9}}, {"character": {"text": "algorithms", "start": 34, "end": 44, "i_start": 5, "i_end": 5}, "action": {"text": "providing", "start": 106, "end": 115, "i_start": 17, "i_end": 17}}], "id": 1695}, {"sent": "gromov introduced the lipschitz order relation on the set of metric measure spaces and developed a rich theory .", "tokens": ["gromov", "introduced", "the", "lipschitz", "order", "relation", "on", "the", "set", "of", "metric", "measure", "spaces", "and", "developed", "a", "rich", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "gromov", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "introduced", "start": 7, "end": 17, "i_start": 1, "i_end": 1}}, {"subject": {"text": "gromov", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "developed", "start": 87, "end": 96, "i_start": 14, "i_end": 14}}, {"character": {"text": "gromov", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 7, "end": 17, "i_start": 1, "i_end": 1}}], "id": 1696}, {"sent": "the resnet50 pretrained on imagenet is employed as our initialized model .", "tokens": ["the", "resnet50", "pretrained", "on", "imagenet", "is", "employed", "as", "our", "initialized", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the resnet50 pretrained on imagenet", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "is employed", "start": 36, "end": 47, "i_start": 5, "i_end": 6}}], "id": 1697}, {"sent": "deep neural network models provide the state-of-art results in several tasks and applications , although the theory has not been completely understood yet .", "tokens": ["deep", "neural", "network", "models", "provide", "the", "state", "-", "of", "-", "art", "results", "in", "several", "tasks", "and", "applications", ",", "although", "the", "theory", "has", "not", "been", "completely", "understood", "yet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural network models", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "provide", "start": 27, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "models", "start": 20, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "provide", "start": 27, "end": 34, "i_start": 4, "i_end": 4}}], "id": 1698}, {"sent": "the shanghaitech dataset contains 1198 annotated images with a total of 330,165 people .", "tokens": ["the", "shanghaitech", "dataset", "contains", "1198", "annotated", "images", "with", "a", "total", "of", "330,165", "people", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the shanghaitech dataset", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "contains", "start": 25, "end": 33, "i_start": 3, "i_end": 3}}, {"character": {"text": "dataset", "start": 17, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "contains", "start": 25, "end": 33, "i_start": 3, "i_end": 3}}], "id": 1699}, {"sent": "we find these results interesting , since we achieved it without learning any attribute classifiers , as in .", "tokens": ["we", "find", "these", "results", "interesting", ",", "since", "we", "achieved", "it", "without", "learning", "any", "attribute", "classifiers", ",", "as", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "interesting", "start": 22, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "achieved", "start": 45, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "learning", "start": 65, "end": 73, "i_start": 11, "i_end": 11}}], "id": 1700}, {"sent": "obviously , every right- or left-cancellative semigroup is quasi-cancellative .", "tokens": ["obviously", ",", "every", "right-", "or", "left", "-", "cancellative", "semigroup", "is", "quasi", "-", "cancellative", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "every right- or left-cancellative semigroup", "start": 12, "end": 55, "i_start": 2, "i_end": 8}, "verb": {"text": "is", "start": 56, "end": 58, "i_start": 9, "i_end": 9}}, {"character": {"text": "semigroup", "start": 46, "end": 55, "i_start": 8, "i_end": 8}, "action": {"text": "cancellative", "start": 65, "end": 77, "i_start": 12, "i_end": 12}}], "id": 1701}, {"sent": "the cox relative risk model has been widely used in survival analysis .", "tokens": ["the", "cox", "relative", "risk", "model", "has", "been", "widely", "used", "in", "survival", "analysis", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the cox relative risk model", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "used", "start": 44, "end": 48, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the cox relative risk model", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "has been", "start": 28, "end": 36, "i_start": 5, "i_end": 6}}], "id": 1702}, {"sent": "this task is left as an exercise to the reader .", "tokens": ["this", "task", "is", "left", "as", "an", "exercise", "to", "the", "reader", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this task", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is left", "start": 10, "end": 17, "i_start": 2, "i_end": 3}}], "id": 1703}, {"sent": "recent studies that have explored attacks on automatic speech recognition systems , have demonstrated that adversarial examples exist in the audio domain .", "tokens": ["recent", "studies", "that", "have", "explored", "attacks", "on", "automatic", "speech", "recognition", "systems", ",", "have", "demonstrated", "that", "adversarial", "examples", "exist", "in", "the", "audio", "domain", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "recent studies that have explored attacks on automatic speech recognition systems", "start": 0, "end": 81, "i_start": 0, "i_end": 10}, "verb": {"text": "have demonstrated", "start": 84, "end": 101, "i_start": 12, "i_end": 13}}, {"subject": {"text": "adversarial examples", "start": 107, "end": 127, "i_start": 15, "i_end": 16}, "verb": {"text": "exist", "start": 128, "end": 133, "i_start": 17, "i_end": 17}}, {"character": {"text": "studies", "start": 7, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "demonstrated", "start": 89, "end": 101, "i_start": 13, "i_end": 13}}, {"character": {"text": "studies", "start": 7, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "explored", "start": 25, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "systems", "start": 74, "end": 81, "i_start": 10, "i_end": 10}, "action": {"text": "recognition", "start": 62, "end": 73, "i_start": 9, "i_end": 9}}], "id": 1704}, {"sent": "deep convolutional neural networks have demonstrated superior performance in various computer vision tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "demonstrated", "superior", "performance", "in", "various", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have demonstrated", "start": 35, "end": 52, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "demonstrated", "start": 40, "end": 52, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 62, "end": 73, "i_start": 7, "i_end": 7}}], "id": 1705}, {"sent": "to improve spatial coherence and quality of our saliency maps , we adopt the fully connected conditional random field method as a selective layer during the inference phase .", "tokens": ["to", "improve", "spatial", "coherence", "and", "quality", "of", "our", "saliency", "maps", ",", "we", "adopt", "the", "fully", "connected", "conditional", "random", "field", "method", "as", "a", "selective", "layer", "during", "the", "inference", "phase", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 64, "end": 66, "i_start": 11, "i_end": 11}, "verb": {"text": "adopt", "start": 67, "end": 72, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "adopt", "start": 67, "end": 72, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "improve", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 1706}, {"sent": "drawing inspiration from the success of deep learning in high-level vision tasks .", "tokens": ["drawing", "inspiration", "from", "the", "success", "of", "deep", "learning", "in", "high", "-", "level", "vision", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "success", "start": 29, "end": 36, "i_start": 4, "i_end": 4}, "action": {"text": "inspiration", "start": 8, "end": 19, "i_start": 1, "i_end": 1}}, {"character": {"text": "learning", "start": 45, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "success", "start": 29, "end": 36, "i_start": 4, "i_end": 4}}], "id": 1707}, {"sent": "many successful applications of neural networks employ regularization techniques such as l 2 regularization , dropout to help prevent overfitting .", "tokens": ["many", "successful", "applications", "of", "neural", "networks", "employ", "regularization", "techniques", "such", "as", "l", "2", "regularization", ",", "dropout", "to", "help", "prevent", "overfitting", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "many successful applications of neural networks", "start": 0, "end": 47, "i_start": 0, "i_end": 5}, "verb": {"text": "employ", "start": 48, "end": 54, "i_start": 6, "i_end": 6}}, {"subject": {"text": "many successful applications of neural networks", "start": 0, "end": 47, "i_start": 0, "i_end": 5}, "verb": {"text": "dropout", "start": 110, "end": 117, "i_start": 15, "i_end": 15}}, {"character": {"text": "applications", "start": 16, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "employ", "start": 48, "end": 54, "i_start": 6, "i_end": 6}}, {"character": {"text": "applications", "start": 16, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "help", "start": 121, "end": 125, "i_start": 17, "i_end": 17}}], "id": 1708}, {"sent": "in the last decade , convolutional neural networks have shown state of the art accuracy on a variety of visual recognition tasks such as image classification .", "tokens": ["in", "the", "last", "decade", ",", "convolutional", "neural", "networks", "have", "shown", "state", "of", "the", "art", "accuracy", "on", "a", "variety", "of", "visual", "recognition", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 21, "end": 50, "i_start": 5, "i_end": 7}, "verb": {"text": "have shown", "start": 51, "end": 61, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 42, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "shown", "start": 56, "end": 61, "i_start": 9, "i_end": 9}}], "id": 1709}, {"sent": "the dashed and dotted lines represent the pure coulomb and pure nuclear contributions .", "tokens": ["the", "dashed", "and", "dotted", "lines", "represent", "the", "pure", "coulomb", "and", "pure", "nuclear", "contributions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the dashed and dotted lines", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "represent", "start": 28, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "lines", "start": 22, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "represent", "start": 28, "end": 37, "i_start": 5, "i_end": 5}}], "id": 1710}, {"sent": "we also introduce a chemical potential \u00b5 which is a constant source for fermion number in order to take account of the finite fermion density of the system .", "tokens": ["we", "also", "introduce", "a", "chemical", "potential", "\u00b5", "which", "is", "a", "constant", "source", "for", "fermion", "number", "in", "order", "to", "take", "account", "of", "the", "finite", "fermion", "density", "of", "the", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "introduce", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "introduce", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "account", "start": 104, "end": 111, "i_start": 19, "i_end": 19}}], "id": 1711}, {"sent": "first , we applied kernel density estimation using the spatstat package saccadic momentum model .", "tokens": ["first", ",", "we", "applied", "kernel", "density", "estimation", "using", "the", "spatstat", "package", "saccadic", "momentum", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "applied", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "applied", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}], "id": 1712}, {"sent": "we refer for instance to where the basis of this approach for problems coming from evolutionary biology were established .", "tokens": ["we", "refer", "for", "instance", "to", "where", "the", "basis", "of", "this", "approach", "for", "problems", "coming", "from", "evolutionary", "biology", "were", "established", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 1713}, {"sent": "privacy-preserving distributed mining of association rules on horizontally partitioned data .", "tokens": ["privacy", "-", "preserving", "distributed", "mining", "of", "association", "rules", "on", "horizontally", "partitioned", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1714}, {"sent": "recently , deep learning has achieved significant performances in many domains .", "tokens": ["recently", ",", "deep", "learning", "has", "achieved", "significant", "performances", "in", "many", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 11, "end": 24, "i_start": 2, "i_end": 3}, "verb": {"text": "has achieved", "start": 25, "end": 37, "i_start": 4, "i_end": 5}}, {"character": {"text": "learning", "start": 16, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}], "id": 1715}, {"sent": "the electron-ion interaction is described by the projector augmented-wave method .", "tokens": ["the", "electron", "-", "ion", "interaction", "is", "described", "by", "the", "projector", "augmented", "-", "wave", "method", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the electron-ion interaction", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "is described", "start": 29, "end": 41, "i_start": 5, "i_end": 6}}, {"character": {"text": "method", "start": 74, "end": 80, "i_start": 13, "i_end": 13}, "action": {"text": "described", "start": 32, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "electron", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "interaction", "start": 17, "end": 28, "i_start": 4, "i_end": 4}}], "id": 1716}, {"sent": "the average slug length increases along the tube due to the collection of particles resting between the slugs .", "tokens": ["the", "average", "slug", "length", "increases", "along", "the", "tube", "due", "to", "the", "collection", "of", "particles", "resting", "between", "the", "slugs", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1717}, {"sent": "krasnov , in black holes , gravitational radiation and the universe , b .", "tokens": ["krasnov", ",", "in", "black", "holes", ",", "gravitational", "radiation", "and", "the", "universe", ",", "b", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "gravitational", "start": 27, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "radiation", "start": 41, "end": 50, "i_start": 7, "i_end": 7}}], "id": 1718}, {"sent": "miramontes , the symmetric space and homogeneous sine-gordon theories , nucl .", "tokens": ["miramontes", ",", "the", "symmetric", "space", "and", "homogeneous", "sine", "-", "gordon", "theories", ",", "nucl", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1719}, {"sent": "suematsu et al reported that some spicules appear as double threads with evidence of spinning motion .", "tokens": ["suematsu", "et", "al", "reported", "that", "some", "spicules", "appear", "as", "double", "threads", "with", "evidence", "of", "spinning", "motion", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "suematsu et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "reported", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"subject": {"text": "some spicules", "start": 29, "end": 42, "i_start": 5, "i_end": 6}, "verb": {"text": "appear", "start": 43, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "suematsu", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "reported", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "threads", "start": 60, "end": 67, "i_start": 10, "i_end": 10}, "action": {"text": "evidence", "start": 73, "end": 81, "i_start": 12, "i_end": 12}}], "id": 1720}, {"sent": "methods based on learning multiple levels of representation have shown to be very effective to process natural data , especially in computer vision and natural language processing .", "tokens": ["methods", "based", "on", "learning", "multiple", "levels", "of", "representation", "have", "shown", "to", "be", "very", "effective", "to", "process", "natural", "data", ",", "especially", "in", "computer", "vision", "and", "natural", "language", "processing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "methods based on learning multiple levels of representation", "start": 0, "end": 59, "i_start": 0, "i_end": 7}, "verb": {"text": "have shown", "start": 60, "end": 70, "i_start": 8, "i_end": 9}}, {"character": {"text": "methods", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "effective", "start": 82, "end": 91, "i_start": 13, "i_end": 13}}], "id": 1721}, {"sent": "thus in this case the dynamical algebra is isomorphic to su .", "tokens": ["thus", "in", "this", "case", "the", "dynamical", "algebra", "is", "isomorphic", "to", "su", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dynamical algebra", "start": 18, "end": 39, "i_start": 4, "i_end": 6}, "verb": {"text": "is", "start": 40, "end": 42, "i_start": 7, "i_end": 7}}], "id": 1722}, {"sent": "first-principles calculations were performed with the vienna ab-initio simulation package package .", "tokens": ["first", "-", "principles", "calculations", "were", "performed", "with", "the", "vienna", "ab", "-", "initio", "simulation", "package", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "first-principles calculations", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "were performed", "start": 30, "end": 44, "i_start": 4, "i_end": 5}}], "id": 1723}, {"sent": "beginning in 2013 , the icecube collaboration has reported the observation of a diffuse flux of high-energy astrophysical neutrinos .", "tokens": ["beginning", "in", "2013", ",", "the", "icecube", "collaboration", "has", "reported", "the", "observation", "of", "a", "diffuse", "flux", "of", "high", "-", "energy", "astrophysical", "neutrinos", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the icecube collaboration", "start": 20, "end": 45, "i_start": 4, "i_end": 6}, "verb": {"text": "has reported", "start": 46, "end": 58, "i_start": 7, "i_end": 8}}, {"character": {"text": "collaboration", "start": 32, "end": 45, "i_start": 6, "i_end": 6}, "action": {"text": "reported", "start": 50, "end": 58, "i_start": 8, "i_end": 8}}], "id": 1724}, {"sent": "deep neural networks have given rise to major advancements in many problems of machine intelligence .", "tokens": ["deep", "neural", "networks", "have", "given", "rise", "to", "major", "advancements", "in", "many", "problems", "of", "machine", "intelligence", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have given", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "rise", "start": 32, "end": 36, "i_start": 5, "i_end": 5}}], "id": 1725}, {"sent": "this means that each agent of cgo possesses a search capability through a mix of both individual and social learning .", "tokens": ["this", "means", "that", "each", "agent", "of", "cgo", "possesses", "a", "search", "capability", "through", "a", "mix", "of", "both", "individual", "and", "social", "learning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "means", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "each agent of cgo", "start": 16, "end": 33, "i_start": 3, "i_end": 6}, "verb": {"text": "possesses", "start": 34, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "agent", "start": 21, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "possesses", "start": 34, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "agent", "start": 21, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "search", "start": 46, "end": 52, "i_start": 9, "i_end": 9}}], "id": 1726}, {"sent": "nowadays , the emerging science of networks has attracted a renewed interested in such models .", "tokens": ["nowadays", ",", "the", "emerging", "science", "of", "networks", "has", "attracted", "a", "renewed", "interested", "in", "such", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the emerging science of networks", "start": 11, "end": 43, "i_start": 2, "i_end": 6}, "verb": {"text": "has attracted", "start": 44, "end": 57, "i_start": 7, "i_end": 8}}, {"character": {"text": "science", "start": 24, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "attracted", "start": 48, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "science", "start": 24, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "emerging", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 1727}, {"sent": "recent experimental progress with cold atomic gases has opened the door for realizing quantum many-body systems and simulating some of the most useful models of many-body physics .", "tokens": ["recent", "experimental", "progress", "with", "cold", "atomic", "gases", "has", "opened", "the", "door", "for", "realizing", "quantum", "many", "-", "body", "systems", "and", "simulating", "some", "of", "the", "most", "useful", "models", "of", "many", "-", "body", "physics", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent experimental progress with cold atomic gases", "start": 0, "end": 51, "i_start": 0, "i_end": 6}, "verb": {"text": "has opened", "start": 52, "end": 62, "i_start": 7, "i_end": 8}}, {"character": {"text": "progress", "start": 20, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "opened", "start": 56, "end": 62, "i_start": 8, "i_end": 8}}], "id": 1728}, {"sent": "this might indicate that the metallicity is the missing ingredient , to understand the formation of ulxs , although the error bars are still very large and the sample of galaxies is quite small .", "tokens": ["this", "might", "indicate", "that", "the", "metallicity", "is", "the", "missing", "ingredient", ",", "to", "understand", "the", "formation", "of", "ulxs", ",", "although", "the", "error", "bars", "are", "still", "very", "large", "and", "the", "sample", "of", "galaxies", "is", "quite", "small", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "might indicate", "start": 5, "end": 19, "i_start": 1, "i_end": 2}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 41, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "indicate", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}], "id": 1729}, {"sent": "designing deeper and wider convolutional neural networks has led to significant breakthroughs in many machine learning tasks , such as image classification .", "tokens": ["designing", "deeper", "and", "wider", "convolutional", "neural", "networks", "has", "led", "to", "significant", "breakthroughs", "in", "many", "machine", "learning", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "designing deeper and wider convolutional neural networks", "start": 0, "end": 56, "i_start": 0, "i_end": 6}, "verb": {"text": "has led", "start": 57, "end": 64, "i_start": 7, "i_end": 8}}, {"character": {"text": "designing", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "led", "start": 61, "end": 64, "i_start": 8, "i_end": 8}}], "id": 1730}, {"sent": "the observation that the frequency of the identified system dynamics is limited to the sample frequency of the signal , used for identification of the model , is confirmed by the nyquistshannon theorem brigham .", "tokens": ["the", "observation", "that", "the", "frequency", "of", "the", "identified", "system", "dynamics", "is", "limited", "to", "the", "sample", "frequency", "of", "the", "signal", ",", "used", "for", "identification", "of", "the", "model", ",", "is", "confirmed", "by", "the", "nyquistshannon", "theorem", "brigham", "."], "score": [1, 0, 1, 0, 1], "labels": [{"subject": {"text": "the observation that the frequency of the identified system dynamics is limited to the sample frequency of the signal", "start": 0, "end": 117, "i_start": 0, "i_end": 18}, "verb": {"text": "is confirmed", "start": 159, "end": 171, "i_start": 27, "i_end": 28}}, {"character": {"text": "theorem", "start": 194, "end": 201, "i_start": 32, "i_end": 32}, "action": {"text": "confirmed", "start": 162, "end": 171, "i_start": 28, "i_end": 28}}], "id": 1731}, {"sent": "in several previous studies , it has been proved that one of the main characteristics of social networks is the presence of a large clustering coefficient and communities .", "tokens": ["in", "several", "previous", "studies", ",", "it", "has", "been", "proved", "that", "one", "of", "the", "main", "characteristics", "of", "social", "networks", "is", "the", "presence", "of", "a", "large", "clustering", "coefficient", "and", "communities", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "verb": {"text": "has been proved", "start": 33, "end": 48, "i_start": 6, "i_end": 8}}, {"subject": {"text": "it", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 105, "end": 107, "i_start": 18, "i_end": 18}}], "id": 1732}, {"sent": "we use the adam optimizer and apply dropout at all lstm layers .", "tokens": ["we", "use", "the", "adam", "optimizer", "and", "apply", "dropout", "at", "all", "lstm", "layers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "apply", "start": 30, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimizer", "start": 16, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "apply", "start": 30, "end": 35, "i_start": 6, "i_end": 6}}], "id": 1733}, {"sent": "a tranche is a portion of the loss of the portfolio between two percentages .", "tokens": ["a", "tranche", "is", "a", "portion", "of", "the", "loss", "of", "the", "portfolio", "between", "two", "percentages", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a tranche", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}], "id": 1734}, {"sent": "in the context of white lies , erat and gneezy reported that women are more likely than men to tell an altruistic white lie , but men are more likely than women to tell a pareto white lie .", "tokens": ["in", "the", "context", "of", "white", "lies", ",", "erat", "and", "gneezy", "reported", "that", "women", "are", "more", "likely", "than", "men", "to", "tell", "an", "altruistic", "white", "lie", ",", "but", "men", "are", "more", "likely", "than", "women", "to", "tell", "a", "pareto", "white", "lie", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "erat and gneezy", "start": 31, "end": 46, "i_start": 7, "i_end": 9}, "verb": {"text": "reported", "start": 47, "end": 55, "i_start": 10, "i_end": 10}}, {"subject": {"text": "erat and gneezy", "start": 31, "end": 46, "i_start": 7, "i_end": 9}, "verb": {"text": "are", "start": 67, "end": 70, "i_start": 13, "i_end": 13}}, {"character": {"text": "erat", "start": 31, "end": 35, "i_start": 7, "i_end": 7}, "action": {"text": "reported", "start": 47, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "gneezy", "start": 40, "end": 46, "i_start": 9, "i_end": 9}, "action": {"text": "reported", "start": 47, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "women", "start": 61, "end": 66, "i_start": 12, "i_end": 12}, "action": {"text": "tell", "start": 95, "end": 99, "i_start": 19, "i_end": 19}}, {"character": {"text": "women", "start": 61, "end": 66, "i_start": 12, "i_end": 12}, "action": {"text": "lies", "start": 24, "end": 28, "i_start": 5, "i_end": 5}}], "id": 1735}, {"sent": "feedback is the most important concept in control engineering , and has a long history going back at least to the mechanical governors used to regulate the speed of steam engines .", "tokens": ["feedback", "is", "the", "most", "important", "concept", "in", "control", "engineering", ",", "and", "has", "a", "long", "history", "going", "back", "at", "least", "to", "the", "mechanical", "governors", "used", "to", "regulate", "the", "speed", "of", "steam", "engines", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "feedback", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}, {"subject": {"text": "feedback", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "has", "start": 68, "end": 71, "i_start": 11, "i_end": 11}}], "id": 1736}, {"sent": "deep neural networks have been found to be quite effective for solving problems in the domain of computer vision .", "tokens": ["deep", "neural", "networks", "have", "been", "found", "to", "be", "quite", "effective", "for", "solving", "problems", "in", "the", "domain", "of", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been found", "start": 21, "end": 36, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "effective", "start": 49, "end": 58, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "solving", "start": 63, "end": 70, "i_start": 11, "i_end": 11}}], "id": 1737}, {"sent": "decoherence and the quantum to classical transition .", "tokens": ["decoherence", "and", "the", "quantum", "to", "classical", "transition", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1738}, {"sent": "the droplet is a positive-energy state and represents the created electron .", "tokens": ["the", "droplet", "is", "a", "positive", "-", "energy", "state", "and", "represents", "the", "created", "electron", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the droplet", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the droplet", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "represents", "start": 43, "end": 53, "i_start": 9, "i_end": 9}}, {"character": {"text": "state", "start": 33, "end": 38, "i_start": 7, "i_end": 7}, "action": {"text": "represents", "start": 43, "end": 53, "i_start": 9, "i_end": 9}}], "id": 1739}, {"sent": "with the rapid development of deep neural networks , computers now can achieve remarkable performance in many fields such as image classification .", "tokens": ["with", "the", "rapid", "development", "of", "deep", "neural", "networks", ",", "computers", "now", "can", "achieve", "remarkable", "performance", "in", "many", "fields", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "computers", "start": 53, "end": 62, "i_start": 9, "i_end": 9}, "verb": {"text": "can achieve", "start": 67, "end": 78, "i_start": 11, "i_end": 12}}, {"character": {"text": "computers", "start": 53, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "achieve", "start": 71, "end": 78, "i_start": 12, "i_end": 12}}, {"character": {"text": "computers", "start": 53, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "performance", "start": 90, "end": 101, "i_start": 14, "i_end": 14}}, {"character": {"text": "computers", "start": 53, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "classification", "start": 131, "end": 145, "i_start": 21, "i_end": 21}}], "id": 1740}, {"sent": "in msugra , there is a 1-1 correspondance between the parameters , and the interactions of light .", "tokens": ["in", "msugra", ",", "there", "is", "a", "1", "-", "1", "correspondance", "between", "the", "parameters", ",", "and", "the", "interactions", "of", "light", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 12, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 4, "i_end": 4}}, {"character": {"text": "light", "start": 91, "end": 96, "i_start": 18, "i_end": 18}, "action": {"text": "interactions", "start": 75, "end": 87, "i_start": 16, "i_end": 16}}], "id": 1741}, {"sent": "the kinetics of island and pit nucleation .", "tokens": ["the", "kinetics", "of", "island", "and", "pit", "nucleation", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1742}, {"sent": "convolutional neural networks have been largely responsible for the significant progress achieved on visual recognition tasks in recent years .", "tokens": ["convolutional", "neural", "networks", "have", "been", "largely", "responsible", "for", "the", "significant", "progress", "achieved", "on", "visual", "recognition", "tasks", "in", "recent", "years", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "responsible", "start": 48, "end": 59, "i_start": 6, "i_end": 6}}], "id": 1743}, {"sent": "goodfellow et al introduced a more efficient algorithm to form adversarial perturbations .", "tokens": ["goodfellow", "et", "al", "introduced", "a", "more", "efficient", "algorithm", "to", "form", "adversarial", "perturbations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "introduced", "start": 17, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "goodfellow", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 17, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "goodfellow", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "form", "start": 58, "end": 62, "i_start": 9, "i_end": 9}}], "id": 1744}, {"sent": "clearly sg is an infinite commutative interval group semiring .", "tokens": ["clearly", "sg", "is", "an", "infinite", "commutative", "interval", "group", "semiring", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "sg", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}], "id": 1745}, {"sent": "one of the central object in the study of scalar products of glinvariant models is the partition function of the six-vertex model with domain wall boundary conditions .", "tokens": ["one", "of", "the", "central", "object", "in", "the", "study", "of", "scalar", "products", "of", "glinvariant", "models", "is", "the", "partition", "function", "of", "the", "six", "-", "vertex", "model", "with", "domain", "wall", "boundary", "conditions", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "one of the central object in the study of scalar products of glinvariant models", "start": 0, "end": 79, "i_start": 0, "i_end": 13}, "verb": {"text": "is", "start": 80, "end": 82, "i_start": 14, "i_end": 14}}, {"character": {"text": "models", "start": 73, "end": 79, "i_start": 13, "i_end": 13}, "action": {"text": "function", "start": 97, "end": 105, "i_start": 17, "i_end": 17}}], "id": 1746}, {"sent": "exchange and correlations are considered in the generalized gradient approximation , following the perdew-burke-ernzerhof parametrization scheme .", "tokens": ["exchange", "and", "correlations", "are", "considered", "in", "the", "generalized", "gradient", "approximation", ",", "following", "the", "perdew", "-", "burke", "-", "ernzerhof", "parametrization", "scheme", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "exchange and correlations", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "are considered", "start": 26, "end": 40, "i_start": 3, "i_end": 4}}], "id": 1747}, {"sent": "in narrow qws the measured optical polarization is smaller than the calculated electron spin polarization due to initial spin relaxation .", "tokens": ["in", "narrow", "qws", "the", "measured", "optical", "polarization", "is", "smaller", "than", "the", "calculated", "electron", "spin", "polarization", "due", "to", "initial", "spin", "relaxation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the measured optical polarization", "start": 14, "end": 47, "i_start": 3, "i_end": 6}, "verb": {"text": "is", "start": 48, "end": 50, "i_start": 7, "i_end": 7}}], "id": 1748}, {"sent": "this is a tractable problem and uses the implication graph method of .", "tokens": ["this", "is", "a", "tractable", "problem", "and", "uses", "the", "implication", "graph", "method", "of", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "uses", "start": 32, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "problem", "start": 20, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "uses", "start": 32, "end": 36, "i_start": 6, "i_end": 6}}], "id": 1749}, {"sent": "we assume familiarity with the basic definitions of communication complexity .", "tokens": ["we", "assume", "familiarity", "with", "the", "basic", "definitions", "of", "communication", "complexity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 1750}, {"sent": "later , neural network approaches have greatly improved the performance of word representation learning .", "tokens": ["later", ",", "neural", "network", "approaches", "have", "greatly", "improved", "the", "performance", "of", "word", "representation", "learning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural network approaches", "start": 8, "end": 33, "i_start": 2, "i_end": 4}, "verb": {"text": "improved", "start": 47, "end": 55, "i_start": 7, "i_end": 7}}, {"subject": {"text": "neural network approaches", "start": 8, "end": 33, "i_start": 2, "i_end": 4}, "verb": {"text": "have", "start": 34, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "approaches", "start": 23, "end": 33, "i_start": 4, "i_end": 4}, "action": {"text": "improved", "start": 47, "end": 55, "i_start": 7, "i_end": 7}}, {"character": {"text": "learning", "start": 95, "end": 103, "i_start": 13, "i_end": 13}, "action": {"text": "performance", "start": 60, "end": 71, "i_start": 9, "i_end": 9}}], "id": 1751}, {"sent": "deep neural networks are at the core of state-of-the-art models for supervised tasks like image recognition and speech recognition .", "tokens": ["deep", "neural", "networks", "are", "at", "the", "core", "of", "state", "-", "of", "-", "the", "-", "art", "models", "for", "supervised", "tasks", "like", "image", "recognition", "and", "speech", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}], "id": 1752}, {"sent": "as emphasizes , multitask learning improves generalization by using the domain information contained in the training signals of related tasks .", "tokens": ["as", "emphasizes", ",", "multitask", "learning", "improves", "generalization", "by", "using", "the", "domain", "information", "contained", "in", "the", "training", "signals", "of", "related", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "multitask learning", "start": 16, "end": 34, "i_start": 3, "i_end": 4}, "verb": {"text": "improves", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "learning", "start": 26, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "improves", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "signals", "start": 117, "end": 124, "i_start": 16, "i_end": 16}, "action": {"text": "contained", "start": 91, "end": 100, "i_start": 12, "i_end": 12}}], "id": 1753}, {"sent": "collobert et al first implements convolutional neural networks with the crf objective .", "tokens": ["collobert", "et", "al", "first", "implements", "convolutional", "neural", "networks", "with", "the", "crf", "objective", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "collobert et al", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "implements", "start": 22, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "collobert", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "implements", "start": 22, "end": 32, "i_start": 4, "i_end": 4}}], "id": 1754}, {"sent": "these algorithms have found applications in various fields like factoring polynomials over rationals .", "tokens": ["these", "algorithms", "have", "found", "applications", "in", "various", "fields", "like", "factoring", "polynomials", "over", "rationals", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "these algorithms", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "have found", "start": 17, "end": 27, "i_start": 2, "i_end": 3}}, {"character": {"text": "algorithms", "start": 6, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "found", "start": 22, "end": 27, "i_start": 3, "i_end": 3}}], "id": 1755}, {"sent": "the coefficient t is the hopping energy between adjacent sites , and u is the on-site interaction energy .", "tokens": ["the", "coefficient", "t", "is", "the", "hopping", "energy", "between", "adjacent", "sites", ",", "and", "u", "is", "the", "on", "-", "site", "interaction", "energy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the coefficient t", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}], "id": 1756}, {"sent": "the best known representatives for generative models are variational autoencoders and generative adversarial networks .", "tokens": ["the", "best", "known", "representatives", "for", "generative", "models", "are", "variational", "autoencoders", "and", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the best known representatives for generative models", "start": 0, "end": 52, "i_start": 0, "i_end": 6}, "verb": {"text": "are", "start": 53, "end": 56, "i_start": 7, "i_end": 7}}], "id": 1757}, {"sent": "li et al proposed a encoder-decoder based framework for both rating prediction and generating tips .", "tokens": ["li", "et", "al", "proposed", "a", "encoder", "-", "decoder", "based", "framework", "for", "both", "rating", "prediction", "and", "generating", "tips", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "li et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "li", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}], "id": 1758}, {"sent": "devinney et al , marchette and priebe , priebe et al , priebe et al , and devinney and priebe applied the concept in higher dimensions and demonstrated relatively good performance of cccds in classification .", "tokens": ["devinney", "et", "al", ",", "marchette", "and", "priebe", ",", "priebe", "et", "al", ",", "priebe", "et", "al", ",", "and", "devinney", "and", "priebe", "applied", "the", "concept", "in", "higher", "dimensions", "and", "demonstrated", "relatively", "good", "performance", "of", "cccds", "in", "classification", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "devinney et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "applied", "start": 94, "end": 101, "i_start": 20, "i_end": 20}}, {"subject": {"text": "devinney et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "demonstrated", "start": 139, "end": 151, "i_start": 27, "i_end": 27}}, {"character": {"text": "devinney et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "action": {"text": "applied", "start": 94, "end": 101, "i_start": 20, "i_end": 20}}, {"character": {"text": "marchette and priebe , priebe et al , priebe et al , and devinney and", "start": 17, "end": 86, "i_start": 4, "i_end": 18}, "action": {"text": "applied", "start": 94, "end": 101, "i_start": 20, "i_end": 20}}, {"character": {"text": "priebe et al", "start": 40, "end": 52, "i_start": 8, "i_end": 10}, "action": {"text": "applied", "start": 94, "end": 101, "i_start": 20, "i_end": 20}}, {"character": {"text": "priebe et al", "start": 55, "end": 67, "i_start": 12, "i_end": 14}, "action": {"text": "applied", "start": 94, "end": 101, "i_start": 20, "i_end": 20}}, {"character": {"text": "and", "start": 135, "end": 138, "i_start": 26, "i_end": 26}, "action": {"text": "applied", "start": 94, "end": 101, "i_start": 20, "i_end": 20}}, {"character": {"text": "devinney et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "action": {"text": "applied", "start": 94, "end": 101, "i_start": 20, "i_end": 20}}, {"character": {"text": "priebe et al", "start": 40, "end": 52, "i_start": 8, "i_end": 10}, "action": {"text": "applied", "start": 94, "end": 101, "i_start": 20, "i_end": 20}}], "id": 1759}, {"sent": "ganin et al applies adversarial training for achieving maximal confusion between the two domains .", "tokens": ["ganin", "et", "al", "applies", "adversarial", "training", "for", "achieving", "maximal", "confusion", "between", "the", "two", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "ganin et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "applies", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "ganin", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "applies", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}], "id": 1760}, {"sent": "several methods have been proposed to generate adversarial examples with the knowledge of the gradient information of a given model , such as fast gradient sign method , which are known as white-box attacks .", "tokens": ["several", "methods", "have", "been", "proposed", "to", "generate", "adversarial", "examples", "with", "the", "knowledge", "of", "the", "gradient", "information", "of", "a", "given", "model", ",", "such", "as", "fast", "gradient", "sign", "method", ",", "which", "are", "known", "as", "white", "-", "box", "attacks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "several methods", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have been proposed", "start": 16, "end": 34, "i_start": 2, "i_end": 4}}], "id": 1761}, {"sent": "we shall present both motivations in this chapter .", "tokens": ["we", "shall", "present", "both", "motivations", "in", "this", "chapter", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "shall present", "start": 3, "end": 16, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "present", "start": 9, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1762}, {"sent": "supervised deep learning has recently improved the state-of-the-art in various tasks , such as image classification .", "tokens": ["supervised", "deep", "learning", "has", "recently", "improved", "the", "state", "-", "of", "-", "the", "-", "art", "in", "various", "tasks", ",", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "learning", "start": 16, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "improved", "start": 38, "end": 46, "i_start": 5, "i_end": 5}}], "id": 1763}, {"sent": "it provides a refinement of a result of barannikov and kontsevich , where only the underlying frobenius manifold structure is considered .", "tokens": ["it", "provides", "a", "refinement", "of", "a", "result", "of", "barannikov", "and", "kontsevich", ",", "where", "only", "the", "underlying", "frobenius", "manifold", "structure", "is", "considered", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "provides", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "provides", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "structure", "start": 113, "end": 122, "i_start": 18, "i_end": 18}, "action": {"text": "underlying", "start": 83, "end": 93, "i_start": 15, "i_end": 15}}], "id": 1764}, {"sent": "along this direction , convolutional neural networks have been very successful in various computer vision and natural language processing tasks in recent years .", "tokens": ["along", "this", "direction", ",", "convolutional", "neural", "networks", "have", "been", "very", "successful", "in", "various", "computer", "vision", "and", "natural", "language", "processing", "tasks", "in", "recent", "years", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 23, "end": 52, "i_start": 4, "i_end": 6}, "verb": {"text": "have been", "start": 53, "end": 62, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "successful", "start": 68, "end": 78, "i_start": 10, "i_end": 10}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "processing", "start": 127, "end": 137, "i_start": 18, "i_end": 18}}], "id": 1765}, {"sent": "li et al proposed a recursive neural network based on an autoencoder to generate the hierarchical structure of shapes .", "tokens": ["li", "et", "al", "proposed", "a", "recursive", "neural", "network", "based", "on", "an", "autoencoder", "to", "generate", "the", "hierarchical", "structure", "of", "shapes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "li et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "li", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "network", "start": 37, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "generate", "start": 72, "end": 80, "i_start": 13, "i_end": 13}}], "id": 1766}, {"sent": "every strongly partition regular family is , in particular , weakly partition regular .", "tokens": ["every", "strongly", "partition", "regular", "family", "is", ",", "in", "particular", ",", "weakly", "partition", "regular", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "every strongly partition regular family", "start": 0, "end": 39, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 40, "end": 42, "i_start": 5, "i_end": 5}}], "id": 1767}, {"sent": "for more comprehensive evaluations , we compare our lmsco with nine state-of-the-art trackers on vot-tir2016 benchmark , including mdnet .", "tokens": ["for", "more", "comprehensive", "evaluations", ",", "we", "compare", "our", "lmsco", "with", "nine", "state", "-", "of", "-", "the", "-", "art", "trackers", "on", "vot", "-", "tir2016", "benchmark", ",", "including", "mdnet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 37, "end": 39, "i_start": 5, "i_end": 5}, "verb": {"text": "compare", "start": 40, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 37, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "compare", "start": 40, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "nine", "start": 63, "end": 67, "i_start": 10, "i_end": 10}, "action": {"text": "trackers", "start": 85, "end": 93, "i_start": 18, "i_end": 18}}], "id": 1768}, {"sent": "this gauge transformation is a consequence of the invariance of the original theory under diffeomorphisms of the internal manifold1 .", "tokens": ["this", "gauge", "transformation", "is", "a", "consequence", "of", "the", "invariance", "of", "the", "original", "theory", "under", "diffeomorphisms", "of", "the", "internal", "manifold1", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this gauge transformation", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 3, "i_end": 3}}], "id": 1769}, {"sent": "cfr works based on the fact that minimizing the regrets of both players makes the time-averaged strategy to approach the nash equilibrium .", "tokens": ["cfr", "works", "based", "on", "the", "fact", "that", "minimizing", "the", "regrets", "of", "both", "players", "makes", "the", "time", "-", "averaged", "strategy", "to", "approach", "the", "nash", "equilibrium", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cfr", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "works", "start": 4, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "both", "start": 59, "end": 63, "i_start": 11, "i_end": 11}, "action": {"text": "regrets", "start": 48, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "minimizing", "start": 33, "end": 43, "i_start": 7, "i_end": 7}, "action": {"text": "makes", "start": 72, "end": 77, "i_start": 13, "i_end": 13}}, {"character": {"text": "strategy", "start": 96, "end": 104, "i_start": 18, "i_end": 18}, "action": {"text": "averaged", "start": 87, "end": 95, "i_start": 17, "i_end": 17}}], "id": 1770}, {"sent": "these network non-linearities have been exploited by researchers who have demonstrated microfluidic memory , logic , and control devices .", "tokens": ["these", "network", "non", "-", "linearities", "have", "been", "exploited", "by", "researchers", "who", "have", "demonstrated", "microfluidic", "memory", ",", "logic", ",", "and", "control", "devices", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "these network non-linearities", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "have been exploited", "start": 30, "end": 49, "i_start": 5, "i_end": 7}}, {"character": {"text": "memory", "start": 100, "end": 106, "i_start": 14, "i_end": 14}, "action": {"text": "exploited", "start": 40, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "microfluidic", "start": 87, "end": 99, "i_start": 13, "i_end": 13}, "action": {"text": "exploited", "start": 40, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "logic", "start": 109, "end": 114, "i_start": 16, "i_end": 16}, "action": {"text": "exploited", "start": 40, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "devices", "start": 129, "end": 136, "i_start": 20, "i_end": 20}, "action": {"text": "exploited", "start": 40, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "devices", "start": 129, "end": 136, "i_start": 20, "i_end": 20}, "action": {"text": "control", "start": 121, "end": 128, "i_start": 19, "i_end": 19}}], "id": 1771}, {"sent": "in particular we recover the fact that the superspace formalism of is naturally formulated in a frame different from the einstein frame .", "tokens": ["in", "particular", "we", "recover", "the", "fact", "that", "the", "superspace", "formalism", "of", "is", "naturally", "formulated", "in", "a", "frame", "different", "from", "the", "einstein", "frame", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "recover", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "recover", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}], "id": 1772}, {"sent": "knus , quadratic and hermitian forms over rings , grundlehren der math .", "tokens": ["knus", ",", "quadratic", "and", "hermitian", "forms", "over", "rings", ",", "grundlehren", "der", "math", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1773}, {"sent": "expectation maximization is an iterative algorithm used for finding maximum likelihood estimates of the parameters of a given statistical model and a group of data .", "tokens": ["expectation", "maximization", "is", "an", "iterative", "algorithm", "used", "for", "finding", "maximum", "likelihood", "estimates", "of", "the", "parameters", "of", "a", "given", "statistical", "model", "and", "a", "group", "of", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "expectation maximization", "start": 0, "end": 24, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 2, "i_end": 2}}], "id": 1774}, {"sent": "zhao et al perform salient object detection through a deep learning framework considering local and global image context .", "tokens": ["zhao", "et", "al", "perform", "salient", "object", "detection", "through", "a", "deep", "learning", "framework", "considering", "local", "and", "global", "image", "context", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhao et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "perform", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhao", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "perform", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhao", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "detection", "start": 34, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "framework", "start": 68, "end": 77, "i_start": 11, "i_end": 11}, "action": {"text": "considering", "start": 78, "end": 89, "i_start": 12, "i_end": 12}}], "id": 1775}, {"sent": "adversarial networks have achieved much success in various studies , especially in image and text generation .", "tokens": ["adversarial", "networks", "have", "achieved", "much", "success", "in", "various", "studies", ",", "especially", "in", "image", "and", "text", "generation", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "adversarial networks", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 2, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 1, "i_end": 1}, "action": {"text": "success", "start": 40, "end": 47, "i_start": 5, "i_end": 5}}], "id": 1776}, {"sent": "shokri et al propose the first membership inference attack against machine learning models .", "tokens": ["shokri", "et", "al", "propose", "the", "first", "membership", "inference", "attack", "against", "machine", "learning", "models", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 7, "end": 12, "i_start": 1, "i_end": 2}, "verb": {"text": "propose", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "shokri", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}], "id": 1777}, {"sent": "for example , the swing equations are inaccurate and only valid on a specific time scale up to the order of a few seconds so that asymptotic stability results have a limited value for the actual system .", "tokens": ["for", "example", ",", "the", "swing", "equations", "are", "inaccurate", "and", "only", "valid", "on", "a", "specific", "time", "scale", "up", "to", "the", "order", "of", "a", "few", "seconds", "so", "that", "asymptotic", "stability", "results", "have", "a", "limited", "value", "for", "the", "actual", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the swing equations", "start": 14, "end": 33, "i_start": 3, "i_end": 5}, "verb": {"text": "are", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}], "id": 1778}, {"sent": "we make use of the formula for the i-and k-bessel functions .", "tokens": ["we", "make", "use", "of", "the", "formula", "for", "the", "i-"], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "make", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}], "id": 1779}, {"sent": "the popular reduced-rank schemes include the auxiliary vector filtering , the multistage wiener filter , and the joint iterative optimization .", "tokens": ["the", "popular", "reduced", "-", "rank", "schemes", "include", "the", "auxiliary", "vector", "filtering", ",", "the", "multistage", "wiener", "filter", ",", "and", "the", "joint", "iterative", "optimization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the popular reduced-rank schemes", "start": 0, "end": 32, "i_start": 0, "i_end": 5}, "verb": {"text": "include", "start": 33, "end": 40, "i_start": 6, "i_end": 6}}], "id": 1780}, {"sent": "the gravitino is the lsp , all cascades will ultimately end in a gravitino .", "tokens": ["the", "gravitino", "is", "the", "lsp", ",", "all", "cascades", "will", "ultimately", "end", "in", "a", "gravitino", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all cascades", "start": 27, "end": 39, "i_start": 6, "i_end": 7}, "verb": {"text": "end", "start": 56, "end": 59, "i_start": 10, "i_end": 10}}, {"subject": {"text": "all cascades", "start": 27, "end": 39, "i_start": 6, "i_end": 7}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"subject": {"text": "all cascades", "start": 27, "end": 39, "i_start": 6, "i_end": 7}, "verb": {"text": "will", "start": 40, "end": 44, "i_start": 8, "i_end": 8}}], "id": 1781}, {"sent": "moreover , it was shown in , the dirichlet-to-neumann map is a nonnegative self-adjoint first order elliptic pseudo differential operator .", "tokens": ["moreover", ",", "it", "was", "shown", "in", ",", "the", "dirichlet", "-", "to", "-", "neumann", "map", "is", "a", "nonnegative", "self", "-", "adjoint", "first", "order", "elliptic", "pseudo", "differential", "operator", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dirichlet-to-neumann map", "start": 29, "end": 57, "i_start": 7, "i_end": 13}, "verb": {"text": "is", "start": 58, "end": 60, "i_start": 14, "i_end": 14}}, {"subject": {"text": "it", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "verb": {"text": "shown", "start": 18, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "map", "start": 54, "end": 57, "i_start": 13, "i_end": 13}, "action": {"text": "operator", "start": 129, "end": 137, "i_start": 25, "i_end": 25}}], "id": 1782}, {"sent": "we use the resnet50 model and extract the features from the third convolutional block .", "tokens": ["we", "use", "the", "resnet50", "model", "and", "extract", "the", "features", "from", "the", "third", "convolutional", "block", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "extract", "start": 30, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extract", "start": 30, "end": 37, "i_start": 6, "i_end": 6}}], "id": 1783}, {"sent": "we implement our kpm hourglass network based on the resnet-50 , which is pretrained on the imagenet dataset .", "tokens": ["we", "implement", "our", "kpm", "hourglass", "network", "based", "on", "the", "resnet-50", ",", "which", "is", "pretrained", "on", "the", "imagenet", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}], "id": 1784}, {"sent": "the nuclear norm is essentially an 1 norm of the singular values and it is well known that 1 norm has a shrinkage effect and leads to a biased estimator .", "tokens": ["the", "nuclear", "norm", "is", "essentially", "an", "1", "norm", "of", "the", "singular", "values", "and", "it", "is", "well", "known", "that", "1", "norm", "has", "a", "shrinkage", "effect", "and", "leads", "to", "a", "biased", "estimator", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the nuclear norm", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "norm is essentially an 1", "start": 12, "end": 36, "i_start": 2, "i_end": 6}, "action": {"text": "effect", "start": 114, "end": 120, "i_start": 23, "i_end": 23}}, {"character": {"text": "norm is essentially an 1", "start": 12, "end": 36, "i_start": 2, "i_end": 6}, "action": {"text": "leads", "start": 125, "end": 130, "i_start": 25, "i_end": 25}}], "id": 1785}, {"sent": "variational autoencoders are a powerful deep generative framework to capture latent structure in complex data .", "tokens": ["variational", "autoencoders", "are", "a", "powerful", "deep", "generative", "framework", "to", "capture", "latent", "structure", "in", "complex", "data", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "variational autoencoders", "start": 0, "end": 24, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 25, "end": 28, "i_start": 2, "i_end": 2}}, {"character": {"text": "autoencoders", "start": 12, "end": 24, "i_start": 1, "i_end": 1}, "action": {"text": "capture", "start": 69, "end": 76, "i_start": 9, "i_end": 9}}], "id": 1786}, {"sent": "deep neural networks have recently led to significant improvements in many fields , such as image classification .", "tokens": ["deep", "neural", "networks", "have", "recently", "led", "to", "significant", "improvements", "in", "many", "fields", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "led", "start": 35, "end": 38, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "led", "start": 35, "end": 38, "i_start": 5, "i_end": 5}}], "id": 1787}, {"sent": "string theory is a promising candidate for a fundamental theory , but there are significant obstacles to deriving convincing models of inflation from string theory .", "tokens": ["string", "theory", "is", "a", "promising", "candidate", "for", "a", "fundamental", "theory", ",", "but", "there", "are", "significant", "obstacles", "to", "deriving", "convincing", "models", "of", "inflation", "from", "string", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "string theory", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"subject": {"text": "there", "start": 70, "end": 75, "i_start": 12, "i_end": 12}, "verb": {"text": "are", "start": 76, "end": 79, "i_start": 13, "i_end": 13}}, {"character": {"text": "candidate", "start": 29, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "promising", "start": 19, "end": 28, "i_start": 4, "i_end": 4}}], "id": 1788}, {"sent": "we now extend the rear-surface integral method for calculating thermal diffusivity to non-instantaneous heat pulse durations .", "tokens": ["we", "now", "extend", "the", "rear", "-", "surface", "integral", "method", "for", "calculating", "thermal", "diffusivity", "to", "non", "-", "instantaneous", "heat", "pulse", "durations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "extend", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extend", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}], "id": 1789}, {"sent": "in the chemical context , a two-port r component represents a chemical reaction with chemical affinity replacing voltage and molar flow replacing current , oster et al , 1971 , oster et al , 1973 .", "tokens": ["in", "the", "chemical", "context", ",", "a", "two", "-", "port", "r", "component", "represents", "a", "chemical", "reaction", "with", "chemical", "affinity", "replacing", "voltage", "and", "molar", "flow", "replacing", "current", ",", "oster", "et", "al", ",", "1971", ",", "oster", "et", "al", ",", "1973", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a two-port r component", "start": 26, "end": 48, "i_start": 5, "i_end": 10}, "verb": {"text": "represents", "start": 49, "end": 59, "i_start": 11, "i_end": 11}}, {"character": {"text": "component", "start": 39, "end": 48, "i_start": 10, "i_end": 10}, "action": {"text": "represents", "start": 49, "end": 59, "i_start": 11, "i_end": 11}}, {"character": {"text": "reaction", "start": 71, "end": 79, "i_start": 14, "i_end": 14}, "action": {"text": "replacing", "start": 103, "end": 112, "i_start": 18, "i_end": 18}}, {"character": {"text": "reaction", "start": 71, "end": 79, "i_start": 14, "i_end": 14}, "action": {"text": "replacing", "start": 136, "end": 145, "i_start": 23, "i_end": 23}}], "id": 1790}, {"sent": "in 1950 nash introduced his concept of equilibrium for the normal form n-person games .", "tokens": ["in", "1950", "nash", "introduced", "his", "concept", "of", "equilibrium", "for", "the", "normal", "form", "n", "-", "person", "games", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "nash", "start": 8, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "introduced", "start": 13, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "nash", "start": 8, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 13, "end": 23, "i_start": 3, "i_end": 3}}], "id": 1791}, {"sent": "however , as shown in minimally coupling the matter sector to more than one metric generically introduces the propagation of ghost-like degrees of freedom already at the classical level .", "tokens": ["however", ",", "as", "shown", "in", "minimally", "coupling", "the", "matter", "sector", "to", "more", "than", "one", "metric", "generically", "introduces", "the", "propagation", "of", "ghost", "-", "like", "degrees", "of", "freedom", "already", "at", "the", "classical", "level", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "coupling", "start": 32, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "introduces", "start": 95, "end": 105, "i_start": 16, "i_end": 16}}], "id": 1792}, {"sent": "the vacuum configuration of the model is obtained by minimizing the effective potential numerically .", "tokens": ["the", "vacuum", "configuration", "of", "the", "model", "is", "obtained", "by", "minimizing", "the", "effective", "potential", "numerically", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the vacuum configuration of the model", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "is obtained", "start": 38, "end": 49, "i_start": 6, "i_end": 7}}, {"character": {"text": "potential", "start": 78, "end": 87, "i_start": 12, "i_end": 12}, "action": {"text": "effective", "start": 68, "end": 77, "i_start": 11, "i_end": 11}}], "id": 1793}, {"sent": "the metallicity is the log of the ratio of the amount of iron to hydrogen in the stars relative to the sun .", "tokens": ["the", "metallicity", "is", "the", "log", "of", "the", "ratio", "of", "the", "amount", "of", "iron", "to", "hydrogen", "in", "the", "stars", "relative", "to", "the", "sun", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the metallicity", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 1794}, {"sent": "this result has been extended to many scenarios , including decentralized caching , among others .", "tokens": ["this", "result", "has", "been", "extended", "to", "many", "scenarios", ",", "including", "decentralized", "caching", ",", "among", "others", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this result", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "has been extended", "start": 12, "end": 29, "i_start": 2, "i_end": 4}}], "id": 1795}, {"sent": "the eigenvalue decomposition ofm 3 has a complexity of o k 4 logto compute each of the k eigenvectors up to an accuracy of .", "tokens": ["the", "eigenvalue", "decomposition", "ofm", "3", "has", "a", "complexity", "of", "o", "k", "4", "logto", "compute", "each", "of", "the", "k", "eigenvectors", "up", "to", "an", "accuracy", "of", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the eigenvalue decomposition ofm 3", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "has", "start": 35, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "decomposition", "start": 15, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "has", "start": 35, "end": 38, "i_start": 5, "i_end": 5}}], "id": 1796}, {"sent": "the scattering transform exhibits the same amount of time-shift invariance and time-warping stability as the mel-spectrogram described previously .", "tokens": ["the", "scattering", "transform", "exhibits", "the", "same", "amount", "of", "time", "-", "shift", "invariance", "and", "time", "-", "warping", "stability", "as", "the", "mel", "-", "spectrogram", "described", "previously", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "transform", "start": 15, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "exhibits", "start": 25, "end": 33, "i_start": 3, "i_end": 3}}], "id": 1797}, {"sent": "cognitive radio as a dynamic spectrum access enabling technique allows unlicensed users to communicate with each other over the unused licensed bands detected through spectrum sensing .", "tokens": ["cognitive", "radio", "as", "a", "dynamic", "spectrum", "access", "enabling", "technique", "allows", "unlicensed", "users", "to", "communicate", "with", "each", "other", "over", "the", "unused", "licensed", "bands", "detected", "through", "spectrum", "sensing", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "cognitive radio as a dynamic spectrum access enabling technique", "start": 0, "end": 63, "i_start": 0, "i_end": 8}, "verb": {"text": "allows", "start": 64, "end": 70, "i_start": 9, "i_end": 9}}, {"subject": {"text": "unlicensed users", "start": 71, "end": 87, "i_start": 10, "i_end": 11}, "verb": {"text": "communicate", "start": 91, "end": 102, "i_start": 13, "i_end": 13}}, {"character": {"text": "radio", "start": 10, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "allows", "start": 64, "end": 70, "i_start": 9, "i_end": 9}}, {"character": {"text": "technique", "start": 54, "end": 63, "i_start": 8, "i_end": 8}, "action": {"text": "enabling", "start": 45, "end": 53, "i_start": 7, "i_end": 7}}], "id": 1798}, {"sent": "in 1980 pease , shostak and lamport introduced the problem of byzantine agreement , a fundamental problem in fault-tolerant distributed computing .", "tokens": ["in", "1980", "pease", ",", "shostak", "and", "lamport", "introduced", "the", "problem", "of", "byzantine", "agreement", ",", "a", "fundamental", "problem", "in", "fault", "-", "tolerant", "distributed", "computing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "shostak and lamport", "start": 16, "end": 35, "i_start": 4, "i_end": 6}, "verb": {"text": "introduced", "start": 36, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "pease", "start": 8, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 36, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "shostak", "start": 16, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "introduced", "start": 36, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "lamport", "start": 28, "end": 35, "i_start": 6, "i_end": 6}, "action": {"text": "introduced", "start": 36, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "computing", "start": 136, "end": 145, "i_start": 22, "i_end": 22}, "action": {"text": "tolerant", "start": 115, "end": 123, "i_start": 20, "i_end": 20}}], "id": 1799}, {"sent": "the technique for proving this result is very much the same as for proving the existence of f .", "tokens": ["the", "technique", "for", "proving", "this", "result", "is", "very", "much", "the", "same", "as", "for", "proving", "the", "existence", "of", "f", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the technique for proving this result", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 6, "i_end": 6}}], "id": 1800}, {"sent": "the geometry we adopt ( fig 4 is the same as the one adopted by tbb6 .", "tokens": ["the", "geometry", "we", "adopt", "(", "fig", "4", "is", "the", "same", "as", "the", "one", "adopted", "by", "tbb6", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the geometry we adopt ( fig 4", "start": 0, "end": 29, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "adopt", "start": 16, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "tbb6", "start": 64, "end": 68, "i_start": 15, "i_end": 15}, "action": {"text": "adopted", "start": 53, "end": 60, "i_start": 13, "i_end": 13}}], "id": 1801}, {"sent": "we implement descriptor learning using a siamese residual network architecture .", "tokens": ["we", "implement", "descriptor", "learning", "using", "a", "siamese", "residual", "network", "architecture", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 33, "end": 38, "i_start": 4, "i_end": 4}}], "id": 1802}, {"sent": "for imagenet , we use a resnet-50 architecture using the code from the tensorpack repository .", "tokens": ["for", "imagenet", ",", "we", "use", "a", "resnet-50", "architecture", "using", "the", "code", "from", "the", "tensorpack", "repository", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "use", "start": 18, "end": 21, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 18, "end": 21, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "using", "start": 47, "end": 52, "i_start": 8, "i_end": 8}}], "id": 1803}, {"sent": "the \u03c3-compatibility condition in a3 is closely related to the restricted eigenvalue assumption introduced in bickel et al .", "tokens": ["the", "\u03c3", "-", "compatibility", "condition", "in", "a3", "is", "closely", "related", "to", "the", "restricted", "eigenvalue", "assumption", "introduced", "in", "bickel", "et", "al", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the \u03c3-compatibility condition in a3", "start": 0, "end": 35, "i_start": 0, "i_end": 6}, "verb": {"text": "related", "start": 47, "end": 54, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the \u03c3-compatibility condition in a3", "start": 0, "end": 35, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 36, "end": 38, "i_start": 7, "i_end": 7}}], "id": 1804}, {"sent": "convolutional neural networks have achieved notable successes in a variety of visual recognition tasks , such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "notable", "successes", "in", "a", "variety", "of", "visual", "recognition", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successes", "start": 52, "end": 61, "i_start": 6, "i_end": 6}}], "id": 1805}, {"sent": "mrk 291 mrk 291 is a sy2 galaxy , it has a bar and two spiral arms started at the end of the bar .", "tokens": ["mrk", "291", "mrk", "291", "is", "a", "sy2", "galaxy", ",", "it", "has", "a", "bar", "and", "two", "spiral", "arms", "started", "at", "the", "end", "of", "the", "bar", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "two spiral arms", "start": 51, "end": 66, "i_start": 14, "i_end": 16}, "verb": {"text": "has", "start": 37, "end": 40, "i_start": 10, "i_end": 10}}, {"subject": {"text": "it", "start": 34, "end": 36, "i_start": 9, "i_end": 9}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 4, "i_end": 4}}, {"subject": {"text": "it", "start": 34, "end": 36, "i_start": 9, "i_end": 9}, "verb": {"text": "started", "start": 67, "end": 74, "i_start": 17, "i_end": 17}}, {"character": {"text": "galaxy", "start": 25, "end": 31, "i_start": 7, "i_end": 7}, "action": {"text": "has", "start": 37, "end": 40, "i_start": 10, "i_end": 10}}], "id": 1806}, {"sent": "in , the variablesized online bin packing problem is studied and a new algorithm is proposed and its upper bound is analyzed .", "tokens": ["in", ",", "the", "variablesized", "online", "bin", "packing", "problem", "is", "studied", "and", "a", "new", "algorithm", "is", "proposed", "and", "its", "upper", "bound", "is", "analyzed", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the variablesized online bin packing problem", "start": 5, "end": 49, "i_start": 2, "i_end": 7}, "verb": {"text": "is studied", "start": 50, "end": 60, "i_start": 8, "i_end": 9}}, {"subject": {"text": "a new algorithm", "start": 65, "end": 80, "i_start": 11, "i_end": 13}, "verb": {"text": "proposed", "start": 84, "end": 92, "i_start": 15, "i_end": 15}}], "id": 1807}, {"sent": "there have been quite a quantity of modelingbased age progression methods proposed , including active appearance model , etc .", "tokens": ["there", "have", "been", "quite", "a", "quantity", "of", "modelingbased", "age", "progression", "methods", "proposed", ",", "including", "active", "appearance", "model", ",", "etc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "have been", "start": 6, "end": 15, "i_start": 1, "i_end": 2}}], "id": 1808}, {"sent": "to see this , consider the following graph cs k , which is a subgraph of a graph appearing in chudnovsky and seymour .", "tokens": ["to", "see", "this", ",", "consider", "the", "following", "graph", "cs", "k", ",", "which", "is", "a", "subgraph", "of", "a", "graph", "appearing", "in", "chudnovsky", "and", "seymour", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1809}, {"sent": "note , however , that it was shown in that total interpretability of an embedding is constant under any orthogonal transformation and it can only be redistributed across the dimensions .", "tokens": ["note", ",", "however", ",", "that", "it", "was", "shown", "in", "that", "total", "interpretability", "of", "an", "embedding", "is", "constant", "under", "any", "orthogonal", "transformation", "and", "it", "can", "only", "be", "redistributed", "across", "the", "dimensions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 22, "end": 24, "i_start": 5, "i_end": 5}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "it", "start": 134, "end": 136, "i_start": 22, "i_end": 22}, "verb": {"text": "shown", "start": 29, "end": 34, "i_start": 7, "i_end": 7}}, {"subject": {"text": "it", "start": 22, "end": 24, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 82, "end": 84, "i_start": 15, "i_end": 15}}, {"subject": {"text": "it", "start": 134, "end": 136, "i_start": 22, "i_end": 22}, "verb": {"text": "redistributed", "start": 149, "end": 162, "i_start": 26, "i_end": 26}}], "id": 1810}, {"sent": "deep convolutional neural networks have been proven very useful in various tasks in computer vision including classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "proven", "very", "useful", "in", "various", "tasks", "in", "computer", "vision", "including", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been proven", "start": 35, "end": 51, "i_start": 4, "i_end": 6}}], "id": 1811}, {"sent": "for training the networks we use the adam optimizer , with its default parameters .", "tokens": ["for", "training", "the", "networks", "we", "use", "the", "adam", "optimizer", ",", "with", "its", "default", "parameters", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 26, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 29, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 26, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "training", "start": 4, "end": 12, "i_start": 1, "i_end": 1}}], "id": 1812}, {"sent": "although their benefit in terms of low-cost personalised healthcare gadgets , however , previous literature have identified several technical and design related issues acting as barriers for wearable adoption in long-term .", "tokens": ["although", "their", "benefit", "in", "terms", "of", "low", "-", "cost", "personalised", "healthcare", "gadgets", ",", "however", ",", "previous", "literature", "have", "identified", "several", "technical", "and", "design", "related", "issues", "acting", "as", "barriers", "for", "wearable", "adoption", "in", "long", "-", "term", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "their benefit in terms of low-cost personalised healthcare gadgets , however , previous literature", "start": 9, "end": 107, "i_start": 1, "i_end": 16}, "verb": {"text": "have identified", "start": 108, "end": 123, "i_start": 17, "i_end": 18}}, {"character": {"text": "literature", "start": 97, "end": 107, "i_start": 16, "i_end": 16}, "action": {"text": "identified", "start": 113, "end": 123, "i_start": 18, "i_end": 18}}, {"character": {"text": "and", "start": 142, "end": 145, "i_start": 21, "i_end": 21}, "action": {"text": "acting", "start": 168, "end": 174, "i_start": 25, "i_end": 25}}], "id": 1813}, {"sent": "the time integration is performed using an explicit third-order accurate runge-kutta method .", "tokens": ["the", "time", "integration", "is", "performed", "using", "an", "explicit", "third", "-", "order", "accurate", "runge", "-", "kutta", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the time integration", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "is performed", "start": 21, "end": 33, "i_start": 3, "i_end": 4}}], "id": 1814}, {"sent": "heterogeneous information network has been heavily studied for its ubiquity in real-world scenarios and its ability to encapsulate rich information .", "tokens": ["heterogeneous", "information", "network", "has", "been", "heavily", "studied", "for", "its", "ubiquity", "in", "real", "-", "world", "scenarios", "and", "its", "ability", "to", "encapsulate", "rich", "information", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "heterogeneous information network", "start": 0, "end": 33, "i_start": 0, "i_end": 2}, "verb": {"text": "studied", "start": 51, "end": 58, "i_start": 6, "i_end": 6}}, {"subject": {"text": "heterogeneous information network", "start": 0, "end": 33, "i_start": 0, "i_end": 2}, "verb": {"text": "has been", "start": 34, "end": 42, "i_start": 3, "i_end": 4}}, {"character": {"text": "network", "start": 26, "end": 33, "i_start": 2, "i_end": 2}, "action": {"text": "encapsulate", "start": 119, "end": 130, "i_start": 19, "i_end": 19}}], "id": 1815}, {"sent": "in recent years , neural networks have been effectively applied in various problems such as voice recognition .", "tokens": ["in", "recent", "years", ",", "neural", "networks", "have", "been", "effectively", "applied", "in", "various", "problems", "such", "as", "voice", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 18, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "applied", "start": 56, "end": 63, "i_start": 9, "i_end": 9}}, {"subject": {"text": "neural networks", "start": 18, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "have been", "start": 34, "end": 43, "i_start": 6, "i_end": 7}}], "id": 1816}, {"sent": "it is well known that the lattice reduction-aided mimo decoding algorithms achieve the full receive diversity .", "tokens": ["it", "is", "well", "known", "that", "the", "lattice", "reduction", "-", "aided", "mimo", "decoding", "algorithms", "achieve", "the", "full", "receive", "diversity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the lattice reduction-aided mimo decoding algorithms", "start": 22, "end": 74, "i_start": 5, "i_end": 12}, "verb": {"text": "achieve", "start": 75, "end": 82, "i_start": 13, "i_end": 13}}, {"character": {"text": "algorithms", "start": 64, "end": 74, "i_start": 12, "i_end": 12}, "action": {"text": "achieve", "start": 75, "end": 82, "i_start": 13, "i_end": 13}}, {"character": {"text": "algorithms", "start": 64, "end": 74, "i_start": 12, "i_end": 12}, "action": {"text": "decoding", "start": 55, "end": 63, "i_start": 11, "i_end": 11}}, {"character": {"text": "reduction", "start": 34, "end": 43, "i_start": 7, "i_end": 7}, "action": {"text": "aided", "start": 44, "end": 49, "i_start": 9, "i_end": 9}}], "id": 1817}, {"sent": "it has been argued that wordnet sense distinctions are too fine-grained for many nlp applications .", "tokens": ["it", "has", "been", "argued", "that", "wordnet", "sense", "distinctions", "are", "too", "fine", "-", "grained", "for", "many", "nlp", "applications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has been argued", "start": 3, "end": 18, "i_start": 1, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 51, "end": 54, "i_start": 8, "i_end": 8}}], "id": 1818}, {"sent": "it is stated that the volume of the hypersphere should be minimized for the data description .", "tokens": ["it", "is", "stated", "that", "the", "volume", "of", "the", "hypersphere", "should", "be", "minimized", "for", "the", "data", "description", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is stated", "start": 3, "end": 12, "i_start": 1, "i_end": 2}}, {"subject": {"text": "the volume of the hypersphere", "start": 18, "end": 47, "i_start": 4, "i_end": 8}, "verb": {"text": "minimized", "start": 58, "end": 67, "i_start": 11, "i_end": 11}}], "id": 1819}, {"sent": "the proposed approach is implemented in popular deep learning framework , pytorch , on an nvidia titan xp gpu .", "tokens": ["the", "proposed", "approach", "is", "implemented", "in", "popular", "deep", "learning", "framework", ",", "pytorch", ",", "on", "an", "nvidia", "titan", "xp", "gpu", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the proposed approach", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is implemented", "start": 22, "end": 36, "i_start": 3, "i_end": 4}}], "id": 1820}, {"sent": "in all experiments , we use adam as the optimizer of which the learning rate is set to 1e-3 , with the batch size of 128 .", "tokens": ["in", "all", "experiments", ",", "we", "use", "adam", "as", "the", "optimizer", "of", "which", "the", "learning", "rate", "is", "set", "to", "1e-3", ",", "with", "the", "batch", "size", "of", "128", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 24, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 24, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "adam", "start": 28, "end": 32, "i_start": 6, "i_end": 6}, "action": {"text": "optimizer", "start": 40, "end": 49, "i_start": 9, "i_end": 9}}], "id": 1821}, {"sent": "see , and for various characterizations of the class of rcdspaces .", "tokens": ["see", ",", "and", "for", "various", "characterizations", "of", "the", "class", "of", "rcdspaces", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1822}, {"sent": "where the ellipsis denotes terms o \u03c3r mtg the hamiltonian .", "tokens": ["where", "the", "ellipsis", "denotes", "terms", "o", "\u03c3r", "mtg", "the", "hamiltonian", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ellipsis", "start": 6, "end": 18, "i_start": 1, "i_end": 2}, "verb": {"text": "denotes", "start": 19, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "ellipsis", "start": 10, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "denotes", "start": 19, "end": 26, "i_start": 3, "i_end": 3}}], "id": 1823}, {"sent": "in fourth acm conference on computer and communications security , pp .", "tokens": ["in", "fourth", "acm", "conference", "on", "computer", "and", "communications", "security", ",", "pp", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1824}, {"sent": "doersch et al proposed to learn representations by predicting the relevant positions of patches extracted from the image .", "tokens": ["doersch", "et", "al", "proposed", "to", "learn", "representations", "by", "predicting", "the", "relevant", "positions", "of", "patches", "extracted", "from", "the", "image", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 8, "end": 13, "i_start": 1, "i_end": 2}, "verb": {"text": "proposed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "doersch", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}], "id": 1825}, {"sent": "we here employ the generalized-gradient approximation in the perdew-burke-ernzerhof form 14 .", "tokens": ["we", "here", "employ", "the", "generalized", "-", "gradient", "approximation", "in", "the", "perdew", "-", "burke", "-", "ernzerhof", "form", "14", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we here", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "employ", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}], "id": 1826}, {"sent": "in this work we use convolutional neural networks motivated by the recent success of deep neural networks .", "tokens": ["in", "this", "work", "we", "use", "convolutional", "neural", "networks", "motivated", "by", "the", "recent", "success", "of", "deep", "neural", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "use", "start": 16, "end": 19, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 16, "end": 19, "i_start": 4, "i_end": 4}}, {"character": {"text": "success", "start": 74, "end": 81, "i_start": 12, "i_end": 12}, "action": {"text": "motivated", "start": 50, "end": 59, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 97, "end": 105, "i_start": 16, "i_end": 16}, "action": {"text": "success", "start": 74, "end": 81, "i_start": 12, "i_end": 12}}], "id": 1827}, {"sent": "in order to compare these theoretical predictions with observational data , we employ a monte carlo markov chain analysis via the publicly available package cosmomc .", "tokens": ["in", "order", "to", "compare", "these", "theoretical", "predictions", "with", "observational", "data", ",", "we", "employ", "a", "monte", "carlo", "markov", "chain", "analysis", "via", "the", "publicly", "available", "package", "cosmomc", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 76, "end": 78, "i_start": 11, "i_end": 11}, "verb": {"text": "employ", "start": 79, "end": 85, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 76, "end": 78, "i_start": 11, "i_end": 11}, "action": {"text": "employ", "start": 79, "end": 85, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 76, "end": 78, "i_start": 11, "i_end": 11}, "action": {"text": "compare", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}], "id": 1828}, {"sent": "the numerical results show that the adaptive construction method significantly reduces the correlations between the sampled data .", "tokens": ["the", "numerical", "results", "show", "that", "the", "adaptive", "construction", "method", "significantly", "reduces", "the", "correlations", "between", "the", "sampled", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the numerical results", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "show", "start": 22, "end": 26, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the adaptive construction method", "start": 32, "end": 64, "i_start": 5, "i_end": 8}, "verb": {"text": "reduces", "start": 79, "end": 86, "i_start": 10, "i_end": 10}}, {"character": {"text": "results", "start": 14, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 22, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "method", "start": 58, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "reduces", "start": 79, "end": 86, "i_start": 10, "i_end": 10}}], "id": 1829}, {"sent": "this is a consequence of the non-uniqeness of the physical vacuum .", "tokens": ["this", "is", "a", "consequence", "of", "the", "non", "-", "uniqeness", "of", "the", "physical", "vacuum", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 1830}, {"sent": "in a parallel work , we have shown that a dimensionally split semi-discrete central scheme along with 1d fourth order cweno reconstruction and a fourth order time integrator provide fourth order accuracy for three dimensional hyperbolic conservation laws .", "tokens": ["in", "a", "parallel", "work", ",", "we", "have", "shown", "that", "a", "dimensionally", "split", "semi", "-", "discrete", "central", "scheme", "along", "with", "1d", "fourth", "order", "cweno", "reconstruction", "and", "a", "fourth", "order", "time", "integrator", "provide", "fourth", "order", "accuracy", "for", "three", "dimensional", "hyperbolic", "conservation", "laws", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 5, "i_end": 5}, "verb": {"text": "have shown", "start": 24, "end": 34, "i_start": 6, "i_end": 7}}, {"subject": {"text": "a dimensionally split semi-discrete central scheme along with 1d fourth order cweno reconstruction and a fourth order time integrator", "start": 40, "end": 173, "i_start": 9, "i_end": 29}, "verb": {"text": "provide", "start": 174, "end": 181, "i_start": 30, "i_end": 30}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 5, "i_end": 5}, "action": {"text": "shown", "start": 29, "end": 34, "i_start": 7, "i_end": 7}}, {"character": {"text": "scheme", "start": 84, "end": 90, "i_start": 16, "i_end": 16}, "action": {"text": "provide", "start": 174, "end": 181, "i_start": 30, "i_end": 30}}, {"character": {"text": "central", "start": 76, "end": 83, "i_start": 15, "i_end": 15}, "action": {"text": "provide", "start": 174, "end": 181, "i_start": 30, "i_end": 30}}, {"character": {"text": "semi", "start": 62, "end": 66, "i_start": 12, "i_end": 12}, "action": {"text": "provide", "start": 174, "end": 181, "i_start": 30, "i_end": 30}}, {"character": {"text": "reconstruction", "start": 124, "end": 138, "i_start": 23, "i_end": 23}, "action": {"text": "provide", "start": 174, "end": 181, "i_start": 30, "i_end": 30}}, {"character": {"text": "order", "start": 112, "end": 117, "i_start": 21, "i_end": 21}, "action": {"text": "provide", "start": 174, "end": 181, "i_start": 30, "i_end": 30}}, {"character": {"text": "order", "start": 152, "end": 157, "i_start": 27, "i_end": 27}, "action": {"text": "provide", "start": 174, "end": 181, "i_start": 30, "i_end": 30}}, {"character": {"text": "order", "start": 189, "end": 194, "i_start": 32, "i_end": 32}, "action": {"text": "provide", "start": 174, "end": 181, "i_start": 30, "i_end": 30}}], "id": 1831}, {"sent": "we postulate that this is the connection that ought to be used in the procedure of minimal coupling .", "tokens": ["we", "postulate", "that", "this", "is", "the", "connection", "that", "ought", "to", "be", "used", "in", "the", "procedure", "of", "minimal", "coupling", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "postulate", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 4, "i_end": 4}}], "id": 1832}, {"sent": "along this direction , convolutional neural networks have been very successful in various computer vision and natural language processing tasks in recent years .", "tokens": ["along", "this", "direction", ",", "convolutional", "neural", "networks", "have", "been", "very", "successful", "in", "various", "computer", "vision", "and", "natural", "language", "processing", "tasks", "in", "recent", "years", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 23, "end": 52, "i_start": 4, "i_end": 6}, "verb": {"text": "have been", "start": 53, "end": 62, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "successful", "start": 68, "end": 78, "i_start": 10, "i_end": 10}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "processing", "start": 127, "end": 137, "i_start": 18, "i_end": 18}}], "id": 1833}, {"sent": "the superpotential is where s is a coupling constant and n invariant under an su ns .", "tokens": ["the", "superpotential", "is", "where", "s", "is", "a", "coupling", "constant", "and", "n", "invariant", "under", "an", "su", "ns", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the superpotential", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the superpotential", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 5, "i_end": 5}}], "id": 1834}, {"sent": "as the fabrication of an array of detectors is demanding , experiments using integrating line detectors are often carried out using a single line detector , scanned on circular paths using scanning stages , which is very time consuming .", "tokens": ["as", "the", "fabrication", "of", "an", "array", "of", "detectors", "is", "demanding", ",", "experiments", "using", "integrating", "line", "detectors", "are", "often", "carried", "out", "using", "a", "single", "line", "detector", ",", "scanned", "on", "circular", "paths", "using", "scanning", "stages", ",", "which", "is", "very", "time", "consuming", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "experiments using integrating line detectors", "start": 59, "end": 103, "i_start": 11, "i_end": 15}, "verb": {"text": "carried out", "start": 114, "end": 125, "i_start": 18, "i_end": 19}}, {"subject": {"text": "experiments using integrating line detectors", "start": 59, "end": 103, "i_start": 11, "i_end": 15}, "verb": {"text": "are", "start": 104, "end": 107, "i_start": 16, "i_end": 16}}, {"subject": {"text": "experiments using integrating line detectors", "start": 59, "end": 103, "i_start": 11, "i_end": 15}, "verb": {"text": "scanned", "start": 157, "end": 164, "i_start": 26, "i_end": 26}}, {"character": {"text": "fabrication", "start": 7, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "demanding", "start": 47, "end": 56, "i_start": 9, "i_end": 9}}, {"character": {"text": "experiments", "start": 59, "end": 70, "i_start": 11, "i_end": 11}, "action": {"text": "using", "start": 71, "end": 76, "i_start": 12, "i_end": 12}}], "id": 1835}, {"sent": "deep convolutional networks made great progress in recent years in the field of computer vision .", "tokens": ["deep", "convolutional", "networks", "made", "great", "progress", "in", "recent", "years", "in", "the", "field", "of", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional networks", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "made", "start": 28, "end": 32, "i_start": 3, "i_end": 3}}], "id": 1836}, {"sent": "frog is a simple , commonly-used technique for full characterization of ultra-short laser pulses which enjoys good experimental performance .", "tokens": ["frog", "is", "a", "simple", ",", "commonly", "-", "used", "technique", "for", "full", "characterization", "of", "ultra", "-", "short", "laser", "pulses", "which", "enjoys", "good", "experimental", "performance", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "frog", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "technique", "start": 33, "end": 42, "i_start": 8, "i_end": 8}, "action": {"text": "enjoys", "start": 103, "end": 109, "i_start": 19, "i_end": 19}}], "id": 1837}, {"sent": "the ds no-hair theorem is not applicable , and this state does not approach the euclidean vacuum at large times .", "tokens": ["the", "ds", "no", "-", "hair", "theorem", "is", "not", "applicable", ",", "and", "this", "state", "does", "not", "approach", "the", "euclidean", "vacuum", "at", "large", "times", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ds no-hair theorem", "start": 0, "end": 22, "i_start": 0, "i_end": 5}, "verb": {"text": "is not", "start": 23, "end": 29, "i_start": 6, "i_end": 7}}, {"subject": {"text": "this state", "start": 47, "end": 57, "i_start": 11, "i_end": 12}, "verb": {"text": "approach", "start": 67, "end": 75, "i_start": 15, "i_end": 15}}, {"character": {"text": "state", "start": 52, "end": 57, "i_start": 12, "i_end": 12}, "action": {"text": "-hair theorem is not applicable , and this state does not approach", "start": 9, "end": 75, "i_start": 3, "i_end": 15}}], "id": 1838}, {"sent": "in , achievable rate regions for the cc-ifc that consist of the non-cooperative causal transmission protocols have been characterized .", "tokens": ["in", ",", "achievable", "rate", "regions", "for", "the", "cc", "-", "ifc", "that", "consist", "of", "the", "non", "-", "cooperative", "causal", "transmission", "protocols", "have", "been", "characterized", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "achievable rate regions for the cc-ifc that consist of the non-cooperative causal transmission protocols", "start": 5, "end": 109, "i_start": 2, "i_end": 19}, "verb": {"text": "have been characterized", "start": 110, "end": 133, "i_start": 20, "i_end": 22}}], "id": 1839}, {"sent": "spielman and srivas-tava showed how to construct a much stronger spectral sparsifier with oedges , by sampling edges with probabilities proportional to their effective resistance , if the graph is viewed as an electrical network .", "tokens": ["spielman", "and", "srivas", "-", "tava", "showed", "how", "to", "construct", "a", "much", "stronger", "spectral", "sparsifier", "with", "oedges", ",", "by", "sampling", "edges", "with", "probabilities", "proportional", "to", "their", "effective", "resistance", ",", "if", "the", "graph", "is", "viewed", "as", "an", "electrical", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "spielman and srivas-tava", "start": 0, "end": 24, "i_start": 0, "i_end": 4}, "verb": {"text": "showed", "start": 25, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "spielman", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 25, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "srivas", "start": 13, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "showed", "start": 25, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "spielman", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "construct", "start": 39, "end": 48, "i_start": 8, "i_end": 8}}, {"character": {"text": "srivas", "start": 13, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "construct", "start": 39, "end": 48, "i_start": 8, "i_end": 8}}, {"character": {"text": "spielman", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "sampling", "start": 102, "end": 110, "i_start": 18, "i_end": 18}}, {"character": {"text": "srivas", "start": 13, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "sampling", "start": 102, "end": 110, "i_start": 18, "i_end": 18}}, {"character": {"text": "edges", "start": 111, "end": 116, "i_start": 19, "i_end": 19}, "action": {"text": "resistance", "start": 168, "end": 178, "i_start": 26, "i_end": 26}}, {"character": {"text": "resistance", "start": 168, "end": 178, "i_start": 26, "i_end": 26}, "action": {"text": "effective", "start": 158, "end": 167, "i_start": 25, "i_end": 25}}], "id": 1840}, {"sent": "a spherical isothermal dark matter density profile has been used .", "tokens": ["a", "spherical", "isothermal", "dark", "matter", "density", "profile", "has", "been", "used", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a spherical isothermal dark matter density profile", "start": 0, "end": 50, "i_start": 0, "i_end": 6}, "verb": {"text": "has been used", "start": 51, "end": 64, "i_start": 7, "i_end": 9}}], "id": 1841}, {"sent": "semantics-preserving hashing tansforms semantic affinity into a probability distribution and approximates the distribution in hamming space .", "tokens": ["semantics", "-", "preserving", "hashing", "tansforms", "semantic", "affinity", "into", "a", "probability", "distribution", "and", "approximates", "the", "distribution", "in", "hamming", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "hashing", "start": 21, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "approximates", "start": 93, "end": 105, "i_start": 12, "i_end": 12}}], "id": 1842}, {"sent": "for generating the image embedding we use the classical vgg16 cnn architecture .", "tokens": ["for", "generating", "the", "image", "embedding", "we", "use", "the", "classical", "vgg16", "cnn", "architecture", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 35, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 38, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 35, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "generating", "start": 4, "end": 14, "i_start": 1, "i_end": 1}}], "id": 1843}, {"sent": "in recent years , deep convolution neural networks have achieved promising performance on many artificial intelligence tasks , including image recognition .", "tokens": ["in", "recent", "years", ",", "deep", "convolution", "neural", "networks", "have", "achieved", "promising", "performance", "on", "many", "artificial", "intelligence", "tasks", ",", "including", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolution neural networks", "start": 18, "end": 50, "i_start": 4, "i_end": 7}, "verb": {"text": "have achieved", "start": 51, "end": 64, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 42, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 56, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 42, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "performance", "start": 75, "end": 86, "i_start": 11, "i_end": 11}}, {"character": {"text": "performance", "start": 75, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "promising", "start": 65, "end": 74, "i_start": 10, "i_end": 10}}], "id": 1844}, {"sent": "the stable model semantics for logic programming .", "tokens": ["the", "stable", "model", "semantics", "for", "logic", "programming", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1845}, {"sent": "we developed an ensemble system using inceptionv3 , inceptionresnetv2 as base classifiers .", "tokens": ["we", "developed", "an", "ensemble", "system", "using", "inceptionv3", ",", "inceptionresnetv2", "as", "base", "classifiers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "developed", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "developed", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 32, "end": 37, "i_start": 5, "i_end": 5}}], "id": 1846}, {"sent": "a random walk is a special case of a discrete time markov process , but does not have a stationary distribution 1 queueing model is a system to transform an arrival stream to a departure stream .", "tokens": ["a", "random", "walk", "is", "a", "special", "case", "of", "a", "discrete", "time", "markov", "process", ",", "but", "does", "not", "have", "a", "stationary", "distribution", "1", "queueing", "model", "is", "a", "system", "to", "transform", "an", "arrival", "stream", "to", "a", "departure", "stream", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a random walk", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 3, "i_end": 3}}, {"subject": {"text": "a random walk", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 81, "end": 85, "i_start": 17, "i_end": 17}}, {"character": {"text": "walk", "start": 9, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "case", "start": 27, "end": 31, "i_start": 6, "i_end": 6}}], "id": 1847}, {"sent": "deep neural networks have seen great success in many cognitive applications such as image classification .", "tokens": ["deep", "neural", "networks", "have", "seen", "great", "success", "in", "many", "cognitive", "applications", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have seen", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 37, "end": 44, "i_start": 6, "i_end": 6}}], "id": 1848}, {"sent": "this is the origin of the ambiguity in the dependence of the energy on the metric .", "tokens": ["this", "is", "the", "origin", "of", "the", "ambiguity", "in", "the", "dependence", "of", "the", "energy", "on", "the", "metric", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "energy", "start": 61, "end": 67, "i_start": 12, "i_end": 12}, "action": {"text": "dependence", "start": 43, "end": 53, "i_start": 9, "i_end": 9}}], "id": 1849}, {"sent": "the renormalization is a quadratic term , regardless of whether or not the original model contained such a term .", "tokens": ["the", "renormalization", "is", "a", "quadratic", "term", ",", "regardless", "of", "whether", "or", "not", "the", "original", "model", "contained", "such", "a", "term", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the renormalization", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "model", "start": 84, "end": 89, "i_start": 14, "i_end": 14}, "action": {"text": "contained", "start": 90, "end": 99, "i_start": 15, "i_end": 15}}, {"character": {"text": "model", "start": 84, "end": 89, "i_start": 14, "i_end": 14}, "action": {"text": "not", "start": 67, "end": 70, "i_start": 11, "i_end": 11}}], "id": 1850}, {"sent": "recently , deep neural networks have demonstrated impressive results in image classification .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "demonstrated", "impressive", "results", "in", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have demonstrated", "start": 32, "end": 49, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "demonstrated", "start": 37, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "results", "start": 61, "end": 68, "i_start": 8, "i_end": 8}, "action": {"text": "impressive", "start": 50, "end": 60, "i_start": 7, "i_end": 7}}], "id": 1851}, {"sent": "we will be using the following terminology .", "tokens": ["we", "will", "be", "using", "the", "following", "terminology", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will be using", "start": 3, "end": 16, "i_start": 1, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 11, "end": 16, "i_start": 3, "i_end": 3}}], "id": 1852}, {"sent": "a strict lie 2-group is a category in liegrp , the category of lie groups .", "tokens": ["a", "strict", "lie", "2", "-", "group", "is", "a", "category", "in", "liegrp", ",", "the", "category", "of", "lie", "groups", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a strict lie 2-group", "start": 0, "end": 20, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 6, "i_end": 6}}], "id": 1853}, {"sent": "cluster algebras were defined and first studied by fomin and zelevinsky .", "tokens": ["cluster", "algebras", "were", "defined", "and", "first", "studied", "by", "fomin", "and", "zelevinsky", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were defined", "start": 17, "end": 29, "i_start": 2, "i_end": 3}}, {"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "studied", "start": 40, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "fomin", "start": 51, "end": 56, "i_start": 8, "i_end": 8}, "action": {"text": "defined", "start": 22, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "zelevinsky", "start": 61, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "defined", "start": 22, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "fomin", "start": 51, "end": 56, "i_start": 8, "i_end": 8}, "action": {"text": "studied", "start": 40, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "zelevinsky", "start": 61, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "studied", "start": 40, "end": 47, "i_start": 6, "i_end": 6}}], "id": 1854}, {"sent": "furthermore the z-dependence is continuous .", "tokens": ["furthermore", "the", "z", "-", "dependence", "is", "continuous", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the z-dependence", "start": 12, "end": 28, "i_start": 1, "i_end": 4}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 5, "i_end": 5}}], "id": 1855}, {"sent": "however , several experimental results have considered the problem of self-interference cancellation in full-duplex systems to investigate the impact of radio circuit impairments on the cancellation capability .", "tokens": ["however", ",", "several", "experimental", "results", "have", "considered", "the", "problem", "of", "self", "-", "interference", "cancellation", "in", "full", "-", "duplex", "systems", "to", "investigate", "the", "impact", "of", "radio", "circuit", "impairments", "on", "the", "cancellation", "capability", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "several experimental results", "start": 10, "end": 38, "i_start": 2, "i_end": 4}, "verb": {"text": "have considered", "start": 39, "end": 54, "i_start": 5, "i_end": 6}}, {"character": {"text": "results", "start": 31, "end": 38, "i_start": 4, "i_end": 4}, "action": {"text": "considered", "start": 44, "end": 54, "i_start": 6, "i_end": 6}}, {"character": {"text": "systems", "start": 116, "end": 123, "i_start": 18, "i_end": 18}, "action": {"text": "interference", "start": 75, "end": 87, "i_start": 12, "i_end": 12}}, {"character": {"text": "results", "start": 31, "end": 38, "i_start": 4, "i_end": 4}, "action": {"text": "investigate", "start": 127, "end": 138, "i_start": 20, "i_end": 20}}, {"character": {"text": "impairments", "start": 167, "end": 178, "i_start": 26, "i_end": 26}, "action": {"text": "impact", "start": 143, "end": 149, "i_start": 22, "i_end": 22}}], "id": 1856}, {"sent": "this completes the proof that is a right bialgebroid .", "tokens": ["this", "completes", "the", "proof", "that", "is", "a", "right", "bialgebroid", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "completes", "start": 5, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "completes", "start": 5, "end": 14, "i_start": 1, "i_end": 1}}], "id": 1857}, {"sent": "specifically , finn et al presented a model-agnostic meta-learner , maml , to optimize the initialization of a learning model with the objective of maximizing its performance on a new task after updating its parameters with a small number of samples .", "tokens": ["specifically", ",", "finn", "et", "al", "presented", "a", "model", "-", "agnostic", "meta", "-", "learner", ",", "maml", ",", "to", "optimize", "the", "initialization", "of", "a", "learning", "model", "with", "the", "objective", "of", "maximizing", "its", "performance", "on", "a", "new", "task", "after", "updating", "its", "parameters", "with", "a", "small", "number", "of", "samples", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 20, "end": 25, "i_start": 3, "i_end": 4}, "verb": {"text": "presented", "start": 26, "end": 35, "i_start": 5, "i_end": 5}}, {"character": {"text": "finn", "start": 15, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "presented", "start": 26, "end": 35, "i_start": 5, "i_end": 5}}, {"character": {"text": "maml", "start": 68, "end": 72, "i_start": 14, "i_end": 14}, "action": {"text": "optimize", "start": 78, "end": 86, "i_start": 17, "i_end": 17}}, {"character": {"text": "meta", "start": 53, "end": 57, "i_start": 10, "i_end": 10}, "action": {"text": "optimize", "start": 78, "end": 86, "i_start": 17, "i_end": 17}}, {"character": {"text": "maml", "start": 68, "end": 72, "i_start": 14, "i_end": 14}, "action": {"text": "maximizing", "start": 148, "end": 158, "i_start": 28, "i_end": 28}}, {"character": {"text": "meta", "start": 53, "end": 57, "i_start": 10, "i_end": 10}, "action": {"text": "maximizing", "start": 148, "end": 158, "i_start": 28, "i_end": 28}}, {"character": {"text": "model", "start": 120, "end": 125, "i_start": 23, "i_end": 23}, "action": {"text": "performance", "start": 163, "end": 174, "i_start": 30, "i_end": 30}}, {"character": {"text": "maml", "start": 68, "end": 72, "i_start": 14, "i_end": 14}, "action": {"text": "updating", "start": 195, "end": 203, "i_start": 36, "i_end": 36}}, {"character": {"text": "meta", "start": 53, "end": 57, "i_start": 10, "i_end": 10}, "action": {"text": "updating", "start": 195, "end": 203, "i_start": 36, "i_end": 36}}], "id": 1858}, {"sent": "an average contribution of pileup interactions is estimated and subsequently subtracted from the jet energy .", "tokens": ["an", "average", "contribution", "of", "pileup", "interactions", "is", "estimated", "and", "subsequently", "subtracted", "from", "the", "jet", "energy", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "an average contribution of pileup interactions", "start": 0, "end": 46, "i_start": 0, "i_end": 5}, "verb": {"text": "is estimated", "start": 47, "end": 59, "i_start": 6, "i_end": 7}}, {"subject": {"text": "an average contribution of pileup interactions", "start": 0, "end": 46, "i_start": 0, "i_end": 5}, "verb": {"text": "subtracted", "start": 77, "end": 87, "i_start": 10, "i_end": 10}}, {"character": {"text": "interactions", "start": 34, "end": 46, "i_start": 5, "i_end": 5}, "action": {"text": "contribution", "start": 11, "end": 23, "i_start": 2, "i_end": 2}}], "id": 1859}, {"sent": "other nonlinear dimensionality reduction methods include manifold learning methods such as isomap , locally linear embedding , among others .", "tokens": ["other", "nonlinear", "dimensionality", "reduction", "methods", "include", "manifold", "learning", "methods", "such", "as", "isomap", ",", "locally", "linear", "embedding", ",", "among", "others", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "other nonlinear dimensionality reduction methods", "start": 0, "end": 48, "i_start": 0, "i_end": 4}, "verb": {"text": "include", "start": 49, "end": 56, "i_start": 5, "i_end": 5}}], "id": 1860}, {"sent": "the neutrino is the only known stable particle immune to the gzk degradation .", "tokens": ["the", "neutrino", "is", "the", "only", "known", "stable", "particle", "immune", "to", "the", "gzk", "degradation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the neutrino", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 1861}, {"sent": "besides , all the hyperplane nodes have degree gx .", "tokens": ["besides", ",", "all", "the", "hyperplane", "nodes", "have", "degree", "gx", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "nodes", "start": 29, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "have", "start": 35, "end": 39, "i_start": 6, "i_end": 6}}], "id": 1862}, {"sent": "the legendre transformation for partially controlled systems .", "tokens": ["the", "legendre", "transformation", "for", "partially", "controlled", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1863}, {"sent": "an offset correction is applied to jet energies to take into account the contributions from neutral particles produced in pileup interactions .", "tokens": ["an", "offset", "correction", "is", "applied", "to", "jet", "energies", "to", "take", "into", "account", "the", "contributions", "from", "neutral", "particles", "produced", "in", "pileup", "interactions", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "an offset correction", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "is applied", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "correction", "start": 10, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "take", "start": 51, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "particles", "start": 100, "end": 109, "i_start": 16, "i_end": 16}, "action": {"text": "contributions", "start": 73, "end": 86, "i_start": 13, "i_end": 13}}, {"character": {"text": "particles", "start": 100, "end": 109, "i_start": 16, "i_end": 16}, "action": {"text": "neutral", "start": 92, "end": 99, "i_start": 15, "i_end": 15}}, {"character": {"text": "interactions", "start": 129, "end": 141, "i_start": 20, "i_end": 20}, "action": {"text": "produced", "start": 110, "end": 118, "i_start": 17, "i_end": 17}}], "id": 1864}, {"sent": "they may be obtained by using general formulae for non-extremal black brane solutions from .", "tokens": ["they", "may", "be", "obtained", "by", "using", "general", "formulae", "for", "non", "-", "extremal", "black", "brane", "solutions", "from", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "may be obtained", "start": 5, "end": 20, "i_start": 1, "i_end": 3}}], "id": 1865}, {"sent": "the model is trained with the adam optimizer using a batch size of 256 .", "tokens": ["the", "model", "is", "trained", "with", "the", "adam", "optimizer", "using", "a", "batch", "size", "of", "256", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is trained", "start": 10, "end": 20, "i_start": 2, "i_end": 3}}], "id": 1866}, {"sent": "deep convolutional neural networks trained on places have shown impressive results in scene recognition tasks and have been applied in many areas .", "tokens": ["deep", "convolutional", "neural", "networks", "trained", "on", "places", "have", "shown", "impressive", "results", "in", "scene", "recognition", "tasks", "and", "have", "been", "applied", "in", "many", "areas", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks trained on places", "start": 0, "end": 52, "i_start": 0, "i_end": 6}, "verb": {"text": "have shown", "start": 53, "end": 63, "i_start": 7, "i_end": 8}}, {"subject": {"text": "deep convolutional neural networks trained on places", "start": 0, "end": 52, "i_start": 0, "i_end": 6}, "verb": {"text": "applied", "start": 124, "end": 131, "i_start": 18, "i_end": 18}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 58, "end": 63, "i_start": 8, "i_end": 8}}, {"character": {"text": "results", "start": 75, "end": 82, "i_start": 10, "i_end": 10}, "action": {"text": "impressive", "start": 64, "end": 74, "i_start": 9, "i_end": 9}}], "id": 1867}, {"sent": "the cnn-based methods achieve great progress in image classification .", "tokens": ["the", "cnn", "-", "based", "methods", "achieve", "great", "progress", "in", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the cnn-based methods", "start": 0, "end": 21, "i_start": 0, "i_end": 4}, "verb": {"text": "achieve", "start": 22, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "methods", "start": 14, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "achieve", "start": 22, "end": 29, "i_start": 5, "i_end": 5}}], "id": 1868}, {"sent": "thesis , princeton university , princeton , new jersey .", "tokens": ["thesis", ",", "princeton", "university", ",", "princeton", ",", "new", "jersey", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1869}, {"sent": "recently , deep neural network has been successfully used to interpret complicated data sets and applied to tasks with pattern recognition , such as image recognition , speech recognition and natural language processing .", "tokens": ["recently", ",", "deep", "neural", "network", "has", "been", "successfully", "used", "to", "interpret", "complicated", "data", "sets", "and", "applied", "to", "tasks", "with", "pattern", "recognition", ",", "such", "as", "image", "recognition", ",", "speech", "recognition", "and", "natural", "language", "processing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural network", "start": 11, "end": 30, "i_start": 2, "i_end": 4}, "verb": {"text": "used", "start": 53, "end": 57, "i_start": 8, "i_end": 8}}, {"subject": {"text": "deep neural network", "start": 11, "end": 30, "i_start": 2, "i_end": 4}, "verb": {"text": "has been", "start": 31, "end": 39, "i_start": 5, "i_end": 6}}, {"subject": {"text": "deep neural network", "start": 11, "end": 30, "i_start": 2, "i_end": 4}, "verb": {"text": "applied", "start": 97, "end": 104, "i_start": 15, "i_end": 15}}], "id": 1870}, {"sent": "objects in the universe represented by the topos are given by the sheaves .", "tokens": ["objects", "in", "the", "universe", "represented", "by", "the", "topos", "are", "given", "by", "the", "sheaves", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "objects in the universe represented by the topos", "start": 0, "end": 48, "i_start": 0, "i_end": 7}, "verb": {"text": "are given", "start": 49, "end": 58, "i_start": 8, "i_end": 9}}, {"character": {"text": "sheaves", "start": 66, "end": 73, "i_start": 12, "i_end": 12}, "action": {"text": "given", "start": 53, "end": 58, "i_start": 9, "i_end": 9}}, {"character": {"text": "topos", "start": 43, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "represented", "start": 24, "end": 35, "i_start": 4, "i_end": 4}}], "id": 1871}, {"sent": "the coupling constant t , which is a loop expansion parameter , represents the temperature of the classical spin model .", "tokens": ["the", "coupling", "constant", "t", ",", "which", "is", "a", "loop", "expansion", "parameter", ",", "represents", "the", "temperature", "of", "the", "classical", "spin", "model", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "the coupling constant t", "start": 0, "end": 23, "i_start": 0, "i_end": 3}, "verb": {"text": "represents", "start": 64, "end": 74, "i_start": 12, "i_end": 12}}, {"character": {"text": "constant t", "start": 13, "end": 23, "i_start": 2, "i_end": 3}, "action": {"text": "represents", "start": 64, "end": 74, "i_start": 12, "i_end": 12}}], "id": 1872}, {"sent": "kernel estimation in semiparametric models .", "tokens": ["kernel", "estimation", "in", "semiparametric", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1873}, {"sent": "pga is an algebraic theory of single-pass instruction sequences that was taken as the basis of the approach to the semantics of programming languages introduced in .", "tokens": ["pga", "is", "an", "algebraic", "theory", "of", "single", "-", "pass", "instruction", "sequences", "that", "was", "taken", "as", "the", "basis", "of", "the", "approach", "to", "the", "semantics", "of", "programming", "languages", "introduced", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "pga", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 4, "end": 6, "i_start": 1, "i_end": 1}}], "id": 1874}, {"sent": "convolutional neural networks have achieved tremendous progress on many pattern recognition tasks , especially large-scale images recognition problems .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "tremendous", "progress", "on", "many", "pattern", "recognition", "tasks", ",", "especially", "large", "-", "scale", "images", "recognition", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 1875}, {"sent": "the communication cost depends very much on the connectivity of the network .", "tokens": ["the", "communication", "cost", "depends", "very", "much", "on", "the", "connectivity", "of", "the", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the communication cost", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "depends", "start": 23, "end": 30, "i_start": 3, "i_end": 3}}], "id": 1876}, {"sent": "sullivan , the convergence of circle packings to riemann mapping .", "tokens": ["sullivan", ",", "the", "convergence", "of", "circle", "packings", "to", "riemann", "mapping", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1877}, {"sent": "instead of using a nmos to cut off the sneak path , we use an operationamplifier in each column to collect the current and transfer the current to the form of output voltage .", "tokens": ["instead", "of", "using", "a", "nmos", "to", "cut", "off", "the", "sneak", "path", ",", "we", "use", "an", "operationamplifier", "in", "each", "column", "to", "collect", "the", "current", "and", "transfer", "the", "current", "to", "the", "form", "of", "output", "voltage", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 52, "end": 54, "i_start": 12, "i_end": 12}, "verb": {"text": "use", "start": 55, "end": 58, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 52, "end": 54, "i_start": 12, "i_end": 12}, "action": {"text": "using", "start": 11, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1878}, {"sent": "in this case the gradient of er concentration at the interface changes the sign again and the interface motion returns to the initial direction .", "tokens": ["in", "this", "case", "the", "gradient", "of", "er", "concentration", "at", "the", "interface", "changes", "the", "sign", "again", "and", "the", "interface", "motion", "returns", "to", "the", "initial", "direction", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the gradient of er concentration at the interface", "start": 13, "end": 62, "i_start": 3, "i_end": 10}, "verb": {"text": "changes", "start": 63, "end": 70, "i_start": 11, "i_end": 11}}, {"subject": {"text": "the interface motion", "start": 90, "end": 110, "i_start": 16, "i_end": 18}, "verb": {"text": "returns", "start": 111, "end": 118, "i_start": 19, "i_end": 19}}, {"character": {"text": "gradient", "start": 17, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "changes", "start": 63, "end": 70, "i_start": 11, "i_end": 11}}], "id": 1879}, {"sent": "learning-based methods have shown promising inpainting results thanks to the rapid development of deep neural networks and generative adversarial networks .", "tokens": ["learning", "-", "based", "methods", "have", "shown", "promising", "inpainting", "results", "thanks", "to", "the", "rapid", "development", "of", "deep", "neural", "networks", "and", "generative", "adversarial", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "learning-based methods", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "have shown", "start": 23, "end": 33, "i_start": 4, "i_end": 5}}, {"character": {"text": "methods", "start": 15, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 28, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "results", "start": 55, "end": 62, "i_start": 8, "i_end": 8}, "action": {"text": "promising", "start": 34, "end": 43, "i_start": 6, "i_end": 6}}], "id": 1880}, {"sent": "the error bars represent the new hipparcos reduction only .", "tokens": ["the", "error", "bars", "represent", "the", "new", "hipparcos", "reduction", "only", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the error bars", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "represent", "start": 15, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "bars", "start": 10, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "represent", "start": 15, "end": 24, "i_start": 3, "i_end": 3}}], "id": 1881}, {"sent": "the bms group is related to soft theorems and the gravitational memory effect .", "tokens": ["the", "bms", "group", "is", "related", "to", "soft", "theorems", "and", "the", "gravitational", "memory", "effect", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the bms group", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is related", "start": 14, "end": 24, "i_start": 3, "i_end": 4}}], "id": 1882}, {"sent": "for the convolutional layers , we use the vgg16 model pre-trained on imagenet data .", "tokens": ["for", "the", "convolutional", "layers", ",", "we", "use", "the", "vgg16", "model", "pre", "-", "trained", "on", "imagenet", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}], "id": 1883}, {"sent": "thus the crucial feature characterizing accessibility is the matching of the claims and the outcomes of physical processes testing the claims , ghirardi , p .", "tokens": ["thus", "the", "crucial", "feature", "characterizing", "accessibility", "is", "the", "matching", "of", "the", "claims", "and", "the", "outcomes", "of", "physical", "processes", "testing", "the", "claims", ",", "ghirardi", ",", "p", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the crucial feature characterizing accessibility", "start": 5, "end": 53, "i_start": 1, "i_end": 5}, "verb": {"text": "is", "start": 54, "end": 56, "i_start": 6, "i_end": 6}}, {"character": {"text": "feature", "start": 17, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "characterizing", "start": 25, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "processes", "start": 113, "end": 122, "i_start": 17, "i_end": 17}, "action": {"text": "testing", "start": 123, "end": 130, "i_start": 18, "i_end": 18}}], "id": 1884}, {"sent": "in other words , the orthogonal state proposed in this paper can be specified by the simultaneous diagonalisation of the conserved operators .", "tokens": ["in", "other", "words", ",", "the", "orthogonal", "state", "proposed", "in", "this", "paper", "can", "be", "specified", "by", "the", "simultaneous", "diagonalisation", "of", "the", "conserved", "operators", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the orthogonal state proposed in this paper", "start": 17, "end": 60, "i_start": 4, "i_end": 10}, "verb": {"text": "can be specified", "start": 61, "end": 77, "i_start": 11, "i_end": 13}}, {"character": {"text": "diagonalisation", "start": 98, "end": 113, "i_start": 17, "i_end": 17}, "action": {"text": "specified", "start": 68, "end": 77, "i_start": 13, "i_end": 13}}], "id": 1885}, {"sent": "reference shows a connection between compressive sensing , n-widths , and the johnsonlindenstrauss lemma .", "tokens": ["reference", "shows", "a", "connection", "between", "compressive", "sensing", ",", "n", "-", "widths", ",", "and", "the", "johnsonlindenstrauss", "lemma", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "reference", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "shows", "start": 10, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "reference", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "shows", "start": 10, "end": 15, "i_start": 1, "i_end": 1}}], "id": 1886}, {"sent": "one earlier paper tangentially connected to computing the empirical poa of congestion games is .", "tokens": ["one", "earlier", "paper", "tangentially", "connected", "to", "computing", "the", "empirical", "poa", "of", "congestion", "games", "is", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "one earlier paper tangentially connected to computing the empirical poa of congestion games", "start": 0, "end": 91, "i_start": 0, "i_end": 12}, "verb": {"text": "is", "start": 92, "end": 94, "i_start": 13, "i_end": 13}}], "id": 1887}, {"sent": "in contrast , as demonstrated in , the one-loop model which we will call the bpr model , exhibits , in addition to the absence of lp , the perturbativity and stability up to the planck scale .", "tokens": ["in", "contrast", ",", "as", "demonstrated", "in", ",", "the", "one", "-", "loop", "model", "which", "we", "will", "call", "the", "bpr", "model", ",", "exhibits", ",", "in", "addition", "to", "the", "absence", "of", "lp", ",", "the", "perturbativity", "and", "stability", "up", "to", "the", "planck", "scale", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "model", "start": 48, "end": 53, "i_start": 11, "i_end": 11}, "action": {"text": "exhibits", "start": 89, "end": 97, "i_start": 20, "i_end": 20}}, {"character": {"text": "we", "start": 60, "end": 62, "i_start": 13, "i_end": 13}, "action": {"text": "call", "start": 68, "end": 72, "i_start": 15, "i_end": 15}}], "id": 1888}, {"sent": "less obviously , it is also necessary , which can be , again , deduced from the proof of positional determinacy of parity games due to emerson and jutla .", "tokens": ["less", "obviously", ",", "it", "is", "also", "necessary", ",", "which", "can", "be", ",", "again", ",", "deduced", "from", "the", "proof", "of", "positional", "determinacy", "of", "parity", "games", "due", "to", "emerson", "and", "jutla", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 17, "end": 19, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 4, "i_end": 4}}], "id": 1889}, {"sent": "any propositional fixpoint definition can be transformed into defnf in polynomial time using tseitin transformation .", "tokens": ["any", "propositional", "fixpoint", "definition", "can", "be", "transformed", "into", "defnf", "in", "polynomial", "time", "using", "tseitin", "transformation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "any propositional fixpoint definition", "start": 0, "end": 37, "i_start": 0, "i_end": 3}, "verb": {"text": "can be transformed", "start": 38, "end": 56, "i_start": 4, "i_end": 6}}], "id": 1890}, {"sent": "if the pressure decreases , the system moves along this branch up to the critical point c .", "tokens": ["if", "the", "pressure", "decreases", ",", "the", "system", "moves", "along", "this", "branch", "up", "to", "the", "critical", "point", "c", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the system", "start": 28, "end": 38, "i_start": 5, "i_end": 6}, "verb": {"text": "moves", "start": 39, "end": 44, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the system", "start": 28, "end": 38, "i_start": 5, "i_end": 6}, "verb": {"text": "up", "start": 63, "end": 65, "i_start": 11, "i_end": 11}}], "id": 1891}, {"sent": "for example , cp-odd scalars typically appear in the string theory landscape .", "tokens": ["for", "example", ",", "cp", "-", "odd", "scalars", "typically", "appear", "in", "the", "string", "theory", "landscape", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cp-odd scalars", "start": 14, "end": 28, "i_start": 3, "i_end": 6}, "verb": {"text": "appear", "start": 39, "end": 45, "i_start": 8, "i_end": 8}}], "id": 1892}, {"sent": "the dual notion is called right cancellation .", "tokens": ["the", "dual", "notion", "is", "called", "right", "cancellation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dual notion", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 16, "end": 25, "i_start": 3, "i_end": 4}}], "id": 1893}, {"sent": "recently , convolutional neural networks have been proved to be capable of dramatically boosting the performance of many mainstream computer vision problems .", "tokens": ["recently", ",", "convolutional", "neural", "networks", "have", "been", "proved", "to", "be", "capable", "of", "dramatically", "boosting", "the", "performance", "of", "many", "mainstream", "computer", "vision", "problems", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 11, "end": 40, "i_start": 2, "i_end": 4}, "verb": {"text": "have been proved", "start": 41, "end": 57, "i_start": 5, "i_end": 7}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "boosting", "start": 88, "end": 96, "i_start": 13, "i_end": 13}}, {"character": {"text": "problems", "start": 148, "end": 156, "i_start": 21, "i_end": 21}, "action": {"text": "performance", "start": 101, "end": 112, "i_start": 15, "i_end": 15}}], "id": 1894}, {"sent": "as immirzi has emphasized , in the canonical transformation used to define the connection variables there is a family of choices generated by one non-zero , real parameter \u03b3 , .", "tokens": ["as", "immirzi", "has", "emphasized", ",", "in", "the", "canonical", "transformation", "used", "to", "define", "the", "connection", "variables", "there", "is", "a", "family", "of", "choices", "generated", "by", "one", "non", "-", "zero", ",", "real", "parameter", "\u03b3", ",", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "there", "start": 100, "end": 105, "i_start": 15, "i_end": 15}, "verb": {"text": "is", "start": 106, "end": 108, "i_start": 16, "i_end": 16}}, {"character": {"text": "immirzi", "start": 3, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "emphasized", "start": 15, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "one non-zero , real parameter", "start": 142, "end": 171, "i_start": 23, "i_end": 29}, "action": {"text": "generated", "start": 129, "end": 138, "i_start": 21, "i_end": 21}}], "id": 1895}, {"sent": "therefore r has exactly two idempotents and so r is a wvnr ring .", "tokens": ["therefore", "r", "has", "exactly", "two", "idempotents", "and", "so", "r", "is", "a", "wvnr", "ring", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "r", "start": 10, "end": 11, "i_start": 1, "i_end": 1}, "verb": {"text": "has", "start": 12, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "r", "start": 10, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "has", "start": 12, "end": 15, "i_start": 2, "i_end": 2}}], "id": 1896}, {"sent": "the equilibrium state of this neutrosophical dynamical system is called the neutrosophic hidden pattern .", "tokens": ["the", "equilibrium", "state", "of", "this", "neutrosophical", "dynamical", "system", "is", "called", "the", "neutrosophic", "hidden", "pattern", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the equilibrium state of this neutrosophical dynamical system", "start": 0, "end": 61, "i_start": 0, "i_end": 7}, "verb": {"text": "is called", "start": 62, "end": 71, "i_start": 8, "i_end": 9}}], "id": 1897}, {"sent": "examples of recent models include denoising autoencoders and generative adversarial networks .", "tokens": ["examples", "of", "recent", "models", "include", "denoising", "autoencoders", "and", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "examples of recent models", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "include", "start": 26, "end": 33, "i_start": 4, "i_end": 4}}], "id": 1898}, {"sent": "multi-task learning aims at improving the generalization performance of a task using related tasks .", "tokens": ["multi", "-", "task", "learning", "aims", "at", "improving", "the", "generalization", "performance", "of", "a", "task", "using", "related", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "multi-task learning", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "aims", "start": 20, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 11, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "aims", "start": 20, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 11, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "improving", "start": 28, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "task", "start": 74, "end": 78, "i_start": 12, "i_end": 12}, "action": {"text": "performance", "start": 57, "end": 68, "i_start": 9, "i_end": 9}}, {"character": {"text": "task", "start": 74, "end": 78, "i_start": 12, "i_end": 12}, "action": {"text": "using", "start": 79, "end": 84, "i_start": 13, "i_end": 13}}], "id": 1899}, {"sent": "cosmic strings are topologically stable one-dimensional objects which are predicted by unified theories and can be created during a phase transition in the early universe .", "tokens": ["cosmic", "strings", "are", "topologically", "stable", "one", "-", "dimensional", "objects", "which", "are", "predicted", "by", "unified", "theories", "and", "can", "be", "created", "during", "a", "phase", "transition", "in", "the", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}], "id": 1900}, {"sent": "we employed the resnet34 architecture for learning the feature embedding .", "tokens": ["we", "employed", "the", "resnet34", "architecture", "for", "learning", "the", "feature", "embedding", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employed", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employed", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "learning", "start": 42, "end": 50, "i_start": 6, "i_end": 6}}], "id": 1901}, {"sent": "because this closure consist of only finitely many components , it is the whole surface .", "tokens": ["because", "this", "closure", "consist", "of", "only", "finitely", "many", "components", ",", "it", "is", "the", "whole", "surface", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 64, "end": 66, "i_start": 10, "i_end": 10}, "verb": {"text": "is", "start": 67, "end": 69, "i_start": 11, "i_end": 11}}, {"character": {"text": "consist", "start": 21, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "because", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}], "id": 1902}, {"sent": "the generalized gradient approximation parameterized by perdew-burke-ernzerhof is utilized to describe exchange-correlation functional .", "tokens": ["the", "generalized", "gradient", "approximation", "parameterized", "by", "perdew", "-", "burke", "-", "ernzerhof", "is", "utilized", "to", "describe", "exchange", "-", "correlation", "functional", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation parameterized by perdew-burke-ernzerhof", "start": 0, "end": 78, "i_start": 0, "i_end": 10}, "verb": {"text": "is utilized", "start": 79, "end": 90, "i_start": 11, "i_end": 12}}, {"character": {"text": "perdew", "start": 56, "end": 62, "i_start": 6, "i_end": 6}, "action": {"text": "parameterized", "start": 39, "end": 52, "i_start": 4, "i_end": 4}}, {"character": {"text": "approximation", "start": 25, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "describe", "start": 94, "end": 102, "i_start": 14, "i_end": 14}}, {"character": {"text": "exchange", "start": 103, "end": 111, "i_start": 15, "i_end": 15}, "action": {"text": "functional", "start": 124, "end": 134, "i_start": 18, "i_end": 18}}], "id": 1903}, {"sent": "this phenomena is the partner of the os 2 .", "tokens": ["this", "phenomena", "is", "the", "partner", "of", "the", "os", "2", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this phenomena", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "phenomena", "start": 5, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "partner", "start": 22, "end": 29, "i_start": 4, "i_end": 4}}], "id": 1904}, {"sent": "convolutional neural networks have achieved exceptional results in many large-scale computer vision applications , particularly in image recognition task .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "exceptional", "results", "in", "many", "large", "-", "scale", "computer", "vision", "applications", ",", "particularly", "in", "image", "recognition", "task", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 1905}, {"sent": "recent study has revealed that deep neural networks trained by gradient-based algorithms can fit training data with random labels and achieve zero training error .", "tokens": ["recent", "study", "has", "revealed", "that", "deep", "neural", "networks", "trained", "by", "gradient", "-", "based", "algorithms", "can", "fit", "training", "data", "with", "random", "labels", "and", "achieve", "zero", "training", "error", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent study", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "has revealed", "start": 13, "end": 25, "i_start": 2, "i_end": 3}}, {"subject": {"text": "deep neural networks trained by gradient-based algorithms", "start": 31, "end": 88, "i_start": 5, "i_end": 13}, "verb": {"text": "fit", "start": 93, "end": 96, "i_start": 15, "i_end": 15}}, {"character": {"text": "study", "start": 7, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "revealed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 43, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "fit", "start": 93, "end": 96, "i_start": 15, "i_end": 15}}, {"character": {"text": "networks", "start": 43, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "achieve", "start": 134, "end": 141, "i_start": 22, "i_end": 22}}], "id": 1906}, {"sent": "the generalized gradient approximation is used to describe the exchangecorrelation functional as parameterized by perdew-burkeernzerhof .", "tokens": ["the", "generalized", "gradient", "approximation", "is", "used", "to", "describe", "the", "exchangecorrelation", "functional", "as", "parameterized", "by", "perdew", "-", "burkeernzerhof", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation", "start": 0, "end": 38, "i_start": 0, "i_end": 3}, "verb": {"text": "is used", "start": 39, "end": 46, "i_start": 4, "i_end": 5}}, {"character": {"text": "approximation", "start": 25, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "describe", "start": 50, "end": 58, "i_start": 7, "i_end": 7}}], "id": 1907}, {"sent": "this system is implemented in python using the pytorch deep learning framework .", "tokens": ["this", "system", "is", "implemented", "in", "python", "using", "the", "pytorch", "deep", "learning", "framework", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this system", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is implemented", "start": 12, "end": 26, "i_start": 2, "i_end": 3}}], "id": 1908}, {"sent": "bosonization is a well-known method in 1d systems , and the presentation in chapter 3 is a variation on a well-worn theme .", "tokens": ["bosonization", "is", "a", "well", "-", "known", "method", "in", "1d", "systems", ",", "and", "the", "presentation", "in", "chapter", "3", "is", "a", "variation", "on", "a", "well", "-", "worn", "theme", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "bosonization", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 1, "i_end": 1}}], "id": 1909}, {"sent": "temperature dependence of pyroelectric coefficient .", "tokens": ["temperature", "dependence", "of", "pyroelectric", "coefficient", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "coefficient", "start": 39, "end": 50, "i_start": 4, "i_end": 4}, "action": {"text": "dependence", "start": 12, "end": 22, "i_start": 1, "i_end": 1}}], "id": 1910}, {"sent": "each conv-layer block consists of a 1d convolutional layer with a kernel width of 5 and a soft-plus nonlinearity , followed by a batch normalization layer .", "tokens": ["each", "conv", "-", "layer", "block", "consists", "of", "a", "1d", "convolutional", "layer", "with", "a", "kernel", "width", "of", "5", "and", "a", "soft", "-", "plus", "nonlinearity", ",", "followed", "by", "a", "batch", "normalization", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each conv-layer block", "start": 0, "end": 21, "i_start": 0, "i_end": 4}, "verb": {"text": "consists", "start": 22, "end": 30, "i_start": 5, "i_end": 5}}], "id": 1911}, {"sent": "by onstru tion we have that t is a proof tree for a and pk .", "tokens": ["by", "onstru", "tion", "we", "have", "that", "t", "is", "a", "proof", "tree", "for", "a", "and", "pk", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "have", "start": 18, "end": 22, "i_start": 4, "i_end": 4}}, {"subject": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "have", "start": 18, "end": 22, "i_start": 4, "i_end": 4}}], "id": 1912}, {"sent": "the free energy consists of the two main contributions , the interaction energy of the collapsed h-blocks do not contribute to the total elastic energy .", "tokens": ["the", "free", "energy", "consists", "of", "the", "two", "main", "contributions", ",", "the", "interaction", "energy", "of", "the", "collapsed", "h", "-", "blocks", "do", "not", "contribute", "to", "the", "total", "elastic", "energy", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the free energy", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the interaction energy of the collapsed h-blocks", "start": 57, "end": 105, "i_start": 10, "i_end": 18}, "verb": {"text": "contribute", "start": 113, "end": 123, "i_start": 21, "i_end": 21}}, {"character": {"text": "energy", "start": 73, "end": 79, "i_start": 12, "i_end": 12}, "action": {"text": "-", "start": 98, "end": 99, "i_start": 17, "i_end": 17}}], "id": 1913}, {"sent": "the wavelength of the critical mode , however , is equal to that when the films interact with rigid contactors and is independent of the shear moduli of the films .", "tokens": ["the", "wavelength", "of", "the", "critical", "mode", ",", "however", ",", "is", "equal", "to", "that", "when", "the", "films", "interact", "with", "rigid", "contactors", "and", "is", "independent", "of", "the", "shear", "moduli", "of", "the", "films", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the wavelength of the critical mode", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 48, "end": 50, "i_start": 9, "i_end": 9}}, {"character": {"text": "films", "start": 74, "end": 79, "i_start": 15, "i_end": 15}, "action": {"text": "interact", "start": 80, "end": 88, "i_start": 16, "i_end": 16}}, {"character": {"text": "wavelength", "start": 4, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "independent", "start": 118, "end": 129, "i_start": 22, "i_end": 22}}], "id": 1914}, {"sent": "such a bivector satisfying is called poisson structure on p .", "tokens": ["such", "a", "bivector", "satisfying", "is", "called", "poisson", "structure", "on", "p", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "such a bivector satisfying", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "is called", "start": 27, "end": 36, "i_start": 4, "i_end": 5}}, {"character": {"text": "bivector", "start": 7, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "satisfying", "start": 16, "end": 26, "i_start": 3, "i_end": 3}}], "id": 1915}, {"sent": "let us define the notion of smarandache infra biseminear-ring .", "tokens": ["let", "us", "define", "the", "notion", "of", "smarandache", "infra", "biseminear", "-", "ring", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "define", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}], "id": 1916}, {"sent": "topological insulators have attracted intense interest from the condensed matter community .", "tokens": ["topological", "insulators", "have", "attracted", "intense", "interest", "from", "the", "condensed", "matter", "community", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "topological insulators", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "have attracted", "start": 23, "end": 37, "i_start": 2, "i_end": 3}}, {"character": {"text": "insulators", "start": 12, "end": 22, "i_start": 1, "i_end": 1}, "action": {"text": "attracted", "start": 28, "end": 37, "i_start": 3, "i_end": 3}}], "id": 1917}, {"sent": "our encoder architecture is based on resnet34 with 3d convolutions .", "tokens": ["our", "encoder", "architecture", "is", "based", "on", "resnet34", "with", "3d", "convolutions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our encoder architecture", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is based", "start": 25, "end": 33, "i_start": 3, "i_end": 4}}], "id": 1918}, {"sent": "the at connect such quantities and thus they refer exclusively to the component form of tensor quantities and in that form they transform only some components of the whole tensor quantity .", "tokens": ["the", "at", "connect", "such", "quantities", "and", "thus", "they", "refer", "exclusively", "to", "the", "component", "form", "of", "tensor", "quantities", "and", "in", "that", "form", "they", "transform", "only", "some", "components", "of", "the", "whole", "tensor", "quantity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "they", "start": 40, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "connect", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "they", "start": 40, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "refer", "start": 45, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "they", "start": 40, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "transform", "start": 128, "end": 137, "i_start": 22, "i_end": 22}}], "id": 1919}, {"sent": "the seq2seq model with lstm has achieved a great success on different tasks such as speech recognition .", "tokens": ["the", "seq2seq", "model", "with", "lstm", "has", "achieved", "a", "great", "success", "on", "different", "tasks", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the seq2seq model with lstm", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "has achieved", "start": 28, "end": 40, "i_start": 5, "i_end": 6}}, {"character": {"text": "model", "start": 12, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 32, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "model", "start": 12, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 49, "end": 56, "i_start": 9, "i_end": 9}}], "id": 1920}, {"sent": "geiser , for the zeus collaboration , these proceedings .", "tokens": ["geiser", ",", "for", "the", "zeus", "collaboration", ",", "these", "proceedings", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1921}, {"sent": "we approach the tasks using a text classification system based on the scikit-learn implementation of the liblinear svm classifier .", "tokens": ["we", "approach", "the", "tasks", "using", "a", "text", "classification", "system", "based", "on", "the", "scikit", "-", "learn", "implementation", "of", "the", "liblinear", "svm", "classifier", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "approach", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "approach", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "system", "start": 50, "end": 56, "i_start": 8, "i_end": 8}, "action": {"text": "classification", "start": 35, "end": 49, "i_start": 7, "i_end": 7}}], "id": 1922}, {"sent": "li et al proposed a detection based approach where the input image was first segmented into foreground-background regions and a hog feature based head-shoulder detector was used to detect each person in the crowd .", "tokens": ["li", "et", "al", "proposed", "a", "detection", "based", "approach", "where", "the", "input", "image", "was", "first", "segmented", "into", "foreground", "-", "background", "regions", "and", "a", "hog", "feature", "based", "head", "-", "shoulder", "detector", "was", "used", "to", "detect", "each", "person", "in", "the", "crowd", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "li et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"subject": {"text": "a detection based approach where the input image was first segmented into foreground-background regions and a hog feature based head-shoulder detector", "start": 18, "end": 168, "i_start": 4, "i_end": 28}, "verb": {"text": "used", "start": 173, "end": 177, "i_start": 30, "i_end": 30}}, {"character": {"text": "person", "start": 193, "end": 199, "i_start": 34, "i_end": 34}, "action": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "li", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}], "id": 1923}, {"sent": "please note that the vois in the cerebellum had to be excluded in 3 subjects , 6 , 7 , 21 .", "tokens": ["please", "note", "that", "the", "vois", "in", "the", "cerebellum", "had", "to", "be", "excluded", "in", "3", "subjects", ",", "6", ",", "7", ",", "21", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the vois in the cerebellum", "start": 17, "end": 43, "i_start": 3, "i_end": 7}, "verb": {"text": "note", "start": 7, "end": 11, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the vois in the cerebellum", "start": 17, "end": 43, "i_start": 3, "i_end": 7}, "verb": {"text": "had", "start": 44, "end": 47, "i_start": 8, "i_end": 8}}], "id": 1924}, {"sent": "if , however , the gluino is the lsp and decays through the r parity violating graph of fig .", "tokens": ["if", ",", "however", ",", "the", "gluino", "is", "the", "lsp", "and", "decays", "through", "the", "r", "parity", "violating", "graph", "of", "fig", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the gluino", "start": 15, "end": 25, "i_start": 4, "i_end": 5}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the gluino", "start": 15, "end": 25, "i_start": 4, "i_end": 5}, "verb": {"text": "decays", "start": 41, "end": 47, "i_start": 10, "i_end": 10}}, {"character": {"text": "gluino", "start": 19, "end": 25, "i_start": 5, "i_end": 5}, "action": {"text": "decays", "start": 41, "end": 47, "i_start": 10, "i_end": 10}}, {"character": {"text": "graph", "start": 79, "end": 84, "i_start": 16, "i_end": 16}, "action": {"text": "violating", "start": 69, "end": 78, "i_start": 15, "i_end": 15}}], "id": 1925}, {"sent": "szegedy et al observed that , despite their excellent recognition performances , neural networks get fooled by structured perturbations that are quasi-imperceptible to humans .", "tokens": ["szegedy", "et", "al", "observed", "that", ",", "despite", "their", "excellent", "recognition", "performances", ",", "neural", "networks", "get", "fooled", "by", "structured", "perturbations", "that", "are", "quasi", "-", "imperceptible", "to", "humans", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "szegedy et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "observed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}, {"subject": {"text": "neural networks", "start": 81, "end": 96, "i_start": 12, "i_end": 13}, "verb": {"text": "fooled", "start": 101, "end": 107, "i_start": 15, "i_end": 15}}, {"character": {"text": "szegedy", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "observed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 88, "end": 96, "i_start": 13, "i_end": 13}, "action": {"text": "performances", "start": 66, "end": 78, "i_start": 10, "i_end": 10}}], "id": 1926}, {"sent": "here we use the notation and results for cell-centered functions from .", "tokens": ["here", "we", "use", "the", "notation", "and", "results", "for", "cell", "-", "centered", "functions", "from", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}], "id": 1927}, {"sent": "the visible sector is the ordinary mssm , which communicates with hidden x-sector via messenger sector .", "tokens": ["the", "visible", "sector", "is", "the", "ordinary", "mssm", ",", "which", "communicates", "with", "hidden", "x", "-", "sector", "via", "messenger", "sector", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the visible sector", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 1928}, {"sent": "in all of our temperature and doping dependent calculations the electronic exchange correlation energy is treated under the generalized gradient approximation using perdew-burke-enzerhof functional .", "tokens": ["in", "all", "of", "our", "temperature", "and", "doping", "dependent", "calculations", "the", "electronic", "exchange", "correlation", "energy", "is", "treated", "under", "the", "generalized", "gradient", "approximation", "using", "perdew", "-", "burke", "-", "enzerhof", "functional", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the electronic exchange correlation energy", "start": 60, "end": 102, "i_start": 9, "i_end": 13}, "verb": {"text": "is treated", "start": 103, "end": 113, "i_start": 14, "i_end": 15}}, {"character": {"text": "approximation", "start": 145, "end": 158, "i_start": 20, "i_end": 20}, "action": {"text": "using", "start": 159, "end": 164, "i_start": 21, "i_end": 21}}, {"character": {"text": "temperature", "start": 14, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "dependent", "start": 37, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "doping", "start": 30, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "dependent", "start": 37, "end": 46, "i_start": 7, "i_end": 7}}], "id": 1929}, {"sent": "the resistivity plays an important parameter in the detector operation .", "tokens": ["the", "resistivity", "plays", "an", "important", "parameter", "in", "the", "detector", "operation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the resistivity", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "plays", "start": 16, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "resistivity", "start": 4, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "plays", "start": 16, "end": 21, "i_start": 2, "i_end": 2}}], "id": 1930}, {"sent": "again , percolation is the key to understanding .", "tokens": ["again", ",", "percolation", "is", "the", "key", "to", "understanding", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "percolation", "start": 8, "end": 19, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 1931}, {"sent": "convolutional neural networks have been extremely successful across many domains in machine learning and computer vision .", "tokens": ["convolutional", "neural", "networks", "have", "been", "extremely", "successful", "across", "many", "domains", "in", "machine", "learning", "and", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 50, "end": 60, "i_start": 6, "i_end": 6}}], "id": 1932}, {"sent": "recently , zamir et al propose utilizing a convolutional lstm as a generic feedback architecture .", "tokens": ["recently", ",", "zamir", "et", "al", "propose", "utilizing", "a", "convolutional", "lstm", "as", "a", "generic", "feedback", "architecture", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "zamir", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "propose", "start": 23, "end": 30, "i_start": 5, "i_end": 5}}], "id": 1933}, {"sent": "furthermore , not all classes of nonlinear systems can be stabilized by smooth feedback control or by time 225 invariant state feedback control .", "tokens": ["furthermore", ",", "not", "all", "classes", "of", "nonlinear", "systems", "can", "be", "stabilized", "by", "smooth", "feedback", "control", "or", "by", "time", "225", "invariant", "state", "feedback", "control", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "not all classes of nonlinear systems", "start": 14, "end": 50, "i_start": 2, "i_end": 7}, "verb": {"text": "can be stabilized", "start": 51, "end": 68, "i_start": 8, "i_end": 10}}, {"character": {"text": "or", "start": 96, "end": 98, "i_start": 15, "i_end": 15}, "action": {"text": "stabilized", "start": 58, "end": 68, "i_start": 10, "i_end": 10}}], "id": 1934}, {"sent": "in this section , we first recall the quasimap theory for nonsingular git quotients introduced in .", "tokens": ["in", "this", "section", ",", "we", "first", "recall", "the", "quasimap", "theory", "for", "nonsingular", "git", "quotients", "introduced", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "recall", "start": 27, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "recall", "start": 27, "end": 33, "i_start": 6, "i_end": 6}}], "id": 1935}, {"sent": "it is plausible that it is the scattering in the less-transparent samples of mgb2 .", "tokens": ["it", "is", "plausible", "that", "it", "is", "the", "scattering", "in", "the", "less", "-", "transparent", "samples", "of", "mgb2", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 5, "i_end": 5}}], "id": 1936}, {"sent": "neural networks have achieved state-of-the-art results in a wide variety of supervised learning tasks , such as image recognition .", "tokens": ["neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "results", "in", "a", "wide", "variety", "of", "supervised", "learning", "tasks", ",", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have achieved", "start": 16, "end": 29, "i_start": 2, "i_end": 3}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "achieved", "start": 21, "end": 29, "i_start": 3, "i_end": 3}}], "id": 1937}, {"sent": "we train the disparity network for 200 epochs using the adam optimizer .", "tokens": ["we", "train", "the", "disparity", "network", "for", "200", "epochs", "using", "the", "adam", "optimizer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 46, "end": 51, "i_start": 8, "i_end": 8}}], "id": 1938}, {"sent": "should the project directory not be specified then the current working directory at the analyst site is used as the source project directory .", "tokens": ["should", "the", "project", "directory", "not", "be", "specified", "then", "the", "current", "working", "directory", "at", "the", "analyst", "site", "is", "used", "as", "the", "source", "project", "directory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the current working directory at the analyst site", "start": 51, "end": 100, "i_start": 8, "i_end": 15}, "verb": {"text": "is used", "start": 101, "end": 108, "i_start": 16, "i_end": 17}}, {"character": {"text": "directory", "start": 19, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "working", "start": 63, "end": 70, "i_start": 10, "i_end": 10}}], "id": 1939}, {"sent": "however , the exact zero modes alone can not break chiral symmetry spontaneously .", "tokens": ["however", ",", "the", "exact", "zero", "modes", "alone", "can", "not", "break", "chiral", "symmetry", "spontaneously", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the exact zero modes alone", "start": 10, "end": 36, "i_start": 2, "i_end": 6}, "verb": {"text": "can not break", "start": 37, "end": 50, "i_start": 7, "i_end": 9}}, {"character": {"text": "zero modes", "start": 20, "end": 30, "i_start": 4, "i_end": 5}, "action": {"text": "break", "start": 45, "end": 50, "i_start": 9, "i_end": 9}}], "id": 1940}, {"sent": "even with good seeing conditions , the corona instrument is not diffraction limited .", "tokens": ["even", "with", "good", "seeing", "conditions", ",", "the", "corona", "instrument", "is", "not", "diffraction", "limited", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the corona instrument", "start": 35, "end": 56, "i_start": 6, "i_end": 8}, "verb": {"text": "is not", "start": 57, "end": 63, "i_start": 9, "i_end": 10}}], "id": 1941}, {"sent": "we use random images from the coco dataset , using the original 80k-40k training and validation splits for our train and test splits .", "tokens": ["we", "use", "random", "images", "from", "the", "coco", "dataset", ",", "using", "the", "original", "80k-40k", "training", "and", "validation", "splits", "for", "our", "train", "and", "test", "splits", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 45, "end": 50, "i_start": 9, "i_end": 9}}], "id": 1942}, {"sent": "a quantum computer is a device that uses the laws of quantum physics to solve problems .", "tokens": ["a", "quantum", "computer", "is", "a", "device", "that", "uses", "the", "laws", "of", "quantum", "physics", "to", "solve", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a quantum computer", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "device", "start": 24, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "uses", "start": 36, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "device", "start": 24, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "solve", "start": 72, "end": 77, "i_start": 14, "i_end": 14}}], "id": 1943}, {"sent": "most existing work on group activity recognition has used hand-crafted features in structured models to represent information between individuals in space and time domains .", "tokens": ["most", "existing", "work", "on", "group", "activity", "recognition", "has", "used", "hand", "-", "crafted", "features", "in", "structured", "models", "to", "represent", "information", "between", "individuals", "in", "space", "and", "time", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "most existing work on group activity recognition", "start": 0, "end": 48, "i_start": 0, "i_end": 6}, "verb": {"text": "has used", "start": 49, "end": 57, "i_start": 7, "i_end": 8}}, {"character": {"text": "work", "start": 14, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "used", "start": 53, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "group", "start": 22, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "activity", "start": 28, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "hand", "start": 58, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "crafted", "start": 63, "end": 70, "i_start": 11, "i_end": 11}}, {"character": {"text": "features", "start": 71, "end": 79, "i_start": 12, "i_end": 12}, "action": {"text": "represent", "start": 104, "end": 113, "i_start": 17, "i_end": 17}}], "id": 1944}, {"sent": "our model is based on a popular u-net architecture with four downsampling and upsampling blocks .", "tokens": ["our", "model", "is", "based", "on", "a", "popular", "u", "-", "net", "architecture", "with", "four", "downsampling", "and", "upsampling", "blocks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is based", "start": 10, "end": 18, "i_start": 2, "i_end": 3}}], "id": 1945}, {"sent": "deep convolutional neural networks have demonstrated significant improvements over traditional approaches in many pattern recognition tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "demonstrated", "significant", "improvements", "over", "traditional", "approaches", "in", "many", "pattern", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have demonstrated", "start": 35, "end": 52, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "demonstrated", "start": 40, "end": 52, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "improvements", "start": 65, "end": 77, "i_start": 7, "i_end": 7}}], "id": 1946}, {"sent": "convolutional neural networks have been largely responsible for the significant progress achieved on visual recognition tasks in recent years .", "tokens": ["convolutional", "neural", "networks", "have", "been", "largely", "responsible", "for", "the", "significant", "progress", "achieved", "on", "visual", "recognition", "tasks", "in", "recent", "years", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "responsible", "start": 48, "end": 59, "i_start": 6, "i_end": 6}}], "id": 1947}, {"sent": "an excellent agreement with the theory can be seen .", "tokens": ["an", "excellent", "agreement", "with", "the", "theory", "can", "be", "seen", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an excellent agreement with the theory", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "can be seen", "start": 39, "end": 50, "i_start": 6, "i_end": 8}}], "id": 1948}, {"sent": "recently , deep learning has been successfully adopted in various areas such as computer vision , automatic speech recognition , natural language processing , audio recognition and bioinformatics .", "tokens": ["recently", ",", "deep", "learning", "has", "been", "successfully", "adopted", "in", "various", "areas", "such", "as", "computer", "vision", ",", "automatic", "speech", "recognition", ",", "natural", "language", "processing", ",", "audio", "recognition", "and", "bioinformatics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 11, "end": 24, "i_start": 2, "i_end": 3}, "verb": {"text": "adopted", "start": 47, "end": 54, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep learning", "start": 11, "end": 24, "i_start": 2, "i_end": 3}, "verb": {"text": "has been", "start": 25, "end": 33, "i_start": 4, "i_end": 5}}], "id": 1949}, {"sent": "circles are from ac-susceptibility measurements ref .", "tokens": ["circles", "are", "from", "ac", "-", "susceptibility", "measurements", "ref", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "circles", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 8, "end": 11, "i_start": 1, "i_end": 1}}], "id": 1950}, {"sent": "such an asymmetry is the remnant of the partonic asymmetry .", "tokens": ["such", "an", "asymmetry", "is", "the", "remnant", "of", "the", "partonic", "asymmetry", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such an asymmetry", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}], "id": 1951}, {"sent": "for mimo uplink communications , the gram-schmidt based analog combiner design algorithm was developed in .", "tokens": ["for", "mimo", "uplink", "communications", ",", "the", "gram", "-", "schmidt", "based", "analog", "combiner", "design", "algorithm", "was", "developed", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the gram-schmidt based analog combiner design algorithm", "start": 33, "end": 88, "i_start": 5, "i_end": 13}, "verb": {"text": "was developed", "start": 89, "end": 102, "i_start": 14, "i_end": 15}}], "id": 1952}, {"sent": "in 2012 , marques and neves verified the willmore conjecture in full generality .", "tokens": ["in", "2012", ",", "marques", "and", "neves", "verified", "the", "willmore", "conjecture", "in", "full", "generality", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "marques and neves", "start": 10, "end": 27, "i_start": 3, "i_end": 5}, "verb": {"text": "verified", "start": 28, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "marques", "start": 10, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "verified", "start": 28, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "neves", "start": 22, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "verified", "start": 28, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "willmore", "start": 41, "end": 49, "i_start": 8, "i_end": 8}, "action": {"text": "conjecture", "start": 50, "end": 60, "i_start": 9, "i_end": 9}}], "id": 1953}, {"sent": "the presence of this coupling acts as a friction term in the inflationary field of the cosmological evolution .", "tokens": ["the", "presence", "of", "this", "coupling", "acts", "as", "a", "friction", "term", "in", "the", "inflationary", "field", "of", "the", "cosmological", "evolution", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the presence of this coupling", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "acts", "start": 30, "end": 34, "i_start": 5, "i_end": 5}}, {"character": {"text": "presence", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "acts", "start": 30, "end": 34, "i_start": 5, "i_end": 5}}], "id": 1954}, {"sent": "the virtual bound state pair of the first exited state is given by triangles , the centrifugal eigenvalue by circles .", "tokens": ["the", "virtual", "bound", "state", "pair", "of", "the", "first", "exited", "state", "is", "given", "by", "triangles", ",", "the", "centrifugal", "eigenvalue", "by", "circles", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the virtual bound state pair of the first exited state", "start": 0, "end": 54, "i_start": 0, "i_end": 9}, "verb": {"text": "is given", "start": 55, "end": 63, "i_start": 10, "i_end": 11}}, {"character": {"text": "state", "start": 49, "end": 54, "i_start": 9, "i_end": 9}, "action": {"text": "exited", "start": 42, "end": 48, "i_start": 8, "i_end": 8}}], "id": 1955}, {"sent": "deep networks have recently exhibited state-of-the-art performance in computer vision tasks such as image classification and object detection .", "tokens": ["deep", "networks", "have", "recently", "exhibited", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "computer", "vision", "tasks", "such", "as", "image", "classification", "and", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep networks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "exhibited", "start": 28, "end": 37, "i_start": 4, "i_end": 4}}, {"subject": {"text": "deep networks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "have", "start": 14, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "networks", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "exhibited", "start": 28, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "performance", "start": 55, "end": 66, "i_start": 12, "i_end": 12}}], "id": 1956}, {"sent": "the numerical setup for our dsa simulations was described in detail kang et al .", "tokens": ["the", "numerical", "setup", "for", "our", "dsa", "simulations", "was", "described", "in", "detail", "kang", "et", "al", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the numerical setup for our dsa simulations", "start": 0, "end": 43, "i_start": 0, "i_end": 6}, "verb": {"text": "was described", "start": 44, "end": 57, "i_start": 7, "i_end": 8}}, {"character": {"text": "kang", "start": 68, "end": 72, "i_start": 11, "i_end": 11}, "action": {"text": "described", "start": 48, "end": 57, "i_start": 8, "i_end": 8}}], "id": 1957}, {"sent": "in this article we construct absorbing boundary conditions for the bssn system which preserve the constraints and discuss the well-posedness of the resulting initial-boundary value problem .", "tokens": ["in", "this", "article", "we", "construct", "absorbing", "boundary", "conditions", "for", "the", "bssn", "system", "which", "preserve", "the", "constraints", "and", "discuss", "the", "well", "-", "posedness", "of", "the", "resulting", "initial", "-", "boundary", "value", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "construct", "start": 19, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "construct", "start": 19, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "conditions", "start": 48, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "absorbing", "start": 29, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "conditions", "start": 48, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "preserve", "start": 85, "end": 93, "i_start": 13, "i_end": 13}}, {"character": {"text": "conditions", "start": 48, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "discuss", "start": 114, "end": 121, "i_start": 17, "i_end": 17}}], "id": 1958}, {"sent": "we also evaluate our mfrcns on the ms coco dataset , that contains images of 80 categories of objects .", "tokens": ["we", "also", "evaluate", "our", "mfrcns", "on", "the", "ms", "coco", "dataset", ",", "that", "contains", "images", "of", "80", "categories", "of", "objects", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "dataset", "start": 43, "end": 50, "i_start": 9, "i_end": 9}, "action": {"text": "contains", "start": 58, "end": 66, "i_start": 12, "i_end": 12}}], "id": 1959}, {"sent": "some of the most successful techniques include generative adversarial networks and variational autoencoders .", "tokens": ["some", "of", "the", "most", "successful", "techniques", "include", "generative", "adversarial", "networks", "and", "variational", "autoencoders", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "some of the most successful techniques", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "include", "start": 39, "end": 46, "i_start": 6, "i_end": 6}}], "id": 1960}, {"sent": "deep neural networks have been significantly successful in many artificial intelligence tasks such as im- age classification .", "tokens": ["deep", "neural", "networks", "have", "been", "significantly", "successful", "in", "many", "artificial", "intelligence", "tasks", "such", "as", "im-", "age", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 45, "end": 55, "i_start": 6, "i_end": 6}}], "id": 1961}, {"sent": "this sensitivity manifests itself in predictable changes in wave speed , wavelength and growth rate along an expanding jet .", "tokens": ["this", "sensitivity", "manifests", "itself", "in", "predictable", "changes", "in", "wave", "speed", ",", "wavelength", "and", "growth", "rate", "along", "an", "expanding", "jet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this sensitivity", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "manifests", "start": 17, "end": 26, "i_start": 2, "i_end": 2}}], "id": 1962}, {"sent": "hd 152391 hd 152391 is the most active star in our sample .", "tokens": ["hd", "152391", "hd", "152391", "is", "the", "most", "active", "star", "in", "our", "sample", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "hd 152391 hd 152391", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 4, "i_end": 4}}, {"character": {"text": "star", "start": 39, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "active", "start": 32, "end": 38, "i_start": 7, "i_end": 7}}], "id": 1963}, {"sent": "the ghirlanda-guerra identities for mixed p-spin model .", "tokens": ["the", "ghirlanda", "-", "guerra", "identities", "for", "mixed", "p", "-", "spin", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1964}, {"sent": "stackgan is able to generate photo-realistic images from some text descriptions .", "tokens": ["stackgan", "is", "able", "to", "generate", "photo", "-", "realistic", "images", "from", "some", "text", "descriptions", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "stackgan", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "stackgan", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "generate", "start": 20, "end": 28, "i_start": 4, "i_end": 4}}], "id": 1965}, {"sent": "the nucleus of arp220 is the only significant source within the beam in the narrow band , the arp220 nucleus is certainly the iron line source .", "tokens": ["the", "nucleus", "of", "arp220", "is", "the", "only", "significant", "source", "within", "the", "beam", "in", "the", "narrow", "band", ",", "the", "arp220", "nucleus", "is", "certainly", "the", "iron", "line", "source", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the arp220 nucleus", "start": 90, "end": 108, "i_start": 17, "i_end": 19}, "verb": {"text": "is", "start": 109, "end": 111, "i_start": 20, "i_end": 20}}, {"subject": {"text": "the arp220 nucleus", "start": 90, "end": 108, "i_start": 17, "i_end": 19}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "nucleus", "start": 4, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "source", "start": 136, "end": 142, "i_start": 25, "i_end": 25}}], "id": 1966}, {"sent": "pravda-starov , spectra and semigroup smoothing for non-elliptic quadratic oper ators , math .", "tokens": ["pravda", "-", "starov", ",", "spectra", "and", "semigroup", "smoothing", "for", "non", "-", "elliptic", "quadratic", "oper", "ators", ",", "math", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "pravda-starov", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "smoothing", "start": 38, "end": 47, "i_start": 7, "i_end": 7}}], "id": 1967}, {"sent": "in , gopalan et al generate intermediate representations in the form of subspaces along the geodesic path connecting the source subspace and the target subspace on the grassmann manifold .", "tokens": ["in", ",", "gopalan", "et", "al", "generate", "intermediate", "representations", "in", "the", "form", "of", "subspaces", "along", "the", "geodesic", "path", "connecting", "the", "source", "subspace", "and", "the", "target", "subspace", "on", "the", "grassmann", "manifold", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "gopalan et al", "start": 5, "end": 18, "i_start": 2, "i_end": 4}, "verb": {"text": "generate", "start": 19, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "gopalan", "start": 5, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "generate", "start": 19, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "subspaces", "start": 72, "end": 81, "i_start": 12, "i_end": 12}, "action": {"text": "connecting", "start": 106, "end": 116, "i_start": 17, "i_end": 17}}], "id": 1968}, {"sent": "in recent years , deep convolution neural networks have achieved promising performance on many artificial intelligence tasks , including image recognition .", "tokens": ["in", "recent", "years", ",", "deep", "convolution", "neural", "networks", "have", "achieved", "promising", "performance", "on", "many", "artificial", "intelligence", "tasks", ",", "including", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolution neural networks", "start": 18, "end": 50, "i_start": 4, "i_end": 7}, "verb": {"text": "have achieved", "start": 51, "end": 64, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 42, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 56, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 42, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "performance", "start": 75, "end": 86, "i_start": 11, "i_end": 11}}, {"character": {"text": "performance", "start": 75, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "promising", "start": 65, "end": 74, "i_start": 10, "i_end": 10}}], "id": 1969}, {"sent": "there have been multiple extensions to overcome this shortcoming , including using a moving fixed-size tsdf volume and meshing voxels exiting this volume .", "tokens": ["there", "have", "been", "multiple", "extensions", "to", "overcome", "this", "shortcoming", ",", "including", "using", "a", "moving", "fixed", "-", "size", "tsdf", "volume", "and", "meshing", "voxels", "exiting", "this", "volume", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "have been", "start": 6, "end": 15, "i_start": 1, "i_end": 2}}, {"character": {"text": "voxels", "start": 127, "end": 133, "i_start": 21, "i_end": 21}, "action": {"text": "exiting", "start": 134, "end": 141, "i_start": 22, "i_end": 22}}], "id": 1970}, {"sent": "solar system constraints on gauss-bonnet mediated dark energy .", "tokens": ["solar", "system", "constraints", "on", "gauss", "-", "bonnet", "mediated", "dark", "energy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "constraints", "start": 13, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "mediated", "start": 41, "end": 49, "i_start": 7, "i_end": 7}}], "id": 1971}, {"sent": "convolutional neural networks have been successfully utilized in many fundamental areas of computer vision , including object detection .", "tokens": ["convolutional", "neural", "networks", "have", "been", "successfully", "utilized", "in", "many", "fundamental", "areas", "of", "computer", "vision", ",", "including", "object", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "utilized", "start": 53, "end": 61, "i_start": 6, "i_end": 6}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}], "id": 1972}, {"sent": "we say that a monoid m is a gaussian monoid if it is atomic , gc d .", "tokens": ["we", "say", "that", "a", "monoid", "m", "is", "a", "gaussian", "monoid", "if", "it", "is", "atomic", ",", "gc", "d", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "say", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "say", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 1973}, {"sent": "clearly the attractor as defined here is the graphical limit of the sequence of functions in x .", "tokens": ["clearly", "the", "attractor", "as", "defined", "here", "is", "the", "graphical", "limit", "of", "the", "sequence", "of", "functions", "in", "x", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the attractor as defined here is the graphical limit of the sequence of functions in x", "start": 8, "end": 94, "i_start": 1, "i_end": 16}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "graphical", "start": 45, "end": 54, "i_start": 8, "i_end": 8}, "action": {"text": "limit", "start": 55, "end": 60, "i_start": 9, "i_end": 9}}], "id": 1974}, {"sent": "in so far as teleportation is a measure of entanglement , our results suggest that quantum entanglement is degraded in non inertial frames .", "tokens": ["in", "so", "far", "as", "teleportation", "is", "a", "measure", "of", "entanglement", ",", "our", "results", "suggest", "that", "quantum", "entanglement", "is", "degraded", "in", "non", "inertial", "frames", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "our results", "start": 58, "end": 69, "i_start": 11, "i_end": 12}, "verb": {"text": "suggest", "start": 70, "end": 77, "i_start": 13, "i_end": 13}}, {"subject": {"text": "quantum entanglement", "start": 83, "end": 103, "i_start": 15, "i_end": 16}, "verb": {"text": "degraded", "start": 107, "end": 115, "i_start": 18, "i_end": 18}}, {"character": {"text": "results", "start": 62, "end": 69, "i_start": 12, "i_end": 12}, "action": {"text": "suggest", "start": 70, "end": 77, "i_start": 13, "i_end": 13}}, {"character": {"text": "frames", "start": 132, "end": 138, "i_start": 22, "i_end": 22}, "action": {"text": "degraded", "start": 107, "end": 115, "i_start": 18, "i_end": 18}}], "id": 1975}, {"sent": "since string theory is a consistent enlargement of the field theory framework , we should not expect the effects of these instantons to be limited to those of their field theoretical counterpart .", "tokens": ["since", "string", "theory", "is", "a", "consistent", "enlargement", "of", "the", "field", "theory", "framework", ",", "we", "should", "not", "expect", "the", "effects", "of", "these", "instantons", "to", "be", "limited", "to", "those", "of", "their", "field", "theoretical", "counterpart", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 80, "end": 82, "i_start": 13, "i_end": 13}, "verb": {"text": "should not expect", "start": 83, "end": 100, "i_start": 14, "i_end": 16}}, {"subject": {"text": "the effects of these instantons", "start": 101, "end": 132, "i_start": 17, "i_end": 21}, "verb": {"text": "limited", "start": 139, "end": 146, "i_start": 24, "i_end": 24}}, {"character": {"text": "theory", "start": 13, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "enlargement", "start": 36, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 80, "end": 82, "i_start": 13, "i_end": 13}, "action": {"text": "not expect", "start": 90, "end": 100, "i_start": 15, "i_end": 16}}], "id": 1976}, {"sent": "the representation levels and bin edges are computed using a closed form quantizer .", "tokens": ["the", "representation", "levels", "and", "bin", "edges", "are", "computed", "using", "a", "closed", "form", "quantizer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the representation levels and bin edges", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "are computed", "start": 40, "end": 52, "i_start": 6, "i_end": 7}}], "id": 1977}, {"sent": "deep convolutional neural networks have been successful in many computer vision tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successful", "in", "many", "computer", "vision", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "successful", "start": 45, "end": 55, "i_start": 6, "i_end": 6}}], "id": 1978}, {"sent": "here , the crosses show the parameter sets for which we and open circles ( have observed the total freezeout , bimodal growth , and unimodal growth , respectively .", "tokens": ["here", ",", "the", "crosses", "show", "the", "parameter", "sets", "for", "which", "we", "and", "open", "circles", "(", "have", "observed", "the", "total", "freezeout", ",", "bimodal", "growth", ",", "and", "unimodal", "growth", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the crosses", "start": 7, "end": 18, "i_start": 2, "i_end": 3}, "verb": {"text": "show", "start": 19, "end": 23, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the parameter", "start": 24, "end": 37, "i_start": 5, "i_end": 6}, "verb": {"text": "sets", "start": 38, "end": 42, "i_start": 7, "i_end": 7}}, {"subject": {"text": "for which we and open circles", "start": 43, "end": 72, "i_start": 8, "i_end": 13}, "verb": {"text": "observed", "start": 80, "end": 88, "i_start": 16, "i_end": 16}}, {"character": {"text": "crosses", "start": 11, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "show", "start": 19, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 53, "end": 55, "i_start": 10, "i_end": 10}, "action": {"text": "observed", "start": 80, "end": 88, "i_start": 16, "i_end": 16}}, {"character": {"text": "circles", "start": 65, "end": 72, "i_start": 13, "i_end": 13}, "action": {"text": "observed", "start": 80, "end": 88, "i_start": 16, "i_end": 16}}], "id": 1979}, {"sent": "iii protocol with personal identification and message authentication .", "tokens": ["iii", "protocol", "with", "personal", "identification", "and", "message", "authentication", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1980}, {"sent": "an immediate corollary of theorem 3 1 is the uniqueness of lerayhopf weak solutions for two-dimensional initial data .", "tokens": ["an", "immediate", "corollary", "of", "theorem", "3", "1", "is", "the", "uniqueness", "of", "lerayhopf", "weak", "solutions", "for", "two", "-", "dimensional", "initial", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an immediate corollary of theorem 3 1", "start": 0, "end": 37, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 7, "i_end": 7}}], "id": 1981}, {"sent": "the pcp proposed in attempts to provably recover to a good approximation , by solving a convex optimization .", "tokens": ["the", "pcp", "proposed", "in", "attempts", "to", "provably", "recover", "to", "a", "good", "approximation", ",", "by", "solving", "a", "convex", "optimization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the pcp", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "proposed", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1982}, {"sent": "all other convolutional layers are initialized from the publicly available vgg model .", "tokens": ["all", "other", "convolutional", "layers", "are", "initialized", "from", "the", "publicly", "available", "vgg", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all other convolutional layers", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "are initialized", "start": 31, "end": 46, "i_start": 4, "i_end": 5}}], "id": 1983}, {"sent": "in this paper , i will describe an extension of the program of groupoidification , described by baez .", "tokens": ["in", "this", "paper", ",", "i", "will", "describe", "an", "extension", "of", "the", "program", "of", "groupoidification", ",", "described", "by", "baez", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "i", "start": 16, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "will describe", "start": 18, "end": 31, "i_start": 5, "i_end": 6}}, {"character": {"text": "i", "start": 16, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "describe", "start": 23, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "baez", "start": 96, "end": 100, "i_start": 17, "i_end": 17}, "action": {"text": "described", "start": 83, "end": 92, "i_start": 15, "i_end": 15}}], "id": 1984}, {"sent": "the attacker model and the methodology follows closely the survey by schrittwieser et al .", "tokens": ["the", "attacker", "model", "and", "the", "methodology", "follows", "closely", "the", "survey", "by", "schrittwieser", "et", "al", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the attacker model and the methodology", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "follows", "start": 39, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "model", "start": 13, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "follows", "start": 39, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "methodology", "start": 27, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "follows", "start": 39, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "schrittwieser", "start": 69, "end": 82, "i_start": 11, "i_end": 11}, "action": {"text": "survey", "start": 59, "end": 65, "i_start": 9, "i_end": 9}}], "id": 1985}, {"sent": "in most all of these examples , the instabilities are caused by a viscosity contrast at the fluid-fluid interface .", "tokens": ["in", "most", "all", "of", "these", "examples", ",", "the", "instabilities", "are", "caused", "by", "a", "viscosity", "contrast", "at", "the", "fluid", "-", "fluid", "interface", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the instabilities", "start": 32, "end": 49, "i_start": 7, "i_end": 8}, "verb": {"text": "are caused", "start": 50, "end": 60, "i_start": 9, "i_end": 10}}, {"character": {"text": "contrast", "start": 76, "end": 84, "i_start": 14, "i_end": 14}, "action": {"text": "caused", "start": 54, "end": 60, "i_start": 10, "i_end": 10}}], "id": 1986}, {"sent": "in this section , we demonstrate the effectiveness of admm-nn-s for non-structure pruning and quantization , based on imagenet ilsvrc-2012 , cifar-10 , and mnist data sets , using alexnet , and lenet-5 dnn models .", "tokens": ["in", "this", "section", ",", "we", "demonstrate", "the", "effectiveness", "of", "admm", "-", "nn", "-", "s", "for", "non", "-", "structure", "pruning", "and", "quantization", ",", "based", "on", "imagenet", "ilsvrc-2012", ",", "cifar-10", ",", "and", "mnist", "data", "sets", ",", "using", "alexnet", ",", "and", "lenet-5", "dnn", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "demonstrate", "start": 21, "end": 32, "i_start": 5, "i_end": 5}}, {"subject": {"text": "mnist data sets", "start": 156, "end": 171, "i_start": 30, "i_end": 32}, "verb": {"text": "using", "start": 174, "end": 179, "i_start": 34, "i_end": 34}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "demonstrate", "start": 21, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "using", "start": 174, "end": 179, "i_start": 34, "i_end": 34}}], "id": 1987}, {"sent": "this modification is the removal of the first cn gate at the start of the qbist 12 acting on the th qubit and controlled by the kth qubit .", "tokens": ["this", "modification", "is", "the", "removal", "of", "the", "first", "cn", "gate", "at", "the", "start", "of", "the", "qbist", "12", "acting", "on", "the", "th", "qubit", "and", "controlled", "by", "the", "kth", "qubit", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this modification", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "qubit", "start": 100, "end": 105, "i_start": 21, "i_end": 21}, "action": {"text": "controlled", "start": 110, "end": 120, "i_start": 23, "i_end": 23}}], "id": 1988}, {"sent": "recently , deep convolutional neural networks have attracted a lot of attention in visual recognition due to its good performance .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "attracted", "a", "lot", "of", "attention", "in", "visual", "recognition", "due", "to", "its", "good", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have attracted", "start": 46, "end": 60, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "attracted", "start": 51, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 118, "end": 129, "i_start": 19, "i_end": 19}}], "id": 1989}, {"sent": "among the various embedding techniques , graph convolutional network have attained much attention recently .", "tokens": ["among", "the", "various", "embedding", "techniques", ",", "graph", "convolutional", "network", "have", "attained", "much", "attention", "recently", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "graph convolutional network", "start": 41, "end": 68, "i_start": 6, "i_end": 8}, "verb": {"text": "have attained", "start": 69, "end": 82, "i_start": 9, "i_end": 10}}, {"character": {"text": "network", "start": 61, "end": 68, "i_start": 8, "i_end": 8}, "action": {"text": "attained", "start": 74, "end": 82, "i_start": 10, "i_end": 10}}], "id": 1990}, {"sent": "one interesting feature of our analysis is the use of temperature-dependent coupling constants in the njl model .", "tokens": ["one", "interesting", "feature", "of", "our", "analysis", "is", "the", "use", "of", "temperature", "-", "dependent", "coupling", "constants", "in", "the", "njl", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one interesting feature of our analysis", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 40, "end": 42, "i_start": 6, "i_end": 6}}, {"character": {"text": "constants", "start": 85, "end": 94, "i_start": 14, "i_end": 14}, "action": {"text": "dependent", "start": 66, "end": 75, "i_start": 12, "i_end": 12}}], "id": 1991}, {"sent": "an integrated design-analysis framework for three dimensional composite panels .", "tokens": ["an", "integrated", "design", "-", "analysis", "framework", "for", "three", "dimensional", "composite", "panels", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1992}, {"sent": "our high-resolution data are not flux-calibrated .", "tokens": ["our", "high", "-", "resolution", "data", "are", "not", "flux", "-", "calibrated", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our high-resolution data", "start": 0, "end": 24, "i_start": 0, "i_end": 4}, "verb": {"text": "are not", "start": 25, "end": 32, "i_start": 5, "i_end": 6}}], "id": 1993}, {"sent": "deep generative models such as variational autoencoders and generative adversarial networks have played a prominent role in the advancement of unsupervised learning .", "tokens": ["deep", "generative", "models", "such", "as", "variational", "autoencoders", "and", "generative", "adversarial", "networks", "have", "played", "a", "prominent", "role", "in", "the", "advancement", "of", "unsupervised", "learning", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "deep generative models such as variational autoencoders and generative adversarial networks", "start": 0, "end": 91, "i_start": 0, "i_end": 10}, "verb": {"text": "have played", "start": 92, "end": 103, "i_start": 11, "i_end": 12}}, {"character": {"text": "models", "start": 16, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "played", "start": 97, "end": 103, "i_start": 12, "i_end": 12}}], "id": 1994}, {"sent": "the most immediate characteristics common to the complex networks is their degree distributions with power-law tails .", "tokens": ["the", "most", "immediate", "characteristics", "common", "to", "the", "complex", "networks", "is", "their", "degree", "distributions", "with", "power", "-", "law", "tails", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the most immediate characteristics common to the complex networks", "start": 0, "end": 65, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 66, "end": 68, "i_start": 9, "i_end": 9}}], "id": 1995}, {"sent": "a , we employ the replica method in the path-integral formalism by generalizing the formulation for ground states .", "tokens": ["a", ",", "we", "employ", "the", "replica", "method", "in", "the", "path", "-", "integral", "formalism", "by", "generalizing", "the", "formulation", "for", "ground", "states", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 2, "i_end": 2}, "verb": {"text": "employ", "start": 7, "end": 13, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 2, "i_end": 2}, "action": {"text": "a , we employ", "start": 0, "end": 13, "i_start": 0, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 2, "i_end": 2}, "action": {"text": "generalizing", "start": 67, "end": 79, "i_start": 14, "i_end": 14}}], "id": 1996}, {"sent": "in recent years , deep convolutional networks have achieved remarkable results in many computer vision tasks .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "networks", "have", "achieved", "remarkable", "results", "in", "many", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional networks", "start": 18, "end": 45, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 8, "i_end": 8}}], "id": 1997}, {"sent": "the seminal work of wyner introduced the degraded wiretap channel and the fundamental notion of secrecy capacity .", "tokens": ["the", "seminal", "work", "of", "wyner", "introduced", "the", "degraded", "wiretap", "channel", "and", "the", "fundamental", "notion", "of", "secrecy", "capacity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the seminal work of wyner", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "introduced", "start": 26, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "work", "start": 12, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 26, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "wyner", "start": 20, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "work", "start": 12, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1998}, {"sent": "a mechanism of flow instability and turbulence transition is presented for parallel shear flows .", "tokens": ["a", "mechanism", "of", "flow", "instability", "and", "turbulence", "transition", "is", "presented", "for", "parallel", "shear", "flows", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a mechanism of flow instability and turbulence transition", "start": 0, "end": 57, "i_start": 0, "i_end": 7}, "verb": {"text": "is presented", "start": 58, "end": 70, "i_start": 8, "i_end": 9}}], "id": 1999}, {"sent": "the exchange correlation energy was described by the generalized gradient approximation using the perdew-burke-ernzerhof functional .", "tokens": ["the", "exchange", "correlation", "energy", "was", "described", "by", "the", "generalized", "gradient", "approximation", "using", "the", "perdew", "-", "burke", "-", "ernzerhof", "functional", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the exchange correlation energy", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "was described", "start": 32, "end": 45, "i_start": 4, "i_end": 5}}, {"character": {"text": "approximation", "start": 74, "end": 87, "i_start": 10, "i_end": 10}, "action": {"text": "described", "start": 36, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "approximation", "start": 74, "end": 87, "i_start": 10, "i_end": 10}, "action": {"text": "using", "start": 88, "end": 93, "i_start": 11, "i_end": 11}}], "id": 2000}, {"sent": "grazzini , infrared factorization of tree level qcd amplitudes at the next-to-next-to-leading order and beyond , nucl .", "tokens": ["grazzini", ",", "infrared", "factorization", "of", "tree", "level", "qcd", "amplitudes", "at", "the", "next", "-", "to", "-", "next", "-", "to", "-", "leading", "order", "and", "beyond", ",", "nucl", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2001}, {"sent": "lomb- scargle analysis , using the mean times .", "tokens": ["lomb-", "scargle", "analysis", ",", "using", "the", "mean", "times", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2002}, {"sent": "the example of applies as well in this case , and the kam theorem can not be true for any perturbation .", "tokens": ["the", "example", "of", "applies", "as", "well", "in", "this", "case", ",", "and", "the", "kam", "theorem", "can", "not", "be", "true", "for", "any", "perturbation", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the example of applies as well in this case , and the kam theorem", "start": 0, "end": 65, "i_start": 0, "i_end": 13}, "verb": {"text": "can not be", "start": 66, "end": 76, "i_start": 14, "i_end": 16}}], "id": 2003}, {"sent": "in particular , convolutional neural networks have now become ubiquitous in computational solutions to visual recognition problems such as image classification .", "tokens": ["in", "particular", ",", "convolutional", "neural", "networks", "have", "now", "become", "ubiquitous", "in", "computational", "solutions", "to", "visual", "recognition", "problems", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "become", "start": 55, "end": 61, "i_start": 8, "i_end": 8}}, {"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "have", "start": 46, "end": 50, "i_start": 6, "i_end": 6}}], "id": 2004}, {"sent": "but if higgs is the elementary field one would say that we already have one supersymmetric partner-namely the higgs field .", "tokens": ["but", "if", "higgs", "is", "the", "elementary", "field", "one", "would", "say", "that", "we", "already", "have", "one", "supersymmetric", "partner", "-", "namely", "the", "higgs", "field", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 37, "end": 40, "i_start": 7, "i_end": 7}, "verb": {"text": "would say", "start": 41, "end": 50, "i_start": 8, "i_end": 9}}, {"subject": {"text": "we", "start": 56, "end": 58, "i_start": 11, "i_end": 11}, "verb": {"text": "have", "start": 67, "end": 71, "i_start": 13, "i_end": 13}}, {"character": {"text": "one", "start": 37, "end": 40, "i_start": 7, "i_end": 7}, "action": {"text": "say", "start": 47, "end": 50, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 56, "end": 58, "i_start": 11, "i_end": 11}, "action": {"text": "have", "start": 67, "end": 71, "i_start": 13, "i_end": 13}}], "id": 2005}, {"sent": "in this work , active learning is a process of identifying locations for additional observations that minimize the prediction error and reduce mse or uncertainty , eg , .", "tokens": ["in", "this", "work", ",", "active", "learning", "is", "a", "process", "of", "identifying", "locations", "for", "additional", "observations", "that", "minimize", "the", "prediction", "error", "and", "reduce", "mse", "or", "uncertainty", ",", "eg", ",", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "active learning", "start": 15, "end": 30, "i_start": 4, "i_end": 5}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "identifying", "start": 47, "end": 58, "i_start": 10, "i_end": 10}, "action": {"text": "minimize", "start": 102, "end": 110, "i_start": 16, "i_end": 16}}, {"character": {"text": "identifying", "start": 47, "end": 58, "i_start": 10, "i_end": 10}, "action": {"text": "reduce", "start": 136, "end": 142, "i_start": 21, "i_end": 21}}], "id": 2006}, {"sent": "the most significant effect in this energy range is by the modification of the trajectory due to the coulomb field .", "tokens": ["the", "most", "significant", "effect", "in", "this", "energy", "range", "is", "by", "the", "modification", "of", "the", "trajectory", "due", "to", "the", "coulomb", "field", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most significant effect in this energy range", "start": 0, "end": 48, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 49, "end": 51, "i_start": 8, "i_end": 8}}], "id": 2007}, {"sent": "the obstruction is the noninvariance of the boundary conditions .", "tokens": ["the", "obstruction", "is", "the", "noninvariance", "of", "the", "boundary", "conditions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the obstruction", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 2008}, {"sent": "compressive sensing for sparse signals in achieving simultaneous data acquisition and compression has been extensively studied in the literature .", "tokens": ["compressive", "sensing", "for", "sparse", "signals", "in", "achieving", "simultaneous", "data", "acquisition", "and", "compression", "has", "been", "extensively", "studied", "in", "the", "literature", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "compressive sensing for sparse signals in achieving simultaneous data acquisition and compression", "start": 0, "end": 97, "i_start": 0, "i_end": 11}, "verb": {"text": "studied", "start": 119, "end": 126, "i_start": 15, "i_end": 15}}, {"subject": {"text": "compressive sensing for sparse signals in achieving simultaneous data acquisition and compression", "start": 0, "end": 97, "i_start": 0, "i_end": 11}, "verb": {"text": "has been", "start": 98, "end": 106, "i_start": 12, "i_end": 13}}], "id": 2009}, {"sent": "the 20 candidate image labels per topic are collected by aletras and stevenson using an information retrieval engine .", "tokens": ["the", "20", "candidate", "image", "labels", "per", "topic", "are", "collected", "by", "aletras", "and", "stevenson", "using", "an", "information", "retrieval", "engine", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the 20 candidate image labels per topic", "start": 0, "end": 39, "i_start": 0, "i_end": 6}, "verb": {"text": "are collected", "start": 40, "end": 53, "i_start": 7, "i_end": 8}}, {"character": {"text": "aletras", "start": 57, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "collected", "start": 44, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "aletras", "start": 57, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "using", "start": 79, "end": 84, "i_start": 13, "i_end": 13}}, {"character": {"text": "engine", "start": 110, "end": 116, "i_start": 17, "i_end": 17}, "action": {"text": "retrieval", "start": 100, "end": 109, "i_start": 16, "i_end": 16}}], "id": 2010}, {"sent": "the prepresentative supervised hashing methods , eg , itq-cca , try to learn binary codes which preserve the label similarity between samples .", "tokens": ["the", "prepresentative", "supervised", "hashing", "methods", ",", "eg", ",", "itq", "-", "cca", ",", "try", "to", "learn", "binary", "codes", "which", "preserve", "the", "label", "similarity", "between", "samples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the prepresentative supervised hashing methods", "start": 0, "end": 46, "i_start": 0, "i_end": 4}, "verb": {"text": "try", "start": 64, "end": 67, "i_start": 12, "i_end": 12}}, {"character": {"text": "methods", "start": 39, "end": 46, "i_start": 4, "i_end": 4}, "action": {"text": "try", "start": 64, "end": 67, "i_start": 12, "i_end": 12}}, {"character": {"text": "methods", "start": 39, "end": 46, "i_start": 4, "i_end": 4}, "action": {"text": "learn", "start": 71, "end": 76, "i_start": 14, "i_end": 14}}, {"character": {"text": "codes", "start": 84, "end": 89, "i_start": 16, "i_end": 16}, "action": {"text": "preserve", "start": 96, "end": 104, "i_start": 18, "i_end": 18}}], "id": 2011}, {"sent": "in recent years , neural networks have been effectively applied in various problems such as voice recognition .", "tokens": ["in", "recent", "years", ",", "neural", "networks", "have", "been", "effectively", "applied", "in", "various", "problems", "such", "as", "voice", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 18, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "applied", "start": 56, "end": 63, "i_start": 9, "i_end": 9}}, {"subject": {"text": "neural networks", "start": 18, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "have been", "start": 34, "end": 43, "i_start": 6, "i_end": 7}}], "id": 2012}, {"sent": "this can be easily measured using density evolution recursion .", "tokens": ["this", "can", "be", "easily", "measured", "using", "density", "evolution", "recursion", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "measured", "start": 19, "end": 27, "i_start": 4, "i_end": 4}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "can be", "start": 5, "end": 11, "i_start": 1, "i_end": 2}}], "id": 2013}, {"sent": "by using results from , the authors choose \u03c1 n to be the radius of a circle of area 100 log n n on s 2 .", "tokens": ["by", "using", "results", "from", ",", "the", "authors", "choose", "\u03c1", "n", "to", "be", "the", "radius", "of", "a", "circle", "of", "area", "100", "log", "n", "n", "on", "s", "2", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 24, "end": 35, "i_start": 5, "i_end": 6}, "verb": {"text": "choose", "start": 36, "end": 42, "i_start": 7, "i_end": 7}}], "id": 2014}, {"sent": "for the acceleration of stochastic gradient descent , we use adaptive optimisation based on adam .", "tokens": ["for", "the", "acceleration", "of", "stochastic", "gradient", "descent", ",", "we", "use", "adaptive", "optimisation", "based", "on", "adam", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 54, "end": 56, "i_start": 8, "i_end": 8}, "verb": {"text": "use", "start": 57, "end": 60, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 54, "end": 56, "i_start": 8, "i_end": 8}, "action": {"text": "use", "start": 57, "end": 60, "i_start": 9, "i_end": 9}}], "id": 2015}, {"sent": "for bounded degree graphs , the policy in achieves sublinear expected time to extinction , but requires a curing budget that is proportional to the number of nodes .", "tokens": ["for", "bounded", "degree", "graphs", ",", "the", "policy", "in", "achieves", "sublinear", "expected", "time", "to", "extinction", ",", "but", "requires", "a", "curing", "budget", "that", "is", "proportional", "to", "the", "number", "of", "nodes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the policy in achieves sublinear", "start": 28, "end": 60, "i_start": 5, "i_end": 9}, "verb": {"text": "expected", "start": 61, "end": 69, "i_start": 10, "i_end": 10}}, {"subject": {"text": "the policy in achieves sublinear", "start": 28, "end": 60, "i_start": 5, "i_end": 9}, "verb": {"text": "requires", "start": 95, "end": 103, "i_start": 16, "i_end": 16}}, {"character": {"text": "policy", "start": 32, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieves", "start": 42, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "policy", "start": 32, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "requires", "start": 95, "end": 103, "i_start": 16, "i_end": 16}}], "id": 2016}, {"sent": "every connected finite strongly simple bol loop is moufang .", "tokens": ["every", "connected", "finite", "strongly", "simple", "bol", "loop", "is", "moufang", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "every connected finite strongly simple bol loop", "start": 0, "end": 47, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 48, "end": 50, "i_start": 7, "i_end": 7}}], "id": 2017}, {"sent": "however , the vacuum is a highest weight state of the spectral ik .", "tokens": ["however", ",", "the", "vacuum", "is", "a", "highest", "weight", "state", "of", "the", "spectral", "ik", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the vacuum", "start": 10, "end": 20, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 4, "i_end": 4}}], "id": 2018}, {"sent": "then , the phase space will consist of all the possible three metrics , extrinsic curvature , and configurations of the matter fields .", "tokens": ["then", ",", "the", "phase", "space", "will", "consist", "of", "all", "the", "possible", "three", "metrics", ",", "extrinsic", "curvature", ",", "and", "configurations", "of", "the", "matter", "fields", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the phase space", "start": 7, "end": 22, "i_start": 2, "i_end": 4}, "verb": {"text": "will consist", "start": 23, "end": 35, "i_start": 5, "i_end": 6}}], "id": 2019}, {"sent": "this comparison study showed that methyl esters larger than methyl octanoate behave similarly and have very close reactivities .", "tokens": ["this", "comparison", "study", "showed", "that", "methyl", "esters", "larger", "than", "methyl", "octanoate", "behave", "similarly", "and", "have", "very", "close", "reactivities", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this comparison study", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 22, "end": 28, "i_start": 3, "i_end": 3}}, {"subject": {"text": "methyl esters larger than methyl octanoate", "start": 34, "end": 76, "i_start": 5, "i_end": 10}, "verb": {"text": "behave", "start": 77, "end": 83, "i_start": 11, "i_end": 11}}, {"character": {"text": "study", "start": 16, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "showed", "start": 22, "end": 28, "i_start": 3, "i_end": 3}}], "id": 2020}, {"sent": "however , bertschinger et al provided a counterexample illustrating that in the multivariate case the identity axiom is incompatible with ensuring the nonnegativity of the pid terms .", "tokens": ["however", ",", "bertschinger", "et", "al", "provided", "a", "counterexample", "illustrating", "that", "in", "the", "multivariate", "case", "the", "identity", "axiom", "is", "incompatible", "with", "ensuring", "the", "nonnegativity", "of", "the", "pid", "terms", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bertschinger et al", "start": 10, "end": 28, "i_start": 2, "i_end": 4}, "verb": {"text": "provided", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "bertschinger", "start": 10, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "provided", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "counterexample", "start": 40, "end": 54, "i_start": 7, "i_end": 7}, "action": {"text": "illustrating", "start": 55, "end": 67, "i_start": 8, "i_end": 8}}], "id": 2021}, {"sent": "deep convolutional neural networks have achieved huge success in solving problems related to computer vision , such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "huge", "success", "in", "solving", "problems", "related", "to", "computer", "vision", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 54, "end": 61, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "solving", "start": 65, "end": 72, "i_start": 9, "i_end": 9}}], "id": 2022}, {"sent": "convolution-based deep neural networks have performed exceedingly well on 2d representation learning tasks .", "tokens": ["convolution", "-", "based", "deep", "neural", "networks", "have", "performed", "exceedingly", "well", "on", "2d", "representation", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolution-based deep neural networks", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "have performed", "start": 39, "end": 53, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "performed", "start": 44, "end": 53, "i_start": 7, "i_end": 7}}], "id": 2023}, {"sent": "for this we make use of a generative adversarial network .", "tokens": ["for", "this", "we", "make", "use", "of", "a", "generative", "adversarial", "network", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "verb": {"text": "make", "start": 12, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 17, "end": 20, "i_start": 4, "i_end": 4}}], "id": 2024}, {"sent": "a transport layer approach for improving end-to-end performance and robustness using redundant paths .", "tokens": ["a", "transport", "layer", "approach", "for", "improving", "end", "-", "to", "-", "end", "performance", "and", "robustness", "using", "redundant", "paths", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2025}, {"sent": "stability conditions on triangulated categories .", "tokens": ["stability", "conditions", "on", "triangulated", "categories", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2026}, {"sent": "the shot noise is the other source of noise .", "tokens": ["the", "shot", "noise", "is", "the", "other", "source", "of", "noise", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the shot noise", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "noise", "start": 9, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "source", "start": 28, "end": 34, "i_start": 6, "i_end": 6}}], "id": 2027}, {"sent": "sindagi et al proposed contextual pyramid cnn , where they demonstrated significant improvements by fusing local and global context through classification networks .", "tokens": ["sindagi", "et", "al", "proposed", "contextual", "pyramid", "cnn", ",", "where", "they", "demonstrated", "significant", "improvements", "by", "fusing", "local", "and", "global", "context", "through", "classification", "networks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 8, "end": 13, "i_start": 1, "i_end": 2}, "verb": {"text": "proposed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "sindagi", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "sindagi", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "demonstrated", "start": 59, "end": 71, "i_start": 10, "i_end": 10}}, {"character": {"text": "sindagi", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "improvements", "start": 84, "end": 96, "i_start": 12, "i_end": 12}}, {"character": {"text": "sindagi", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "fusing", "start": 100, "end": 106, "i_start": 14, "i_end": 14}}, {"character": {"text": "networks", "start": 155, "end": 163, "i_start": 21, "i_end": 21}, "action": {"text": "classification", "start": 140, "end": 154, "i_start": 20, "i_end": 20}}], "id": 2028}, {"sent": "deep neural networks have achieved state-of-the-art performance on tasks such as image recognition in the last few years .", "tokens": ["deep", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "tasks", "such", "as", "image", "recognition", "in", "the", "last", "few", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 52, "end": 63, "i_start": 12, "i_end": 12}}], "id": 2029}, {"sent": "we have shown that the gw mechanism can work under non-zero dirichlet bcs with appropriate size of vevs .", "tokens": ["we", "have", "shown", "that", "the", "gw", "mechanism", "can", "work", "under", "non", "-", "zero", "dirichlet", "bcs", "with", "appropriate", "size", "of", "vevs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have shown", "start": 3, "end": 13, "i_start": 1, "i_end": 2}}, {"subject": {"text": "the gw mechanism", "start": 19, "end": 35, "i_start": 4, "i_end": 6}, "verb": {"text": "work", "start": 40, "end": 44, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "shown", "start": 8, "end": 13, "i_start": 2, "i_end": 2}}], "id": 2030}, {"sent": "deep convolutional neural networks have been successful in many computer vision tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successful", "in", "many", "computer", "vision", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "successful", "start": 45, "end": 55, "i_start": 6, "i_end": 6}}], "id": 2031}, {"sent": "the generalized gradient approximation of perdew-burke-ernzerhof form is used for the exchange correlation potential .", "tokens": ["the", "generalized", "gradient", "approximation", "of", "perdew", "-", "burke", "-", "ernzerhof", "form", "is", "used", "for", "the", "exchange", "correlation", "potential", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation of perdew-burke-ernzerhof form", "start": 0, "end": 69, "i_start": 0, "i_end": 10}, "verb": {"text": "is used", "start": 70, "end": 77, "i_start": 11, "i_end": 12}}], "id": 2032}, {"sent": "it may be too soon to tell whether string theory is the correct description of all interactions and constituents of nature .", "tokens": ["it", "may", "be", "too", "soon", "to", "tell", "whether", "string", "theory", "is", "the", "correct", "description", "of", "all", "interactions", "and", "constituents", "of", "nature", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "may be", "start": 3, "end": 9, "i_start": 1, "i_end": 2}}, {"character": {"text": "theory", "start": 42, "end": 48, "i_start": 9, "i_end": 9}, "action": {"text": "description", "start": 64, "end": 75, "i_start": 13, "i_end": 13}}], "id": 2033}, {"sent": "according to eigenstate thermalization hypothesis , a highly excited state of a chaotic system behaves like a high engergy microcanonical ensemble thermal state .", "tokens": ["according", "to", "eigenstate", "thermalization", "hypothesis", ",", "a", "highly", "excited", "state", "of", "a", "chaotic", "system", "behaves", "like", "a", "high", "engergy", "microcanonical", "ensemble", "thermal", "state", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a highly excited state of a chaotic system", "start": 52, "end": 94, "i_start": 6, "i_end": 13}, "verb": {"text": "behaves", "start": 95, "end": 102, "i_start": 14, "i_end": 14}}], "id": 2034}, {"sent": "deep neural networks have been significantly successful in many artificial intelligence tasks such as im- age classification .", "tokens": ["deep", "neural", "networks", "have", "been", "significantly", "successful", "in", "many", "artificial", "intelligence", "tasks", "such", "as", "im-", "age", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 45, "end": 55, "i_start": 6, "i_end": 6}}], "id": 2035}, {"sent": "we exploit the gradient-weighted class activation mapping technique to find the critical regions in the input image that mostly activate the the network output .", "tokens": ["we", "exploit", "the", "gradient", "-", "weighted", "class", "activation", "mapping", "technique", "to", "find", "the", "critical", "regions", "in", "the", "input", "image", "that", "mostly", "activate", "the", "the", "network", "output", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "exploit", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "exploit", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 71, "end": 75, "i_start": 11, "i_end": 11}}], "id": 2036}, {"sent": "we use the vienna ab initio simulation package , with plane wave basis set with a cut-off energy of 400-500 ev .", "tokens": ["we", "use", "the", "vienna", "ab", "initio", "simulation", "package", ",", "with", "plane", "wave", "basis", "set", "with", "a", "cut", "-", "off", "energy", "of", "400", "-", "500", "ev", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 2037}, {"sent": "in huang et al , the authors use a multi-modal context-modulated attention mechanism to compute the similarity between an image and a caption .", "tokens": ["in", "huang", "et", "al", ",", "the", "authors", "use", "a", "multi", "-", "modal", "context", "-", "modulated", "attention", "mechanism", "to", "compute", "the", "similarity", "between", "an", "image", "and", "a", "caption", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 17, "end": 28, "i_start": 5, "i_end": 6}, "verb": {"text": "use", "start": 29, "end": 32, "i_start": 7, "i_end": 7}}], "id": 2038}, {"sent": "however , the next term of the expansion , the quadrupole term , is instead characterised by three constants , the interpretation of which is less clear .", "tokens": ["however", ",", "the", "next", "term", "of", "the", "expansion", ",", "the", "quadrupole", "term", ",", "is", "instead", "characterised", "by", "three", "constants", ",", "the", "interpretation", "of", "which", "is", "less", "clear", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the next term of the expansion", "start": 10, "end": 40, "i_start": 2, "i_end": 7}, "verb": {"text": "characterised", "start": 76, "end": 89, "i_start": 15, "i_end": 15}}, {"subject": {"text": "the next term of the expansion", "start": 10, "end": 40, "i_start": 2, "i_end": 7}, "verb": {"text": "is", "start": 65, "end": 67, "i_start": 13, "i_end": 13}}], "id": 2039}, {"sent": "to do this , they use a method similar to net2net , which is designed to transfer the learned knowledge from one neural network to a second model .", "tokens": ["to", "do", "this", ",", "they", "use", "a", "method", "similar", "to", "net2net", ",", "which", "is", "designed", "to", "transfer", "the", "learned", "knowledge", "from", "one", "neural", "network", "to", "a", "second", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 13, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 18, "end": 21, "i_start": 5, "i_end": 5}}, {"character": {"text": "they", "start": 13, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 18, "end": 21, "i_start": 5, "i_end": 5}}, {"character": {"text": "method", "start": 24, "end": 30, "i_start": 7, "i_end": 7}, "action": {"text": "transfer", "start": 73, "end": 81, "i_start": 16, "i_end": 16}}], "id": 2040}, {"sent": "the momentum space topological invariants protect gapless fermions on the boundaries of topological insulators .", "tokens": ["the", "momentum", "space", "topological", "invariants", "protect", "gapless", "fermions", "on", "the", "boundaries", "of", "topological", "insulators", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the momentum space topological invariants", "start": 0, "end": 41, "i_start": 0, "i_end": 4}, "verb": {"text": "protect", "start": 42, "end": 49, "i_start": 5, "i_end": 5}}, {"character": {"text": "invariants", "start": 31, "end": 41, "i_start": 4, "i_end": 4}, "action": {"text": "protect", "start": 42, "end": 49, "i_start": 5, "i_end": 5}}], "id": 2041}, {"sent": "because the difference grows over time , the steady state is unstable .", "tokens": ["because", "the", "difference", "grows", "over", "time", ",", "the", "steady", "state", "is", "unstable", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the steady state", "start": 41, "end": 57, "i_start": 7, "i_end": 9}, "verb": {"text": "is", "start": 58, "end": 60, "i_start": 10, "i_end": 10}}, {"character": {"text": "grows", "start": 23, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "because", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}], "id": 2042}, {"sent": "in addition , deep convolutional neural networks are popular for feature-learning and supervised classification .", "tokens": ["in", "addition", ",", "deep", "convolutional", "neural", "networks", "are", "popular", "for", "feature", "-", "learning", "and", "supervised", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 14, "end": 48, "i_start": 3, "i_end": 6}, "verb": {"text": "are", "start": 49, "end": 52, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep convolutional neural networks", "start": 14, "end": 48, "i_start": 3, "i_end": 6}, "verb": {"text": "supervised", "start": 86, "end": 96, "i_start": 14, "i_end": 14}}], "id": 2043}, {"sent": "the loss function is optimized via batch-based adam and backpropagation .", "tokens": ["the", "loss", "function", "is", "optimized", "via", "batch", "-", "based", "adam", "and", "backpropagation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the loss function", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is optimized", "start": 18, "end": 30, "i_start": 3, "i_end": 4}}], "id": 2044}, {"sent": "this free energy consists of nearest neighbor repulsion energies of z-ions and the attraction energy of z-ions to the charge surface .", "tokens": ["this", "free", "energy", "consists", "of", "nearest", "neighbor", "repulsion", "energies", "of", "z", "-", "ions", "and", "the", "attraction", "energy", "of", "z", "-", "ions", "to", "the", "charge", "surface", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this free energy", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "energies", "start": 56, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "repulsion", "start": 46, "end": 55, "i_start": 7, "i_end": 7}}, {"character": {"text": "energy", "start": 94, "end": 100, "i_start": 16, "i_end": 16}, "action": {"text": "attraction", "start": 83, "end": 93, "i_start": 15, "i_end": 15}}], "id": 2045}, {"sent": "the fractional difference is shown in the bottom panel .", "tokens": ["the", "fractional", "difference", "is", "shown", "in", "the", "bottom", "panel", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the fractional difference", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "is shown", "start": 26, "end": 34, "i_start": 3, "i_end": 4}}], "id": 2046}, {"sent": "differential privacy is a standard , well-accepted definition of privacy .", "tokens": ["differential", "privacy", "is", "a", "standard", ",", "well", "-", "accepted", "definition", "of", "privacy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "differential privacy", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 2, "i_end": 2}}], "id": 2047}, {"sent": "could also adopt implementations of stronger objects like the ones presented in but we preferred to show the simplest modification in a fundamental algorithm .", "tokens": ["could", "also", "adopt", "implementations", "of", "stronger", "objects", "like", "the", "ones", "presented", "in", "but", "we", "preferred", "to", "show", "the", "simplest", "modification", "in", "a", "fundamental", "algorithm", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 84, "end": 86, "i_start": 13, "i_end": 13}, "verb": {"text": "adopt", "start": 11, "end": 16, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 84, "end": 86, "i_start": 13, "i_end": 13}, "verb": {"text": "could", "start": 0, "end": 5, "i_start": 0, "i_end": 0}}, {"subject": {"text": "we", "start": 84, "end": 86, "i_start": 13, "i_end": 13}, "verb": {"text": "preferred", "start": 87, "end": 96, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 84, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "adopt", "start": 11, "end": 16, "i_start": 2, "i_end": 2}}], "id": 2048}, {"sent": "this section gives a brief definition of the abstract tile assembly model with negative glue strengths .", "tokens": ["this", "section", "gives", "a", "brief", "definition", "of", "the", "abstract", "tile", "assembly", "model", "with", "negative", "glue", "strengths", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this section", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "gives", "start": 13, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "section", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "definition", "start": 27, "end": 37, "i_start": 5, "i_end": 5}}], "id": 2049}, {"sent": "we apply batch normalization right after the last fc layer to improve the convergence during training .", "tokens": ["we", "apply", "batch", "normalization", "right", "after", "the", "last", "fc", "layer", "to", "improve", "the", "convergence", "during", "training", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "apply", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "apply", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "improve", "start": 62, "end": 69, "i_start": 11, "i_end": 11}}], "id": 2050}, {"sent": "recently , deep cnn-based methods have achieved considerable progress on some low level vision tasks .", "tokens": ["recently", ",", "deep", "cnn", "-", "based", "methods", "have", "achieved", "considerable", "progress", "on", "some", "low", "level", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep cnn-based methods", "start": 11, "end": 33, "i_start": 2, "i_end": 6}, "verb": {"text": "have achieved", "start": 34, "end": 47, "i_start": 7, "i_end": 8}}, {"character": {"text": "methods", "start": 26, "end": 33, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 39, "end": 47, "i_start": 8, "i_end": 8}}], "id": 2051}, {"sent": "minimizing nonconvex objectives , which typically exhibit many stationary points , is np-hard in general .", "tokens": ["minimizing", "nonconvex", "objectives", ",", "which", "typically", "exhibit", "many", "stationary", "points", ",", "is", "np", "-", "hard", "in", "general", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "minimizing nonconvex objectives", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 83, "end": 85, "i_start": 11, "i_end": 11}}, {"character": {"text": "objectives", "start": 21, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "exhibit", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}], "id": 2052}, {"sent": "in agreement with the recent results obtained in the analysis of widely spread gaussian states , we find that the effective theory always overestimates the energy density and underestimates the volume at the bounce .", "tokens": ["in", "agreement", "with", "the", "recent", "results", "obtained", "in", "the", "analysis", "of", "widely", "spread", "gaussian", "states", ",", "we", "find", "that", "the", "effective", "theory", "always", "overestimates", "the", "energy", "density", "and", "underestimates", "the", "volume", "at", "the", "bounce", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 97, "end": 99, "i_start": 16, "i_end": 16}, "verb": {"text": "find", "start": 100, "end": 104, "i_start": 17, "i_end": 17}}, {"subject": {"text": "the effective theory", "start": 110, "end": 130, "i_start": 19, "i_end": 21}, "verb": {"text": "overestimates", "start": 138, "end": 151, "i_start": 23, "i_end": 23}}, {"character": {"text": "we", "start": 97, "end": 99, "i_start": 16, "i_end": 16}, "action": {"text": "agreement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 97, "end": 99, "i_start": 16, "i_end": 16}, "action": {"text": "find", "start": 100, "end": 104, "i_start": 17, "i_end": 17}}, {"character": {"text": "theory", "start": 124, "end": 130, "i_start": 21, "i_end": 21}, "action": {"text": "overestimates", "start": 138, "end": 151, "i_start": 23, "i_end": 23}}, {"character": {"text": "theory", "start": 124, "end": 130, "i_start": 21, "i_end": 21}, "action": {"text": "effective", "start": 114, "end": 123, "i_start": 20, "i_end": 20}}, {"character": {"text": "theory", "start": 124, "end": 130, "i_start": 21, "i_end": 21}, "action": {"text": "underestimates", "start": 175, "end": 189, "i_start": 28, "i_end": 28}}], "id": 2053}, {"sent": "for the discretization of the laplacian we use the local discontinuous galerkin method developed by .", "tokens": ["for", "the", "discretization", "of", "the", "laplacian", "we", "use", "the", "local", "discontinuous", "galerkin", "method", "developed", "by", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 40, "end": 42, "i_start": 6, "i_end": 6}, "verb": {"text": "use", "start": 43, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 40, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "use", "start": 43, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 40, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "discretization", "start": 8, "end": 22, "i_start": 2, "i_end": 2}}], "id": 2054}, {"sent": "various successful approaches to automatic verification of termination properties of higher-order functional programs are based on sized-types .", "tokens": ["various", "successful", "approaches", "to", "automatic", "verification", "of", "termination", "properties", "of", "higher", "-", "order", "functional", "programs", "are", "based", "on", "sized", "-", "types", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "various successful approaches to automatic verification of termination properties of higher-order functional programs", "start": 0, "end": 117, "i_start": 0, "i_end": 14}, "verb": {"text": "are based", "start": 118, "end": 127, "i_start": 15, "i_end": 16}}], "id": 2055}, {"sent": "every sequence that is both completely additive and ultimately periodic is trivial .", "tokens": ["every", "sequence", "that", "is", "both", "completely", "additive", "and", "ultimately", "periodic", "is", "trivial", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "every sequence that is both completely additive and ultimately periodic", "start": 0, "end": 71, "i_start": 0, "i_end": 9}, "verb": {"text": "is", "start": 72, "end": 74, "i_start": 10, "i_end": 10}}], "id": 2056}, {"sent": "for the features-based system we used the gradientboostingclassifier from the scikit-learn library .", "tokens": ["for", "the", "features", "-", "based", "system", "we", "used", "the", "gradientboostingclassifier", "from", "the", "scikit", "-", "learn", "library", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 30, "end": 32, "i_start": 6, "i_end": 6}, "verb": {"text": "used", "start": 33, "end": 37, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 30, "end": 32, "i_start": 6, "i_end": 6}, "action": {"text": "used", "start": 33, "end": 37, "i_start": 7, "i_end": 7}}], "id": 2057}, {"sent": "the equilibrium configurations of membranes have attracted much attention of mathematicians and physicists .", "tokens": ["the", "equilibrium", "configurations", "of", "membranes", "have", "attracted", "much", "attention", "of", "mathematicians", "and", "physicists", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the equilibrium configurations of membranes", "start": 0, "end": 43, "i_start": 0, "i_end": 4}, "verb": {"text": "have attracted", "start": 44, "end": 58, "i_start": 5, "i_end": 6}}, {"character": {"text": "configurations", "start": 16, "end": 30, "i_start": 2, "i_end": 2}, "action": {"text": "attracted", "start": 49, "end": 58, "i_start": 6, "i_end": 6}}, {"character": {"text": "mathematicians", "start": 77, "end": 91, "i_start": 10, "i_end": 10}, "action": {"text": "attention", "start": 64, "end": 73, "i_start": 8, "i_end": 8}}, {"character": {"text": "physicists", "start": 96, "end": 106, "i_start": 12, "i_end": 12}, "action": {"text": "attention", "start": 64, "end": 73, "i_start": 8, "i_end": 8}}], "id": 2058}, {"sent": "first of all , an infinitesimal version of the central algebraic relation in the qhdalgebra reproduces the canonical commutation relations of canonical quantum gravity formulated in terms of ashtekar variables 1 .", "tokens": ["first", "of", "all", ",", "an", "infinitesimal", "version", "of", "the", "central", "algebraic", "relation", "in", "the", "qhdalgebra", "reproduces", "the", "canonical", "commutation", "relations", "of", "canonical", "quantum", "gravity", "formulated", "in", "terms", "of", "ashtekar", "variables", "1", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "an infinitesimal version of the central algebraic relation in the qhdalgebra", "start": 15, "end": 91, "i_start": 4, "i_end": 14}, "verb": {"text": "reproduces", "start": 92, "end": 102, "i_start": 15, "i_end": 15}}, {"character": {"text": "version", "start": 32, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "reproduces", "start": 92, "end": 102, "i_start": 15, "i_end": 15}}, {"character": {"text": "gravity", "start": 160, "end": 167, "i_start": 23, "i_end": 23}, "action": {"text": "relations", "start": 129, "end": 138, "i_start": 19, "i_end": 19}}], "id": 2059}, {"sent": "in recent years , deep neural networks have revolutionized machine-learning tasks such as image classification , speech recognition , and language translation .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "revolutionized", "machine", "-", "learning", "tasks", "such", "as", "image", "classification", ",", "speech", "recognition", ",", "and", "language", "translation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have revolutionized", "start": 39, "end": 58, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "revolutionized", "start": 44, "end": 58, "i_start": 8, "i_end": 8}}], "id": 2060}, {"sent": "deep learning models have dramatically improved speech recognition , visual object recognition , object detection and many other domains .", "tokens": ["deep", "learning", "models", "have", "dramatically", "improved", "speech", "recognition", ",", "visual", "object", "recognition", ",", "object", "detection", "and", "many", "other", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning models", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "improved", "start": 39, "end": 47, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep learning models", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improved", "start": 39, "end": 47, "i_start": 5, "i_end": 5}}], "id": 2061}, {"sent": "nevertheless , a visual inspection denotes a clear magnitude drop at the moment of occultation , and reveals at least the principal diffraction fringe .", "tokens": ["nevertheless", ",", "a", "visual", "inspection", "denotes", "a", "clear", "magnitude", "drop", "at", "the", "moment", "of", "occultation", ",", "and", "reveals", "at", "least", "the", "principal", "diffraction", "fringe", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a visual inspection", "start": 15, "end": 34, "i_start": 2, "i_end": 4}, "verb": {"text": "denotes", "start": 35, "end": 42, "i_start": 5, "i_end": 5}}, {"subject": {"text": "a visual inspection", "start": 15, "end": 34, "i_start": 2, "i_end": 4}, "verb": {"text": "reveals", "start": 101, "end": 108, "i_start": 17, "i_end": 17}}, {"character": {"text": "inspection", "start": 24, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "denotes", "start": 35, "end": 42, "i_start": 5, "i_end": 5}}, {"character": {"text": "inspection", "start": 24, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "reveals", "start": 101, "end": 108, "i_start": 17, "i_end": 17}}], "id": 2062}, {"sent": "if we assume that matrix theory is a correct description of m-theory around a flat background , then there is a large class of curved backgrounds for which we know it is possible to construct a matrix theory action for n n matrices .", "tokens": ["if", "we", "assume", "that", "matrix", "theory", "is", "a", "correct", "description", "of", "m", "-", "theory", "around", "a", "flat", "background", ",", "then", "there", "is", "a", "large", "class", "of", "curved", "backgrounds", "for", "which", "we", "know", "it", "is", "possible", "to", "construct", "a", "matrix", "theory", "action", "for", "n", "n", "matrices", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "there", "start": 101, "end": 106, "i_start": 20, "i_end": 20}, "verb": {"text": "is", "start": 107, "end": 109, "i_start": 21, "i_end": 21}}, {"character": {"text": "class", "start": 118, "end": 123, "i_start": 24, "i_end": 24}, "action": {"text": "if", "start": 0, "end": 2, "i_start": 0, "i_end": 0}}, {"character": {"text": "we", "start": 3, "end": 5, "i_start": 1, "i_end": 1}, "action": {"text": "know", "start": 159, "end": 163, "i_start": 31, "i_end": 31}}], "id": 2063}, {"sent": "thus instead of making the user directly color an image , other studies make users take a more indirect approach by utilizing color palettes to recolor an image .", "tokens": ["thus", "instead", "of", "making", "the", "user", "directly", "color", "an", "image", ",", "other", "studies", "make", "users", "take", "a", "more", "indirect", "approach", "by", "utilizing", "color", "palettes", "to", "recolor", "an", "image", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "other studies", "start": 58, "end": 71, "i_start": 11, "i_end": 12}, "verb": {"text": "make", "start": 72, "end": 76, "i_start": 13, "i_end": 13}}, {"subject": {"text": "users", "start": 77, "end": 82, "i_start": 14, "i_end": 14}, "verb": {"text": "take", "start": 83, "end": 87, "i_start": 15, "i_end": 15}}, {"character": {"text": "studies", "start": 64, "end": 71, "i_start": 12, "i_end": 12}, "action": {"text": "making", "start": 16, "end": 22, "i_start": 3, "i_end": 3}}], "id": 2064}, {"sent": "graphene is a hexagonal lattice built out of two inter-penetrating triangular sub-lattices a and b .", "tokens": ["graphene", "is", "a", "hexagonal", "lattice", "built", "out", "of", "two", "inter", "-", "penetrating", "triangular", "sub", "-", "lattices", "a", "and", "b", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "graphene", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "two", "start": 45, "end": 48, "i_start": 8, "i_end": 8}, "action": {"text": "penetrating", "start": 55, "end": 66, "i_start": 11, "i_end": 11}}], "id": 2065}, {"sent": "molecular motors are protein molecules that drive a wide range of intra-cellular activities including transport of molecular cargo .", "tokens": ["molecular", "motors", "are", "protein", "molecules", "that", "drive", "a", "wide", "range", "of", "intra", "-", "cellular", "activities", "including", "transport", "of", "molecular", "cargo", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "molecular motors", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 17, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "molecules", "start": 29, "end": 38, "i_start": 4, "i_end": 4}, "action": {"text": "drive", "start": 44, "end": 49, "i_start": 6, "i_end": 6}}], "id": 2066}, {"sent": "related studies show that deep neural networks still have vulnerabilities , which can be fooled by adversarial examples .", "tokens": ["related", "studies", "show", "that", "deep", "neural", "networks", "still", "have", "vulnerabilities", ",", "which", "can", "be", "fooled", "by", "adversarial", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "related studies", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "show", "start": 16, "end": 20, "i_start": 2, "i_end": 2}}, {"subject": {"text": "deep neural networks", "start": 26, "end": 46, "i_start": 4, "i_end": 6}, "verb": {"text": "have", "start": 53, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "studies", "start": 8, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 16, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "examples", "start": 111, "end": 119, "i_start": 17, "i_end": 17}, "action": {"text": "fooled", "start": 89, "end": 95, "i_start": 14, "i_end": 14}}], "id": 2067}, {"sent": "this feature can be used to control the plate scale of the telescope .", "tokens": ["this", "feature", "can", "be", "used", "to", "control", "the", "plate", "scale", "of", "the", "telescope", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this feature", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "can be used", "start": 13, "end": 24, "i_start": 2, "i_end": 4}}, {"character": {"text": "feature", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "control", "start": 28, "end": 35, "i_start": 6, "i_end": 6}}], "id": 2068}, {"sent": "massive mimo has been identified as a key technology to improve spectral efficiency of wireless communication systems and one of the main enablers of the upcoming 5th generation .", "tokens": ["massive", "mimo", "has", "been", "identified", "as", "a", "key", "technology", "to", "improve", "spectral", "efficiency", "of", "wireless", "communication", "systems", "and", "one", "of", "the", "main", "enablers", "of", "the", "upcoming", "5th", "generation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "massive mimo", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "has been identified", "start": 13, "end": 32, "i_start": 2, "i_end": 4}}], "id": 2069}, {"sent": "cosmic strings are one-dimensional topological defects which are solutions of the field equations in many theories beyond the standard model of particle physics .", "tokens": ["cosmic", "strings", "are", "one", "-", "dimensional", "topological", "defects", "which", "are", "solutions", "of", "the", "field", "equations", "in", "many", "theories", "beyond", "the", "standard", "model", "of", "particle", "physics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}], "id": 2070}, {"sent": "the weight parameters were initialized following the he algorithm .", "tokens": ["the", "weight", "parameters", "were", "initialized", "following", "the", "he", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the weight parameters", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "were initialized", "start": 22, "end": 38, "i_start": 3, "i_end": 4}}], "id": 2071}, {"sent": "gerstenhaber , the cohomology structure of an associative ring .", "tokens": ["gerstenhaber", ",", "the", "cohomology", "structure", "of", "an", "associative", "ring", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "ring", "start": 58, "end": 62, "i_start": 8, "i_end": 8}, "action": {"text": "associative", "start": 46, "end": 57, "i_start": 7, "i_end": 7}}], "id": 2072}, {"sent": "convolutional neural networks have demonstrated impressive performance on computer vision tasks .", "tokens": ["convolutional", "neural", "networks", "have", "demonstrated", "impressive", "performance", "on", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 30, "end": 47, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 35, "end": 47, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 59, "end": 70, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 59, "end": 70, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 48, "end": 58, "i_start": 5, "i_end": 5}}], "id": 2073}, {"sent": "katok and the second author showed that c 1 -small perturbations of higher-rank algebraic anosov actions with semisimple linear parts are smoothly conjugate to the original action .", "tokens": ["katok", "and", "the", "second", "author", "showed", "that", "c", "1", "-small", "perturbations", "of", "higher", "-", "rank", "algebraic", "anosov", "actions", "with", "semisimple", "linear", "parts", "are", "smoothly", "conjugate", "to", "the", "original", "action", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the second author", "start": 10, "end": 27, "i_start": 2, "i_end": 4}, "verb": {"text": "showed", "start": 28, "end": 34, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the second author", "start": 10, "end": 27, "i_start": 2, "i_end": 4}, "verb": {"text": "are", "start": 134, "end": 137, "i_start": 22, "i_end": 22}}, {"character": {"text": "katok", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 28, "end": 34, "i_start": 5, "i_end": 5}}], "id": 2074}, {"sent": "the accuracy of various ocr methods has recently greatly improved due to advances in deep learning .", "tokens": ["the", "accuracy", "of", "various", "ocr", "methods", "has", "recently", "greatly", "improved", "due", "to", "advances", "in", "deep", "learning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the accuracy of various ocr methods", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "improved", "start": 57, "end": 65, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the accuracy of various ocr methods", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "has", "start": 36, "end": 39, "i_start": 6, "i_end": 6}}], "id": 2075}, {"sent": "calculated from the dt the interrupted straight line was obtained by ls method .", "tokens": ["calculated", "from", "the", "dt", "the", "interrupted", "straight", "line", "was", "obtained", "by", "ls", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the interrupted straight line", "start": 23, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "was obtained", "start": 53, "end": 65, "i_start": 8, "i_end": 9}}], "id": 2076}, {"sent": "let us restrict our attention to the case where the photons are emitted along the x-z plane .", "tokens": ["let", "us", "restrict", "our", "attention", "to", "the", "case", "where", "the", "photons", "are", "emitted", "along", "the", "x", "-", "z", "plane", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "restrict", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "restrict", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "attention", "start": 20, "end": 29, "i_start": 4, "i_end": 4}}], "id": 2077}, {"sent": "to build such a generator we use a generative adversarial network structure .", "tokens": ["to", "build", "such", "a", "generator", "we", "use", "a", "generative", "adversarial", "network", "structure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 29, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "build", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2078}, {"sent": "deep convolutional neural networks have demonstrated significant improvements over traditional approaches in many pattern recognition tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "demonstrated", "significant", "improvements", "over", "traditional", "approaches", "in", "many", "pattern", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have demonstrated", "start": 35, "end": 52, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "demonstrated", "start": 40, "end": 52, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "improvements", "start": 65, "end": 77, "i_start": 7, "i_end": 7}}], "id": 2079}, {"sent": "the other geometry to be considered is a scattering medium that extends from the observer out through the galactic disc .", "tokens": ["the", "other", "geometry", "to", "be", "considered", "is", "a", "scattering", "medium", "that", "extends", "from", "the", "observer", "out", "through", "the", "galactic", "disc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the other geometry to be considered", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 36, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "medium", "start": 52, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "scattering", "start": 41, "end": 51, "i_start": 8, "i_end": 8}}], "id": 2080}, {"sent": "the standard error in each data point is in all cases smaller than the data point itself .", "tokens": ["the", "standard", "error", "in", "each", "data", "point", "is", "in", "all", "cases", "smaller", "than", "the", "data", "point", "itself", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the standard error in each data point", "start": 0, "end": 37, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 7, "i_end": 7}}], "id": 2081}, {"sent": "we follow the implementation of the chambolle-pock algorithm provided by g .", "tokens": ["we", "follow", "the", "implementation", "of", "the", "chambolle", "-", "pock", "algorithm", "provided", "by", "g", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "g", "start": 73, "end": 74, "i_start": 12, "i_end": 12}, "action": {"text": "provided", "start": 61, "end": 69, "i_start": 10, "i_end": 10}}], "id": 2082}, {"sent": "we assume standard background from quantum computing and boolean function complexity , see for nice references .", "tokens": ["we", "assume", "standard", "background", "from", "quantum", "computing", "and", "boolean", "function", "complexity", ",", "see", "for", "nice", "references", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "see", "start": 87, "end": 90, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 2083}, {"sent": "polar codes as introduced in , are binary linear codes that can provably achieve the capacity of a binary-input discrete memoryless channel using low-complexity encoding and decoding as the code length tends to infinity .", "tokens": ["polar", "codes", "as", "introduced", "in", ",", "are", "binary", "linear", "codes", "that", "can", "provably", "achieve", "the", "capacity", "of", "a", "binary", "-", "input", "discrete", "memoryless", "channel", "using", "low", "-", "complexity", "encoding", "and", "decoding", "as", "the", "code", "length", "tends", "to", "infinity", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "polar codes as introduced in", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "are", "start": 31, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "codes", "start": 6, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "achieve", "start": 73, "end": 80, "i_start": 13, "i_end": 13}}], "id": 2084}, {"sent": "the perturbation is the so-called scattering in the literature .", "tokens": ["the", "perturbation", "is", "the", "so", "-", "called", "scattering", "in", "the", "literature", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the perturbation", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}], "id": 2085}, {"sent": "graphene is a two-dimensional material with the unique .", "tokens": ["graphene", "is", "a", "two", "-", "dimensional", "material", "with", "the", "unique", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "graphene", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2086}, {"sent": "isola et al proposed pix2pix to give a supervised solution to general image-to-image translation based on conditional adversarial networks .", "tokens": ["isola", "et", "al", "proposed", "pix2pix", "to", "give", "a", "supervised", "solution", "to", "general", "image", "-", "to", "-", "image", "translation", "based", "on", "conditional", "adversarial", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "isola et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "isola", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}], "id": 2087}, {"sent": "we find that the minimum of the frequency takes place when the thread is centered within the magnetic tube .", "tokens": ["we", "find", "that", "the", "minimum", "of", "the", "frequency", "takes", "place", "when", "the", "thread", "is", "centered", "within", "the", "magnetic", "tube", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the minimum of the frequency", "start": 13, "end": 41, "i_start": 3, "i_end": 7}, "verb": {"text": "takes", "start": 42, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 2088}, {"sent": "convolutional neural networks have seen tremendous success across different problems including image classification .", "tokens": ["convolutional", "neural", "networks", "have", "seen", "tremendous", "success", "across", "different", "problems", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have seen", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "seen", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 51, "end": 58, "i_start": 6, "i_end": 6}}], "id": 2089}, {"sent": "the quantum channel consists of a source that emits pairs of spin one-half particles , in a singlet state .", "tokens": ["the", "quantum", "channel", "consists", "of", "a", "source", "that", "emits", "pairs", "of", "spin", "one", "-", "half", "particles", ",", "in", "a", "singlet", "state", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quantum channel", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 20, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "source", "start": 34, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "emits", "start": 46, "end": 51, "i_start": 8, "i_end": 8}}], "id": 2090}, {"sent": "we use adam optimizer as our optimization algorithm with the default parameters .", "tokens": ["we", "use", "adam", "optimizer", "as", "our", "optimization", "algorithm", "with", "the", "default", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 2091}, {"sent": "ordinate is the relative power on logarithmic scale , and abscissa is the spatial frequency , from the largest scales near the origin to the smallest scales at the nyquist limit , corresponding to two pixels .", "tokens": ["ordinate", "is", "the", "relative", "power", "on", "logarithmic", "scale", ",", "and", "abscissa", "is", "the", "spatial", "frequency", ",", "from", "the", "largest", "scales", "near", "the", "origin", "to", "the", "smallest", "scales", "at", "the", "nyquist", "limit", ",", "corresponding", "to", "two", "pixels", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "ordinate", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2092}, {"sent": "in this section , we first apply the progressive shrinking algorithm to train the once-for-all network on imagenet .", "tokens": ["in", "this", "section", ",", "we", "first", "apply", "the", "progressive", "shrinking", "algorithm", "to", "train", "the", "once", "-", "for", "-", "all", "network", "on", "imagenet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "apply", "start": 27, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "apply", "start": 27, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "train", "start": 72, "end": 77, "i_start": 12, "i_end": 12}}], "id": 2093}, {"sent": "we adopt the packet and frame structure as in , where the cyclic redundancy check bits of each packet facilitate perfect error detection .", "tokens": ["we", "adopt", "the", "packet", "and", "frame", "structure", "as", "in", ",", "where", "the", "cyclic", "redundancy", "check", "bits", "of", "each", "packet", "facilitate", "perfect", "error", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "bits", "start": 82, "end": 86, "i_start": 15, "i_end": 15}, "action": {"text": "facilitate", "start": 102, "end": 112, "i_start": 19, "i_end": 19}}, {"character": {"text": "bits", "start": 82, "end": 86, "i_start": 15, "i_end": 15}, "action": {"text": "check", "start": 76, "end": 81, "i_start": 14, "i_end": 14}}], "id": 2094}, {"sent": "a rich litterature has been devoted to this subject , one may consult a new class of alternating minimization algorithms with costs to move has been introduced .", "tokens": ["a", "rich", "litterature", "has", "been", "devoted", "to", "this", "subject", ",", "one", "may", "consult", "a", "new", "class", "of", "alternating", "minimization", "algorithms", "with", "costs", "to", "move", "has", "been", "introduced", "."], "score": [0, 0, 0, 1, 1], "labels": [{"subject": {"text": "one", "start": 54, "end": 57, "i_start": 10, "i_end": 10}, "verb": {"text": "has been introduced", "start": 140, "end": 159, "i_start": 24, "i_end": 26}}, {"subject": {"text": "one", "start": 54, "end": 57, "i_start": 10, "i_end": 10}, "verb": {"text": "consult", "start": 62, "end": 69, "i_start": 12, "i_end": 12}}, {"character": {"text": "one", "start": 54, "end": 57, "i_start": 10, "i_end": 10}, "action": {"text": "consult", "start": 62, "end": 69, "i_start": 12, "i_end": 12}}], "id": 2095}, {"sent": "we performed dft calculations as implemented in the vienna ab initio simulation package code .", "tokens": ["we", "performed", "dft", "calculations", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "code", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "performed", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "performed", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}], "id": 2096}, {"sent": "in addition , the optimal configuration of the proposed spherical coil array is found and its communication performances are similar as the ideal m 2 i in .", "tokens": ["in", "addition", ",", "the", "optimal", "configuration", "of", "the", "proposed", "spherical", "coil", "array", "is", "found", "and", "its", "communication", "performances", "are", "similar", "as", "the", "ideal", "m", "2", "i", "in", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the optimal configuration of the proposed spherical coil array", "start": 14, "end": 76, "i_start": 3, "i_end": 11}, "verb": {"text": "is found", "start": 77, "end": 85, "i_start": 12, "i_end": 13}}, {"character": {"text": "array", "start": 71, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "performances", "start": 108, "end": 120, "i_start": 17, "i_end": 17}}, {"character": {"text": "array", "start": 71, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "communication", "start": 94, "end": 107, "i_start": 16, "i_end": 16}}], "id": 2097}, {"sent": "convolutional neural network architectures achieve human performance in many computer vision problems including image classification tasks .", "tokens": ["convolutional", "neural", "network", "architectures", "achieve", "human", "performance", "in", "many", "computer", "vision", "problems", "including", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural network architectures", "start": 0, "end": 42, "i_start": 0, "i_end": 3}, "verb": {"text": "achieve", "start": 43, "end": 50, "i_start": 4, "i_end": 4}}, {"character": {"text": "architectures", "start": 29, "end": 42, "i_start": 3, "i_end": 3}, "action": {"text": "achieve", "start": 43, "end": 50, "i_start": 4, "i_end": 4}}, {"character": {"text": "human", "start": 51, "end": 56, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 57, "end": 68, "i_start": 6, "i_end": 6}}], "id": 2098}, {"sent": "thus the space of physical closed-string states is four-dimensional , with two-dimensional even subspace .", "tokens": ["thus", "the", "space", "of", "physical", "closed", "-", "string", "states", "is", "four", "-", "dimensional", ",", "with", "two", "-", "dimensional", "even", "subspace", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the space of physical closed-string states", "start": 5, "end": 47, "i_start": 1, "i_end": 8}, "verb": {"text": "is", "start": 48, "end": 50, "i_start": 9, "i_end": 9}}], "id": 2099}, {"sent": "lattice boltzmann model was shown to predict the linear and finite amplitude stability criteria of the subcritical bifurcation in the ec flow for both 2d and 3d flow scenarios .", "tokens": ["lattice", "boltzmann", "model", "was", "shown", "to", "predict", "the", "linear", "and", "finite", "amplitude", "stability", "criteria", "of", "the", "subcritical", "bifurcation", "in", "the", "ec", "flow", "for", "both", "2d", "and", "3d", "flow", "scenarios", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "lattice boltzmann model", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "was shown", "start": 24, "end": 33, "i_start": 3, "i_end": 4}}, {"character": {"text": "model", "start": 18, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "predict", "start": 37, "end": 44, "i_start": 6, "i_end": 6}}], "id": 2100}, {"sent": "in most cases , the averaged versions of structured perceptrons and mira work empirically better than naive versions of structured perceptron and mira .", "tokens": ["in", "most", "cases", ",", "the", "averaged", "versions", "of", "structured", "perceptrons", "and", "mira", "work", "empirically", "better", "than", "naive", "versions", "of", "structured", "perceptron", "and", "mira", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the averaged versions of structured perceptrons and mira", "start": 16, "end": 72, "i_start": 4, "i_end": 11}, "verb": {"text": "work", "start": 73, "end": 77, "i_start": 12, "i_end": 12}}], "id": 2101}, {"sent": "the interdisciplinary field of complex networks has recently received considerable attention .", "tokens": ["the", "interdisciplinary", "field", "of", "complex", "networks", "has", "recently", "received", "considerable", "attention", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the interdisciplinary field of complex networks", "start": 0, "end": 47, "i_start": 0, "i_end": 5}, "verb": {"text": "received", "start": 61, "end": 69, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the interdisciplinary field of complex networks", "start": 0, "end": 47, "i_start": 0, "i_end": 5}, "verb": {"text": "has", "start": 48, "end": 51, "i_start": 6, "i_end": 6}}], "id": 2102}, {"sent": "xiong et al studied the problem of finding the top-k similar object pairs by virtue of locality sensitive hashing .", "tokens": ["xiong", "et", "al", "studied", "the", "problem", "of", "finding", "the", "top", "-", "k", "similar", "object", "pairs", "by", "virtue", "of", "locality", "sensitive", "hashing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "xiong et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "studied", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "xiong", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "studied", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "hashing", "start": 106, "end": 113, "i_start": 20, "i_end": 20}, "action": {"text": "sensitive", "start": 96, "end": 105, "i_start": 19, "i_end": 19}}], "id": 2103}, {"sent": "lattice boltzmann simulation of nonideal fluids .", "tokens": ["lattice", "boltzmann", "simulation", "of", "nonideal", "fluids", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "boltzmann", "start": 8, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "simulation", "start": 18, "end": 28, "i_start": 2, "i_end": 2}}], "id": 2104}, {"sent": "the low energy spectrum then consists of the standard model with a single light higgs boson together with the gluino , chargino , and neutralino superpartners .", "tokens": ["the", "low", "energy", "spectrum", "then", "consists", "of", "the", "standard", "model", "with", "a", "single", "light", "higgs", "boson", "together", "with", "the", "gluino", ",", "chargino", ",", "and", "neutralino", "superpartners", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the low energy spectrum", "start": 0, "end": 23, "i_start": 0, "i_end": 3}, "verb": {"text": "consists", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}], "id": 2105}, {"sent": "deep neural networks have achieved recordbreaking accuracy in many image classification tasks .", "tokens": ["deep", "neural", "networks", "have", "achieved", "recordbreaking", "accuracy", "in", "many", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}], "id": 2106}, {"sent": "the feature encoder consists of 3 convolutional blocks , and each block comprises a convolutional layer , a batch normalization layer , a max pooling layer , and an activation layer .", "tokens": ["the", "feature", "encoder", "consists", "of", "3", "convolutional", "blocks", ",", "and", "each", "block", "comprises", "a", "convolutional", "layer", ",", "a", "batch", "normalization", "layer", ",", "a", "max", "pooling", "layer", ",", "and", "an", "activation", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the feature encoder", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 20, "end": 28, "i_start": 3, "i_end": 3}}, {"subject": {"text": "each block", "start": 61, "end": 71, "i_start": 10, "i_end": 11}, "verb": {"text": "comprises", "start": 72, "end": 81, "i_start": 12, "i_end": 12}}], "id": 2107}, {"sent": "unsupervised pre-training shows significant improvements in almost every nlp task .", "tokens": ["unsupervised", "pre", "-", "training", "shows", "significant", "improvements", "in", "almost", "every", "nlp", "task", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "-training", "start": 16, "end": 25, "i_start": 2, "i_end": 3}, "verb": {"text": "unsupervised", "start": 0, "end": 12, "i_start": 0, "i_end": 0}}, {"subject": {"text": "-training", "start": 16, "end": 25, "i_start": 2, "i_end": 3}, "verb": {"text": "shows", "start": 26, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "training", "start": 17, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "shows", "start": 26, "end": 31, "i_start": 4, "i_end": 4}}], "id": 2108}, {"sent": "missing ingredient is a caustic-crossing binary detection efficiency .", "tokens": ["missing", "ingredient", "is", "a", "caustic", "-", "crossing", "binary", "detection", "efficiency", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "missing ingredient", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "detection", "start": 48, "end": 57, "i_start": 8, "i_end": 8}, "action": {"text": "crossing", "start": 32, "end": 40, "i_start": 6, "i_end": 6}}], "id": 2109}, {"sent": "in unsupervised learning , generative adversarial networks is by far one of the most widely used methods for training deep generative models .", "tokens": ["in", "unsupervised", "learning", ",", "generative", "adversarial", "networks", "is", "by", "far", "one", "of", "the", "most", "widely", "used", "methods", "for", "training", "deep", "generative", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 27, "end": 58, "i_start": 4, "i_end": 6}, "verb": {"text": "is", "start": 59, "end": 61, "i_start": 7, "i_end": 7}}], "id": 2110}, {"sent": "the topological vertex formalism provides an natural way of calculating the topological string amplitudes of the calabi-yau threefold dual to the compactified web .", "tokens": ["the", "topological", "vertex", "formalism", "provides", "an", "natural", "way", "of", "calculating", "the", "topological", "string", "amplitudes", "of", "the", "calabi", "-", "yau", "threefold", "dual", "to", "the", "compactified", "web", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the topological vertex formalism", "start": 0, "end": 32, "i_start": 0, "i_end": 3}, "verb": {"text": "provides", "start": 33, "end": 41, "i_start": 4, "i_end": 4}}, {"character": {"text": "formalism", "start": 23, "end": 32, "i_start": 3, "i_end": 3}, "action": {"text": "provides", "start": 33, "end": 41, "i_start": 4, "i_end": 4}}], "id": 2111}, {"sent": "the recent proposed sequential matching network matches a response with each utterance in the context at multiple levels of granularity , leading to state-of-the-art performance on two multi-turn conversation corpora .", "tokens": ["the", "recent", "proposed", "sequential", "matching", "network", "matches", "a", "response", "with", "each", "utterance", "in", "the", "context", "at", "multiple", "levels", "of", "granularity", ",", "leading", "to", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "two", "multi", "-", "turn", "conversation", "corpora", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the recent proposed sequential matching network", "start": 0, "end": 47, "i_start": 0, "i_end": 5}, "verb": {"text": "matches", "start": 48, "end": 55, "i_start": 6, "i_end": 6}}, {"character": {"text": "network", "start": 40, "end": 47, "i_start": 5, "i_end": 5}, "action": {"text": "matches", "start": 48, "end": 55, "i_start": 6, "i_end": 6}}, {"character": {"text": "network", "start": 40, "end": 47, "i_start": 5, "i_end": 5}, "action": {"text": "matching", "start": 31, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "matches", "start": 48, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "leading", "start": 138, "end": 145, "i_start": 21, "i_end": 21}}], "id": 2112}, {"sent": "lrr captures the global structure of the data by imposing a low-rank constraint on the data representation matrix .", "tokens": ["lrr", "captures", "the", "global", "structure", "of", "the", "data", "by", "imposing", "a", "low", "-", "rank", "constraint", "on", "the", "data", "representation", "matrix", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "lrr", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "captures", "start": 4, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "lrr", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "captures", "start": 4, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "lrr", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "imposing", "start": 49, "end": 57, "i_start": 9, "i_end": 9}}, {"character": {"text": "matrix", "start": 107, "end": 113, "i_start": 19, "i_end": 19}, "action": {"text": "representation", "start": 92, "end": 106, "i_start": 18, "i_end": 18}}], "id": 2113}, {"sent": "we illustrate this situation by some examples .", "tokens": ["we", "illustrate", "this", "situation", "by", "some", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "illustrate", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "illustrate", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}], "id": 2114}, {"sent": "it was later successfully applied in the quantum automata setting by ambainis and freivalds in 1998 , .", "tokens": ["it", "was", "later", "successfully", "applied", "in", "the", "quantum", "automata", "setting", "by", "ambainis", "and", "freivalds", "in", "1998", ",", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "applied", "start": 26, "end": 33, "i_start": 4, "i_end": 4}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "was", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "freivalds", "start": 82, "end": 91, "i_start": 13, "i_end": 13}, "action": {"text": "applied", "start": 26, "end": 33, "i_start": 4, "i_end": 4}}], "id": 2115}, {"sent": "in most methods , image intensity-based or gradient-based methods have been preferred to extract the boundaries of target anatomies .", "tokens": ["in", "most", "methods", ",", "image", "intensity", "-", "based", "or", "gradient", "-", "based", "methods", "have", "been", "preferred", "to", "extract", "the", "boundaries", "of", "target", "anatomies", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "image intensity-based or gradient-based methods", "start": 18, "end": 65, "i_start": 4, "i_end": 12}, "verb": {"text": "have been preferred", "start": 66, "end": 85, "i_start": 13, "i_end": 15}}], "id": 2116}, {"sent": "the gray shaded band represents the parametrization of ref .", "tokens": ["the", "gray", "shaded", "band", "represents", "the", "parametrization", "of", "ref", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the gray shaded band", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "represents", "start": 21, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "band", "start": 16, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "represents", "start": 21, "end": 31, "i_start": 4, "i_end": 4}}], "id": 2117}, {"sent": "similarly , in , stochastic differential games in which one player uses impulse control and the other uses continuous controls were studied .", "tokens": ["similarly", ",", "in", ",", "stochastic", "differential", "games", "in", "which", "one", "player", "uses", "impulse", "control", "and", "the", "other", "uses", "continuous", "controls", "were", "studied", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "the other", "start": 92, "end": 101, "i_start": 15, "i_end": 16}, "verb": {"text": "uses", "start": 102, "end": 106, "i_start": 17, "i_end": 17}}, {"subject": {"text": "the other", "start": 92, "end": 101, "i_start": 15, "i_end": 16}, "verb": {"text": "studied", "start": 132, "end": 139, "i_start": 21, "i_end": 21}}, {"character": {"text": "one", "start": 56, "end": 59, "i_start": 9, "i_end": 9}, "action": {"text": "player", "start": 60, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "other", "start": 96, "end": 101, "i_start": 16, "i_end": 16}, "action": {"text": "uses", "start": 102, "end": 106, "i_start": 17, "i_end": 17}}], "id": 2118}, {"sent": "with these definitions , we are now able to formulate the inverse problem which we will consider in the following .", "tokens": ["with", "these", "definitions", ",", "we", "are", "now", "able", "to", "formulate", "the", "inverse", "problem", "which", "we", "will", "consider", "in", "the", "following", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 25, "end": 27, "i_start": 4, "i_end": 4}, "verb": {"text": "are", "start": 28, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "formulate", "start": 44, "end": 53, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "consider", "start": 88, "end": 96, "i_start": 16, "i_end": 16}}], "id": 2119}, {"sent": "on the other hand , deep in the superfluid phase , the amplitude modes are gapped and the emergence of the small contour around the gap frequency should be easy to observe .", "tokens": ["on", "the", "other", "hand", ",", "deep", "in", "the", "superfluid", "phase", ",", "the", "amplitude", "modes", "are", "gapped", "and", "the", "emergence", "of", "the", "small", "contour", "around", "the", "gap", "frequency", "should", "be", "easy", "to", "observe", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the amplitude modes", "start": 51, "end": 70, "i_start": 11, "i_end": 13}, "verb": {"text": "are gapped", "start": 71, "end": 81, "i_start": 14, "i_end": 15}}], "id": 2120}, {"sent": "for example , noisy instances are problematic for boosting algorithms where more weight is placed upon misclassified instances , which often include mislabeled and noisy instances .", "tokens": ["for", "example", ",", "noisy", "instances", "are", "problematic", "for", "boosting", "algorithms", "where", "more", "weight", "is", "placed", "upon", "misclassified", "instances", ",", "which", "often", "include", "mislabeled", "and", "noisy", "instances", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "noisy instances", "start": 14, "end": 29, "i_start": 3, "i_end": 4}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 5, "i_end": 5}}], "id": 2121}, {"sent": "the singular locus will consist of the crossing circle components of l .", "tokens": ["the", "singular", "locus", "will", "consist", "of", "the", "crossing", "circle", "components", "of", "l", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the singular locus", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "will consist", "start": 19, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "components", "start": 55, "end": 65, "i_start": 9, "i_end": 9}, "action": {"text": "crossing", "start": 39, "end": 47, "i_start": 7, "i_end": 7}}], "id": 2122}, {"sent": "the axes of the confidence ellipsoids are at an angle to the parameter space , and the .", "tokens": ["the", "axes", "of", "the", "confidence", "ellipsoids", "are", "at", "an", "angle", "to", "the", "parameter", "space", ",", "and", "the", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the axes of the confidence ellipsoids", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 38, "end": 41, "i_start": 6, "i_end": 6}}], "id": 2123}, {"sent": "since the second variation of the rayleigh functional is actually the second variation of the lagrange modified energy functional , evaluated in the space of normalized functions , the optimization method based on the rayleigh functional has the capacity to return the absolute minimum .", "tokens": ["since", "the", "second", "variation", "of", "the", "rayleigh", "functional", "is", "actually", "the", "second", "variation", "of", "the", "lagrange", "modified", "energy", "functional", ",", "evaluated", "in", "the", "space", "of", "normalized", "functions", ",", "the", "optimization", "method", "based", "on", "the", "rayleigh", "functional", "has", "the", "capacity", "to", "return", "the", "absolute", "minimum", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the second variation of the rayleigh functional", "start": 6, "end": 53, "i_start": 1, "i_end": 7}, "verb": {"text": "is", "start": 54, "end": 56, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the optimization method based on the rayleigh functional", "start": 181, "end": 237, "i_start": 28, "i_end": 35}, "verb": {"text": "has", "start": 238, "end": 241, "i_start": 36, "i_end": 36}}], "id": 2124}, {"sent": "convolutional neural networks have achieved superior performance in many visual tasks , such as object detection and segmentation .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "detection", "and", "segmentation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 6, "i_end": 6}}], "id": 2125}, {"sent": "we conduct extensive experiments on pascal voc which is an established semantic segmentation benchmark that comprises 20 semantic classes and provides 1464 training images .", "tokens": ["we", "conduct", "extensive", "experiments", "on", "pascal", "voc", "which", "is", "an", "established", "semantic", "segmentation", "benchmark", "that", "comprises", "20", "semantic", "classes", "and", "provides", "1464", "training", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "conduct", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "conduct", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "experiments", "start": 21, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "benchmark", "start": 93, "end": 102, "i_start": 13, "i_end": 13}, "action": {"text": "comprises", "start": 108, "end": 117, "i_start": 15, "i_end": 15}}, {"character": {"text": "benchmark", "start": 93, "end": 102, "i_start": 13, "i_end": 13}, "action": {"text": "provides", "start": 142, "end": 150, "i_start": 20, "i_end": 20}}], "id": 2126}, {"sent": "scientists are able to gain a greater understanding of the environmental states through environmental sensing and monitoring .", "tokens": ["scientists", "are", "able", "to", "gain", "a", "greater", "understanding", "of", "the", "environmental", "states", "through", "environmental", "sensing", "and", "monitoring", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "scientists", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 11, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "scientists", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "gain", "start": 23, "end": 27, "i_start": 4, "i_end": 4}}], "id": 2127}, {"sent": "recently deep neural networks have attained impressive performance in many fields such as image classification .", "tokens": ["recently", "deep", "neural", "networks", "have", "attained", "impressive", "performance", "in", "many", "fields", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 9, "end": 29, "i_start": 1, "i_end": 3}, "verb": {"text": "have attained", "start": 30, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "attained", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 55, "end": 66, "i_start": 7, "i_end": 7}}, {"character": {"text": "performance", "start": 55, "end": 66, "i_start": 7, "i_end": 7}, "action": {"text": "impressive", "start": 44, "end": 54, "i_start": 6, "i_end": 6}}], "id": 2128}, {"sent": "the classical representer theorem in rkhss was first established by kimeldorf and wahba .", "tokens": ["the", "classical", "representer", "theorem", "in", "rkhss", "was", "first", "established", "by", "kimeldorf", "and", "wahba", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the classical representer theorem in rkhss", "start": 0, "end": 42, "i_start": 0, "i_end": 5}, "verb": {"text": "established", "start": 53, "end": 64, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the classical representer theorem in rkhss", "start": 0, "end": 42, "i_start": 0, "i_end": 5}, "verb": {"text": "was", "start": 43, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "kimeldorf", "start": 68, "end": 77, "i_start": 10, "i_end": 10}, "action": {"text": "established", "start": 53, "end": 64, "i_start": 8, "i_end": 8}}, {"character": {"text": "wahba", "start": 82, "end": 87, "i_start": 12, "i_end": 12}, "action": {"text": "established", "start": 53, "end": 64, "i_start": 8, "i_end": 8}}], "id": 2129}, {"sent": "low-density parity-check codes were first introduced by robert gallager in his doctoral dissertation .", "tokens": ["low", "-", "density", "parity", "-", "check", "codes", "were", "first", "introduced", "by", "robert", "gallager", "in", "his", "doctoral", "dissertation", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "low-density parity-check codes", "start": 0, "end": 30, "i_start": 0, "i_end": 6}, "verb": {"text": "introduced", "start": 42, "end": 52, "i_start": 9, "i_end": 9}}, {"subject": {"text": "low-density parity-check codes", "start": 0, "end": 30, "i_start": 0, "i_end": 6}, "verb": {"text": "were", "start": 31, "end": 35, "i_start": 7, "i_end": 7}}, {"character": {"text": "robert gallager", "start": 56, "end": 71, "i_start": 11, "i_end": 12}, "action": {"text": "introduced", "start": 42, "end": 52, "i_start": 9, "i_end": 9}}], "id": 2130}, {"sent": "the misconception is caused by shifting imagination from dif ficult vector space thinking to straightforward thinking .", "tokens": ["the", "misconception", "is", "caused", "by", "shifting", "imagination", "from", "dif", "ficult", "vector", "space", "thinking", "to", "straightforward", "thinking", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the misconception", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is caused", "start": 18, "end": 27, "i_start": 2, "i_end": 3}}, {"character": {"text": "shifting", "start": 31, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "caused", "start": 21, "end": 27, "i_start": 3, "i_end": 3}}], "id": 2131}, {"sent": "a quantum computation is a unitary time-evolutional dynamical process subjected to a given quantum algorithm from the input quantum states to the output in a quantum system .", "tokens": ["a", "quantum", "computation", "is", "a", "unitary", "time", "-", "evolutional", "dynamical", "process", "subjected", "to", "a", "given", "quantum", "algorithm", "from", "the", "input", "quantum", "states", "to", "the", "output", "in", "a", "quantum", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a quantum computation", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2132}, {"sent": "the fiducial model is the cosmological constant model in table 1 , and is marked with an in the figure .", "tokens": ["the", "fiducial", "model", "is", "the", "cosmological", "constant", "model", "in", "table", "1", ",", "and", "is", "marked", "with", "an", "in", "the", "figure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the fiducial model", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the fiducial model", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "marked", "start": 74, "end": 80, "i_start": 14, "i_end": 14}}], "id": 2133}, {"sent": "in this section we demonstrate that the dm-induced contribution to the cosmological recombination spectrum is sensitive to the branching of the deposited energy into heating , ionization and excitations .", "tokens": ["in", "this", "section", "we", "demonstrate", "that", "the", "dm", "-", "induced", "contribution", "to", "the", "cosmological", "recombination", "spectrum", "is", "sensitive", "to", "the", "branching", "of", "the", "deposited", "energy", "into", "heating", ",", "ionization", "and", "excitations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "demonstrate", "start": 19, "end": 30, "i_start": 4, "i_end": 4}}, {"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 107, "end": 109, "i_start": 16, "i_end": 16}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "demonstrate", "start": 19, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "contribution", "start": 51, "end": 63, "i_start": 10, "i_end": 10}, "action": {"text": "sensitive", "start": 110, "end": 119, "i_start": 17, "i_end": 17}}], "id": 2134}, {"sent": "we follow the coalition structure model of , where agents can form several teams working simultaneously .", "tokens": ["we", "follow", "the", "coalition", "structure", "model", "of", ",", "where", "agents", "can", "form", "several", "teams", "working", "simultaneously", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "agents", "start": 51, "end": 57, "i_start": 9, "i_end": 9}, "action": {"text": "form", "start": 62, "end": 66, "i_start": 11, "i_end": 11}}, {"character": {"text": "teams", "start": 75, "end": 80, "i_start": 13, "i_end": 13}, "action": {"text": "working", "start": 81, "end": 88, "i_start": 14, "i_end": 14}}], "id": 2135}, {"sent": "in channel coding problems , strassen , hayashi , have determined the second-order capacity .", "tokens": ["in", "channel", "coding", "problems", ",", "strassen", ",", "hayashi", ",", "have", "determined", "the", "second", "-", "order", "capacity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "strassen", "start": 29, "end": 37, "i_start": 5, "i_end": 5}, "verb": {"text": "have determined", "start": 50, "end": 65, "i_start": 9, "i_end": 10}}, {"character": {"text": "strassen", "start": 29, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "determined", "start": 55, "end": 65, "i_start": 10, "i_end": 10}}, {"character": {"text": "hayashi", "start": 40, "end": 47, "i_start": 7, "i_end": 7}, "action": {"text": "determined", "start": 55, "end": 65, "i_start": 10, "i_end": 10}}], "id": 2136}, {"sent": "the mpii human pose dataset consists of images taken from a wide-range of real-world activities with full-body pose annotations .", "tokens": ["the", "mpii", "human", "pose", "dataset", "consists", "of", "images", "taken", "from", "a", "wide", "-", "range", "of", "real", "-", "world", "activities", "with", "full", "-", "body", "pose", "annotations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the mpii human pose dataset", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "consists", "start": 28, "end": 36, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the mpii human pose dataset", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "pose", "start": 111, "end": 115, "i_start": 23, "i_end": 23}}], "id": 2137}, {"sent": "one can clearly do the same with the type b operators .", "tokens": ["one", "can", "clearly", "do", "the", "same", "with", "the", "type", "b", "operators", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "do", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}, {"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "can", "start": 4, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "do", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 2138}, {"sent": "it is worth noticing the difference to the problem studied in the field of compressive sensing .", "tokens": ["it", "is", "worth", "noticing", "the", "difference", "to", "the", "problem", "studied", "in", "the", "field", "of", "compressive", "sensing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}], "id": 2139}, {"sent": "each profile is the average of the 312 pixels along the slit .", "tokens": ["each", "profile", "is", "the", "average", "of", "the", "312", "pixels", "along", "the", "slit", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each profile", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 2140}, {"sent": "in the proposed scheme , the random access can be formulated as a pomdp optimization problem because rbs states can not be directly observed by mtcds .", "tokens": ["in", "the", "proposed", "scheme", ",", "the", "random", "access", "can", "be", "formulated", "as", "a", "pomdp", "optimization", "problem", "because", "rbs", "states", "can", "not", "be", "directly", "observed", "by", "mtcds", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the random access", "start": 25, "end": 42, "i_start": 5, "i_end": 7}, "verb": {"text": "can be formulated", "start": 43, "end": 60, "i_start": 8, "i_end": 10}}, {"character": {"text": "not", "start": 116, "end": 119, "i_start": 20, "i_end": 20}, "action": {"text": "because", "start": 93, "end": 100, "i_start": 16, "i_end": 16}}], "id": 2141}, {"sent": "note that path-prefix routing requires that each router know the entire topology of the network .", "tokens": ["note", "that", "path", "-", "prefix", "routing", "requires", "that", "each", "router", "know", "the", "entire", "topology", "of", "the", "network", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "path-prefix routing", "start": 10, "end": 29, "i_start": 2, "i_end": 5}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "path-prefix routing", "start": 10, "end": 29, "i_start": 2, "i_end": 5}, "verb": {"text": "requires", "start": 30, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "router", "start": 49, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "requires", "start": 30, "end": 38, "i_start": 6, "i_end": 6}}], "id": 2142}, {"sent": "deep neural network architectures achieved state-of-art results in many areas like speech recognition .", "tokens": ["deep", "neural", "network", "architectures", "achieved", "state", "-", "of", "-", "art", "results", "in", "many", "areas", "like", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural network architectures", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "achieved", "start": 34, "end": 42, "i_start": 4, "i_end": 4}}, {"character": {"text": "architectures", "start": 20, "end": 33, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 34, "end": 42, "i_start": 4, "i_end": 4}}], "id": 2143}, {"sent": "in particular , we focus on phase-averaged spectra as well as on bolometric and photon-energy-dependent pulsed fractions .", "tokens": ["in", "particular", ",", "we", "focus", "on", "phase", "-", "averaged", "spectra", "as", "well", "as", "on", "bolometric", "and", "photon", "-", "energy", "-", "dependent", "pulsed", "fractions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "focus", "start": 19, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "focus", "start": 19, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "energy", "start": 87, "end": 93, "i_start": 18, "i_end": 18}, "action": {"text": "dependent", "start": 94, "end": 103, "i_start": 20, "i_end": 20}}], "id": 2144}, {"sent": "the bepposax satellite is a joint italian-dutch programme .", "tokens": ["the", "bepposax", "satellite", "is", "a", "joint", "italian", "-", "dutch", "programme", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the bepposax satellite", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}], "id": 2145}, {"sent": "our result also shows that the quantization conditions conjectured in are only approximate , although they become exact in the maximally supersymmetric cases .", "tokens": ["our", "result", "also", "shows", "that", "the", "quantization", "conditions", "conjectured", "in", "are", "only", "approximate", ",", "although", "they", "become", "exact", "in", "the", "maximally", "supersymmetric", "cases", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our result", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "shows", "start": 16, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the quantization conditions", "start": 27, "end": 54, "i_start": 5, "i_end": 7}, "verb": {"text": "conjectured", "start": 55, "end": 66, "i_start": 8, "i_end": 8}}, {"subject": {"text": "our result", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 70, "end": 73, "i_start": 10, "i_end": 10}}], "id": 2146}, {"sent": "in this paper , we present further and more detailed results from this study .", "tokens": ["in", "this", "paper", ",", "we", "present", "further", "and", "more", "detailed", "results", "from", "this", "study", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "present", "start": 19, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "present", "start": 19, "end": 26, "i_start": 5, "i_end": 5}}], "id": 2147}, {"sent": "deep neural networks are powerful models that achieve state-of-the-art performance across several domains , such as bioinformatics .", "tokens": ["deep", "neural", "networks", "are", "powerful", "models", "that", "achieve", "state", "-", "of", "-", "the", "-", "art", "performance", "across", "several", "domains", ",", "such", "as", "bioinformatics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 34, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "achieve", "start": 46, "end": 53, "i_start": 7, "i_end": 7}}], "id": 2148}, {"sent": "furthermore , it turns out that these automorphisms are completely determined by semigroup automorphisms of s .", "tokens": ["furthermore", ",", "it", "turns", "out", "that", "these", "automorphisms", "are", "completely", "determined", "by", "semigroup", "automorphisms", "of", "s", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "turns out", "start": 17, "end": 26, "i_start": 3, "i_end": 4}}, {"subject": {"text": "these automorphisms", "start": 32, "end": 51, "i_start": 6, "i_end": 7}, "verb": {"text": "determined", "start": 67, "end": 77, "i_start": 10, "i_end": 10}}, {"character": {"text": "automorphisms", "start": 38, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "determined", "start": 67, "end": 77, "i_start": 10, "i_end": 10}}], "id": 2149}, {"sent": "residual learning is originally designed to relieve gradient vanishing problem when training very deep neural networks .", "tokens": ["residual", "learning", "is", "originally", "designed", "to", "relieve", "gradient", "vanishing", "problem", "when", "training", "very", "deep", "neural", "networks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "residual learning", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "designed", "start": 32, "end": 40, "i_start": 4, "i_end": 4}}, {"subject": {"text": "residual learning", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "learning", "start": 9, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "relieve", "start": 44, "end": 51, "i_start": 6, "i_end": 6}}], "id": 2150}, {"sent": "these degrees of freedom are obscured in the unitary gauge .", "tokens": ["these", "degrees", "of", "freedom", "are", "obscured", "in", "the", "unitary", "gauge", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "these degrees of freedom", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "are obscured", "start": 25, "end": 37, "i_start": 4, "i_end": 5}}, {"character": {"text": "gauge", "start": 53, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "obscured", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}], "id": 2151}, {"sent": "a semidefinite program -based gf solver , attaining a higher success probability than the nr scheme , is developed in .", "tokens": ["a", "semidefinite", "program", "-based", "gf", "solver", ",", "attaining", "a", "higher", "success", "probability", "than", "the", "nr", "scheme", ",", "is", "developed", "in", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "a semidefinite program -based", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "is developed", "start": 102, "end": 114, "i_start": 17, "i_end": 18}}, {"subject": {"text": "a semidefinite program -based", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "solver", "start": 33, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "solver", "start": 33, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "attaining", "start": 42, "end": 51, "i_start": 7, "i_end": 7}}], "id": 2152}, {"sent": "this approach is extended to the complex channel in for the compound mimo broadcast channel .", "tokens": ["this", "approach", "is", "extended", "to", "the", "complex", "channel", "in", "for", "the", "compound", "mimo", "broadcast", "channel", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this approach", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is extended", "start": 14, "end": 25, "i_start": 2, "i_end": 3}}], "id": 2153}, {"sent": "we use a cnn structure based on resnet-101 up to the filter banks at level 4 .", "tokens": ["we", "use", "a", "cnn", "structure", "based", "on", "resnet-101", "up", "to", "the", "filter", "banks", "at", "level", "4", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "banks", "start": 60, "end": 65, "i_start": 12, "i_end": 12}, "action": {"text": "filter", "start": 53, "end": 59, "i_start": 11, "i_end": 11}}], "id": 2154}, {"sent": "for an alternative way to look at the data , we plot the birefringence vs .", "tokens": ["for", "an", "alternative", "way", "to", "look", "at", "the", "data", ",", "we", "plot", "the", "birefringence", "vs", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 45, "end": 47, "i_start": 10, "i_end": 10}, "verb": {"text": "plot", "start": 48, "end": 52, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 45, "end": 47, "i_start": 10, "i_end": 10}, "action": {"text": "plot", "start": 48, "end": 52, "i_start": 11, "i_end": 11}}], "id": 2155}, {"sent": "measure the first register to obtain the integer y .", "tokens": ["measure", "the", "first", "register", "to", "obtain", "the", "integer", "y", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2156}, {"sent": "dark energy is a qcd effect related to the mismatch between vacuum energies in infinite minkowski and compact or curved spaces , and it is conceivably proportional to the rate of the expansion of the universe .", "tokens": ["dark", "energy", "is", "a", "qcd", "effect", "related", "to", "the", "mismatch", "between", "vacuum", "energies", "in", "infinite", "minkowski", "and", "compact", "or", "curved", "spaces", ",", "and", "it", "is", "conceivably", "proportional", "to", "the", "rate", "of", "the", "expansion", "of", "the", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dark energy", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 2157}, {"sent": "we implement the network f as a u-net architecture , with 5 layers for both the encoding and decoding parts .", "tokens": ["we", "implement", "the", "network", "f", "as", "a", "u", "-", "net", "architecture", ",", "with", "5", "layers", "for", "both", "the", "encoding", "and", "decoding", "parts", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}], "id": 2158}, {"sent": "deformation , is the electron-phonon interaction parameter .", "tokens": ["deformation", ",", "is", "the", "electron", "-", "phonon", "interaction", "parameter", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deformation", "start": 0, "end": 11, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "electron", "start": 21, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "interaction", "start": 37, "end": 48, "i_start": 7, "i_end": 7}}], "id": 2159}, {"sent": "hence the flavour vacuum is a pure mixing condensate .", "tokens": ["hence", "the", "flavour", "vacuum", "is", "a", "pure", "mixing", "condensate", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the flavour vacuum", "start": 6, "end": 24, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 4, "i_end": 4}}], "id": 2160}, {"sent": "the persistent homology software returns the starting edge and birth density of each homology class .", "tokens": ["the", "persistent", "homology", "software", "returns", "the", "starting", "edge", "and", "birth", "density", "of", "each", "homology", "class", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the persistent homology software", "start": 0, "end": 32, "i_start": 0, "i_end": 3}, "verb": {"text": "returns", "start": 33, "end": 40, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the persistent homology software", "start": 0, "end": 32, "i_start": 0, "i_end": 3}, "verb": {"text": "birth", "start": 63, "end": 68, "i_start": 9, "i_end": 9}}, {"character": {"text": "software", "start": 24, "end": 32, "i_start": 3, "i_end": 3}, "action": {"text": "returns", "start": 33, "end": 40, "i_start": 4, "i_end": 4}}], "id": 2161}, {"sent": "recently , convolutional neural networks have shown their powerful abilities on image representation .", "tokens": ["recently", ",", "convolutional", "neural", "networks", "have", "shown", "their", "powerful", "abilities", "on", "image", "representation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 11, "end": 40, "i_start": 2, "i_end": 4}, "verb": {"text": "have shown", "start": 41, "end": 51, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "shown", "start": 46, "end": 51, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "representation", "start": 86, "end": 100, "i_start": 12, "i_end": 12}}], "id": 2162}, {"sent": "we evaluate the proposed hcp on the pascal visual object classes challenge datasets , which are widely used as the benchmark for multilabel classification .", "tokens": ["we", "evaluate", "the", "proposed", "hcp", "on", "the", "pascal", "visual", "object", "classes", "challenge", "datasets", ",", "which", "are", "widely", "used", "as", "the", "benchmark", "for", "multilabel", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "datasets", "start": 75, "end": 83, "i_start": 12, "i_end": 12}, "action": {"text": "challenge", "start": 65, "end": 74, "i_start": 11, "i_end": 11}}], "id": 2163}, {"sent": "the quantum networks arise naturally in the circuit model of quantum computation .", "tokens": ["the", "quantum", "networks", "arise", "naturally", "in", "the", "circuit", "model", "of", "quantum", "computation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quantum networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "arise", "start": 21, "end": 26, "i_start": 3, "i_end": 3}}], "id": 2164}, {"sent": "this discontinuity is the signature of the bec long range order of the triplet bosons in the magnetized state .", "tokens": ["this", "discontinuity", "is", "the", "signature", "of", "the", "bec", "long", "range", "order", "of", "the", "triplet", "bosons", "in", "the", "magnetized", "state", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this discontinuity", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}], "id": 2165}, {"sent": "this interesting feature of the monopole problem has not been emphasized in the literature .", "tokens": ["this", "interesting", "feature", "of", "the", "monopole", "problem", "has", "not", "been", "emphasized", "in", "the", "literature", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this interesting feature of the monopole problem", "start": 0, "end": 48, "i_start": 0, "i_end": 6}, "verb": {"text": "has not been emphasized", "start": 49, "end": 72, "i_start": 7, "i_end": 10}}, {"character": {"text": "literature", "start": 80, "end": 90, "i_start": 13, "i_end": 13}, "action": {"text": "not been emphasized", "start": 53, "end": 72, "i_start": 8, "i_end": 10}}, {"character": {"text": "feature", "start": 17, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "interesting", "start": 5, "end": 16, "i_start": 1, "i_end": 1}}], "id": 2166}, {"sent": "the abraham-lorentz analysis correctly calculates the electromagnetic self-force .", "tokens": ["the", "abraham", "-", "lorentz", "analysis", "correctly", "calculates", "the", "electromagnetic", "self", "-", "force", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the abraham-lorentz analysis", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "calculates", "start": 39, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "analysis", "start": 20, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "calculates", "start": 39, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "abraham", "start": 4, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "analysis", "start": 20, "end": 28, "i_start": 4, "i_end": 4}}], "id": 2167}, {"sent": "elmo is a pre-trained contextualized word embeddings involving character-level representation .", "tokens": ["elmo", "is", "a", "pre", "-", "trained", "contextualized", "word", "embeddings", "involving", "character", "-", "level", "representation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "elmo", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 2168}, {"sent": "the patchbased feature extraction method is a representative example of this approach .", "tokens": ["the", "patchbased", "feature", "extraction", "method", "is", "a", "representative", "example", "of", "this", "approach", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the patchbased feature extraction method", "start": 0, "end": 40, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 41, "end": 43, "i_start": 5, "i_end": 5}}], "id": 2169}, {"sent": "kipf and welling was the first to apply a graph neural network to citation datasets , and achieved the state-of-the-art performance with gcn .", "tokens": ["kipf", "and", "welling", "was", "the", "first", "to", "apply", "a", "graph", "neural", "network", "to", "citation", "datasets", ",", "and", "achieved", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "with", "gcn", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "kipf", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "apply", "start": 34, "end": 39, "i_start": 7, "i_end": 7}}, {"character": {"text": "welling", "start": 9, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "apply", "start": 34, "end": 39, "i_start": 7, "i_end": 7}}, {"character": {"text": "kipf", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "achieved", "start": 90, "end": 98, "i_start": 17, "i_end": 17}}, {"character": {"text": "welling", "start": 9, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 90, "end": 98, "i_start": 17, "i_end": 17}}], "id": 2170}, {"sent": "in recent years , convolutional neural networks have achieved superior performance in many visual tasks , such as object classification and detection .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "classification", "and", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 48, "end": 61, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 53, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 71, "end": 82, "i_start": 10, "i_end": 10}}], "id": 2171}, {"sent": "a few recent methods update d and x jointly in an iterative fashion .", "tokens": ["a", "few", "recent", "methods", "update", "d", "and", "x", "jointly", "in", "an", "iterative", "fashion", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a few recent methods", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "update", "start": 21, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "methods", "start": 13, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "update", "start": 21, "end": 27, "i_start": 4, "i_end": 4}}], "id": 2172}, {"sent": "moreover , scenarios obtaining the multiuser diversity have been studied in cooperative networks by applying an opportunistic two-hop relaying protocol .", "tokens": ["moreover", ",", "scenarios", "obtaining", "the", "multiuser", "diversity", "have", "been", "studied", "in", "cooperative", "networks", "by", "applying", "an", "opportunistic", "two", "-", "hop", "relaying", "protocol", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "scenarios obtaining the multiuser diversity", "start": 11, "end": 54, "i_start": 2, "i_end": 6}, "verb": {"text": "have been studied", "start": 55, "end": 72, "i_start": 7, "i_end": 9}}, {"character": {"text": "scenarios", "start": 11, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "obtaining", "start": 21, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "two-hop", "start": 126, "end": 133, "i_start": 17, "i_end": 19}, "action": {"text": "relaying", "start": 134, "end": 142, "i_start": 20, "i_end": 20}}], "id": 2173}, {"sent": "doersch et al proposed to learn visual features by predicting the relative positions of two patches from same image .", "tokens": ["doersch", "et", "al", "proposed", "to", "learn", "visual", "features", "by", "predicting", "the", "relative", "positions", "of", "two", "patches", "from", "same", "image", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 8, "end": 13, "i_start": 1, "i_end": 2}, "verb": {"text": "proposed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "doersch", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}], "id": 2174}, {"sent": "in the past few years , deep learning systems have demonstrated its competitiveness on a wide range of applications , such as image classification .", "tokens": ["in", "the", "past", "few", "years", ",", "deep", "learning", "systems", "have", "demonstrated", "its", "competitiveness", "on", "a", "wide", "range", "of", "applications", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning systems", "start": 24, "end": 45, "i_start": 6, "i_end": 8}, "verb": {"text": "have demonstrated", "start": 46, "end": 63, "i_start": 9, "i_end": 10}}, {"character": {"text": "systems", "start": 38, "end": 45, "i_start": 8, "i_end": 8}, "action": {"text": "demonstrated", "start": 51, "end": 63, "i_start": 10, "i_end": 10}}, {"character": {"text": "systems", "start": 38, "end": 45, "i_start": 8, "i_end": 8}, "action": {"text": "learning", "start": 29, "end": 37, "i_start": 7, "i_end": 7}}], "id": 2175}, {"sent": "deep neural networks have achieved recordbreaking accuracy in many image classification tasks .", "tokens": ["deep", "neural", "networks", "have", "achieved", "recordbreaking", "accuracy", "in", "many", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}], "id": 2176}, {"sent": "elementary single-fold operations are defined in terms of incidence constraints between pairs of objects that must be satisfied with a fold .", "tokens": ["elementary", "single", "-", "fold", "operations", "are", "defined", "in", "terms", "of", "incidence", "constraints", "between", "pairs", "of", "objects", "that", "must", "be", "satisfied", "with", "a", "fold", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "elementary single-fold operations", "start": 0, "end": 33, "i_start": 0, "i_end": 4}, "verb": {"text": "are defined", "start": 34, "end": 45, "i_start": 5, "i_end": 6}}], "id": 2177}, {"sent": "recently , li et al presented a neural deep model for english discourse coherence modeling .", "tokens": ["recently", ",", "li", "et", "al", "presented", "a", "neural", "deep", "model", "for", "english", "discourse", "coherence", "modeling", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "li et al", "start": 11, "end": 19, "i_start": 2, "i_end": 4}, "verb": {"text": "presented", "start": 20, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "li", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "presented", "start": 20, "end": 29, "i_start": 5, "i_end": 5}}], "id": 2178}, {"sent": "the photometry was carried out in the same way as described in sect .", "tokens": ["the", "photometry", "was", "carried", "out", "in", "the", "same", "way", "as", "described", "in", "sect", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the photometry", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "was carried out", "start": 15, "end": 30, "i_start": 2, "i_end": 4}}, {"character": {"text": "sect", "start": 63, "end": 67, "i_start": 12, "i_end": 12}, "action": {"text": "described", "start": 50, "end": 59, "i_start": 10, "i_end": 10}}], "id": 2179}, {"sent": "among them , convolutional neural networks have been demonstrated to be extremely successful in computer vision .", "tokens": ["among", "them", ",", "convolutional", "neural", "networks", "have", "been", "demonstrated", "to", "be", "extremely", "successful", "in", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 13, "end": 42, "i_start": 3, "i_end": 5}, "verb": {"text": "have been demonstrated", "start": 43, "end": 65, "i_start": 6, "i_end": 8}}, {"character": {"text": "networks", "start": 34, "end": 42, "i_start": 5, "i_end": 5}, "action": {"text": "successful", "start": 82, "end": 92, "i_start": 12, "i_end": 12}}], "id": 2180}, {"sent": "this mobility behavior together with an increase of the effective mass is known as large polaron .", "tokens": ["this", "mobility", "behavior", "together", "with", "an", "increase", "of", "the", "effective", "mass", "is", "known", "as", "large", "polaron", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "this mobility behavior together with an increase of the effective mass", "start": 0, "end": 70, "i_start": 0, "i_end": 10}, "verb": {"text": "is known", "start": 71, "end": 79, "i_start": 11, "i_end": 12}}, {"character": {"text": "mass", "start": 66, "end": 70, "i_start": 10, "i_end": 10}, "action": {"text": "effective", "start": 56, "end": 65, "i_start": 9, "i_end": 9}}], "id": 2181}, {"sent": "convolutional neural networks have achieved exceptional results in many large-scale computer vision applications , particularly in image recognition task .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "exceptional", "results", "in", "many", "large", "-", "scale", "computer", "vision", "applications", ",", "particularly", "in", "image", "recognition", "task", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 2182}, {"sent": "qca devices have been implemented using both metallic quantum dots .", "tokens": ["qca", "devices", "have", "been", "implemented", "using", "both", "metallic", "quantum", "dots", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "qca devices", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "have been implemented", "start": 12, "end": 33, "i_start": 2, "i_end": 4}}], "id": 2183}, {"sent": "srinivasan , multiplicities of monomial ideals .", "tokens": ["srinivasan", ",", "multiplicities", "of", "monomial", "ideals", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2184}, {"sent": "in summary , small delays and moderate precision are required to get robust stimulus competition .", "tokens": ["in", "summary", ",", "small", "delays", "and", "moderate", "precision", "are", "required", "to", "get", "robust", "stimulus", "competition", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "small delays and moderate precision", "start": 13, "end": 48, "i_start": 3, "i_end": 7}, "verb": {"text": "are required", "start": 49, "end": 61, "i_start": 8, "i_end": 9}}, {"character": {"text": "get", "start": 65, "end": 68, "i_start": 11, "i_end": 11}, "action": {"text": "required", "start": 53, "end": 61, "i_start": 9, "i_end": 9}}, {"character": {"text": "stimulus", "start": 76, "end": 84, "i_start": 13, "i_end": 13}, "action": {"text": "competition", "start": 85, "end": 96, "i_start": 14, "i_end": 14}}], "id": 2185}, {"sent": "nucleus is the rarest naturally occurring isotope .", "tokens": ["nucleus", "is", "the", "rarest", "naturally", "occurring", "isotope", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "nucleus", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}], "id": 2186}, {"sent": "the first documented use of comparisons by pairs dates back to the xiii century .", "tokens": ["the", "first", "documented", "use", "of", "comparisons", "by", "pairs", "dates", "back", "to", "the", "xiii", "century", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the first documented use of comparisons by pairs", "start": 0, "end": 48, "i_start": 0, "i_end": 7}, "verb": {"text": "dates", "start": 49, "end": 54, "i_start": 8, "i_end": 8}}], "id": 2187}, {"sent": "let us recall the definition of these color codes .", "tokens": ["let", "us", "recall", "the", "definition", "of", "these", "color", "codes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "recall", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "recall", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}], "id": 2188}, {"sent": "the other perturbation to consider is the change in incoming solar flux .", "tokens": ["the", "other", "perturbation", "to", "consider", "is", "the", "change", "in", "incoming", "solar", "flux", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the other perturbation to consider", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 5, "i_end": 5}}], "id": 2189}, {"sent": "coherent risk measures on general probability spaces .", "tokens": ["coherent", "risk", "measures", "on", "general", "probability", "spaces", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2190}, {"sent": "metasurfaces , which are the two-dimensional counterparts of volume metamaterials , have attracted much attention over the past years .", "tokens": ["metasurfaces", ",", "which", "are", "the", "two", "-", "dimensional", "counterparts", "of", "volume", "metamaterials", ",", "have", "attracted", "much", "attention", "over", "the", "past", "years", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "metasurfaces", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "have attracted", "start": 84, "end": 98, "i_start": 13, "i_end": 14}}, {"character": {"text": "metasurfaces", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "action": {"text": "attracted", "start": 89, "end": 98, "i_start": 14, "i_end": 14}}], "id": 2191}, {"sent": "however , it is well-known that eye scan patterns in a film audience follow a specific pattern after a scene change , activating the dorsal pathway .", "tokens": ["however", ",", "it", "is", "well", "-", "known", "that", "eye", "scan", "patterns", "in", "a", "film", "audience", "follow", "a", "specific", "pattern", "after", "a", "scene", "change", ",", "activating", "the", "dorsal", "pathway", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 3, "i_end": 3}}, {"subject": {"text": "eye scan patterns in a film audience", "start": 32, "end": 68, "i_start": 8, "i_end": 14}, "verb": {"text": "follow", "start": 69, "end": 75, "i_start": 15, "i_end": 15}}, {"character": {"text": "patterns", "start": 41, "end": 49, "i_start": 10, "i_end": 10}, "action": {"text": "follow", "start": 69, "end": 75, "i_start": 15, "i_end": 15}}, {"character": {"text": "follow", "start": 69, "end": 75, "i_start": 15, "i_end": 15}, "action": {"text": "activating", "start": 118, "end": 128, "i_start": 24, "i_end": 24}}], "id": 2192}, {"sent": "the number of flare events for the different brightness classes , given in absolute values and percentages of the respective importance class .", "tokens": ["the", "number", "of", "flare", "events", "for", "the", "different", "brightness", "classes", ",", "given", "in", "absolute", "values", "and", "percentages", "of", "the", "respective", "importance", "class", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2193}, {"sent": "other examples of sytems with scale separation include chemical reaction systems where there can exist a difference of several orders of magnitude among the different reaction rates .", "tokens": ["other", "examples", "of", "sytems", "with", "scale", "separation", "include", "chemical", "reaction", "systems", "where", "there", "can", "exist", "a", "difference", "of", "several", "orders", "of", "magnitude", "among", "the", "different", "reaction", "rates", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "other examples of sytems with scale separation", "start": 0, "end": 46, "i_start": 0, "i_end": 6}, "verb": {"text": "include", "start": 47, "end": 54, "i_start": 7, "i_end": 7}}, {"character": {"text": "systems", "start": 73, "end": 80, "i_start": 10, "i_end": 10}, "action": {"text": "reaction", "start": 64, "end": 72, "i_start": 9, "i_end": 9}}, {"character": {"text": "rates", "start": 176, "end": 181, "i_start": 26, "i_end": 26}, "action": {"text": "reaction", "start": 167, "end": 175, "i_start": 25, "i_end": 25}}], "id": 2194}, {"sent": "deep neural networks have shown tremendous success in several computer vision tasks in recent years .", "tokens": ["deep", "neural", "networks", "have", "shown", "tremendous", "success", "in", "several", "computer", "vision", "tasks", "in", "recent", "years", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}], "id": 2195}, {"sent": "convolutional neural networks provide state-of-the-art results for many machine learning challenges , such as image classification .", "tokens": ["convolutional", "neural", "networks", "provide", "state", "-", "of", "-", "the", "-", "art", "results", "for", "many", "machine", "learning", "challenges", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "provide", "start": 30, "end": 37, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "provide", "start": 30, "end": 37, "i_start": 3, "i_end": 3}}], "id": 2196}, {"sent": "deep neural networks have become the fundamental building blocks of many emerging application domains such as computer vision .", "tokens": ["deep", "neural", "networks", "have", "become", "the", "fundamental", "building", "blocks", "of", "many", "emerging", "application", "domains", "such", "as", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have become", "start": 21, "end": 32, "i_start": 3, "i_end": 4}}, {"character": {"text": "domains", "start": 94, "end": 101, "i_start": 13, "i_end": 13}, "action": {"text": "emerging", "start": 73, "end": 81, "i_start": 11, "i_end": 11}}], "id": 2197}, {"sent": "let us now see the details of this technique for particular dimensionalities .", "tokens": ["let", "us", "now", "see", "the", "details", "of", "this", "technique", "for", "particular", "dimensionalities", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "see", "start": 11, "end": 14, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "see", "start": 11, "end": 14, "i_start": 3, "i_end": 3}}], "id": 2198}, {"sent": "these maps compare well to the maps recently obtained at lower frequencies by the wmap experiment .", "tokens": ["these", "maps", "compare", "well", "to", "the", "maps", "recently", "obtained", "at", "lower", "frequencies", "by", "the", "wmap", "experiment", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these maps", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "compare", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "experiment", "start": 87, "end": 97, "i_start": 15, "i_end": 15}, "action": {"text": "obtained", "start": 45, "end": 53, "i_start": 8, "i_end": 8}}], "id": 2199}, {"sent": "again , it is apparent that the double perturbation simulation takes longer to develop than the single perturbation simulation .", "tokens": ["again", ",", "it", "is", "apparent", "that", "the", "double", "perturbation", "simulation", "takes", "longer", "to", "develop", "than", "the", "single", "perturbation", "simulation", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the double perturbation simulation", "start": 28, "end": 62, "i_start": 6, "i_end": 9}, "verb": {"text": "takes", "start": 63, "end": 68, "i_start": 10, "i_end": 10}}, {"character": {"text": "develop", "start": 79, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "takes", "start": 63, "end": 68, "i_start": 10, "i_end": 10}}], "id": 2200}, {"sent": "fisher , in renormalization group in critical phenomena and quantum field theory , edited by j .", "tokens": ["fisher", ",", "in", "renormalization", "group", "in", "critical", "phenomena", "and", "quantum", "field", "theory", ",", "edited", "by", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "phenomena", "start": 46, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "critical", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "fisher", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "edited", "start": 83, "end": 89, "i_start": 13, "i_end": 13}}], "id": 2201}, {"sent": "t he sparsity problems emerging in many areas of scientific research and engineering practice have attracted considerable attention in recent years .", "tokens": ["t", "he", "sparsity", "problems", "emerging", "in", "many", "areas", "of", "scientific", "research", "and", "engineering", "practice", "have", "attracted", "considerable", "attention", "in", "recent", "years", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "t he sparsity problems emerging in many areas of scientific research and engineering practice", "start": 0, "end": 93, "i_start": 0, "i_end": 13}, "verb": {"text": "have attracted", "start": 94, "end": 108, "i_start": 14, "i_end": 15}}, {"character": {"text": "problems", "start": 14, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "attracted", "start": 99, "end": 108, "i_start": 15, "i_end": 15}}, {"character": {"text": "problems", "start": 14, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "emerging", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}], "id": 2202}, {"sent": "the residual network is used to perform feature extraction tasks .", "tokens": ["the", "residual", "network", "is", "used", "to", "perform", "feature", "extraction", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the residual network", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "is used", "start": 21, "end": 28, "i_start": 3, "i_end": 4}}, {"character": {"text": "network", "start": 13, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "perform", "start": 32, "end": 39, "i_start": 6, "i_end": 6}}], "id": 2203}, {"sent": "visual recognition from images has witnessed tremendous success in recent years with the advent of deep convolutional neural networks .", "tokens": ["visual", "recognition", "from", "images", "has", "witnessed", "tremendous", "success", "in", "recent", "years", "with", "the", "advent", "of", "deep", "convolutional", "neural", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "visual recognition from images", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "has witnessed", "start": 31, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "recognition", "start": 7, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "witnessed", "start": 35, "end": 44, "i_start": 5, "i_end": 5}}, {"character": {"text": "recognition", "start": 7, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "success", "start": 56, "end": 63, "i_start": 7, "i_end": 7}}], "id": 2204}, {"sent": "if the normed vector spaces v , w are complete , the pair hv , wi is called a statistical duality .", "tokens": ["if", "the", "normed", "vector", "spaces", "v", ",", "w", "are", "complete", ",", "the", "pair", "hv", ",", "wi", "is", "called", "a", "statistical", "duality", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the pair hv , wi", "start": 49, "end": 65, "i_start": 11, "i_end": 15}, "verb": {"text": "is called", "start": 66, "end": 75, "i_start": 16, "i_end": 17}}], "id": 2205}, {"sent": "such a combination is called a nash equilibrium .", "tokens": ["such", "a", "combination", "is", "called", "a", "nash", "equilibrium", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such a combination", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 19, "end": 28, "i_start": 3, "i_end": 4}}], "id": 2206}, {"sent": "again , the validity of the incoherent approximation is reached at about the debye frequency .", "tokens": ["again", ",", "the", "validity", "of", "the", "incoherent", "approximation", "is", "reached", "at", "about", "the", "debye", "frequency", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the validity of the incoherent approximation", "start": 8, "end": 52, "i_start": 2, "i_end": 7}, "verb": {"text": "is reached", "start": 53, "end": 63, "i_start": 8, "i_end": 9}}], "id": 2207}, {"sent": "we give the following example to the interested reader .", "tokens": ["we", "give", "the", "following", "example", "to", "the", "interested", "reader", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "give", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "give", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 2208}, {"sent": "before applying our theory to further confirm this hypothesis , we first examine the alternative approaches , in addition to that of .", "tokens": ["before", "applying", "our", "theory", "to", "further", "confirm", "this", "hypothesis", ",", "we", "first", "examine", "the", "alternative", "approaches", ",", "in", "addition", "to", "that", "of", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 64, "end": 66, "i_start": 10, "i_end": 10}, "verb": {"text": "examine", "start": 73, "end": 80, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 10, "i_end": 10}, "action": {"text": "examine", "start": 73, "end": 80, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 10, "i_end": 10}, "action": {"text": "applying", "start": 7, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 10, "i_end": 10}, "action": {"text": "confirm", "start": 38, "end": 45, "i_start": 6, "i_end": 6}}], "id": 2209}, {"sent": "deep neural networks have achieved excellent results on speech recognition , and other challenging tasks , so there has been much interest in applying them to natural language processing problems as well .", "tokens": ["deep", "neural", "networks", "have", "achieved", "excellent", "results", "on", "speech", "recognition", ",", "and", "other", "challenging", "tasks", ",", "so", "there", "has", "been", "much", "interest", "in", "applying", "them", "to", "natural", "language", "processing", "problems", "as", "well", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}], "id": 2210}, {"sent": "goodfellow et al proposed the fast gradient sign method for generating adversarial examples .", "tokens": ["goodfellow", "et", "al", "proposed", "the", "fast", "gradient", "sign", "method", "for", "generating", "adversarial", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "goodfellow", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}], "id": 2211}, {"sent": "recent development of deep convolutional neural networks has led to great success in a variety of tasks including image classfication and others .", "tokens": ["recent", "development", "of", "deep", "convolutional", "neural", "networks", "has", "led", "to", "great", "success", "in", "a", "variety", "of", "tasks", "including", "image", "classfication", "and", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent development of deep convolutional neural networks", "start": 0, "end": 56, "i_start": 0, "i_end": 6}, "verb": {"text": "has led", "start": 57, "end": 64, "i_start": 7, "i_end": 8}}, {"character": {"text": "development", "start": 7, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 61, "end": 64, "i_start": 8, "i_end": 8}}], "id": 2212}, {"sent": "sindagi et al develop a contextual pyramid cnn that combines both global and local contextual information for crowd counting .", "tokens": ["sindagi", "et", "al", "develop", "a", "contextual", "pyramid", "cnn", "that", "combines", "both", "global", "and", "local", "contextual", "information", "for", "crowd", "counting", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "sindagi et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "develop", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "sindagi", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "develop", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}], "id": 2213}, {"sent": "for example , the master equation has found many applications in thermodynamics .", "tokens": ["for", "example", ",", "the", "master", "equation", "has", "found", "many", "applications", "in", "thermodynamics", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the master equation", "start": 14, "end": 33, "i_start": 3, "i_end": 5}, "verb": {"text": "has found", "start": 34, "end": 43, "i_start": 6, "i_end": 7}}, {"character": {"text": "equation", "start": 25, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "found", "start": 38, "end": 43, "i_start": 7, "i_end": 7}}], "id": 2214}, {"sent": "ijjaali i , welter r , venturini g , malaman b , ressouche e , j .", "tokens": ["ijjaali", "i", ",", "welter", "r", ",", "venturini", "g", ",", "malaman", "b", ",", "ressouche", "e", ",", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2215}, {"sent": "symbolic execution is a program analysis technique to test whether certain properties can be violated by the software under test .", "tokens": ["symbolic", "execution", "is", "a", "program", "analysis", "technique", "to", "test", "whether", "certain", "properties", "can", "be", "violated", "by", "the", "software", "under", "test", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "symbolic execution", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "software", "start": 109, "end": 117, "i_start": 17, "i_end": 17}, "action": {"text": "violated", "start": 93, "end": 101, "i_start": 14, "i_end": 14}}], "id": 2216}, {"sent": "the first-principles calculations have been performed using the plane-wave pseudopotential as implemented in the vasp code .", "tokens": ["the", "first", "-", "principles", "calculations", "have", "been", "performed", "using", "the", "plane", "-", "wave", "pseudopotential", "as", "implemented", "in", "the", "vasp", "code", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the first-principles calculations", "start": 0, "end": 33, "i_start": 0, "i_end": 4}, "verb": {"text": "have been performed", "start": 34, "end": 53, "i_start": 5, "i_end": 7}}], "id": 2217}, {"sent": "densenet consists of many dense blocks , which are connected to a transition layer to re-utilize the previous features .", "tokens": ["densenet", "consists", "of", "many", "dense", "blocks", ",", "which", "are", "connected", "to", "a", "transition", "layer", "to", "re", "-", "utilize", "the", "previous", "features", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "densenet", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "consists", "start": 9, "end": 17, "i_start": 1, "i_end": 1}}], "id": 2218}, {"sent": "modern neural networks have achieved superior results in classification problems recently .", "tokens": ["modern", "neural", "networks", "have", "achieved", "superior", "results", "in", "classification", "problems", "recently", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "modern neural networks", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 23, "end": 36, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 14, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 28, "end": 36, "i_start": 4, "i_end": 4}}], "id": 2219}, {"sent": "in , another exact approach for mbbp for general graphs was studied .", "tokens": ["in", ",", "another", "exact", "approach", "for", "mbbp", "for", "general", "graphs", "was", "studied", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another exact approach for mbbp for general graphs", "start": 5, "end": 55, "i_start": 2, "i_end": 9}, "verb": {"text": "was studied", "start": 56, "end": 67, "i_start": 10, "i_end": 11}}], "id": 2220}, {"sent": "computational complexity is originally introduced in physics of quantum information .", "tokens": ["computational", "complexity", "is", "originally", "introduced", "in", "physics", "of", "quantum", "information", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "computational complexity", "start": 0, "end": 24, "i_start": 0, "i_end": 1}, "verb": {"text": "introduced", "start": 39, "end": 49, "i_start": 4, "i_end": 4}}, {"subject": {"text": "computational complexity", "start": 0, "end": 24, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 2, "i_end": 2}}], "id": 2221}, {"sent": "the k-means algorithm is one of the most frequently used clustering methods .", "tokens": ["the", "k", "-", "means", "algorithm", "is", "one", "of", "the", "most", "frequently", "used", "clustering", "methods", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the k-means algorithm", "start": 0, "end": 21, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 5, "i_end": 5}}], "id": 2222}, {"sent": "the quantization is a special procedure , which is accompanied by introduction of special concepts , and this procedure can not be repeated .", "tokens": ["the", "quantization", "is", "a", "special", "procedure", ",", "which", "is", "accompanied", "by", "introduction", "of", "special", "concepts", ",", "and", "this", "procedure", "can", "not", "be", "repeated", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quantization", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}, {"subject": {"text": "this procedure", "start": 105, "end": 119, "i_start": 17, "i_end": 18}, "verb": {"text": "repeated", "start": 131, "end": 139, "i_start": 22, "i_end": 22}}, {"character": {"text": "introduction", "start": 66, "end": 78, "i_start": 11, "i_end": 11}, "action": {"text": "accompanied", "start": 51, "end": 62, "i_start": 9, "i_end": 9}}], "id": 2223}, {"sent": "we show how this can be calculated easily using simple approximations for the cmb trispectra , and then also discuss the effect of lensing on any primordial local trispectrum .", "tokens": ["we", "show", "how", "this", "can", "be", "calculated", "easily", "using", "simple", "approximations", "for", "the", "cmb", "trispectra", ",", "and", "then", "also", "discuss", "the", "effect", "of", "lensing", "on", "any", "primordial", "local", "trispectrum", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "this", "start": 12, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "calculated", "start": 24, "end": 34, "i_start": 6, "i_end": 6}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "discuss", "start": 109, "end": 116, "i_start": 19, "i_end": 19}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 2224}, {"sent": "the following theorem is obvious and the reader is expected to prove .", "tokens": ["the", "following", "theorem", "is", "obvious", "and", "the", "reader", "is", "expected", "to", "prove", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the following theorem", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the reader", "start": 37, "end": 47, "i_start": 6, "i_end": 7}, "verb": {"text": "expected", "start": 51, "end": 59, "i_start": 9, "i_end": 9}}], "id": 2225}, {"sent": "deep neural networks have achieved state-of-the-art performance in many application areas , such as computer vision and natural language processing .", "tokens": ["deep", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "many", "application", "areas", ",", "such", "as", "computer", "vision", "and", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 52, "end": 63, "i_start": 12, "i_end": 12}}], "id": 2226}, {"sent": "in recent years , deep neural networks have shown great power on image classification tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "shown", "great", "power", "on", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have shown", "start": 39, "end": 49, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "shown", "start": 44, "end": 49, "i_start": 8, "i_end": 8}}], "id": 2227}, {"sent": "the simplest possibility is that of what has been termed a perfect solid , meaning one for which the elastic structure at each material position is isotropic with respect to the relaxed metric , which in that case can vary only by a conformal factor .", "tokens": ["the", "simplest", "possibility", "is", "that", "of", "what", "has", "been", "termed", "a", "perfect", "solid", ",", "meaning", "one", "for", "which", "the", "elastic", "structure", "at", "each", "material", "position", "is", "isotropic", "with", "respect", "to", "the", "relaxed", "metric", ",", "which", "in", "that", "case", "can", "vary", "only", "by", "a", "conformal", "factor", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the simplest possibility", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 3, "i_end": 3}}], "id": 2228}, {"sent": "itti et al used low-level features of intensity , colour and orientation to build several conspicuity maps which are combined in a linear fashion to generate a saliency map .", "tokens": ["itti", "et", "al", "used", "low", "-", "level", "features", "of", "intensity", ",", "colour", "and", "orientation", "to", "build", "several", "conspicuity", "maps", "which", "are", "combined", "in", "a", "linear", "fashion", "to", "generate", "a", "saliency", "map", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "itti et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "itti", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "itti", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "build", "start": 76, "end": 81, "i_start": 15, "i_end": 15}}, {"character": {"text": "maps", "start": 102, "end": 106, "i_start": 18, "i_end": 18}, "action": {"text": "generate", "start": 149, "end": 157, "i_start": 27, "i_end": 27}}], "id": 2229}, {"sent": "deepfreak uses an adapted version of the residual neural network with 50 layers .", "tokens": ["deepfreak", "uses", "an", "adapted", "version", "of", "the", "residual", "neural", "network", "with", "50", "layers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deepfreak", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "uses", "start": 10, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "deepfreak", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "uses", "start": 10, "end": 14, "i_start": 1, "i_end": 1}}], "id": 2230}, {"sent": "the multipole expansion of the electromagnetic radiation .", "tokens": ["the", "multipole", "expansion", "of", "the", "electromagnetic", "radiation", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2231}, {"sent": "sanderson and croft present a means of automatically deriving a hierarchical organization of concepts from a set of documents by using a type of co-occurrence known as subsumption .", "tokens": ["sanderson", "and", "croft", "present", "a", "means", "of", "automatically", "deriving", "a", "hierarchical", "organization", "of", "concepts", "from", "a", "set", "of", "documents", "by", "using", "a", "type", "of", "co", "-", "occurrence", "known", "as", "subsumption", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "sanderson and croft", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "present", "start": 20, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "sanderson", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "present", "start": 20, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "croft", "start": 14, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "present", "start": 20, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "sanderson", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "deriving", "start": 53, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "croft", "start": 14, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "deriving", "start": 53, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "sanderson", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 129, "end": 134, "i_start": 20, "i_end": 20}}, {"character": {"text": "croft", "start": 14, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "using", "start": 129, "end": 134, "i_start": 20, "i_end": 20}}], "id": 2232}, {"sent": "then color x 0 x 1 , x 1 x 2 , x 3 x 4 , x 4 x 5 , x 5 x 6 , x 6 x 7 , x 7 x 0 , x 4 x 0 with 5 , 2 , 1 , 4 , 3 , 5 , 1 , 3 , respectively , and color x 2 x 3 from with respect to 1 and u \u03c6 .", "tokens": ["then", "color", "x", "0", "x", "1", ",", "x", "1", "x", "2", ",", "x", "3", "x", "4", ",", "x", "4", "x", "5", ",", "x", "5", "x", "6", ",", "x", "6", "x", "7", ",", "x", "7", "x", "0", ",", "x", "4", "x", "0", "with", "5", ",", "2", ",", "1", ",", "4", ",", "3", ",", "5", ",", "1", ",", "3", ",", "respectively", ",", "and", "color", "x", "2", "x", "3", "from", "with", "respect", "to", "1", "and", "u", "\u03c6", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2233}, {"sent": "we evaluate the models on the pascal voc 2007 detection benchmark with 5 k test images over 20 object categories .", "tokens": ["we", "evaluate", "the", "models", "on", "the", "pascal", "voc", "2007", "detection", "benchmark", "with", "5", "k", "test", "images", "over", "20", "object", "categories", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2234}, {"sent": "the exterior differential forms allow us to see an internal connection between various branches of mathematics and physics .", "tokens": ["the", "exterior", "differential", "forms", "allow", "us", "to", "see", "an", "internal", "connection", "between", "various", "branches", "of", "mathematics", "and", "physics", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the exterior differential forms", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "allow", "start": 32, "end": 37, "i_start": 4, "i_end": 4}}, {"subject": {"text": "us", "start": 38, "end": 40, "i_start": 5, "i_end": 5}, "verb": {"text": "see", "start": 44, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "forms", "start": 26, "end": 31, "i_start": 3, "i_end": 3}, "action": {"text": "allow", "start": 32, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "us", "start": 38, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "see", "start": 44, "end": 47, "i_start": 7, "i_end": 7}}], "id": 2235}, {"sent": "the dashed lines correspond to the correlation function between mock groups and mock neighbour galaxies in the direction perpendicular to the group shape major axis , as seen projected onto the sky .", "tokens": ["the", "dashed", "lines", "correspond", "to", "the", "correlation", "function", "between", "mock", "groups", "and", "mock", "neighbour", "galaxies", "in", "the", "direction", "perpendicular", "to", "the", "group", "shape", "major", "axis", ",", "as", "seen", "projected", "onto", "the", "sky", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dashed lines", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "correspond", "start": 17, "end": 27, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the dashed lines", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "mock", "start": 80, "end": 84, "i_start": 12, "i_end": 12}}, {"character": {"text": "groups", "start": 69, "end": 75, "i_start": 10, "i_end": 10}, "action": {"text": "function", "start": 47, "end": 55, "i_start": 7, "i_end": 7}}], "id": 2236}, {"sent": "this formulation has recently found application in metric learning for few-shot learning .", "tokens": ["this", "formulation", "has", "recently", "found", "application", "in", "metric", "learning", "for", "few", "-", "shot", "learning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this formulation", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "found", "start": 30, "end": 35, "i_start": 4, "i_end": 4}}, {"subject": {"text": "this formulation", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "has", "start": 17, "end": 20, "i_start": 2, "i_end": 2}}], "id": 2237}, {"sent": "the bloom filter is a probabilistic data structure designed to represent a set of elements .", "tokens": ["the", "bloom", "filter", "is", "a", "probabilistic", "data", "structure", "designed", "to", "represent", "a", "set", "of", "elements", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the bloom filter", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "structure", "start": 41, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "represent", "start": 63, "end": 72, "i_start": 10, "i_end": 10}}], "id": 2238}, {"sent": "to assemble the chromatin interaction network , we used the recent pchi-c dataset in mescs from schoenfelder et al , including interactions amongst promoters and between promoters and other genomic elements .", "tokens": ["to", "assemble", "the", "chromatin", "interaction", "network", ",", "we", "used", "the", "recent", "pchi", "-", "c", "dataset", "in", "mescs", "from", "schoenfelder", "et", "al", ",", "including", "interactions", "amongst", "promoters", "and", "between", "promoters", "and", "other", "genomic", "elements", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 48, "end": 50, "i_start": 7, "i_end": 7}, "verb": {"text": "used", "start": 51, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 48, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "used", "start": 51, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "promoters", "start": 148, "end": 157, "i_start": 25, "i_end": 25}, "action": {"text": "interaction", "start": 26, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "promoters", "start": 170, "end": 179, "i_start": 28, "i_end": 28}, "action": {"text": "interaction", "start": 26, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "elements", "start": 198, "end": 206, "i_start": 32, "i_end": 32}, "action": {"text": "interaction", "start": 26, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "other", "start": 184, "end": 189, "i_start": 30, "i_end": 30}, "action": {"text": "interaction", "start": 26, "end": 37, "i_start": 4, "i_end": 4}}], "id": 2239}, {"sent": "reconstruction of sugra parameters with nonuniversal guagino masses .", "tokens": ["reconstruction", "of", "sugra", "parameters", "with", "nonuniversal", "guagino", "masses", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2240}, {"sent": "the hopf algebra of motivic iterated integrals .", "tokens": ["the", "hopf", "algebra", "of", "motivic", "iterated", "integrals", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the hopf algebra of motivic", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "iterated", "start": 28, "end": 36, "i_start": 5, "i_end": 5}}], "id": 2241}, {"sent": "convolutional neural networks are widely used in many image recognition tasks , such as image classification , due to their significant advantages over traditional machine learning methods .", "tokens": ["convolutional", "neural", "networks", "are", "widely", "used", "in", "many", "image", "recognition", "tasks", ",", "such", "as", "image", "classification", ",", "due", "to", "their", "significant", "advantages", "over", "traditional", "machine", "learning", "methods", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 41, "end": 45, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 3, "i_end": 3}}], "id": 2242}, {"sent": "this strategy is compared with a baseline snn taken from , and is shown to outperform it , especially in the regime of small networks , and particularly so with the n-gram voting scheme .", "tokens": ["this", "strategy", "is", "compared", "with", "a", "baseline", "snn", "taken", "from", ",", "and", "is", "shown", "to", "outperform", "it", ",", "especially", "in", "the", "regime", "of", "small", "networks", ",", "and", "particularly", "so", "with", "the", "n", "-", "gram", "voting", "scheme", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this strategy", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is compared", "start": 14, "end": 25, "i_start": 2, "i_end": 3}}, {"subject": {"text": "this strategy", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "shown", "start": 66, "end": 71, "i_start": 13, "i_end": 13}}, {"character": {"text": "strategy", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "outperform", "start": 75, "end": 85, "i_start": 15, "i_end": 15}}], "id": 2243}, {"sent": "convolutional neural networks achieve remarkable success in a variety of tasks .", "tokens": ["convolutional", "neural", "networks", "achieve", "remarkable", "success", "in", "a", "variety", "of", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "achieve", "start": 30, "end": 37, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 30, "end": 37, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 49, "end": 56, "i_start": 5, "i_end": 5}}], "id": 2244}, {"sent": "in recent years , deep learning technology has attracted considerable interest in the computer vision and machine learning community .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "technology", "has", "attracted", "considerable", "interest", "in", "the", "computer", "vision", "and", "machine", "learning", "community", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning technology", "start": 18, "end": 42, "i_start": 4, "i_end": 6}, "verb": {"text": "has attracted", "start": 43, "end": 56, "i_start": 7, "i_end": 8}}, {"character": {"text": "technology", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "attracted", "start": 47, "end": 56, "i_start": 8, "i_end": 8}}], "id": 2245}, {"sent": "a maximal ideal i in a is a proper ideal with the property that any ideal in a which contains i is either equal to i or to a .", "tokens": ["a", "maximal", "ideal", "i", "in", "a", "is", "a", "proper", "ideal", "with", "the", "property", "that", "any", "ideal", "in", "a", "which", "contains", "i", "is", "either", "equal", "to", "i", "or", "to", "a", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "i in a", "start": 16, "end": 22, "i_start": 3, "i_end": 5}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 6, "i_end": 6}}, {"subject": {"text": "i in a", "start": 16, "end": 22, "i_start": 3, "i_end": 5}, "verb": {"text": "is", "start": 96, "end": 98, "i_start": 21, "i_end": 21}}], "id": 2246}, {"sent": "this property should be of interest in mathematical logic .", "tokens": ["this", "property", "should", "be", "of", "interest", "in", "mathematical", "logic", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this property", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "should be", "start": 14, "end": 23, "i_start": 2, "i_end": 3}}], "id": 2247}, {"sent": "instead of manually designing the semantic label space , frome et al used semantic information gleaned from unannotated text to learn visual-semantic embedding where semantic relationship between labels was preserved .", "tokens": ["instead", "of", "manually", "designing", "the", "semantic", "label", "space", ",", "frome", "et", "al", "used", "semantic", "information", "gleaned", "from", "unannotated", "text", "to", "learn", "visual", "-", "semantic", "embedding", "where", "semantic", "relationship", "between", "labels", "was", "preserved", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "frome et al", "start": 57, "end": 68, "i_start": 9, "i_end": 11}, "verb": {"text": "used", "start": 69, "end": 73, "i_start": 12, "i_end": 12}}, {"character": {"text": "frome", "start": 57, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "designing", "start": 20, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "frome", "start": 57, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "used", "start": 69, "end": 73, "i_start": 12, "i_end": 12}}, {"character": {"text": "frome", "start": 57, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "learn", "start": 128, "end": 133, "i_start": 20, "i_end": 20}}, {"character": {"text": "labels", "start": 196, "end": 202, "i_start": 29, "i_end": 29}, "action": {"text": "relationship", "start": 175, "end": 187, "i_start": 27, "i_end": 27}}], "id": 2248}, {"sent": "both curves are arbitrarily normalised to unity at the high-mass end .", "tokens": ["both", "curves", "are", "arbitrarily", "normalised", "to", "unity", "at", "the", "high", "-", "mass", "end", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "both curves", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 12, "end": 15, "i_start": 2, "i_end": 2}}], "id": 2249}, {"sent": "convolutional neural networks have achieved great success on visual recognition tasks .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "great", "success", "on", "visual", "recognition", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}], "id": 2250}, {"sent": "we used the adam optimizer with a learning-rate of 1e-08 to update the parameters .", "tokens": ["we", "used", "the", "adam", "optimizer", "with", "a", "learning", "-", "rate", "of", "1e-08", "to", "update", "the", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "update", "start": 60, "end": 66, "i_start": 13, "i_end": 13}}], "id": 2251}, {"sent": "the automaton is a model of \u03c8 if this evaluation yields tt , and is not otherwise .", "tokens": ["the", "automaton", "is", "a", "model", "of", "\u03c8", "if", "this", "evaluation", "yields", "tt", ",", "and", "is", "not", "otherwise", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the automaton", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "automaton", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "model", "start": 19, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "evaluation", "start": 38, "end": 48, "i_start": 9, "i_end": 9}, "action": {"text": "yields", "start": 49, "end": 55, "i_start": 10, "i_end": 10}}], "id": 2252}, {"sent": "the segment polarity network is a robust developmental module , nature 406 , 188 - 192 .", "tokens": ["the", "segment", "polarity", "network", "is", "a", "robust", "developmental", "module", ",", "nature", "406", ",", "188", "-", "192", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the segment polarity network", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 4, "i_end": 4}}], "id": 2253}, {"sent": "the monoid m is a garside monoid , with set of simples s and garside element \u03b4 .", "tokens": ["the", "monoid", "m", "is", "a", "garside", "monoid", ",", "with", "set", "of", "simples", "s", "and", "garside", "element", "\u03b4", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the monoid m", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 3, "i_end": 3}}], "id": 2254}, {"sent": "recently , many different methods have been developed to obtain the approximate solutions of nonlinear systems including the harmonic balance method .", "tokens": ["recently", ",", "many", "different", "methods", "have", "been", "developed", "to", "obtain", "the", "approximate", "solutions", "of", "nonlinear", "systems", "including", "the", "harmonic", "balance", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many different methods", "start": 11, "end": 33, "i_start": 2, "i_end": 4}, "verb": {"text": "have been developed", "start": 34, "end": 53, "i_start": 5, "i_end": 7}}], "id": 2255}, {"sent": "neural networks have led to state-of-the-art results on many important problems in artificial intelligence .", "tokens": ["neural", "networks", "have", "led", "to", "state", "-", "of", "-", "the", "-", "art", "results", "on", "many", "important", "problems", "in", "artificial", "intelligence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have led", "start": 16, "end": 24, "i_start": 2, "i_end": 3}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2256}, {"sent": "in index coding , the optimal linear code length is characterized by a term minrank , which is the minimum rank of a mixed matrix associated with the requirement graph .", "tokens": ["in", "index", "coding", ",", "the", "optimal", "linear", "code", "length", "is", "characterized", "by", "a", "term", "minrank", ",", "which", "is", "the", "minimum", "rank", "of", "a", "mixed", "matrix", "associated", "with", "the", "requirement", "graph", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the optimal linear code length", "start": 18, "end": 48, "i_start": 4, "i_end": 8}, "verb": {"text": "is characterized", "start": 49, "end": 65, "i_start": 9, "i_end": 10}}, {"character": {"text": "minrank", "start": 76, "end": 83, "i_start": 14, "i_end": 14}, "action": {"text": "characterized", "start": 52, "end": 65, "i_start": 10, "i_end": 10}}], "id": 2257}, {"sent": "when taking into account the effect of the opposite neutrino directions given by eq .", "tokens": ["when", "taking", "into", "account", "the", "effect", "of", "the", "opposite", "neutrino", "directions", "given", "by", "eq", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2258}, {"sent": "such an expansion is called perturbation theory .", "tokens": ["such", "an", "expansion", "is", "called", "perturbation", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such an expansion", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 18, "end": 27, "i_start": 3, "i_end": 4}}], "id": 2259}, {"sent": "bayesian networks in general , and continuous variable networks in particular , are being used in a wide range of applications , including fault detection , modeling of biological systems and medical diagnosis .", "tokens": ["bayesian", "networks", "in", "general", ",", "and", "continuous", "variable", "networks", "in", "particular", ",", "are", "being", "used", "in", "a", "wide", "range", "of", "applications", ",", "including", "fault", "detection", ",", "modeling", "of", "biological", "systems", "and", "medical", "diagnosis", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "bayesian networks in general", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "are being used", "start": 80, "end": 94, "i_start": 12, "i_end": 14}}], "id": 2260}, {"sent": "other than the source of the random lines used in the construction , this scheme goes back at least to , when computing c , suppose pi is in region v of the family .", "tokens": ["other", "than", "the", "source", "of", "the", "random", "lines", "used", "in", "the", "construction", ",", "this", "scheme", "goes", "back", "at", "least", "to", ",", "when", "computing", "c", ",", "suppose", "pi", "is", "in", "region", "v", "of", "the", "family", "."], "score": [1, 1, 0, 1, 1], "labels": [{"subject": {"text": "this scheme", "start": 69, "end": 80, "i_start": 13, "i_end": 14}, "verb": {"text": "suppose", "start": 124, "end": 131, "i_start": 25, "i_end": 25}}, {"subject": {"text": "this scheme", "start": 69, "end": 80, "i_start": 13, "i_end": 14}, "verb": {"text": "goes", "start": 81, "end": 85, "i_start": 15, "i_end": 15}}, {"subject": {"text": "this scheme", "start": 69, "end": 80, "i_start": 13, "i_end": 14}, "verb": {"text": "is", "start": 135, "end": 137, "i_start": 27, "i_end": 27}}], "id": 2261}, {"sent": "a set of 8 generators for o denote the canonical orthonormal basis in r8 .", "tokens": ["a", "set", "of", "8", "generators", "for", "o", "denote", "the", "canonical", "orthonormal", "basis", "in", "r8", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "set", "start": 2, "end": 5, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 28, "end": 34, "i_start": 7, "i_end": 7}}], "id": 2262}, {"sent": "really , for the proof of instability , it is enough to prove instability with respect to at least one perturbation .", "tokens": ["really", ",", "for", "the", "proof", "of", "instability", ",", "it", "is", "enough", "to", "prove", "instability", "with", "respect", "to", "at", "least", "one", "perturbation", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 40, "end": 42, "i_start": 8, "i_end": 8}, "verb": {"text": "is", "start": 43, "end": 45, "i_start": 9, "i_end": 9}}, {"character": {"text": "it", "start": 40, "end": 42, "i_start": 8, "i_end": 8}, "action": {"text": "prove", "start": 56, "end": 61, "i_start": 12, "i_end": 12}}], "id": 2263}, {"sent": "the density functional description of the bond formation .", "tokens": ["the", "density", "functional", "description", "of", "the", "bond", "formation", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2264}, {"sent": "we use gated recurrent unit with bi-directions to model the contextual representations .", "tokens": ["we", "use", "gated", "recurrent", "unit", "with", "bi", "-", "directions", "to", "model", "the", "contextual", "representations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "unit", "start": 23, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "model", "start": 50, "end": 55, "i_start": 10, "i_end": 10}}], "id": 2265}, {"sent": "we include some examples of this type in the following section .", "tokens": ["we", "include", "some", "examples", "of", "this", "type", "in", "the", "following", "section", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "include", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "include", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 2266}, {"sent": "the string tension is a rapidly decreasing zz as fitting parameters .", "tokens": ["the", "string", "tension", "is", "a", "rapidly", "decreasing", "zz", "as", "fitting", "parameters", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the string tension", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 2267}, {"sent": "for image representation , we use resnet generated image features which are provided by the wmt organization .", "tokens": ["for", "image", "representation", ",", "we", "use", "resnet", "generated", "image", "features", "which", "are", "provided", "by", "the", "wmt", "organization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 27, "end": 29, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 30, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 27, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 30, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "organization", "start": 96, "end": 108, "i_start": 16, "i_end": 16}, "action": {"text": "provided", "start": 76, "end": 84, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 27, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "representation", "start": 10, "end": 24, "i_start": 2, "i_end": 2}}], "id": 2268}, {"sent": "qian et al proved that sampling is robust to one-bit noise and additive gaussian noise .", "tokens": ["qian", "et", "al", "proved", "that", "sampling", "is", "robust", "to", "one", "-", "bit", "noise", "and", "additive", "gaussian", "noise", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "qian et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "proved", "start": 11, "end": 17, "i_start": 3, "i_end": 3}}, {"subject": {"text": "qian et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "qian", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proved", "start": 11, "end": 17, "i_start": 3, "i_end": 3}}], "id": 2269}, {"sent": "multi-task learning leverages the task relatedness in the form of shared structures to jointly learn multiple tasks .", "tokens": ["multi", "-", "task", "learning", "leverages", "the", "task", "relatedness", "in", "the", "form", "of", "shared", "structures", "to", "jointly", "learn", "multiple", "tasks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "multi-task learning", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "leverages", "start": 20, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "learn", "start": 95, "end": 100, "i_start": 16, "i_end": 16}, "action": {"text": "leverages", "start": 20, "end": 29, "i_start": 4, "i_end": 4}}], "id": 2270}, {"sent": "deep convolutional neural networks have made significant breakthroughs in many visual understanding tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "significant", "breakthroughs", "in", "many", "visual", "understanding", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "breakthroughs", "start": 57, "end": 70, "i_start": 7, "i_end": 7}}], "id": 2271}, {"sent": "the icecube collaboration has recently reported evidence for extraterrestrial neutrinos , after the observation of three pev neutrino cascades within three years of operation .", "tokens": ["the", "icecube", "collaboration", "has", "recently", "reported", "evidence", "for", "extraterrestrial", "neutrinos", ",", "after", "the", "observation", "of", "three", "pev", "neutrino", "cascades", "within", "three", "years", "of", "operation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the icecube collaboration", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "reported", "start": 39, "end": 47, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the icecube collaboration", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "has", "start": 26, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "collaboration", "start": 12, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "reported", "start": 39, "end": 47, "i_start": 5, "i_end": 5}}], "id": 2272}, {"sent": "the model is trained end-to-end using the adam optimizer with a mini-batch size of 100 .", "tokens": ["the", "model", "is", "trained", "end", "-", "to", "-", "end", "using", "the", "adam", "optimizer", "with", "a", "mini", "-", "batch", "size", "of", "100", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is trained", "start": 10, "end": 20, "i_start": 2, "i_end": 3}}], "id": 2273}, {"sent": "the dice similarity metric was used for the overlap evaluation of the segmented regions .", "tokens": ["the", "dice", "similarity", "metric", "was", "used", "for", "the", "overlap", "evaluation", "of", "the", "segmented", "regions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dice similarity metric", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "was used", "start": 27, "end": 35, "i_start": 4, "i_end": 5}}], "id": 2274}, {"sent": "some examples are marching , singing and noise making at street demonstrations before a physical confrontation with the incumbent power .", "tokens": ["some", "examples", "are", "marching", ",", "singing", "and", "noise", "making", "at", "street", "demonstrations", "before", "a", "physical", "confrontation", "with", "the", "incumbent", "power", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "some examples", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "are marching", "start": 14, "end": 26, "i_start": 2, "i_end": 3}}], "id": 2275}, {"sent": "k-fold vector cross products on linear spaces are studied by brown and gray .", "tokens": ["k", "-", "fold", "vector", "cross", "products", "on", "linear", "spaces", "are", "studied", "by", "brown", "and", "gray", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "-fold vector cross products on linear spaces", "start": 1, "end": 45, "i_start": 1, "i_end": 8}, "verb": {"text": "are studied", "start": 46, "end": 57, "i_start": 9, "i_end": 10}}, {"character": {"text": "brown", "start": 61, "end": 66, "i_start": 12, "i_end": 12}, "action": {"text": "studied", "start": 50, "end": 57, "i_start": 10, "i_end": 10}}, {"character": {"text": "gray", "start": 71, "end": 75, "i_start": 14, "i_end": 14}, "action": {"text": "studied", "start": 50, "end": 57, "i_start": 10, "i_end": 10}}], "id": 2276}, {"sent": "dropout is commonly used to reduce overfitting in neural networks by randomly dropping units from the neural network during training .", "tokens": ["dropout", "is", "commonly", "used", "to", "reduce", "overfitting", "in", "neural", "networks", "by", "randomly", "dropping", "units", "from", "the", "neural", "network", "during", "training", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "dropout", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 20, "end": 24, "i_start": 3, "i_end": 3}}, {"subject": {"text": "dropout", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "dropout", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "reduce", "start": 28, "end": 34, "i_start": 5, "i_end": 5}}], "id": 2277}, {"sent": "in social psychology , it has been shown that people prefer to team up with others possessing similar morphological and behavioral features , and that they tend to coordinate their movement unconsciously .", "tokens": ["in", "social", "psychology", ",", "it", "has", "been", "shown", "that", "people", "prefer", "to", "team", "up", "with", "others", "possessing", "similar", "morphological", "and", "behavioral", "features", ",", "and", "that", "they", "tend", "to", "coordinate", "their", "movement", "unconsciously", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "verb": {"text": "has been shown", "start": 26, "end": 40, "i_start": 5, "i_end": 7}}, {"subject": {"text": "people", "start": 46, "end": 52, "i_start": 9, "i_end": 9}, "verb": {"text": "prefer", "start": 53, "end": 59, "i_start": 10, "i_end": 10}}, {"character": {"text": "others", "start": 76, "end": 82, "i_start": 15, "i_end": 15}, "action": {"text": "possessing", "start": 83, "end": 93, "i_start": 16, "i_end": 16}}], "id": 2278}, {"sent": "when there is no forcing , the system represents a delayed genetic toggle switch , a synthetic gene regulatory network .", "tokens": ["when", "there", "is", "no", "forcing", ",", "the", "system", "represents", "a", "delayed", "genetic", "toggle", "switch", ",", "a", "synthetic", "gene", "regulatory", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the system", "start": 27, "end": 37, "i_start": 6, "i_end": 7}, "verb": {"text": "represents", "start": 38, "end": 48, "i_start": 8, "i_end": 8}}, {"character": {"text": "system", "start": 31, "end": 37, "i_start": 7, "i_end": 7}, "action": {"text": "represents", "start": 38, "end": 48, "i_start": 8, "i_end": 8}}, {"character": {"text": "network", "start": 111, "end": 118, "i_start": 19, "i_end": 19}, "action": {"text": "regulatory", "start": 100, "end": 110, "i_start": 18, "i_end": 18}}], "id": 2279}, {"sent": "due to the global approximation nature of neural networks , high learning rates cause catastrophic interference .", "tokens": ["due", "to", "the", "global", "approximation", "nature", "of", "neural", "networks", ",", "high", "learning", "rates", "cause", "catastrophic", "interference", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "high learning rates", "start": 60, "end": 79, "i_start": 10, "i_end": 12}, "verb": {"text": "cause", "start": 80, "end": 85, "i_start": 13, "i_end": 13}}, {"character": {"text": "rates", "start": 74, "end": 79, "i_start": 12, "i_end": 12}, "action": {"text": "cause", "start": 80, "end": 85, "i_start": 13, "i_end": 13}}], "id": 2280}, {"sent": "the kitti dataset contains 42 , 382 rectified stereo pairs from 61 scenes .", "tokens": ["the", "kitti", "dataset", "contains", "42", ",", "382", "rectified", "stereo", "pairs", "from", "61", "scenes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the kitti dataset", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "contains", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "dataset", "start": 10, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "contains", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}], "id": 2281}, {"sent": "here is the definition of unbiased monoidal category .", "tokens": ["here", "is", "the", "definition", "of", "unbiased", "monoidal", "category", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the definition of unbiased monoidal category", "start": 8, "end": 52, "i_start": 2, "i_end": 7}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 2282}, {"sent": "this is what we call actor-network procedures .", "tokens": ["this", "is", "what", "we", "call", "actor", "-", "network", "procedures", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "call", "start": 16, "end": 20, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "call", "start": 16, "end": 20, "i_start": 4, "i_end": 4}}], "id": 2283}, {"sent": "the data produced by these teams can include information like command and control ip addresses , low-level indicators of compromise , and malware hash values .", "tokens": ["the", "data", "produced", "by", "these", "teams", "can", "include", "information", "like", "command", "and", "control", "ip", "addresses", ",", "low", "-", "level", "indicators", "of", "compromise", ",", "and", "malware", "hash", "values", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data produced by these teams", "start": 0, "end": 32, "i_start": 0, "i_end": 5}, "verb": {"text": "can include", "start": 33, "end": 44, "i_start": 6, "i_end": 7}}, {"character": {"text": "teams", "start": 27, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "produced", "start": 9, "end": 17, "i_start": 2, "i_end": 2}}], "id": 2284}, {"sent": "it has been shown in that for any set of polynomials with integer coefficients , there exists a network which has an slnc solution over a finite field if and only if the set of polynomials have a common root over the field .", "tokens": ["it", "has", "been", "shown", "in", "that", "for", "any", "set", "of", "polynomials", "with", "integer", "coefficients", ",", "there", "exists", "a", "network", "which", "has", "an", "slnc", "solution", "over", "a", "finite", "field", "if", "and", "only", "if", "the", "set", "of", "polynomials", "have", "a", "common", "root", "over", "the", "field", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has been shown", "start": 3, "end": 17, "i_start": 1, "i_end": 3}}, {"character": {"text": "set", "start": 34, "end": 37, "i_start": 8, "i_end": 8}, "action": {"text": "has", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "set", "start": 34, "end": 37, "i_start": 8, "i_end": 8}, "action": {"text": "has", "start": 110, "end": 113, "i_start": 20, "i_end": 20}}], "id": 2285}, {"sent": "in this paper , we investigate the use of channel coding on top of cresm to reduce the error probability .", "tokens": ["in", "this", "paper", ",", "we", "investigate", "the", "use", "of", "channel", "coding", "on", "top", "of", "cresm", "to", "reduce", "the", "error", "probability", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "investigate", "start": 19, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "investigate", "start": 19, "end": 30, "i_start": 5, "i_end": 5}}], "id": 2286}, {"sent": "deep convolutional neural networks have recently shown immense success for various image recognition tasks , such as object recognition .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "recently", "shown", "immense", "success", "for", "various", "image", "recognition", "tasks", ",", "such", "as", "object", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "shown", "start": 49, "end": 54, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 63, "end": 70, "i_start": 8, "i_end": 8}}], "id": 2287}, {"sent": "each deconvolutional layer is followed by a batch normalization layer .", "tokens": ["each", "deconvolutional", "layer", "is", "followed", "by", "a", "batch", "normalization", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each deconvolutional layer", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "is followed", "start": 27, "end": 38, "i_start": 3, "i_end": 4}}], "id": 2288}, {"sent": "this type of regularization is analogous to the local shrinkage term developed in prior work .", "tokens": ["this", "type", "of", "regularization", "is", "analogous", "to", "the", "local", "shrinkage", "term", "developed", "in", "prior", "work", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this type of regularization", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 4, "i_end": 4}}], "id": 2289}, {"sent": "in reinforcement learning , a behaving agent interacts with its environment and tries to maximize the expected future reward it receives from the environment as a consequence of this interaction .", "tokens": ["in", "reinforcement", "learning", ",", "a", "behaving", "agent", "interacts", "with", "its", "environment", "and", "tries", "to", "maximize", "the", "expected", "future", "reward", "it", "receives", "from", "the", "environment", "as", "a", "consequence", "of", "this", "interaction", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a behaving agent", "start": 28, "end": 44, "i_start": 4, "i_end": 6}, "verb": {"text": "interacts", "start": 45, "end": 54, "i_start": 7, "i_end": 7}}, {"subject": {"text": "a behaving agent", "start": 28, "end": 44, "i_start": 4, "i_end": 6}, "verb": {"text": "tries", "start": 80, "end": 85, "i_start": 12, "i_end": 12}}, {"character": {"text": "agent", "start": 39, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "interacts", "start": 45, "end": 54, "i_start": 7, "i_end": 7}}, {"character": {"text": "agent", "start": 39, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "behaving", "start": 30, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "agent", "start": 39, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "tries", "start": 80, "end": 85, "i_start": 12, "i_end": 12}}, {"character": {"text": "agent", "start": 39, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "maximize", "start": 89, "end": 97, "i_start": 14, "i_end": 14}}, {"character": {"text": "environment", "start": 64, "end": 75, "i_start": 10, "i_end": 10}, "action": {"text": "reward", "start": 118, "end": 124, "i_start": 18, "i_end": 18}}, {"character": {"text": "agent", "start": 39, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "receives", "start": 128, "end": 136, "i_start": 20, "i_end": 20}}], "id": 2290}, {"sent": "to avoid overfitting , we apply dropout to fully connected layers for all dnn models .", "tokens": ["to", "avoid", "overfitting", ",", "we", "apply", "dropout", "to", "fully", "connected", "layers", "for", "all", "dnn", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "verb": {"text": "apply", "start": 26, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "apply", "start": 26, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "avoid", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2291}, {"sent": "traditional human pose estimation methods often follow the framework of tree structured graphical model .", "tokens": ["traditional", "human", "pose", "estimation", "methods", "often", "follow", "the", "framework", "of", "tree", "structured", "graphical", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "traditional human pose estimation methods", "start": 0, "end": 41, "i_start": 0, "i_end": 4}, "verb": {"text": "follow", "start": 48, "end": 54, "i_start": 6, "i_end": 6}}, {"character": {"text": "methods", "start": 34, "end": 41, "i_start": 4, "i_end": 4}, "action": {"text": "follow", "start": 48, "end": 54, "i_start": 6, "i_end": 6}}], "id": 2292}, {"sent": "in , a distributed ia scheme was constructed for the mimo interference channel with time-invariant coefficients .", "tokens": ["in", ",", "a", "distributed", "ia", "scheme", "was", "constructed", "for", "the", "mimo", "interference", "channel", "with", "time", "-", "invariant", "coefficients", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a distributed ia scheme", "start": 5, "end": 28, "i_start": 2, "i_end": 5}, "verb": {"text": "was constructed", "start": 29, "end": 44, "i_start": 6, "i_end": 7}}, {"character": {"text": "channel", "start": 71, "end": 78, "i_start": 12, "i_end": 12}, "action": {"text": "interference", "start": 58, "end": 70, "i_start": 11, "i_end": 11}}], "id": 2293}, {"sent": "convolutional neural networks have been trained to achieve near human-level performance on object detection .", "tokens": ["convolutional", "neural", "networks", "have", "been", "trained", "to", "achieve", "near", "human", "-", "level", "performance", "on", "object", "detection", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been trained", "start": 30, "end": 47, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 51, "end": 58, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 76, "end": 87, "i_start": 12, "i_end": 12}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "detection", "start": 98, "end": 107, "i_start": 15, "i_end": 15}}], "id": 2294}, {"sent": "we also demonstrate the connection between the effect of reflectionless tunneling in ballistic systems discussed in this paper , to the one in diffusive systems .", "tokens": ["we", "also", "demonstrate", "the", "connection", "between", "the", "effect", "of", "reflectionless", "tunneling", "in", "ballistic", "systems", "discussed", "in", "this", "paper", ",", "to", "the", "one", "in", "diffusive", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "demonstrate", "start": 8, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "demonstrate", "start": 8, "end": 19, "i_start": 2, "i_end": 2}}], "id": 2295}, {"sent": "deep learning approaches , in particularly deep convolutional neural networks , have achieved tremendous successes in various visual recognition tasks .", "tokens": ["deep", "learning", "approaches", ",", "in", "particularly", "deep", "convolutional", "neural", "networks", ",", "have", "achieved", "tremendous", "successes", "in", "various", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep learning approaches", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 80, "end": 93, "i_start": 11, "i_end": 12}}, {"character": {"text": "approaches", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 85, "end": 93, "i_start": 12, "i_end": 12}}], "id": 2296}, {"sent": "the particle-flow event algorithm is designed to reconstruct and identify each individual particle with an optimized combination of information from the various elements of the cms detector .", "tokens": ["the", "particle", "-", "flow", "event", "algorithm", "is", "designed", "to", "reconstruct", "and", "identify", "each", "individual", "particle", "with", "an", "optimized", "combination", "of", "information", "from", "the", "various", "elements", "of", "the", "cms", "detector", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the particle-flow event algorithm", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "is designed", "start": 34, "end": 45, "i_start": 6, "i_end": 7}}, {"character": {"text": "algorithm", "start": 24, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "reconstruct", "start": 49, "end": 60, "i_start": 9, "i_end": 9}}, {"character": {"text": "algorithm", "start": 24, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "identify", "start": 65, "end": 73, "i_start": 11, "i_end": 11}}], "id": 2297}, {"sent": "the exchange-correlation energy was evaluated with the help of the perdew-burke-erzenhof approach , within the generalised gradient approximation .", "tokens": ["the", "exchange", "-", "correlation", "energy", "was", "evaluated", "with", "the", "help", "of", "the", "perdew", "-", "burke", "-", "erzenhof", "approach", ",", "within", "the", "generalised", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange-correlation energy", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "was evaluated", "start": 32, "end": 45, "i_start": 5, "i_end": 6}}, {"character": {"text": "approach", "start": 89, "end": 97, "i_start": 17, "i_end": 17}, "action": {"text": "help", "start": 55, "end": 59, "i_start": 9, "i_end": 9}}], "id": 2298}, {"sent": "we use the adam optimizer with recommended default hyperparameters in sgd optimization .", "tokens": ["we", "use", "the", "adam", "optimizer", "with", "recommended", "default", "hyperparameters", "in", "sgd", "optimization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 2299}, {"sent": "the ordinate is the binary fraction for all objects with projected radius less than the value on the abscissa .", "tokens": ["the", "ordinate", "is", "the", "binary", "fraction", "for", "all", "objects", "with", "projected", "radius", "less", "than", "the", "value", "on", "the", "abscissa", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ordinate", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 2300}, {"sent": "generative adversarial networks are one of the most common tools for learning complex distributions .", "tokens": ["generative", "adversarial", "networks", "are", "one", "of", "the", "most", "common", "tools", "for", "learning", "complex", "distributions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}], "id": 2301}, {"sent": "deep learning has succeeded in making hierarchical neural networks perform excellently in various practical applications .", "tokens": ["deep", "learning", "has", "succeeded", "in", "making", "hierarchical", "neural", "networks", "perform", "excellently", "in", "various", "practical", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has succeeded", "start": 14, "end": 27, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "succeeded", "start": 18, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "making", "start": 31, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 58, "end": 66, "i_start": 8, "i_end": 8}, "action": {"text": "perform", "start": 67, "end": 74, "i_start": 9, "i_end": 9}}], "id": 2302}, {"sent": "physical foundations of cosmology , cambridge university press .", "tokens": ["physical", "foundations", "of", "cosmology", ",", "cambridge", "university", "press", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2303}, {"sent": "in the latter phase , the optimal orientation is parallel to the external modulation .", "tokens": ["in", "the", "latter", "phase", ",", "the", "optimal", "orientation", "is", "parallel", "to", "the", "external", "modulation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the optimal orientation", "start": 22, "end": 45, "i_start": 5, "i_end": 7}, "verb": {"text": "is", "start": 46, "end": 48, "i_start": 8, "i_end": 8}}], "id": 2304}, {"sent": "in recent years , there have been outstanding achievements in objects detection by successfully deploying a convolutional neural network .", "tokens": ["in", "recent", "years", ",", "there", "have", "been", "outstanding", "achievements", "in", "objects", "detection", "by", "successfully", "deploying", "a", "convolutional", "neural", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 18, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "have been", "start": 24, "end": 33, "i_start": 5, "i_end": 6}}], "id": 2305}, {"sent": "the semicolon denotes string concatenation .", "tokens": ["the", "semicolon", "denotes", "string", "concatenation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the semicolon", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "denotes", "start": 14, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "semicolon", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "denotes", "start": 14, "end": 21, "i_start": 2, "i_end": 2}}], "id": 2306}, {"sent": "the gradient descent is simple to implement and has accelerated practical achievements in developing rnns .", "tokens": ["the", "gradient", "descent", "is", "simple", "to", "implement", "and", "has", "accelerated", "practical", "achievements", "in", "developing", "rnns", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the gradient descent", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the gradient descent", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "accelerated", "start": 52, "end": 63, "i_start": 9, "i_end": 9}}, {"character": {"text": "implement", "start": 34, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "accelerated", "start": 52, "end": 63, "i_start": 9, "i_end": 9}}], "id": 2307}, {"sent": "deep learning or representation learning has received increasing interest in recent years owing to their success in several applications .", "tokens": ["deep", "learning", "or", "representation", "learning", "has", "received", "increasing", "interest", "in", "recent", "years", "owing", "to", "their", "success", "in", "several", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning or representation learning", "start": 0, "end": 40, "i_start": 0, "i_end": 4}, "verb": {"text": "has received", "start": 41, "end": 53, "i_start": 5, "i_end": 6}}, {"character": {"text": "or", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "received", "start": 45, "end": 53, "i_start": 6, "i_end": 6}}, {"character": {"text": "or", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 105, "end": 112, "i_start": 15, "i_end": 15}}], "id": 2308}, {"sent": "bremsstrahlung is the dominant cooling mechanism at these very high temperatures .", "tokens": ["bremsstrahlung", "is", "the", "dominant", "cooling", "mechanism", "at", "these", "very", "high", "temperatures", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "bremsstrahlung", "start": 0, "end": 14, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 1, "i_end": 1}}, {"character": {"text": "mechanism", "start": 39, "end": 48, "i_start": 5, "i_end": 5}, "action": {"text": "cooling", "start": 31, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "mechanism", "start": 39, "end": 48, "i_start": 5, "i_end": 5}, "action": {"text": "dominant", "start": 22, "end": 30, "i_start": 3, "i_end": 3}}], "id": 2309}, {"sent": "deep neural networks are at the core of state-of-the-art models for supervised tasks like image recognition and speech recognition .", "tokens": ["deep", "neural", "networks", "are", "at", "the", "core", "of", "state", "-", "of", "-", "the", "-", "art", "models", "for", "supervised", "tasks", "like", "image", "recognition", "and", "speech", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2310}, {"sent": "by means of the representation of \u03be the notions of relative velocity and relative acceleration are introduced in -spaces .", "tokens": ["by", "means", "of", "the", "representation", "of", "\u03be", "the", "notions", "of", "relative", "velocity", "and", "relative", "acceleration", "are", "introduced", "in", "-spaces", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2311}, {"sent": "in event-triggered broadcasting a subsystem sends its local state to the network only when a measure of the local subsystem state error is above a specified threshold .", "tokens": ["in", "event", "-", "triggered", "broadcasting", "a", "subsystem", "sends", "its", "local", "state", "to", "the", "network", "only", "when", "a", "measure", "of", "the", "local", "subsystem", "state", "error", "is", "above", "a", "specified", "threshold", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "subsystem", "start": 34, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "sends", "start": 44, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "event", "start": 3, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "triggered", "start": 9, "end": 18, "i_start": 3, "i_end": 3}}], "id": 2312}, {"sent": "we will not distinguish n-tuples equivalent under this action .", "tokens": ["we", "will", "not", "distinguish", "n", "-", "tuples", "equivalent", "under", "this", "action", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will not distinguish", "start": 3, "end": 23, "i_start": 1, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "not distinguish", "start": 8, "end": 23, "i_start": 2, "i_end": 3}}], "id": 2313}, {"sent": "in this subsection , we recall the definition and properties of the quasi-automorphism group from .", "tokens": ["in", "this", "subsection", ",", "we", "recall", "the", "definition", "and", "properties", "of", "the", "quasi", "-", "automorphism", "group", "from", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "recall", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "recall", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}], "id": 2314}, {"sent": "however , the cfo estimation technique presented in , requires multidimensional grid search and therefore has an exponential complexity with increasing number of uts .", "tokens": ["however", ",", "the", "cfo", "estimation", "technique", "presented", "in", ",", "requires", "multidimensional", "grid", "search", "and", "therefore", "has", "an", "exponential", "complexity", "with", "increasing", "number", "of", "uts", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the cfo estimation technique presented in", "start": 10, "end": 51, "i_start": 2, "i_end": 7}, "verb": {"text": "requires", "start": 54, "end": 62, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the cfo estimation technique presented in", "start": 10, "end": 51, "i_start": 2, "i_end": 7}, "verb": {"text": "has", "start": 106, "end": 109, "i_start": 15, "i_end": 15}}, {"character": {"text": "technique", "start": 29, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "requires", "start": 54, "end": 62, "i_start": 9, "i_end": 9}}], "id": 2315}, {"sent": "interpretation of the directional derivative in terms of intersection products and many applications are given in .", "tokens": ["interpretation", "of", "the", "directional", "derivative", "in", "terms", "of", "intersection", "products", "and", "many", "applications", "are", "given", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "interpretation of the directional derivative in terms of intersection products and many applications", "start": 0, "end": 100, "i_start": 0, "i_end": 12}, "verb": {"text": "are given in", "start": 101, "end": 113, "i_start": 13, "i_end": 15}}], "id": 2316}, {"sent": "a special case of the kuperberg invariant reduces to the dijkgraaf-witten theory .", "tokens": ["a", "special", "case", "of", "the", "kuperberg", "invariant", "reduces", "to", "the", "dijkgraaf", "-", "witten", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a special case of the kuperberg invariant", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "reduces", "start": 42, "end": 49, "i_start": 7, "i_end": 7}}], "id": 2317}, {"sent": "deep neural networks have significantly improved the state of the art on many supervised tasks .", "tokens": ["deep", "neural", "networks", "have", "significantly", "improved", "the", "state", "of", "the", "art", "on", "many", "supervised", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}], "id": 2318}, {"sent": "automatic repeat request and hybrid arq , which combines fec and arq error control , have been used in 5g mobile networks .", "tokens": ["automatic", "repeat", "request", "and", "hybrid", "arq", ",", "which", "combines", "fec", "and", "arq", "error", "control", ",", "have", "been", "used", "in", "5", "g", "mobile", "networks", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "automatic repeat request and hybrid arq", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "have been used", "start": 85, "end": 99, "i_start": 15, "i_end": 17}}], "id": 2319}, {"sent": "gravity is a key force in multi-dimensional astrophysical hydrodynamics .", "tokens": ["gravity", "is", "a", "key", "force", "in", "multi", "-", "dimensional", "astrophysical", "hydrodynamics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "gravity", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}], "id": 2320}, {"sent": "we will illustrate each of the situation by some examples .", "tokens": ["we", "will", "illustrate", "each", "of", "the", "situation", "by", "some", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will illustrate", "start": 3, "end": 18, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "illustrate", "start": 8, "end": 18, "i_start": 2, "i_end": 2}}], "id": 2321}, {"sent": "independent of the conventions chosen , the chernsimons and green-schwarz terms must always have the same sign .", "tokens": ["independent", "of", "the", "conventions", "chosen", ",", "the", "chernsimons", "and", "green", "-", "schwarz", "terms", "must", "always", "have", "the", "same", "sign", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the chernsimons and green-schwarz terms", "start": 40, "end": 79, "i_start": 6, "i_end": 12}, "verb": {"text": "have", "start": 92, "end": 96, "i_start": 15, "i_end": 15}}, {"subject": {"text": "the chernsimons and green-schwarz terms", "start": 40, "end": 79, "i_start": 6, "i_end": 12}, "verb": {"text": "must", "start": 80, "end": 84, "i_start": 13, "i_end": 13}}, {"character": {"text": "terms", "start": 74, "end": 79, "i_start": 12, "i_end": 12}, "action": {"text": "sign", "start": 106, "end": 110, "i_start": 18, "i_end": 18}}, {"character": {"text": "chernsimons", "start": 44, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "sign", "start": 106, "end": 110, "i_start": 18, "i_end": 18}}, {"character": {"text": "green", "start": 60, "end": 65, "i_start": 9, "i_end": 9}, "action": {"text": "sign", "start": 106, "end": 110, "i_start": 18, "i_end": 18}}], "id": 2322}, {"sent": "this idea leads to several kinds of matrix models which have been proposed for the constructive definition of string theory or m-theory .", "tokens": ["this", "idea", "leads", "to", "several", "kinds", "of", "matrix", "models", "which", "have", "been", "proposed", "for", "the", "constructive", "definition", "of", "string", "theory", "or", "m", "-", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this idea", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "leads", "start": 10, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "idea", "start": 5, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "leads", "start": 10, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "definition", "start": 96, "end": 106, "i_start": 16, "i_end": 16}, "action": {"text": "constructive", "start": 83, "end": 95, "i_start": 15, "i_end": 15}}], "id": 2323}, {"sent": "in recent years , deep learning based algorithms have shown great power in object detection and classification tasks .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "based", "algorithms", "have", "shown", "great", "power", "in", "object", "detection", "and", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning based algorithms", "start": 18, "end": 48, "i_start": 4, "i_end": 7}, "verb": {"text": "have shown", "start": 49, "end": 59, "i_start": 8, "i_end": 9}}, {"character": {"text": "algorithms", "start": 38, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "shown", "start": 54, "end": 59, "i_start": 9, "i_end": 9}}], "id": 2324}, {"sent": "the dashed line shows the linear regression for spirals in s-s pairs .", "tokens": ["the", "dashed", "line", "shows", "the", "linear", "regression", "for", "spirals", "in", "s", "-", "s", "pairs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the dashed line", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "shows", "start": 16, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "line", "start": 11, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "shows", "start": 16, "end": 21, "i_start": 3, "i_end": 3}}], "id": 2325}, {"sent": "now we proceed on to define free near-ring .", "tokens": ["now", "we", "proceed", "on", "to", "define", "free", "near", "-", "ring", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed on", "start": 7, "end": 17, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 2326}, {"sent": "the lagrangian can be used to define the couplings of the theory and the mass matrices .", "tokens": ["the", "lagrangian", "can", "be", "used", "to", "define", "the", "couplings", "of", "the", "theory", "and", "the", "mass", "matrices", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lagrangian", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "can be used", "start": 15, "end": 26, "i_start": 2, "i_end": 4}}, {"character": {"text": "lagrangian", "start": 4, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 30, "end": 36, "i_start": 6, "i_end": 6}}], "id": 2327}, {"sent": "the method uses u-net , which contains 8 downsampling and 8 upsampling layers , with skip connections to preserve local information .", "tokens": ["the", "method", "uses", "u", "-", "net", ",", "which", "contains", "8", "downsampling", "and", "8", "upsampling", "layers", ",", "with", "skip", "connections", "to", "preserve", "local", "information", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the method", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "uses", "start": 11, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "method", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "uses", "start": 11, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "method", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "preserve", "start": 105, "end": 113, "i_start": 20, "i_end": 20}}], "id": 2328}, {"sent": "after that , the notion of information theoretic security was characterized by wyner as the wiretap channel model in which a single source-destination communication link is eavesdropped by a wiretapper via a degraded channel .", "tokens": ["after", "that", ",", "the", "notion", "of", "information", "theoretic", "security", "was", "characterized", "by", "wyner", "as", "the", "wiretap", "channel", "model", "in", "which", "a", "single", "source", "-", "destination", "communication", "link", "is", "eavesdropped", "by", "a", "wiretapper", "via", "a", "degraded", "channel", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the notion of information theoretic security", "start": 13, "end": 57, "i_start": 3, "i_end": 8}, "verb": {"text": "was characterized", "start": 58, "end": 75, "i_start": 9, "i_end": 10}}], "id": 2329}, {"sent": "the mc samples were processed through a detailed atlas detector simulation .", "tokens": ["the", "mc", "samples", "were", "processed", "through", "a", "detailed", "atlas", "detector", "simulation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the mc samples", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "were processed", "start": 15, "end": 29, "i_start": 3, "i_end": 4}}], "id": 2330}, {"sent": "we now show that the group is an abelian group .", "tokens": ["we", "now", "show", "that", "the", "group", "is", "an", "abelian", "group", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}], "id": 2331}, {"sent": "a vortex is a topological defect in the bose field .", "tokens": ["a", "vortex", "is", "a", "topological", "defect", "in", "the", "bose", "field", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a vortex", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 2, "i_end": 2}}], "id": 2332}, {"sent": "the temporal structure is given by the sets qt of simultaneously measured qubits .", "tokens": ["the", "temporal", "structure", "is", "given", "by", "the", "sets", "qt", "of", "simultaneously", "measured", "qubits", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the temporal structure", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is given", "start": 23, "end": 31, "i_start": 3, "i_end": 4}}], "id": 2333}, {"sent": "each block contains two gated convolutional layers and a max-pooling layer .", "tokens": ["each", "block", "contains", "two", "gated", "convolutional", "layers", "and", "a", "max", "-", "pooling", "layer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "each block", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "contains", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "block", "start": 5, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "contains", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}], "id": 2334}, {"sent": "an asterisk denotes that the d relationship was added on the second iteration .", "tokens": ["an", "asterisk", "denotes", "that", "the", "d", "relationship", "was", "added", "on", "the", "second", "iteration", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "an asterisk", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "denotes", "start": 12, "end": 19, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the d relationship", "start": 25, "end": 43, "i_start": 4, "i_end": 6}, "verb": {"text": "added", "start": 48, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "asterisk", "start": 3, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "denotes", "start": 12, "end": 19, "i_start": 2, "i_end": 2}}], "id": 2335}, {"sent": "in , barton showed that for a thin piston with weakly reflecting dielectrics , the casimir force at small separations is attractive , but turn to repulsive as the separation increases .", "tokens": ["in", ",", "barton", "showed", "that", "for", "a", "thin", "piston", "with", "weakly", "reflecting", "dielectrics", ",", "the", "casimir", "force", "at", "small", "separations", "is", "attractive", ",", "but", "turn", "to", "repulsive", "as", "the", "separation", "increases", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "barton", "start": 5, "end": 11, "i_start": 2, "i_end": 2}, "verb": {"text": "showed", "start": 12, "end": 18, "i_start": 3, "i_end": 3}}, {"subject": {"text": "barton", "start": 5, "end": 11, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 118, "end": 120, "i_start": 20, "i_end": 20}}, {"character": {"text": "barton", "start": 5, "end": 11, "i_start": 2, "i_end": 2}, "action": {"text": "showed", "start": 12, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "force", "start": 91, "end": 96, "i_start": 16, "i_end": 16}, "action": {"text": "attractive", "start": 121, "end": 131, "i_start": 21, "i_end": 21}}, {"character": {"text": "casimir", "start": 83, "end": 90, "i_start": 15, "i_end": 15}, "action": {"text": "force", "start": 91, "end": 96, "i_start": 16, "i_end": 16}}, {"character": {"text": "force", "start": 91, "end": 96, "i_start": 16, "i_end": 16}, "action": {"text": "repulsive", "start": 146, "end": 155, "i_start": 26, "i_end": 26}}], "id": 2336}, {"sent": "dropout is a well-known regularization method that has been used very successfully for feed-forward neural networks .", "tokens": ["dropout", "is", "a", "well", "-", "known", "regularization", "method", "that", "has", "been", "used", "very", "successfully", "for", "feed", "-", "forward", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dropout", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}], "id": 2337}, {"sent": "more conceptually , all finite functorial semi-norms provide obstructions to strong inflexibility and vice versa .", "tokens": ["more", "conceptually", ",", "all", "finite", "functorial", "semi", "-", "norms", "provide", "obstructions", "to", "strong", "inflexibility", "and", "vice", "versa", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "all finite functorial semi-norms", "start": 20, "end": 52, "i_start": 3, "i_end": 8}, "verb": {"text": "provide", "start": 53, "end": 60, "i_start": 9, "i_end": 9}}, {"character": {"text": "norms", "start": 47, "end": 52, "i_start": 8, "i_end": 8}, "action": {"text": "obstructions", "start": 61, "end": 73, "i_start": 10, "i_end": 10}}], "id": 2338}, {"sent": "the context switch , waiting time , turn around time has been calculated and the results were compared .", "tokens": ["the", "context", "switch", ",", "waiting", "time", ",", "turn", "around", "time", "has", "been", "calculated", "and", "the", "results", "were", "compared", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the context switch", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "has been calculated", "start": 53, "end": 72, "i_start": 10, "i_end": 12}}, {"subject": {"text": "the results", "start": 77, "end": 88, "i_start": 14, "i_end": 15}, "verb": {"text": "compared", "start": 94, "end": 102, "i_start": 17, "i_end": 17}}], "id": 2339}, {"sent": "for sobolev spaces complete classifications for valuations intertwining the slwere established .", "tokens": ["for", "sobolev", "spaces", "complete", "classifications", "for", "valuations", "intertwining", "the", "slwere", "established", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "classifications", "start": 28, "end": 43, "i_start": 4, "i_end": 4}, "action": {"text": "intertwining", "start": 59, "end": 71, "i_start": 7, "i_end": 7}}], "id": 2340}, {"sent": "convolutional neural networks have witnessed great improvement on a series of vision tasks such as object classification .", "tokens": ["convolutional", "neural", "networks", "have", "witnessed", "great", "improvement", "on", "a", "series", "of", "vision", "tasks", "such", "as", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have witnessed", "start": 30, "end": 44, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "witnessed", "start": 35, "end": 44, "i_start": 4, "i_end": 4}}], "id": 2341}, {"sent": "we report results on standard image-captioning datasets -flickr-8k , flickr-30k and coco .", "tokens": ["we", "report", "results", "on", "standard", "image", "-", "captioning", "datasets", "-flickr-8k", ",", "flickr-30k", "and", "coco", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "report", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "report", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 2342}, {"sent": "the choice of a suitable splitting mechanism is a long standing problem with many statistical and computational implications .", "tokens": ["the", "choice", "of", "a", "suitable", "splitting", "mechanism", "is", "a", "long", "standing", "problem", "with", "many", "statistical", "and", "computational", "implications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the choice of a suitable splitting mechanism", "start": 0, "end": 44, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 45, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "problem", "start": 64, "end": 71, "i_start": 11, "i_end": 11}, "action": {"text": "implications", "start": 112, "end": 124, "i_start": 17, "i_end": 17}}], "id": 2343}, {"sent": "since then , continuous crf has been successfully applied for solving various structured regression problems , eg , remote sensing .", "tokens": ["since", "then", ",", "continuous", "crf", "has", "been", "successfully", "applied", "for", "solving", "various", "structured", "regression", "problems", ",", "eg", ",", "remote", "sensing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "continuous crf", "start": 13, "end": 27, "i_start": 3, "i_end": 4}, "verb": {"text": "applied", "start": 50, "end": 57, "i_start": 8, "i_end": 8}}, {"subject": {"text": "continuous crf", "start": 13, "end": 27, "i_start": 3, "i_end": 4}, "verb": {"text": "has been", "start": 28, "end": 36, "i_start": 5, "i_end": 6}}], "id": 2344}, {"sent": "we also derive corresponding results for discretetime systems .", "tokens": ["we", "also", "derive", "corresponding", "results", "for", "discretetime", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "derive", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "derive", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}], "id": 2345}, {"sent": "in recent years , deep neural networks have been successfully applied to multiple challenging tasks such as image processing , learning model predictive controllers .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "been", "successfully", "applied", "to", "multiple", "challenging", "tasks", "such", "as", "image", "processing", ",", "learning", "model", "predictive", "controllers", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "applied", "start": 62, "end": 69, "i_start": 10, "i_end": 10}}, {"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have been", "start": 39, "end": 48, "i_start": 7, "i_end": 8}}, {"character": {"text": "tasks", "start": 94, "end": 99, "i_start": 14, "i_end": 14}, "action": {"text": "challenging", "start": 82, "end": 93, "i_start": 13, "i_end": 13}}, {"character": {"text": "model", "start": 136, "end": 141, "i_start": 21, "i_end": 21}, "action": {"text": "predictive", "start": 142, "end": 152, "i_start": 22, "i_end": 22}}], "id": 2346}, {"sent": "the spinning kerr black holes as particle accelerators discussed by the ref , they found that the ultra-energetic collisions can not occur near black holes in nature .", "tokens": ["the", "spinning", "kerr", "black", "holes", "as", "particle", "accelerators", "discussed", "by", "the", "ref", ",", "they", "found", "that", "the", "ultra", "-", "energetic", "collisions", "can", "not", "occur", "near", "black", "holes", "in", "nature", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "they", "start": 78, "end": 82, "i_start": 13, "i_end": 13}, "verb": {"text": "found", "start": 83, "end": 88, "i_start": 14, "i_end": 14}}, {"subject": {"text": "the ultra-energetic collisions", "start": 94, "end": 124, "i_start": 16, "i_end": 20}, "verb": {"text": "occur", "start": 133, "end": 138, "i_start": 23, "i_end": 23}}, {"character": {"text": "they", "start": 78, "end": 82, "i_start": 13, "i_end": 13}, "action": {"text": "found", "start": 83, "end": 88, "i_start": 14, "i_end": 14}}], "id": 2347}, {"sent": "the convolution operation reduces the dimensionality of the data .", "tokens": ["the", "convolution", "operation", "reduces", "the", "dimensionality", "of", "the", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the convolution operation", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "reduces", "start": 26, "end": 33, "i_start": 3, "i_end": 3}}, {"character": {"text": "operation", "start": 16, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "reduces", "start": 26, "end": 33, "i_start": 3, "i_end": 3}}], "id": 2348}, {"sent": "in this section we overview the classification of the weyl tensor in higher dimensions .", "tokens": ["in", "this", "section", "we", "overview", "the", "classification", "of", "the", "weyl", "tensor", "in", "higher", "dimensions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "overview", "start": 19, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "overview", "start": 19, "end": 27, "i_start": 4, "i_end": 4}}], "id": 2349}, {"sent": "recently , cho et al proposed a novel max pooling matching , where they tweak the power method to better cope with noise in the affinities .", "tokens": ["recently", ",", "cho", "et", "al", "proposed", "a", "novel", "max", "pooling", "matching", ",", "where", "they", "tweak", "the", "power", "method", "to", "better", "cope", "with", "noise", "in", "the", "affinities", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "cho et al", "start": 11, "end": 20, "i_start": 2, "i_end": 4}, "verb": {"text": "proposed", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "cho", "start": 11, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "proposed", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "cho", "start": 11, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "tweak", "start": 72, "end": 77, "i_start": 14, "i_end": 14}}, {"character": {"text": "cho", "start": 11, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "cope", "start": 105, "end": 109, "i_start": 20, "i_end": 20}}], "id": 2350}, {"sent": "the lagrangian is a function of fields which are themselves not smooth functions .", "tokens": ["the", "lagrangian", "is", "a", "function", "of", "fields", "which", "are", "themselves", "not", "smooth", "functions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lagrangian", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "fields", "start": 32, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "function", "start": 20, "end": 28, "i_start": 4, "i_end": 4}}], "id": 2351}, {"sent": "chen et al provide a variation of differential privacy which allows for privacy and protection against edge-disclosure attacks in the correlated setting of osns .", "tokens": ["chen", "et", "al", "provide", "a", "variation", "of", "differential", "privacy", "which", "allows", "for", "privacy", "and", "protection", "against", "edge", "-", "disclosure", "attacks", "in", "the", "correlated", "setting", "of", "osns", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "chen et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "provide", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "chen", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "provide", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}], "id": 2352}, {"sent": "particle acceleration in relativistic laser channels .", "tokens": ["particle", "acceleration", "in", "relativistic", "laser", "channels", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2353}, {"sent": "this means that for any universally valid statement on forward or backward-forward bisimulations there is the corresponding universally valid statement on backward and forward-backward bisimulations .", "tokens": ["this", "means", "that", "for", "any", "universally", "valid", "statement", "on", "forward", "or", "backward", "-", "forward", "bisimulations", "there", "is", "the", "corresponding", "universally", "valid", "statement", "on", "backward", "and", "forward", "-", "backward", "bisimulations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "means", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "there", "start": 97, "end": 102, "i_start": 15, "i_end": 15}, "verb": {"text": "is", "start": 103, "end": 105, "i_start": 16, "i_end": 16}}], "id": 2354}, {"sent": "c ognitive radio is a promising technology offering a significant enhancement in wireless systems spectrum efficiency via dynamic spectrum access .", "tokens": ["c", "ognitive", "radio", "is", "a", "promising", "technology", "offering", "a", "significant", "enhancement", "in", "wireless", "systems", "spectrum", "efficiency", "via", "dynamic", "spectrum", "access", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "c ognitive radio", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "technology", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "promising", "start": 22, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "technology", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "offering", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "radio", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "enhancement", "start": 66, "end": 77, "i_start": 10, "i_end": 10}}], "id": 2355}, {"sent": "previous studies have focused primarily on how data of a single modality might be processed in various tasks , eg , music genre classification , music information retrieval , melody extraction , image retrieval , and video classification .", "tokens": ["previous", "studies", "have", "focused", "primarily", "on", "how", "data", "of", "a", "single", "modality", "might", "be", "processed", "in", "various", "tasks", ",", "eg", ",", "music", "genre", "classification", ",", "music", "information", "retrieval", ",", "melody", "extraction", ",", "image", "retrieval", ",", "and", "video", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "previous studies", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "have focused", "start": 17, "end": 29, "i_start": 2, "i_end": 3}}, {"character": {"text": "studies", "start": 9, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "focused", "start": 22, "end": 29, "i_start": 3, "i_end": 3}}], "id": 2356}, {"sent": "the project lasted for three months , and the costs were met by the ngo .", "tokens": ["the", "project", "lasted", "for", "three", "months", ",", "and", "the", "costs", "were", "met", "by", "the", "ngo", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the project", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "lasted", "start": 12, "end": 18, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the costs", "start": 42, "end": 51, "i_start": 8, "i_end": 9}, "verb": {"text": "met", "start": 57, "end": 60, "i_start": 11, "i_end": 11}}], "id": 2357}, {"sent": "this fact is most likely related to the reduction in nanoflake aspect ratio , which was reported to have a detrimental effect on the improvement of nanocomposites thermal conductivity .", "tokens": ["this", "fact", "is", "most", "likely", "related", "to", "the", "reduction", "in", "nanoflake", "aspect", "ratio", ",", "which", "was", "reported", "to", "have", "a", "detrimental", "effect", "on", "the", "improvement", "of", "nanocomposites", "thermal", "conductivity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this fact", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}], "id": 2358}, {"sent": "we evaluate our proposed method on 6 widely used saliency detection benchmarks , including msra-b .", "tokens": ["we", "evaluate", "our", "proposed", "method", "on", "6", "widely", "used", "saliency", "detection", "benchmarks", ",", "including", "msra", "-", "b", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2359}, {"sent": "a spacetime admits a time function iff it admits a temporal function iff it is stably causal .", "tokens": ["a", "spacetime", "admits", "a", "time", "function", "iff", "it", "admits", "a", "temporal", "function", "iff", "it", "is", "stably", "causal", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 73, "end": 75, "i_start": 13, "i_end": 13}, "verb": {"text": "is", "start": 76, "end": 78, "i_start": 14, "i_end": 14}}, {"subject": {"text": "it", "start": 39, "end": 41, "i_start": 7, "i_end": 7}, "verb": {"text": "admits", "start": 42, "end": 48, "i_start": 8, "i_end": 8}}, {"character": {"text": "spacetime", "start": 2, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "admits", "start": 12, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "spacetime", "start": 2, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "function", "start": 26, "end": 34, "i_start": 5, "i_end": 5}}, {"character": {"text": "spacetime", "start": 2, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "admits", "start": 42, "end": 48, "i_start": 8, "i_end": 8}}], "id": 2360}, {"sent": "wallner and dyn showed that the resulting riemannian cubic subdivision scheme yields c 1 curves .", "tokens": ["wallner", "and", "dyn", "showed", "that", "the", "resulting", "riemannian", "cubic", "subdivision", "scheme", "yields", "c", "1", "curves", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "wallner and dyn", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 16, "end": 22, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the resulting riemannian cubic subdivision scheme", "start": 28, "end": 77, "i_start": 5, "i_end": 10}, "verb": {"text": "yields", "start": 78, "end": 84, "i_start": 11, "i_end": 11}}, {"character": {"text": "wallner", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 16, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "dyn", "start": 12, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "showed", "start": 16, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "scheme", "start": 71, "end": 77, "i_start": 10, "i_end": 10}, "action": {"text": "yields", "start": 78, "end": 84, "i_start": 11, "i_end": 11}}], "id": 2361}, {"sent": "for an algorithm running time is the number of steps makes before terminating with an output .", "tokens": ["for", "an", "algorithm", "running", "time", "is", "the", "number", "of", "steps", "makes", "before", "terminating", "with", "an", "output", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the number of steps", "start": 33, "end": 52, "i_start": 6, "i_end": 9}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the number of steps", "start": 33, "end": 52, "i_start": 6, "i_end": 9}, "verb": {"text": "makes", "start": 53, "end": 58, "i_start": 10, "i_end": 10}}], "id": 2362}, {"sent": "zuber , final chorus and nomad results , paper presented at this conference .", "tokens": ["zuber", ",", "final", "chorus", "and", "nomad", "results", ",", "paper", "presented", "at", "this", "conference", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2363}, {"sent": "in addition to mtl , we regularize our model using dropout .", "tokens": ["in", "addition", "to", "mtl", ",", "we", "regularize", "our", "model", "using", "dropout", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 5, "i_end": 5}, "verb": {"text": "regularize", "start": 24, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 5, "i_end": 5}, "action": {"text": "regularize", "start": 24, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 5, "i_end": 5}, "action": {"text": "using", "start": 45, "end": 50, "i_start": 9, "i_end": 9}}], "id": 2364}, {"sent": "malek , on the stokes phenomenon for holomorphic solutions of integro-differential equations with irregular singularity , j .", "tokens": ["malek", ",", "on", "the", "stokes", "phenomenon", "for", "holomorphic", "solutions", "of", "integro", "-", "differential", "equations", "with", "irregular", "singularity", ",", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2365}, {"sent": "re-engineering of old systems to an object-oriented architecture .", "tokens": ["re", "-", "engineering", "of", "old", "systems", "to", "an", "object", "-", "oriented", "architecture", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2366}, {"sent": "in more detail , our embedding model is build on deeplab-v2 backbone architecture .", "tokens": ["in", "more", "detail", ",", "our", "embedding", "model", "is", "build", "on", "deeplab", "-", "v2", "backbone", "architecture", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our embedding model", "start": 17, "end": 36, "i_start": 4, "i_end": 6}, "verb": {"text": "is build", "start": 37, "end": 45, "i_start": 7, "i_end": 8}}], "id": 2367}, {"sent": "let be a vertex operator algebra and g an automorphism of v with finite order t .", "tokens": ["let", "be", "a", "vertex", "operator", "algebra", "and", "g", "an", "automorphism", "of", "v", "with", "finite", "order", "t", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "algebra", "start": 25, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "operator", "start": 16, "end": 24, "i_start": 4, "i_end": 4}}], "id": 2368}, {"sent": "son et al showed that acoustic interference on mems gyroscopes in drones can cause them to crash .", "tokens": ["son", "et", "al", "showed", "that", "acoustic", "interference", "on", "mems", "gyroscopes", "in", "drones", "can", "cause", "them", "to", "crash", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "son et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 10, "end": 16, "i_start": 3, "i_end": 3}}, {"subject": {"text": "acoustic interference on mems gyroscopes in drones", "start": 22, "end": 72, "i_start": 5, "i_end": 11}, "verb": {"text": "cause", "start": 77, "end": 82, "i_start": 13, "i_end": 13}}, {"character": {"text": "interference", "start": 31, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "cause", "start": 77, "end": 82, "i_start": 13, "i_end": 13}}, {"character": {"text": "interference", "start": 31, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "crash", "start": 91, "end": 96, "i_start": 16, "i_end": 16}}], "id": 2369}, {"sent": "in this paper , we propose a fixed point quantization of u-net , a popular segmentation architecture in the medical imaging domain .", "tokens": ["in", "this", "paper", ",", "we", "propose", "a", "fixed", "point", "quantization", "of", "u", "-", "net", ",", "a", "popular", "segmentation", "architecture", "in", "the", "medical", "imaging", "domain", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "propose", "start": 19, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "propose", "start": 19, "end": 26, "i_start": 5, "i_end": 5}}], "id": 2370}, {"sent": "for the purely implicational logic of one variable , the exact value of the density of true formulas was computed by moczurad , tyszkiewicz and zaionc in .", "tokens": ["for", "the", "purely", "implicational", "logic", "of", "one", "variable", ",", "the", "exact", "value", "of", "the", "density", "of", "true", "formulas", "was", "computed", "by", "moczurad", ",", "tyszkiewicz", "and", "zaionc", "in", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "the exact value of the density of true formulas", "start": 53, "end": 100, "i_start": 9, "i_end": 17}, "verb": {"text": "was computed", "start": 101, "end": 113, "i_start": 18, "i_end": 19}}, {"character": {"text": "moczurad", "start": 117, "end": 125, "i_start": 21, "i_end": 21}, "action": {"text": "computed", "start": 105, "end": 113, "i_start": 19, "i_end": 19}}, {"character": {"text": "tyszkiewicz", "start": 128, "end": 139, "i_start": 23, "i_end": 23}, "action": {"text": "computed", "start": 105, "end": 113, "i_start": 19, "i_end": 19}}, {"character": {"text": "zaionc", "start": 144, "end": 150, "i_start": 25, "i_end": 25}, "action": {"text": "computed", "start": 105, "end": 113, "i_start": 19, "i_end": 19}}], "id": 2371}, {"sent": "the arches cluster is the most compact massive star cluster known in our galaxy .", "tokens": ["the", "arches", "cluster", "is", "the", "most", "compact", "massive", "star", "cluster", "known", "in", "our", "galaxy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the arches cluster", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 2372}, {"sent": "it is known that the adjacency tensor of a uniform hypergraph g is weakly irreducible if and only if g is connected .", "tokens": ["it", "is", "known", "that", "the", "adjacency", "tensor", "of", "a", "uniform", "hypergraph", "g", "is", "weakly", "irreducible", "if", "and", "only", "if", "g", "is", "connected", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is known", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 64, "end": 66, "i_start": 12, "i_end": 12}}], "id": 2373}, {"sent": "each convolutional layers are followed by a batch normalization layer and a rectified linear unit .", "tokens": ["each", "convolutional", "layers", "are", "followed", "by", "a", "batch", "normalization", "layer", "and", "a", "rectified", "linear", "unit", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each convolutional layers", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "are followed", "start": 26, "end": 38, "i_start": 3, "i_end": 4}}], "id": 2374}, {"sent": "we employ the glauber approximation for the fsi of the struck nucleon .", "tokens": ["we", "employ", "the", "glauber", "approximation", "for", "the", "fsi", "of", "the", "struck", "nucleon", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "glauber", "start": 14, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "approximation", "start": 22, "end": 35, "i_start": 4, "i_end": 4}}], "id": 2375}, {"sent": "we find that up to and beyond the chiral symmetry restoration density the pressure of the quark fermi sea can be negative indicating its mechanical instability .", "tokens": ["we", "find", "that", "up", "to", "and", "beyond", "the", "chiral", "symmetry", "restoration", "density", "the", "pressure", "of", "the", "quark", "fermi", "sea", "can", "be", "negative", "indicating", "its", "mechanical", "instability", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "be", "start": 110, "end": 112, "i_start": 20, "i_end": 20}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "pressure", "start": 74, "end": 82, "i_start": 13, "i_end": 13}, "action": {"text": "negative", "start": 113, "end": 121, "i_start": 21, "i_end": 21}}, {"character": {"text": "negative", "start": 113, "end": 121, "i_start": 21, "i_end": 21}, "action": {"text": "indicating", "start": 122, "end": 132, "i_start": 22, "i_end": 22}}], "id": 2376}, {"sent": "let jper be the periodic range function of v .", "tokens": ["let", "jper", "be", "the", "periodic", "range", "function", "of", "v", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2377}, {"sent": "the electron-electron interactions are evaluated from the exchange-correlation function under the generalized gradient approximation of perdew-burke-ernzerhof .", "tokens": ["the", "electron", "-", "electron", "interactions", "are", "evaluated", "from", "the", "exchange", "-", "correlation", "function", "under", "the", "generalized", "gradient", "approximation", "of", "perdew", "-", "burke", "-", "ernzerhof", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electron-electron interactions", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "are evaluated", "start": 35, "end": 48, "i_start": 5, "i_end": 6}}, {"character": {"text": "electron", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "interactions", "start": 22, "end": 34, "i_start": 4, "i_end": 4}}], "id": 2378}, {"sent": "in the implementation we utilized a variant of stochastic gradient descent -the adam optimizer .", "tokens": ["in", "the", "implementation", "we", "utilized", "a", "variant", "of", "stochastic", "gradient", "descent", "-the", "adam", "optimizer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 22, "end": 24, "i_start": 3, "i_end": 3}, "verb": {"text": "utilized", "start": 25, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "utilized", "start": 25, "end": 33, "i_start": 4, "i_end": 4}}], "id": 2379}, {"sent": "the authors would like to thank the referee for their constructive suggestions .", "tokens": ["the", "authors", "would", "like", "to", "thank", "the", "referee", "for", "their", "constructive", "suggestions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "would like", "start": 12, "end": 22, "i_start": 2, "i_end": 3}}], "id": 2380}, {"sent": "lem me de comparaison des p-modules quasi-libres analytiques .", "tokens": ["lem", "me", "de", "comparaison", "des", "p", "-", "modules", "quasi", "-", "libres", "analytiques", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2381}, {"sent": "that the graphene flake itself is a conductor that effectively shields the field produced by .", "tokens": ["that", "the", "graphene", "flake", "itself", "is", "a", "conductor", "that", "effectively", "shields", "the", "field", "produced", "by", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the graphene flake itself", "start": 5, "end": 30, "i_start": 1, "i_end": 4}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "flake", "start": 18, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "produced", "start": 81, "end": 89, "i_start": 13, "i_end": 13}}], "id": 2382}, {"sent": "over-dots here denote differentiation with respect to proper time on the brane , t .", "tokens": ["over", "-", "dots", "here", "denote", "differentiation", "with", "respect", "to", "proper", "time", "on", "the", "brane", ",", "t", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "dots", "start": 5, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "denote", "start": 15, "end": 21, "i_start": 4, "i_end": 4}}], "id": 2383}, {"sent": "duality is a general concept relating physical quantities in different regions of the parameter space .", "tokens": ["duality", "is", "a", "general", "concept", "relating", "physical", "quantities", "in", "different", "regions", "of", "the", "parameter", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "duality", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "concept", "start": 21, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "relating", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}], "id": 2384}, {"sent": "we initialise the weight matrices using he uniform initialisation .", "tokens": ["we", "initialise", "the", "weight", "matrices", "using", "he", "uniform", "initialisation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "initialise", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "initialise", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}], "id": 2385}, {"sent": "ordinate is the real part and abscissa is the imaginary part .", "tokens": ["ordinate", "is", "the", "real", "part", "and", "abscissa", "is", "the", "imaginary", "part", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "ordinate", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2386}, {"sent": "many nbv methods are heuristic , relying on holes , open boundaries , or point densities to find nbvs .", "tokens": ["many", "nbv", "methods", "are", "heuristic", ",", "relying", "on", "holes", ",", "open", "boundaries", ",", "or", "point", "densities", "to", "find", "nbvs", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "many nbv methods", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 17, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "methods", "start": 9, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "relying", "start": 33, "end": 40, "i_start": 6, "i_end": 6}}], "id": 2387}, {"sent": "assume that property li holds for all simple lie algebras of rank at most l .", "tokens": ["assume", "that", "property", "li", "holds", "for", "all", "simple", "lie", "algebras", "of", "rank", "at", "most", "l", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "property li", "start": 12, "end": 23, "i_start": 2, "i_end": 3}, "verb": {"text": "assume", "start": 0, "end": 6, "i_start": 0, "i_end": 0}}, {"subject": {"text": "property li", "start": 12, "end": 23, "i_start": 2, "i_end": 3}, "verb": {"text": "holds", "start": 24, "end": 29, "i_start": 4, "i_end": 4}}], "id": 2388}, {"sent": "the exact expressions of the eigenvalues , mixing angles , and the oscillation probabilities have been obtained , albeit under the assumption of uniform matter density .", "tokens": ["the", "exact", "expressions", "of", "the", "eigenvalues", ",", "mixing", "angles", ",", "and", "the", "oscillation", "probabilities", "have", "been", "obtained", ",", "albeit", "under", "the", "assumption", "of", "uniform", "matter", "density", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2389}, {"sent": "deep convolutional neural networks have achieved huge success in solving problems related to computer vision , such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "huge", "success", "in", "solving", "problems", "related", "to", "computer", "vision", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 54, "end": 61, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "solving", "start": 65, "end": 72, "i_start": 9, "i_end": 9}}], "id": 2390}, {"sent": "this instability is a generic problem of any gb system containing a negative tension brane .", "tokens": ["this", "instability", "is", "a", "generic", "problem", "of", "any", "gb", "system", "containing", "a", "negative", "tension", "brane", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this instability", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "system", "start": 48, "end": 54, "i_start": 9, "i_end": 9}, "action": {"text": "containing", "start": 55, "end": 65, "i_start": 10, "i_end": 10}}, {"character": {"text": "tension", "start": 77, "end": 84, "i_start": 13, "i_end": 13}, "action": {"text": "negative", "start": 68, "end": 76, "i_start": 12, "i_end": 12}}], "id": 2391}, {"sent": "lattice qcd is a genuine non-perturbative method which can handle hadron-hadron scattering at low-energies .", "tokens": ["lattice", "qcd", "is", "a", "genuine", "non", "-", "perturbative", "method", "which", "can", "handle", "hadron", "-", "hadron", "scattering", "at", "low", "-", "energies", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "lattice qcd", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "method", "start": 42, "end": 48, "i_start": 8, "i_end": 8}, "action": {"text": "-", "start": 28, "end": 29, "i_start": 6, "i_end": 6}}, {"character": {"text": "method", "start": 42, "end": 48, "i_start": 8, "i_end": 8}, "action": {"text": "handle", "start": 59, "end": 65, "i_start": 11, "i_end": 11}}, {"character": {"text": "hadron", "start": 66, "end": 72, "i_start": 12, "i_end": 12}, "action": {"text": "scattering", "start": 80, "end": 90, "i_start": 15, "i_end": 15}}, {"character": {"text": "hadron", "start": 73, "end": 79, "i_start": 14, "i_end": 14}, "action": {"text": "scattering", "start": 80, "end": 90, "i_start": 15, "i_end": 15}}], "id": 2392}, {"sent": "normalization techniques such as batch normalization are indispensable components in deep neural networks .", "tokens": ["normalization", "techniques", "such", "as", "batch", "normalization", "are", "indispensable", "components", "in", "deep", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "normalization techniques such as batch normalization", "start": 0, "end": 52, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 53, "end": 56, "i_start": 6, "i_end": 6}}], "id": 2393}, {"sent": "an approach to deriving global authorizations in feder ated database systems .", "tokens": ["an", "approach", "to", "deriving", "global", "authorizations", "in", "feder", "ated", "database", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an approach to deriving global authorizations in feder", "start": 0, "end": 54, "i_start": 0, "i_end": 7}, "verb": {"text": "ated", "start": 55, "end": 59, "i_start": 8, "i_end": 8}}], "id": 2394}, {"sent": "massive mimo is considered as a promising technique in 5g communication systems , which has a potential of increasing spectral and energy efficiency significantly with simple signal processing .", "tokens": ["massive", "mimo", "is", "considered", "as", "a", "promising", "technique", "in", "5", "g", "communication", "systems", ",", "which", "has", "a", "potential", "of", "increasing", "spectral", "and", "energy", "efficiency", "significantly", "with", "simple", "signal", "processing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "massive mimo", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is considered", "start": 13, "end": 26, "i_start": 2, "i_end": 3}}, {"character": {"text": "mimo", "start": 8, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "promising", "start": 32, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "technique", "start": 42, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "increasing", "start": 107, "end": 117, "i_start": 19, "i_end": 19}}], "id": 2395}, {"sent": "polyhedron p itself is the image of a hyperbolic-de sitter polyhedron p hds .", "tokens": ["polyhedron", "p", "itself", "is", "the", "image", "of", "a", "hyperbolic", "-", "de", "sitter", "polyhedron", "p", "hds", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "polyhedron p itself", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 2396}, {"sent": "since string theory is a consistent theory of quantum gravity , we can study strings on black hole backgrounds that are asymptotically ads to try and realize that hope .", "tokens": ["since", "string", "theory", "is", "a", "consistent", "theory", "of", "quantum", "gravity", ",", "we", "can", "study", "strings", "on", "black", "hole", "backgrounds", "that", "are", "asymptotically", "ads", "to", "try", "and", "realize", "that", "hope", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 64, "end": 66, "i_start": 11, "i_end": 11}, "verb": {"text": "can study", "start": 67, "end": 76, "i_start": 12, "i_end": 13}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "study", "start": 71, "end": 76, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "try", "start": 142, "end": 145, "i_start": 24, "i_end": 24}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "realize", "start": 150, "end": 157, "i_start": 26, "i_end": 26}}], "id": 2397}, {"sent": "the quoted uncertainty is the standard deviation of the results when 1 .", "tokens": ["the", "quoted", "uncertainty", "is", "the", "standard", "deviation", "of", "the", "results", "when", "1", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quoted uncertainty", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}], "id": 2398}, {"sent": "convolutional neural networks have achieved great success in many computer vision tasks recently , eg , image classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "many", "computer", "vision", "tasks", "recently", ",", "eg", ",", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}], "id": 2399}, {"sent": "for the task specifications , we concatenate the word embeddings of the attributes and objects with word2vec trained with googlenews .", "tokens": ["for", "the", "task", "specifications", ",", "we", "concatenate", "the", "word", "embeddings", "of", "the", "attributes", "and", "objects", "with", "word2vec", "trained", "with", "googlenews", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "verb": {"text": "concatenate", "start": 33, "end": 44, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "concatenate", "start": 33, "end": 44, "i_start": 6, "i_end": 6}}], "id": 2400}, {"sent": "the operator of total angular momentum lel about the z-axis is denoted by lt ot with lt ot lel hamiltonian h .", "tokens": ["the", "operator", "of", "total", "angular", "momentum", "lel", "about", "the", "z", "-", "axis", "is", "denoted", "by", "lt", "ot", "with", "lt", "ot", "lel", "hamiltonian", "h", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the operator of total angular momentum lel about the z-axis", "start": 0, "end": 59, "i_start": 0, "i_end": 11}, "verb": {"text": "is denoted", "start": 60, "end": 70, "i_start": 12, "i_end": 13}}], "id": 2401}, {"sent": "where the curves are truncated the system becomes antiferromagnetic .", "tokens": ["where", "the", "curves", "are", "truncated", "the", "system", "becomes", "antiferromagnetic", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the system", "start": 31, "end": 41, "i_start": 5, "i_end": 6}, "verb": {"text": "becomes", "start": 42, "end": 49, "i_start": 7, "i_end": 7}}], "id": 2402}, {"sent": "recent advancement in deep feature learning has revealed that features extracted from upper or intermediate layers of a cnn are generic features that have good transfer learning capabilities across different domains .", "tokens": ["recent", "advancement", "in", "deep", "feature", "learning", "has", "revealed", "that", "features", "extracted", "from", "upper", "or", "intermediate", "layers", "of", "a", "cnn", "are", "generic", "features", "that", "have", "good", "transfer", "learning", "capabilities", "across", "different", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent advancement in deep feature learning", "start": 0, "end": 43, "i_start": 0, "i_end": 5}, "verb": {"text": "has revealed", "start": 44, "end": 56, "i_start": 6, "i_end": 7}}, {"subject": {"text": "recent advancement in deep feature learning", "start": 0, "end": 43, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 124, "end": 127, "i_start": 19, "i_end": 19}}, {"character": {"text": "advancement", "start": 7, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "revealed", "start": 48, "end": 56, "i_start": 7, "i_end": 7}}], "id": 2403}, {"sent": "a permutation is a word without repetition on an initial interval of the alphabet .", "tokens": ["a", "permutation", "is", "a", "word", "without", "repetition", "on", "an", "initial", "interval", "of", "the", "alphabet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a permutation", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 2404}, {"sent": "linear quantum stochastic systems are a class of models used in linear quantum optics , and elsewhere .", "tokens": ["linear", "quantum", "stochastic", "systems", "are", "a", "class", "of", "models", "used", "in", "linear", "quantum", "optics", ",", "and", "elsewhere", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "linear quantum stochastic systems", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 34, "end": 37, "i_start": 4, "i_end": 4}}], "id": 2405}, {"sent": "convolutional neural networks have achieved state-of-the-art performance on the object detection task .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "the", "object", "detection", "task", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 61, "end": 72, "i_start": 12, "i_end": 12}}], "id": 2406}, {"sent": "we use a unidirectional recurrent network with 1028 gated recurrent units , as an encoder .", "tokens": ["we", "use", "a", "unidirectional", "recurrent", "network", "with", "1028", "gated", "recurrent", "units", ",", "as", "an", "encoder", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 2407}, {"sent": "the bound states are shown to enhance the transmission of multiphoton states and suppress the transmission of single-photon states .", "tokens": ["the", "bound", "states", "are", "shown", "to", "enhance", "the", "transmission", "of", "multiphoton", "states", "and", "suppress", "the", "transmission", "of", "single", "-", "photon", "states", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the bound states", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "are shown", "start": 17, "end": 26, "i_start": 3, "i_end": 4}}, {"character": {"text": "states", "start": 10, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "enhance", "start": 30, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "states", "start": 10, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "suppress", "start": 81, "end": 89, "i_start": 13, "i_end": 13}}], "id": 2408}, {"sent": "in 2005 , important progress made by bianchini-bressan justifies the vanishing viscosity limit in bv-space even though the problem is still unsolved for the physical system such as the compressible navierstokes equations .", "tokens": ["in", "2005", ",", "important", "progress", "made", "by", "bianchini", "-", "bressan", "justifies", "the", "vanishing", "viscosity", "limit", "in", "bv", "-", "space", "even", "though", "the", "problem", "is", "still", "unsolved", "for", "the", "physical", "system", "such", "as", "the", "compressible", "navierstokes", "equations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "important progress made by bianchini-bressan", "start": 10, "end": 54, "i_start": 3, "i_end": 9}, "verb": {"text": "justifies", "start": 55, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "progress", "start": 20, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "justifies", "start": 55, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "bianchini", "start": 37, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "made", "start": 29, "end": 33, "i_start": 5, "i_end": 5}}], "id": 2409}, {"sent": "in addition , multi-task learning is known to reduce the risk of overfitting .", "tokens": ["in", "addition", ",", "multi", "-", "task", "learning", "is", "known", "to", "reduce", "the", "risk", "of", "overfitting", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "multi-task learning", "start": 14, "end": 33, "i_start": 3, "i_end": 6}, "verb": {"text": "is known", "start": 34, "end": 42, "i_start": 7, "i_end": 8}}, {"character": {"text": "learning", "start": 25, "end": 33, "i_start": 6, "i_end": 6}, "action": {"text": "reduce", "start": 46, "end": 52, "i_start": 10, "i_end": 10}}], "id": 2410}, {"sent": "deep convolutional neural networks have achieved great success in object classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "classification", "start": 73, "end": 87, "i_start": 10, "i_end": 10}}], "id": 2411}, {"sent": "an episode consists of a packet finding its way from an originating source to its prescribed destination .", "tokens": ["an", "episode", "consists", "of", "a", "packet", "finding", "its", "way", "from", "an", "originating", "source", "to", "its", "prescribed", "destination", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an episode", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "packet", "start": 25, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "finding", "start": 32, "end": 39, "i_start": 6, "i_end": 6}}], "id": 2412}, {"sent": "deep neural networks have demonstrated significant performance improvements in a wide range of computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "significant", "performance", "improvements", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improvements", "start": 63, "end": 75, "i_start": 7, "i_end": 7}}], "id": 2413}, {"sent": "the most studied cases were spin waves in long-wave approximation corresponding to rotating and pulsating strings in certain limits , see for instance reviews and references therein .", "tokens": ["the", "most", "studied", "cases", "were", "spin", "waves", "in", "long", "-", "wave", "approximation", "corresponding", "to", "rotating", "and", "pulsating", "strings", "in", "certain", "limits", ",", "see", "for", "instance", "reviews", "and", "references", "therein", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most studied cases", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "were", "start": 23, "end": 27, "i_start": 4, "i_end": 4}}], "id": 2414}, {"sent": "in joint work with ueno , we have given a proof , based mainly on the results of , that the tuy-construction of the wzw-conformal field theory after twist by a fractional power of an abelian theory , satisfies all the axioms of a modular functor .", "tokens": ["in", "joint", "work", "with", "ueno", ",", "we", "have", "given", "a", "proof", ",", "based", "mainly", "on", "the", "results", "of", ",", "that", "the", "tuy", "-", "construction", "of", "the", "wzw", "-", "conformal", "field", "theory", "after", "twist", "by", "a", "fractional", "power", "of", "an", "abelian", "theory", ",", "satisfies", "all", "the", "axioms", "of", "a", "modular", "functor", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 26, "end": 28, "i_start": 6, "i_end": 6}, "verb": {"text": "have given", "start": 29, "end": 39, "i_start": 7, "i_end": 8}}, {"character": {"text": "construction", "start": 96, "end": 108, "i_start": 23, "i_end": 23}, "action": {"text": "satisfies", "start": 200, "end": 209, "i_start": 42, "i_end": 42}}, {"character": {"text": "power", "start": 171, "end": 176, "i_start": 36, "i_end": 36}, "action": {"text": "twist", "start": 149, "end": 154, "i_start": 32, "i_end": 32}}], "id": 2415}, {"sent": "the case of section rings of line bundles has been been considered by hyry and smith in connection with a conjecture by kawamata .", "tokens": ["the", "case", "of", "section", "rings", "of", "line", "bundles", "has", "been", "been", "considered", "by", "hyry", "and", "smith", "in", "connection", "with", "a", "conjecture", "by", "kawamata", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the case of section rings of line bundles", "start": 0, "end": 41, "i_start": 0, "i_end": 7}, "verb": {"text": "has been been considered", "start": 42, "end": 66, "i_start": 8, "i_end": 11}}, {"character": {"text": "hyry", "start": 70, "end": 74, "i_start": 13, "i_end": 13}, "action": {"text": "considered", "start": 56, "end": 66, "i_start": 11, "i_end": 11}}, {"character": {"text": "smith", "start": 79, "end": 84, "i_start": 15, "i_end": 15}, "action": {"text": "considered", "start": 56, "end": 66, "i_start": 11, "i_end": 11}}, {"character": {"text": "kawamata", "start": 120, "end": 128, "i_start": 22, "i_end": 22}, "action": {"text": "conjecture", "start": 106, "end": 116, "i_start": 20, "i_end": 20}}], "id": 2416}, {"sent": "the tevatron is a pp collider with a center of mass energy of 1800 gev and the lhc is a pp collider under 14 construction with a planned center of mass energy of 14000 gev .", "tokens": ["the", "tevatron", "is", "a", "pp", "collider", "with", "a", "center", "of", "mass", "energy", "of", "1800", "gev", "and", "the", "lhc", "is", "a", "pp", "collider", "under", "14", "construction", "with", "a", "planned", "center", "of", "mass", "energy", "of", "14000", "gev", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the tevatron", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 2417}, {"sent": "in early studies , eg , the principle of physical layer security was established in a single-input single-output wiretap channel .", "tokens": ["in", "early", "studies", ",", "eg", ",", "the", "principle", "of", "physical", "layer", "security", "was", "established", "in", "a", "single", "-", "input", "single", "-", "output", "wiretap", "channel", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "eg , the principle of physical layer security", "start": 19, "end": 64, "i_start": 4, "i_end": 11}, "verb": {"text": "was established", "start": 65, "end": 80, "i_start": 12, "i_end": 13}}], "id": 2418}, {"sent": "we refer to for a more detailed discussion on catmetric spaces .", "tokens": ["we", "refer", "to", "for", "a", "more", "detailed", "discussion", "on", "catmetric", "spaces", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2419}, {"sent": "thus , there is considerable interest in elucidating the origin and form of common structural features of networks .", "tokens": ["thus", ",", "there", "is", "considerable", "interest", "in", "elucidating", "the", "origin", "and", "form", "of", "common", "structural", "features", "of", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 7, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 3, "i_end": 3}}], "id": 2420}, {"sent": "the system under investigation here consists of a vortex line trapped by a zigzag of very large pinning centers , namely , spherical insulating cavities , with radius taken to vary from 0 point 2\u03be to 3 point 0\u03be .", "tokens": ["the", "system", "under", "investigation", "here", "consists", "of", "a", "vortex", "line", "trapped", "by", "a", "zigzag", "of", "very", "large", "pinning", "centers", ",", "namely", ",", "spherical", "insulating", "cavities", ",", "with", "radius", "taken", "to", "vary", "from", "0", "point", "2\u03be", "to", "3", "point", "0\u03be", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the system under investigation here", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "consists", "start": 36, "end": 44, "i_start": 5, "i_end": 5}}, {"character": {"text": "zigzag", "start": 75, "end": 81, "i_start": 13, "i_end": 13}, "action": {"text": "trapped", "start": 62, "end": 69, "i_start": 10, "i_end": 10}}], "id": 2421}, {"sent": "deep neural networks show very high performance in various fields such as speech recognition .", "tokens": ["deep", "neural", "networks", "show", "very", "high", "performance", "in", "various", "fields", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "show", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 36, "end": 47, "i_start": 6, "i_end": 6}}], "id": 2422}, {"sent": "recently , convolutional neural networks -based methods achieve great success in image classification tasks .", "tokens": ["recently", ",", "convolutional", "neural", "networks", "-based", "methods", "achieve", "great", "success", "in", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks -based methods", "start": 11, "end": 55, "i_start": 2, "i_end": 6}, "verb": {"text": "achieve", "start": 56, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "methods", "start": 48, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "achieve", "start": 56, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "methods", "start": 48, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 70, "end": 77, "i_start": 9, "i_end": 9}}], "id": 2423}, {"sent": "he et al generalize matrix factorization and factorization machines for neural collaborative filtering .", "tokens": ["he", "et", "al", "generalize", "matrix", "factorization", "and", "factorization", "machines", "for", "neural", "collaborative", "filtering", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "he", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "generalize", "start": 9, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "he", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "generalize", "start": 9, "end": 19, "i_start": 3, "i_end": 3}}], "id": 2424}, {"sent": "deep learning using convolutional neural networks has achieved excellent performance for a wide range of tasks , such as image recognition .", "tokens": ["deep", "learning", "using", "convolutional", "neural", "networks", "has", "achieved", "excellent", "performance", "for", "a", "wide", "range", "of", "tasks", ",", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning using convolutional neural networks", "start": 0, "end": 49, "i_start": 0, "i_end": 5}, "verb": {"text": "has achieved", "start": 50, "end": 62, "i_start": 6, "i_end": 7}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "achieved", "start": 54, "end": 62, "i_start": 7, "i_end": 7}}], "id": 2425}, {"sent": "it is also shown that the residue calculus for the pade approximated functions can be used to confirm the numerical accuracy of the pade approximation and quasianalyticity of the random power series .", "tokens": ["it", "is", "also", "shown", "that", "the", "residue", "calculus", "for", "the", "pade", "approximated", "functions", "can", "be", "used", "to", "confirm", "the", "numerical", "accuracy", "of", "the", "pade", "approximation", "and", "quasianalyticity", "of", "the", "random", "power", "series", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the residue calculus for the pade approximated functions", "start": 22, "end": 78, "i_start": 5, "i_end": 12}, "verb": {"text": "shown", "start": 11, "end": 16, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 86, "end": 90, "i_start": 15, "i_end": 15}}, {"character": {"text": "calculus", "start": 34, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "confirm", "start": 94, "end": 101, "i_start": 17, "i_end": 17}}], "id": 2426}, {"sent": "the third equality follows from the chain rule for quantum mutual information .", "tokens": ["the", "third", "equality", "follows", "from", "the", "chain", "rule", "for", "quantum", "mutual", "information", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the third equality", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "follows", "start": 19, "end": 26, "i_start": 3, "i_end": 3}}], "id": 2427}, {"sent": "in this part , we compare \u03b4-togl with other classical dictionary-based learning schemes such as the pure greedy learning pgl .", "tokens": ["in", "this", "part", ",", "we", "compare", "\u03b4", "-", "togl", "with", "other", "classical", "dictionary", "-", "based", "learning", "schemes", "such", "as", "the", "pure", "greedy", "learning", "pgl", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "compare", "start": 18, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "compare", "start": 18, "end": 25, "i_start": 5, "i_end": 5}}], "id": 2428}, {"sent": "to optimize this objective function , we employ the stochastic gradient descent with diagonal variant of adagrad in .", "tokens": ["to", "optimize", "this", "objective", "function", ",", "we", "employ", "the", "stochastic", "gradient", "descent", "with", "diagonal", "variant", "of", "adagrad", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 38, "end": 40, "i_start": 6, "i_end": 6}, "verb": {"text": "employ", "start": 41, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 38, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "employ", "start": 41, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 38, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "optimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2429}, {"sent": "in , subband assignment and power allocation are done in two separate stages .", "tokens": ["in", ",", "subband", "assignment", "and", "power", "allocation", "are", "done", "in", "two", "separate", "stages", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "subband assignment and power allocation", "start": 5, "end": 44, "i_start": 2, "i_end": 6}, "verb": {"text": "are done", "start": 45, "end": 53, "i_start": 7, "i_end": 8}}], "id": 2430}, {"sent": "the unique topological nature of dirac and weyl semimetals indicates novel properties such as fermi arc states on their surface .", "tokens": ["the", "unique", "topological", "nature", "of", "dirac", "and", "weyl", "semimetals", "indicates", "novel", "properties", "such", "as", "fermi", "arc", "states", "on", "their", "surface", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the unique topological nature of dirac and weyl semimetals", "start": 0, "end": 58, "i_start": 0, "i_end": 8}, "verb": {"text": "indicates", "start": 59, "end": 68, "i_start": 9, "i_end": 9}}, {"character": {"text": "nature", "start": 23, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "indicates", "start": 59, "end": 68, "i_start": 9, "i_end": 9}}], "id": 2431}, {"sent": "the specific feature here is a variable coefficient for the new bulk viscosity form proposed , characterized by two free parameters that can be best fitted by astrophysics observational data sets .", "tokens": ["the", "specific", "feature", "here", "is", "a", "variable", "coefficient", "for", "the", "new", "bulk", "viscosity", "form", "proposed", ",", "characterized", "by", "two", "free", "parameters", "that", "can", "be", "best", "fitted", "by", "astrophysics", "observational", "data", "sets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the specific feature here", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "sets", "start": 191, "end": 195, "i_start": 30, "i_end": 30}, "action": {"text": "fitted", "start": 149, "end": 155, "i_start": 25, "i_end": 25}}], "id": 2432}, {"sent": "following the design study methodology , reflection is the third contribution to a design study for the improvement of current guidelines .", "tokens": ["following", "the", "design", "study", "methodology", ",", "reflection", "is", "the", "third", "contribution", "to", "a", "design", "study", "for", "the", "improvement", "of", "current", "guidelines", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "reflection", "start": 41, "end": 51, "i_start": 6, "i_end": 6}, "verb": {"text": "is", "start": 52, "end": 54, "i_start": 7, "i_end": 7}}, {"character": {"text": "reflection", "start": 41, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "contribution", "start": 65, "end": 77, "i_start": 10, "i_end": 10}}], "id": 2433}, {"sent": "we compare our approach denoted as banet with 16 state-of-the-art methods , including ksr .", "tokens": ["we", "compare", "our", "approach", "denoted", "as", "banet", "with", "16", "state", "-", "of", "-", "the", "-", "art", "methods", ",", "including", "ksr", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "approach", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 2434}, {"sent": "the expectation-maximization algorithm provides a good starting point for this problem .", "tokens": ["the", "expectation", "-", "maximization", "algorithm", "provides", "a", "good", "starting", "point", "for", "this", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the expectation-maximization algorithm", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "provides", "start": 39, "end": 47, "i_start": 5, "i_end": 5}}, {"character": {"text": "algorithm", "start": 29, "end": 38, "i_start": 4, "i_end": 4}, "action": {"text": "provides", "start": 39, "end": 47, "i_start": 5, "i_end": 5}}], "id": 2435}, {"sent": "we call legendrian submanifolds with this property chord generic .", "tokens": ["we", "call", "legendrian", "submanifolds", "with", "this", "property", "chord", "generic", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "call", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "call", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 2436}, {"sent": "the commutation relations of these generators are completely fixed by imposing jacobi identities .", "tokens": ["the", "commutation", "relations", "of", "these", "generators", "are", "completely", "fixed", "by", "imposing", "jacobi", "identities", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the commutation relations of these generators", "start": 0, "end": 45, "i_start": 0, "i_end": 5}, "verb": {"text": "fixed", "start": 61, "end": 66, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the commutation relations of these generators", "start": 0, "end": 45, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 46, "end": 49, "i_start": 6, "i_end": 6}}], "id": 2437}, {"sent": "performance comparison of lg-lstm with a variety of cnn models on three public datasets show high test scores .", "tokens": ["performance", "comparison", "of", "lg", "-", "lstm", "with", "a", "variety", "of", "cnn", "models", "on", "three", "public", "datasets", "show", "high", "test", "scores", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "performance comparison of lg-lstm with a variety of cnn models on three public datasets", "start": 0, "end": 87, "i_start": 0, "i_end": 15}, "verb": {"text": "show", "start": 88, "end": 92, "i_start": 16, "i_end": 16}}, {"character": {"text": "comparison", "start": 12, "end": 22, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 88, "end": 92, "i_start": 16, "i_end": 16}}], "id": 2438}, {"sent": "in , universality was proven for wigner matrices whose entries have a sufficiently regular law .", "tokens": ["in", ",", "universality", "was", "proven", "for", "wigner", "matrices", "whose", "entries", "have", "a", "sufficiently", "regular", "law", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "universality", "start": 5, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "was proven", "start": 18, "end": 28, "i_start": 3, "i_end": 4}}], "id": 2439}, {"sent": "success of convolutional neural networks over the past several years has lead to their extensive deployment in a wide range of computer vision tasks .", "tokens": ["success", "of", "convolutional", "neural", "networks", "over", "the", "past", "several", "years", "has", "lead", "to", "their", "extensive", "deployment", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "success of convolutional neural networks over the past several years", "start": 0, "end": 68, "i_start": 0, "i_end": 9}, "verb": {"text": "has lead", "start": 69, "end": 77, "i_start": 10, "i_end": 11}}, {"character": {"text": "success", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "lead", "start": 73, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "success", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}], "id": 2440}, {"sent": "in , juditsky et al developed a stochastic mirror-prox method to solve stochastic vis with monotone operators .", "tokens": ["in", ",", "juditsky", "et", "al", "developed", "a", "stochastic", "mirror", "-", "prox", "method", "to", "solve", "stochastic", "vis", "with", "monotone", "operators", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "juditsky et al", "start": 5, "end": 19, "i_start": 2, "i_end": 4}, "verb": {"text": "developed", "start": 20, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "juditsky", "start": 5, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "developed", "start": 20, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "juditsky", "start": 5, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "solve", "start": 65, "end": 70, "i_start": 13, "i_end": 13}}], "id": 2441}, {"sent": "with the success of deep learning , convolutional neural network has been applied successfully in this domain .", "tokens": ["with", "the", "success", "of", "deep", "learning", ",", "convolutional", "neural", "network", "has", "been", "applied", "successfully", "in", "this", "domain", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural network", "start": 36, "end": 64, "i_start": 7, "i_end": 9}, "verb": {"text": "has been applied", "start": 65, "end": 81, "i_start": 10, "i_end": 12}}, {"character": {"text": "learning", "start": 25, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "successfully", "start": 82, "end": 94, "i_start": 13, "i_end": 13}}], "id": 2442}, {"sent": "more recently , sinha et al propose a method to generate the surface of an object using a representation based on geometry images .", "tokens": ["more", "recently", ",", "sinha", "et", "al", "propose", "a", "method", "to", "generate", "the", "surface", "of", "an", "object", "using", "a", "representation", "based", "on", "geometry", "images", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 22, "end": 27, "i_start": 4, "i_end": 5}, "verb": {"text": "propose", "start": 28, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "sinha", "start": 16, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "propose", "start": 28, "end": 35, "i_start": 6, "i_end": 6}}], "id": 2443}, {"sent": "deep learning technology has been widely adopted in various ai tasks and has achieved the state-of-the-art performance .", "tokens": ["deep", "learning", "technology", "has", "been", "widely", "adopted", "in", "various", "ai", "tasks", "and", "has", "achieved", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning technology", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "adopted", "start": 41, "end": 48, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep learning technology", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "has been", "start": 25, "end": 33, "i_start": 3, "i_end": 4}}, {"subject": {"text": "deep learning technology", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 77, "end": 85, "i_start": 13, "i_end": 13}}, {"character": {"text": "technology", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 77, "end": 85, "i_start": 13, "i_end": 13}}], "id": 2444}, {"sent": "let us discuss the possible interpretation of this bound state in the bulk .", "tokens": ["let", "us", "discuss", "the", "possible", "interpretation", "of", "this", "bound", "state", "in", "the", "bulk", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "discuss", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "discuss", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}], "id": 2445}, {"sent": "at low temperatures , particles in a gas can reside in the same quantum state , forming a bose-einstein condensate .", "tokens": ["at", "low", "temperatures", ",", "particles", "in", "a", "gas", "can", "reside", "in", "the", "same", "quantum", "state", ",", "forming", "a", "bose", "-", "einstein", "condensate", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "particles in a gas", "start": 22, "end": 40, "i_start": 4, "i_end": 7}, "verb": {"text": "can reside", "start": 41, "end": 51, "i_start": 8, "i_end": 9}}, {"character": {"text": "particles", "start": 22, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "reside", "start": 45, "end": 51, "i_start": 9, "i_end": 9}}], "id": 2446}, {"sent": "greedyfuture only touches nodes on the search path , and then rearranges the search path in order to greedily minimize the time for upcoming searches .", "tokens": ["greedyfuture", "only", "touches", "nodes", "on", "the", "search", "path", ",", "and", "then", "rearranges", "the", "search", "path", "in", "order", "to", "greedily", "minimize", "the", "time", "for", "upcoming", "searches", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "greedyfuture", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "touches", "start": 18, "end": 25, "i_start": 2, "i_end": 2}}, {"subject": {"text": "greedyfuture", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "rearranges", "start": 62, "end": 72, "i_start": 11, "i_end": 11}}], "id": 2447}, {"sent": "this last conclusion implies what is asserted in proposition a .", "tokens": ["this", "last", "conclusion", "implies", "what", "is", "asserted", "in", "proposition", "a", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this last conclusion", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "implies", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"subject": {"text": "what", "start": 29, "end": 33, "i_start": 4, "i_end": 4}, "verb": {"text": "asserted", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}], "id": 2448}, {"sent": "most of such pulsars are located on the lower left part of the diagram .", "tokens": ["most", "of", "such", "pulsars", "are", "located", "on", "the", "lower", "left", "part", "of", "the", "diagram", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "most of such pulsars", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "are located", "start": 21, "end": 32, "i_start": 4, "i_end": 5}}], "id": 2449}, {"sent": "the gravitational field is a power-law function of the extra coordinate , y .", "tokens": ["the", "gravitational", "field", "is", "a", "power", "-", "law", "function", "of", "the", "extra", "coordinate", ",", "y", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the gravitational field", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "coordinate", "start": 61, "end": 71, "i_start": 12, "i_end": 12}, "action": {"text": "function", "start": 39, "end": 47, "i_start": 8, "i_end": 8}}], "id": 2450}, {"sent": "indeed , we show that follow the perturbed leader algorithm arises in this way .", "tokens": ["indeed", ",", "we", "show", "that", "follow", "the", "perturbed", "leader", "algorithm", "arises", "in", "this", "way", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "verb": {"text": "show", "start": 12, "end": 16, "i_start": 3, "i_end": 3}}, {"subject": {"text": "that", "start": 17, "end": 21, "i_start": 4, "i_end": 4}, "verb": {"text": "follow", "start": 22, "end": 28, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "verb": {"text": "arises", "start": 60, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 12, "end": 16, "i_start": 3, "i_end": 3}}], "id": 2451}, {"sent": "there is a maximal open set u is called maximal is a diffeomorphism .", "tokens": ["there", "is", "a", "maximal", "open", "set", "u", "is", "called", "maximal", "is", "a", "diffeomorphism", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2452}, {"sent": "we evaluate our model on ucf-101 in both pose space and video space .", "tokens": ["we", "evaluate", "our", "model", "on", "ucf-101", "in", "both", "pose", "space", "and", "video", "space", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "pose", "start": 41, "end": 45, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2453}, {"sent": "we used the publicly available matconvnet matlab implementations .", "tokens": ["we", "used", "the", "publicly", "available", "matconvnet", "matlab", "implementations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 2454}, {"sent": "we show that the transmission displays an energy spec trum with forbidden and allowed bands that depends on the detuning parameter of the system .", "tokens": ["we", "show", "that", "the", "transmission", "displays", "an", "energy", "spec", "trum", "with", "forbidden", "and", "allowed", "bands", "that", "depends", "on", "the", "detuning", "parameter", "of", "the", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the transmission", "start": 13, "end": 29, "i_start": 3, "i_end": 4}, "verb": {"text": "displays", "start": 30, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "transmission", "start": 17, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "displays", "start": 30, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "bands", "start": 86, "end": 91, "i_start": 14, "i_end": 14}, "action": {"text": "depends", "start": 97, "end": 104, "i_start": 16, "i_end": 16}}], "id": 2455}, {"sent": "neural networks with multi-modal inputs can often be dominated by one of the inputs .", "tokens": ["neural", "networks", "with", "multi", "-", "modal", "inputs", "can", "often", "be", "dominated", "by", "one", "of", "the", "inputs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural networks with multi-modal inputs", "start": 0, "end": 39, "i_start": 0, "i_end": 6}, "verb": {"text": "be dominated", "start": 50, "end": 62, "i_start": 9, "i_end": 10}}, {"subject": {"text": "neural networks with multi-modal inputs", "start": 0, "end": 39, "i_start": 0, "i_end": 6}, "verb": {"text": "can", "start": 40, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "inputs can often be dominated by one", "start": 33, "end": 69, "i_start": 6, "i_end": 12}, "action": {"text": "dominated", "start": 53, "end": 62, "i_start": 10, "i_end": 10}}], "id": 2456}, {"sent": "the class of possible physical geometries is more powerful , than the class of axiomatizable geometries .", "tokens": ["the", "class", "of", "possible", "physical", "geometries", "is", "more", "powerful", ",", "than", "the", "class", "of", "axiomatizable", "geometries", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the class of possible physical geometries", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 42, "end": 44, "i_start": 6, "i_end": 6}}], "id": 2457}, {"sent": "in cloud storage systems , erasure coding has seen itself quickly emerged as a promising technique to reduce the storage cost for a given reliability as compared to the replicated systems .", "tokens": ["in", "cloud", "storage", "systems", ",", "erasure", "coding", "has", "seen", "itself", "quickly", "emerged", "as", "a", "promising", "technique", "to", "reduce", "the", "storage", "cost", "for", "a", "given", "reliability", "as", "compared", "to", "the", "replicated", "systems", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "erasure coding", "start": 27, "end": 41, "i_start": 5, "i_end": 6}, "verb": {"text": "has seen", "start": 42, "end": 50, "i_start": 7, "i_end": 8}}, {"subject": {"text": "itself", "start": 51, "end": 57, "i_start": 9, "i_end": 9}, "verb": {"text": "emerged", "start": 66, "end": 73, "i_start": 11, "i_end": 11}}, {"character": {"text": "systems", "start": 17, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "seen", "start": 46, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "systems", "start": 17, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "storage", "start": 9, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "technique", "start": 89, "end": 98, "i_start": 15, "i_end": 15}, "action": {"text": "promising", "start": 79, "end": 88, "i_start": 14, "i_end": 14}}], "id": 2458}, {"sent": "atiyah , patodi and singer introduced in an integer valued homotopy invariant for paths of selfadjoint fredholm operators which is called spectral flow .", "tokens": ["atiyah", ",", "patodi", "and", "singer", "introduced", "in", "an", "integer", "valued", "homotopy", "invariant", "for", "paths", "of", "selfadjoint", "fredholm", "operators", "which", "is", "called", "spectral", "flow", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "atiyah", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "introduced", "start": 27, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "atiyah", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 27, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "patodi", "start": 9, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 27, "end": 37, "i_start": 5, "i_end": 5}}], "id": 2459}, {"sent": "each image modality is embedded into 64-dimensional vectors using a modified resnet-18 .", "tokens": ["each", "image", "modality", "is", "embedded", "into", "64", "-", "dimensional", "vectors", "using", "a", "modified", "resnet-18", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each image modality", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is embedded", "start": 20, "end": 31, "i_start": 3, "i_end": 4}}], "id": 2460}, {"sent": "reinforcement learning is the problem of finding an action policy that maximizes reward for an agent embedded in an environment .", "tokens": ["reinforcement", "learning", "is", "the", "problem", "of", "finding", "an", "action", "policy", "that", "maximizes", "reward", "for", "an", "agent", "embedded", "in", "an", "environment", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "policy", "start": 59, "end": 65, "i_start": 9, "i_end": 9}, "action": {"text": "maximizes", "start": 71, "end": 80, "i_start": 11, "i_end": 11}}], "id": 2461}, {"sent": "neural networks have become ubiquitous in applications including computer vision .", "tokens": ["neural", "networks", "have", "become", "ubiquitous", "in", "applications", "including", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have become", "start": 16, "end": 27, "i_start": 2, "i_end": 3}}], "id": 2462}, {"sent": "with these attractive characteristics , coupled waveguide-emitter systems have generated tremendous interest for qip and quantum network applications .", "tokens": ["with", "these", "attractive", "characteristics", ",", "coupled", "waveguide", "-", "emitter", "systems", "have", "generated", "tremendous", "interest", "for", "qip", "and", "quantum", "network", "applications", "."], "score": [1, 0, 0, 0, 1], "labels": [{"subject": {"text": "with these attractive characteristics", "start": 0, "end": 37, "i_start": 0, "i_end": 3}, "verb": {"text": "have generated", "start": 74, "end": 88, "i_start": 10, "i_end": 11}}, {"character": {"text": "systems", "start": 66, "end": 73, "i_start": 9, "i_end": 9}, "action": {"text": "generated", "start": 79, "end": 88, "i_start": 11, "i_end": 11}}, {"character": {"text": "systems", "start": 66, "end": 73, "i_start": 9, "i_end": 9}, "action": {"text": "emitter", "start": 58, "end": 65, "i_start": 8, "i_end": 8}}, {"character": {"text": "systems", "start": 66, "end": 73, "i_start": 9, "i_end": 9}, "action": {"text": "attractive", "start": 11, "end": 21, "i_start": 2, "i_end": 2}}], "id": 2463}, {"sent": "the specific case of tree-shaped computations with a more accurate model has been studied in .", "tokens": ["the", "specific", "case", "of", "tree", "-", "shaped", "computations", "with", "a", "more", "accurate", "model", "has", "been", "studied", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the specific case of tree-shaped computations with a more accurate model", "start": 0, "end": 72, "i_start": 0, "i_end": 12}, "verb": {"text": "has been studied", "start": 73, "end": 89, "i_start": 13, "i_end": 15}}], "id": 2464}, {"sent": "the resurgence of convolutional neural networks has enabled significant progress to be made on several problems in computer vision .", "tokens": ["the", "resurgence", "of", "convolutional", "neural", "networks", "has", "enabled", "significant", "progress", "to", "be", "made", "on", "several", "problems", "in", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the resurgence of convolutional neural networks", "start": 0, "end": 47, "i_start": 0, "i_end": 5}, "verb": {"text": "has enabled", "start": 48, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "resurgence", "start": 4, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "enabled", "start": 52, "end": 59, "i_start": 7, "i_end": 7}}], "id": 2465}, {"sent": "the problem is how to estimate model parameters given the extreme strategic flexibility of the human cognitive system .", "tokens": ["the", "problem", "is", "how", "to", "estimate", "model", "parameters", "given", "the", "extreme", "strategic", "flexibility", "of", "the", "human", "cognitive", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the problem", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 2466}, {"sent": "higher resolution models tend to rely on datasets that are only available in data-rich regions of the world .", "tokens": ["higher", "resolution", "models", "tend", "to", "rely", "on", "datasets", "that", "are", "only", "available", "in", "data", "-", "rich", "regions", "of", "the", "world", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "higher resolution models", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "tend", "start": 25, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 18, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "rely", "start": 33, "end": 37, "i_start": 5, "i_end": 5}}], "id": 2467}, {"sent": "convolutional neural networks have achieved state-of-the-art performance on visual tasks such as image and video recognition in the last few years .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "visual", "tasks", "such", "as", "image", "and", "video", "recognition", "in", "the", "last", "few", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 61, "end": 72, "i_start": 12, "i_end": 12}}], "id": 2468}, {"sent": "overlaid is the result of the linear fit as defined in eq .", "tokens": ["overlaid", "is", "the", "result", "of", "the", "linear", "fit", "as", "defined", "in", "eq", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2469}, {"sent": "convolutional neural networks have seen tremendous success across different problems including image classification .", "tokens": ["convolutional", "neural", "networks", "have", "seen", "tremendous", "success", "across", "different", "problems", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have seen", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "seen", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 51, "end": 58, "i_start": 6, "i_end": 6}}], "id": 2470}, {"sent": "note that the location of the boundaries depends only on the jet reference momenta qi .", "tokens": ["note", "that", "the", "location", "of", "the", "boundaries", "depends", "only", "on", "the", "jet", "reference", "momenta", "qi", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the location of the boundaries", "start": 10, "end": 40, "i_start": 2, "i_end": 6}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "the location of the boundaries", "start": 10, "end": 40, "i_start": 2, "i_end": 6}, "verb": {"text": "depends", "start": 41, "end": 48, "i_start": 7, "i_end": 7}}, {"character": {"text": "location", "start": 14, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "depends", "start": 41, "end": 48, "i_start": 7, "i_end": 7}}, {"character": {"text": "jet", "start": 61, "end": 64, "i_start": 11, "i_end": 11}, "action": {"text": "reference", "start": 65, "end": 74, "i_start": 12, "i_end": 12}}], "id": 2471}, {"sent": "stewart and ermon have shown recently how to learn object detectors without any labels by incorporating hand-engineered constraint functions as part of the training objective .", "tokens": ["stewart", "and", "ermon", "have", "shown", "recently", "how", "to", "learn", "object", "detectors", "without", "any", "labels", "by", "incorporating", "hand", "-", "engineered", "constraint", "functions", "as", "part", "of", "the", "training", "objective", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "stewart and ermon", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 18, "end": 28, "i_start": 3, "i_end": 4}}, {"character": {"text": "stewart", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "shown", "start": 23, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "ermon", "start": 12, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 23, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "stewart", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "learn", "start": 45, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "ermon", "start": 12, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "learn", "start": 45, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "stewart", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "incorporating", "start": 90, "end": 103, "i_start": 15, "i_end": 15}}, {"character": {"text": "ermon", "start": 12, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "incorporating", "start": 90, "end": 103, "i_start": 15, "i_end": 15}}, {"character": {"text": "hand", "start": 104, "end": 108, "i_start": 16, "i_end": 16}, "action": {"text": "engineered", "start": 109, "end": 119, "i_start": 18, "i_end": 18}}], "id": 2472}, {"sent": "deep neural networks have demonstrated to be effective models for solving a large variety of problems in several domains , including image , to name a few .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "to", "be", "effective", "models", "for", "solving", "a", "large", "variety", "of", "problems", "in", "several", "domains", ",", "including", "image", ",", "to", "name", "a", "few", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "models", "start": 55, "end": 61, "i_start": 8, "i_end": 8}, "action": {"text": "effective", "start": 45, "end": 54, "i_start": 7, "i_end": 7}}], "id": 2473}, {"sent": "convolutional neural networks have achieved superior performance in many visual tasks , such as object classification and detection .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "classification", "and", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 6, "i_end": 6}}], "id": 2474}, {"sent": "for some special values of one of the parameters of the model , we are able to obtain closed form expressions for the stable vacuum state and for the value of the potential at the minimum .", "tokens": ["for", "some", "special", "values", "of", "one", "of", "the", "parameters", "of", "the", "model", ",", "we", "are", "able", "to", "obtain", "closed", "form", "expressions", "for", "the", "stable", "vacuum", "state", "and", "for", "the", "value", "of", "the", "potential", "at", "the", "minimum", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 64, "end": 66, "i_start": 13, "i_end": 13}, "verb": {"text": "are", "start": 67, "end": 70, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 13, "i_end": 13}, "action": {"text": "obtain", "start": 79, "end": 85, "i_start": 17, "i_end": 17}}], "id": 2475}, {"sent": "we make use of the adam algorithm for stochastic gradient descent .", "tokens": ["we", "make", "use", "of", "the", "adam", "algorithm", "for", "stochastic", "gradient", "descent", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "make", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}], "id": 2476}, {"sent": "semi-supervised learning aims to boost the model performance by leveraging limited labeled data and a large amount of unlabeled data .", "tokens": ["semi", "-", "supervised", "learning", "aims", "to", "boost", "the", "model", "performance", "by", "leveraging", "limited", "labeled", "data", "and", "a", "large", "amount", "of", "unlabeled", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "semi-supervised learning", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "aims", "start": 25, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 16, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "aims", "start": 25, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 16, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "boost", "start": 33, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "model", "start": 43, "end": 48, "i_start": 8, "i_end": 8}, "action": {"text": "performance", "start": 49, "end": 60, "i_start": 9, "i_end": 9}}, {"character": {"text": "learning", "start": 16, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "leveraging", "start": 64, "end": 74, "i_start": 11, "i_end": 11}}], "id": 2477}, {"sent": "deep neural networks , together with large scale accurately annotated datasets , have achieved remarkable performance in a great many classification tasks in recent years .", "tokens": ["deep", "neural", "networks", ",", "together", "with", "large", "scale", "accurately", "annotated", "datasets", ",", "have", "achieved", "remarkable", "performance", "in", "a", "great", "many", "classification", "tasks", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "annotated", "start": 60, "end": 69, "i_start": 9, "i_end": 9}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 86, "end": 94, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 86, "end": 94, "i_start": 13, "i_end": 13}}, {"character": {"text": "deep", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "achieved", "start": 86, "end": 94, "i_start": 13, "i_end": 13}}, {"character": {"text": "datasets", "start": 70, "end": 78, "i_start": 10, "i_end": 10}, "action": {"text": "achieved", "start": 86, "end": 94, "i_start": 13, "i_end": 13}}, {"character": {"text": "accurately", "start": 49, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "achieved", "start": 86, "end": 94, "i_start": 13, "i_end": 13}}, {"character": {"text": "large", "start": 37, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 86, "end": 94, "i_start": 13, "i_end": 13}}], "id": 2478}, {"sent": "afterwards , many forward-secure schemes were constructed , such as forward-secure signatures .", "tokens": ["afterwards", ",", "many", "forward", "-", "secure", "schemes", "were", "constructed", ",", "such", "as", "forward", "-", "secure", "signatures", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "many forward-secure schemes were constructed , such as forward-secure signatures", "start": 13, "end": 93, "i_start": 2, "i_end": 15}, "verb": {"text": "were constructed", "start": 41, "end": 57, "i_start": 7, "i_end": 8}}], "id": 2479}, {"sent": "the sis has been successfully applied to poiseuille flow in channels of arbitrary shapes using the bhatnagar-gross-krook kinetic model for single-species gases .", "tokens": ["the", "sis", "has", "been", "successfully", "applied", "to", "poiseuille", "flow", "in", "channels", "of", "arbitrary", "shapes", "using", "the", "bhatnagar", "-", "gross", "-", "krook", "kinetic", "model", "for", "single", "-", "species", "gases", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the sis", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "applied", "start": 30, "end": 37, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the sis", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "has been", "start": 8, "end": 16, "i_start": 2, "i_end": 3}}], "id": 2480}, {"sent": "convolutional neural networks have been largely responsible for the significant progress achieved on visual recognition tasks in recent years .", "tokens": ["convolutional", "neural", "networks", "have", "been", "largely", "responsible", "for", "the", "significant", "progress", "achieved", "on", "visual", "recognition", "tasks", "in", "recent", "years", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "responsible", "start": 48, "end": 59, "i_start": 6, "i_end": 6}}], "id": 2481}, {"sent": "current constraint solvers , such as choco are monolithic in design , accepting a broad range of models .", "tokens": ["current", "constraint", "solvers", ",", "such", "as", "choco", "are", "monolithic", "in", "design", ",", "accepting", "a", "broad", "range", "of", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "current constraint solvers", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 43, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "monolithic", "start": 47, "end": 57, "i_start": 8, "i_end": 8}, "action": {"text": "accepting", "start": 70, "end": 79, "i_start": 12, "i_end": 12}}], "id": 2482}, {"sent": "the ellipses in denote terms of higher order in the chiral expansion .", "tokens": ["the", "ellipses", "in", "denote", "terms", "of", "higher", "order", "in", "the", "chiral", "expansion", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "ellipses", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 16, "end": 22, "i_start": 3, "i_end": 3}}], "id": 2483}, {"sent": "since a cosmological constant is a homogeneous source of stress-energy , its effect enters the dynamics of cosmological perturbations only through a modification of the background .", "tokens": ["since", "a", "cosmological", "constant", "is", "a", "homogeneous", "source", "of", "stress", "-", "energy", ",", "its", "effect", "enters", "the", "dynamics", "of", "cosmological", "perturbations", "only", "through", "a", "modification", "of", "the", "background", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "its effect", "start": 73, "end": 83, "i_start": 13, "i_end": 14}, "verb": {"text": "enters", "start": 84, "end": 90, "i_start": 15, "i_end": 15}}, {"character": {"text": "effect", "start": 77, "end": 83, "i_start": 14, "i_end": 14}, "action": {"text": "enters", "start": 84, "end": 90, "i_start": 15, "i_end": 15}}], "id": 2484}, {"sent": "convolutional neural network has been found to be effective for learning better feature representations in the field of computer vision .", "tokens": ["convolutional", "neural", "network", "has", "been", "found", "to", "be", "effective", "for", "learning", "better", "feature", "representations", "in", "the", "field", "of", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural network", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "has been found", "start": 29, "end": 43, "i_start": 3, "i_end": 5}}, {"character": {"text": "network", "start": 21, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "effective", "start": 50, "end": 59, "i_start": 8, "i_end": 8}}], "id": 2485}, {"sent": "compressive sensing has gained considerable attention the last decade .", "tokens": ["compressive", "sensing", "has", "gained", "considerable", "attention", "the", "last", "decade", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "compressive sensing", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "has gained", "start": 20, "end": 30, "i_start": 2, "i_end": 3}}, {"character": {"text": "sensing", "start": 12, "end": 19, "i_start": 1, "i_end": 1}, "action": {"text": "gained", "start": 24, "end": 30, "i_start": 3, "i_end": 3}}], "id": 2486}, {"sent": "latent dirichlet allocation model is a popular topic model based on the assumption that a document is composed of a mixture of concepts .", "tokens": ["latent", "dirichlet", "allocation", "model", "is", "a", "popular", "topic", "model", "based", "on", "the", "assumption", "that", "a", "document", "is", "composed", "of", "a", "mixture", "of", "concepts", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "latent dirichlet allocation model", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 4, "i_end": 4}}], "id": 2487}, {"sent": "this brings some structure in the triangulation dependence of the intersection numbers .", "tokens": ["this", "brings", "some", "structure", "in", "the", "triangulation", "dependence", "of", "the", "intersection", "numbers", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "brings", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "structure", "start": 17, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "numbers", "start": 79, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "dependence", "start": 48, "end": 58, "i_start": 7, "i_end": 7}}, {"character": {"text": "numbers", "start": 79, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "intersection", "start": 66, "end": 78, "i_start": 10, "i_end": 10}}], "id": 2488}, {"sent": "we use the i3d with resnet-50 backbone shown in table 10 for feature extraction .", "tokens": ["we", "use", "the", "i3d", "with", "resnet-50", "backbone", "shown", "in", "table", "10", "for", "feature", "extraction", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extraction", "start": 69, "end": 79, "i_start": 13, "i_end": 13}}], "id": 2489}, {"sent": "two activation rules exist for the activation of the neuron dynamics , namely sumof-sum and sum-of-max .", "tokens": ["two", "activation", "rules", "exist", "for", "the", "activation", "of", "the", "neuron", "dynamics", ",", "namely", "sumof", "-", "sum", "and", "sum", "-", "of", "-", "max", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "two activation rules", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "exist", "start": 21, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "two activation rules", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "action": {"text": "activation", "start": 4, "end": 14, "i_start": 1, "i_end": 1}}], "id": 2490}, {"sent": "there is a large number of approaches to the decomposition methodologies .", "tokens": ["there", "is", "a", "large", "number", "of", "approaches", "to", "the", "decomposition", "methodologies", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2491}, {"sent": "devlin et al generate repairs with a rule-based method and then rank them using a neural network .", "tokens": ["devlin", "et", "al", "generate", "repairs", "with", "a", "rule", "-", "based", "method", "and", "then", "rank", "them", "using", "a", "neural", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "devlin et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "generate", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "devlin et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "rank", "start": 64, "end": 68, "i_start": 13, "i_end": 13}}, {"character": {"text": "devlin", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "generate", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "devlin", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "rank", "start": 64, "end": 68, "i_start": 13, "i_end": 13}}], "id": 2492}, {"sent": "convolutional neural networks have achieved remarkable success in many computer vision domains such as classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "remarkable", "success", "in", "many", "computer", "vision", "domains", "such", "as", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 6, "i_end": 6}}], "id": 2493}, {"sent": "noise-resistant lbp , robust lbpare also used for noise reduction of a normal lbp feature .", "tokens": ["noise", "-", "resistant", "lbp", ",", "robust", "lbpare", "also", "used", "for", "noise", "reduction", "of", "a", "normal", "lbp", "feature", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "noise-resistant lbp , robust lbpare", "start": 0, "end": 35, "i_start": 0, "i_end": 6}, "verb": {"text": "used", "start": 41, "end": 45, "i_start": 8, "i_end": 8}}], "id": 2494}, {"sent": "for conventional face recognition tasks , significant advances have been made along with the development of deep convolutional neural networks and large scale labeled datasets .", "tokens": ["for", "conventional", "face", "recognition", "tasks", ",", "significant", "advances", "have", "been", "made", "along", "with", "the", "development", "of", "deep", "convolutional", "neural", "networks", "and", "large", "scale", "labeled", "datasets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "significant advances", "start": 42, "end": 62, "i_start": 6, "i_end": 7}, "verb": {"text": "have been made", "start": 63, "end": 77, "i_start": 8, "i_end": 10}}], "id": 2495}, {"sent": "recently , banerjee et al developed a scheme based on ehrenfests relations to study phase transitions in black holes .", "tokens": ["recently", ",", "banerjee", "et", "al", "developed", "a", "scheme", "based", "on", "ehrenfests", "relations", "to", "study", "phase", "transitions", "in", "black", "holes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "banerjee et al", "start": 11, "end": 25, "i_start": 2, "i_end": 4}, "verb": {"text": "developed", "start": 26, "end": 35, "i_start": 5, "i_end": 5}}, {"character": {"text": "banerjee", "start": 11, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "developed", "start": 26, "end": 35, "i_start": 5, "i_end": 5}}, {"character": {"text": "banerjee", "start": 11, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "study", "start": 78, "end": 83, "i_start": 13, "i_end": 13}}], "id": 2496}, {"sent": "in the recent years the reinforcement learning approach has experienced unprecedented success , reaching human-level performance in several domains , including atari video-games or the ancient game of go .", "tokens": ["in", "the", "recent", "years", "the", "reinforcement", "learning", "approach", "has", "experienced", "unprecedented", "success", ",", "reaching", "human", "-", "level", "performance", "in", "several", "domains", ",", "including", "atari", "video", "-", "games", "or", "the", "ancient", "game", "of", "go", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the reinforcement learning approach", "start": 20, "end": 55, "i_start": 4, "i_end": 7}, "verb": {"text": "has experienced", "start": 56, "end": 71, "i_start": 8, "i_end": 9}}, {"character": {"text": "approach", "start": 47, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "experienced", "start": 60, "end": 71, "i_start": 9, "i_end": 9}}, {"character": {"text": "approach", "start": 47, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "success", "start": 86, "end": 93, "i_start": 11, "i_end": 11}}, {"character": {"text": "approach", "start": 47, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "reaching", "start": 96, "end": 104, "i_start": 13, "i_end": 13}}, {"character": {"text": "approach", "start": 47, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "performance", "start": 117, "end": 128, "i_start": 17, "i_end": 17}}], "id": 2497}, {"sent": "variation of cost functions in integer programming .", "tokens": ["variation", "of", "cost", "functions", "in", "integer", "programming", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2498}, {"sent": "since attention mechanism can selectively focus on more informative data , it is also used in other natural language processing tasks such as question answering .", "tokens": ["since", "attention", "mechanism", "can", "selectively", "focus", "on", "more", "informative", "data", ",", "it", "is", "also", "used", "in", "other", "natural", "language", "processing", "tasks", "such", "as", "question", "answering", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 75, "end": 77, "i_start": 11, "i_end": 11}, "verb": {"text": "used", "start": 86, "end": 90, "i_start": 14, "i_end": 14}}, {"subject": {"text": "it", "start": 75, "end": 77, "i_start": 11, "i_end": 11}, "verb": {"text": "is", "start": 78, "end": 80, "i_start": 12, "i_end": 12}}, {"character": {"text": "mechanism", "start": 16, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "focus", "start": 42, "end": 47, "i_start": 5, "i_end": 5}}, {"character": {"text": "mechanism", "start": 16, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "attention", "start": 6, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "data", "start": 68, "end": 72, "i_start": 9, "i_end": 9}, "action": {"text": "informative", "start": 56, "end": 67, "i_start": 8, "i_end": 8}}], "id": 2499}, {"sent": "bengio et al propose a feed-forward neural probabilistic language model to predict the next word based on its previous contextual words .", "tokens": ["bengio", "et", "al", "propose", "a", "feed", "-", "forward", "neural", "probabilistic", "language", "model", "to", "predict", "the", "next", "word", "based", "on", "its", "previous", "contextual", "words", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bengio et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "bengio", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}], "id": 2500}, {"sent": "the axion is a particle that is theoretically motivated , since is the consequence of the peccei quinn solution to the strong cp problem .", "tokens": ["the", "axion", "is", "a", "particle", "that", "is", "theoretically", "motivated", ",", "since", "is", "the", "consequence", "of", "the", "peccei", "quinn", "solution", "to", "the", "strong", "cp", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the axion", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}], "id": 2501}, {"sent": "luo et al and zhang et al also utilize u-net based models to incorporate multi-level contexts to detect salient objects .", "tokens": ["luo", "et", "al", "and", "zhang", "et", "al", "also", "utilize", "u", "-", "net", "based", "models", "to", "incorporate", "multi", "-", "level", "contexts", "to", "detect", "salient", "objects", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "luo et al and zhang et al", "start": 0, "end": 25, "i_start": 0, "i_end": 6}, "verb": {"text": "utilize", "start": 31, "end": 38, "i_start": 8, "i_end": 8}}, {"character": {"text": "luo et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "action": {"text": "utilize", "start": 31, "end": 38, "i_start": 8, "i_end": 8}}, {"character": {"text": "zhang et al", "start": 14, "end": 25, "i_start": 4, "i_end": 6}, "action": {"text": "utilize", "start": 31, "end": 38, "i_start": 8, "i_end": 8}}, {"character": {"text": "luo et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "action": {"text": "incorporate", "start": 61, "end": 72, "i_start": 15, "i_end": 15}}, {"character": {"text": "zhang et al", "start": 14, "end": 25, "i_start": 4, "i_end": 6}, "action": {"text": "incorporate", "start": 61, "end": 72, "i_start": 15, "i_end": 15}}, {"character": {"text": "luo et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "action": {"text": "detect", "start": 97, "end": 103, "i_start": 21, "i_end": 21}}, {"character": {"text": "zhang et al", "start": 14, "end": 25, "i_start": 4, "i_end": 6}, "action": {"text": "detect", "start": 97, "end": 103, "i_start": 21, "i_end": 21}}], "id": 2502}, {"sent": "the oh radical is a key species to molecular formation .", "tokens": ["the", "oh", "radical", "is", "a", "key", "species", "to", "molecular", "formation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the oh radical", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}], "id": 2503}, {"sent": "in particular , the norm of it is constant in calabi-yau case .", "tokens": ["in", "particular", ",", "the", "norm", "of", "it", "is", "constant", "in", "calabi", "-", "yau", "case", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the norm of it", "start": 16, "end": 30, "i_start": 3, "i_end": 6}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 7, "i_end": 7}}], "id": 2504}, {"sent": "the higgs boson is the only elementary scalar field entering the sm .", "tokens": ["the", "higgs", "boson", "is", "the", "only", "elementary", "scalar", "field", "entering", "the", "sm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the higgs boson", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "field", "start": 46, "end": 51, "i_start": 8, "i_end": 8}, "action": {"text": "entering", "start": 52, "end": 60, "i_start": 9, "i_end": 9}}], "id": 2505}, {"sent": "all images are represented by 2048 features extracted from the inception-v3 network .", "tokens": ["all", "images", "are", "represented", "by", "2048", "features", "extracted", "from", "the", "inception", "-", "v3", "network", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "all images", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "are represented", "start": 11, "end": 26, "i_start": 2, "i_end": 3}}, {"character": {"text": "2048 features", "start": 30, "end": 43, "i_start": 5, "i_end": 6}, "action": {"text": "represented", "start": 15, "end": 26, "i_start": 3, "i_end": 3}}], "id": 2506}, {"sent": "the arcade learning environment , originally proposed in 2013 , is a suite of atari 2600 games which provides dozens of problems in which to train and evaluate rl agents .", "tokens": ["the", "arcade", "learning", "environment", ",", "originally", "proposed", "in", "2013", ",", "is", "a", "suite", "of", "atari", "2600", "games", "which", "provides", "dozens", "of", "problems", "in", "which", "to", "train", "and", "evaluate", "rl", "agents", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the arcade learning environment", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 64, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "games", "start": 89, "end": 94, "i_start": 16, "i_end": 16}, "action": {"text": "provides", "start": 101, "end": 109, "i_start": 18, "i_end": 18}}], "id": 2507}, {"sent": "in the authors present another symbolwise precoder based on the minimum mean square error and extended it to higher modulation scheme in .", "tokens": ["in", "the", "authors", "present", "another", "symbolwise", "precoder", "based", "on", "the", "minimum", "mean", "square", "error", "and", "extended", "it", "to", "higher", "modulation", "scheme", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2508}, {"sent": "this explanation is called dynamical compactification .", "tokens": ["this", "explanation", "is", "called", "dynamical", "compactification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this explanation", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is called", "start": 17, "end": 26, "i_start": 2, "i_end": 3}}], "id": 2509}, {"sent": "the typical spectrum of the prompt emission of grbs can be expressed as exponentially connected broken power-law , the so called band function .", "tokens": ["the", "typical", "spectrum", "of", "the", "prompt", "emission", "of", "grbs", "can", "be", "expressed", "as", "exponentially", "connected", "broken", "power", "-", "law", ",", "the", "so", "called", "band", "function", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the typical spectrum of the prompt emission of grbs", "start": 0, "end": 51, "i_start": 0, "i_end": 8}, "verb": {"text": "can be expressed", "start": 52, "end": 68, "i_start": 9, "i_end": 11}}], "id": 2510}, {"sent": "with the development of machine learning technologies , deep neural networks have shown their extraordinary performance for their high accuracy and excellent scalability .", "tokens": ["with", "the", "development", "of", "machine", "learning", "technologies", ",", "deep", "neural", "networks", "have", "shown", "their", "extraordinary", "performance", "for", "their", "high", "accuracy", "and", "excellent", "scalability", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 56, "end": 76, "i_start": 8, "i_end": 10}, "verb": {"text": "have shown", "start": 77, "end": 87, "i_start": 11, "i_end": 12}}, {"character": {"text": "networks", "start": 68, "end": 76, "i_start": 10, "i_end": 10}, "action": {"text": "shown", "start": 82, "end": 87, "i_start": 12, "i_end": 12}}, {"character": {"text": "networks", "start": 68, "end": 76, "i_start": 10, "i_end": 10}, "action": {"text": "performance", "start": 108, "end": 119, "i_start": 15, "i_end": 15}}], "id": 2511}, {"sent": "we proceed on to define inner commutative loops and its smarandache analogue .", "tokens": ["we", "proceed", "on", "to", "define", "inner", "commutative", "loops", "and", "its", "smarandache", "analogue", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "proceed on", "start": 3, "end": 13, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proceed", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "define", "start": 17, "end": 23, "i_start": 4, "i_end": 4}}], "id": 2512}, {"sent": "the deep features learned by cnns can disentangle the exploratory factors of variations in data distributions and promote knowledge adaptation .", "tokens": ["the", "deep", "features", "learned", "by", "cnns", "can", "disentangle", "the", "exploratory", "factors", "of", "variations", "in", "data", "distributions", "and", "promote", "knowledge", "adaptation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the deep features learned by cnns", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "can disentangle", "start": 34, "end": 49, "i_start": 6, "i_end": 7}}, {"subject": {"text": "the deep features learned by cnns", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "promote", "start": 114, "end": 121, "i_start": 17, "i_end": 17}}, {"character": {"text": "features", "start": 9, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "disentangle", "start": 38, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "factors", "start": 66, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "exploratory", "start": 54, "end": 65, "i_start": 9, "i_end": 9}}, {"character": {"text": "features", "start": 9, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "promote", "start": 114, "end": 121, "i_start": 17, "i_end": 17}}], "id": 2513}, {"sent": "all the dft calculations were performed with the ab-initio simulation package vasp using the projector augmented wave method .", "tokens": ["all", "the", "dft", "calculations", "were", "performed", "with", "the", "ab", "-", "initio", "simulation", "package", "vasp", "using", "the", "projector", "augmented", "wave", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all the dft calculations", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "were performed", "start": 25, "end": 39, "i_start": 4, "i_end": 5}}, {"character": {"text": "projector", "start": 93, "end": 102, "i_start": 16, "i_end": 16}, "action": {"text": "augmented", "start": 103, "end": 112, "i_start": 17, "i_end": 17}}], "id": 2514}, {"sent": "we initialize the weights of the convolutional layers from a model pretrained on imagenet .", "tokens": ["we", "initialize", "the", "weights", "of", "the", "convolutional", "layers", "from", "a", "model", "pretrained", "on", "imagenet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "initialize", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "initialize", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}], "id": 2515}, {"sent": "the attention network can be further enhanced with multi-head attention .", "tokens": ["the", "attention", "network", "can", "be", "further", "enhanced", "with", "multi", "-", "head", "attention", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the attention network", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "enhanced", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the attention network", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "can be", "start": 22, "end": 28, "i_start": 3, "i_end": 4}}, {"character": {"text": "attention", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "enhanced", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}], "id": 2516}, {"sent": "faster rcnn uses region proposal network for object localization .", "tokens": ["faster", "rcnn", "uses", "region", "proposal", "network", "for", "object", "localization", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "rcnn", "start": 7, "end": 11, "i_start": 1, "i_end": 1}, "verb": {"text": "uses", "start": 12, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "network", "start": 33, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "uses", "start": 12, "end": 16, "i_start": 2, "i_end": 2}}], "id": 2517}, {"sent": "gravitational waves is a very difficult task .", "tokens": ["gravitational", "waves", "is", "a", "very", "difficult", "task", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "gravitational waves", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 2, "i_end": 2}}], "id": 2518}, {"sent": "thus , the kinetic energy gain is likely in the under-doped region .", "tokens": ["thus", ",", "the", "kinetic", "energy", "gain", "is", "likely", "in", "the", "under", "-", "doped", "region", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the kinetic energy gain", "start": 7, "end": 30, "i_start": 2, "i_end": 5}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 6, "i_end": 6}}], "id": 2519}, {"sent": "the package directly interfaces with post-dmft packages such as abinitiodga 65 and ladderdga .", "tokens": ["the", "package", "directly", "interfaces", "with", "post", "-", "dmft", "packages", "such", "as", "abinitiodga", "65", "and", "ladderdga", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the package", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "interfaces", "start": 21, "end": 31, "i_start": 3, "i_end": 3}}, {"character": {"text": "package", "start": 4, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "interfaces", "start": 21, "end": 31, "i_start": 3, "i_end": 3}}], "id": 2520}, {"sent": "model-agnostic meta-learning learns easily adaptable model parameters through gradient descent in a meta-learning fashion .", "tokens": ["model", "-", "agnostic", "meta", "-", "learning", "learns", "easily", "adaptable", "model", "parameters", "through", "gradient", "descent", "in", "a", "meta", "-", "learning", "fashion", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "model-agnostic meta-learning", "start": 0, "end": 28, "i_start": 0, "i_end": 5}, "verb": {"text": "learns", "start": 29, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "learning", "start": 20, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "learns", "start": 29, "end": 35, "i_start": 6, "i_end": 6}}], "id": 2521}, {"sent": "each of these copies of the system is called replica .", "tokens": ["each", "of", "these", "copies", "of", "the", "system", "is", "called", "replica", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each of these copies of the system", "start": 0, "end": 34, "i_start": 0, "i_end": 6}, "verb": {"text": "is called", "start": 35, "end": 44, "i_start": 7, "i_end": 8}}], "id": 2522}, {"sent": "the class of dual divergence estimators has been recently introduced by keziou and broniatowski and keziou .", "tokens": ["the", "class", "of", "dual", "divergence", "estimators", "has", "been", "recently", "introduced", "by", "keziou", "and", "broniatowski", "and", "keziou", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the class of dual divergence estimators", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "introduced", "start": 58, "end": 68, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the class of dual divergence estimators", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "has been", "start": 40, "end": 48, "i_start": 6, "i_end": 7}}, {"character": {"text": "keziou", "start": 72, "end": 78, "i_start": 11, "i_end": 11}, "action": {"text": "introduced", "start": 58, "end": 68, "i_start": 9, "i_end": 9}}, {"character": {"text": "broniatowski", "start": 83, "end": 95, "i_start": 13, "i_end": 13}, "action": {"text": "introduced", "start": 58, "end": 68, "i_start": 9, "i_end": 9}}, {"character": {"text": "keziou", "start": 72, "end": 78, "i_start": 11, "i_end": 11}, "action": {"text": "introduced", "start": 58, "end": 68, "i_start": 9, "i_end": 9}}, {"character": {"text": "keziou", "start": 72, "end": 78, "i_start": 11, "i_end": 11}, "action": {"text": "introduced", "start": 58, "end": 68, "i_start": 9, "i_end": 9}}], "id": 2523}, {"sent": "the continuum is a double peaked emission originating from the stellar chromosphere .", "tokens": ["the", "continuum", "is", "a", "double", "peaked", "emission", "originating", "from", "the", "stellar", "chromosphere", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the continuum", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 2524}, {"sent": "it is shown to have applications in areas such as speech recognition .", "tokens": ["it", "is", "shown", "to", "have", "applications", "in", "areas", "such", "as", "speech", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is shown", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}], "id": 2525}, {"sent": "convolutional neural networks have achieved exceptional results in many large-scale computer vision applications , particularly in image recognition task .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "exceptional", "results", "in", "many", "large", "-", "scale", "computer", "vision", "applications", ",", "particularly", "in", "image", "recognition", "task", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 2526}, {"sent": "intersection cohomology of quotients of nonsingular varieties 5 in this case , x is called a topological stratification .", "tokens": ["intersection", "cohomology", "of", "quotients", "of", "nonsingular", "varieties", "5", "in", "this", "case", ",", "x", "is", "called", "a", "topological", "stratification", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "intersection cohomology of quotients of nonsingular varieties 5 in this case", "start": 0, "end": 76, "i_start": 0, "i_end": 10}, "verb": {"text": "is called", "start": 81, "end": 90, "i_start": 13, "i_end": 14}}], "id": 2527}, {"sent": "the weights of field probing filters are initialized by the xavier scheme .", "tokens": ["the", "weights", "of", "field", "probing", "filters", "are", "initialized", "by", "the", "xavier", "scheme", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the weights of field probing filters", "start": 0, "end": 36, "i_start": 0, "i_end": 5}, "verb": {"text": "are initialized", "start": 37, "end": 52, "i_start": 6, "i_end": 7}}, {"character": {"text": "scheme", "start": 67, "end": 73, "i_start": 11, "i_end": 11}, "action": {"text": "initialized", "start": 41, "end": 52, "i_start": 7, "i_end": 7}}, {"character": {"text": "filters", "start": 29, "end": 36, "i_start": 5, "i_end": 5}, "action": {"text": "probing", "start": 21, "end": 28, "i_start": 4, "i_end": 4}}], "id": 2528}, {"sent": "in some cases , we search for schemes with prescribed properties leading to what is known in the literature as frame design problem .", "tokens": ["in", "some", "cases", ",", "we", "search", "for", "schemes", "with", "prescribed", "properties", "leading", "to", "what", "is", "known", "in", "the", "literature", "as", "frame", "design", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "search", "start": 19, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "search", "start": 19, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "schemes", "start": 30, "end": 37, "i_start": 7, "i_end": 7}, "action": {"text": "leading", "start": 65, "end": 72, "i_start": 11, "i_end": 11}}, {"character": {"text": "literature", "start": 97, "end": 107, "i_start": 18, "i_end": 18}, "action": {"text": "known", "start": 84, "end": 89, "i_start": 15, "i_end": 15}}], "id": 2529}, {"sent": "dnns , especially convolutional neural networks , have recently achieved human performance in various visual tasks .", "tokens": ["dnns", ",", "especially", "convolutional", "neural", "networks", ",", "have", "recently", "achieved", "human", "performance", "in", "various", "visual", "tasks", "."], "score": [1, 0, 0, 0, 1], "labels": [{"subject": {"text": "dnns", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "achieved", "start": 64, "end": 72, "i_start": 9, "i_end": 9}}, {"subject": {"text": "dnns", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "have", "start": 50, "end": 54, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 64, "end": 72, "i_start": 9, "i_end": 9}}, {"character": {"text": "human", "start": 73, "end": 78, "i_start": 10, "i_end": 10}, "action": {"text": "performance", "start": 79, "end": 90, "i_start": 11, "i_end": 11}}], "id": 2530}, {"sent": "the author proved that each superinjective simplicial map of the complex of curves is induced by a homeomorphism in most cases in .", "tokens": ["the", "author", "proved", "that", "each", "superinjective", "simplicial", "map", "of", "the", "complex", "of", "curves", "is", "induced", "by", "a", "homeomorphism", "in", "most", "cases", "in", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the author", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "proved", "start": 11, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "each superinjective simplicial map of the complex of curves", "start": 23, "end": 82, "i_start": 4, "i_end": 12}, "verb": {"text": "induced", "start": 86, "end": 93, "i_start": 14, "i_end": 14}}, {"character": {"text": "homeomorphism", "start": 99, "end": 112, "i_start": 17, "i_end": 17}, "action": {"text": "induced", "start": 86, "end": 93, "i_start": 14, "i_end": 14}}], "id": 2531}, {"sent": "this is a familiar concept from the hamiltonian reduction of the chernsimons formulation of einstein gravity .", "tokens": ["this", "is", "a", "familiar", "concept", "from", "the", "hamiltonian", "reduction", "of", "the", "chernsimons", "formulation", "of", "einstein", "gravity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "chernsimons", "start": 65, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "formulation", "start": 77, "end": 88, "i_start": 12, "i_end": 12}}], "id": 2532}, {"sent": "indeed , an isomorphism is a bijection , and both it and its inverse are continuous because addition and multiplication in ft are continuous .", "tokens": ["indeed", ",", "an", "isomorphism", "is", "a", "bijection", ",", "and", "both", "it", "and", "its", "inverse", "are", "continuous", "because", "addition", "and", "multiplication", "in", "ft", "are", "continuous", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an isomorphism", "start": 9, "end": 23, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "continuous", "start": 130, "end": 140, "i_start": 23, "i_end": 23}, "action": {"text": "because", "start": 84, "end": 91, "i_start": 16, "i_end": 16}}], "id": 2533}, {"sent": "the set of such matrices is a 2-dimensional vector space .", "tokens": ["the", "set", "of", "such", "matrices", "is", "a", "2", "-", "dimensional", "vector", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the set of such matrices", "start": 0, "end": 24, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 5, "i_end": 5}}], "id": 2534}, {"sent": "the simplest examples of ldpc codes decoding algorithms relying on one-bit messages were introduced by gallager .", "tokens": ["the", "simplest", "examples", "of", "ldpc", "codes", "decoding", "algorithms", "relying", "on", "one", "-", "bit", "messages", "were", "introduced", "by", "gallager", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the simplest examples of ldpc codes decoding algorithms relying on one-bit messages", "start": 0, "end": 83, "i_start": 0, "i_end": 13}, "verb": {"text": "were introduced", "start": 84, "end": 99, "i_start": 14, "i_end": 15}}, {"character": {"text": "decoding", "start": 36, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "relying", "start": 56, "end": 63, "i_start": 8, "i_end": 8}}], "id": 2535}, {"sent": "we will also assume that the inflaton is the field that underwent the initial tunneling transition , so that the reheating surface is determined by the evolution of that field and can be affected by the collision with the other bubble through its non-linear equation of motion , and that no other scalar fields are relevant .", "tokens": ["we", "will", "also", "assume", "that", "the", "inflaton", "is", "the", "field", "that", "underwent", "the", "initial", "tunneling", "transition", ",", "so", "that", "the", "reheating", "surface", "is", "determined", "by", "the", "evolution", "of", "that", "field", "and", "can", "be", "affected", "by", "the", "collision", "with", "the", "other", "bubble", "through", "its", "non", "-", "linear", "equation", "of", "motion", ",", "and", "that", "no", "other", "scalar", "fields", "are", "relevant", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assume", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assume", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "evolution", "start": 152, "end": 161, "i_start": 26, "i_end": 26}, "action": {"text": "determined", "start": 134, "end": 144, "i_start": 23, "i_end": 23}}, {"character": {"text": "collision", "start": 203, "end": 212, "i_start": 36, "i_end": 36}, "action": {"text": "affected", "start": 187, "end": 195, "i_start": 33, "i_end": 33}}], "id": 2536}, {"sent": "faster-rcnn replaces the traditional region proposal method with the region proposal network , and proposes an end-to-end detection framework .", "tokens": ["faster", "-", "rcnn", "replaces", "the", "traditional", "region", "proposal", "method", "with", "the", "region", "proposal", "network", ",", "and", "proposes", "an", "end", "-", "to", "-", "end", "detection", "framework", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "faster-rcnn", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "replaces", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"subject": {"text": "faster-rcnn", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "proposes", "start": 99, "end": 107, "i_start": 16, "i_end": 16}}, {"character": {"text": "network", "start": 85, "end": 92, "i_start": 13, "i_end": 13}, "action": {"text": "replaces", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}], "id": 2537}, {"sent": "on one hand , we reproduce the results of chen et al , which noticed that the msda representations have greater pad values than original data .", "tokens": ["on", "one", "hand", ",", "we", "reproduce", "the", "results", "of", "chen", "et", "al", ",", "which", "noticed", "that", "the", "msda", "representations", "have", "greater", "pad", "values", "than", "original", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "verb": {"text": "reproduce", "start": 17, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "reproduce", "start": 17, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "representations", "start": 83, "end": 98, "i_start": 18, "i_end": 18}, "action": {"text": "have", "start": 99, "end": 103, "i_start": 19, "i_end": 19}}], "id": 2538}, {"sent": "this asymmetry is a direct manifestation of the broken time-reversal symmetry characteristic of a complex superconducting order parameter .", "tokens": ["this", "asymmetry", "is", "a", "direct", "manifestation", "of", "the", "broken", "time", "-", "reversal", "symmetry", "characteristic", "of", "a", "complex", "superconducting", "order", "parameter", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this asymmetry", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "symmetry", "start": 69, "end": 77, "i_start": 12, "i_end": 12}, "action": {"text": "manifestation", "start": 27, "end": 40, "i_start": 5, "i_end": 5}}], "id": 2539}, {"sent": "virtual knot theory , introduced by kauffman in , is an extension of classical knot theory .", "tokens": ["virtual", "knot", "theory", ",", "introduced", "by", "kauffman", "in", ",", "is", "an", "extension", "of", "classical", "knot", "theory", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "virtual knot theory", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 50, "end": 52, "i_start": 9, "i_end": 9}}, {"character": {"text": "kauffman", "start": 36, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 4, "i_end": 4}}], "id": 2540}, {"sent": "for existence and properties of different attractors for autonomous deterministic lattice dynamical systems , see egfor non-autonomous deterministic cases .", "tokens": ["for", "existence", "and", "properties", "of", "different", "attractors", "for", "autonomous", "deterministic", "lattice", "dynamical", "systems", ",", "see", "egfor", "non", "-", "autonomous", "deterministic", "cases", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2541}, {"sent": "we can now specify the complete protocol for randomness concentration .", "tokens": ["we", "can", "now", "specify", "the", "complete", "protocol", "for", "randomness", "concentration", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "specify", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "can", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "specify", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}], "id": 2542}, {"sent": "the black squares are the suddenly appearing obstacles .", "tokens": ["the", "black", "squares", "are", "the", "suddenly", "appearing", "obstacles", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the black squares", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 18, "end": 21, "i_start": 3, "i_end": 3}}], "id": 2543}, {"sent": "cosmic strings are linear topological defects that can be produced in the early universe via phase transitions .", "tokens": ["cosmic", "strings", "are", "linear", "topological", "defects", "that", "can", "be", "produced", "in", "the", "early", "universe", "via", "phase", "transitions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}], "id": 2544}, {"sent": "convolutional neural networks has shown phenomenal results for many computer vision applications .", "tokens": ["convolutional", "neural", "networks", "has", "shown", "phenomenal", "results", "for", "many", "computer", "vision", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "has shown", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 34, "end": 39, "i_start": 4, "i_end": 4}}], "id": 2545}, {"sent": "in recent years , deep convolution neural networks have achieved promising performance on many artificial intelligence tasks , including image recognition .", "tokens": ["in", "recent", "years", ",", "deep", "convolution", "neural", "networks", "have", "achieved", "promising", "performance", "on", "many", "artificial", "intelligence", "tasks", ",", "including", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolution neural networks", "start": 18, "end": 50, "i_start": 4, "i_end": 7}, "verb": {"text": "have achieved", "start": 51, "end": 64, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 42, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 56, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 42, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "performance", "start": 75, "end": 86, "i_start": 11, "i_end": 11}}, {"character": {"text": "performance", "start": 75, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "promising", "start": 65, "end": 74, "i_start": 10, "i_end": 10}}], "id": 2546}, {"sent": "in recent years , deep convolutional neural networks have been widely used in a variety of computer vision tasks and have achieved unprecedented progress .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "been", "widely", "used", "in", "a", "variety", "of", "computer", "vision", "tasks", "and", "have", "achieved", "unprecedented", "progress", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "used", "start": 70, "end": 74, "i_start": 11, "i_end": 11}}, {"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have been", "start": 53, "end": 62, "i_start": 8, "i_end": 9}}, {"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "achieved", "start": 122, "end": 130, "i_start": 21, "i_end": 21}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 122, "end": 130, "i_start": 21, "i_end": 21}}], "id": 2547}, {"sent": "deep neural networks are responsible for numerous state-of-the-art results in a variety of domains , including computer vision , speech recognition , and natural language processing .", "tokens": ["deep", "neural", "networks", "are", "responsible", "for", "numerous", "state", "-", "of", "-", "the", "-", "art", "results", "in", "a", "variety", "of", "domains", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "and", "natural", "language", "processing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "responsible", "start": 25, "end": 36, "i_start": 4, "i_end": 4}}], "id": 2548}, {"sent": "the pacific asian cluster is joined by indonesia and connects with kazakhstan .", "tokens": ["the", "pacific", "asian", "cluster", "is", "joined", "by", "indonesia", "and", "connects", "with", "kazakhstan", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the pacific asian cluster", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "is joined", "start": 26, "end": 35, "i_start": 4, "i_end": 5}}, {"subject": {"text": "the pacific asian cluster", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "connects", "start": 53, "end": 61, "i_start": 9, "i_end": 9}}], "id": 2549}, {"sent": "there have been extensive studies of various classes of boolean functions which are particularly suited to the logical expression of gene regulation .", "tokens": ["there", "have", "been", "extensive", "studies", "of", "various", "classes", "of", "boolean", "functions", "which", "are", "particularly", "suited", "to", "the", "logical", "expression", "of", "gene", "regulation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "have been", "start": 6, "end": 15, "i_start": 1, "i_end": 2}}], "id": 2550}, {"sent": "quantum interference and the quantum potential .", "tokens": ["quantum", "interference", "and", "the", "quantum", "potential", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2551}, {"sent": "the spectral analysis was performed with the xspec package .", "tokens": ["the", "spectral", "analysis", "was", "performed", "with", "the", "xspec", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the spectral analysis", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "was performed", "start": 22, "end": 35, "i_start": 3, "i_end": 4}}], "id": 2552}, {"sent": "the mutual information is the relative entropy between \u03c1ab and \u03c1a mutual information is used to measure the total correlations between the two subsystems of a bipartite quantum system .", "tokens": ["the", "mutual", "information", "is", "the", "relative", "entropy", "between", "\u03c1ab", "and", "\u03c1a", "mutual", "information", "is", "used", "to", "measure", "the", "total", "correlations", "between", "the", "two", "subsystems", "of", "a", "bipartite", "quantum", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the mutual information", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the mutual information", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 88, "end": 92, "i_start": 14, "i_end": 14}}], "id": 2553}, {"sent": "mst stems from the matrix formulation of light-cone quantization of m-theory and takes the form of the maximally supersymmetric yang-mills theory .", "tokens": ["mst", "stems", "from", "the", "matrix", "formulation", "of", "light", "-", "cone", "quantization", "of", "m", "-", "theory", "and", "takes", "the", "form", "of", "the", "maximally", "supersymmetric", "yang", "-", "mills", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "mst", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "stems", "start": 4, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "mst", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "takes", "start": 81, "end": 86, "i_start": 16, "i_end": 16}}], "id": 2554}, {"sent": "the notation used in this paper is quite standard and follows primarily .", "tokens": ["the", "notation", "used", "in", "this", "paper", "is", "quite", "standard", "and", "follows", "primarily", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the notation used in this paper", "start": 0, "end": 31, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the notation used in this paper", "start": 0, "end": 31, "i_start": 0, "i_end": 5}, "verb": {"text": "follows", "start": 54, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "notation", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "follows", "start": 54, "end": 61, "i_start": 10, "i_end": 10}}], "id": 2555}, {"sent": "recently , deep neural networks have led to significant improvement in several machine learning domains , from speech recognition to computer vision and machine translation .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "led", "to", "significant", "improvement", "in", "several", "machine", "learning", "domains", ",", "from", "speech", "recognition", "to", "computer", "vision", "and", "machine", "translation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have led", "start": 32, "end": 40, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "led", "start": 37, "end": 40, "i_start": 6, "i_end": 6}}], "id": 2556}, {"sent": "diffusion coefficient d consist of 200 points each , whereas the solid lines are respectively smoothed curves obtained from suitable running averages over the original data .", "tokens": ["diffusion", "coefficient", "d", "consist", "of", "200", "points", "each", ",", "whereas", "the", "solid", "lines", "are", "respectively", "smoothed", "curves", "obtained", "from", "suitable", "running", "averages", "over", "the", "original", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2557}, {"sent": "to prove our statement quantitatively we compare our flow fields with different number of scales k to the state-of-the-art annf approach presented in .", "tokens": ["to", "prove", "our", "statement", "quantitatively", "we", "compare", "our", "flow", "fields", "with", "different", "number", "of", "scales", "k", "to", "the", "state", "-", "of", "-", "the", "-", "art", "annf", "approach", "presented", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 38, "end": 40, "i_start": 5, "i_end": 5}, "verb": {"text": "compare", "start": 41, "end": 48, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 38, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "compare", "start": 41, "end": 48, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 38, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "prove", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 38, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "state", "start": 106, "end": 111, "i_start": 18, "i_end": 18}}], "id": 2558}, {"sent": "deep neural networks have achieved great progress in a variety of computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "achieved", "great", "progress", "in", "a", "variety", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}], "id": 2559}, {"sent": "deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification among many others .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "already", "achieved", "tremendous", "success", "on", "a", "variety", "of", "computer", "vision", "tasks", "such", "as", "image", "classification", "among", "many", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "achieved", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 68, "end": 75, "i_start": 8, "i_end": 8}}], "id": 2560}, {"sent": "floater and reimers presented a meshless parameterization method by solving a sparse linear system .", "tokens": ["floater", "and", "reimers", "presented", "a", "meshless", "parameterization", "method", "by", "solving", "a", "sparse", "linear", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "floater and reimers", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "presented", "start": 20, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "floater", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "presented", "start": 20, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "floater", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "solving", "start": 68, "end": 75, "i_start": 9, "i_end": 9}}], "id": 2561}, {"sent": "in this section , we conduct extensive experiments on the imagenet dataset to validate the effectiveness of the proposed methods .", "tokens": ["in", "this", "section", ",", "we", "conduct", "extensive", "experiments", "on", "the", "imagenet", "dataset", "to", "validate", "the", "effectiveness", "of", "the", "proposed", "methods", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "conduct", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "conduct", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "experiments", "start": 39, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "validate", "start": 78, "end": 86, "i_start": 13, "i_end": 13}}, {"character": {"text": "methods", "start": 121, "end": 128, "i_start": 19, "i_end": 19}, "action": {"text": "effectiveness", "start": 91, "end": 104, "i_start": 15, "i_end": 15}}], "id": 2562}, {"sent": "awodey and warren explained that types can be regarded as , roughly speaking , topological spaces .", "tokens": ["awodey", "and", "warren", "explained", "that", "types", "can", "be", "regarded", "as", ",", "roughly", "speaking", ",", "topological", "spaces", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "awodey and warren", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "explained", "start": 18, "end": 27, "i_start": 3, "i_end": 3}}, {"subject": {"text": "types", "start": 33, "end": 38, "i_start": 5, "i_end": 5}, "verb": {"text": "regarded", "start": 46, "end": 54, "i_start": 8, "i_end": 8}}, {"character": {"text": "awodey", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "explained", "start": 18, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "warren", "start": 11, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "explained", "start": 18, "end": 27, "i_start": 3, "i_end": 3}}], "id": 2563}, {"sent": "we utilize a deep residual network where we use its 152-layer model to predict the compressed cell location signal signalx .", "tokens": ["we", "utilize", "a", "deep", "residual", "network", "where", "we", "use", "its", "152", "-", "layer", "model", "to", "predict", "the", "compressed", "cell", "location", "signal", "signalx", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "utilize", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "utilize", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 44, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "predict", "start": 71, "end": 78, "i_start": 15, "i_end": 15}}], "id": 2564}, {"sent": "the weights and biases in each layer was initialized using the xavier initialization .", "tokens": ["the", "weights", "and", "biases", "in", "each", "layer", "was", "initialized", "using", "the", "xavier", "initialization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the weights and biases in each layer", "start": 0, "end": 36, "i_start": 0, "i_end": 6}, "verb": {"text": "was initialized", "start": 37, "end": 52, "i_start": 7, "i_end": 8}}], "id": 2565}, {"sent": "in a second example , michel et al presented a method for predicting behavior from fmri images by combining an 1 and a total variation penalty .", "tokens": ["in", "a", "second", "example", ",", "michel", "et", "al", "presented", "a", "method", "for", "predicting", "behavior", "from", "fmri", "images", "by", "combining", "an", "1", "and", "a", "total", "variation", "penalty", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "michel et al", "start": 22, "end": 34, "i_start": 5, "i_end": 7}, "verb": {"text": "presented", "start": 35, "end": 44, "i_start": 8, "i_end": 8}}, {"character": {"text": "michel", "start": 22, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "presented", "start": 35, "end": 44, "i_start": 8, "i_end": 8}}], "id": 2566}, {"sent": "now we can define substructures in interval polynomial semirings .", "tokens": ["now", "we", "can", "define", "substructures", "in", "interval", "polynomial", "semirings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "can define", "start": 7, "end": 17, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 11, "end": 17, "i_start": 3, "i_end": 3}}], "id": 2567}, {"sent": "the exchange correlation functional is approximated by the generalized gradient approximation as parametrized by perdew , burke and ernzerhof .", "tokens": ["the", "exchange", "correlation", "functional", "is", "approximated", "by", "the", "generalized", "gradient", "approximation", "as", "parametrized", "by", "perdew", ",", "burke", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange correlation functional", "start": 0, "end": 35, "i_start": 0, "i_end": 3}, "verb": {"text": "is approximated", "start": 36, "end": 51, "i_start": 4, "i_end": 5}}, {"character": {"text": "perdew", "start": 113, "end": 119, "i_start": 14, "i_end": 14}, "action": {"text": "parametrized", "start": 97, "end": 109, "i_start": 12, "i_end": 12}}, {"character": {"text": "burke", "start": 122, "end": 127, "i_start": 16, "i_end": 16}, "action": {"text": "parametrized", "start": 97, "end": 109, "i_start": 12, "i_end": 12}}, {"character": {"text": "ernzerhof", "start": 132, "end": 141, "i_start": 18, "i_end": 18}, "action": {"text": "parametrized", "start": 97, "end": 109, "i_start": 12, "i_end": 12}}], "id": 2568}, {"sent": "all these approaches are built upon image local features such as sift .", "tokens": ["all", "these", "approaches", "are", "built", "upon", "image", "local", "features", "such", "as", "sift", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all these approaches", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are built", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}], "id": 2569}, {"sent": "the hpcg benchmark , for example , shows that krylov subspace methods are able to attain only a small fraction of the machine peak performance on large scale hardware .", "tokens": ["the", "hpcg", "benchmark", ",", "for", "example", ",", "shows", "that", "krylov", "subspace", "methods", "are", "able", "to", "attain", "only", "a", "small", "fraction", "of", "the", "machine", "peak", "performance", "on", "large", "scale", "hardware", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the hpcg benchmark", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "shows", "start": 35, "end": 40, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the hpcg benchmark", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 70, "end": 73, "i_start": 12, "i_end": 12}}, {"character": {"text": "benchmark", "start": 9, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "shows", "start": 35, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "methods", "start": 62, "end": 69, "i_start": 11, "i_end": 11}, "action": {"text": "attain", "start": 82, "end": 88, "i_start": 15, "i_end": 15}}, {"character": {"text": "machine", "start": 118, "end": 125, "i_start": 22, "i_end": 22}, "action": {"text": "performance", "start": 131, "end": 142, "i_start": 24, "i_end": 24}}], "id": 2570}, {"sent": "lovelock gravity is a particular higher curvature gravity theory which successfully solves the problem of fourth order field equations and ghost .", "tokens": ["lovelock", "gravity", "is", "a", "particular", "higher", "curvature", "gravity", "theory", "which", "successfully", "solves", "the", "problem", "of", "fourth", "order", "field", "equations", "and", "ghost", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "lovelock gravity", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "theory", "start": 58, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "solves", "start": 84, "end": 90, "i_start": 11, "i_end": 11}}], "id": 2571}, {"sent": "here we consider the cartesian product which is the 1-skeleton of the n-dimensional cube .", "tokens": ["here", "we", "consider", "the", "cartesian", "product", "which", "is", "the", "1", "-", "skeleton", "of", "the", "n", "-", "dimensional", "cube", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "consider", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "consider", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}], "id": 2572}, {"sent": "compressed sensing addresses the problem of retrieving sparse signals from under-determined linear measurements .", "tokens": ["compressed", "sensing", "addresses", "the", "problem", "of", "retrieving", "sparse", "signals", "from", "under", "-", "determined", "linear", "measurements", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "sensing", "start": 11, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "addresses", "start": 19, "end": 28, "i_start": 2, "i_end": 2}}], "id": 2573}, {"sent": "due to its recent success in discriminative tasks with small training data , dictionary learning and sparse coding have also been applied to hyperspectral image classification .", "tokens": ["due", "to", "its", "recent", "success", "in", "discriminative", "tasks", "with", "small", "training", "data", ",", "dictionary", "learning", "and", "sparse", "coding", "have", "also", "been", "applied", "to", "hyperspectral", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "tasks", "start": 44, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "discriminative", "start": 29, "end": 43, "i_start": 6, "i_end": 6}}], "id": 2574}, {"sent": "a standard cosmological model is now supported by a considerable body of evidence , especially precise measurements of correlations in cosmic microwave background radiation .", "tokens": ["a", "standard", "cosmological", "model", "is", "now", "supported", "by", "a", "considerable", "body", "of", "evidence", ",", "especially", "precise", "measurements", "of", "correlations", "in", "cosmic", "microwave", "background", "radiation", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "a standard cosmological model", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "supported", "start": 37, "end": 46, "i_start": 6, "i_end": 6}}, {"subject": {"text": "a standard cosmological model", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "body", "start": 65, "end": 69, "i_start": 10, "i_end": 10}, "action": {"text": "supported", "start": 37, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "background", "start": 152, "end": 162, "i_start": 22, "i_end": 22}, "action": {"text": "radiation", "start": 163, "end": 172, "i_start": 23, "i_end": 23}}], "id": 2575}, {"sent": "in the limit of vanishing interaction , the natural wannier functions do , however , not reduce to the conventional wannier functions .", "tokens": ["in", "the", "limit", "of", "vanishing", "interaction", ",", "the", "natural", "wannier", "functions", "do", ",", "however", ",", "not", "reduce", "to", "the", "conventional", "wannier", "functions", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2576}, {"sent": "such local hamiltonian structures are determined by a differential-geometric poisson bracket of the first order .", "tokens": ["such", "local", "hamiltonian", "structures", "are", "determined", "by", "a", "differential", "-", "geometric", "poisson", "bracket", "of", "the", "first", "order", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such local hamiltonian structures", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "are determined", "start": 34, "end": 48, "i_start": 4, "i_end": 5}}], "id": 2577}, {"sent": "overlaid is a grid of the loci of a simple absorbed power law model as \u03b3 and nh vary .", "tokens": ["overlaid", "is", "a", "grid", "of", "the", "loci", "of", "a", "simple", "absorbed", "power", "law", "model", "as", "\u03b3", "and", "nh", "vary", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "overlaid", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2578}, {"sent": "deep neural networks have seen great success in many cognitive applications such as image classification .", "tokens": ["deep", "neural", "networks", "have", "seen", "great", "success", "in", "many", "cognitive", "applications", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have seen", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 37, "end": 44, "i_start": 6, "i_end": 6}}], "id": 2579}, {"sent": "the generalized gradient approximation was used in conjunction with the perdew , burke , and ernzerhof density functional .", "tokens": ["the", "generalized", "gradient", "approximation", "was", "used", "in", "conjunction", "with", "the", "perdew", ",", "burke", ",", "and", "ernzerhof", "density", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation", "start": 0, "end": 38, "i_start": 0, "i_end": 3}, "verb": {"text": "was used", "start": 39, "end": 47, "i_start": 4, "i_end": 5}}], "id": 2580}, {"sent": "the global zeta function in this section , we study analytic properties of the global zeta function for non-split cases .", "tokens": ["the", "global", "zeta", "function", "in", "this", "section", ",", "we", "study", "analytic", "properties", "of", "the", "global", "zeta", "function", "for", "non", "-", "split", "cases", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 43, "end": 45, "i_start": 8, "i_end": 8}, "verb": {"text": "study", "start": 46, "end": 51, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 43, "end": 45, "i_start": 8, "i_end": 8}, "action": {"text": "study", "start": 46, "end": 51, "i_start": 9, "i_end": 9}}], "id": 2581}, {"sent": "abadi et al provided stricter bounds on the privacy loss induced by a noisy sgd by introducing the moments accountant .", "tokens": ["abadi", "et", "al", "provided", "stricter", "bounds", "on", "the", "privacy", "loss", "induced", "by", "a", "noisy", "sgd", "by", "introducing", "the", "moments", "accountant", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "abadi et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "provided", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "abadi", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "provided", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "abadi", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "introducing", "start": 83, "end": 94, "i_start": 16, "i_end": 16}}], "id": 2582}, {"sent": "it is well known by that solutions of are radially symmetric and decreasing .", "tokens": ["it", "is", "well", "known", "by", "that", "solutions", "of", "are", "radially", "symmetric", "and", "decreasing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "known", "start": 11, "end": 16, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 38, "end": 41, "i_start": 8, "i_end": 8}}], "id": 2583}, {"sent": "to simulate hypervelocity impact processes in solid materials sale was modified to include an elastoplastic constitutive model , fragmentation models , various equations of state , and multiple materials .", "tokens": ["to", "simulate", "hypervelocity", "impact", "processes", "in", "solid", "materials", "sale", "was", "modified", "to", "include", "an", "elastoplastic", "constitutive", "model", ",", "fragmentation", "models", ",", "various", "equations", "of", "state", ",", "and", "multiple", "materials", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2584}, {"sent": "in the final chapter we define both the concept of bisemivector spaces and smarandache bisemivector spaces and give some interesting results about them .", "tokens": ["in", "the", "final", "chapter", "we", "define", "both", "the", "concept", "of", "bisemivector", "spaces", "and", "smarandache", "bisemivector", "spaces", "and", "give", "some", "interesting", "results", "about", "them", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "define", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "give", "start": 111, "end": 115, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "define", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}], "id": 2585}, {"sent": "note that lambek and goldie torsion theories are differential by propositions 9 and 14 of .", "tokens": ["note", "that", "lambek", "and", "goldie", "torsion", "theories", "are", "differential", "by", "propositions", "9", "and", "14", "of", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2586}, {"sent": "quantum conductance in semimetallic bismuth nanocontacts .", "tokens": ["quantum", "conductance", "in", "semimetallic", "bismuth", "nanocontacts", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2587}, {"sent": "the axion is a particle that is theoretically motivated , since is the consequence of the peccei quinn solution to the strong cp problem .", "tokens": ["the", "axion", "is", "a", "particle", "that", "is", "theoretically", "motivated", ",", "since", "is", "the", "consequence", "of", "the", "peccei", "quinn", "solution", "to", "the", "strong", "cp", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the axion", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}], "id": 2588}, {"sent": "in both narrow-band , some two-hop cooperative communication schemes have been investigated that provide significant performance improvement .", "tokens": ["in", "both", "narrow", "-", "band", ",", "some", "two", "-", "hop", "cooperative", "communication", "schemes", "have", "been", "investigated", "that", "provide", "significant", "performance", "improvement", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "some two-hop cooperative communication schemes have been investigated that provide significant performance improvement", "start": 22, "end": 140, "i_start": 6, "i_end": 20}, "verb": {"text": "have been investigated", "start": 69, "end": 91, "i_start": 13, "i_end": 15}}, {"character": {"text": "schemes", "start": 61, "end": 68, "i_start": 12, "i_end": 12}, "action": {"text": "provide", "start": 97, "end": 104, "i_start": 17, "i_end": 17}}, {"character": {"text": "schemes", "start": 61, "end": 68, "i_start": 12, "i_end": 12}, "action": {"text": "improvement", "start": 129, "end": 140, "i_start": 20, "i_end": 20}}], "id": 2589}, {"sent": "two-dimensional quantum gravity in minkowski space .", "tokens": ["two", "-", "dimensional", "quantum", "gravity", "in", "minkowski", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2590}, {"sent": "in recent years , deep convolutional neural networks have been widely applied to various computer vision tasks , eg , image classification , object detection , action recognition , since alexnet .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "been", "widely", "applied", "to", "various", "computer", "vision", "tasks", ",", "eg", ",", "image", "classification", ",", "object", "detection", ",", "action", "recognition", ",", "since", "alexnet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "applied", "start": 70, "end": 77, "i_start": 11, "i_end": 11}}, {"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have been", "start": 53, "end": 62, "i_start": 8, "i_end": 9}}], "id": 2591}, {"sent": "we simulated the 2-choices dynamics on 70 real-world networks , 25 of them taken from konect .", "tokens": ["we", "simulated", "the", "2", "-", "choices", "dynamics", "on", "70", "real", "-", "world", "networks", ",", "25", "of", "them", "taken", "from", "konect", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "25 of them", "start": 64, "end": 74, "i_start": 14, "i_end": 16}, "verb": {"text": "taken", "start": 75, "end": 80, "i_start": 17, "i_end": 17}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "simulated", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "simulated", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}], "id": 2592}, {"sent": "these sensors are ideal for nanoscale imaging of living biological systems .", "tokens": ["these", "sensors", "are", "ideal", "for", "nanoscale", "imaging", "of", "living", "biological", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these sensors", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 14, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "systems", "start": 67, "end": 74, "i_start": 10, "i_end": 10}, "action": {"text": "living", "start": 49, "end": 55, "i_start": 8, "i_end": 8}}], "id": 2593}, {"sent": "for the heavier gravitino , there is a very small region which is compatible with the bounds from the stau nlsp and the muon g 2 .", "tokens": ["for", "the", "heavier", "gravitino", ",", "there", "is", "a", "very", "small", "region", "which", "is", "compatible", "with", "the", "bounds", "from", "the", "stau", "nlsp", "and", "the", "muon", "g", "2", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 28, "end": 33, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 6, "i_end": 6}}], "id": 2594}, {"sent": "in proceedings of the twelfth national conference on artificial intelligence , pp .", "tokens": ["in", "proceedings", "of", "the", "twelfth", "national", "conference", "on", "artificial", "intelligence", ",", "pp", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2595}, {"sent": "typical one of the qkd protocols is the bb84 protocol invented by bennett and brassard .", "tokens": ["typical", "one", "of", "the", "qkd", "protocols", "is", "the", "bb84", "protocol", "invented", "by", "bennett", "and", "brassard", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "typical one of the qkd protocols", "start": 0, "end": 32, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "bennett", "start": 66, "end": 73, "i_start": 12, "i_end": 12}, "action": {"text": "invented", "start": 54, "end": 62, "i_start": 10, "i_end": 10}}, {"character": {"text": "brassard", "start": 78, "end": 86, "i_start": 14, "i_end": 14}, "action": {"text": "invented", "start": 54, "end": 62, "i_start": 10, "i_end": 10}}], "id": 2596}, {"sent": "the sloan digital sky survey is a joint project of the university of chicago , fermilab , the institute for advanced study , the japan participation group , the johns hopkins university , the los alamos national laboratory , the max-planckinstitute for astronomy , new mexico state university , princeton university , the united states naval observatory , and the university of washington .", "tokens": ["the", "sloan", "digital", "sky", "survey", "is", "a", "joint", "project", "of", "the", "university", "of", "chicago", ",", "fermilab", ",", "the", "institute", "for", "advanced", "study", ",", "the", "japan", "participation", "group", ",", "the", "johns", "hopkins", "university", ",", "the", "los", "alamos", "national", "laboratory", ",", "the", "max", "-", "planckinstitute", "for", "astronomy", ",", "new", "mexico", "state", "university", ",", "princeton", "university", ",", "the", "united", "states", "naval", "observatory", ",", "and", "the", "university", "of", "washington", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the sloan digital sky survey", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "group", "start": 149, "end": 154, "i_start": 26, "i_end": 26}, "action": {"text": "participation", "start": 135, "end": 148, "i_start": 25, "i_end": 25}}], "id": 2597}, {"sent": "fast direct solvers for integral equations in complex three-dimensional domains .", "tokens": ["fast", "direct", "solvers", "for", "integral", "equations", "in", "complex", "three", "-", "dimensional", "domains", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2598}, {"sent": "in quantum mechanics , l2 is a second order casimir invariant operator , c2 .", "tokens": ["in", "quantum", "mechanics", ",", "l2", "is", "a", "second", "order", "casimir", "invariant", "operator", ",", "c2", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "l2", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 5, "i_end": 5}}], "id": 2599}, {"sent": "the mass-loss rates inferred from the analysis of uv lines are significantly lower than predicted by hydrodynamically consistent models .", "tokens": ["the", "mass", "-", "loss", "rates", "inferred", "from", "the", "analysis", "of", "uv", "lines", "are", "significantly", "lower", "than", "predicted", "by", "hydrodynamically", "consistent", "models", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the mass-loss rates", "start": 0, "end": 19, "i_start": 0, "i_end": 4}, "verb": {"text": "inferred", "start": 20, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "analysis", "start": 38, "end": 46, "i_start": 8, "i_end": 8}, "action": {"text": "inferred", "start": 20, "end": 28, "i_start": 5, "i_end": 5}}], "id": 2600}, {"sent": "it was shown that computing the rainbow connection number of an arbitrary graph is np-hard .", "tokens": ["it", "was", "shown", "that", "computing", "the", "rainbow", "connection", "number", "of", "an", "arbitrary", "graph", "is", "np", "-", "hard", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "was shown", "start": 3, "end": 12, "i_start": 1, "i_end": 2}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 80, "end": 82, "i_start": 13, "i_end": 13}}], "id": 2601}, {"sent": "on the network architecture side , we can explore the use of generative adversarial networks .", "tokens": ["on", "the", "network", "architecture", "side", ",", "we", "can", "explore", "the", "use", "of", "generative", "adversarial", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 35, "end": 37, "i_start": 6, "i_end": 6}, "verb": {"text": "can explore", "start": 38, "end": 49, "i_start": 7, "i_end": 8}}, {"character": {"text": "we", "start": 35, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "explore", "start": 42, "end": 49, "i_start": 8, "i_end": 8}}], "id": 2602}, {"sent": "the geometry transverse to the 5-branes is a long tube which opens up into the asymptotic flat space region with the horizon at the other end .", "tokens": ["the", "geometry", "transverse", "to", "the", "5", "-", "branes", "is", "a", "long", "tube", "which", "opens", "up", "into", "the", "asymptotic", "flat", "space", "region", "with", "the", "horizon", "at", "the", "other", "end", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the geometry transverse to the 5-branes", "start": 0, "end": 39, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 40, "end": 42, "i_start": 8, "i_end": 8}}], "id": 2603}, {"sent": "at the last decades there were several attempts to get the equation from pure non-equilibrium thermodynamics .", "tokens": ["at", "the", "last", "decades", "there", "were", "several", "attempts", "to", "get", "the", "equation", "from", "pure", "non", "-", "equilibrium", "thermodynamics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 20, "end": 25, "i_start": 4, "i_end": 4}, "verb": {"text": "were", "start": 26, "end": 30, "i_start": 5, "i_end": 5}}], "id": 2604}, {"sent": "convolutional neural networks have achieved great success in many fields , such as object classification , face recognition .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "many", "fields", ",", "such", "as", "object", "classification", ",", "face", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "face", "start": 107, "end": 111, "i_start": 16, "i_end": 16}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}], "id": 2605}, {"sent": "we find that the recurrence is related to the velocities of the peaks of the probability distribution of the quantum walk .", "tokens": ["we", "find", "that", "the", "recurrence", "is", "related", "to", "the", "velocities", "of", "the", "peaks", "of", "the", "probability", "distribution", "of", "the", "quantum", "walk", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the recurrence", "start": 13, "end": 27, "i_start": 3, "i_end": 4}, "verb": {"text": "related", "start": 31, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 2606}, {"sent": "since the seminal work of wilson and cowan , these nonlocal models have helped understanding the emergence of spatial and spatio-temporal coherent structures in various experimental observations .", "tokens": ["since", "the", "seminal", "work", "of", "wilson", "and", "cowan", ",", "these", "nonlocal", "models", "have", "helped", "understanding", "the", "emergence", "of", "spatial", "and", "spatio", "-", "temporal", "coherent", "structures", "in", "various", "experimental", "observations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "these nonlocal models", "start": 45, "end": 66, "i_start": 9, "i_end": 11}, "verb": {"text": "have helped", "start": 67, "end": 78, "i_start": 12, "i_end": 13}}, {"character": {"text": "models", "start": 60, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "helped", "start": 72, "end": 78, "i_start": 13, "i_end": 13}}, {"character": {"text": "observations", "start": 182, "end": 194, "i_start": 28, "i_end": 28}, "action": {"text": "emergence", "start": 97, "end": 106, "i_start": 16, "i_end": 16}}], "id": 2607}, {"sent": "nonlinear perturbations and conservation laws on curved backgrounds in gr and other metric theories .", "tokens": ["nonlinear", "perturbations", "and", "conservation", "laws", "on", "curved", "backgrounds", "in", "gr", "and", "other", "metric", "theories", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2608}, {"sent": "for frequencies below the stopband the phase velocity is lower than that in the long wavelength limit , which works against phase-matching since it adds to the effect of normal index dispersion .", "tokens": ["for", "frequencies", "below", "the", "stopband", "the", "phase", "velocity", "is", "lower", "than", "that", "in", "the", "long", "wavelength", "limit", ",", "which", "works", "against", "phase", "-", "matching", "since", "it", "adds", "to", "the", "effect", "of", "normal", "index", "dispersion", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the phase velocity", "start": 35, "end": 53, "i_start": 5, "i_end": 7}, "verb": {"text": "is", "start": 54, "end": 56, "i_start": 8, "i_end": 8}}], "id": 2609}, {"sent": "harvesting energy from the environment has emerged as a promising solution for prolonging the lifetime of energy-constrained devices in wireless communication systems .", "tokens": ["harvesting", "energy", "from", "the", "environment", "has", "emerged", "as", "a", "promising", "solution", "for", "prolonging", "the", "lifetime", "of", "energy", "-", "constrained", "devices", "in", "wireless", "communication", "systems", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "energy from the environment", "start": 11, "end": 38, "i_start": 1, "i_end": 4}, "verb": {"text": "has emerged", "start": 39, "end": 50, "i_start": 5, "i_end": 6}}, {"character": {"text": "harvesting", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "emerged", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}, {"character": {"text": "energy", "start": 106, "end": 112, "i_start": 16, "i_end": 16}, "action": {"text": "constrained", "start": 113, "end": 124, "i_start": 18, "i_end": 18}}], "id": 2610}, {"sent": "the htdn model is trained using the adam optimizer .", "tokens": ["the", "htdn", "model", "is", "trained", "using", "the", "adam", "optimizer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the htdn model", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is trained", "start": 15, "end": 25, "i_start": 3, "i_end": 4}}], "id": 2611}, {"sent": "the x-ray spectral data was fitted within the xspec package .", "tokens": ["the", "x", "-", "ray", "spectral", "data", "was", "fitted", "within", "the", "xspec", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the x-ray spectral data", "start": 0, "end": 23, "i_start": 0, "i_end": 5}, "verb": {"text": "was fitted", "start": 24, "end": 34, "i_start": 6, "i_end": 7}}], "id": 2612}, {"sent": "recent developments in the areas of sampling theory and numerical optimization have recently given rise to the novel sampling framework of compressed sensing .", "tokens": ["recent", "developments", "in", "the", "areas", "of", "sampling", "theory", "and", "numerical", "optimization", "have", "recently", "given", "rise", "to", "the", "novel", "sampling", "framework", "of", "compressed", "sensing", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "recent developments in the areas of sampling theory and numerical optimization", "start": 0, "end": 78, "i_start": 0, "i_end": 10}, "verb": {"text": "given", "start": 93, "end": 98, "i_start": 13, "i_end": 13}}, {"subject": {"text": "recent developments in the areas of sampling theory and numerical optimization", "start": 0, "end": 78, "i_start": 0, "i_end": 10}, "verb": {"text": "have", "start": 79, "end": 83, "i_start": 11, "i_end": 11}}, {"character": {"text": "developments", "start": 7, "end": 19, "i_start": 1, "i_end": 1}, "action": {"text": "rise", "start": 99, "end": 103, "i_start": 14, "i_end": 14}}], "id": 2613}, {"sent": "unfortunately , just as for the other established methods , there is no clear recipe for the a priori estimation of the initial sampling , for an arbitrary function .", "tokens": ["unfortunately", ",", "just", "as", "for", "the", "other", "established", "methods", ",", "there", "is", "no", "clear", "recipe", "for", "the", "a", "priori", "estimation", "of", "the", "initial", "sampling", ",", "for", "an", "arbitrary", "function", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 60, "end": 65, "i_start": 10, "i_end": 10}, "verb": {"text": "is", "start": 66, "end": 68, "i_start": 11, "i_end": 11}}], "id": 2614}, {"sent": "reinforcement learning is a principled mathematical framework for learning optimal controllers from trial and error .", "tokens": ["reinforcement", "learning", "is", "a", "principled", "mathematical", "framework", "for", "learning", "optimal", "controllers", "from", "trial", "and", "error", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 2, "i_end": 2}}], "id": 2615}, {"sent": "recent research has shown that deep convolutional neural networkcan achieve human-competitive accuracy on various image recognition tasks .", "tokens": ["recent", "research", "has", "shown", "that", "deep", "convolutional", "neural", "networkcan", "achieve", "human", "-", "competitive", "accuracy", "on", "various", "image", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent research", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "has shown", "start": 16, "end": 25, "i_start": 2, "i_end": 3}}, {"subject": {"text": "deep convolutional neural networkcan", "start": 31, "end": 67, "i_start": 5, "i_end": 8}, "verb": {"text": "achieve", "start": 68, "end": 75, "i_start": 9, "i_end": 9}}, {"character": {"text": "research", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "shown", "start": 20, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networkcan", "start": 57, "end": 67, "i_start": 8, "i_end": 8}, "action": {"text": "achieve", "start": 68, "end": 75, "i_start": 9, "i_end": 9}}, {"character": {"text": "human", "start": 76, "end": 81, "i_start": 10, "i_end": 10}, "action": {"text": "competitive", "start": 82, "end": 93, "i_start": 12, "i_end": 12}}], "id": 2616}, {"sent": "wegner , in phase transitions and critical phenomena , edited by c .", "tokens": ["wegner", ",", "in", "phase", "transitions", "and", "critical", "phenomena", ",", "edited", "by", "c", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "phenomena", "start": 43, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "critical", "start": 34, "end": 42, "i_start": 6, "i_end": 6}}, {"character": {"text": "wegner", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "edited", "start": 55, "end": 61, "i_start": 9, "i_end": 9}}], "id": 2617}, {"sent": "in recent years , convolutional neural networks have demonstrated the state-of-the-art performance in visual recognition tasks .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "demonstrated", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have demonstrated", "start": 48, "end": 65, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "demonstrated", "start": 53, "end": 65, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 87, "end": 98, "i_start": 17, "i_end": 17}}], "id": 2618}, {"sent": "in recent years , convolutional neural networks have become the de facto standard in many computer vision tasks , such as image classification and object detection .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "become", "the", "de", "facto", "standard", "in", "many", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "and", "object", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have become", "start": 48, "end": 59, "i_start": 7, "i_end": 8}}], "id": 2619}, {"sent": "which directions are appropriate depends on the velocity of the particles , the curvature of the spacetime , and the positions of the observers .", "tokens": ["which", "directions", "are", "appropriate", "depends", "on", "the", "velocity", "of", "the", "particles", ",", "the", "curvature", "of", "the", "spacetime", ",", "and", "the", "positions", "of", "the", "observers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "which directions", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 17, "end": 20, "i_start": 2, "i_end": 2}}, {"subject": {"text": "which directions", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "depends", "start": 33, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "directions", "start": 6, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "depends", "start": 33, "end": 40, "i_start": 4, "i_end": 4}}], "id": 2620}, {"sent": "deep learning has been successfully applied to several machine learning tasks including visual object classification .", "tokens": ["deep", "learning", "has", "been", "successfully", "applied", "to", "several", "machine", "learning", "tasks", "including", "visual", "object", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "applied", "start": 36, "end": 43, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has been", "start": 14, "end": 22, "i_start": 2, "i_end": 3}}], "id": 2621}, {"sent": "convolutional neural networks have been the driving factor behind the recent advances in object detection .", "tokens": ["convolutional", "neural", "networks", "have", "been", "the", "driving", "factor", "behind", "the", "recent", "advances", "in", "object", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "factor", "start": 52, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "driving", "start": 44, "end": 51, "i_start": 6, "i_end": 6}}], "id": 2622}, {"sent": "in spacetime , which is a 4-dimensional subspace of c , we have not only the 4-dimensional gravity , but also other interactions , just as in kaluzaklein theories .", "tokens": ["in", "spacetime", ",", "which", "is", "a", "4", "-", "dimensional", "subspace", "of", "c", ",", "we", "have", "not", "only", "the", "4", "-", "dimensional", "gravity", ",", "but", "also", "other", "interactions", ",", "just", "as", "in", "kaluzaklein", "theories", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 56, "end": 58, "i_start": 13, "i_end": 13}, "verb": {"text": "have", "start": 59, "end": 63, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 56, "end": 58, "i_start": 13, "i_end": 13}, "action": {"text": "have", "start": 59, "end": 63, "i_start": 14, "i_end": 14}}], "id": 2623}, {"sent": "to overcome overfitting problems , we use batch normalization after each convolution and deconvolutional layer .", "tokens": ["to", "overcome", "overfitting", "problems", ",", "we", "use", "batch", "normalization", "after", "each", "convolution", "and", "deconvolutional", "layer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 35, "end": 37, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 38, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 35, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 38, "end": 41, "i_start": 6, "i_end": 6}}], "id": 2624}, {"sent": "selvaraju et al presented a technique for making convolutional neural network based models more transparent .", "tokens": ["selvaraju", "et", "al", "presented", "a", "technique", "for", "making", "convolutional", "neural", "network", "based", "models", "more", "transparent", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "selvaraju et al", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "presented", "start": 16, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "selvaraju", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "presented", "start": 16, "end": 25, "i_start": 3, "i_end": 3}}], "id": 2625}, {"sent": "thefirstpartisthedevices internationaljournalofcomputerscienceandinformationsecurity , vol .", "tokens": ["thefirstpartisthedevices", "internationaljournalofcomputerscienceandinformationsecurity", ",", "vol", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2626}, {"sent": "for model training , we use cross-entropy as the loss function and adam as the optimizer .", "tokens": ["for", "model", "training", ",", "we", "use", "cross", "-", "entropy", "as", "the", "loss", "function", "and", "adam", "as", "the", "optimizer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 24, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 24, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "adam", "start": 67, "end": 71, "i_start": 14, "i_end": 14}, "action": {"text": "function", "start": 54, "end": 62, "i_start": 12, "i_end": 12}}, {"character": {"text": "adam", "start": 67, "end": 71, "i_start": 14, "i_end": 14}, "action": {"text": "optimizer", "start": 79, "end": 88, "i_start": 17, "i_end": 17}}], "id": 2627}, {"sent": "higher dimensional damage models are analytically investigated in and , there , existence and regularity properties are shown .", "tokens": ["higher", "dimensional", "damage", "models", "are", "analytically", "investigated", "in", "and", ",", "there", ",", "existence", "and", "regularity", "properties", "are", "shown", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "existence and regularity properties", "start": 80, "end": 115, "i_start": 12, "i_end": 15}, "verb": {"text": "are shown", "start": 116, "end": 125, "i_start": 16, "i_end": 17}}, {"subject": {"text": "higher dimensional damage models", "start": 0, "end": 32, "i_start": 0, "i_end": 3}, "verb": {"text": "investigated", "start": 50, "end": 62, "i_start": 6, "i_end": 6}}], "id": 2628}, {"sent": "song et al used the attention mechanism with lstm units to selectively focus on discriminative skeleton joints at each gesture frame .", "tokens": ["song", "et", "al", "used", "the", "attention", "mechanism", "with", "lstm", "units", "to", "selectively", "focus", "on", "discriminative", "skeleton", "joints", "at", "each", "gesture", "frame", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "song et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "song", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "song", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "focus", "start": 71, "end": 76, "i_start": 12, "i_end": 12}}, {"character": {"text": "joints", "start": 104, "end": 110, "i_start": 16, "i_end": 16}, "action": {"text": "discriminative", "start": 80, "end": 94, "i_start": 14, "i_end": 14}}], "id": 2629}, {"sent": "the reason behind adversarial examples may be the linearity in neural networks .", "tokens": ["the", "reason", "behind", "adversarial", "examples", "may", "be", "the", "linearity", "in", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the reason behind adversarial examples", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "may be", "start": 39, "end": 45, "i_start": 5, "i_end": 6}}], "id": 2630}, {"sent": "a practical situation is that of the weak measurement , where information about the measured observable is extracted from the system at a slow rate .", "tokens": ["a", "practical", "situation", "is", "that", "of", "the", "weak", "measurement", ",", "where", "information", "about", "the", "measured", "observable", "is", "extracted", "from", "the", "system", "at", "a", "slow", "rate", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a practical situation", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2631}, {"sent": "deep learning has brought significant breakthroughs in many computer vision tasks , including object detection .", "tokens": ["deep", "learning", "has", "brought", "significant", "breakthroughs", "in", "many", "computer", "vision", "tasks", ",", "including", "object", "detection", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has brought", "start": 14, "end": 25, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "breakthroughs", "start": 38, "end": 51, "i_start": 5, "i_end": 5}}], "id": 2632}, {"sent": "this similarity is a guide to understanding our work .", "tokens": ["this", "similarity", "is", "a", "guide", "to", "understanding", "our", "work", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this similarity", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 2633}, {"sent": "collagen gel considered in experiments is converted into a computational network using the approach of stein , andrew m , et al .", "tokens": ["collagen", "gel", "considered", "in", "experiments", "is", "converted", "into", "a", "computational", "network", "using", "the", "approach", "of", "stein", ",", "andrew", "m", ",", "et", "al", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "collagen gel considered in experiments", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "is converted", "start": 39, "end": 51, "i_start": 5, "i_end": 6}}, {"character": {"text": "stein", "start": 103, "end": 108, "i_start": 15, "i_end": 15}, "action": {"text": "approach", "start": 91, "end": 99, "i_start": 13, "i_end": 13}}, {"character": {"text": "andrew m", "start": 111, "end": 119, "i_start": 17, "i_end": 18}, "action": {"text": "approach", "start": 91, "end": 99, "i_start": 13, "i_end": 13}}], "id": 2634}, {"sent": "mathematically the underlying concept of a vertex algebra was introduced by borcherds , .", "tokens": ["mathematically", "the", "underlying", "concept", "of", "a", "vertex", "algebra", "was", "introduced", "by", "borcherds", ",", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the underlying concept of a vertex algebra", "start": 15, "end": 57, "i_start": 1, "i_end": 7}, "verb": {"text": "was introduced", "start": 58, "end": 72, "i_start": 8, "i_end": 9}}, {"character": {"text": "borcherds", "start": 76, "end": 85, "i_start": 11, "i_end": 11}, "action": {"text": "introduced", "start": 62, "end": 72, "i_start": 9, "i_end": 9}}, {"character": {"text": "concept", "start": 30, "end": 37, "i_start": 3, "i_end": 3}, "action": {"text": "underlying", "start": 19, "end": 29, "i_start": 2, "i_end": 2}}], "id": 2635}, {"sent": "we state the results in the form we need and include the proofs for completeness .", "tokens": ["we", "state", "the", "results", "in", "the", "form", "we", "need", "and", "include", "the", "proofs", "for", "completeness", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "state", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "state", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "need", "start": 36, "end": 40, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "include", "start": 45, "end": 52, "i_start": 10, "i_end": 10}}], "id": 2636}, {"sent": "string theory is a natural framework to talk about all of the issues i have raised above .", "tokens": ["string", "theory", "is", "a", "natural", "framework", "to", "talk", "about", "all", "of", "the", "issues", "i", "have", "raised", "above", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "string theory", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "i", "start": 69, "end": 70, "i_start": 13, "i_end": 13}, "action": {"text": "raised", "start": 76, "end": 82, "i_start": 15, "i_end": 15}}], "id": 2637}, {"sent": "these transformations give rise to the shift of the lax matrices .", "tokens": ["these", "transformations", "give", "rise", "to", "the", "shift", "of", "the", "lax", "matrices", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "these transformations", "start": 0, "end": 21, "i_start": 0, "i_end": 1}, "verb": {"text": "give", "start": 22, "end": 26, "i_start": 2, "i_end": 2}}, {"character": {"text": "transformations", "start": 6, "end": 21, "i_start": 1, "i_end": 1}, "action": {"text": "rise", "start": 27, "end": 31, "i_start": 3, "i_end": 3}}], "id": 2638}, {"sent": "the problem set-up is adapted from a general concept of expectation over transformation .", "tokens": ["the", "problem", "set", "-", "up", "is", "adapted", "from", "a", "general", "concept", "of", "expectation", "over", "transformation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the problem set-up", "start": 0, "end": 18, "i_start": 0, "i_end": 4}, "verb": {"text": "is adapted", "start": 19, "end": 29, "i_start": 5, "i_end": 6}}], "id": 2639}, {"sent": "generative adversarial nets consist of a generator g and a discriminator d .", "tokens": ["generative", "adversarial", "nets", "consist", "of", "a", "generator", "g", "and", "a", "discriminator", "d", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial nets", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "consist", "start": 28, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "d", "start": 73, "end": 74, "i_start": 11, "i_end": 11}, "action": {"text": "discriminator", "start": 59, "end": 72, "i_start": 10, "i_end": 10}}], "id": 2640}, {"sent": "the theory of constrained hamiltonian system was introduced by dirac , and extended by him to general relativity .", "tokens": ["the", "theory", "of", "constrained", "hamiltonian", "system", "was", "introduced", "by", "dirac", ",", "and", "extended", "by", "him", "to", "general", "relativity", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the theory of constrained hamiltonian system", "start": 0, "end": 44, "i_start": 0, "i_end": 5}, "verb": {"text": "was introduced", "start": 45, "end": 59, "i_start": 6, "i_end": 7}}, {"subject": {"text": "the theory of constrained hamiltonian system", "start": 0, "end": 44, "i_start": 0, "i_end": 5}, "verb": {"text": "extended", "start": 75, "end": 83, "i_start": 12, "i_end": 12}}, {"character": {"text": "dirac", "start": 63, "end": 68, "i_start": 9, "i_end": 9}, "action": {"text": "introduced", "start": 49, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "dirac", "start": 63, "end": 68, "i_start": 9, "i_end": 9}, "action": {"text": "extended", "start": 75, "end": 83, "i_start": 12, "i_end": 12}}], "id": 2641}, {"sent": "near-infrared pitch angle in degrees versus rotation curve type .", "tokens": ["near", "-", "infrared", "pitch", "angle", "in", "degrees", "versus", "rotation", "curve", "type", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2642}, {"sent": "ml is intractable in general and often requires the expectationmaximisation algorithm to find approximate solutions .", "tokens": ["ml", "is", "intractable", "in", "general", "and", "often", "requires", "the", "expectationmaximisation", "algorithm", "to", "find", "approximate", "solutions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "ml", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "ml", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "requires", "start": 39, "end": 47, "i_start": 7, "i_end": 7}}], "id": 2643}, {"sent": "we extensively evaluate the proposed approach on two publicly available datasets , namely humaneva-i .", "tokens": ["we", "extensively", "evaluate", "the", "proposed", "approach", "on", "two", "publicly", "available", "datasets", ",", "namely", "humaneva", "-", "i", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 15, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 15, "end": 23, "i_start": 2, "i_end": 2}}], "id": 2644}, {"sent": "a detailed description of the cms detector , together with the definition of the coordinate system used and the relevant kinematic variables , can be found in ref .", "tokens": ["a", "detailed", "description", "of", "the", "cms", "detector", ",", "together", "with", "the", "definition", "of", "the", "coordinate", "system", "used", "and", "the", "relevant", "kinematic", "variables", ",", "can", "be", "found", "in", "ref", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "a detailed description of the cms detector", "start": 0, "end": 42, "i_start": 0, "i_end": 6}, "verb": {"text": "can be found", "start": 143, "end": 155, "i_start": 23, "i_end": 25}}], "id": 2645}, {"sent": "dietrich , critical casimir torques and forces acting on needles in two spatial dimensions , phys .", "tokens": ["dietrich", ",", "critical", "casimir", "torques", "and", "forces", "acting", "on", "needles", "in", "two", "spatial", "dimensions", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "dietrich", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "acting", "start": 47, "end": 53, "i_start": 7, "i_end": 7}}, {"character": {"text": "torques", "start": 28, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "acting", "start": 47, "end": 53, "i_start": 7, "i_end": 7}}, {"character": {"text": "casimir", "start": 20, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "acting", "start": 47, "end": 53, "i_start": 7, "i_end": 7}}, {"character": {"text": "forces", "start": 40, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "acting", "start": 47, "end": 53, "i_start": 7, "i_end": 7}}], "id": 2646}, {"sent": "following recent advances , deep learning models have achieved tremendous success in speech recognition , and in learning natural language processing .", "tokens": ["following", "recent", "advances", ",", "deep", "learning", "models", "have", "achieved", "tremendous", "success", "in", "speech", "recognition", ",", "and", "in", "learning", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning models", "start": 28, "end": 48, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 49, "end": 62, "i_start": 7, "i_end": 8}}, {"character": {"text": "models", "start": 42, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 54, "end": 62, "i_start": 8, "i_end": 8}}, {"character": {"text": "models", "start": 42, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "learning", "start": 113, "end": 121, "i_start": 17, "i_end": 17}}, {"character": {"text": "models", "start": 42, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 74, "end": 81, "i_start": 10, "i_end": 10}}], "id": 2647}, {"sent": "the one-dimensional spectra were extracted using standard iraf 15 routines .", "tokens": ["the", "one", "-", "dimensional", "spectra", "were", "extracted", "using", "standard", "iraf", "15", "routines", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the one-dimensional spectra", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "were extracted", "start": 28, "end": 42, "i_start": 5, "i_end": 6}}], "id": 2648}, {"sent": "the underlying idea is the repeated application of the inclusion-exclusion principle to obtain a decomposition of orbit pairs into sets of which only a relatively small proportion gives nonzero contribution .", "tokens": ["the", "underlying", "idea", "is", "the", "repeated", "application", "of", "the", "inclusion", "-", "exclusion", "principle", "to", "obtain", "a", "decomposition", "of", "orbit", "pairs", "into", "sets", "of", "which", "only", "a", "relatively", "small", "proportion", "gives", "nonzero", "contribution", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the underlying idea", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "idea", "start": 15, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "underlying", "start": 4, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "proportion", "start": 169, "end": 179, "i_start": 28, "i_end": 28}, "action": {"text": "contribution", "start": 194, "end": 206, "i_start": 31, "i_end": 31}}], "id": 2649}, {"sent": "deep neural networks have been shown to outperform shallow learning algorithms in applications such as computer vision .", "tokens": ["deep", "neural", "networks", "have", "been", "shown", "to", "outperform", "shallow", "learning", "algorithms", "in", "applications", "such", "as", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been shown", "start": 21, "end": 36, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "outperform", "start": 40, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "algorithms", "start": 68, "end": 78, "i_start": 10, "i_end": 10}, "action": {"text": "learning", "start": 59, "end": 67, "i_start": 9, "i_end": 9}}], "id": 2650}, {"sent": "we train the proposed drn model using a random subset of 350k images from the imagenet dataset .", "tokens": ["we", "train", "the", "proposed", "drn", "model", "using", "a", "random", "subset", "of", "350k", "images", "from", "the", "imagenet", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 32, "end": 37, "i_start": 6, "i_end": 6}}], "id": 2651}, {"sent": "the red star is representative of the strongly self-interacting scenario described in refs .", "tokens": ["the", "red", "star", "is", "representative", "of", "the", "strongly", "self", "-", "interacting", "scenario", "described", "in", "refs", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the red star", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "star", "start": 8, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "representative", "start": 16, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "star", "start": 8, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "interacting", "start": 52, "end": 63, "i_start": 10, "i_end": 10}}], "id": 2652}, {"sent": "however , the magnetic helicity is a volume integral which is probably hopeless to measure in practice , because the field can not be observed in the solar interior .", "tokens": ["however", ",", "the", "magnetic", "helicity", "is", "a", "volume", "integral", "which", "is", "probably", "hopeless", "to", "measure", "in", "practice", ",", "because", "the", "field", "can", "not", "be", "observed", "in", "the", "solar", "interior", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the magnetic helicity", "start": 10, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 5, "i_end": 5}}], "id": 2653}, {"sent": "reinforcement learning is an area of machine learning that has been successfully applied to solve complex decision problems .", "tokens": ["reinforcement", "learning", "is", "an", "area", "of", "machine", "learning", "that", "has", "been", "successfully", "applied", "to", "solve", "complex", "decision", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 2, "i_end": 2}}], "id": 2654}, {"sent": "more precisely , the higgs is a pseudo-goldstone as the couplings of the sm gauge and matter fields with the cft sector explicitly break g .", "tokens": ["more", "precisely", ",", "the", "higgs", "is", "a", "pseudo", "-", "goldstone", "as", "the", "couplings", "of", "the", "sm", "gauge", "and", "matter", "fields", "with", "the", "cft", "sector", "explicitly", "break", "g", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the higgs", "start": 17, "end": 26, "i_start": 3, "i_end": 4}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "couplings", "start": 56, "end": 65, "i_start": 12, "i_end": 12}, "action": {"text": "break", "start": 131, "end": 136, "i_start": 25, "i_end": 25}}], "id": 2655}, {"sent": "excitations in zero magnetic field for polar states .", "tokens": ["excitations", "in", "zero", "magnetic", "field", "for", "polar", "states", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "zero magnetic field", "start": 15, "end": 34, "i_start": 2, "i_end": 4}, "action": {"text": "excitations", "start": 0, "end": 11, "i_start": 0, "i_end": 0}}], "id": 2656}, {"sent": "the power spectrum is the most important statistic that can be measured from large scale structure .", "tokens": ["the", "power", "spectrum", "is", "the", "most", "important", "statistic", "that", "can", "be", "measured", "from", "large", "scale", "structure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the power spectrum", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 2657}, {"sent": "this enables us to point out some integrals for the truncated normal form .", "tokens": ["this", "enables", "us", "to", "point", "out", "some", "integrals", "for", "the", "truncated", "normal", "form", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "enables", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}, {"subject": {"text": "us", "start": 13, "end": 15, "i_start": 2, "i_end": 2}, "verb": {"text": "point", "start": 19, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "enables", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "us", "start": 13, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "point", "start": 19, "end": 24, "i_start": 4, "i_end": 4}}], "id": 2658}, {"sent": "a batch normalization layer is added after each convolution layer .", "tokens": ["a", "batch", "normalization", "layer", "is", "added", "after", "each", "convolution", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a batch normalization layer", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "is added", "start": 28, "end": 36, "i_start": 4, "i_end": 5}}], "id": 2659}, {"sent": "extremal optimization for graph partitioning .", "tokens": ["extremal", "optimization", "for", "graph", "partitioning", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2660}, {"sent": "the lagrangian is the constant brane tension integrated over the area of the brane .", "tokens": ["the", "lagrangian", "is", "the", "constant", "brane", "tension", "integrated", "over", "the", "area", "of", "the", "brane", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lagrangian", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 2661}, {"sent": "deep neural networks have achieved a great success on many tasks such as image classification when a large set of labeled examples are available .", "tokens": ["deep", "neural", "networks", "have", "achieved", "a", "great", "success", "on", "many", "tasks", "such", "as", "image", "classification", "when", "a", "large", "set", "of", "labeled", "examples", "are", "available", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 43, "end": 50, "i_start": 7, "i_end": 7}}], "id": 2662}, {"sent": "deep neural networks are powerful methods for solving large scale real world problems such as automated image classification .", "tokens": ["deep", "neural", "networks", "are", "powerful", "methods", "for", "solving", "large", "scale", "real", "world", "problems", "such", "as", "automated", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2663}, {"sent": "inflation is a powerful framework for understanding the early universe , in particular the spectrum of density perturbations that led to structure formation and to anisotropies in the cosmic microwave background .", "tokens": ["inflation", "is", "a", "powerful", "framework", "for", "understanding", "the", "early", "universe", ",", "in", "particular", "the", "spectrum", "of", "density", "perturbations", "that", "led", "to", "structure", "formation", "and", "to", "anisotropies", "in", "the", "cosmic", "microwave", "background", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "inflation", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 1, "i_end": 1}}], "id": 2664}, {"sent": "in recent years , neural networks have been effectively applied in various problems such as voice recognition .", "tokens": ["in", "recent", "years", ",", "neural", "networks", "have", "been", "effectively", "applied", "in", "various", "problems", "such", "as", "voice", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 18, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "applied", "start": 56, "end": 63, "i_start": 9, "i_end": 9}}, {"subject": {"text": "neural networks", "start": 18, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "have been", "start": 34, "end": 43, "i_start": 6, "i_end": 7}}], "id": 2665}, {"sent": "the dashed line represents the one-dimensional planewave limit of the multi-parameter formalism .", "tokens": ["the", "dashed", "line", "represents", "the", "one", "-", "dimensional", "planewave", "limit", "of", "the", "multi", "-", "parameter", "formalism", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the dashed line", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "represents", "start": 16, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "line", "start": 11, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "represents", "start": 16, "end": 26, "i_start": 3, "i_end": 3}}], "id": 2666}, {"sent": "the asterisks denote the time lags for which the absolute value of the correlation is largest .", "tokens": ["the", "asterisks", "denote", "the", "time", "lags", "for", "which", "the", "absolute", "value", "of", "the", "correlation", "is", "largest", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the time lags for which the absolute value of the correlation is largest", "start": 21, "end": 93, "i_start": 3, "i_end": 15}, "verb": {"text": "lags", "start": 30, "end": 34, "i_start": 5, "i_end": 5}}, {"character": {"text": "asterisks", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 14, "end": 20, "i_start": 2, "i_end": 2}}], "id": 2667}, {"sent": "for this experiment we used the implementation from the python scikit-learn project .", "tokens": ["for", "this", "experiment", "we", "used", "the", "implementation", "from", "the", "python", "scikit", "-", "learn", "project", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "verb": {"text": "used", "start": 23, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "used", "start": 23, "end": 27, "i_start": 4, "i_end": 4}}], "id": 2668}, {"sent": "the model is trained with the adam optimizer using a batch size of 256 .", "tokens": ["the", "model", "is", "trained", "with", "the", "adam", "optimizer", "using", "a", "batch", "size", "of", "256", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is trained", "start": 10, "end": 20, "i_start": 2, "i_end": 3}}], "id": 2669}, {"sent": "although more recent approaches have incorporated time into these models , current methods do not focus on inferring the driving force behind animal actions .", "tokens": ["although", "more", "recent", "approaches", "have", "incorporated", "time", "into", "these", "models", ",", "current", "methods", "do", "not", "focus", "on", "inferring", "the", "driving", "force", "behind", "animal", "actions", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "current methods", "start": 75, "end": 90, "i_start": 11, "i_end": 12}, "verb": {"text": "do not focus", "start": 91, "end": 103, "i_start": 13, "i_end": 15}}, {"character": {"text": "methods", "start": 83, "end": 90, "i_start": 12, "i_end": 12}, "action": {"text": "not focus", "start": 94, "end": 103, "i_start": 14, "i_end": 15}}, {"character": {"text": "methods", "start": 83, "end": 90, "i_start": 12, "i_end": 12}, "action": {"text": "inferring", "start": 107, "end": 116, "i_start": 17, "i_end": 17}}, {"character": {"text": "force", "start": 129, "end": 134, "i_start": 20, "i_end": 20}, "action": {"text": "driving", "start": 121, "end": 128, "i_start": 19, "i_end": 19}}, {"character": {"text": "approaches", "start": 21, "end": 31, "i_start": 3, "i_end": 3}, "action": {"text": "incorporated", "start": 37, "end": 49, "i_start": 5, "i_end": 5}}], "id": 2670}, {"sent": "in this section , we report results on image-tosentence and sentence-to-image retrieval on the standard flickr30k datasets .", "tokens": ["in", "this", "section", ",", "we", "report", "results", "on", "image", "-", "tosentence", "and", "sentence", "-", "to", "-", "image", "retrieval", "on", "the", "standard", "flickr30k", "datasets", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "report", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "report", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 2671}, {"sent": "it consists of two linear layers with hidden relu nonlinearity in the middle .", "tokens": ["it", "consists", "of", "two", "linear", "layers", "with", "hidden", "relu", "nonlinearity", "in", "the", "middle", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "consists", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2672}, {"sent": "the position of the maximum does not depend on the inclination i .", "tokens": ["the", "position", "of", "the", "maximum", "does", "not", "depend", "on", "the", "inclination", "i", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the position of the maximum", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "does not depend", "start": 28, "end": 43, "i_start": 5, "i_end": 7}}, {"character": {"text": "position", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "not depend", "start": 33, "end": 43, "i_start": 6, "i_end": 7}}], "id": 2673}, {"sent": "deep neural networks have been successfully applied to many machine learning and statistical inference problems including speech recognition , natural language processing .", "tokens": ["deep", "neural", "networks", "have", "been", "successfully", "applied", "to", "many", "machine", "learning", "and", "statistical", "inference", "problems", "including", "speech", "recognition", ",", "natural", "language", "processing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "applied", "start": 44, "end": 51, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}], "id": 2674}, {"sent": "chirality is a multispin variable representing the handedness of the noncollinear or noncoplanar structures induced by frustration .", "tokens": ["chirality", "is", "a", "multispin", "variable", "representing", "the", "handedness", "of", "the", "noncollinear", "or", "noncoplanar", "structures", "induced", "by", "frustration", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "chirality", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "frustration", "start": 119, "end": 130, "i_start": 16, "i_end": 16}, "action": {"text": "induced", "start": 108, "end": 115, "i_start": 14, "i_end": 14}}], "id": 2675}, {"sent": "ledig et al propose srgan model that uses perceptual loss and adversarial loss to favor outputs residing on the manifold of natural images .", "tokens": ["ledig", "et", "al", "propose", "srgan", "model", "that", "uses", "perceptual", "loss", "and", "adversarial", "loss", "to", "favor", "outputs", "residing", "on", "the", "manifold", "of", "natural", "images", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "ledig", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "model", "start": 26, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "uses", "start": 37, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "outputs", "start": 88, "end": 95, "i_start": 15, "i_end": 15}, "action": {"text": "residing", "start": 96, "end": 104, "i_start": 16, "i_end": 16}}], "id": 2676}, {"sent": "deep learning has recently had a remarkable impact on multiple domains , including natural language processing and computer vision .", "tokens": ["deep", "learning", "has", "recently", "had", "a", "remarkable", "impact", "on", "multiple", "domains", ",", "including", "natural", "language", "processing", "and", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "had", "start": 27, "end": 30, "i_start": 4, "i_end": 4}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has", "start": 14, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "impact", "start": 44, "end": 50, "i_start": 7, "i_end": 7}}], "id": 2677}, {"sent": "an equivalence class of bases is called an orientation .", "tokens": ["an", "equivalence", "class", "of", "bases", "is", "called", "an", "orientation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an equivalence class of bases", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "is called", "start": 30, "end": 39, "i_start": 5, "i_end": 6}}], "id": 2678}, {"sent": "facility location is a well-studied problem in operations research that arises in contexts such as locating hospitals in a city or locating distribution centers in a region .", "tokens": ["facility", "location", "is", "a", "well", "-", "studied", "problem", "in", "operations", "research", "that", "arises", "in", "contexts", "such", "as", "locating", "hospitals", "in", "a", "city", "or", "locating", "distribution", "centers", "in", "a", "region", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "facility location", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}], "id": 2679}, {"sent": "similarly , for the packet-oriented schedulers , po weighted round robin achieves the highest throughput .", "tokens": ["similarly", ",", "for", "the", "packet", "-", "oriented", "schedulers", ",", "po", "weighted", "round", "robin", "achieves", "the", "highest", "throughput", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "po", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "verb": {"text": "weighted", "start": 52, "end": 60, "i_start": 10, "i_end": 10}}, {"subject": {"text": "round robin", "start": 61, "end": 72, "i_start": 11, "i_end": 12}, "verb": {"text": "achieves", "start": 73, "end": 81, "i_start": 13, "i_end": 13}}], "id": 2680}, {"sent": "the dotted and dashed lines represent the pure coulomb and pure nuclear contributions , respectively , while their coherent and incoherent sums are shown by the solid and dot-dashed lines , respectively .", "tokens": ["the", "dotted", "and", "dashed", "lines", "represent", "the", "pure", "coulomb", "and", "pure", "nuclear", "contributions", ",", "respectively", ",", "while", "their", "coherent", "and", "incoherent", "sums", "are", "shown", "by", "the", "solid", "and", "dot", "-", "dashed", "lines", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the dotted and dashed lines", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "represent", "start": 28, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "lines", "start": 22, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "represent", "start": 28, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "lines", "start": 182, "end": 187, "i_start": 31, "i_end": 31}, "action": {"text": "represent", "start": 28, "end": 37, "i_start": 5, "i_end": 5}}], "id": 2681}, {"sent": "zhu et al introduce the cyclegan framework , which achieves unpaired image-to-image translation using the cycle-consistency loss .", "tokens": ["zhu", "et", "al", "introduce", "the", "cyclegan", "framework", ",", "which", "achieves", "unpaired", "image", "-", "to", "-", "image", "translation", "using", "the", "cycle", "-", "consistency", "loss", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhu et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "introduce", "start": 10, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhu", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "introduce", "start": 10, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "framework", "start": 33, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "achieves", "start": 51, "end": 59, "i_start": 9, "i_end": 9}}], "id": 2682}, {"sent": "the bayesian optimization algorithm evolves a population of candidate solutions represented by fixed-length vectors over a finite alphabet .", "tokens": ["the", "bayesian", "optimization", "algorithm", "evolves", "a", "population", "of", "candidate", "solutions", "represented", "by", "fixed", "-", "length", "vectors", "over", "a", "finite", "alphabet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the bayesian optimization algorithm", "start": 0, "end": 35, "i_start": 0, "i_end": 3}, "verb": {"text": "evolves", "start": 36, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "algorithm", "start": 26, "end": 35, "i_start": 3, "i_end": 3}, "action": {"text": "evolves", "start": 36, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "vectors", "start": 108, "end": 115, "i_start": 15, "i_end": 15}, "action": {"text": "represented", "start": 80, "end": 91, "i_start": 10, "i_end": 10}}], "id": 2683}, {"sent": "deep learning models have achieved remarkable success in computer vision .", "tokens": ["deep", "learning", "models", "have", "achieved", "remarkable", "success", "in", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning models", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "models", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "models", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "models", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 46, "end": 53, "i_start": 6, "i_end": 6}}], "id": 2684}, {"sent": "convolutional neural networks have achieved state-of-the-art accuracy in computer vision tasks such as image recognition .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "accuracy", "in", "computer", "vision", "tasks", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 2685}, {"sent": "we train the default caffe model of alexnet on the imagenet dataset .", "tokens": ["we", "train", "the", "default", "caffe", "model", "of", "alexnet", "on", "the", "imagenet", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2686}, {"sent": "it is easy to see that the closed string solution are not g-invariant .", "tokens": ["it", "is", "easy", "to", "see", "that", "the", "closed", "string", "solution", "are", "not", "g", "-", "invariant", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}], "id": 2687}, {"sent": "deep features learned from convolutional neural networks have recently been applied to numerous vision problems .", "tokens": ["deep", "features", "learned", "from", "convolutional", "neural", "networks", "have", "recently", "been", "applied", "to", "numerous", "vision", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep features learned from convolutional neural networks", "start": 0, "end": 56, "i_start": 0, "i_end": 6}, "verb": {"text": "been applied", "start": 71, "end": 83, "i_start": 9, "i_end": 10}}, {"subject": {"text": "deep features learned from convolutional neural networks", "start": 0, "end": 56, "i_start": 0, "i_end": 6}, "verb": {"text": "have", "start": 57, "end": 61, "i_start": 7, "i_end": 7}}], "id": 2688}, {"sent": "deep convolutional neural networks have been proven very useful in various tasks in computer vision including classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "proven", "very", "useful", "in", "various", "tasks", "in", "computer", "vision", "including", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been proven", "start": 35, "end": 51, "i_start": 4, "i_end": 6}}], "id": 2689}, {"sent": "we refer the reader to vaswani et al for more details on the model architecture .", "tokens": ["we", "refer", "the", "reader", "to", "vaswani", "et", "al", "for", "more", "details", "on", "the", "model", "architecture", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2690}, {"sent": "nuclear relaxation during electron transmission .", "tokens": ["nuclear", "relaxation", "during", "electron", "transmission", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2691}, {"sent": "let us assume on the contrary that the hyperelliptic involution of the quotient modulo \u03c3 has real fixed points .", "tokens": ["let", "us", "assume", "on", "the", "contrary", "that", "the", "hyperelliptic", "involution", "of", "the", "quotient", "modulo", "\u03c3", "has", "real", "fixed", "points", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "assume", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "assume", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}], "id": 2692}, {"sent": "the spacetime is a product r1,1 is a compact spin turn implies that locally manifold .", "tokens": ["the", "spacetime", "is", "a", "product", "r1,1", "is", "a", "compact", "spin", "turn", "implies", "that", "locally", "manifold", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the spacetime", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the spacetime", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "implies", "start": 55, "end": 62, "i_start": 11, "i_end": 11}}, {"character": {"text": "turn", "start": 50, "end": 54, "i_start": 10, "i_end": 10}, "action": {"text": "implies", "start": 55, "end": 62, "i_start": 11, "i_end": 11}}], "id": 2693}, {"sent": "the soliton is the unique lowest mass solution for all spacetimes in its class .", "tokens": ["the", "soliton", "is", "the", "unique", "lowest", "mass", "solution", "for", "all", "spacetimes", "in", "its", "class", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the soliton", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 2694}, {"sent": "we mainly will use the latter formulation , which is called euclidean quantum field theory .", "tokens": ["we", "mainly", "will", "use", "the", "latter", "formulation", ",", "which", "is", "called", "euclidean", "quantum", "field", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will use", "start": 10, "end": 18, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 15, "end": 18, "i_start": 3, "i_end": 3}}], "id": 2695}, {"sent": "the local dephasing rates that optimizes the transfer efficiency are given by numerical simulation .", "tokens": ["the", "local", "dephasing", "rates", "that", "optimizes", "the", "transfer", "efficiency", "are", "given", "by", "numerical", "simulation", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the local dephasing rates that optimizes the transfer efficiency", "start": 0, "end": 64, "i_start": 0, "i_end": 8}, "verb": {"text": "are given", "start": 65, "end": 74, "i_start": 9, "i_end": 10}}, {"character": {"text": "rates", "start": 20, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "optimizes", "start": 31, "end": 40, "i_start": 5, "i_end": 5}}], "id": 2696}, {"sent": "moreover , in traditional multi-view geometry , multiple cameras in different poses are defined as a set of unconstrained rays , which is known as as generalized camera model .", "tokens": ["moreover", ",", "in", "traditional", "multi", "-", "view", "geometry", ",", "multiple", "cameras", "in", "different", "poses", "are", "defined", "as", "a", "set", "of", "unconstrained", "rays", ",", "which", "is", "known", "as", "as", "generalized", "camera", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "multiple cameras in different poses", "start": 48, "end": 83, "i_start": 9, "i_end": 13}, "verb": {"text": "are defined", "start": 84, "end": 95, "i_start": 14, "i_end": 15}}], "id": 2697}, {"sent": "this allows us to constrain the ir behavior of supersymmetric field theories .", "tokens": ["this", "allows", "us", "to", "constrain", "the", "ir", "behavior", "of", "supersymmetric", "field", "theories", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "allows", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}, {"subject": {"text": "us", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "constrain", "start": 18, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "allows", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "us", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "constrain", "start": 18, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "theories", "start": 68, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "behavior", "start": 35, "end": 43, "i_start": 7, "i_end": 7}}], "id": 2698}, {"sent": "finite-tree analysis for constraint logic-based languages .", "tokens": ["finite", "-", "tree", "analysis", "for", "constraint", "logic", "-", "based", "languages", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "logic", "start": 36, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "constraint", "start": 25, "end": 35, "i_start": 5, "i_end": 5}}], "id": 2699}, {"sent": "it is well known that it is possible to measure only the intensity of the scattered wave at such huge frequencies , whereas the phase can not be measured .", "tokens": ["it", "is", "well", "known", "that", "it", "is", "possible", "to", "measure", "only", "the", "intensity", "of", "the", "scattered", "wave", "at", "such", "huge", "frequencies", ",", "whereas", "the", "phase", "can", "not", "be", "measured", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}], "id": 2700}, {"sent": "t h e o u t p u t group was further drawing inspiration from biological neurons to implement machine learning was the topic of the first paper presented at the first machine learning conference in 1955 .", "tokens": ["t", "h", "e", "o", "u", "t", "p", "u", "t", "group", "was", "further", "drawing", "inspiration", "from", "biological", "neurons", "to", "implement", "machine", "learning", "was", "the", "topic", "of", "the", "first", "paper", "presented", "at", "the", "first", "machine", "learning", "conference", "in", "1955", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "t h e o u t p u t group was further drawing inspiration from biological neurons to implement machine learning", "start": 0, "end": 109, "i_start": 0, "i_end": 20}, "verb": {"text": "was", "start": 110, "end": 113, "i_start": 21, "i_end": 21}}, {"character": {"text": "group", "start": 18, "end": 23, "i_start": 9, "i_end": 9}, "action": {"text": "inspiration", "start": 44, "end": 55, "i_start": 13, "i_end": 13}}, {"character": {"text": "group", "start": 18, "end": 23, "i_start": 9, "i_end": 9}, "action": {"text": "implement", "start": 83, "end": 92, "i_start": 18, "i_end": 18}}], "id": 2701}, {"sent": "we say that the polyhedron is a realization of the cell decomposition .", "tokens": ["we", "say", "that", "the", "polyhedron", "is", "a", "realization", "of", "the", "cell", "decomposition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "say", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "say", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 2702}, {"sent": "generative adversarial networks are an innovative technique for training generative models to produce realistic examples from a data distribution .", "tokens": ["generative", "adversarial", "networks", "are", "an", "innovative", "technique", "for", "training", "generative", "models", "to", "produce", "realistic", "examples", "from", "a", "data", "distribution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 84, "end": 90, "i_start": 10, "i_end": 10}, "action": {"text": "produce", "start": 94, "end": 101, "i_start": 12, "i_end": 12}}], "id": 2703}, {"sent": "every node runs the redhat federo core 6 linux with the kprobe feature enabled .", "tokens": ["every", "node", "runs", "the", "redhat", "federo", "core", "6", "linux", "with", "the", "kprobe", "feature", "enabled", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "every node", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "runs", "start": 11, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "node", "start": 6, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "runs", "start": 11, "end": 15, "i_start": 2, "i_end": 2}}], "id": 2704}, {"sent": "convolutional neural networks have achieved tremendous progress on many pattern recognition tasks , especially large-scale images recognition problems .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "tremendous", "progress", "on", "many", "pattern", "recognition", "tasks", ",", "especially", "large", "-", "scale", "images", "recognition", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 2705}, {"sent": "recent works show that neural networks are vulnerable to adversarial examples , even though the perturbations to data are imperceptible to human eyes .", "tokens": ["recent", "works", "show", "that", "neural", "networks", "are", "vulnerable", "to", "adversarial", "examples", ",", "even", "though", "the", "perturbations", "to", "data", "are", "imperceptible", "to", "human", "eyes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent works", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "show", "start": 13, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "recent works", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 39, "end": 42, "i_start": 6, "i_end": 6}}, {"character": {"text": "works", "start": 7, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 13, "end": 17, "i_start": 2, "i_end": 2}}], "id": 2706}, {"sent": "conversely any torsion-free finitely generated nilpotent group \u03b3 can be embedded in a simply connected nilpotent lie group n whose lie algebra n admits a q-structure n q .", "tokens": ["conversely", "any", "torsion", "-", "free", "finitely", "generated", "nilpotent", "group", "\u03b3", "can", "be", "embedded", "in", "a", "simply", "connected", "nilpotent", "lie", "group", "n", "whose", "lie", "algebra", "n", "admits", "a", "q", "-", "structure", "n", "q", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "conversely any torsion-free finitely generated nilpotent group \u03b3", "start": 0, "end": 64, "i_start": 0, "i_end": 9}, "verb": {"text": "can be embedded", "start": 65, "end": 80, "i_start": 10, "i_end": 12}}, {"subject": {"text": "conversely any torsion-free finitely generated nilpotent group \u03b3", "start": 0, "end": 64, "i_start": 0, "i_end": 9}, "verb": {"text": "admits", "start": 145, "end": 151, "i_start": 25, "i_end": 25}}, {"character": {"text": "algebra", "start": 135, "end": 142, "i_start": 23, "i_end": 23}, "action": {"text": "admits", "start": 145, "end": 151, "i_start": 25, "i_end": 25}}], "id": 2707}, {"sent": "deep neural networks have demonstrated significant performance improvements in a wide range of computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "significant", "performance", "improvements", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improvements", "start": 63, "end": 75, "i_start": 7, "i_end": 7}}], "id": 2708}, {"sent": "massive mimo millimeterwave systems have recently emerged as the main key player in the future wireless networks .", "tokens": ["massive", "mimo", "millimeterwave", "systems", "have", "recently", "emerged", "as", "the", "main", "key", "player", "in", "the", "future", "wireless", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "massive mimo millimeterwave systems", "start": 0, "end": 35, "i_start": 0, "i_end": 3}, "verb": {"text": "emerged", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}, {"subject": {"text": "massive mimo millimeterwave systems", "start": 0, "end": 35, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 36, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "systems", "start": 28, "end": 35, "i_start": 3, "i_end": 3}, "action": {"text": "emerged", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}, {"character": {"text": "systems", "start": 28, "end": 35, "i_start": 3, "i_end": 3}, "action": {"text": "player", "start": 74, "end": 80, "i_start": 11, "i_end": 11}}], "id": 2709}, {"sent": "we are now concerned with explicit continuous families of hypercomplex struc tures which are non-abelian .", "tokens": ["we", "are", "now", "concerned", "with", "explicit", "continuous", "families", "of", "hypercomplex", "struc", "tures", "which", "are", "non", "-", "abelian", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "families", "start": 46, "end": 54, "i_start": 7, "i_end": 7}, "action": {"text": "concerned", "start": 11, "end": 20, "i_start": 3, "i_end": 3}}], "id": 2710}, {"sent": "when the orbit is a collection of line segments , such an unfolding will be a straight line .", "tokens": ["when", "the", "orbit", "is", "a", "collection", "of", "line", "segments", ",", "such", "an", "unfolding", "will", "be", "a", "straight", "line", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "such an unfolding", "start": 50, "end": 67, "i_start": 10, "i_end": 12}, "verb": {"text": "will be", "start": 68, "end": 75, "i_start": 13, "i_end": 14}}], "id": 2711}, {"sent": "convolutional neural networks have recently been applied to various computer vision tasks such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "been", "applied", "to", "various", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "been applied", "start": 44, "end": 56, "i_start": 5, "i_end": 6}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}], "id": 2712}, {"sent": "scale invariant feature transform was used in conjunction with bag of words to recognize adult images in .", "tokens": ["scale", "invariant", "feature", "transform", "was", "used", "in", "conjunction", "with", "bag", "of", "words", "to", "recognize", "adult", "images", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "scale invariant feature transform", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "was used", "start": 34, "end": 42, "i_start": 4, "i_end": 5}}], "id": 2713}, {"sent": "here , pentaquark is considered to consist of five quarks .", "tokens": ["here", ",", "pentaquark", "is", "considered", "to", "consist", "of", "five", "quarks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "pentaquark", "start": 7, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "is considered", "start": 18, "end": 31, "i_start": 3, "i_end": 4}}], "id": 2714}, {"sent": "transfer learning is a new and effective learning framework to address this problem .", "tokens": ["transfer", "learning", "is", "a", "new", "and", "effective", "learning", "framework", "to", "address", "this", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "transfer learning", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "framework", "start": 50, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "effective", "start": 31, "end": 40, "i_start": 6, "i_end": 6}}], "id": 2715}, {"sent": "sparse signal reconstruction has been an active research area for the past few years due to the emergence of compressed sensing as a new sub-nyquist sampling paradigm .", "tokens": ["sparse", "signal", "reconstruction", "has", "been", "an", "active", "research", "area", "for", "the", "past", "few", "years", "due", "to", "the", "emergence", "of", "compressed", "sensing", "as", "a", "new", "sub", "-", "nyquist", "sampling", "paradigm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "sparse signal reconstruction", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "has been", "start": 29, "end": 37, "i_start": 3, "i_end": 4}}, {"character": {"text": "sensing", "start": 120, "end": 127, "i_start": 20, "i_end": 20}, "action": {"text": "emergence", "start": 96, "end": 105, "i_start": 17, "i_end": 17}}], "id": 2716}, {"sent": "the phase space consists of m such unit cells side by side .", "tokens": ["the", "phase", "space", "consists", "of", "m", "such", "unit", "cells", "side", "by", "side", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the phase space", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2717}, {"sent": "in , it is shown that the capacity achieving input distribution of an awgn channel under average , peak and delivered power constraints is discrete in amplitude with a finite number of mass-points and with a uniformly distributed independent phase .", "tokens": ["in", ",", "it", "is", "shown", "that", "the", "capacity", "achieving", "input", "distribution", "of", "an", "awgn", "channel", "under", "average", ",", "peak", "and", "delivered", "power", "constraints", "is", "discrete", "in", "amplitude", "with", "a", "finite", "number", "of", "mass", "-", "points", "and", "with", "a", "uniformly", "distributed", "independent", "phase", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "verb": {"text": "is shown", "start": 8, "end": 16, "i_start": 3, "i_end": 4}}, {"subject": {"text": "it", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 136, "end": 138, "i_start": 23, "i_end": 23}}, {"character": {"text": "capacity", "start": 26, "end": 34, "i_start": 7, "i_end": 7}, "action": {"text": "achieving", "start": 35, "end": 44, "i_start": 8, "i_end": 8}}, {"character": {"text": "phase", "start": 242, "end": 247, "i_start": 41, "i_end": 41}, "action": {"text": "-points and with a uniformly distributed independent", "start": 189, "end": 241, "i_start": 33, "i_end": 40}}], "id": 2718}, {"sent": "we train a logistic regression model with l2 regularization , implemented with the python scikitlearn package .", "tokens": ["we", "train", "a", "logistic", "regression", "model", "with", "l2", "regularization", ",", "implemented", "with", "the", "python", "scikitlearn", "package", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implemented", "start": 62, "end": 73, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2719}, {"sent": "over the past few years , neural networks has been widely used in some domains , such as large vocabulary continuous speech recognition .", "tokens": ["over", "the", "past", "few", "years", ",", "neural", "networks", "has", "been", "widely", "used", "in", "some", "domains", ",", "such", "as", "large", "vocabulary", "continuous", "speech", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 26, "end": 41, "i_start": 6, "i_end": 7}, "verb": {"text": "used", "start": 58, "end": 62, "i_start": 11, "i_end": 11}}, {"subject": {"text": "neural networks", "start": 26, "end": 41, "i_start": 6, "i_end": 7}, "verb": {"text": "has been", "start": 42, "end": 50, "i_start": 8, "i_end": 9}}], "id": 2720}, {"sent": "recent work by hardt et al shows that the convergence rate of stochastic gradient methods have implications for generalization bounds in both convex and nonconvex settings .", "tokens": ["recent", "work", "by", "hardt", "et", "al", "shows", "that", "the", "convergence", "rate", "of", "stochastic", "gradient", "methods", "have", "implications", "for", "generalization", "bounds", "in", "both", "convex", "and", "nonconvex", "settings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent work by hardt et al", "start": 0, "end": 26, "i_start": 0, "i_end": 5}, "verb": {"text": "shows", "start": 27, "end": 32, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the convergence rate of stochastic gradient methods", "start": 38, "end": 89, "i_start": 8, "i_end": 14}, "verb": {"text": "have", "start": 90, "end": 94, "i_start": 15, "i_end": 15}}, {"character": {"text": "work", "start": 7, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "shows", "start": 27, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "hardt", "start": 15, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "work", "start": 7, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "rate", "start": 54, "end": 58, "i_start": 10, "i_end": 10}, "action": {"text": "implications", "start": 95, "end": 107, "i_start": 16, "i_end": 16}}], "id": 2721}, {"sent": "deep neural networks have shown great success in computer vision and natural language processing tasks .", "tokens": ["deep", "neural", "networks", "have", "shown", "great", "success", "in", "computer", "vision", "and", "natural", "language", "processing", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 38, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "processing", "start": 86, "end": 96, "i_start": 13, "i_end": 13}}], "id": 2722}, {"sent": "each layer consists of a linear transformation , followed by a batch normalization .", "tokens": ["each", "layer", "consists", "of", "a", "linear", "transformation", ",", "followed", "by", "a", "batch", "normalization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each layer", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}], "id": 2723}, {"sent": "correct localization is to test our model on the training set measuring the localization accuracy .", "tokens": ["correct", "localization", "is", "to", "test", "our", "model", "on", "the", "training", "set", "measuring", "the", "localization", "accuracy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "correct localization", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "set", "start": 58, "end": 61, "i_start": 10, "i_end": 10}, "action": {"text": "measuring", "start": 62, "end": 71, "i_start": 11, "i_end": 11}}], "id": 2724}, {"sent": "convolutional neural networks have been instrumental to the recent breakthroughs in computer vision .", "tokens": ["convolutional", "neural", "networks", "have", "been", "instrumental", "to", "the", "recent", "breakthroughs", "in", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}], "id": 2725}, {"sent": "to validate the advantages of our proposed model , we compared it with 11 methods , including mtds .", "tokens": ["to", "validate", "the", "advantages", "of", "our", "proposed", "model", ",", "we", "compared", "it", "with", "11", "methods", ",", "including", "mtds", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 51, "end": 53, "i_start": 9, "i_end": 9}, "verb": {"text": "compared", "start": 54, "end": 62, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 9, "i_end": 9}, "action": {"text": "compared", "start": 54, "end": 62, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 9, "i_end": 9}, "action": {"text": "proposed", "start": 34, "end": 42, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 9, "i_end": 9}, "action": {"text": "validate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2726}, {"sent": "methods like variational auto-encoders and generative adversarial networks have found success at modeling data distributions .", "tokens": ["methods", "like", "variational", "auto", "-", "encoders", "and", "generative", "adversarial", "networks", "have", "found", "success", "at", "modeling", "data", "distributions", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "methods like variational auto-encoders and generative adversarial networks", "start": 0, "end": 74, "i_start": 0, "i_end": 9}, "verb": {"text": "have found", "start": 75, "end": 85, "i_start": 10, "i_end": 11}}, {"character": {"text": "methods", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "success", "start": 86, "end": 93, "i_start": 12, "i_end": 12}}], "id": 2727}, {"sent": "we only prove the first statement , since the second one is an immediate consequence .", "tokens": ["we", "only", "prove", "the", "first", "statement", ",", "since", "the", "second", "one", "is", "an", "immediate", "consequence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "prove", "start": 8, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "prove", "start": 8, "end": 13, "i_start": 2, "i_end": 2}}], "id": 2728}, {"sent": "in conclusion , this execution satisfies the weakly fair scheduling .", "tokens": ["in", "conclusion", ",", "this", "execution", "satisfies", "the", "weakly", "fair", "scheduling", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this execution", "start": 16, "end": 30, "i_start": 3, "i_end": 4}, "verb": {"text": "satisfies", "start": 31, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "execution", "start": 21, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "satisfies", "start": 31, "end": 40, "i_start": 5, "i_end": 5}}], "id": 2729}, {"sent": "since it is difficult to acquire the full knowledge of each rb state , the mtcd needs to observe the rb state based on the state transition and optimal action taken in this time slot .", "tokens": ["since", "it", "is", "difficult", "to", "acquire", "the", "full", "knowledge", "of", "each", "rb", "state", ",", "the", "mtcd", "needs", "to", "observe", "the", "rb", "state", "based", "on", "the", "state", "transition", "and", "optimal", "action", "taken", "in", "this", "time", "slot", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the mtcd", "start": 71, "end": 79, "i_start": 14, "i_end": 15}, "verb": {"text": "needs", "start": 80, "end": 85, "i_start": 16, "i_end": 16}}, {"character": {"text": "state", "start": 63, "end": 68, "i_start": 12, "i_end": 12}, "action": {"text": "knowledge", "start": 42, "end": 51, "i_start": 8, "i_end": 8}}], "id": 2730}, {"sent": "we adopt the generalized gradient approximation of perdew , burke , and ernzerhof exchange-correlation functional .", "tokens": ["we", "adopt", "the", "generalized", "gradient", "approximation", "of", "perdew", ",", "burke", ",", "and", "ernzerhof", "exchange", "-", "correlation", "functional", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "perdew", "start": 51, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "functional", "start": 103, "end": 113, "i_start": 16, "i_end": 16}}, {"character": {"text": "burke", "start": 60, "end": 65, "i_start": 9, "i_end": 9}, "action": {"text": "functional", "start": 103, "end": 113, "i_start": 16, "i_end": 16}}, {"character": {"text": "ernzerhof", "start": 72, "end": 81, "i_start": 12, "i_end": 12}, "action": {"text": "functional", "start": 103, "end": 113, "i_start": 16, "i_end": 16}}], "id": 2731}, {"sent": "the proposed method is compared with five state-of-theart multimodal hashing methods cmssh .", "tokens": ["the", "proposed", "method", "is", "compared", "with", "five", "state", "-", "of", "-", "theart", "multimodal", "hashing", "methods", "cmssh", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the proposed method", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is compared", "start": 20, "end": 31, "i_start": 3, "i_end": 4}}], "id": 2732}, {"sent": "recently , inspired by the success of convolutional neural networks in many computer vision problems , deep cnn architectures have been widely used for person re-id .", "tokens": ["recently", ",", "inspired", "by", "the", "success", "of", "convolutional", "neural", "networks", "in", "many", "computer", "vision", "problems", ",", "deep", "cnn", "architectures", "have", "been", "widely", "used", "for", "person", "re", "-", "id", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "deep cnn architectures", "start": 103, "end": 125, "i_start": 16, "i_end": 18}, "verb": {"text": "used", "start": 143, "end": 147, "i_start": 22, "i_end": 22}}, {"subject": {"text": "deep cnn architectures", "start": 103, "end": 125, "i_start": 16, "i_end": 18}, "verb": {"text": "have been", "start": 126, "end": 135, "i_start": 19, "i_end": 20}}, {"character": {"text": "success", "start": 27, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "inspired", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}], "id": 2733}, {"sent": "furthermore , we showed that localized ph heterogeneities can induce local dynamical membrane deformations and developed a theoretical description of this phenomenon .", "tokens": ["furthermore", ",", "we", "showed", "that", "localized", "ph", "heterogeneities", "can", "induce", "local", "dynamical", "membrane", "deformations", "and", "developed", "a", "theoretical", "description", "of", "this", "phenomenon", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "showed", "start": 17, "end": 23, "i_start": 3, "i_end": 3}}, {"subject": {"text": "localized ph heterogeneities", "start": 29, "end": 57, "i_start": 5, "i_end": 7}, "verb": {"text": "induce", "start": 62, "end": 68, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "showed", "start": 17, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "heterogeneities", "start": 42, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "induce", "start": 62, "end": 68, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "developed", "start": 111, "end": 120, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "description", "start": 135, "end": 146, "i_start": 18, "i_end": 18}}], "id": 2734}, {"sent": "in particular we prove the following result .", "tokens": ["in", "particular", "we", "prove", "the", "following", "result", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "prove", "start": 17, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "prove", "start": 17, "end": 22, "i_start": 3, "i_end": 3}}], "id": 2735}, {"sent": "these systems are commonly described theoretically in the framework of the tomonaga-luttinger liquid theory .", "tokens": ["these", "systems", "are", "commonly", "described", "theoretically", "in", "the", "framework", "of", "the", "tomonaga", "-", "luttinger", "liquid", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these systems", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "described", "start": 27, "end": 36, "i_start": 4, "i_end": 4}}, {"subject": {"text": "these systems", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 14, "end": 17, "i_start": 2, "i_end": 2}}], "id": 2736}, {"sent": "since the number of string oscillatory states increases exponentially with energy , there is a limiting temperature for a gas of strings in thermal equilibrium , the hagedorn temperature t h .", "tokens": ["since", "the", "number", "of", "string", "oscillatory", "states", "increases", "exponentially", "with", "energy", ",", "there", "is", "a", "limiting", "temperature", "for", "a", "gas", "of", "strings", "in", "thermal", "equilibrium", ",", "the", "hagedorn", "temperature", "t", "h", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "there", "start": 84, "end": 89, "i_start": 12, "i_end": 12}, "verb": {"text": "is", "start": 90, "end": 92, "i_start": 13, "i_end": 13}}, {"character": {"text": "states", "start": 39, "end": 45, "i_start": 6, "i_end": 6}, "action": {"text": "oscillatory", "start": 27, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "temperature", "start": 104, "end": 115, "i_start": 16, "i_end": 16}, "action": {"text": "limiting", "start": 95, "end": 103, "i_start": 15, "i_end": 15}}], "id": 2737}, {"sent": "when the size of aq is large , the cse algorithm in requires a lot of time and memory so that it becomes impractical .", "tokens": ["when", "the", "size", "of", "aq", "is", "large", ",", "the", "cse", "algorithm", "in", "requires", "a", "lot", "of", "time", "and", "memory", "so", "that", "it", "becomes", "impractical", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the cse algorithm", "start": 31, "end": 48, "i_start": 8, "i_end": 10}, "verb": {"text": "requires", "start": 52, "end": 60, "i_start": 12, "i_end": 12}}, {"character": {"text": "algorithm", "start": 39, "end": 48, "i_start": 10, "i_end": 10}, "action": {"text": "requires", "start": 52, "end": 60, "i_start": 12, "i_end": 12}}], "id": 2738}, {"sent": "more recently , lavaei and low have shown that a semidefinite programming relaxation produces global optima in some cases .", "tokens": ["more", "recently", ",", "lavaei", "and", "low", "have", "shown", "that", "a", "semidefinite", "programming", "relaxation", "produces", "global", "optima", "in", "some", "cases", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a semidefinite programming relaxation", "start": 47, "end": 84, "i_start": 9, "i_end": 12}, "verb": {"text": "have shown", "start": 31, "end": 41, "i_start": 6, "i_end": 7}}, {"subject": {"text": "a semidefinite programming relaxation", "start": 47, "end": 84, "i_start": 9, "i_end": 12}, "verb": {"text": "produces", "start": 85, "end": 93, "i_start": 13, "i_end": 13}}, {"character": {"text": "low", "start": 27, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "shown", "start": 36, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "relaxation", "start": 74, "end": 84, "i_start": 12, "i_end": 12}, "action": {"text": "produces", "start": 85, "end": 93, "i_start": 13, "i_end": 13}}], "id": 2739}, {"sent": "boxler , use the same separation of time scales that underlies the application of centre manifolds to form and support low-dimensional , long time models of sdes and spdes that have both fast and slow modes .", "tokens": ["boxler", ",", "use", "the", "same", "separation", "of", "time", "scales", "that", "underlies", "the", "application", "of", "centre", "manifolds", "to", "form", "and", "support", "low", "-", "dimensional", ",", "long", "time", "models", "of", "sdes", "and", "spdes", "that", "have", "both", "fast", "and", "slow", "modes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "boxler", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 9, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "boxler", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 9, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "models", "start": 147, "end": 153, "i_start": 26, "i_end": 26}, "action": {"text": "have", "start": 177, "end": 181, "i_start": 32, "i_end": 32}}], "id": 2740}, {"sent": "with the success of deep learning , convolutional neural network has been applied successfully in this domain .", "tokens": ["with", "the", "success", "of", "deep", "learning", ",", "convolutional", "neural", "network", "has", "been", "applied", "successfully", "in", "this", "domain", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural network", "start": 36, "end": 64, "i_start": 7, "i_end": 9}, "verb": {"text": "has been applied", "start": 65, "end": 81, "i_start": 10, "i_end": 12}}, {"character": {"text": "learning", "start": 25, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "successfully", "start": 82, "end": 94, "i_start": 13, "i_end": 13}}], "id": 2741}, {"sent": "thus , the phase space consists of pairs of fields with the symplectic structure .", "tokens": ["thus", ",", "the", "phase", "space", "consists", "of", "pairs", "of", "fields", "with", "the", "symplectic", "structure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the phase space", "start": 7, "end": 22, "i_start": 2, "i_end": 4}, "verb": {"text": "consists", "start": 23, "end": 31, "i_start": 5, "i_end": 5}}], "id": 2742}, {"sent": "let us denote by top the category of topological spaces , and by sober the full subcategory of top whose objects are the sober topological spaces .", "tokens": ["let", "us", "denote", "by", "top", "the", "category", "of", "topological", "spaces", ",", "and", "by", "sober", "the", "full", "subcategory", "of", "top", "whose", "objects", "are", "the", "sober", "topological", "spaces", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "denote", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}], "id": 2743}, {"sent": "rl algorithms can be broadly classified into model-free and model-based .", "tokens": ["rl", "algorithms", "can", "be", "broadly", "classified", "into", "model", "-", "free", "and", "model", "-", "based", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "rl algorithms", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "classified", "start": 29, "end": 39, "i_start": 5, "i_end": 5}}, {"subject": {"text": "rl algorithms", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "can be", "start": 14, "end": 20, "i_start": 2, "i_end": 3}}], "id": 2744}, {"sent": "another significant feature is the channel bonding , which increases the channel bandwidth from 20 mhz to 40 mhz and thus doubles the theoretical capacity limits .", "tokens": ["another", "significant", "feature", "is", "the", "channel", "bonding", ",", "which", "increases", "the", "channel", "bandwidth", "from", "20", "mhz", "to", "40", "mhz", "and", "thus", "doubles", "the", "theoretical", "capacity", "limits", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another significant feature", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "bonding", "start": 43, "end": 50, "i_start": 6, "i_end": 6}, "action": {"text": "increases", "start": 59, "end": 68, "i_start": 9, "i_end": 9}}], "id": 2745}, {"sent": "we adopt a simple picture that was first conceived by fuchs 70 and afterwards widely used in the study of for instance anomalous skin effect 71 , 73 , 74 .", "tokens": ["we", "adopt", "a", "simple", "picture", "that", "was", "first", "conceived", "by", "fuchs", "70", "and", "afterwards", "widely", "used", "in", "the", "study", "of", "for", "instance", "anomalous", "skin", "effect", "71", ",", "73", ",", "74", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "fuchs", "start": 54, "end": 59, "i_start": 10, "i_end": 10}, "action": {"text": "conceived", "start": 41, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "70", "start": 60, "end": 62, "i_start": 11, "i_end": 11}, "action": {"text": "conceived", "start": 41, "end": 50, "i_start": 8, "i_end": 8}}], "id": 2746}, {"sent": "recurrent neural networks have regained interest recently , achieving competitive results in the areas of natural language processing .", "tokens": ["recurrent", "neural", "networks", "have", "regained", "interest", "recently", ",", "achieving", "competitive", "results", "in", "the", "areas", "of", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recurrent neural networks", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "have regained", "start": 26, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 17, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "regained", "start": 31, "end": 39, "i_start": 4, "i_end": 4}}], "id": 2747}, {"sent": "gliese 570d because it is a companion to a well-studied main sequence star , gl 570d has the most precisely determined physical parameters of any t dwarf to date .", "tokens": ["gliese", "570d", "because", "it", "is", "a", "companion", "to", "a", "well", "-", "studied", "main", "sequence", "star", ",", "gl", "570d", "has", "the", "most", "precisely", "determined", "physical", "parameters", "of", "any", "t", "dwarf", "to", "date", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "gliese 570d because it is a companion to a well-studied main sequence star , gl 570d", "start": 0, "end": 84, "i_start": 0, "i_end": 17}, "verb": {"text": "has", "start": 85, "end": 88, "i_start": 18, "i_end": 18}}, {"character": {"text": "has", "start": 85, "end": 88, "i_start": 18, "i_end": 18}, "action": {"text": "because", "start": 12, "end": 19, "i_start": 2, "i_end": 2}}], "id": 2748}, {"sent": "performing two inverse fourier transforms yields the sought waveforms of acoustic response in the time-space domain .", "tokens": ["performing", "two", "inverse", "fourier", "transforms", "yields", "the", "sought", "waveforms", "of", "acoustic", "response", "in", "the", "time", "-", "space", "domain", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "performing two inverse fourier", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "transforms", "start": 31, "end": 41, "i_start": 4, "i_end": 4}}, {"character": {"text": "performing", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "yields", "start": 42, "end": 48, "i_start": 5, "i_end": 5}}], "id": 2749}, {"sent": "assume the induced map is a cofibration too .", "tokens": ["assume", "the", "induced", "map", "is", "a", "cofibration", "too", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2750}, {"sent": "the em algorithm provides a broad framework for maximum likelihood estimation in the presence of missing data .", "tokens": ["the", "em", "algorithm", "provides", "a", "broad", "framework", "for", "maximum", "likelihood", "estimation", "in", "the", "presence", "of", "missing", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the em algorithm", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "provides", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithm", "start": 7, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "provides", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}], "id": 2751}, {"sent": "for higher values the coupling minimum of the minimum of the potential tends to disappear .", "tokens": ["for", "higher", "values", "the", "coupling", "minimum", "of", "the", "minimum", "of", "the", "potential", "tends", "to", "disappear", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the coupling minimum of the minimum of the potential", "start": 18, "end": 70, "i_start": 3, "i_end": 11}, "verb": {"text": "tends", "start": 71, "end": 76, "i_start": 12, "i_end": 12}}], "id": 2752}, {"sent": "radio emission is a powerful way to investigate such sources , through radio morphology and the implications made by source energy and lifetimes derived from the radio .", "tokens": ["radio", "emission", "is", "a", "powerful", "way", "to", "investigate", "such", "sources", ",", "through", "radio", "morphology", "and", "the", "implications", "made", "by", "source", "energy", "and", "lifetimes", "derived", "from", "the", "radio", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "radio emission", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "energy", "start": 124, "end": 130, "i_start": 20, "i_end": 20}, "action": {"text": "implications", "start": 96, "end": 108, "i_start": 16, "i_end": 16}}, {"character": {"text": "source", "start": 117, "end": 123, "i_start": 19, "i_end": 19}, "action": {"text": "implications", "start": 96, "end": 108, "i_start": 16, "i_end": 16}}, {"character": {"text": "lifetimes", "start": 135, "end": 144, "i_start": 22, "i_end": 22}, "action": {"text": "implications", "start": 96, "end": 108, "i_start": 16, "i_end": 16}}], "id": 2753}, {"sent": "moreover we include reproducing kernel spaces which can be considered as an abstract version of the bargmann-fock representation .", "tokens": ["moreover", "we", "include", "reproducing", "kernel", "spaces", "which", "can", "be", "considered", "as", "an", "abstract", "version", "of", "the", "bargmann", "-", "fock", "representation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 9, "end": 11, "i_start": 1, "i_end": 1}, "verb": {"text": "include", "start": 12, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 9, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "include", "start": 12, "end": 19, "i_start": 2, "i_end": 2}}], "id": 2754}, {"sent": "the missing ingredient is the quasigeodesic property of these pseudo-anosov flows which is needed to apply the main theorem .", "tokens": ["the", "missing", "ingredient", "is", "the", "quasigeodesic", "property", "of", "these", "pseudo", "-", "anosov", "flows", "which", "is", "needed", "to", "apply", "the", "main", "theorem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the missing ingredient", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}], "id": 2755}, {"sent": "the galactocentric distances in kpc of each field are labeled on the top-left corner .", "tokens": ["the", "galactocentric", "distances", "in", "kpc", "of", "each", "field", "are", "labeled", "on", "the", "top", "-", "left", "corner", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the galactocentric distances in kpc of each field", "start": 0, "end": 49, "i_start": 0, "i_end": 7}, "verb": {"text": "are labeled", "start": 50, "end": 61, "i_start": 8, "i_end": 9}}], "id": 2756}, {"sent": "for a recent review on other cmb circular polarization mechanisms see ref .", "tokens": ["for", "a", "recent", "review", "on", "other", "cmb", "circular", "polarization", "mechanisms", "see", "ref", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2757}, {"sent": "convolutional neural networks have achieved state-of-the-art accuracy in computer vision tasks such as image recognition .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "accuracy", "in", "computer", "vision", "tasks", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 2758}, {"sent": "the notion of labelled bisimilarity for the spi-calculus has been introduced to approximate trace equivalence .", "tokens": ["the", "notion", "of", "labelled", "bisimilarity", "for", "the", "spi", "-", "calculus", "has", "been", "introduced", "to", "approximate", "trace", "equivalence", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the notion of labelled bisimilarity for the spi-calculus", "start": 0, "end": 56, "i_start": 0, "i_end": 9}, "verb": {"text": "has been introduced", "start": 57, "end": 76, "i_start": 10, "i_end": 12}}, {"character": {"text": "notion", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "approximate", "start": 80, "end": 91, "i_start": 14, "i_end": 14}}], "id": 2759}, {"sent": "lower bounds for computation with limited nondeterminism .", "tokens": ["lower", "bounds", "for", "computation", "with", "limited", "nondeterminism", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2760}, {"sent": "in this work , we employ the contextualized word representations bert in for this purpose .", "tokens": ["in", "this", "work", ",", "we", "employ", "the", "contextualized", "word", "representations", "bert", "in", "for", "this", "purpose", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "employ", "start": 18, "end": 24, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the contextualized word", "start": 25, "end": 48, "i_start": 6, "i_end": 8}, "verb": {"text": "representations", "start": 49, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "employ", "start": 18, "end": 24, "i_start": 5, "i_end": 5}}, {"character": {"text": "bert", "start": 65, "end": 69, "i_start": 10, "i_end": 10}, "action": {"text": "representations", "start": 49, "end": 64, "i_start": 9, "i_end": 9}}], "id": 2761}, {"sent": "in particular , prior work has claimed that plain bnns are possibly more robust than hardened models-one can quantitatively verify such claims .", "tokens": ["in", "particular", ",", "prior", "work", "has", "claimed", "that", "plain", "bnns", "are", "possibly", "more", "robust", "than", "hardened", "models", "-", "one", "can", "quantitatively", "verify", "such", "claims", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "prior work", "start": 16, "end": 26, "i_start": 3, "i_end": 4}, "verb": {"text": "has claimed", "start": 27, "end": 38, "i_start": 5, "i_end": 6}}, {"subject": {"text": "one", "start": 101, "end": 104, "i_start": 18, "i_end": 18}, "verb": {"text": "are", "start": 55, "end": 58, "i_start": 10, "i_end": 10}}, {"subject": {"text": "prior work", "start": 16, "end": 26, "i_start": 3, "i_end": 4}, "verb": {"text": "verify", "start": 124, "end": 130, "i_start": 21, "i_end": 21}}, {"character": {"text": "work", "start": 22, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "claimed", "start": 31, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "one", "start": 101, "end": 104, "i_start": 18, "i_end": 18}, "action": {"text": "verify", "start": 124, "end": 130, "i_start": 21, "i_end": 21}}], "id": 2762}, {"sent": "similar to martinez et al , we found this approach to be beneficial for short-term prediction , but we also discovered that it leads to instability for long-term generation .", "tokens": ["similar", "to", "martinez", "et", "al", ",", "we", "found", "this", "approach", "to", "be", "beneficial", "for", "short", "-", "term", "prediction", ",", "but", "we", "also", "discovered", "that", "it", "leads", "to", "instability", "for", "long", "-", "term", "generation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 28, "end": 30, "i_start": 6, "i_end": 6}, "verb": {"text": "found", "start": 31, "end": 36, "i_start": 7, "i_end": 7}}, {"subject": {"text": "we", "start": 100, "end": 102, "i_start": 20, "i_end": 20}, "verb": {"text": "be", "start": 54, "end": 56, "i_start": 11, "i_end": 11}}, {"subject": {"text": "we", "start": 28, "end": 30, "i_start": 6, "i_end": 6}, "verb": {"text": "discovered", "start": 108, "end": 118, "i_start": 22, "i_end": 22}}, {"character": {"text": "we", "start": 28, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "found", "start": 31, "end": 36, "i_start": 7, "i_end": 7}}, {"character": {"text": "approach", "start": 42, "end": 50, "i_start": 9, "i_end": 9}, "action": {"text": "beneficial", "start": 57, "end": 67, "i_start": 12, "i_end": 12}}], "id": 2763}, {"sent": "work on adversarial examples has shown that neural networks are vulnerable to the attacks perturbing the data in imperceptible ways .", "tokens": ["work", "on", "adversarial", "examples", "has", "shown", "that", "neural", "networks", "are", "vulnerable", "to", "the", "attacks", "perturbing", "the", "data", "in", "imperceptible", "ways", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "work on adversarial examples", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "has shown", "start": 29, "end": 38, "i_start": 4, "i_end": 5}}, {"subject": {"text": "work on adversarial examples", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 60, "end": 63, "i_start": 9, "i_end": 9}}, {"character": {"text": "work", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "shown", "start": 33, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "attacks", "start": 82, "end": 89, "i_start": 13, "i_end": 13}, "action": {"text": "perturbing", "start": 90, "end": 100, "i_start": 14, "i_end": 14}}], "id": 2764}, {"sent": "quenched qcd is a model , so the associated uncertainty is difficult to estimate .", "tokens": ["quenched", "qcd", "is", "a", "model", ",", "so", "the", "associated", "uncertainty", "is", "difficult", "to", "estimate", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the associated uncertainty", "start": 29, "end": 55, "i_start": 7, "i_end": 9}, "verb": {"text": "is", "start": 56, "end": 58, "i_start": 10, "i_end": 10}}], "id": 2765}, {"sent": "then , if the inflaton is a free field , the slice of constant \u03c6 will coincide with the flat slice and with the constant energy density slice even at the end of inflation , i .", "tokens": ["then", ",", "if", "the", "inflaton", "is", "a", "free", "field", ",", "the", "slice", "of", "constant", "\u03c6", "will", "coincide", "with", "the", "flat", "slice", "and", "with", "the", "constant", "energy", "density", "slice", "even", "at", "the", "end", "of", "inflation", ",", "i", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the slice of constant \u03c6", "start": 41, "end": 64, "i_start": 10, "i_end": 14}, "verb": {"text": "will coincide", "start": 65, "end": 78, "i_start": 15, "i_end": 16}}], "id": 2766}, {"sent": "a transition to sustainability will require changes in consumer lifestyles as well as the development of new technologies .", "tokens": ["a", "transition", "to", "sustainability", "will", "require", "changes", "in", "consumer", "lifestyles", "as", "well", "as", "the", "development", "of", "new", "technologies", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a transition to sustainability", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "will require", "start": 31, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "transition", "start": 2, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "require", "start": 36, "end": 43, "i_start": 5, "i_end": 5}}], "id": 2767}, {"sent": "the codensity bisimilarity in this setting coincides with bisimulation metric from .", "tokens": ["the", "codensity", "bisimilarity", "in", "this", "setting", "coincides", "with", "bisimulation", "metric", "from", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2768}, {"sent": "as an alternative , physical layer security utilizes the physical properties of wireless communication channels , such as interference and channel fading , for ensuring perfectly secure communication .", "tokens": ["as", "an", "alternative", ",", "physical", "layer", "security", "utilizes", "the", "physical", "properties", "of", "wireless", "communication", "channels", ",", "such", "as", "interference", "and", "channel", "fading", ",", "for", "ensuring", "perfectly", "secure", "communication", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "an alternative", "start": 3, "end": 17, "i_start": 1, "i_end": 2}, "verb": {"text": "utilizes", "start": 44, "end": 52, "i_start": 7, "i_end": 7}}, {"character": {"text": "security", "start": 35, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "utilizes", "start": 44, "end": 52, "i_start": 7, "i_end": 7}}, {"character": {"text": "security", "start": 35, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "ensuring", "start": 160, "end": 168, "i_start": 24, "i_end": 24}}], "id": 2769}, {"sent": "in the last decade , convolutional neural networks have shown state of the art accuracy on a variety of visual recognition tasks such as image classification .", "tokens": ["in", "the", "last", "decade", ",", "convolutional", "neural", "networks", "have", "shown", "state", "of", "the", "art", "accuracy", "on", "a", "variety", "of", "visual", "recognition", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 21, "end": 50, "i_start": 5, "i_end": 7}, "verb": {"text": "have shown", "start": 51, "end": 61, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 42, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "shown", "start": 56, "end": 61, "i_start": 9, "i_end": 9}}], "id": 2770}, {"sent": "recent deep learning methods have yielded exciting results on large-scale image recognition .", "tokens": ["recent", "deep", "learning", "methods", "have", "yielded", "exciting", "results", "on", "large", "-", "scale", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent deep learning methods", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "have yielded", "start": 29, "end": 41, "i_start": 4, "i_end": 5}}, {"character": {"text": "methods", "start": 21, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "yielded", "start": 34, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "results", "start": 51, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "exciting", "start": 42, "end": 50, "i_start": 6, "i_end": 6}}], "id": 2771}, {"sent": "at non-zero t there is a large literature on average-atom methods , for example refs .", "tokens": ["at", "non", "-", "zero", "t", "there", "is", "a", "large", "literature", "on", "average", "-", "atom", "methods", ",", "for", "example", "refs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 14, "end": 19, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 6, "i_end": 6}}], "id": 2772}, {"sent": "in this work , we first have derived and computationally implemented a two variable recurrence that permits construction of the whole orthonormal matrix the derivation follows our paper in and is also of interest for other 3nj symbols .", "tokens": ["in", "this", "work", ",", "we", "first", "have", "derived", "and", "computationally", "implemented", "a", "two", "variable", "recurrence", "that", "permits", "construction", "of", "the", "whole", "orthonormal", "matrix", "the", "derivation", "follows", "our", "paper", "in", "and", "is", "also", "of", "interest", "for", "other", "3nj", "symbols", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "have derived", "start": 24, "end": 36, "i_start": 6, "i_end": 7}}, {"subject": {"text": "the derivation", "start": 153, "end": 167, "i_start": 23, "i_end": 24}, "verb": {"text": "implemented", "start": 57, "end": 68, "i_start": 10, "i_end": 10}}, {"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "follows", "start": 168, "end": 175, "i_start": 25, "i_end": 25}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "derived", "start": 29, "end": 36, "i_start": 7, "i_end": 7}}, {"character": {"text": "two variable recurrence", "start": 71, "end": 94, "i_start": 12, "i_end": 14}, "action": {"text": "permits", "start": 100, "end": 107, "i_start": 16, "i_end": 16}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "implemented", "start": 57, "end": 68, "i_start": 10, "i_end": 10}}], "id": 2773}, {"sent": "for instance , a flattening technique is used by comon and jurski to establish that the binary reachability of timed automata is definable in the additive theory of reals and integers .", "tokens": ["for", "instance", ",", "a", "flattening", "technique", "is", "used", "by", "comon", "and", "jurski", "to", "establish", "that", "the", "binary", "reachability", "of", "timed", "automata", "is", "definable", "in", "the", "additive", "theory", "of", "reals", "and", "integers", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "a flattening technique", "start": 15, "end": 37, "i_start": 3, "i_end": 5}, "verb": {"text": "is used", "start": 38, "end": 45, "i_start": 6, "i_end": 7}}, {"subject": {"text": "a flattening technique", "start": 15, "end": 37, "i_start": 3, "i_end": 5}, "verb": {"text": "jurski", "start": 59, "end": 65, "i_start": 11, "i_end": 11}}, {"character": {"text": "comon", "start": 49, "end": 54, "i_start": 9, "i_end": 9}, "action": {"text": "used", "start": 41, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "jurski", "start": 59, "end": 65, "i_start": 11, "i_end": 11}, "action": {"text": "used", "start": 41, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "comon", "start": 49, "end": 54, "i_start": 9, "i_end": 9}, "action": {"text": "establish", "start": 69, "end": 78, "i_start": 13, "i_end": 13}}, {"character": {"text": "jurski", "start": 59, "end": 65, "i_start": 11, "i_end": 11}, "action": {"text": "establish", "start": 69, "end": 78, "i_start": 13, "i_end": 13}}, {"character": {"text": "automata", "start": 117, "end": 125, "i_start": 20, "i_end": 20}, "action": {"text": "reachability", "start": 95, "end": 107, "i_start": 17, "i_end": 17}}, {"character": {"text": "theory", "start": 155, "end": 161, "i_start": 26, "i_end": 26}, "action": {"text": "definable", "start": 129, "end": 138, "i_start": 22, "i_end": 22}}], "id": 2774}, {"sent": "asterisks denote non-oscillatory , diamonds oscillatory solutions .", "tokens": ["asterisks", "denote", "non", "-", "oscillatory", ",", "diamonds", "oscillatory", "solutions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "asterisks", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "diamonds", "start": 35, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "oscillatory", "start": 21, "end": 32, "i_start": 4, "i_end": 4}}], "id": 2775}, {"sent": "in section iii we introduce the quantum map and spin coherent states .", "tokens": ["in", "section", "iii", "we", "introduce", "the", "quantum", "map", "and", "spin", "coherent", "states", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "introduce", "start": 18, "end": 27, "i_start": 4, "i_end": 4}}, {"subject": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "spin", "start": 48, "end": 52, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "introduce", "start": 18, "end": 27, "i_start": 4, "i_end": 4}}], "id": 2776}, {"sent": "bayesian state estimation has a wide range of applications from positioning .", "tokens": ["bayesian", "state", "estimation", "has", "a", "wide", "range", "of", "applications", "from", "positioning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "bayesian state estimation", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "has", "start": 26, "end": 29, "i_start": 3, "i_end": 3}}], "id": 2777}, {"sent": "we implemented our models in the pytorch deep learning framework .", "tokens": ["we", "implemented", "our", "models", "in", "the", "pytorch", "deep", "learning", "framework", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implemented", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implemented", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}], "id": 2778}, {"sent": "the ellipses in denote terms of higher order in the chiral expansion .", "tokens": ["the", "ellipses", "in", "denote", "terms", "of", "higher", "order", "in", "the", "chiral", "expansion", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "ellipses", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 16, "end": 22, "i_start": 3, "i_end": 3}}], "id": 2779}, {"sent": "the visual representation are extracted from the so-called res4f relu layer from a resnet-50 convolutional neural network trained on the imagenet dataset .", "tokens": ["the", "visual", "representation", "are", "extracted", "from", "the", "so", "-", "called", "res4f", "relu", "layer", "from", "a", "resnet-50", "convolutional", "neural", "network", "trained", "on", "the", "imagenet", "dataset", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the visual representation", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "are extracted", "start": 26, "end": 39, "i_start": 3, "i_end": 4}}], "id": 2780}, {"sent": "formula was discussed during the conference icnaam 2006 in greece and it appeared , with an inductive proof , in paper , .", "tokens": ["formula", "was", "discussed", "during", "the", "conference", "icnaam", "2006", "in", "greece", "and", "it", "appeared", ",", "with", "an", "inductive", "proof", ",", "in", "paper", ",", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "formula", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "was discussed", "start": 8, "end": 21, "i_start": 1, "i_end": 2}}, {"subject": {"text": "it", "start": 70, "end": 72, "i_start": 11, "i_end": 11}, "verb": {"text": "appeared", "start": 73, "end": 81, "i_start": 12, "i_end": 12}}], "id": 2781}, {"sent": "the u-net architecture is an encoder-decoder network with skip connections between the encoder and the decoder .", "tokens": ["the", "u", "-", "net", "architecture", "is", "an", "encoder", "-", "decoder", "network", "with", "skip", "connections", "between", "the", "encoder", "and", "the", "decoder", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the u-net architecture", "start": 0, "end": 22, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 5, "i_end": 5}}], "id": 2782}, {"sent": "we built a standard phrase-based system with moses open source toolkit .", "tokens": ["we", "built", "a", "standard", "phrase", "-", "based", "system", "with", "moses", "open", "source", "toolkit", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "built", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "built", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2783}, {"sent": "convolutional neural networks have been instrumental to the recent breakthroughs in computer vision .", "tokens": ["convolutional", "neural", "networks", "have", "been", "instrumental", "to", "the", "recent", "breakthroughs", "in", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}], "id": 2784}, {"sent": "free knots can be treated as equivalence classes of corresponding gauss diagrams .", "tokens": ["free", "knots", "can", "be", "treated", "as", "equivalence", "classes", "of", "corresponding", "gauss", "diagrams", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "free knots", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "can be treated", "start": 11, "end": 25, "i_start": 2, "i_end": 4}}], "id": 2785}, {"sent": "the recent progress achieved in computer vision tasks largely rely on deep neural networks , scene understanding .", "tokens": ["the", "recent", "progress", "achieved", "in", "computer", "vision", "tasks", "largely", "rely", "on", "deep", "neural", "networks", ",", "scene", "understanding", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the recent progress achieved in computer vision tasks", "start": 0, "end": 53, "i_start": 0, "i_end": 7}, "verb": {"text": "rely", "start": 62, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "progress", "start": 11, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "rely", "start": 62, "end": 66, "i_start": 9, "i_end": 9}}], "id": 2786}, {"sent": "the network is initialized with the weights of the vgg-16 model dataset .", "tokens": ["the", "network", "is", "initialized", "with", "the", "weights", "of", "the", "vgg-16", "model", "dataset", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the network", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is initialized", "start": 12, "end": 26, "i_start": 2, "i_end": 3}}], "id": 2787}, {"sent": "let us now consider each of these in turn .", "tokens": ["let", "us", "now", "consider", "each", "of", "these", "in", "turn", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "consider", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "consider", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}], "id": 2788}, {"sent": "travaglinia , b infn sezione di catania a , universita di catania b , catania , italy s .", "tokens": ["travaglinia", ",", "b", "infn", "sezione", "di", "catania", "a", ",", "universita", "di", "catania", "b", ",", "catania", ",", "italy", "s", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2789}, {"sent": "this concludes the proof of the main theorem .", "tokens": ["this", "concludes", "the", "proof", "of", "the", "main", "theorem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "concludes", "start": 5, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "concludes", "start": 5, "end": 14, "i_start": 1, "i_end": 1}}], "id": 2790}, {"sent": "so , in our calculations there is a free parameter c2 .", "tokens": ["so", ",", "in", "our", "calculations", "there", "is", "a", "free", "parameter", "c2", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 25, "end": 30, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 6, "i_end": 6}}], "id": 2791}, {"sent": "network analysis has revealed as a powerful approach to understand complex phenomena and organization in social , biological and technological systems .", "tokens": ["network", "analysis", "has", "revealed", "as", "a", "powerful", "approach", "to", "understand", "complex", "phenomena", "and", "organization", "in", "social", ",", "biological", "and", "technological", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "network analysis", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "has revealed", "start": 17, "end": 29, "i_start": 2, "i_end": 3}}, {"character": {"text": "analysis", "start": 8, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "revealed", "start": 21, "end": 29, "i_start": 3, "i_end": 3}}], "id": 2792}, {"sent": "boosted by the development of deep convolutional neural network , the accuracy of object detection has been improved greatly .", "tokens": ["boosted", "by", "the", "development", "of", "deep", "convolutional", "neural", "network", ",", "the", "accuracy", "of", "object", "detection", "has", "been", "improved", "greatly", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the accuracy of object detection", "start": 66, "end": 98, "i_start": 10, "i_end": 14}, "verb": {"text": "has been improved", "start": 99, "end": 116, "i_start": 15, "i_end": 17}}, {"character": {"text": "development", "start": 15, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "boosted", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}], "id": 2793}, {"sent": "deep convolutional neural networks are powerful discriminative models that yield impressive results at object classification .", "tokens": ["deep", "convolutional", "neural", "networks", "are", "powerful", "discriminative", "models", "that", "yield", "impressive", "results", "at", "object", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 35, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "models", "start": 63, "end": 69, "i_start": 7, "i_end": 7}, "action": {"text": "discriminative", "start": 48, "end": 62, "i_start": 6, "i_end": 6}}, {"character": {"text": "models", "start": 63, "end": 69, "i_start": 7, "i_end": 7}, "action": {"text": "yield", "start": 75, "end": 80, "i_start": 9, "i_end": 9}}, {"character": {"text": "results", "start": 92, "end": 99, "i_start": 11, "i_end": 11}, "action": {"text": "impressive", "start": 81, "end": 91, "i_start": 10, "i_end": 10}}], "id": 2794}, {"sent": "deep convolutional neural networks have achieved huge success in solving problems related to computer vision , such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "huge", "success", "in", "solving", "problems", "related", "to", "computer", "vision", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 54, "end": 61, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "solving", "start": 65, "end": 72, "i_start": 9, "i_end": 9}}], "id": 2795}, {"sent": "the objective functions can be easily solved by the lars algorithm with minimal computation cost on the master .", "tokens": ["the", "objective", "functions", "can", "be", "easily", "solved", "by", "the", "lars", "algorithm", "with", "minimal", "computation", "cost", "on", "the", "master", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the objective functions", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "solved", "start": 38, "end": 44, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the objective functions", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "can be", "start": 24, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "algorithm", "start": 57, "end": 66, "i_start": 10, "i_end": 10}, "action": {"text": "solved", "start": 38, "end": 44, "i_start": 6, "i_end": 6}}], "id": 2796}, {"sent": "in fact , deflate is an enhanced version of the lempel-ziv compression algorithm .", "tokens": ["in", "fact", ",", "deflate", "is", "an", "enhanced", "version", "of", "the", "lempel", "-", "ziv", "compression", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deflate", "start": 10, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 4, "i_end": 4}}], "id": 2797}, {"sent": "in this study , we used eigen value-one-criterion , also known as kaiser criterion , which means any component having an eigen value greater than one was retained .", "tokens": ["in", "this", "study", ",", "we", "used", "eigen", "value", "-", "one", "-", "criterion", ",", "also", "known", "as", "kaiser", "criterion", ",", "which", "means", "any", "component", "having", "an", "eigen", "value", "greater", "than", "one", "was", "retained", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "used", "start": 19, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "used", "start": 19, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "component", "start": 101, "end": 110, "i_start": 22, "i_end": 22}, "action": {"text": "having", "start": 111, "end": 117, "i_start": 23, "i_end": 23}}], "id": 2798}, {"sent": "juschenko and monod have proven that the topological full group of any minimal homeomorphism of the cantor space is amenable .", "tokens": ["juschenko", "and", "monod", "have", "proven", "that", "the", "topological", "full", "group", "of", "any", "minimal", "homeomorphism", "of", "the", "cantor", "space", "is", "amenable", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "juschenko and monod", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "have proven", "start": 20, "end": 31, "i_start": 3, "i_end": 4}}, {"subject": {"text": "juschenko and monod", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 113, "end": 115, "i_start": 18, "i_end": 18}}, {"character": {"text": "juschenko", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "proven", "start": 25, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "monod", "start": 14, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "proven", "start": 25, "end": 31, "i_start": 4, "i_end": 4}}], "id": 2799}, {"sent": "bp-mf has to learn the noise precision to take into account the interference from other users even when the noise power is known .", "tokens": ["bp", "-", "mf", "has", "to", "learn", "the", "noise", "precision", "to", "take", "into", "account", "the", "interference", "from", "other", "users", "even", "when", "the", "noise", "power", "is", "known", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "bp-mf", "start": 0, "end": 5, "i_start": 0, "i_end": 2}, "verb": {"text": "has", "start": 6, "end": 9, "i_start": 3, "i_end": 3}}, {"character": {"text": "other", "start": 82, "end": 87, "i_start": 16, "i_end": 16}, "action": {"text": "interference", "start": 64, "end": 76, "i_start": 14, "i_end": 14}}], "id": 2800}, {"sent": "in , a gru architecture was found to achieve better performance than lstm on some tasks .", "tokens": ["in", ",", "a", "gru", "architecture", "was", "found", "to", "achieve", "better", "performance", "than", "lstm", "on", "some", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a gru architecture", "start": 5, "end": 23, "i_start": 2, "i_end": 4}, "verb": {"text": "was found", "start": 24, "end": 33, "i_start": 5, "i_end": 6}}, {"character": {"text": "architecture", "start": 11, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "achieve", "start": 37, "end": 44, "i_start": 8, "i_end": 8}}, {"character": {"text": "architecture", "start": 11, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "performance", "start": 52, "end": 63, "i_start": 10, "i_end": 10}}], "id": 2801}, {"sent": "the optimality properties of a preemptive last generated first served service discipline in a multi-hop network are established in .", "tokens": ["the", "optimality", "properties", "of", "a", "preemptive", "last", "generated", "first", "served", "service", "discipline", "in", "a", "multi", "-", "hop", "network", "are", "established", "in", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the optimality properties of a preemptive last generated first served service discipline in a multi-hop network", "start": 0, "end": 111, "i_start": 0, "i_end": 17}, "verb": {"text": "are established", "start": 112, "end": 127, "i_start": 18, "i_end": 19}}, {"character": {"text": "discipline", "start": 78, "end": 88, "i_start": 11, "i_end": 11}, "action": {"text": "preemptive", "start": 31, "end": 41, "i_start": 5, "i_end": 5}}], "id": 2802}, {"sent": "in the shaded regions , destabilization of the wta state occurs in response to the switching of the mode of the syn-asyn input layer from asynchronous to synchronous incoming spikes .", "tokens": ["in", "the", "shaded", "regions", ",", "destabilization", "of", "the", "wta", "state", "occurs", "in", "response", "to", "the", "switching", "of", "the", "mode", "of", "the", "syn", "-", "asyn", "input", "layer", "from", "asynchronous", "to", "synchronous", "incoming", "spikes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "destabilization of the wta state", "start": 24, "end": 56, "i_start": 5, "i_end": 9}, "verb": {"text": "occurs", "start": 57, "end": 63, "i_start": 10, "i_end": 10}}], "id": 2803}, {"sent": "we conclude that the generalized model with distinguishable particles is not exactly solvable by the coordinate bethe ansatz .", "tokens": ["we", "conclude", "that", "the", "generalized", "model", "with", "distinguishable", "particles", "is", "not", "exactly", "solvable", "by", "the", "coordinate", "bethe", "ansatz", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "conclude", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 70, "end": 72, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "conclude", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "particles", "start": 60, "end": 69, "i_start": 8, "i_end": 8}, "action": {"text": "distinguishable", "start": 44, "end": 59, "i_start": 7, "i_end": 7}}], "id": 2804}, {"sent": "since the seminal work of koenker and bassett , quantile regression has attracted considerable interest in statistics and econometrics .", "tokens": ["since", "the", "seminal", "work", "of", "koenker", "and", "bassett", ",", "quantile", "regression", "has", "attracted", "considerable", "interest", "in", "statistics", "and", "econometrics", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "quantile regression", "start": 48, "end": 67, "i_start": 9, "i_end": 10}, "verb": {"text": "has attracted", "start": 68, "end": 81, "i_start": 11, "i_end": 12}}, {"character": {"text": "regression", "start": 57, "end": 67, "i_start": 10, "i_end": 10}, "action": {"text": "attracted", "start": 72, "end": 81, "i_start": 12, "i_end": 12}}, {"character": {"text": "koenker", "start": 26, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "work", "start": 18, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "bassett", "start": 38, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "work", "start": 18, "end": 22, "i_start": 3, "i_end": 3}}], "id": 2805}, {"sent": "we start by using a vanilla u-net interpolation architecture for reconstructing frames other than the key frames .", "tokens": ["we", "start", "by", "using", "a", "vanilla", "u", "-", "net", "interpolation", "architecture", "for", "reconstructing", "frames", "other", "than", "the", "key", "frames", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "start", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "start", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 12, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "reconstructing", "start": 65, "end": 79, "i_start": 12, "i_end": 12}}], "id": 2806}, {"sent": "for lstm model we choose to use stochastic adam gradient descent for training .", "tokens": ["for", "lstm", "model", "we", "choose", "to", "use", "stochastic", "adam", "gradient", "descent", "for", "training", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "choose", "start": 18, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "choose", "start": 18, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 28, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "descent", "start": 57, "end": 64, "i_start": 10, "i_end": 10}}], "id": 2807}, {"sent": "the gravitino is the superpartner of the graviton .", "tokens": ["the", "gravitino", "is", "the", "superpartner", "of", "the", "graviton", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the gravitino", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 2808}, {"sent": "quantum coherent tunable coupling of superconducting qubits .", "tokens": ["quantum", "coherent", "tunable", "coupling", "of", "superconducting", "qubits", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2809}, {"sent": "the images were reduced using the fors pipeline .", "tokens": ["the", "images", "were", "reduced", "using", "the", "fors", "pipeline", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the images", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "were reduced", "start": 11, "end": 23, "i_start": 2, "i_end": 3}}], "id": 2810}, {"sent": "the enhancement is a consequence of relatively long time that electrons spend on the dot .", "tokens": ["the", "enhancement", "is", "a", "consequence", "of", "relatively", "long", "time", "that", "electrons", "spend", "on", "the", "dot", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the enhancement", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "electrons", "start": 62, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "spend", "start": 72, "end": 77, "i_start": 11, "i_end": 11}}], "id": 2811}, {"sent": "the generalized notions , hom-bialgebras , hom-hopf algebras were developed in .", "tokens": ["the", "generalized", "notions", ",", "hom", "-", "bialgebras", ",", "hom", "-", "hopf", "algebras", "were", "developed", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalized notions , hom-bialgebras , hom-hopf algebras", "start": 0, "end": 60, "i_start": 0, "i_end": 11}, "verb": {"text": "were developed", "start": 61, "end": 75, "i_start": 12, "i_end": 13}}], "id": 2812}, {"sent": "this free energy consists of nearest neighbor repulsion energies of z-ions and the attraction energy of z-ions to the charge surface .", "tokens": ["this", "free", "energy", "consists", "of", "nearest", "neighbor", "repulsion", "energies", "of", "z", "-", "ions", "and", "the", "attraction", "energy", "of", "z", "-", "ions", "to", "the", "charge", "surface", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this free energy", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "energies", "start": 56, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "repulsion", "start": 46, "end": 55, "i_start": 7, "i_end": 7}}, {"character": {"text": "energy", "start": 94, "end": 100, "i_start": 16, "i_end": 16}, "action": {"text": "attraction", "start": 83, "end": 93, "i_start": 15, "i_end": 15}}], "id": 2813}, {"sent": "copenhagen interpretation of quantum mechanics asserts that we can not speak about the quantum properties of the system before these properties are measured .", "tokens": ["copenhagen", "interpretation", "of", "quantum", "mechanics", "asserts", "that", "we", "can", "not", "speak", "about", "the", "quantum", "properties", "of", "the", "system", "before", "these", "properties", "are", "measured", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "copenhagen interpretation of quantum mechanics", "start": 0, "end": 46, "i_start": 0, "i_end": 4}, "verb": {"text": "asserts", "start": 47, "end": 54, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 60, "end": 62, "i_start": 7, "i_end": 7}, "verb": {"text": "speak", "start": 71, "end": 76, "i_start": 10, "i_end": 10}}, {"character": {"text": "interpretation", "start": 11, "end": 25, "i_start": 1, "i_end": 1}, "action": {"text": "asserts", "start": 47, "end": 54, "i_start": 5, "i_end": 5}}, {"character": {"text": "copenhagen", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "interpretation", "start": 11, "end": 25, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 60, "end": 62, "i_start": 7, "i_end": 7}, "action": {"text": "speak", "start": 71, "end": 76, "i_start": 10, "i_end": 10}}], "id": 2814}, {"sent": "this delay is the light travel time of photons from the central continuum region and is , hence , the distance of the broad line gas from the continuum region .", "tokens": ["this", "delay", "is", "the", "light", "travel", "time", "of", "photons", "from", "the", "central", "continuum", "region", "and", "is", ",", "hence", ",", "the", "distance", "of", "the", "broad", "line", "gas", "from", "the", "continuum", "region", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this delay", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "photons", "start": 39, "end": 46, "i_start": 8, "i_end": 8}, "action": {"text": "travel", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}], "id": 2815}, {"sent": "in recent years , ssd have been proposed to achieve better performance in object detection .", "tokens": ["in", "recent", "years", ",", "ssd", "have", "been", "proposed", "to", "achieve", "better", "performance", "in", "object", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "ssd", "start": 18, "end": 21, "i_start": 4, "i_end": 4}, "verb": {"text": "have been proposed", "start": 22, "end": 40, "i_start": 5, "i_end": 7}}], "id": 2816}, {"sent": "deep convolutional neural networks achieve state of the art results on image recognition problems .", "tokens": ["deep", "convolutional", "neural", "networks", "achieve", "state", "of", "the", "art", "results", "on", "image", "recognition", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "achieve", "start": 35, "end": 42, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieve", "start": 35, "end": 42, "i_start": 4, "i_end": 4}}], "id": 2817}, {"sent": "the values for the parameters and vacuum quantities are listed in table v .", "tokens": ["the", "values", "for", "the", "parameters", "and", "vacuum", "quantities", "are", "listed", "in", "table", "v", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the values for the parameters and vacuum quantities", "start": 0, "end": 51, "i_start": 0, "i_end": 7}, "verb": {"text": "are listed", "start": 52, "end": 62, "i_start": 8, "i_end": 9}}], "id": 2818}, {"sent": "we mentioned this already refs in which yamabe functional for manifolds with boundary were discussed .", "tokens": ["we", "mentioned", "this", "already", "refs", "in", "which", "yamabe", "functional", "for", "manifolds", "with", "boundary", "were", "discussed", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "mentioned", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"subject": {"text": "in which yamabe functional for manifolds with boundary", "start": 31, "end": 85, "i_start": 5, "i_end": 12}, "verb": {"text": "discussed", "start": 91, "end": 100, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "mentioned", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "yamabe", "start": 40, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "functional", "start": 47, "end": 57, "i_start": 8, "i_end": 8}}], "id": 2819}, {"sent": "there is also a recent global well-posedness result of kdv with quasi-periodic initial data by damanik-goldstein .", "tokens": ["there", "is", "also", "a", "recent", "global", "well", "-", "posedness", "result", "of", "kdv", "with", "quasi", "-", "periodic", "initial", "data", "by", "damanik", "-", "goldstein", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2820}, {"sent": "in this case we use , as in ref , the glauber approach to get the initial condition for a nucleus from the one of a proton .", "tokens": ["in", "this", "case", "we", "use", ",", "as", "in", "ref", ",", "the", "glauber", "approach", "to", "get", "the", "initial", "condition", "for", "a", "nucleus", "from", "the", "one", "of", "a", "proton", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "use", "start": 16, "end": 19, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 16, "end": 19, "i_start": 4, "i_end": 4}}, {"character": {"text": "glauber", "start": 38, "end": 45, "i_start": 11, "i_end": 11}, "action": {"text": "approach", "start": 46, "end": 54, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "get", "start": 58, "end": 61, "i_start": 14, "i_end": 14}}], "id": 2821}, {"sent": "periodic dft calculations were performed within the generalized gradient approximation using perdew-burke-ernzerhof parametrization of exchange correlation functional .", "tokens": ["periodic", "dft", "calculations", "were", "performed", "within", "the", "generalized", "gradient", "approximation", "using", "perdew", "-", "burke", "-", "ernzerhof", "parametrization", "of", "exchange", "correlation", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "periodic dft calculations", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "were performed", "start": 26, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "exchange", "start": 135, "end": 143, "i_start": 18, "i_end": 18}, "action": {"text": "functional", "start": 156, "end": 166, "i_start": 20, "i_end": 20}}], "id": 2822}, {"sent": "this to warm up , let us first rephrase the seminal lsd results in this language .", "tokens": ["this", "to", "warm", "up", ",", "let", "us", "first", "rephrase", "the", "seminal", "lsd", "results", "in", "this", "language", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this to warm up", "start": 0, "end": 15, "i_start": 0, "i_end": 3}, "verb": {"text": "let", "start": 18, "end": 21, "i_start": 5, "i_end": 5}}, {"character": {"text": "us", "start": 22, "end": 24, "i_start": 6, "i_end": 6}, "action": {"text": "let", "start": 18, "end": 21, "i_start": 5, "i_end": 5}}, {"character": {"text": "us", "start": 22, "end": 24, "i_start": 6, "i_end": 6}, "action": {"text": "rephrase", "start": 31, "end": 39, "i_start": 8, "i_end": 8}}], "id": 2823}, {"sent": "the origin of this behavior is a spontaneous nucleation of defects in the static chain at larger disorder .", "tokens": ["the", "origin", "of", "this", "behavior", "is", "a", "spontaneous", "nucleation", "of", "defects", "in", "the", "static", "chain", "at", "larger", "disorder", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the origin of this behavior", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "nucleation", "start": 45, "end": 55, "i_start": 8, "i_end": 8}, "action": {"text": "origin", "start": 4, "end": 10, "i_start": 1, "i_end": 1}}], "id": 2824}, {"sent": "the perdew-burke-ernzehof form of the generalized gradient approximation is used to describe electron exchange and correlation .", "tokens": ["the", "perdew", "-", "burke", "-", "ernzehof", "form", "of", "the", "generalized", "gradient", "approximation", "is", "used", "to", "describe", "electron", "exchange", "and", "correlation", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the perdew-burke-ernzehof form of the generalized gradient approximation", "start": 0, "end": 72, "i_start": 0, "i_end": 11}, "verb": {"text": "is used", "start": 73, "end": 80, "i_start": 12, "i_end": 13}}, {"character": {"text": "form", "start": 26, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "describe", "start": 84, "end": 92, "i_start": 15, "i_end": 15}}], "id": 2825}, {"sent": "however , we have the following easy result .", "tokens": ["however", ",", "we", "have", "the", "following", "easy", "result", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "have", "start": 13, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "have", "start": 13, "end": 17, "i_start": 3, "i_end": 3}}], "id": 2826}, {"sent": "significant improvements have been obtained in various computer vision tasks by applying deep learning techniques , including image classification .", "tokens": ["significant", "improvements", "have", "been", "obtained", "in", "various", "computer", "vision", "tasks", "by", "applying", "deep", "learning", "techniques", ",", "including", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "significant improvements", "start": 0, "end": 24, "i_start": 0, "i_end": 1}, "verb": {"text": "have been obtained", "start": 25, "end": 43, "i_start": 2, "i_end": 4}}], "id": 2827}, {"sent": "note that cnoiis equivalent to the number of two-step directed paths from u to v , which was shown to be useful for reciprocity prediction .", "tokens": ["note", "that", "cnoiis", "equivalent", "to", "the", "number", "of", "two", "-", "step", "directed", "paths", "from", "u", "to", "v", ",", "which", "was", "shown", "to", "be", "useful", "for", "reciprocity", "prediction", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2828}, {"sent": "this set may be either the original dataset or the result of a mapping into a feature space of higher dimensionality .", "tokens": ["this", "set", "may", "be", "either", "the", "original", "dataset", "or", "the", "result", "of", "a", "mapping", "into", "a", "feature", "space", "of", "higher", "dimensionality", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this set", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "may be", "start": 9, "end": 15, "i_start": 2, "i_end": 3}}], "id": 2829}, {"sent": "the babyskyrme and skyrme models are non-renormalisable , and we find that it is therefore not possible to remove all the lattice-dependency from the energy expression .", "tokens": ["the", "babyskyrme", "and", "skyrme", "models", "are", "non", "-", "renormalisable", ",", "and", "we", "find", "that", "it", "is", "therefore", "not", "possible", "to", "remove", "all", "the", "lattice", "-", "dependency", "from", "the", "energy", "expression", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the babyskyrme and skyrme models", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "are", "start": 33, "end": 36, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 62, "end": 64, "i_start": 11, "i_end": 11}, "verb": {"text": "find", "start": 65, "end": 69, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 62, "end": 64, "i_start": 11, "i_end": 11}, "action": {"text": "find", "start": 65, "end": 69, "i_start": 12, "i_end": 12}}, {"character": {"text": "lattice", "start": 122, "end": 129, "i_start": 23, "i_end": 23}, "action": {"text": "dependency", "start": 130, "end": 140, "i_start": 25, "i_end": 25}}], "id": 2830}, {"sent": "neural networks have led to state-of-the-art results on many important problems in artificial intelligence .", "tokens": ["neural", "networks", "have", "led", "to", "state", "-", "of", "-", "the", "-", "art", "results", "on", "many", "important", "problems", "in", "artificial", "intelligence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have led", "start": 16, "end": 24, "i_start": 2, "i_end": 3}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2831}, {"sent": "the map between the non-commutative description and the ordinary description is called seiberg-witten map .", "tokens": ["the", "map", "between", "the", "non", "-", "commutative", "description", "and", "the", "ordinary", "description", "is", "called", "seiberg", "-", "witten", "map", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the map between the non-commutative description and the ordinary description", "start": 0, "end": 76, "i_start": 0, "i_end": 11}, "verb": {"text": "is called", "start": 77, "end": 86, "i_start": 12, "i_end": 13}}], "id": 2832}, {"sent": "generative adversarial learning generative adversarial networks have been increasingly popular for generative modeling .", "tokens": ["generative", "adversarial", "learning", "generative", "adversarial", "networks", "have", "been", "increasingly", "popular", "for", "generative", "modeling", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial learning generative adversarial networks", "start": 0, "end": 63, "i_start": 0, "i_end": 5}, "verb": {"text": "have been", "start": 64, "end": 73, "i_start": 6, "i_end": 7}}], "id": 2833}, {"sent": "in this paper , we propose to use generative adversarial networks .", "tokens": ["in", "this", "paper", ",", "we", "propose", "to", "use", "generative", "adversarial", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "propose", "start": 19, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "propose", "start": 19, "end": 26, "i_start": 5, "i_end": 5}}], "id": 2834}, {"sent": "batch normalization and relu activation are applied after every convolutional layer .", "tokens": ["batch", "normalization", "and", "relu", "activation", "are", "applied", "after", "every", "convolutional", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "batch normalization and relu activation", "start": 0, "end": 39, "i_start": 0, "i_end": 4}, "verb": {"text": "are applied", "start": 40, "end": 51, "i_start": 5, "i_end": 6}}], "id": 2835}, {"sent": "besides the chemical potential \u00b5 , there is the inverse gluon screening length which is of the order of the gluon mass parameter mg .", "tokens": ["besides", "the", "chemical", "potential", "\u00b5", ",", "there", "is", "the", "inverse", "gluon", "screening", "length", "which", "is", "of", "the", "order", "of", "the", "gluon", "mass", "parameter", "mg", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 35, "end": 40, "i_start": 6, "i_end": 6}, "verb": {"text": "is", "start": 41, "end": 43, "i_start": 7, "i_end": 7}}], "id": 2836}, {"sent": "weakly chaotic behavior alternates with non-chaotic behavior over the entire period of analysis .", "tokens": ["weakly", "chaotic", "behavior", "alternates", "with", "non", "-", "chaotic", "behavior", "over", "the", "entire", "period", "of", "analysis", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2837}, {"sent": "deep neural networks are being successful in accomplishing challenging tasks such as image classification .", "tokens": ["deep", "neural", "networks", "are", "being", "successful", "in", "accomplishing", "challenging", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are being", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 31, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "accomplishing", "start": 45, "end": 58, "i_start": 7, "i_end": 7}}], "id": 2838}, {"sent": "one of the remarkable advantages of knn is the ability to implement the complicated and irregular decision boundaries unlike some model-based learners such as rule-based methods and decision trees whose boundaries are triangular and straight lines .", "tokens": ["one", "of", "the", "remarkable", "advantages", "of", "knn", "is", "the", "ability", "to", "implement", "the", "complicated", "and", "irregular", "decision", "boundaries", "unlike", "some", "model", "-", "based", "learners", "such", "as", "rule", "-", "based", "methods", "and", "decision", "trees", "whose", "boundaries", "are", "triangular", "and", "straight", "lines", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "one of the remarkable advantages of knn", "start": 0, "end": 39, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 40, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "knn", "start": 36, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "implement", "start": 58, "end": 67, "i_start": 11, "i_end": 11}}], "id": 2839}, {"sent": "the model is composed of an elmo embedding layer and a bidirectional lstm .", "tokens": ["the", "model", "is", "composed", "of", "an", "elmo", "embedding", "layer", "and", "a", "bidirectional", "lstm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is composed", "start": 10, "end": 21, "i_start": 2, "i_end": 3}}], "id": 2840}, {"sent": "deep neural networks are responsible for numerous state-of-the-art results in a variety of domains , including computer vision , speech recognition , and natural language processing .", "tokens": ["deep", "neural", "networks", "are", "responsible", "for", "numerous", "state", "-", "of", "-", "the", "-", "art", "results", "in", "a", "variety", "of", "domains", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "and", "natural", "language", "processing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "responsible", "start": 25, "end": 36, "i_start": 4, "i_end": 4}}], "id": 2841}, {"sent": "convolutional neural networks have achieved significant progress in computer vision tasks such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "significant", "progress", "in", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 2842}, {"sent": "we see that on the whole , all four models describe reasonably well most of the measured neutron spectra , although different models agree differently with data from specific reactions and some serious discrepances are observed for some reactions .", "tokens": ["we", "see", "that", "on", "the", "whole", ",", "all", "four", "models", "describe", "reasonably", "well", "most", "of", "the", "measured", "neutron", "spectra", ",", "although", "different", "models", "agree", "differently", "with", "data", "from", "specific", "reactions", "and", "some", "serious", "discrepances", "are", "observed", "for", "some", "reactions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "see", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "all four models", "start": 27, "end": 42, "i_start": 7, "i_end": 9}, "verb": {"text": "describe", "start": 43, "end": 51, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "see", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "four models", "start": 31, "end": 42, "i_start": 8, "i_end": 9}, "action": {"text": "describe", "start": 43, "end": 51, "i_start": 10, "i_end": 10}}, {"character": {"text": "models", "start": 126, "end": 132, "i_start": 22, "i_end": 22}, "action": {"text": "agree", "start": 133, "end": 138, "i_start": 23, "i_end": 23}}], "id": 2843}, {"sent": "the lie subalgebra tn of gln , consisting all the diagonal n by n matrices , is called cartan subalgebra .", "tokens": ["the", "lie", "subalgebra", "tn", "of", "gln", ",", "consisting", "all", "the", "diagonal", "n", "by", "n", "matrices", ",", "is", "called", "cartan", "subalgebra", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the lie subalgebra tn of gln", "start": 0, "end": 28, "i_start": 0, "i_end": 5}, "verb": {"text": "is called", "start": 77, "end": 86, "i_start": 16, "i_end": 17}}], "id": 2844}, {"sent": "otherwise , the orbit contains only one element and is called a fixed orbit .", "tokens": ["otherwise", ",", "the", "orbit", "contains", "only", "one", "element", "and", "is", "called", "a", "fixed", "orbit", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the orbit", "start": 12, "end": 21, "i_start": 2, "i_end": 3}, "verb": {"text": "contains", "start": 22, "end": 30, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the orbit", "start": 12, "end": 21, "i_start": 2, "i_end": 3}, "verb": {"text": "called", "start": 55, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "orbit", "start": 16, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "contains", "start": 22, "end": 30, "i_start": 4, "i_end": 4}}], "id": 2845}, {"sent": "along this direction , convolutional neural networks have been very successful in various computer vision and natural language processing tasks in recent years .", "tokens": ["along", "this", "direction", ",", "convolutional", "neural", "networks", "have", "been", "very", "successful", "in", "various", "computer", "vision", "and", "natural", "language", "processing", "tasks", "in", "recent", "years", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 23, "end": 52, "i_start": 4, "i_end": 6}, "verb": {"text": "have been", "start": 53, "end": 62, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "successful", "start": 68, "end": 78, "i_start": 10, "i_end": 10}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "processing", "start": 127, "end": 137, "i_start": 18, "i_end": 18}}], "id": 2846}, {"sent": "merlin is a national facility operated by the university of manchester at jodrell bank observatory on behalf of the uk science and technology facilities council .", "tokens": ["merlin", "is", "a", "national", "facility", "operated", "by", "the", "university", "of", "manchester", "at", "jodrell", "bank", "observatory", "on", "behalf", "of", "the", "uk", "science", "and", "technology", "facilities", "council", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "merlin", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 7, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "university", "start": 46, "end": 56, "i_start": 8, "i_end": 8}, "action": {"text": "operated", "start": 30, "end": 38, "i_start": 5, "i_end": 5}}], "id": 2847}, {"sent": "we compare our proposed approach with state-of-the-art blind deblurring methods , including conventional deblurring methods .", "tokens": ["we", "compare", "our", "proposed", "approach", "with", "state", "-", "of", "-", "the", "-", "art", "blind", "deblurring", "methods", ",", "including", "conventional", "deblurring", "methods", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "approach", "start": 24, "end": 32, "i_start": 4, "i_end": 4}}], "id": 2848}, {"sent": "we assume that momentum space is a metric manifold with a preferred point , the origin that corresponds to zero energy and momenta .", "tokens": ["we", "assume", "that", "momentum", "space", "is", "a", "metric", "manifold", "with", "a", "preferred", "point", ",", "the", "origin", "that", "corresponds", "to", "zero", "energy", "and", "momenta", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 2849}, {"sent": "we refer the reader to , eg , for a treatment particularly tailored for our purposes .", "tokens": ["we", "refer", "the", "reader", "to", ",", "eg", ",", "for", "a", "treatment", "particularly", "tailored", "for", "our", "purposes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2850}, {"sent": "among them , convolutional neural networks have been demonstrated to be extremely successful in computer vision .", "tokens": ["among", "them", ",", "convolutional", "neural", "networks", "have", "been", "demonstrated", "to", "be", "extremely", "successful", "in", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 13, "end": 42, "i_start": 3, "i_end": 5}, "verb": {"text": "have been demonstrated", "start": 43, "end": 65, "i_start": 6, "i_end": 8}}, {"character": {"text": "networks", "start": 34, "end": 42, "i_start": 5, "i_end": 5}, "action": {"text": "successful", "start": 82, "end": 92, "i_start": 12, "i_end": 12}}], "id": 2851}, {"sent": "graphene is a two-dimensional system with high carrier mobility that provides a rich playground for building novel high-frequency devices1 .", "tokens": ["graphene", "is", "a", "two", "-", "dimensional", "system", "with", "high", "carrier", "mobility", "that", "provides", "a", "rich", "playground", "for", "building", "novel", "high", "-", "frequency", "devices1", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "graphene", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "system", "start": 30, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "provides", "start": 69, "end": 77, "i_start": 12, "i_end": 12}}], "id": 2852}, {"sent": "we use the liblinear implementation with l 2 regularization .", "tokens": ["we", "use", "the", "liblinear", "implementation", "with", "l", "2", "regularization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 2853}, {"sent": "convolutional neural networks have been extremely successful across many domains in machine learning and computer vision .", "tokens": ["convolutional", "neural", "networks", "have", "been", "extremely", "successful", "across", "many", "domains", "in", "machine", "learning", "and", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 50, "end": 60, "i_start": 6, "i_end": 6}}], "id": 2854}, {"sent": "in recent years , neural networks have been effectively applied in various problems such as voice recognition .", "tokens": ["in", "recent", "years", ",", "neural", "networks", "have", "been", "effectively", "applied", "in", "various", "problems", "such", "as", "voice", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 18, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "applied", "start": 56, "end": 63, "i_start": 9, "i_end": 9}}, {"subject": {"text": "neural networks", "start": 18, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "have been", "start": 34, "end": 43, "i_start": 6, "i_end": 7}}], "id": 2855}, {"sent": "we utilize faster-rcnn as object detector trained on the 35 objects from ms-coco datasets .", "tokens": ["we", "utilize", "faster", "-", "rcnn", "as", "object", "detector", "trained", "on", "the", "35", "objects", "from", "ms", "-", "coco", "datasets", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "utilize", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "utilize", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 2856}, {"sent": "previous work has argued that a cloudbased implementation of an iot coordination framework could be susceptible to cloud disconnection .", "tokens": ["previous", "work", "has", "argued", "that", "a", "cloudbased", "implementation", "of", "an", "iot", "coordination", "framework", "could", "be", "susceptible", "to", "cloud", "disconnection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "previous work", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has argued", "start": 14, "end": 24, "i_start": 2, "i_end": 3}}, {"subject": {"text": "previous work", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "be", "start": 97, "end": 99, "i_start": 14, "i_end": 14}}, {"character": {"text": "work", "start": 9, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "argued", "start": 18, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2857}, {"sent": "all the other convolutional layers use normalized initialization following the method presented by xavier .", "tokens": ["all", "the", "other", "convolutional", "layers", "use", "normalized", "initialization", "following", "the", "method", "presented", "by", "xavier", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "all the other convolutional layers", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "use", "start": 35, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "layers", "start": 28, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 35, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "xavier", "start": 99, "end": 105, "i_start": 13, "i_end": 13}, "action": {"text": "presented", "start": 86, "end": 95, "i_start": 11, "i_end": 11}}], "id": 2858}, {"sent": "recently , graph convolutional networks have been widely studied for graph data representation and learning .", "tokens": ["recently", ",", "graph", "convolutional", "networks", "have", "been", "widely", "studied", "for", "graph", "data", "representation", "and", "learning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "graph convolutional networks", "start": 11, "end": 39, "i_start": 2, "i_end": 4}, "verb": {"text": "studied", "start": 57, "end": 64, "i_start": 8, "i_end": 8}}, {"subject": {"text": "graph convolutional networks", "start": 11, "end": 39, "i_start": 2, "i_end": 4}, "verb": {"text": "have been", "start": 40, "end": 49, "i_start": 5, "i_end": 6}}], "id": 2859}, {"sent": "for this dataset , we use deep learning features by training a googlenet style convnet .", "tokens": ["for", "this", "dataset", ",", "we", "use", "deep", "learning", "features", "by", "training", "a", "googlenet", "style", "convnet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 22, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 22, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "training", "start": 52, "end": 60, "i_start": 10, "i_end": 10}}], "id": 2860}, {"sent": "convolutional neural networks have recently been applied to various computer vision tasks such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "been", "applied", "to", "various", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "been applied", "start": 44, "end": 56, "i_start": 5, "i_end": 6}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}], "id": 2861}, {"sent": "more specifically , a qubit is a two-dimensional pure quantum state living in h2 .", "tokens": ["more", "specifically", ",", "a", "qubit", "is", "a", "two", "-", "dimensional", "pure", "quantum", "state", "living", "in", "h2", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a qubit", "start": 20, "end": 27, "i_start": 3, "i_end": 4}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "state", "start": 62, "end": 67, "i_start": 12, "i_end": 12}, "action": {"text": "living", "start": 68, "end": 74, "i_start": 13, "i_end": 13}}], "id": 2862}, {"sent": "motivated by the success of convolutional neural networks , recent work has adopted the cnn framework to learn graph representations in a number of applications .", "tokens": ["motivated", "by", "the", "success", "of", "convolutional", "neural", "networks", ",", "recent", "work", "has", "adopted", "the", "cnn", "framework", "to", "learn", "graph", "representations", "in", "a", "number", "of", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent work", "start": 60, "end": 71, "i_start": 9, "i_end": 10}, "verb": {"text": "has adopted", "start": 72, "end": 83, "i_start": 11, "i_end": 12}}, {"character": {"text": "work", "start": 67, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "adopted", "start": 76, "end": 83, "i_start": 12, "i_end": 12}}, {"character": {"text": "work", "start": 67, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "learn", "start": 105, "end": 110, "i_start": 17, "i_end": 17}}, {"character": {"text": "success", "start": 17, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "motivated", "start": 0, "end": 9, "i_start": 0, "i_end": 0}}, {"character": {"text": "networks", "start": 49, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "success", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2863}, {"sent": "convolutional neural networks have shown remarkable performance in domains like vision and nlp .", "tokens": ["convolutional", "neural", "networks", "have", "shown", "remarkable", "performance", "in", "domains", "like", "vision", "and", "nlp", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 35, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 52, "end": 63, "i_start": 6, "i_end": 6}}], "id": 2864}, {"sent": "note that our method differs from earlier investigations , in which the authors directly compared the properties of the two lines .", "tokens": ["note", "that", "our", "method", "differs", "from", "earlier", "investigations", ",", "in", "which", "the", "authors", "directly", "compared", "the", "properties", "of", "the", "two", "lines", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our method", "start": 10, "end": 20, "i_start": 2, "i_end": 3}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "our method", "start": 10, "end": 20, "i_start": 2, "i_end": 3}, "verb": {"text": "differs", "start": 21, "end": 28, "i_start": 4, "i_end": 4}}], "id": 2865}, {"sent": "overhead quality contour in wireless signaling qo vs .", "tokens": ["overhead", "quality", "contour", "in", "wireless", "signaling", "qo", "vs", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2866}, {"sent": "techniques such as dropout have been proposed to reduce overfitting and increase generalization .", "tokens": ["techniques", "such", "as", "dropout", "have", "been", "proposed", "to", "reduce", "overfitting", "and", "increase", "generalization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "techniques such as dropout", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "have been proposed", "start": 27, "end": 45, "i_start": 4, "i_end": 6}}], "id": 2867}, {"sent": "in most scenarios the lsp is neutral and is called the neutralino , \u03c7 .", "tokens": ["in", "most", "scenarios", "the", "lsp", "is", "neutral", "and", "is", "called", "the", "neutralino", ",", "\u03c7", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lsp", "start": 18, "end": 25, "i_start": 3, "i_end": 4}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the lsp", "start": 18, "end": 25, "i_start": 3, "i_end": 4}, "verb": {"text": "called", "start": 44, "end": 50, "i_start": 9, "i_end": 9}}], "id": 2868}, {"sent": "to perform these tests , we used the scikit-learn framework in python .", "tokens": ["to", "perform", "these", "tests", ",", "we", "used", "the", "scikit", "-", "learn", "framework", "in", "python", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "verb": {"text": "used", "start": 28, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "used", "start": 28, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "perform", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 2869}, {"sent": "the error from the theory is fully correlated .", "tokens": ["the", "error", "from", "the", "theory", "is", "fully", "correlated", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the error from the theory", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "correlated", "start": 35, "end": 45, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the error from the theory", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 5, "i_end": 5}}], "id": 2870}, {"sent": "in recent years , deep neural networks have gained enormous popularity for a wide spectrum of applications , ranging from image recognition .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "gained", "enormous", "popularity", "for", "a", "wide", "spectrum", "of", "applications", ",", "ranging", "from", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have gained", "start": 39, "end": 50, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "gained", "start": 44, "end": 50, "i_start": 8, "i_end": 8}}], "id": 2871}, {"sent": "all calculations were carried out using the vienna ab-initio simulation package with the scan exchange-correlation functional .", "tokens": ["all", "calculations", "were", "carried", "out", "using", "the", "vienna", "ab", "-", "initio", "simulation", "package", "with", "the", "scan", "exchange", "-", "correlation", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all calculations", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were carried out", "start": 17, "end": 33, "i_start": 2, "i_end": 4}}], "id": 2872}, {"sent": "this method was employed in the spectacular proof of the riemannian penrose inequality in general relativity due to huisken and ilmanen .", "tokens": ["this", "method", "was", "employed", "in", "the", "spectacular", "proof", "of", "the", "riemannian", "penrose", "inequality", "in", "general", "relativity", "due", "to", "huisken", "and", "ilmanen", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this method", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "was employed", "start": 12, "end": 24, "i_start": 2, "i_end": 3}}], "id": 2873}, {"sent": "in recent years , deep learning has dramatically improved the state of the art in several research domains including computer vision , speech recognition , and natural language processing .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "has", "dramatically", "improved", "the", "state", "of", "the", "art", "in", "several", "research", "domains", "including", "computer", "vision", ",", "speech", "recognition", ",", "and", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 18, "end": 31, "i_start": 4, "i_end": 5}, "verb": {"text": "improved", "start": 49, "end": 57, "i_start": 8, "i_end": 8}}, {"subject": {"text": "deep learning", "start": 18, "end": 31, "i_start": 4, "i_end": 5}, "verb": {"text": "has", "start": 32, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "learning", "start": 23, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "improved", "start": 49, "end": 57, "i_start": 8, "i_end": 8}}], "id": 2874}, {"sent": "our method is evaluated on the challenging kitti tracking benchmark .", "tokens": ["our", "method", "is", "evaluated", "on", "the", "challenging", "kitti", "tracking", "benchmark", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our method", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is evaluated", "start": 11, "end": 23, "i_start": 2, "i_end": 3}}, {"character": {"text": "benchmark", "start": 58, "end": 67, "i_start": 9, "i_end": 9}, "action": {"text": "tracking", "start": 49, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "benchmark", "start": 58, "end": 67, "i_start": 9, "i_end": 9}, "action": {"text": "challenging", "start": 31, "end": 42, "i_start": 6, "i_end": 6}}], "id": 2875}, {"sent": "the emission lines were fitted by a single gaussian in each spatial bin along the slit using the idl mpfit library .", "tokens": ["the", "emission", "lines", "were", "fitted", "by", "a", "single", "gaussian", "in", "each", "spatial", "bin", "along", "the", "slit", "using", "the", "idl", "mpfit", "library", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the emission lines", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "were fitted", "start": 19, "end": 30, "i_start": 3, "i_end": 4}}], "id": 2876}, {"sent": "this is a variational algorithm for the ground state in the manifold of matrix product states .", "tokens": ["this", "is", "a", "variational", "algorithm", "for", "the", "ground", "state", "in", "the", "manifold", "of", "matrix", "product", "states", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 2877}, {"sent": "ruan , on approximation properties for operator spaces .", "tokens": ["ruan", ",", "on", "approximation", "properties", "for", "operator", "spaces", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2878}, {"sent": "many progress has been made in recent years with the rapid development of convolutional neural networks .", "tokens": ["many", "progress", "has", "been", "made", "in", "recent", "years", "with", "the", "rapid", "development", "of", "convolutional", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many progress", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has been made", "start": 14, "end": 27, "i_start": 2, "i_end": 4}}], "id": 2879}, {"sent": "li et al proposed a multi-task learning model that learns hard region-level and soft pixel-level attention jointly to produce more discriminative feature representations .", "tokens": ["li", "et", "al", "proposed", "a", "multi", "-", "task", "learning", "model", "that", "learns", "hard", "region", "-", "level", "and", "soft", "pixel", "-", "level", "attention", "jointly", "to", "produce", "more", "discriminative", "feature", "representations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "li et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "li", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "model", "start": 40, "end": 45, "i_start": 9, "i_end": 9}, "action": {"text": "learning", "start": 31, "end": 39, "i_start": 8, "i_end": 8}}, {"character": {"text": "attention", "start": 97, "end": 106, "i_start": 21, "i_end": 21}, "action": {"text": "produce", "start": 118, "end": 125, "i_start": 24, "i_end": 24}}, {"character": {"text": "level", "start": 70, "end": 75, "i_start": 15, "i_end": 15}, "action": {"text": "produce", "start": 118, "end": 125, "i_start": 24, "i_end": 24}}, {"character": {"text": "region", "start": 63, "end": 69, "i_start": 13, "i_end": 13}, "action": {"text": "produce", "start": 118, "end": 125, "i_start": 24, "i_end": 24}}, {"character": {"text": "level", "start": 91, "end": 96, "i_start": 20, "i_end": 20}, "action": {"text": "produce", "start": 118, "end": 125, "i_start": 24, "i_end": 24}}, {"character": {"text": "pixel", "start": 85, "end": 90, "i_start": 18, "i_end": 18}, "action": {"text": "produce", "start": 118, "end": 125, "i_start": 24, "i_end": 24}}, {"character": {"text": "representations", "start": 154, "end": 169, "i_start": 28, "i_end": 28}, "action": {"text": "discriminative", "start": 131, "end": 145, "i_start": 26, "i_end": 26}}], "id": 2880}, {"sent": "cluster algebras were invented by fomin and zelevinsky in order to provide a combinatorial approach to canonical bases and total positivity .", "tokens": ["cluster", "algebras", "were", "invented", "by", "fomin", "and", "zelevinsky", "in", "order", "to", "provide", "a", "combinatorial", "approach", "to", "canonical", "bases", "and", "total", "positivity", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were invented", "start": 17, "end": 30, "i_start": 2, "i_end": 3}}, {"character": {"text": "fomin", "start": 34, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "invented", "start": 22, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "zelevinsky", "start": 44, "end": 54, "i_start": 7, "i_end": 7}, "action": {"text": "invented", "start": 22, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "fomin", "start": 34, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "provide", "start": 67, "end": 74, "i_start": 11, "i_end": 11}}, {"character": {"text": "zelevinsky", "start": 44, "end": 54, "i_start": 7, "i_end": 7}, "action": {"text": "provide", "start": 67, "end": 74, "i_start": 11, "i_end": 11}}], "id": 2881}, {"sent": "the initial weights throughout the network are initialized using the xavier initialization scheme .", "tokens": ["the", "initial", "weights", "throughout", "the", "network", "are", "initialized", "using", "the", "xavier", "initialization", "scheme", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the initial weights throughout the network", "start": 0, "end": 42, "i_start": 0, "i_end": 5}, "verb": {"text": "are initialized", "start": 43, "end": 58, "i_start": 6, "i_end": 7}}], "id": 2882}, {"sent": "peaks in st-fmr spectra v mix arise from resonant excitation of spin wave eigenmodes of the mtj .", "tokens": ["peaks", "in", "st", "-", "fmr", "spectra", "v", "mix", "arise", "from", "resonant", "excitation", "of", "spin", "wave", "eigenmodes", "of", "the", "mtj", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "peaks in st-fmr spectra v mix", "start": 0, "end": 29, "i_start": 0, "i_end": 7}, "verb": {"text": "arise", "start": 30, "end": 35, "i_start": 8, "i_end": 8}}, {"character": {"text": "excitation", "start": 50, "end": 60, "i_start": 11, "i_end": 11}, "action": {"text": "arise", "start": 30, "end": 35, "i_start": 8, "i_end": 8}}], "id": 2883}, {"sent": "exchange and correlations are considered in the generalized gradient approximation , following the perdew-burke-ernzerhof parametrization scheme .", "tokens": ["exchange", "and", "correlations", "are", "considered", "in", "the", "generalized", "gradient", "approximation", ",", "following", "the", "perdew", "-", "burke", "-", "ernzerhof", "parametrization", "scheme", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "exchange and correlations", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "are considered", "start": 26, "end": 40, "i_start": 3, "i_end": 4}}], "id": 2884}, {"sent": "a computationally efficient way of exactly solving the ils problem is the sphere decoder .", "tokens": ["a", "computationally", "efficient", "way", "of", "exactly", "solving", "the", "ils", "problem", "is", "the", "sphere", "decoder", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a computationally efficient way of exactly solving the ils problem", "start": 0, "end": 66, "i_start": 0, "i_end": 9}, "verb": {"text": "is", "start": 67, "end": 69, "i_start": 10, "i_end": 10}}], "id": 2885}, {"sent": "in recent works , an intriguing phenomenon was revealed whereby it was shown that weakly-connected graphs enable certain agents to control the opinion of other agents to great degree , irrespective of the observations sensed by these latter agents .", "tokens": ["in", "recent", "works", ",", "an", "intriguing", "phenomenon", "was", "revealed", "whereby", "it", "was", "shown", "that", "weakly", "-", "connected", "graphs", "enable", "certain", "agents", "to", "control", "the", "opinion", "of", "other", "agents", "to", "great", "degree", ",", "irrespective", "of", "the", "observations", "sensed", "by", "these", "latter", "agents", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "an intriguing phenomenon", "start": 18, "end": 42, "i_start": 4, "i_end": 6}, "verb": {"text": "was revealed", "start": 43, "end": 55, "i_start": 7, "i_end": 8}}, {"subject": {"text": "it", "start": 64, "end": 66, "i_start": 10, "i_end": 10}, "verb": {"text": "shown", "start": 71, "end": 76, "i_start": 12, "i_end": 12}}, {"character": {"text": "phenomenon", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "intriguing", "start": 21, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "graphs", "start": 99, "end": 105, "i_start": 17, "i_end": 17}, "action": {"text": "enable", "start": 106, "end": 112, "i_start": 18, "i_end": 18}}, {"character": {"text": "agents", "start": 121, "end": 127, "i_start": 20, "i_end": 20}, "action": {"text": "control", "start": 131, "end": 138, "i_start": 22, "i_end": 22}}, {"character": {"text": "agents", "start": 160, "end": 166, "i_start": 27, "i_end": 27}, "action": {"text": "opinion", "start": 143, "end": 150, "i_start": 24, "i_end": 24}}, {"character": {"text": "agents", "start": 241, "end": 247, "i_start": 40, "i_end": 40}, "action": {"text": "observations", "start": 205, "end": 217, "i_start": 35, "i_end": 35}}, {"character": {"text": "agents", "start": 121, "end": 127, "i_start": 20, "i_end": 20}, "action": {"text": "sensed", "start": 218, "end": 224, "i_start": 36, "i_end": 36}}], "id": 2886}, {"sent": "it is evident that the integration cost per unit output energy is the smaller for the whole of japan due to the small coefficient of variation .", "tokens": ["it", "is", "evident", "that", "the", "integration", "cost", "per", "unit", "output", "energy", "is", "the", "smaller", "for", "the", "whole", "of", "japan", "due", "to", "the", "small", "coefficient", "of", "variation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 63, "end": 65, "i_start": 11, "i_end": 11}}], "id": 2887}, {"sent": "the notion of quasi-isometry is an equivalence relation between metric spaces which plays a significant role in the study of discrete groups , for an overview see and references therein .", "tokens": ["the", "notion", "of", "quasi", "-", "isometry", "is", "an", "equivalence", "relation", "between", "metric", "spaces", "which", "plays", "a", "significant", "role", "in", "the", "study", "of", "discrete", "groups", ",", "for", "an", "overview", "see", "and", "references", "therein", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the notion of quasi-isometry", "start": 0, "end": 28, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "relation", "start": 47, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "plays", "start": 84, "end": 89, "i_start": 14, "i_end": 14}}], "id": 2888}, {"sent": "another ingredient is the partial elimination ideal theory .", "tokens": ["another", "ingredient", "is", "the", "partial", "elimination", "ideal", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another ingredient", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}], "id": 2889}, {"sent": "worthey g , faber sm , gonzales j , burstein d .", "tokens": ["worthey", "g", ",", "faber", "sm", ",", "gonzales", "j", ",", "burstein", "d", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2890}, {"sent": "recently , deep learning based methods , such as faster r-cnn , have achieved significant improvement in object detection with real-time performance .", "tokens": ["recently", ",", "deep", "learning", "based", "methods", ",", "such", "as", "faster", "r", "-", "cnn", ",", "have", "achieved", "significant", "improvement", "in", "object", "detection", "with", "real", "-", "time", "performance", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep learning based methods", "start": 11, "end": 38, "i_start": 2, "i_end": 5}, "verb": {"text": "have achieved", "start": 64, "end": 77, "i_start": 14, "i_end": 15}}, {"character": {"text": "methods", "start": 31, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 69, "end": 77, "i_start": 15, "i_end": 15}}], "id": 2891}, {"sent": "the set of left ideals and their lattice structure .", "tokens": ["the", "set", "of", "left", "ideals", "and", "their", "lattice", "structure", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2892}, {"sent": "show that quotients of amenable groups are amenable .", "tokens": ["show", "that", "quotients", "of", "amenable", "groups", "are", "amenable", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2893}, {"sent": "for this reason we introduce another security condition based on the shannon entropy of the string .", "tokens": ["for", "this", "reason", "we", "introduce", "another", "security", "condition", "based", "on", "the", "shannon", "entropy", "of", "the", "string", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "introduce", "start": 19, "end": 28, "i_start": 4, "i_end": 4}}], "id": 2894}, {"sent": "we use the output of a fully-connected layer in a resnet-50 model as the global feature .", "tokens": ["we", "use", "the", "output", "of", "a", "fully", "-", "connected", "layer", "in", "a", "resnet-50", "model", "as", "the", "global", "feature", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 2895}, {"sent": "this will be discussed at length for local models in section five , and for compact calabi-yau threefolds in section seven .", "tokens": ["this", "will", "be", "discussed", "at", "length", "for", "local", "models", "in", "section", "five", ",", "and", "for", "compact", "calabi", "-", "yau", "threefolds", "in", "section", "seven", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "will be discussed", "start": 5, "end": 22, "i_start": 1, "i_end": 3}}], "id": 2896}, {"sent": "deep learning has brought significant breakthroughs in many computer vision tasks , including object detection .", "tokens": ["deep", "learning", "has", "brought", "significant", "breakthroughs", "in", "many", "computer", "vision", "tasks", ",", "including", "object", "detection", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has brought", "start": 14, "end": 25, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "breakthroughs", "start": 38, "end": 51, "i_start": 5, "i_end": 5}}], "id": 2897}, {"sent": "specifically , following mnih et al , our q-value function is approximated with a deep neural network .", "tokens": ["specifically", ",", "following", "mnih", "et", "al", ",", "our", "q", "-", "value", "function", "is", "approximated", "with", "a", "deep", "neural", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2898}, {"sent": "however , to perform the integration over the moduli space properly , we should introduce the contact terms .", "tokens": ["however", ",", "to", "perform", "the", "integration", "over", "the", "moduli", "space", "properly", ",", "we", "should", "introduce", "the", "contact", "terms", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 70, "end": 72, "i_start": 12, "i_end": 12}, "verb": {"text": "should introduce", "start": 73, "end": 89, "i_start": 13, "i_end": 14}}, {"character": {"text": "we", "start": 70, "end": 72, "i_start": 12, "i_end": 12}, "action": {"text": "introduce", "start": 80, "end": 89, "i_start": 14, "i_end": 14}}], "id": 2899}, {"sent": "the vertical dotted lines show the critical coupling strength obtained in this work .", "tokens": ["the", "vertical", "dotted", "lines", "show", "the", "critical", "coupling", "strength", "obtained", "in", "this", "work", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the vertical dotted lines", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "show", "start": 26, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "lines", "start": 20, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "show", "start": 26, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "work", "start": 79, "end": 83, "i_start": 12, "i_end": 12}, "action": {"text": "obtained", "start": 62, "end": 70, "i_start": 9, "i_end": 9}}], "id": 2900}, {"sent": "d eep convolutional neural networks have achieved great success in many computer vision tasks , especially in visual recognition .", "tokens": ["d", "eep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "many", "computer", "vision", "tasks", ",", "especially", "in", "visual", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "d eep convolutional neural networks", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "have achieved", "start": 36, "end": 49, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 27, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 41, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 27, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "success", "start": 56, "end": 63, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 27, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "recognition", "start": 117, "end": 128, "i_start": 18, "i_end": 18}}], "id": 2901}, {"sent": "a case for which differential calculi have been worked out is the structure of q-deformed quantum spaces .", "tokens": ["a", "case", "for", "which", "differential", "calculi", "have", "been", "worked", "out", "is", "the", "structure", "of", "q", "-", "deformed", "quantum", "spaces", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a case for which differential calculi have been worked out", "start": 0, "end": 58, "i_start": 0, "i_end": 9}, "verb": {"text": "is", "start": 59, "end": 61, "i_start": 10, "i_end": 10}}], "id": 2902}, {"sent": "these networks are trained with adam optimizer for 200 epochs .", "tokens": ["these", "networks", "are", "trained", "with", "adam", "optimizer", "for", "200", "epochs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these networks", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are trained", "start": 15, "end": 26, "i_start": 2, "i_end": 3}}], "id": 2903}, {"sent": "gabrilovich and markovitch evaluate their method on ws-353 , a set of 352 english word pairs , the semantic relatedness of which has been evaluated by 15-16 human judges .", "tokens": ["gabrilovich", "and", "markovitch", "evaluate", "their", "method", "on", "ws-353", ",", "a", "set", "of", "352", "english", "word", "pairs", ",", "the", "semantic", "relatedness", "of", "which", "has", "been", "evaluated", "by", "15", "-", "16", "human", "judges", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "gabrilovich and markovitch", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "evaluate", "start": 27, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "gabrilovich", "start": 0, "end": 11, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 27, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "markovitch", "start": 16, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "evaluate", "start": 27, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "15-16", "start": 151, "end": 156, "i_start": 26, "i_end": 28}, "action": {"text": "evaluated", "start": 138, "end": 147, "i_start": 24, "i_end": 24}}, {"character": {"text": "human", "start": 157, "end": 162, "i_start": 29, "i_end": 29}, "action": {"text": "evaluated", "start": 138, "end": 147, "i_start": 24, "i_end": 24}}], "id": 2904}, {"sent": "social network information is available in a wide range of contexts , from social media to political speech to historical texts .", "tokens": ["social", "network", "information", "is", "available", "in", "a", "wide", "range", "of", "contexts", ",", "from", "social", "media", "to", "political", "speech", "to", "historical", "texts", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "social network information", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 3, "i_end": 3}}], "id": 2905}, {"sent": "our proofs are quite different from because of the non-compactness of \u03c3 .", "tokens": ["our", "proofs", "are", "quite", "different", "from", "because", "of", "the", "non", "-", "compactness", "of", "\u03c3", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our proofs", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 11, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "-compactness", "start": 54, "end": 66, "i_start": 10, "i_end": 11}, "action": {"text": "because", "start": 36, "end": 43, "i_start": 6, "i_end": 6}}], "id": 2906}, {"sent": "a formal framework for specifying sequent calculus proof systems .", "tokens": ["a", "formal", "framework", "for", "specifying", "sequent", "calculus", "proof", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "framework", "start": 9, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "specifying", "start": 23, "end": 33, "i_start": 4, "i_end": 4}}], "id": 2907}, {"sent": "recent success in computer vision and image retrieval are closely related to convolutional neural networks .", "tokens": ["recent", "success", "in", "computer", "vision", "and", "image", "retrieval", "are", "closely", "related", "to", "convolutional", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "recent success in computer vision and image retrieval", "start": 0, "end": 53, "i_start": 0, "i_end": 7}, "verb": {"text": "related", "start": 66, "end": 73, "i_start": 10, "i_end": 10}}, {"subject": {"text": "recent success in computer vision and image retrieval", "start": 0, "end": 53, "i_start": 0, "i_end": 7}, "verb": {"text": "are", "start": 54, "end": 57, "i_start": 8, "i_end": 8}}], "id": 2908}, {"sent": "as can be seen , the proposed algorithm is consistently faster than the algorithm of and requires significantly less memory for larger graphs .", "tokens": ["as", "can", "be", "seen", ",", "the", "proposed", "algorithm", "is", "consistently", "faster", "than", "the", "algorithm", "of", "and", "requires", "significantly", "less", "memory", "for", "larger", "graphs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the proposed algorithm", "start": 17, "end": 39, "i_start": 5, "i_end": 7}, "verb": {"text": "is", "start": 40, "end": 42, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the proposed algorithm", "start": 17, "end": 39, "i_start": 5, "i_end": 7}, "verb": {"text": "requires", "start": 89, "end": 97, "i_start": 16, "i_end": 16}}], "id": 2909}, {"sent": "similarly , zeiler et al proposed a deconvnet-based network to visualize activations .", "tokens": ["similarly", ",", "zeiler", "et", "al", "proposed", "a", "deconvnet", "-", "based", "network", "to", "visualize", "activations", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 19, "end": 24, "i_start": 3, "i_end": 4}, "verb": {"text": "proposed", "start": 25, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "zeiler", "start": 12, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "proposed", "start": 25, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "zeiler", "start": 12, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "visualize", "start": 63, "end": 72, "i_start": 12, "i_end": 12}}], "id": 2910}, {"sent": "in this work , we propose to address the inpainting problem using the recently emerged convolutional neural network .", "tokens": ["in", "this", "work", ",", "we", "propose", "to", "address", "the", "inpainting", "problem", "using", "the", "recently", "emerged", "convolutional", "neural", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "propose", "start": 18, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "propose", "start": 18, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "address", "start": 29, "end": 36, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "using", "start": 60, "end": 65, "i_start": 11, "i_end": 11}}], "id": 2911}, {"sent": "for some problems there are quantum algorithms which are asymptotically faster than the known classical algorithms .", "tokens": ["for", "some", "problems", "there", "are", "quantum", "algorithms", "which", "are", "asymptotically", "faster", "than", "the", "known", "classical", "algorithms", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 18, "end": 23, "i_start": 3, "i_end": 3}, "verb": {"text": "are", "start": 24, "end": 27, "i_start": 4, "i_end": 4}}], "id": 2912}, {"sent": "we train both networks using a variant of the stochastic gradient descent method .", "tokens": ["we", "train", "both", "networks", "using", "a", "variant", "of", "the", "stochastic", "gradient", "descent", "method", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2913}, {"sent": "without loss of generality , we take the vertices of k c to be as shown in figure 4 .", "tokens": ["without", "loss", "of", "generality", ",", "we", "take", "the", "vertices", "of", "k", "c", "to", "be", "as", "shown", "in", "figure", "4", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "verb": {"text": "take", "start": 32, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "take", "start": 32, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "figure 4", "start": 75, "end": 83, "i_start": 17, "i_end": 18}, "action": {"text": "shown", "start": 66, "end": 71, "i_start": 15, "i_end": 15}}], "id": 2914}, {"sent": "the stabilizer is a finite abelian group , and allows a straightforward characterization of the error-correcting properties of the code .", "tokens": ["the", "stabilizer", "is", "a", "finite", "abelian", "group", ",", "and", "allows", "a", "straightforward", "characterization", "of", "the", "error", "-", "correcting", "properties", "of", "the", "code", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the stabilizer", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the stabilizer", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "allows", "start": 47, "end": 53, "i_start": 9, "i_end": 9}}, {"character": {"text": "stabilizer", "start": 4, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "allows", "start": 47, "end": 53, "i_start": 9, "i_end": 9}}], "id": 2915}, {"sent": "in the last two years , the performance of object detection has been significantly improved with the success of novel deep convolutional neural networks .", "tokens": ["in", "the", "last", "two", "years", ",", "the", "performance", "of", "object", "detection", "has", "been", "significantly", "improved", "with", "the", "success", "of", "novel", "deep", "convolutional", "neural", "networks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the performance of object detection", "start": 24, "end": 59, "i_start": 6, "i_end": 10}, "verb": {"text": "improved", "start": 83, "end": 91, "i_start": 14, "i_end": 14}}, {"subject": {"text": "the performance of object detection", "start": 24, "end": 59, "i_start": 6, "i_end": 10}, "verb": {"text": "has been", "start": 60, "end": 68, "i_start": 11, "i_end": 12}}, {"character": {"text": "success", "start": 101, "end": 108, "i_start": 17, "i_end": 17}, "action": {"text": "improved", "start": 83, "end": 91, "i_start": 14, "i_end": 14}}, {"character": {"text": "networks", "start": 144, "end": 152, "i_start": 23, "i_end": 23}, "action": {"text": "success", "start": 101, "end": 108, "i_start": 17, "i_end": 17}}], "id": 2916}, {"sent": "subsequently , it was shown in that noncommutative gauge theories will generically arise from open string theory in the presence of a constant neveu-schwarz b-field .", "tokens": ["subsequently", ",", "it", "was", "shown", "in", "that", "noncommutative", "gauge", "theories", "will", "generically", "arise", "from", "open", "string", "theory", "in", "the", "presence", "of", "a", "constant", "neveu", "-", "schwarz", "b", "-", "field", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "was shown", "start": 18, "end": 27, "i_start": 3, "i_end": 4}}], "id": 2917}, {"sent": "counterexample in the maxwell molecules case with only mass , energy and entropy bounds .", "tokens": ["counterexample", "in", "the", "maxwell", "molecules", "case", "with", "only", "mass", ",", "energy", "and", "entropy", "bounds", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2918}, {"sent": "in the last two years , the performance of object detection has been significantly improved with the success of novel deep convolutional neural networks .", "tokens": ["in", "the", "last", "two", "years", ",", "the", "performance", "of", "object", "detection", "has", "been", "significantly", "improved", "with", "the", "success", "of", "novel", "deep", "convolutional", "neural", "networks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the performance of object detection", "start": 24, "end": 59, "i_start": 6, "i_end": 10}, "verb": {"text": "improved", "start": 83, "end": 91, "i_start": 14, "i_end": 14}}, {"subject": {"text": "the performance of object detection", "start": 24, "end": 59, "i_start": 6, "i_end": 10}, "verb": {"text": "has been", "start": 60, "end": 68, "i_start": 11, "i_end": 12}}, {"character": {"text": "success", "start": 101, "end": 108, "i_start": 17, "i_end": 17}, "action": {"text": "improved", "start": 83, "end": 91, "i_start": 14, "i_end": 14}}, {"character": {"text": "networks", "start": 144, "end": 152, "i_start": 23, "i_end": 23}, "action": {"text": "success", "start": 101, "end": 108, "i_start": 17, "i_end": 17}}], "id": 2919}, {"sent": "it is shown that the basic mathematical structure of quantum mechanics like the probability amplitude , born rule , probability density current , commutation relations , momentum operator , uncertainty relations , rules for including the scalar and vector potentials and existence of antiparticles can be derived from the definition of the mean values of the space coordinates and time .", "tokens": ["it", "is", "shown", "that", "the", "basic", "mathematical", "structure", "of", "quantum", "mechanics", "like", "the", "probability", "amplitude", ",", "born", "rule", ",", "probability", "density", "current", ",", "commutation", "relations", ",", "momentum", "operator", ",", "uncertainty", "relations", ",", "rules", "for", "including", "the", "scalar", "and", "vector", "potentials", "and", "existence", "of", "antiparticles", "can", "be", "derived", "from", "the", "definition", "of", "the", "mean", "values", "of", "the", "space", "coordinates", "and", "time", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is shown", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"subject": {"text": "the basic mathematical structure of quantum mechanics like the probability amplitude , born rule , probability density current , commutation relations", "start": 17, "end": 167, "i_start": 4, "i_end": 24}, "verb": {"text": "derived", "start": 305, "end": 312, "i_start": 46, "i_end": 46}}, {"character": {"text": "rules", "start": 214, "end": 219, "i_start": 32, "i_end": 32}, "action": {"text": "of", "start": 50, "end": 52, "i_start": 8, "i_end": 8}}], "id": 2920}, {"sent": "for example , while the results in are limited to tss and etss , in this work , we also cover letss , abss and elementary abss .", "tokens": ["for", "example", ",", "while", "the", "results", "in", "are", "limited", "to", "tss", "and", "etss", ",", "in", "this", "work", ",", "we", "also", "cover", "letss", ",", "abss", "and", "elementary", "abss", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 80, "end": 82, "i_start": 18, "i_end": 18}, "verb": {"text": "cover", "start": 88, "end": 93, "i_start": 20, "i_end": 20}}, {"character": {"text": "we", "start": 80, "end": 82, "i_start": 18, "i_end": 18}, "action": {"text": "cover", "start": 88, "end": 93, "i_start": 20, "i_end": 20}}], "id": 2921}, {"sent": "convolutional neural networks have achieved state-of-the-art accuracy in many supervised learning challenges .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "accuracy", "in", "many", "supervised", "learning", "challenges", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 2922}, {"sent": "energy that is not radiated away by the explosion itself travels outwards at a relativistic speed , causing a highly relativistic shock wave to propagates forward into space .", "tokens": ["energy", "that", "is", "not", "radiated", "away", "by", "the", "explosion", "itself", "travels", "outwards", "at", "a", "relativistic", "speed", ",", "causing", "a", "highly", "relativistic", "shock", "wave", "to", "propagates", "forward", "into", "space", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "energy that is not radiated away by the explosion itself", "start": 0, "end": 56, "i_start": 0, "i_end": 9}, "verb": {"text": "travels", "start": 57, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "energy", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "travels", "start": 57, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "explosion", "start": 40, "end": 49, "i_start": 8, "i_end": 8}, "action": {"text": "not radiated", "start": 15, "end": 27, "i_start": 3, "i_end": 4}}, {"character": {"text": "travels", "start": 57, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "causing", "start": 100, "end": 107, "i_start": 17, "i_end": 17}}], "id": 2923}, {"sent": "recently , the success of cnn-based methods in different computer vision tasks such as object recognition has inspired several face detection approaches .", "tokens": ["recently", ",", "the", "success", "of", "cnn", "-", "based", "methods", "in", "different", "computer", "vision", "tasks", "such", "as", "object", "recognition", "has", "inspired", "several", "face", "detection", "approaches", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the success of cnn-based methods in different computer vision tasks such as object recognition", "start": 11, "end": 105, "i_start": 2, "i_end": 17}, "verb": {"text": "has inspired", "start": 106, "end": 118, "i_start": 18, "i_end": 19}}, {"character": {"text": "success", "start": 15, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "inspired", "start": 110, "end": 118, "i_start": 19, "i_end": 19}}, {"character": {"text": "methods", "start": 36, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "success", "start": 15, "end": 22, "i_start": 3, "i_end": 3}}], "id": 2924}, {"sent": "rebuffi et al and propose a new parameterization of the standard residual network architecture that enables a high degree of parameter sharing between domains with a small increase in the model parameters .", "tokens": ["rebuffi", "et", "al", "and", "propose", "a", "new", "parameterization", "of", "the", "standard", "residual", "network", "architecture", "that", "enables", "a", "high", "degree", "of", "parameter", "sharing", "between", "domains", "with", "a", "small", "increase", "in", "the", "model", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "rebuffi et al and", "start": 0, "end": 17, "i_start": 0, "i_end": 3}, "verb": {"text": "propose", "start": 18, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "rebuffi", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 18, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "parameterization", "start": 32, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "enables", "start": 100, "end": 107, "i_start": 15, "i_end": 15}}, {"character": {"text": "domains", "start": 151, "end": 158, "i_start": 23, "i_end": 23}, "action": {"text": "sharing", "start": 135, "end": 142, "i_start": 21, "i_end": 21}}], "id": 2925}, {"sent": "the same behavior holds for the other data .", "tokens": ["the", "same", "behavior", "holds", "for", "the", "other", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the same behavior", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "holds", "start": 18, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "behavior", "start": 9, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "holds", "start": 18, "end": 23, "i_start": 3, "i_end": 3}}], "id": 2926}, {"sent": "a quantum circuit is a sequence of quantum gates ordered into layers .", "tokens": ["a", "quantum", "circuit", "is", "a", "sequence", "of", "quantum", "gates", "ordered", "into", "layers", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a quantum circuit", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}], "id": 2927}, {"sent": "recent developments showed that neural networks can be applied successfully in many technical applications like computer vision .", "tokens": ["recent", "developments", "showed", "that", "neural", "networks", "can", "be", "applied", "successfully", "in", "many", "technical", "applications", "like", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent developments", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "showed", "start": 20, "end": 26, "i_start": 2, "i_end": 2}}, {"subject": {"text": "neural networks", "start": 32, "end": 47, "i_start": 4, "i_end": 5}, "verb": {"text": "applied", "start": 55, "end": 62, "i_start": 8, "i_end": 8}}, {"character": {"text": "developments", "start": 7, "end": 19, "i_start": 1, "i_end": 1}, "action": {"text": "showed", "start": 20, "end": 26, "i_start": 2, "i_end": 2}}], "id": 2928}, {"sent": "in a proof of the fluctuation relation was given for anosov systems .", "tokens": ["in", "a", "proof", "of", "the", "fluctuation", "relation", "was", "given", "for", "anosov", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a proof of the fluctuation relation", "start": 3, "end": 38, "i_start": 1, "i_end": 6}, "verb": {"text": "was given", "start": 39, "end": 48, "i_start": 7, "i_end": 8}}], "id": 2929}, {"sent": "in particular , each finite-dimensional malcev algebra is a tangent algebra of a unique simply-connected global moufang loop .", "tokens": ["in", "particular", ",", "each", "finite", "-", "dimensional", "malcev", "algebra", "is", "a", "tangent", "algebra", "of", "a", "unique", "simply", "-", "connected", "global", "moufang", "loop", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each finite-dimensional malcev algebra", "start": 16, "end": 54, "i_start": 3, "i_end": 8}, "verb": {"text": "is", "start": 55, "end": 57, "i_start": 9, "i_end": 9}}], "id": 2930}, {"sent": "each gyroscope is a fused quartz sphere coated with superconducting niobium .", "tokens": ["each", "gyroscope", "is", "a", "fused", "quartz", "sphere", "coated", "with", "superconducting", "niobium", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each gyroscope", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 2931}, {"sent": "thus , the tachyon is the unique field of level 0 , the gauge field a\u00b5 is the unique field of level 1 , etc .", "tokens": ["thus", ",", "the", "tachyon", "is", "the", "unique", "field", "of", "level", "0", ",", "the", "gauge", "field", "a\u00b5", "is", "the", "unique", "field", "of", "level", "1", ",", "etc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the tachyon", "start": 7, "end": 18, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 4, "i_end": 4}}], "id": 2932}, {"sent": "in a mapping is proposed between ordinary and non-commutative gauge fields which do not preserve the gauge groups but preserve the gauge equivalent classes .", "tokens": ["in", "a", "mapping", "is", "proposed", "between", "ordinary", "and", "non", "-", "commutative", "gauge", "fields", "which", "do", "not", "preserve", "the", "gauge", "groups", "but", "preserve", "the", "gauge", "equivalent", "classes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "fields", "start": 68, "end": 74, "i_start": 12, "i_end": 12}, "action": {"text": "not preserve", "start": 84, "end": 96, "i_start": 15, "i_end": 16}}, {"character": {"text": "fields", "start": 68, "end": 74, "i_start": 12, "i_end": 12}, "action": {"text": "preserve", "start": 118, "end": 126, "i_start": 21, "i_end": 21}}], "id": 2933}, {"sent": "simulation results validate our analytical results on the policy design and demonstrate the performance gains enabled by the proposed policy .", "tokens": ["simulation", "results", "validate", "our", "analytical", "results", "on", "the", "policy", "design", "and", "demonstrate", "the", "performance", "gains", "enabled", "by", "the", "proposed", "policy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "simulation results", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "validate", "start": 19, "end": 27, "i_start": 2, "i_end": 2}}, {"subject": {"text": "simulation results", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "demonstrate", "start": 76, "end": 87, "i_start": 11, "i_end": 11}}, {"character": {"text": "results", "start": 11, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "validate", "start": 19, "end": 27, "i_start": 2, "i_end": 2}}], "id": 2934}, {"sent": "in the past several years , researchers have revealed that cnns can give the state-of-the-art performance in many computer vision tasks , especially for image classification and recognition tasks .", "tokens": ["in", "the", "past", "several", "years", ",", "researchers", "have", "revealed", "that", "cnns", "can", "give", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "many", "computer", "vision", "tasks", ",", "especially", "for", "image", "classification", "and", "recognition", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "researchers", "start": 28, "end": 39, "i_start": 6, "i_end": 6}, "verb": {"text": "have revealed", "start": 40, "end": 53, "i_start": 7, "i_end": 8}}, {"subject": {"text": "cnns", "start": 59, "end": 63, "i_start": 10, "i_end": 10}, "verb": {"text": "give", "start": 68, "end": 72, "i_start": 12, "i_end": 12}}], "id": 2935}, {"sent": "lowe proposed sift to extract distinctive invariant features present in images , which can be used for matching different object or scene views reliably .", "tokens": ["lowe", "proposed", "sift", "to", "extract", "distinctive", "invariant", "features", "present", "in", "images", ",", "which", "can", "be", "used", "for", "matching", "different", "object", "or", "scene", "views", "reliably", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "lowe proposed", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "sift", "start": 14, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "sift", "start": 14, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "extract", "start": 22, "end": 29, "i_start": 4, "i_end": 4}}], "id": 2936}, {"sent": "cluster algebras have been introduced in 2001 by fomin and zelevinski .", "tokens": ["cluster", "algebras", "have", "been", "introduced", "in", "2001", "by", "fomin", "and", "zelevinski", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "have been introduced", "start": 17, "end": 37, "i_start": 2, "i_end": 4}}, {"character": {"text": "fomin", "start": 49, "end": 54, "i_start": 8, "i_end": 8}, "action": {"text": "introduced", "start": 27, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "zelevinski", "start": 59, "end": 69, "i_start": 10, "i_end": 10}, "action": {"text": "introduced", "start": 27, "end": 37, "i_start": 4, "i_end": 4}}], "id": 2937}, {"sent": "each computer is a node and every connection between two computers is a link .", "tokens": ["each", "computer", "is", "a", "node", "and", "every", "connection", "between", "two", "computers", "is", "a", "link", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each computer", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 2938}, {"sent": "we employ the akaike information criterion and the bayesian information criterion to do the analysis .", "tokens": ["we", "employ", "the", "akaike", "information", "criterion", "and", "the", "bayesian", "information", "criterion", "to", "do", "the", "analysis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 2939}, {"sent": "on the other hand , it turns out that the simplicial volume of q-rank 1 locally symmetric spaces covered by a product of r-rank 1 symmetric spaces is positive for amenable boundary group cases .", "tokens": ["on", "the", "other", "hand", ",", "it", "turns", "out", "that", "the", "simplicial", "volume", "of", "q", "-", "rank", "1", "locally", "symmetric", "spaces", "covered", "by", "a", "product", "of", "r", "-", "rank", "1", "symmetric", "spaces", "is", "positive", "for", "amenable", "boundary", "group", "cases", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 20, "end": 22, "i_start": 5, "i_end": 5}, "verb": {"text": "turns out", "start": 23, "end": 32, "i_start": 6, "i_end": 7}}, {"subject": {"text": "it", "start": 20, "end": 22, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 147, "end": 149, "i_start": 31, "i_end": 31}}, {"character": {"text": "product", "start": 110, "end": 117, "i_start": 23, "i_end": 23}, "action": {"text": "covered", "start": 97, "end": 104, "i_start": 20, "i_end": 20}}], "id": 2940}, {"sent": "this model , and its reduction to account for multiple viruses and virus strains in one population , is presented by levy et al .", "tokens": ["this", "model", ",", "and", "its", "reduction", "to", "account", "for", "multiple", "viruses", "and", "virus", "strains", "in", "one", "population", ",", "is", "presented", "by", "levy", "et", "al", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "this model", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is presented", "start": 101, "end": 113, "i_start": 18, "i_end": 19}}, {"character": {"text": "levy", "start": 117, "end": 121, "i_start": 21, "i_end": 21}, "action": {"text": "presented", "start": 104, "end": 113, "i_start": 19, "i_end": 19}}, {"character": {"text": "model", "start": 5, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "account", "start": 34, "end": 41, "i_start": 7, "i_end": 7}}], "id": 2941}, {"sent": "the eastin-knill theorem establishes that no stabilizer code can simultaneously implement a universal set of encoded gates transversally .", "tokens": ["the", "eastin", "-", "knill", "theorem", "establishes", "that", "no", "stabilizer", "code", "can", "simultaneously", "implement", "a", "universal", "set", "of", "encoded", "gates", "transversally", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the eastin-knill theorem", "start": 0, "end": 24, "i_start": 0, "i_end": 4}, "verb": {"text": "establishes", "start": 25, "end": 36, "i_start": 5, "i_end": 5}}, {"subject": {"text": "no stabilizer code", "start": 42, "end": 60, "i_start": 7, "i_end": 9}, "verb": {"text": "implement", "start": 80, "end": 89, "i_start": 12, "i_end": 12}}, {"character": {"text": "theorem", "start": 17, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "establishes", "start": 25, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "code", "start": 56, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "implement", "start": 80, "end": 89, "i_start": 12, "i_end": 12}}, {"character": {"text": "code", "start": 56, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "stabilizer", "start": 45, "end": 55, "i_start": 8, "i_end": 8}}], "id": 2942}, {"sent": "we initialize our network by vgg on the last convolutional feature map of the pre-trained vgg network .", "tokens": ["we", "initialize", "our", "network", "by", "vgg", "on", "the", "last", "convolutional", "feature", "map", "of", "the", "pre", "-", "trained", "vgg", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "initialize", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "initialize", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}], "id": 2943}, {"sent": "the subject of complex networks has been widely explored in the past few years in part due to its broad range of applications to social , biological and communication systems .", "tokens": ["the", "subject", "of", "complex", "networks", "has", "been", "widely", "explored", "in", "the", "past", "few", "years", "in", "part", "due", "to", "its", "broad", "range", "of", "applications", "to", "social", ",", "biological", "and", "communication", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the subject of complex networks", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "explored", "start": 48, "end": 56, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the subject of complex networks", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "has been", "start": 32, "end": 40, "i_start": 5, "i_end": 6}}], "id": 2944}, {"sent": "in particular cases we provide explicit formulae for the minimizer .", "tokens": ["in", "particular", "cases", "we", "provide", "explicit", "formulae", "for", "the", "minimizer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "verb": {"text": "provide", "start": 23, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "provide", "start": 23, "end": 30, "i_start": 4, "i_end": 4}}], "id": 2945}, {"sent": "to circumvent this problem , algorithms that work directly on the compressed representation without explicit decompression have gained attention , especially for the string pattern matching problem .", "tokens": ["to", "circumvent", "this", "problem", ",", "algorithms", "that", "work", "directly", "on", "the", "compressed", "representation", "without", "explicit", "decompression", "have", "gained", "attention", ",", "especially", "for", "the", "string", "pattern", "matching", "problem", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "algorithms that work directly on the compressed representation without explicit decompression", "start": 29, "end": 122, "i_start": 5, "i_end": 15}, "verb": {"text": "have gained", "start": 123, "end": 134, "i_start": 16, "i_end": 17}}, {"character": {"text": "algorithms", "start": 29, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "gained", "start": 128, "end": 134, "i_start": 17, "i_end": 17}}, {"character": {"text": "algorithms", "start": 29, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "work", "start": 45, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "algorithms", "start": 29, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "circumvent", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}], "id": 2946}, {"sent": "ngiam et al present a stacked multimodal autoencoder to learn joint audio and video representations .", "tokens": ["ngiam", "et", "al", "present", "a", "stacked", "multimodal", "autoencoder", "to", "learn", "joint", "audio", "and", "video", "representations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "ngiam et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "present", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "ngiam", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "present", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "ngiam", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "learn", "start": 56, "end": 61, "i_start": 9, "i_end": 9}}], "id": 2947}, {"sent": "for an introduction to the notion of finite type invariants of knots and 3-manifolds , see .", "tokens": ["for", "an", "introduction", "to", "the", "notion", "of", "finite", "type", "invariants", "of", "knots", "and", "3", "-", "manifolds", ",", "see", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2948}, {"sent": "here we propose an experiment which can realise the hom effect with matter waves using a collision of two atomic bose-einstein condensates and a pair of laser-induced bragg pulses .", "tokens": ["here", "we", "propose", "an", "experiment", "which", "can", "realise", "the", "hom", "effect", "with", "matter", "waves", "using", "a", "collision", "of", "two", "atomic", "bose", "-", "einstein", "condensates", "and", "a", "pair", "of", "laser", "-", "induced", "bragg", "pulses", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "propose", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "propose", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "experiment", "start": 19, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "realise", "start": 40, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "two atomic bose-einstein condensates", "start": 102, "end": 138, "i_start": 18, "i_end": 23}, "action": {"text": "collision", "start": 89, "end": 98, "i_start": 16, "i_end": 16}}, {"character": {"text": "laser", "start": 153, "end": 158, "i_start": 28, "i_end": 28}, "action": {"text": "induced", "start": 159, "end": 166, "i_start": 30, "i_end": 30}}], "id": 2949}, {"sent": "the global structure of the turing degrees .", "tokens": ["the", "global", "structure", "of", "the", "turing", "degrees", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2950}, {"sent": "we use the gradient boosting classifier implemented in the scikit-learn toolkit .", "tokens": ["we", "use", "the", "gradient", "boosting", "classifier", "implemented", "in", "the", "scikit", "-", "learn", "toolkit", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "classifier", "start": 29, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "boosting", "start": 20, "end": 28, "i_start": 4, "i_end": 4}}], "id": 2951}, {"sent": "for many prior adversarial adaptation methods , all layers are constrained , thus enforcing exact source and target mapping consistency .", "tokens": ["for", "many", "prior", "adversarial", "adaptation", "methods", ",", "all", "layers", "are", "constrained", ",", "thus", "enforcing", "exact", "source", "and", "target", "mapping", "consistency", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all layers", "start": 48, "end": 58, "i_start": 7, "i_end": 8}, "verb": {"text": "are constrained", "start": 59, "end": 74, "i_start": 9, "i_end": 10}}], "id": 2952}, {"sent": "cluster algebras were introduced and studied by fomin-zelevinsky and berenstein-fomin-zelevinsky in a series of articles .", "tokens": ["cluster", "algebras", "were", "introduced", "and", "studied", "by", "fomin", "-", "zelevinsky", "and", "berenstein", "-", "fomin", "-", "zelevinsky", "in", "a", "series", "of", "articles", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were introduced", "start": 17, "end": 32, "i_start": 2, "i_end": 3}}, {"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "studied", "start": 37, "end": 44, "i_start": 5, "i_end": 5}}, {"character": {"text": "fomin", "start": 48, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "berenstein", "start": 69, "end": 79, "i_start": 11, "i_end": 11}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "fomin", "start": 48, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "studied", "start": 37, "end": 44, "i_start": 5, "i_end": 5}}, {"character": {"text": "berenstein", "start": 69, "end": 79, "i_start": 11, "i_end": 11}, "action": {"text": "studied", "start": 37, "end": 44, "i_start": 5, "i_end": 5}}], "id": 2953}, {"sent": "this so-called gabriel-roiter measure on module categories was further studied by ringel in in the representation-infinite case .", "tokens": ["this", "so", "-", "called", "gabriel", "-", "roiter", "measure", "on", "module", "categories", "was", "further", "studied", "by", "ringel", "in", "in", "the", "representation", "-", "infinite", "case", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "this so-called gabriel-roiter measure on module categories", "start": 0, "end": 58, "i_start": 0, "i_end": 10}, "verb": {"text": "studied", "start": 71, "end": 78, "i_start": 13, "i_end": 13}}, {"subject": {"text": "this so-called gabriel-roiter measure on module categories", "start": 0, "end": 58, "i_start": 0, "i_end": 10}, "verb": {"text": "was", "start": 59, "end": 62, "i_start": 11, "i_end": 11}}, {"character": {"text": "ringel", "start": 82, "end": 88, "i_start": 15, "i_end": 15}, "action": {"text": "studied", "start": 71, "end": 78, "i_start": 13, "i_end": 13}}], "id": 2954}, {"sent": "one of the most attractive frameworks to explain the matter-antimatter asymmetry of the universe is the so-called leptogenesis mechanism .", "tokens": ["one", "of", "the", "most", "attractive", "frameworks", "to", "explain", "the", "matter", "-", "antimatter", "asymmetry", "of", "the", "universe", "is", "the", "so", "-", "called", "leptogenesis", "mechanism", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "one of the most attractive frameworks to explain the matter-antimatter asymmetry of the universe", "start": 0, "end": 96, "i_start": 0, "i_end": 15}, "verb": {"text": "is", "start": 97, "end": 99, "i_start": 16, "i_end": 16}}, {"character": {"text": "frameworks", "start": 27, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "attractive", "start": 16, "end": 26, "i_start": 4, "i_end": 4}}], "id": 2955}, {"sent": "for further robustness , we use batch normalization throughout our network before activation layers during training .", "tokens": ["for", "further", "robustness", ",", "we", "use", "batch", "normalization", "throughout", "our", "network", "before", "activation", "layers", "during", "training", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 25, "end": 27, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 28, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 28, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "layers", "start": 93, "end": 99, "i_start": 13, "i_end": 13}, "action": {"text": "activation", "start": 82, "end": 92, "i_start": 12, "i_end": 12}}], "id": 2956}, {"sent": "the lac operon in escherichia coli has been studied extensively and is one of the earliest gene systems found to undergo both positive and negative control .", "tokens": ["the", "lac", "operon", "in", "escherichia", "coli", "has", "been", "studied", "extensively", "and", "is", "one", "of", "the", "earliest", "gene", "systems", "found", "to", "undergo", "both", "positive", "and", "negative", "control", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lac operon in escherichia coli", "start": 0, "end": 34, "i_start": 0, "i_end": 5}, "verb": {"text": "has been studied", "start": 35, "end": 51, "i_start": 6, "i_end": 8}}], "id": 2957}, {"sent": "classical unsupervised learning methods based on hand-crafted features offer poor re-id performance when compared to the supervised learning based re-id models .", "tokens": ["classical", "unsupervised", "learning", "methods", "based", "on", "hand", "-", "crafted", "features", "offer", "poor", "re", "-", "id", "performance", "when", "compared", "to", "the", "supervised", "learning", "based", "re", "-", "id", "models", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "classical unsupervised learning methods based on hand-crafted features", "start": 0, "end": 70, "i_start": 0, "i_end": 9}, "verb": {"text": "offer", "start": 71, "end": 76, "i_start": 10, "i_end": 10}}, {"subject": {"text": "classical unsupervised learning methods based on hand-crafted features", "start": 0, "end": 70, "i_start": 0, "i_end": 9}, "verb": {"text": "based", "start": 141, "end": 146, "i_start": 22, "i_end": 22}}, {"character": {"text": "methods", "start": 32, "end": 39, "i_start": 3, "i_end": 3}, "action": {"text": "offer", "start": 71, "end": 76, "i_start": 10, "i_end": 10}}, {"character": {"text": "hand", "start": 49, "end": 53, "i_start": 6, "i_end": 6}, "action": {"text": "crafted", "start": 54, "end": 61, "i_start": 8, "i_end": 8}}], "id": 2958}, {"sent": "we use batch normalization , relu activation and max pooling in between convolutional layers , and use same padding in the model .", "tokens": ["we", "use", "batch", "normalization", ",", "relu", "activation", "and", "max", "pooling", "in", "between", "convolutional", "layers", ",", "and", "use", "same", "padding", "in", "the", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "in", "start": 61, "end": 63, "i_start": 10, "i_end": 10}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 99, "end": 102, "i_start": 16, "i_end": 16}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 2959}, {"sent": "one example is the random halves model proposed in , in which the number of clock varies randomly with time instead of being a constant .", "tokens": ["one", "example", "is", "the", "random", "halves", "model", "proposed", "in", ",", "in", "which", "the", "number", "of", "clock", "varies", "randomly", "with", "time", "instead", "of", "being", "a", "constant", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one example", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 2960}, {"sent": "state of the art methods for face recognition use face embeddings generated by a deep convolutional neural network .", "tokens": ["state", "of", "the", "art", "methods", "for", "face", "recognition", "use", "face", "embeddings", "generated", "by", "a", "deep", "convolutional", "neural", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "methods", "start": 17, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 46, "end": 49, "i_start": 8, "i_end": 8}}, {"character": {"text": "network", "start": 107, "end": 114, "i_start": 17, "i_end": 17}, "action": {"text": "generated", "start": 66, "end": 75, "i_start": 11, "i_end": 11}}], "id": 2961}, {"sent": "advances in both image-based learning and language-based learning using deep neural networks have made huge strides in difficult tasks such as object recognition .", "tokens": ["advances", "in", "both", "image", "-", "based", "learning", "and", "language", "-", "based", "learning", "using", "deep", "neural", "networks", "have", "made", "huge", "strides", "in", "difficult", "tasks", "such", "as", "object", "recognition", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "advances in both image-based learning and language-based learning using deep neural networks", "start": 0, "end": 92, "i_start": 0, "i_end": 15}, "verb": {"text": "have made", "start": 93, "end": 102, "i_start": 16, "i_end": 17}}, {"character": {"text": "advances", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "strides", "start": 108, "end": 115, "i_start": 19, "i_end": 19}}], "id": 2962}, {"sent": "for all the experiments , we use resnet50 as the encoder , which is pre-trained on imagenet .", "tokens": ["for", "all", "the", "experiments", ",", "we", "use", "resnet50", "as", "the", "encoder", ",", "which", "is", "pre", "-", "trained", "on", "imagenet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 29, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 29, "end": 32, "i_start": 6, "i_end": 6}}], "id": 2963}, {"sent": "moreover , we calculate anomalous dimensions of all fields and rg functions of gauge parameters appearing in our action to one-loop order of perturbation theory in the scheme of the dimensional regularization .", "tokens": ["moreover", ",", "we", "calculate", "anomalous", "dimensions", "of", "all", "fields", "and", "rg", "functions", "of", "gauge", "parameters", "appearing", "in", "our", "action", "to", "one", "-", "loop", "order", "of", "perturbation", "theory", "in", "the", "scheme", "of", "the", "dimensional", "regularization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "verb": {"text": "calculate", "start": 14, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "calculate", "start": 14, "end": 23, "i_start": 3, "i_end": 3}}], "id": 2964}, {"sent": "note that there is no need to consider odd dimensional even characteristic orthogonal groups , as these are isomorphic to symplectic groups .", "tokens": ["note", "that", "there", "is", "no", "need", "to", "consider", "odd", "dimensional", "even", "characteristic", "orthogonal", "groups", ",", "as", "these", "are", "isomorphic", "to", "symplectic", "groups", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "there", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 2965}, {"sent": "crown structures for vertex cover kernelization .", "tokens": ["crown", "structures", "for", "vertex", "cover", "kernelization", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2966}, {"sent": "palles , jj neumeier , and dh goodwin , phys .", "tokens": ["palles", ",", "jj", "neumeier", ",", "and", "dh", "goodwin", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2967}, {"sent": "the contribution to the power spectrum of cosmological perturbations is scale-invariant .", "tokens": ["the", "contribution", "to", "the", "power", "spectrum", "of", "cosmological", "perturbations", "is", "scale", "-", "invariant", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the contribution to the power spectrum of cosmological perturbations", "start": 0, "end": 68, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 69, "end": 71, "i_start": 9, "i_end": 9}}], "id": 2968}, {"sent": "finally , in , edge swapping was proposed as a technique to increase the stopping distance of an ldpc code , and thus to improve its error floor performance over the binary erasure channel .", "tokens": ["finally", ",", "in", ",", "edge", "swapping", "was", "proposed", "as", "a", "technique", "to", "increase", "the", "stopping", "distance", "of", "an", "ldpc", "code", ",", "and", "thus", "to", "improve", "its", "error", "floor", "performance", "over", "the", "binary", "erasure", "channel", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "edge swapping", "start": 15, "end": 28, "i_start": 4, "i_end": 5}, "verb": {"text": "was proposed", "start": 29, "end": 41, "i_start": 6, "i_end": 7}}, {"subject": {"text": "edge swapping", "start": 15, "end": 28, "i_start": 4, "i_end": 5}, "verb": {"text": "improve", "start": 121, "end": 128, "i_start": 24, "i_end": 24}}], "id": 2969}, {"sent": "the kernel of a p-semi-linear map is a subspace so that if two p-operators that make g a restricted lie algebra agree on a basis , they are identical .", "tokens": ["the", "kernel", "of", "a", "p", "-", "semi", "-", "linear", "map", "is", "a", "subspace", "so", "that", "if", "two", "p", "-", "operators", "that", "make", "g", "a", "restricted", "lie", "algebra", "agree", "on", "a", "basis", ",", "they", "are", "identical", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the kernel of a p-semi-linear map", "start": 0, "end": 33, "i_start": 0, "i_end": 9}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 10, "i_end": 10}}, {"character": {"text": "subspace", "start": 39, "end": 47, "i_start": 12, "i_end": 12}, "action": {"text": "if", "start": 56, "end": 58, "i_start": 15, "i_end": 15}}, {"character": {"text": "two", "start": 59, "end": 62, "i_start": 16, "i_end": 16}, "action": {"text": "operators", "start": 65, "end": 74, "i_start": 19, "i_end": 19}}, {"character": {"text": "make", "start": 80, "end": 84, "i_start": 21, "i_end": 21}, "action": {"text": "agree", "start": 112, "end": 117, "i_start": 27, "i_end": 27}}, {"character": {"text": "lie algebra", "start": 100, "end": 111, "i_start": 25, "i_end": 26}, "action": {"text": "agree", "start": 112, "end": 117, "i_start": 27, "i_end": 27}}], "id": 2970}, {"sent": "the millimeter wave bands -roughly corresponding to frequencies above 10 ghz -have attracted considerable attention for next-generation cellular wireless systems .", "tokens": ["the", "millimeter", "wave", "bands", "-roughly", "corresponding", "to", "frequencies", "above", "10", "ghz", "-have", "attracted", "considerable", "attention", "for", "next", "-", "generation", "cellular", "wireless", "systems", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the millimeter wave bands -roughly corresponding to frequencies above 10 ghz", "start": 0, "end": 76, "i_start": 0, "i_end": 10}, "verb": {"text": "-have attracted", "start": 77, "end": 92, "i_start": 11, "i_end": 12}}, {"character": {"text": "bands", "start": 20, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "attracted", "start": 83, "end": 92, "i_start": 12, "i_end": 12}}], "id": 2971}, {"sent": "the data was reduced using the miriad package .", "tokens": ["the", "data", "was", "reduced", "using", "the", "miriad", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "was reduced", "start": 9, "end": 20, "i_start": 2, "i_end": 3}}], "id": 2972}, {"sent": "deep neural networks have shown tremendous success in several computer vision tasks in recent years .", "tokens": ["deep", "neural", "networks", "have", "shown", "tremendous", "success", "in", "several", "computer", "vision", "tasks", "in", "recent", "years", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}], "id": 2973}, {"sent": "like residual networks , the architecture also has many one-step skip connections .", "tokens": ["like", "residual", "networks", ",", "the", "architecture", "also", "has", "many", "one", "-", "step", "skip", "connections", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the architecture", "start": 25, "end": 41, "i_start": 4, "i_end": 5}, "verb": {"text": "has", "start": 47, "end": 50, "i_start": 7, "i_end": 7}}], "id": 2974}, {"sent": "as our baseline we use a deep convolutional neural network which is based on the inception architecture .", "tokens": ["as", "our", "baseline", "we", "use", "a", "deep", "convolutional", "neural", "network", "which", "is", "based", "on", "the", "inception", "architecture", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "use", "start": 19, "end": 22, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 19, "end": 22, "i_start": 4, "i_end": 4}}], "id": 2975}, {"sent": "ryu and takayanagi have provided a proposal to compute the entanglement entropy of cfts from the minimal area surface in gravity side .", "tokens": ["ryu", "and", "takayanagi", "have", "provided", "a", "proposal", "to", "compute", "the", "entanglement", "entropy", "of", "cfts", "from", "the", "minimal", "area", "surface", "in", "gravity", "side", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "ryu and takayanagi", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "have provided", "start": 19, "end": 32, "i_start": 3, "i_end": 4}}, {"character": {"text": "ryu", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "proposal", "start": 35, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "takayanagi", "start": 8, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "proposal", "start": 35, "end": 43, "i_start": 6, "i_end": 6}}], "id": 2976}, {"sent": "deep learning or deep neural networks have achieved extraordinary performance in many application domains such as image classification .", "tokens": ["deep", "learning", "or", "deep", "neural", "networks", "have", "achieved", "extraordinary", "performance", "in", "many", "application", "domains", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning or deep neural networks", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "have achieved", "start": 38, "end": 51, "i_start": 6, "i_end": 7}}, {"character": {"text": "or", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}], "id": 2977}, {"sent": "deep neural networks are powerful models that achieve state-of-the-art performance across several domains , such as bioinformatics .", "tokens": ["deep", "neural", "networks", "are", "powerful", "models", "that", "achieve", "state", "-", "of", "-", "the", "-", "art", "performance", "across", "several", "domains", ",", "such", "as", "bioinformatics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 34, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "achieve", "start": 46, "end": 53, "i_start": 7, "i_end": 7}}], "id": 2978}, {"sent": "to train the dnn model , we choose the adam optimizer , which is the most widely used variant of traditional gradient descent algorithms in deep learning .", "tokens": ["to", "train", "the", "dnn", "model", ",", "we", "choose", "the", "adam", "optimizer", ",", "which", "is", "the", "most", "widely", "used", "variant", "of", "traditional", "gradient", "descent", "algorithms", "in", "deep", "learning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 25, "end": 27, "i_start": 6, "i_end": 6}, "verb": {"text": "choose", "start": 28, "end": 34, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 6, "i_end": 6}, "action": {"text": "choose", "start": 28, "end": 34, "i_start": 7, "i_end": 7}}], "id": 2979}, {"sent": "calculations were carried out employing spin-polarized hse06 and pbe-gga based dft methods using the projector augmented wave method 27 , as implemented in the vienna ab initio simulation package .", "tokens": ["calculations", "were", "carried", "out", "employing", "spin", "-", "polarized", "hse06", "and", "pbe", "-", "gga", "based", "dft", "methods", "using", "the", "projector", "augmented", "wave", "method", "27", ",", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "calculations", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "were carried out", "start": 13, "end": 29, "i_start": 1, "i_end": 3}}, {"character": {"text": "calculations", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 91, "end": 96, "i_start": 16, "i_end": 16}}], "id": 2980}, {"sent": "the space h is a direct sum of all hn and a one-dimensional space h0 which corresponds to the absence of particles .", "tokens": ["the", "space", "h", "is", "a", "direct", "sum", "of", "all", "hn", "and", "a", "one", "-", "dimensional", "space", "h0", "which", "corresponds", "to", "the", "absence", "of", "particles", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the space h", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 3, "i_end": 3}}], "id": 2981}, {"sent": "obviously , every pseudorandom generator is a weakly pseudorandom every p-dense language over \u03c3 in generator .", "tokens": ["obviously", ",", "every", "pseudorandom", "generator", "is", "a", "weakly", "pseudorandom", "every", "p", "-", "dense", "language", "over", "\u03c3", "in", "generator", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "every pseudorandom generator", "start": 12, "end": 40, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 41, "end": 43, "i_start": 5, "i_end": 5}}], "id": 2982}, {"sent": "the whole system still consists of four plastic scintillator planes ( two above pp .", "tokens": ["the", "whole", "system", "still", "consists", "of", "four", "plastic", "scintillator", "planes", "(", "two", "above", "pp", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the whole system", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}], "id": 2983}, {"sent": "for the imaging program , we used twilight sky flats to correct for pixel-topixel sensitivity variation .", "tokens": ["for", "the", "imaging", "program", ",", "we", "used", "twilight", "sky", "flats", "to", "correct", "for", "pixel", "-", "topixel", "sensitivity", "variation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "verb": {"text": "used", "start": 29, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "used", "start": 29, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "correct", "start": 56, "end": 63, "i_start": 11, "i_end": 11}}, {"character": {"text": "pixel", "start": 68, "end": 73, "i_start": 13, "i_end": 13}, "action": {"text": "sensitivity", "start": 82, "end": 93, "i_start": 16, "i_end": 16}}], "id": 2984}, {"sent": "the issue is that a large reduction in precision , leads to large information loss which incurs significant accuracy degradation , especially for complex datasets such as imagenet .", "tokens": ["the", "issue", "is", "that", "a", "large", "reduction", "in", "precision", ",", "leads", "to", "large", "information", "loss", "which", "incurs", "significant", "accuracy", "degradation", ",", "especially", "for", "complex", "datasets", "such", "as", "imagenet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the issue", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}, {"subject": {"text": "a large reduction in precision", "start": 18, "end": 48, "i_start": 4, "i_end": 8}, "verb": {"text": "leads", "start": 51, "end": 56, "i_start": 10, "i_end": 10}}, {"character": {"text": "leads", "start": 51, "end": 56, "i_start": 10, "i_end": 10}, "action": {"text": "issue", "start": 4, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "reduction", "start": 26, "end": 35, "i_start": 6, "i_end": 6}, "action": {"text": "leads", "start": 51, "end": 56, "i_start": 10, "i_end": 10}}], "id": 2985}, {"sent": "neural network models are vulnerable to adversarial variants .", "tokens": ["neural", "network", "models", "are", "vulnerable", "to", "adversarial", "variants", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural network models", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 22, "end": 25, "i_start": 3, "i_end": 3}}], "id": 2986}, {"sent": "we then analyze some phenomenological implications of the gravity-matter interactions in this particular model .", "tokens": ["we", "then", "analyze", "some", "phenomenological", "implications", "of", "the", "gravity", "-", "matter", "interactions", "in", "this", "particular", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "analyze", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "analyze", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "interactions", "start": 73, "end": 85, "i_start": 11, "i_end": 11}, "action": {"text": "implications", "start": 38, "end": 50, "i_start": 5, "i_end": 5}}, {"character": {"text": "gravity", "start": 58, "end": 65, "i_start": 8, "i_end": 8}, "action": {"text": "interactions", "start": 73, "end": 85, "i_start": 11, "i_end": 11}}], "id": 2987}, {"sent": "local f-theory model buildings have been emphasized in recent studies .", "tokens": ["local", "f", "-", "theory", "model", "buildings", "have", "been", "emphasized", "in", "recent", "studies", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "local f-theory model buildings", "start": 0, "end": 30, "i_start": 0, "i_end": 5}, "verb": {"text": "have been emphasized", "start": 31, "end": 51, "i_start": 6, "i_end": 8}}, {"character": {"text": "studies", "start": 62, "end": 69, "i_start": 11, "i_end": 11}, "action": {"text": "emphasized", "start": 41, "end": 51, "i_start": 8, "i_end": 8}}], "id": 2988}, {"sent": "this is a key element for transporting trapped-ion qubits in a scalable quantum-computing architecture .", "tokens": ["this", "is", "a", "key", "element", "for", "transporting", "trapped", "-", "ion", "qubits", "in", "a", "scalable", "quantum", "-", "computing", "architecture", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 2989}, {"sent": "consequently the orbit is a conic section .", "tokens": ["consequently", "the", "orbit", "is", "a", "conic", "section", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the orbit", "start": 13, "end": 22, "i_start": 1, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}], "id": 2990}, {"sent": "obviously gx , m is an algebraic subgroup of gl is an algebraic representation .", "tokens": ["obviously", "gx", ",", "m", "is", "an", "algebraic", "subgroup", "of", "gl", "is", "an", "algebraic", "representation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "m", "start": 15, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 4, "i_end": 4}}], "id": 2991}, {"sent": "we use an expectationmaximization algorithm to fit the model .", "tokens": ["we", "use", "an", "expectationmaximization", "algorithm", "to", "fit", "the", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 2992}, {"sent": "experimentally , it has been consistently observed that the mrna decays substantially faster than its protein counterpart .", "tokens": ["experimentally", ",", "it", "has", "been", "consistently", "observed", "that", "the", "mrna", "decays", "substantially", "faster", "than", "its", "protein", "counterpart", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the mrna", "start": 56, "end": 64, "i_start": 8, "i_end": 9}, "verb": {"text": "observed", "start": 42, "end": 50, "i_start": 6, "i_end": 6}}, {"subject": {"text": "it", "start": 17, "end": 19, "i_start": 2, "i_end": 2}, "verb": {"text": "has been", "start": 20, "end": 28, "i_start": 3, "i_end": 4}}, {"subject": {"text": "it", "start": 17, "end": 19, "i_start": 2, "i_end": 2}, "verb": {"text": "decays", "start": 65, "end": 71, "i_start": 10, "i_end": 10}}], "id": 2993}, {"sent": "a similar analysis was performed in to place the constraints on lrf mediated by vector and non-vector neutral bosons where the authors assumed one mass scale dominance .", "tokens": ["a", "similar", "analysis", "was", "performed", "in", "to", "place", "the", "constraints", "on", "lrf", "mediated", "by", "vector", "and", "non", "-", "vector", "neutral", "bosons", "where", "the", "authors", "assumed", "one", "mass", "scale", "dominance", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a similar analysis", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "was performed", "start": 19, "end": 32, "i_start": 3, "i_end": 4}}, {"character": {"text": "vector and non-", "start": 80, "end": 95, "i_start": 14, "i_end": 17}, "action": {"text": "mediated", "start": 68, "end": 76, "i_start": 12, "i_end": 12}}, {"character": {"text": "bosons", "start": 110, "end": 116, "i_start": 20, "i_end": 20}, "action": {"text": "mediated", "start": 68, "end": 76, "i_start": 12, "i_end": 12}}, {"character": {"text": "vector and non-", "start": 80, "end": 95, "i_start": 14, "i_end": 17}, "action": {"text": "mediated", "start": 68, "end": 76, "i_start": 12, "i_end": 12}}], "id": 2994}, {"sent": "deep neural networks have garnered interest from many researchers after being successfully applied in image classification .", "tokens": ["deep", "neural", "networks", "have", "garnered", "interest", "from", "many", "researchers", "after", "being", "successfully", "applied", "in", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have garnered", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "garnered", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successfully", "start": 78, "end": 90, "i_start": 11, "i_end": 11}}], "id": 2995}, {"sent": "in recent years , deep convolutional neural networks have been shown to be exceptionally effective for image classification .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "been", "shown", "to", "be", "exceptionally", "effective", "for", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have been shown", "start": 53, "end": 68, "i_start": 8, "i_end": 10}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "effective", "start": 89, "end": 98, "i_start": 14, "i_end": 14}}], "id": 2996}, {"sent": "generative adversarial networks are an effective approach for training generative models .", "tokens": ["generative", "adversarial", "networks", "are", "an", "effective", "approach", "for", "training", "generative", "models", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "approach", "start": 49, "end": 57, "i_start": 6, "i_end": 6}}, {"character": {"text": "approach", "start": 49, "end": 57, "i_start": 6, "i_end": 6}, "action": {"text": "effective", "start": 39, "end": 48, "i_start": 5, "i_end": 5}}], "id": 2997}, {"sent": "furthermore , direct numerical simulation could be employed to verify studies on the critical wave number at fixed capillary number , such as the prior work of miranda and widom .", "tokens": ["furthermore", ",", "direct", "numerical", "simulation", "could", "be", "employed", "to", "verify", "studies", "on", "the", "critical", "wave", "number", "at", "fixed", "capillary", "number", ",", "such", "as", "the", "prior", "work", "of", "miranda", "and", "widom", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "direct numerical simulation", "start": 14, "end": 41, "i_start": 2, "i_end": 4}, "verb": {"text": "could be employed", "start": 42, "end": 59, "i_start": 5, "i_end": 7}}, {"character": {"text": "simulation", "start": 31, "end": 41, "i_start": 4, "i_end": 4}, "action": {"text": "verify", "start": 63, "end": 69, "i_start": 9, "i_end": 9}}, {"character": {"text": "miranda", "start": 160, "end": 167, "i_start": 27, "i_end": 27}, "action": {"text": "work", "start": 152, "end": 156, "i_start": 25, "i_end": 25}}, {"character": {"text": "widom", "start": 172, "end": 177, "i_start": 29, "i_end": 29}, "action": {"text": "work", "start": 152, "end": 156, "i_start": 25, "i_end": 25}}], "id": 2998}, {"sent": "we also have the closed symmetric monoidal category gs of orthogonal g-spectra .", "tokens": ["we", "also", "have", "the", "closed", "symmetric", "monoidal", "category", "gs", "of", "orthogonal", "g", "-", "spectra", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "have", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}], "id": 2999}, {"sent": "we prove the equality of the two formulas by showing that the contribution of every column is the same .", "tokens": ["we", "prove", "the", "equality", "of", "the", "two", "formulas", "by", "showing", "that", "the", "contribution", "of", "every", "column", "is", "the", "same", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "prove", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "prove", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "showing", "start": 45, "end": 52, "i_start": 9, "i_end": 9}}, {"character": {"text": "column", "start": 84, "end": 90, "i_start": 15, "i_end": 15}, "action": {"text": "contribution", "start": 62, "end": 74, "i_start": 12, "i_end": 12}}], "id": 3000}, {"sent": "a new algorithm for nding trees with many leaves .", "tokens": ["a", "new", "algorithm", "for", "nding", "trees", "with", "many", "leaves", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3001}, {"sent": "for example , poisoning attacks systematically introduce adversarial data during the training phase with the aim of causing the misclassification of data during the test phase .", "tokens": ["for", "example", ",", "poisoning", "attacks", "systematically", "introduce", "adversarial", "data", "during", "the", "training", "phase", "with", "the", "aim", "of", "causing", "the", "misclassification", "of", "data", "during", "the", "test", "phase", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "poisoning attacks", "start": 14, "end": 31, "i_start": 3, "i_end": 4}, "verb": {"text": "introduce", "start": 47, "end": 56, "i_start": 6, "i_end": 6}}, {"character": {"text": "attacks", "start": 24, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "introduce", "start": 47, "end": 56, "i_start": 6, "i_end": 6}}, {"character": {"text": "attacks", "start": 24, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "causing", "start": 116, "end": 123, "i_start": 17, "i_end": 17}}], "id": 3002}, {"sent": "in particular , for this purpose the multicarrier cvqkd modulation has been recently proposed through the multicarrier transmission scheme of amqd .", "tokens": ["in", "particular", ",", "for", "this", "purpose", "the", "multicarrier", "cvqkd", "modulation", "has", "been", "recently", "proposed", "through", "the", "multicarrier", "transmission", "scheme", "of", "amqd", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the multicarrier cvqkd modulation", "start": 33, "end": 66, "i_start": 6, "i_end": 9}, "verb": {"text": "proposed", "start": 85, "end": 93, "i_start": 13, "i_end": 13}}, {"subject": {"text": "the multicarrier cvqkd modulation", "start": 33, "end": 66, "i_start": 6, "i_end": 9}, "verb": {"text": "has been", "start": 67, "end": 75, "i_start": 10, "i_end": 11}}], "id": 3003}, {"sent": "exchange and correlation effects were treated in the generalized gradient approximation in the formulation of perdew , burke , and ernzerhof .", "tokens": ["exchange", "and", "correlation", "effects", "were", "treated", "in", "the", "generalized", "gradient", "approximation", "in", "the", "formulation", "of", "perdew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "exchange and correlation effects", "start": 0, "end": 32, "i_start": 0, "i_end": 3}, "verb": {"text": "were treated", "start": 33, "end": 45, "i_start": 4, "i_end": 5}}], "id": 3004}, {"sent": "as the transition to the spin-liquid state is approached , the spectral weight of the quasiparticle peak goes to zero and the incoherent continuum grows .", "tokens": ["as", "the", "transition", "to", "the", "spin", "-", "liquid", "state", "is", "approached", ",", "the", "spectral", "weight", "of", "the", "quasiparticle", "peak", "goes", "to", "zero", "and", "the", "incoherent", "continuum", "grows", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the spectral weight of the quasiparticle peak", "start": 59, "end": 104, "i_start": 12, "i_end": 18}, "verb": {"text": "goes", "start": 105, "end": 109, "i_start": 19, "i_end": 19}}, {"subject": {"text": "the incoherent continuum", "start": 122, "end": 146, "i_start": 23, "i_end": 25}, "verb": {"text": "grows", "start": 147, "end": 152, "i_start": 26, "i_end": 26}}], "id": 3005}, {"sent": "r egion-based approaches with convolutional neural networks have achieved great success in object detection .", "tokens": ["r", "egion", "-", "based", "approaches", "with", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "object", "detection", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "r egion-based approaches with convolutional neural networks", "start": 0, "end": 59, "i_start": 0, "i_end": 8}, "verb": {"text": "have achieved", "start": 60, "end": 73, "i_start": 9, "i_end": 10}}, {"character": {"text": "approaches", "start": 14, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 65, "end": 73, "i_start": 10, "i_end": 10}}], "id": 3006}, {"sent": "for implementation , we used the matconvnet toolbox , with a 21-layer cnn pre-trained model being used .", "tokens": ["for", "implementation", ",", "we", "used", "the", "matconvnet", "toolbox", ",", "with", "a", "21", "-", "layer", "cnn", "pre", "-", "trained", "model", "being", "used", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 3, "i_end": 3}, "verb": {"text": "used", "start": 24, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "used", "start": 24, "end": 28, "i_start": 4, "i_end": 4}}], "id": 3007}, {"sent": "the quark mass serves to regulate any would be collinear singularities .", "tokens": ["the", "quark", "mass", "serves", "to", "regulate", "any", "would", "be", "collinear", "singularities", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quark mass", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "serves", "start": 15, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "mass", "start": 10, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "regulate", "start": 25, "end": 33, "i_start": 5, "i_end": 5}}], "id": 3008}, {"sent": "gans are a framework for training generative deep models via an adversarial process .", "tokens": ["gans", "are", "a", "framework", "for", "training", "generative", "deep", "models", "via", "an", "adversarial", "process", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "gans", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 5, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3009}, {"sent": "for the purposes of these lectures , we will restrict our attention to the classical bosonic open string action .", "tokens": ["for", "the", "purposes", "of", "these", "lectures", ",", "we", "will", "restrict", "our", "attention", "to", "the", "classical", "bosonic", "open", "string", "action", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 37, "end": 39, "i_start": 7, "i_end": 7}, "verb": {"text": "will restrict", "start": 40, "end": 53, "i_start": 8, "i_end": 9}}, {"character": {"text": "we", "start": 37, "end": 39, "i_start": 7, "i_end": 7}, "action": {"text": "restrict", "start": 45, "end": 53, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 37, "end": 39, "i_start": 7, "i_end": 7}, "action": {"text": "attention", "start": 58, "end": 67, "i_start": 11, "i_end": 11}}], "id": 3010}, {"sent": "in refthe successful implementation of this protocol was shown for the 144-km atmospheric channel between two canary islands .", "tokens": ["in", "refthe", "successful", "implementation", "of", "this", "protocol", "was", "shown", "for", "the", "144", "-", "km", "atmospheric", "channel", "between", "two", "canary", "islands", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "refthe successful implementation of this protocol", "start": 3, "end": 52, "i_start": 1, "i_end": 6}, "verb": {"text": "was shown", "start": 53, "end": 62, "i_start": 7, "i_end": 8}}], "id": 3011}, {"sent": "to be specific , as the solute charge separation increases , both the cation and anion radial distribution functions become more structured and their densities close to the solute become enhanced .", "tokens": ["to", "be", "specific", ",", "as", "the", "solute", "charge", "separation", "increases", ",", "both", "the", "cation", "and", "anion", "radial", "distribution", "functions", "become", "more", "structured", "and", "their", "densities", "close", "to", "the", "solute", "become", "enhanced", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3012}, {"sent": "polytope 4552 is the pentagonal prism , which is rigid by theorem 4 point 3 .", "tokens": ["polytope", "4552", "is", "the", "pentagonal", "prism", ",", "which", "is", "rigid", "by", "theorem", "4", "point", "3", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "polytope 4552", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 3013}, {"sent": "here , the signal corresponds to excited-state absorption and not the ground state bleaching .", "tokens": ["here", ",", "the", "signal", "corresponds", "to", "excited", "-", "state", "absorption", "and", "not", "the", "ground", "state", "bleaching", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the signal", "start": 7, "end": 17, "i_start": 2, "i_end": 3}, "verb": {"text": "corresponds", "start": 18, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "state", "start": 41, "end": 46, "i_start": 8, "i_end": 8}, "action": {"text": "absorption", "start": 47, "end": 57, "i_start": 9, "i_end": 9}}, {"character": {"text": "state", "start": 77, "end": 82, "i_start": 14, "i_end": 14}, "action": {"text": "bleaching", "start": 83, "end": 92, "i_start": 15, "i_end": 15}}], "id": 3014}, {"sent": "deep neural networks have achieved state-of-the-art performance in many application areas , such as computer vision and natural language processing .", "tokens": ["deep", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "many", "application", "areas", ",", "such", "as", "computer", "vision", "and", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 52, "end": 63, "i_start": 12, "i_end": 12}}], "id": 3015}, {"sent": "deep convolutional neural networks have demonstrated significant improvements over traditional approaches in many pattern recognition tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "demonstrated", "significant", "improvements", "over", "traditional", "approaches", "in", "many", "pattern", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have demonstrated", "start": 35, "end": 52, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "demonstrated", "start": 40, "end": 52, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "improvements", "start": 65, "end": 77, "i_start": 7, "i_end": 7}}], "id": 3016}, {"sent": "although this higgs is a composite particle , it acts like a weakly coupled elementary scalar in the effective theory , driving electroweak symmetry breaking at a naturally low scale .", "tokens": ["although", "this", "higgs", "is", "a", "composite", "particle", ",", "it", "acts", "like", "a", "weakly", "coupled", "elementary", "scalar", "in", "the", "effective", "theory", ",", "driving", "electroweak", "symmetry", "breaking", "at", "a", "naturally", "low", "scale", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 46, "end": 48, "i_start": 8, "i_end": 8}, "verb": {"text": "acts", "start": 49, "end": 53, "i_start": 9, "i_end": 9}}, {"character": {"text": "theory", "start": 111, "end": 117, "i_start": 19, "i_end": 19}, "action": {"text": "effective", "start": 101, "end": 110, "i_start": 18, "i_end": 18}}, {"character": {"text": "acts", "start": 49, "end": 53, "i_start": 9, "i_end": 9}, "action": {"text": "driving", "start": 120, "end": 127, "i_start": 21, "i_end": 21}}], "id": 3017}, {"sent": "gu and rigazio proposed deep contractive network that adds a smoothness penalty on the partial derivatives at every layer .", "tokens": ["gu", "and", "rigazio", "proposed", "deep", "contractive", "network", "that", "adds", "a", "smoothness", "penalty", "on", "the", "partial", "derivatives", "at", "every", "layer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "gu and rigazio", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "gu", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "rigazio", "start": 7, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "network", "start": 41, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "contractive", "start": 29, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "network", "start": 41, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "adds", "start": 54, "end": 58, "i_start": 8, "i_end": 8}}], "id": 3018}, {"sent": "cnns have improved the state of the art in a number of computer vision tasks such as image classification .", "tokens": ["cnns", "have", "improved", "the", "state", "of", "the", "art", "in", "a", "number", "of", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cnns", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "have improved", "start": 5, "end": 18, "i_start": 1, "i_end": 2}}], "id": 3019}, {"sent": "cellule ayant quatre sorties au lieu de deux , les chemins comportent un croisement de .", "tokens": ["cellule", "ayant", "quatre", "sorties", "au", "lieu", "de", "deux", ",", "les", "chemins", "comportent", "un", "croisement", "de", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3020}, {"sent": "to treat our multidimensional problem , we now extend formally the one-dimensional formulae obtained in to the multidimensional case .", "tokens": ["to", "treat", "our", "multidimensional", "problem", ",", "we", "now", "extend", "formally", "the", "one", "-", "dimensional", "formulae", "obtained", "in", "to", "the", "multidimensional", "case", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 40, "end": 42, "i_start": 6, "i_end": 6}, "verb": {"text": "extend", "start": 47, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 40, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "extend", "start": 47, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 40, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "treat", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3021}, {"sent": "quantum entanglement is a quite amazing physical it was first discussed in depth in 1935 phenomenon .", "tokens": ["quantum", "entanglement", "is", "a", "quite", "amazing", "physical", "it", "was", "first", "discussed", "in", "depth", "in", "1935", "phenomenon", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 49, "end": 51, "i_start": 7, "i_end": 7}, "verb": {"text": "discussed", "start": 62, "end": 71, "i_start": 10, "i_end": 10}}, {"subject": {"text": "it", "start": 49, "end": 51, "i_start": 7, "i_end": 7}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 2, "i_end": 2}}, {"subject": {"text": "it", "start": 49, "end": 51, "i_start": 7, "i_end": 7}, "verb": {"text": "was", "start": 52, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "physical", "start": 40, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "amazing", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}], "id": 3022}, {"sent": "semantic pixel-wise segmentation is an ongoing topic of research , fuelled by challenging datasets .", "tokens": ["semantic", "pixel", "-", "wise", "segmentation", "is", "an", "ongoing", "topic", "of", "research", ",", "fuelled", "by", "challenging", "datasets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "semantic pixel-wise segmentation", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 5, "i_end": 5}}, {"character": {"text": "datasets", "start": 90, "end": 98, "i_start": 15, "i_end": 15}, "action": {"text": "fuelled", "start": 67, "end": 74, "i_start": 12, "i_end": 12}}, {"character": {"text": "datasets", "start": 90, "end": 98, "i_start": 15, "i_end": 15}, "action": {"text": "challenging", "start": 78, "end": 89, "i_start": 14, "i_end": 14}}], "id": 3023}, {"sent": "deep convolutional neural networks have led to major breakthroughs in many computer vision tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "led", "to", "major", "breakthroughs", "in", "many", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have led", "start": 35, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "led", "start": 40, "end": 43, "i_start": 5, "i_end": 5}}], "id": 3024}, {"sent": "this cohomology class is the godbillon-vey invariant of f .", "tokens": ["this", "cohomology", "class", "is", "the", "godbillon", "-", "vey", "invariant", "of", "f", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this cohomology class", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3025}, {"sent": "after each convolutional layer and before relu nonlinearity , we applied batch normalization to improve the networks generalization capability .", "tokens": ["after", "each", "convolutional", "layer", "and", "before", "relu", "nonlinearity", ",", "we", "applied", "batch", "normalization", "to", "improve", "the", "networks", "generalization", "capability", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 62, "end": 64, "i_start": 9, "i_end": 9}, "verb": {"text": "applied", "start": 65, "end": 72, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 62, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "applied", "start": 65, "end": 72, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 62, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "improve", "start": 96, "end": 103, "i_start": 14, "i_end": 14}}], "id": 3026}, {"sent": "such a geometry is a physical geometry , ie it is described completely by the world function , which is a half of the squared distance function .", "tokens": ["such", "a", "geometry", "is", "a", "physical", "geometry", ",", "ie", "it", "is", "described", "completely", "by", "the", "world", "function", ",", "which", "is", "a", "half", "of", "the", "squared", "distance", "function", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 44, "end": 46, "i_start": 9, "i_end": 9}, "verb": {"text": "is described", "start": 47, "end": 59, "i_start": 10, "i_end": 11}}, {"subject": {"text": "it", "start": 44, "end": 46, "i_start": 9, "i_end": 9}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "function", "start": 84, "end": 92, "i_start": 16, "i_end": 16}, "action": {"text": "described", "start": 50, "end": 59, "i_start": 11, "i_end": 11}}], "id": 3027}, {"sent": "this observable is of particular interest because it is regularly measured in experiments with ultracold quantum gases .", "tokens": ["this", "observable", "is", "of", "particular", "interest", "because", "it", "is", "regularly", "measured", "in", "experiments", "with", "ultracold", "quantum", "gases", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this observable", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "measured", "start": 66, "end": 74, "i_start": 10, "i_end": 10}, "action": {"text": "because", "start": 42, "end": 49, "i_start": 6, "i_end": 6}}], "id": 3028}, {"sent": "recent progress in neural networks has led to impressive successes in a wide range of applications , including image classification , language representation , move selection for go , and many more .", "tokens": ["recent", "progress", "in", "neural", "networks", "has", "led", "to", "impressive", "successes", "in", "a", "wide", "range", "of", "applications", ",", "including", "image", "classification", ",", "language", "representation", ",", "move", "selection", "for", "go", ",", "and", "many", "more", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent progress in neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "has led", "start": 35, "end": 42, "i_start": 5, "i_end": 6}}, {"subject": {"text": "recent progress in neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "move", "start": 160, "end": 164, "i_start": 24, "i_end": 24}}, {"character": {"text": "progress", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 39, "end": 42, "i_start": 6, "i_end": 6}}, {"character": {"text": "successes", "start": 57, "end": 66, "i_start": 9, "i_end": 9}, "action": {"text": "impressive", "start": 46, "end": 56, "i_start": 8, "i_end": 8}}], "id": 3029}, {"sent": "for a hilbert space h , we denote the banach space of all bounded linear operators by l .", "tokens": ["for", "a", "hilbert", "space", "h", ",", "we", "denote", "the", "banach", "space", "of", "all", "bounded", "linear", "operators", "by", "l", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 24, "end": 26, "i_start": 6, "i_end": 6}, "verb": {"text": "denote", "start": 27, "end": 33, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the banach space of", "start": 34, "end": 53, "i_start": 8, "i_end": 11}, "verb": {"text": "bounded", "start": 58, "end": 65, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 6, "i_end": 6}, "action": {"text": "denote", "start": 27, "end": 33, "i_start": 7, "i_end": 7}}], "id": 3030}, {"sent": "in contrast , for high accretion rates radiation has little impact on the spin evolution and the value of terminal spin is mostly determined by the properties of the flow .", "tokens": ["in", "contrast", ",", "for", "high", "accretion", "rates", "radiation", "has", "little", "impact", "on", "the", "spin", "evolution", "and", "the", "value", "of", "terminal", "spin", "is", "mostly", "determined", "by", "the", "properties", "of", "the", "flow", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "the value of terminal spin", "start": 93, "end": 119, "i_start": 16, "i_end": 20}, "verb": {"text": "has", "start": 49, "end": 52, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the value of terminal spin", "start": 93, "end": 119, "i_start": 16, "i_end": 20}, "verb": {"text": "determined", "start": 130, "end": 140, "i_start": 23, "i_end": 23}}, {"character": {"text": "radiation", "start": 39, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "impact", "start": 60, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "properties", "start": 148, "end": 158, "i_start": 26, "i_end": 26}, "action": {"text": "determined", "start": 130, "end": 140, "i_start": 23, "i_end": 23}}], "id": 3031}, {"sent": "comparison lemma for analytic quasi-cofree comodules .", "tokens": ["comparison", "lemma", "for", "analytic", "quasi", "-", "cofree", "comodules", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3032}, {"sent": "in recent years , deep convolutional neural networks have set the state-of-the-art on a broad range of computer vision tasks .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "set", "the", "state", "-", "of", "-", "the", "-", "art", "on", "a", "broad", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have set", "start": 53, "end": 61, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "set", "start": 58, "end": 61, "i_start": 9, "i_end": 9}}], "id": 3033}, {"sent": "as a fundamental problem in the field of image processing , image restoration has been widely studied in the past two decades .", "tokens": ["as", "a", "fundamental", "problem", "in", "the", "field", "of", "image", "processing", ",", "image", "restoration", "has", "been", "widely", "studied", "in", "the", "past", "two", "decades", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "image restoration", "start": 60, "end": 77, "i_start": 11, "i_end": 12}, "verb": {"text": "studied", "start": 94, "end": 101, "i_start": 16, "i_end": 16}}, {"subject": {"text": "image restoration", "start": 60, "end": 77, "i_start": 11, "i_end": 12}, "verb": {"text": "has been", "start": 78, "end": 86, "i_start": 13, "i_end": 14}}], "id": 3034}, {"sent": "from the study of the sequential case , one knows that a postorder traversal , while not optimal for all instances , provides good results .", "tokens": ["from", "the", "study", "of", "the", "sequential", "case", ",", "one", "knows", "that", "a", "postorder", "traversal", ",", "while", "not", "optimal", "for", "all", "instances", ",", "provides", "good", "results", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 40, "end": 43, "i_start": 8, "i_end": 8}, "verb": {"text": "knows", "start": 44, "end": 49, "i_start": 9, "i_end": 9}}, {"subject": {"text": "a postorder traversal", "start": 55, "end": 76, "i_start": 11, "i_end": 13}, "verb": {"text": "provides", "start": 117, "end": 125, "i_start": 22, "i_end": 22}}, {"character": {"text": "one", "start": 40, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "knows", "start": 44, "end": 49, "i_start": 9, "i_end": 9}}, {"character": {"text": "traversal", "start": 67, "end": 76, "i_start": 13, "i_end": 13}, "action": {"text": "provides", "start": 117, "end": 125, "i_start": 22, "i_end": 22}}], "id": 3035}, {"sent": "however , the boundary condition is completely different in the twobrane system .", "tokens": ["however", ",", "the", "boundary", "condition", "is", "completely", "different", "in", "the", "twobrane", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the boundary condition", "start": 10, "end": 32, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 5, "i_end": 5}}], "id": 3036}, {"sent": "therefore , both 5 and 13 are adjacent to 67 , and hence the degree of 67 must be at least 2 , which is a contradiction .", "tokens": ["therefore", ",", "both", "5", "and", "13", "are", "adjacent", "to", "67", ",", "and", "hence", "the", "degree", "of", "67", "must", "be", "at", "least", "2", ",", "which", "is", "a", "contradiction", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "both 5 and 13", "start": 12, "end": 25, "i_start": 2, "i_end": 5}, "verb": {"text": "are", "start": 26, "end": 29, "i_start": 6, "i_end": 6}}], "id": 3037}, {"sent": "indeed , we first reduce our problem to one with homogeneous boundary conditions by subtracting from the solution a more regular function .", "tokens": ["indeed", ",", "we", "first", "reduce", "our", "problem", "to", "one", "with", "homogeneous", "boundary", "conditions", "by", "subtracting", "from", "the", "solution", "a", "more", "regular", "function", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "verb": {"text": "reduce", "start": 18, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "action": {"text": "reduce", "start": 18, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "action": {"text": "subtracting", "start": 84, "end": 95, "i_start": 14, "i_end": 14}}], "id": 3038}, {"sent": "the model is motivated by recent experiments in which purified simian virus 40 capsid proteins assemble in vitro around ssrna molecules to form virus-like particles composed of 12 homopentamer subunits .", "tokens": ["the", "model", "is", "motivated", "by", "recent", "experiments", "in", "which", "purified", "simian", "virus", "40", "capsid", "proteins", "assemble", "in", "vitro", "around", "ssrna", "molecules", "to", "form", "virus", "-", "like", "particles", "composed", "of", "12", "homopentamer", "subunits", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is motivated", "start": 10, "end": 22, "i_start": 2, "i_end": 3}}, {"character": {"text": "experiments", "start": 33, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "motivated", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "40 capsid proteins", "start": 76, "end": 94, "i_start": 12, "i_end": 14}, "action": {"text": "form", "start": 139, "end": 143, "i_start": 22, "i_end": 22}}], "id": 3039}, {"sent": "every magnet consists of 24 segments of vacodym alloy 4 .", "tokens": ["every", "magnet", "consists", "of", "24", "segments", "of", "vacodym", "alloy", "4", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "every magnet", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 13, "end": 21, "i_start": 2, "i_end": 2}}], "id": 3040}, {"sent": "now we proceed on to define smarandache biquasi groups .", "tokens": ["now", "we", "proceed", "on", "to", "define", "smarandache", "biquasi", "groups", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed on", "start": 7, "end": 17, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 3041}, {"sent": "a popular example is the molecular dynamics algorithm of lubachevsky and stillinger , which simulates a dilute system of interacting particles , whose size grows linearly in time until jamming occurs .", "tokens": ["a", "popular", "example", "is", "the", "molecular", "dynamics", "algorithm", "of", "lubachevsky", "and", "stillinger", ",", "which", "simulates", "a", "dilute", "system", "of", "interacting", "particles", ",", "whose", "size", "grows", "linearly", "in", "time", "until", "jamming", "occurs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a popular example", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithm", "start": 44, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "simulates", "start": 92, "end": 101, "i_start": 14, "i_end": 14}}, {"character": {"text": "particles", "start": 133, "end": 142, "i_start": 20, "i_end": 20}, "action": {"text": "interacting", "start": 121, "end": 132, "i_start": 19, "i_end": 19}}], "id": 3042}, {"sent": "in , the authors employed deep reinforcement learning to allocate caching , computing and communication resources for mec system in vehicle networks .", "tokens": ["in", ",", "the", "authors", "employed", "deep", "reinforcement", "learning", "to", "allocate", "caching", ",", "computing", "and", "communication", "resources", "for", "mec", "system", "in", "vehicle", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 5, "end": 16, "i_start": 2, "i_end": 3}, "verb": {"text": "employed", "start": 17, "end": 25, "i_start": 4, "i_end": 4}}], "id": 3043}, {"sent": "here we compare physical and logical models trained by quantum annealing , simulated thermal annealing , and exact gradient .", "tokens": ["here", "we", "compare", "physical", "and", "logical", "models", "trained", "by", "quantum", "annealing", ",", "simulated", "thermal", "annealing", ",", "and", "exact", "gradient", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "compare", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "compare", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "annealing", "start": 63, "end": 72, "i_start": 10, "i_end": 10}, "action": {"text": "trained", "start": 44, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "quantum", "start": 55, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "trained", "start": 44, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "annealing", "start": 93, "end": 102, "i_start": 14, "i_end": 14}, "action": {"text": "trained", "start": 44, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "thermal", "start": 85, "end": 92, "i_start": 13, "i_end": 13}, "action": {"text": "trained", "start": 44, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "gradient", "start": 115, "end": 123, "i_start": 18, "i_end": 18}, "action": {"text": "trained", "start": 44, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "exact", "start": 109, "end": 114, "i_start": 17, "i_end": 17}, "action": {"text": "trained", "start": 44, "end": 51, "i_start": 7, "i_end": 7}}], "id": 3044}, {"sent": "the lagrangian is a lagrangian of dynamical noncommutativity of the space co ordinates .", "tokens": ["the", "lagrangian", "is", "a", "lagrangian", "of", "dynamical", "noncommutativity", "of", "the", "space", "co", "ordinates", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lagrangian", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 3045}, {"sent": "we check all the results against the results obtained from numerical programs fiesta .", "tokens": ["we", "check", "all", "the", "results", "against", "the", "results", "obtained", "from", "numerical", "programs", "fiesta", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "check", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "check", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3046}, {"sent": "thistlethwaite described an expansion of the jones polynomial in terms of spanning trees of the tait graph .", "tokens": ["thistlethwaite", "described", "an", "expansion", "of", "the", "jones", "polynomial", "in", "terms", "of", "spanning", "trees", "of", "the", "tait", "graph", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "thistlethwaite", "start": 0, "end": 14, "i_start": 0, "i_end": 0}, "verb": {"text": "described", "start": 15, "end": 24, "i_start": 1, "i_end": 1}}, {"character": {"text": "thistlethwaite", "start": 0, "end": 14, "i_start": 0, "i_end": 0}, "action": {"text": "described", "start": 15, "end": 24, "i_start": 1, "i_end": 1}}, {"character": {"text": "polynomial", "start": 51, "end": 61, "i_start": 7, "i_end": 7}, "action": {"text": "spanning", "start": 74, "end": 82, "i_start": 11, "i_end": 11}}], "id": 3047}, {"sent": "the second inverted arrow is on one of the two boundaries adjacent ( rather than opposite ) to that of the first .", "tokens": ["the", "second", "inverted", "arrow", "is", "on", "one", "of", "the", "two", "boundaries", "adjacent", "(", "rather", "than", "opposite", ")", "to", "that", "of", "the", "first", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the second inverted arrow", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 4, "i_end": 4}}], "id": 3048}, {"sent": "this principle is therefore also called observer invariance .", "tokens": ["this", "principle", "is", "therefore", "also", "called", "observer", "invariance", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this principle", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "called", "start": 33, "end": 39, "i_start": 5, "i_end": 5}}, {"subject": {"text": "this principle", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 3049}, {"sent": "vaughn , two loop renormalization group equations for soft supersymmetry breaking couplings , phys .", "tokens": ["vaughn", ",", "two", "loop", "renormalization", "group", "equations", "for", "soft", "supersymmetry", "breaking", "couplings", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3050}, {"sent": "zamolodchikov , exact expectation values of local fields in quantum sine-gordon model nucl .", "tokens": ["zamolodchikov", ",", "exact", "expectation", "values", "of", "local", "fields", "in", "quantum", "sine", "-", "gordon", "model", "nucl", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3051}, {"sent": "the solid curve is the result of the curve fitting .", "tokens": ["the", "solid", "curve", "is", "the", "result", "of", "the", "curve", "fitting", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the solid curve", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 3052}, {"sent": "for strongly causal spacetimes a is the manifold topology m , while it is strictly coarser than m when strong causality is violated .", "tokens": ["for", "strongly", "causal", "spacetimes", "a", "is", "the", "manifold", "topology", "m", ",", "while", "it", "is", "strictly", "coarser", "than", "m", "when", "strong", "causality", "is", "violated", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a", "start": 31, "end": 32, "i_start": 4, "i_end": 4}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 5, "i_end": 5}}], "id": 3053}, {"sent": "we use word2vec toolkit to pre-train 200d word embeddings on wikipedia corpus 3 , and randomly initialize the oov words .", "tokens": ["we", "use", "word2vec", "toolkit", "to", "pre", "-", "train", "200d", "word", "embeddings", "on", "wikipedia", "corpus", "3", ",", "and", "randomly", "initialize", "the", "oov", "words", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "initialize", "start": 95, "end": 105, "i_start": 18, "i_end": 18}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "initialize", "start": 95, "end": 105, "i_start": 18, "i_end": 18}}], "id": 3054}, {"sent": "we assume now that the terminal is a diffusive metal of negligible resistance .", "tokens": ["we", "assume", "now", "that", "the", "terminal", "is", "a", "diffusive", "metal", "of", "negligible", "resistance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "metal", "start": 47, "end": 52, "i_start": 9, "i_end": 9}, "action": {"text": "resistance", "start": 67, "end": 77, "i_start": 12, "i_end": 12}}], "id": 3055}, {"sent": "in recent years , deep learning technology has boosted automatic speech recognition performance significantly .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "technology", "has", "boosted", "automatic", "speech", "recognition", "performance", "significantly", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning technology", "start": 18, "end": 42, "i_start": 4, "i_end": 6}, "verb": {"text": "has boosted", "start": 43, "end": 54, "i_start": 7, "i_end": 8}}, {"character": {"text": "technology", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "boosted", "start": 47, "end": 54, "i_start": 8, "i_end": 8}}], "id": 3056}, {"sent": "arguably , prolog is the most popular and powerful logic programming language .", "tokens": ["arguably", ",", "prolog", "is", "the", "most", "popular", "and", "powerful", "logic", "programming", "language", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "prolog", "start": 11, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}], "id": 3057}, {"sent": "the hindwing in its downstroke is responsible for the large .", "tokens": ["the", "hindwing", "in", "its", "downstroke", "is", "responsible", "for", "the", "large", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the hindwing in its downstroke", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "hindwing", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "responsible", "start": 34, "end": 45, "i_start": 6, "i_end": 6}}], "id": 3058}, {"sent": "the apparatus usually consists of a chain of correlated events .", "tokens": ["the", "apparatus", "usually", "consists", "of", "a", "chain", "of", "correlated", "events", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the apparatus", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 22, "end": 30, "i_start": 3, "i_end": 3}}], "id": 3059}, {"sent": "the seiberg-witten invariant is the characteristic number obtained from these data by specifying an orientation of the moduli space .", "tokens": ["the", "seiberg", "-", "witten", "invariant", "is", "the", "characteristic", "number", "obtained", "from", "these", "data", "by", "specifying", "an", "orientation", "of", "the", "moduli", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the seiberg-witten invariant", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 5, "i_end": 5}}], "id": 3060}, {"sent": "the convergence of specific learning algorithms has been studied in recent works .", "tokens": ["the", "convergence", "of", "specific", "learning", "algorithms", "has", "been", "studied", "in", "recent", "works", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the convergence of specific learning algorithms", "start": 0, "end": 47, "i_start": 0, "i_end": 5}, "verb": {"text": "has been studied", "start": 48, "end": 64, "i_start": 6, "i_end": 8}}], "id": 3061}, {"sent": "recently , deep neural networks have demonstrated impressive results in image classification .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "demonstrated", "impressive", "results", "in", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have demonstrated", "start": 32, "end": 49, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "demonstrated", "start": 37, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "results", "start": 61, "end": 68, "i_start": 8, "i_end": 8}, "action": {"text": "impressive", "start": 50, "end": 60, "i_start": 7, "i_end": 7}}], "id": 3062}, {"sent": "as indicated in , the process times of many parallel jobs , in particular , jobs to data centers , tend to be non-exponential .", "tokens": ["as", "indicated", "in", ",", "the", "process", "times", "of", "many", "parallel", "jobs", ",", "in", "particular", ",", "jobs", "to", "data", "centers", ",", "tend", "to", "be", "non", "-", "exponential", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "as indicated in", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "tend", "start": 99, "end": 103, "i_start": 20, "i_end": 20}}], "id": 3063}, {"sent": "therefore , we can conclude results for the triebel-lizorkin and sobolev spaces .", "tokens": ["therefore", ",", "we", "can", "conclude", "results", "for", "the", "triebel", "-", "lizorkin", "and", "sobolev", "spaces", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "can conclude", "start": 15, "end": 27, "i_start": 3, "i_end": 4}}, {"character": {"text": "we", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "conclude", "start": 19, "end": 27, "i_start": 4, "i_end": 4}}], "id": 3064}, {"sent": "many deep learning structures have been proposed based on convolutional neural networks .", "tokens": ["many", "deep", "learning", "structures", "have", "been", "proposed", "based", "on", "convolutional", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many deep learning structures", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "have been proposed", "start": 30, "end": 48, "i_start": 4, "i_end": 6}}], "id": 3065}, {"sent": "this is one of the main new result of the present paper .", "tokens": ["this", "is", "one", "of", "the", "main", "new", "result", "of", "the", "present", "paper", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3066}, {"sent": "indeed , so far , existence of optimal policies for static teams and a class of sequential dynamic teams has been studied recently in .", "tokens": ["indeed", ",", "so", "far", ",", "existence", "of", "optimal", "policies", "for", "static", "teams", "and", "a", "class", "of", "sequential", "dynamic", "teams", "has", "been", "studied", "recently", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "existence of optimal policies for static teams and a class of sequential dynamic teams", "start": 18, "end": 104, "i_start": 5, "i_end": 18}, "verb": {"text": "has been studied", "start": 105, "end": 121, "i_start": 19, "i_end": 21}}], "id": 3067}, {"sent": "the kernel k-means algorithm performs clustering in feature space using mean functions as the representatives of the clusters .", "tokens": ["the", "kernel", "k", "-", "means", "algorithm", "performs", "clustering", "in", "feature", "space", "using", "mean", "functions", "as", "the", "representatives", "of", "the", "clusters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the kernel k-means algorithm", "start": 0, "end": 28, "i_start": 0, "i_end": 5}, "verb": {"text": "performs", "start": 29, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "algorithm", "start": 19, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "performs", "start": 29, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "algorithm", "start": 19, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "using", "start": 66, "end": 71, "i_start": 11, "i_end": 11}}], "id": 3068}, {"sent": "in addition , this performance is impacted by the low energy sensitivity and rf-to-direct current rectification efficiency .", "tokens": ["in", "addition", ",", "this", "performance", "is", "impacted", "by", "the", "low", "energy", "sensitivity", "and", "rf", "-", "to", "-", "direct", "current", "rectification", "efficiency", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this performance", "start": 14, "end": 30, "i_start": 3, "i_end": 4}, "verb": {"text": "is impacted", "start": 31, "end": 42, "i_start": 5, "i_end": 6}}, {"character": {"text": "sensitivity", "start": 61, "end": 72, "i_start": 11, "i_end": 11}, "action": {"text": "impacted", "start": 34, "end": 42, "i_start": 6, "i_end": 6}}, {"character": {"text": "efficiency", "start": 112, "end": 122, "i_start": 20, "i_end": 20}, "action": {"text": "impacted", "start": 34, "end": 42, "i_start": 6, "i_end": 6}}, {"character": {"text": "current", "start": 90, "end": 97, "i_start": 18, "i_end": 18}, "action": {"text": "impacted", "start": 34, "end": 42, "i_start": 6, "i_end": 6}}], "id": 3069}, {"sent": "the numerical and analytical solutions of the two-term ordinary fde are studied in .", "tokens": ["the", "numerical", "and", "analytical", "solutions", "of", "the", "two", "-", "term", "ordinary", "fde", "are", "studied", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the numerical and analytical solutions of the two-term ordinary fde", "start": 0, "end": 67, "i_start": 0, "i_end": 11}, "verb": {"text": "are studied", "start": 68, "end": 79, "i_start": 12, "i_end": 13}}], "id": 3070}, {"sent": "the lagrangian comprises degrees of freedom corresponding to the coset space symmetry transformations .", "tokens": ["the", "lagrangian", "comprises", "degrees", "of", "freedom", "corresponding", "to", "the", "coset", "space", "symmetry", "transformations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lagrangian", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "comprises", "start": 15, "end": 24, "i_start": 2, "i_end": 2}}], "id": 3071}, {"sent": "in order to prolong the lifetime of energy-constrained wireless nodes , energy harvesting has been proposed as a very promising approach .", "tokens": ["in", "order", "to", "prolong", "the", "lifetime", "of", "energy", "-", "constrained", "wireless", "nodes", ",", "energy", "harvesting", "has", "been", "proposed", "as", "a", "very", "promising", "approach", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "energy harvesting", "start": 72, "end": 89, "i_start": 13, "i_end": 14}, "verb": {"text": "has been proposed", "start": 90, "end": 107, "i_start": 15, "i_end": 17}}, {"character": {"text": "approach", "start": 128, "end": 136, "i_start": 22, "i_end": 22}, "action": {"text": "promising", "start": 118, "end": 127, "i_start": 21, "i_end": 21}}], "id": 3072}, {"sent": "entanglement represents correlations among quantum systems that can not be explained by classical local models , and it is at the core of quantum information science .", "tokens": ["entanglement", "represents", "correlations", "among", "quantum", "systems", "that", "can", "not", "be", "explained", "by", "classical", "local", "models", ",", "and", "it", "is", "at", "the", "core", "of", "quantum", "information", "science", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "entanglement", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "represents", "start": 13, "end": 23, "i_start": 1, "i_end": 1}}, {"character": {"text": "entanglement", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "action": {"text": "represents", "start": 13, "end": 23, "i_start": 1, "i_end": 1}}, {"character": {"text": "models", "start": 104, "end": 110, "i_start": 14, "i_end": 14}, "action": {"text": "explained", "start": 75, "end": 84, "i_start": 10, "i_end": 10}}], "id": 3073}, {"sent": "in order to meet the demands of high data rate transmissions and improve the connectivities of the secure networks , the multiple antenna systems with security concerns are considered by several authors .", "tokens": ["in", "order", "to", "meet", "the", "demands", "of", "high", "data", "rate", "transmissions", "and", "improve", "the", "connectivities", "of", "the", "secure", "networks", ",", "the", "multiple", "antenna", "systems", "with", "security", "concerns", "are", "considered", "by", "several", "authors", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "the multiple antenna systems with security concerns", "start": 117, "end": 168, "i_start": 20, "i_end": 26}, "verb": {"text": "are considered", "start": 169, "end": 183, "i_start": 27, "i_end": 28}}, {"character": {"text": "several", "start": 187, "end": 194, "i_start": 30, "i_end": 30}, "action": {"text": "considered", "start": 173, "end": 183, "i_start": 28, "i_end": 28}}, {"character": {"text": "systems", "start": 138, "end": 145, "i_start": 23, "i_end": 23}, "action": {"text": "concerns", "start": 160, "end": 168, "i_start": 26, "i_end": 26}}, {"character": {"text": "systems", "start": 138, "end": 145, "i_start": 23, "i_end": 23}, "action": {"text": "meet", "start": 12, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "systems", "start": 138, "end": 145, "i_start": 23, "i_end": 23}, "action": {"text": "improve", "start": 65, "end": 72, "i_start": 12, "i_end": 12}}], "id": 3074}, {"sent": "extending the idea of susy , parametric families of complex potentials with all-real spectra can be constructed .", "tokens": ["extending", "the", "idea", "of", "susy", ",", "parametric", "families", "of", "complex", "potentials", "with", "all", "-", "real", "spectra", "can", "be", "constructed", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "parametric families of complex potentials with all-real spectra", "start": 29, "end": 92, "i_start": 6, "i_end": 15}, "verb": {"text": "can be constructed", "start": 93, "end": 111, "i_start": 16, "i_end": 18}}], "id": 3075}, {"sent": "the collection of cts over m , ie the image of \u03b3 , is called the central sphere congruence on m .", "tokens": ["the", "collection", "of", "cts", "over", "m", ",", "ie", "the", "image", "of", "\u03b3", ",", "is", "called", "the", "central", "sphere", "congruence", "on", "m", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the collection of cts over m", "start": 0, "end": 28, "i_start": 0, "i_end": 5}, "verb": {"text": "is called", "start": 51, "end": 60, "i_start": 13, "i_end": 14}}], "id": 3076}, {"sent": "deep neural networks have given rise to major advancements in many problems of machine intelligence .", "tokens": ["deep", "neural", "networks", "have", "given", "rise", "to", "major", "advancements", "in", "many", "problems", "of", "machine", "intelligence", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have given", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "rise", "start": 32, "end": 36, "i_start": 5, "i_end": 5}}], "id": 3077}, {"sent": "recently , a lot of network embedding models are proposed , which aim to learn low-dimension representations of vertices while preserving the network structure .", "tokens": ["recently", ",", "a", "lot", "of", "network", "embedding", "models", "are", "proposed", ",", "which", "aim", "to", "learn", "low", "-", "dimension", "representations", "of", "vertices", "while", "preserving", "the", "network", "structure", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a lot of network embedding models", "start": 11, "end": 44, "i_start": 2, "i_end": 7}, "verb": {"text": "are proposed", "start": 45, "end": 57, "i_start": 8, "i_end": 9}}, {"character": {"text": "models", "start": 38, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "aim", "start": 66, "end": 69, "i_start": 12, "i_end": 12}}], "id": 3078}, {"sent": "the collapse is a phase transition from binary lattice space to miscible space .", "tokens": ["the", "collapse", "is", "a", "phase", "transition", "from", "binary", "lattice", "space", "to", "miscible", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the collapse", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 3079}, {"sent": "the interested reader should refer to for a thorough account on the subject of the stability of functional equations .", "tokens": ["the", "interested", "reader", "should", "refer", "to", "for", "a", "thorough", "account", "on", "the", "subject", "of", "the", "stability", "of", "functional", "equations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the interested reader", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "should refer", "start": 22, "end": 34, "i_start": 3, "i_end": 4}}], "id": 3080}, {"sent": "specifically , the key performance indicator of 1 ms over-the-air latency has been proposed by such standards bodies as the itu , as well as recent studies such as those carried out under the metis 2020 project , as one of the core 5g requirements .", "tokens": ["specifically", ",", "the", "key", "performance", "indicator", "of", "1", "ms", "over", "-", "the", "-", "air", "latency", "has", "been", "proposed", "by", "such", "standards", "bodies", "as", "the", "itu", ",", "as", "well", "as", "recent", "studies", "such", "as", "those", "carried", "out", "under", "the", "metis", "2020", "project", ",", "as", "one", "of", "the", "core", "5", "g", "requirements", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "the key performance indicator of 1 ms over-the-air latency", "start": 15, "end": 73, "i_start": 2, "i_end": 14}, "verb": {"text": "has been proposed", "start": 74, "end": 91, "i_start": 15, "i_end": 17}}, {"character": {"text": "bodies", "start": 110, "end": 116, "i_start": 21, "i_end": 21}, "action": {"text": "proposed", "start": 83, "end": 91, "i_start": 17, "i_end": 17}}], "id": 3081}, {"sent": "convolutional neural networks have achieved remarkable success in many computer vision domains such as classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "remarkable", "success", "in", "many", "computer", "vision", "domains", "such", "as", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 6, "i_end": 6}}], "id": 3082}, {"sent": "based on even higher field enhancements , strong coupling at room temperature has recently been achieved for a single dye molecule placed in a plasmonic gap resonance .", "tokens": ["based", "on", "even", "higher", "field", "enhancements", ",", "strong", "coupling", "at", "room", "temperature", "has", "recently", "been", "achieved", "for", "a", "single", "dye", "molecule", "placed", "in", "a", "plasmonic", "gap", "resonance", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "strong coupling at room temperature", "start": 42, "end": 77, "i_start": 7, "i_end": 11}, "verb": {"text": "been achieved", "start": 91, "end": 104, "i_start": 14, "i_end": 15}}, {"subject": {"text": "strong coupling at room temperature", "start": 42, "end": 77, "i_start": 7, "i_end": 11}, "verb": {"text": "has", "start": 78, "end": 81, "i_start": 12, "i_end": 12}}], "id": 3083}, {"sent": "the weight matrices for the filters were initialized using the xavier method and weights for the two cnns were shared .", "tokens": ["the", "weight", "matrices", "for", "the", "filters", "were", "initialized", "using", "the", "xavier", "method", "and", "weights", "for", "the", "two", "cnns", "were", "shared", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the weight matrices for the filters", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "were initialized", "start": 36, "end": 52, "i_start": 6, "i_end": 7}}, {"subject": {"text": "the weight matrices for the filters", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "shared", "start": 111, "end": 117, "i_start": 19, "i_end": 19}}], "id": 3084}, {"sent": "the lagrangian is the constant brane tension integrated over the area of the brane .", "tokens": ["the", "lagrangian", "is", "the", "constant", "brane", "tension", "integrated", "over", "the", "area", "of", "the", "brane", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lagrangian", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 3085}, {"sent": "note that checking positive semidefiniteness of a polynomial por a polynomial matrix p is np-hard in general .", "tokens": ["note", "that", "checking", "positive", "semidefiniteness", "of", "a", "polynomial", "por", "a", "polynomial", "matrix", "p", "is", "np", "-", "hard", "in", "general", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3086}, {"sent": "generative adversarial networks have been very successful in learning probability distributions .", "tokens": ["generative", "adversarial", "networks", "have", "been", "very", "successful", "in", "learning", "probability", "distributions", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 32, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 47, "end": 57, "i_start": 6, "i_end": 6}}], "id": 3087}, {"sent": "the corresponding optimization problem can be solved through a coordinate descent algorithm .", "tokens": ["the", "corresponding", "optimization", "problem", "can", "be", "solved", "through", "a", "coordinate", "descent", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the corresponding optimization problem", "start": 0, "end": 38, "i_start": 0, "i_end": 3}, "verb": {"text": "can be solved", "start": 39, "end": 52, "i_start": 4, "i_end": 6}}], "id": 3088}, {"sent": "machine learning methods built on deep neural networks have had unparalleled success across a dizzying array of tasks ranging from image recognition to speech recognition and synthesis .", "tokens": ["machine", "learning", "methods", "built", "on", "deep", "neural", "networks", "have", "had", "unparalleled", "success", "across", "a", "dizzying", "array", "of", "tasks", "ranging", "from", "image", "recognition", "to", "speech", "recognition", "and", "synthesis", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "machine learning methods built on deep neural networks", "start": 0, "end": 54, "i_start": 0, "i_end": 7}, "verb": {"text": "have had", "start": 55, "end": 63, "i_start": 8, "i_end": 9}}, {"character": {"text": "methods", "start": 17, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 77, "end": 84, "i_start": 11, "i_end": 11}}, {"character": {"text": "tasks", "start": 112, "end": 117, "i_start": 17, "i_end": 17}, "action": {"text": "dizzying", "start": 94, "end": 102, "i_start": 14, "i_end": 14}}], "id": 3089}, {"sent": "the gabor features has been applied successfully in character and word recognition .", "tokens": ["the", "gabor", "features", "has", "been", "applied", "successfully", "in", "character", "and", "word", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the gabor features", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "has been applied", "start": 19, "end": 35, "i_start": 3, "i_end": 5}}], "id": 3090}, {"sent": "deep convolutional neural networks have achieved huge success in solving problems related to computer vision , such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "huge", "success", "in", "solving", "problems", "related", "to", "computer", "vision", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 54, "end": 61, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "solving", "start": 65, "end": 72, "i_start": 9, "i_end": 9}}], "id": 3091}, {"sent": "dft calculations were performed using the plane-wave quantum espresso package within the generalized gradient approximation , with the perdew-burke-ernzerhof parametrization for the exchange-correlation functional .", "tokens": ["dft", "calculations", "were", "performed", "using", "the", "plane", "-", "wave", "quantum", "espresso", "package", "within", "the", "generalized", "gradient", "approximation", ",", "with", "the", "perdew", "-", "burke", "-", "ernzerhof", "parametrization", "for", "the", "exchange", "-", "correlation", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dft calculations", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were performed", "start": 17, "end": 31, "i_start": 2, "i_end": 3}}], "id": 3092}, {"sent": "modified newtonian dynamics as an alternative to dark matter .", "tokens": ["modified", "newtonian", "dynamics", "as", "an", "alternative", "to", "dark", "matter", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3093}, {"sent": "machine learning models , especially deep neural networks , have been deployed prominently in many real-world applications , such as image classification .", "tokens": ["machine", "learning", "models", ",", "especially", "deep", "neural", "networks", ",", "have", "been", "deployed", "prominently", "in", "many", "real", "-", "world", "applications", ",", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "machine learning models", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "have been deployed", "start": 60, "end": 78, "i_start": 9, "i_end": 11}}], "id": 3094}, {"sent": "neural networks have enjoyed great success in many practical applications .", "tokens": ["neural", "networks", "have", "enjoyed", "great", "success", "in", "many", "practical", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have enjoyed", "start": 16, "end": 28, "i_start": 2, "i_end": 3}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "enjoyed", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "success", "start": 35, "end": 42, "i_start": 5, "i_end": 5}}], "id": 3095}, {"sent": "the cosmological model is the \u03bbchdm model having different neutrino fractions .", "tokens": ["the", "cosmological", "model", "is", "the", "\u03bbchdm", "model", "having", "different", "neutrino", "fractions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the cosmological model", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "model", "start": 36, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "having", "start": 42, "end": 48, "i_start": 7, "i_end": 7}}], "id": 3096}, {"sent": "generative adversarial networks are neural generative models that can be trained using backpropagation to mimick sampling from very high dimensional nonparametric distributions .", "tokens": ["generative", "adversarial", "networks", "are", "neural", "generative", "models", "that", "can", "be", "trained", "using", "backpropagation", "to", "mimick", "sampling", "from", "very", "high", "dimensional", "nonparametric", "distributions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}], "id": 3097}, {"sent": "however , the temperature fluctuation is the same in both ensembles .", "tokens": ["however", ",", "the", "temperature", "fluctuation", "is", "the", "same", "in", "both", "ensembles", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the temperature fluctuation", "start": 10, "end": 37, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 5, "i_end": 5}}], "id": 3098}, {"sent": "artificial neural networks , especially with deep network structures , have achieved great success on machine learning applications such as image classification .", "tokens": ["artificial", "neural", "networks", ",", "especially", "with", "deep", "network", "structures", ",", "have", "achieved", "great", "success", "on", "machine", "learning", "applications", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "artificial neural networks", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 71, "end": 84, "i_start": 10, "i_end": 11}}, {"character": {"text": "networks", "start": 18, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 76, "end": 84, "i_start": 11, "i_end": 11}}], "id": 3099}, {"sent": "the reduced hamiltonian is the energy er\u00b5 .", "tokens": ["the", "reduced", "hamiltonian", "is", "the", "energy", "er\u00b5", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the reduced hamiltonian", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}], "id": 3100}, {"sent": "this complexity is the same as the quotient complexity of l , which is the number of distinct left quotients of l .", "tokens": ["this", "complexity", "is", "the", "same", "as", "the", "quotient", "complexity", "of", "l", ",", "which", "is", "the", "number", "of", "distinct", "left", "quotients", "of", "l", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this complexity", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3101}, {"sent": "we proceed on to define the notion of bisimple .", "tokens": ["we", "proceed", "on", "to", "define", "the", "notion", "of", "bisimple", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "proceed on", "start": 3, "end": 13, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proceed", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "define", "start": 17, "end": 23, "i_start": 4, "i_end": 4}}], "id": 3102}, {"sent": "in recent years , deep neural networks have achieved great success in a variety of machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "achieved", "great", "success", "in", "a", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}], "id": 3103}, {"sent": "convolutional neural networks have recently been applied to various computer vision tasks such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "been", "applied", "to", "various", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "been applied", "start": 44, "end": 56, "i_start": 5, "i_end": 6}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}], "id": 3104}, {"sent": "neural network-based architectures have recently had great success in significantly advancing the state of the art on challenging image classification and object detection datasets .", "tokens": ["neural", "network", "-", "based", "architectures", "have", "recently", "had", "great", "success", "in", "significantly", "advancing", "the", "state", "of", "the", "art", "on", "challenging", "image", "classification", "and", "object", "detection", "datasets", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural network-based architectures", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "had", "start": 49, "end": 52, "i_start": 7, "i_end": 7}}, {"subject": {"text": "neural network-based architectures", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "architectures", "start": 21, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "architectures", "start": 21, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "advancing", "start": 84, "end": 93, "i_start": 12, "i_end": 12}}, {"character": {"text": "architectures", "start": 21, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "challenging", "start": 118, "end": 129, "i_start": 19, "i_end": 19}}, {"character": {"text": "datasets", "start": 172, "end": 180, "i_start": 25, "i_end": 25}, "action": {"text": "classification", "start": 136, "end": 150, "i_start": 21, "i_end": 21}}], "id": 3105}, {"sent": "here , a microwave source is used to directly drive the magnon mode and it can enhance the magnomechanical coupling .", "tokens": ["here", ",", "a", "microwave", "source", "is", "used", "to", "directly", "drive", "the", "magnon", "mode", "and", "it", "can", "enhance", "the", "magnomechanical", "coupling", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a microwave source", "start": 7, "end": 25, "i_start": 2, "i_end": 4}, "verb": {"text": "is used", "start": 26, "end": 33, "i_start": 5, "i_end": 6}}, {"subject": {"text": "it", "start": 72, "end": 74, "i_start": 14, "i_end": 14}, "verb": {"text": "enhance", "start": 79, "end": 86, "i_start": 16, "i_end": 16}}, {"character": {"text": "source", "start": 19, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "drive", "start": 46, "end": 51, "i_start": 9, "i_end": 9}}, {"character": {"text": "source", "start": 19, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "enhance", "start": 79, "end": 86, "i_start": 16, "i_end": 16}}], "id": 3106}, {"sent": "it would also be interesting in this context to extend our analysis for the anomaly-free type ib vacuum with 32 d9branes to an anomaly-free type ib thermal vacuum with n additional d9brane-anti-d9brane pairs .", "tokens": ["it", "would", "also", "be", "interesting", "in", "this", "context", "to", "extend", "our", "analysis", "for", "the", "anomaly", "-", "free", "type", "ib", "vacuum", "with", "32", "d9branes", "to", "an", "anomaly", "-", "free", "type", "ib", "thermal", "vacuum", "with", "n", "additional", "d9brane", "-", "anti", "-", "d9brane", "pairs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "be", "start": 14, "end": 16, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "would", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3107}, {"sent": "our derivation is based on the second law of thermodynamics .", "tokens": ["our", "derivation", "is", "based", "on", "the", "second", "law", "of", "thermodynamics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our derivation", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is based", "start": 15, "end": 23, "i_start": 2, "i_end": 3}}], "id": 3108}, {"sent": "magnetic or non-magnetic dopants , vacancies 7 , 8 and grain boundaries 9 , 10 , have been attempted to introduce long-range ferromagnetic orders in semiconductors .", "tokens": ["magnetic", "or", "non", "-", "magnetic", "dopants", ",", "vacancies", "7", ",", "8", "and", "grain", "boundaries", "9", ",", "10", ",", "have", "been", "attempted", "to", "introduce", "long", "-", "range", "ferromagnetic", "orders", "in", "semiconductors", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "magnetic or non-magnetic dopants", "start": 0, "end": 32, "i_start": 0, "i_end": 5}, "verb": {"text": "have been attempted", "start": 81, "end": 100, "i_start": 18, "i_end": 20}}], "id": 3109}, {"sent": "the physics objects are the jets , clustered using the jet finding algorithm with the tracks assigned to the vertex as inputs , and the associated p miss t , taken as the negative vector sum of the p t of those jets .", "tokens": ["the", "physics", "objects", "are", "the", "jets", ",", "clustered", "using", "the", "jet", "finding", "algorithm", "with", "the", "tracks", "assigned", "to", "the", "vertex", "as", "inputs", ",", "and", "the", "associated", "p", "miss", "t", ",", "taken", "as", "the", "negative", "vector", "sum", "of", "the", "p", "t", "of", "those", "jets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the physics objects", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 20, "end": 23, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the associated p", "start": 132, "end": 148, "i_start": 24, "i_end": 26}, "verb": {"text": "miss", "start": 149, "end": 153, "i_start": 27, "i_end": 27}}], "id": 3110}, {"sent": "we implement our models in pytorch on top of the allennlp library .", "tokens": ["we", "implement", "our", "models", "in", "pytorch", "on", "top", "of", "the", "allennlp", "library", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}], "id": 3111}, {"sent": "differential privacy , introduced by dwork et al , is one of the usual approaches for the privacy concerns .", "tokens": ["differential", "privacy", ",", "introduced", "by", "dwork", "et", "al", ",", "is", "one", "of", "the", "usual", "approaches", "for", "the", "privacy", "concerns", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "differential privacy", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 51, "end": 53, "i_start": 9, "i_end": 9}}, {"character": {"text": "dwork", "start": 37, "end": 42, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 23, "end": 33, "i_start": 3, "i_end": 3}}], "id": 3112}, {"sent": "the main difference with is that , here , the singular set k is not assumed to be connected .", "tokens": ["the", "main", "difference", "with", "is", "that", ",", "here", ",", "the", "singular", "set", "k", "is", "not", "assumed", "to", "be", "connected", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the main difference with", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the singular set k", "start": 42, "end": 60, "i_start": 9, "i_end": 12}, "verb": {"text": "assumed", "start": 68, "end": 75, "i_start": 15, "i_end": 15}}], "id": 3113}, {"sent": "we measure the run-time overhead and memory impact of snapshotting using the savina benchmark suite .", "tokens": ["we", "measure", "the", "run", "-", "time", "overhead", "and", "memory", "impact", "of", "snapshotting", "using", "the", "savina", "benchmark", "suite", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "measure", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "measure", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "snapshotting", "start": 54, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "impact", "start": 44, "end": 50, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 67, "end": 72, "i_start": 12, "i_end": 12}}], "id": 3114}, {"sent": "deep learning has brought significant breakthroughs in many computer vision tasks , including object detection .", "tokens": ["deep", "learning", "has", "brought", "significant", "breakthroughs", "in", "many", "computer", "vision", "tasks", ",", "including", "object", "detection", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has brought", "start": 14, "end": 25, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "breakthroughs", "start": 38, "end": 51, "i_start": 5, "i_end": 5}}], "id": 3115}, {"sent": "the ellipses denote the loops and arrows on them show drifting directions .", "tokens": ["the", "ellipses", "denote", "the", "loops", "and", "arrows", "on", "them", "show", "drifting", "directions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ellipses", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "denote", "start": 13, "end": 19, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the loops and arrows on them", "start": 20, "end": 48, "i_start": 3, "i_end": 8}, "verb": {"text": "show", "start": 49, "end": 53, "i_start": 9, "i_end": 9}}, {"character": {"text": "ellipses", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 13, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "loops", "start": 24, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "show", "start": 49, "end": 53, "i_start": 9, "i_end": 9}}, {"character": {"text": "arrows", "start": 34, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "show", "start": 49, "end": 53, "i_start": 9, "i_end": 9}}, {"character": {"text": "ellipses", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 49, "end": 53, "i_start": 9, "i_end": 9}}], "id": 3116}, {"sent": "one thus obtains the omplete past and future history of the system \u03c8 .", "tokens": ["one", "thus", "obtains", "the", "omplete", "past", "and", "future", "history", "of", "the", "system", "\u03c8", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "obtains", "start": 9, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "obtains", "start": 9, "end": 16, "i_start": 2, "i_end": 2}}], "id": 3117}, {"sent": "in recent years , the development of deep convolutional neural networks has made notable progress in providing accurate segmentation results .", "tokens": ["in", "recent", "years", ",", "the", "development", "of", "deep", "convolutional", "neural", "networks", "has", "made", "notable", "progress", "in", "providing", "accurate", "segmentation", "results", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the development of deep convolutional neural networks", "start": 18, "end": 71, "i_start": 4, "i_end": 10}, "verb": {"text": "has made", "start": 72, "end": 80, "i_start": 11, "i_end": 12}}, {"character": {"text": "networks", "start": 63, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "providing", "start": 101, "end": 110, "i_start": 16, "i_end": 16}}], "id": 3118}, {"sent": "zhang , for the belle collaboration , these proceedings .", "tokens": ["zhang", ",", "for", "the", "belle", "collaboration", ",", "these", "proceedings", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "belle", "start": 16, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "collaboration", "start": 22, "end": 35, "i_start": 5, "i_end": 5}}], "id": 3119}, {"sent": "such adaptivity has recently been shown to hold for isotonic regression .", "tokens": ["such", "adaptivity", "has", "recently", "been", "shown", "to", "hold", "for", "isotonic", "regression", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such adaptivity", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "been shown", "start": 29, "end": 39, "i_start": 4, "i_end": 5}}, {"subject": {"text": "such adaptivity", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "has", "start": 16, "end": 19, "i_start": 2, "i_end": 2}}], "id": 3120}, {"sent": "such canonical representations have been given for binarymemoryless symmetric channels in .", "tokens": ["such", "canonical", "representations", "have", "been", "given", "for", "binarymemoryless", "symmetric", "channels", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such canonical representations", "start": 0, "end": 30, "i_start": 0, "i_end": 2}, "verb": {"text": "have been given", "start": 31, "end": 46, "i_start": 3, "i_end": 5}}], "id": 3121}, {"sent": "for the regularized problem , several properties , like well-posedness of the cauchy problem and existence of invariant measures can be proved .", "tokens": ["for", "the", "regularized", "problem", ",", "several", "properties", ",", "like", "well", "-", "posedness", "of", "the", "cauchy", "problem", "and", "existence", "of", "invariant", "measures", "can", "be", "proved", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "several properties", "start": 30, "end": 48, "i_start": 5, "i_end": 6}, "verb": {"text": "can be proved", "start": 129, "end": 142, "i_start": 21, "i_end": 23}}], "id": 3122}, {"sent": "the same pulse width , pulse energy and peak power .", "tokens": ["the", "same", "pulse", "width", ",", "pulse", "energy", "and", "peak", "power", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3123}, {"sent": "the best results with respect to polynomial exactness are obtained by genz and genz and keister .", "tokens": ["the", "best", "results", "with", "respect", "to", "polynomial", "exactness", "are", "obtained", "by", "genz", "and", "genz", "and", "keister", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the best results with respect to polynomial exactness", "start": 0, "end": 53, "i_start": 0, "i_end": 7}, "verb": {"text": "are obtained", "start": 54, "end": 66, "i_start": 8, "i_end": 9}}, {"character": {"text": "genz", "start": 70, "end": 74, "i_start": 11, "i_end": 11}, "action": {"text": "obtained", "start": 58, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "genz", "start": 79, "end": 83, "i_start": 13, "i_end": 13}, "action": {"text": "obtained", "start": 58, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "keister", "start": 88, "end": 95, "i_start": 15, "i_end": 15}, "action": {"text": "obtained", "start": 58, "end": 66, "i_start": 9, "i_end": 9}}], "id": 3124}, {"sent": "deep neural networks have demonstrated to be effective models for solving a large variety of problems in several domains , including image , to name a few .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "to", "be", "effective", "models", "for", "solving", "a", "large", "variety", "of", "problems", "in", "several", "domains", ",", "including", "image", ",", "to", "name", "a", "few", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "models", "start": 55, "end": 61, "i_start": 8, "i_end": 8}, "action": {"text": "effective", "start": 45, "end": 54, "i_start": 7, "i_end": 7}}], "id": 3125}, {"sent": "though gravity is the oldest known one , it is still the less well understood .", "tokens": ["though", "gravity", "is", "the", "oldest", "known", "one", ",", "it", "is", "still", "the", "less", "well", "understood", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 41, "end": 43, "i_start": 8, "i_end": 8}, "verb": {"text": "is", "start": 44, "end": 46, "i_start": 9, "i_end": 9}}], "id": 3126}, {"sent": "the blow-up phenomena and global existence of strong solutions to in sobolev spaces have been derived in .", "tokens": ["the", "blow", "-", "up", "phenomena", "and", "global", "existence", "of", "strong", "solutions", "to", "in", "sobolev", "spaces", "have", "been", "derived", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the blow-up phenomena and global existence of strong solutions to in sobolev spaces", "start": 0, "end": 83, "i_start": 0, "i_end": 14}, "verb": {"text": "have been derived", "start": 84, "end": 101, "i_start": 15, "i_end": 17}}], "id": 3127}, {"sent": "in proceedings of the thirteenth european conference on arti cial intel ligence , pp .", "tokens": ["in", "proceedings", "of", "the", "thirteenth", "european", "conference", "on", "arti", "cial", "intel", "ligence", ",", "pp", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3128}, {"sent": "several different approaches have been proposed for generating adversarial examples , including fast gradient-based methods .", "tokens": ["several", "different", "approaches", "have", "been", "proposed", "for", "generating", "adversarial", "examples", ",", "including", "fast", "gradient", "-", "based", "methods", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "several different approaches", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "have been proposed", "start": 29, "end": 47, "i_start": 3, "i_end": 5}}], "id": 3129}, {"sent": "in the case of faces , we use the vgg face model from , pretrained on celeb face data for face recognition .", "tokens": ["in", "the", "case", "of", "faces", ",", "we", "use", "the", "vgg", "face", "model", "from", ",", "pretrained", "on", "celeb", "face", "data", "for", "face", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 23, "end": 25, "i_start": 6, "i_end": 6}, "verb": {"text": "use", "start": 26, "end": 29, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 6, "i_end": 6}, "action": {"text": "use", "start": 26, "end": 29, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 6, "i_end": 6}, "action": {"text": "pretrained", "start": 56, "end": 66, "i_start": 14, "i_end": 14}}], "id": 3130}, {"sent": "the minimal set of vl multiplets that can mix with sm quarks and a sm higgs boson have been extensively studied in literature .", "tokens": ["the", "minimal", "set", "of", "vl", "multiplets", "that", "can", "mix", "with", "sm", "quarks", "and", "a", "sm", "higgs", "boson", "have", "been", "extensively", "studied", "in", "literature", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the minimal set of vl multiplets that can mix with sm quarks and a sm higgs boson", "start": 0, "end": 81, "i_start": 0, "i_end": 16}, "verb": {"text": "studied", "start": 104, "end": 111, "i_start": 20, "i_end": 20}}, {"subject": {"text": "the minimal set of vl multiplets that can mix with sm quarks and a sm higgs boson", "start": 0, "end": 81, "i_start": 0, "i_end": 16}, "verb": {"text": "have been", "start": 82, "end": 91, "i_start": 17, "i_end": 18}}], "id": 3131}, {"sent": "this has stimulated a large number of investigations into synchronization properties of complex networks , with small-world , scale-free and other types of topologies .", "tokens": ["this", "has", "stimulated", "a", "large", "number", "of", "investigations", "into", "synchronization", "properties", "of", "complex", "networks", ",", "with", "small", "-", "world", ",", "scale", "-", "free", "and", "other", "types", "of", "topologies", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "has stimulated", "start": 5, "end": 19, "i_start": 1, "i_end": 2}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "stimulated", "start": 9, "end": 19, "i_start": 2, "i_end": 2}}], "id": 3132}, {"sent": "recently , deep convolutional neural networks have attracted a lot of attention in visual recognition , largely due to their excellent performance .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "attracted", "a", "lot", "of", "attention", "in", "visual", "recognition", ",", "largely", "due", "to", "their", "excellent", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have attracted", "start": 46, "end": 60, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "attracted", "start": 51, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 135, "end": 146, "i_start": 21, "i_end": 21}}], "id": 3133}, {"sent": "based on this dataset , johnson et al proposed the dense caption task , which aims to generate sophisticated lever of regions of interest in an image , and describe each region by a sentence .", "tokens": ["based", "on", "this", "dataset", ",", "johnson", "et", "al", "proposed", "the", "dense", "caption", "task", ",", "which", "aims", "to", "generate", "sophisticated", "lever", "of", "regions", "of", "interest", "in", "an", "image", ",", "and", "describe", "each", "region", "by", "a", "sentence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "johnson et al", "start": 24, "end": 37, "i_start": 5, "i_end": 7}, "verb": {"text": "proposed", "start": 38, "end": 46, "i_start": 8, "i_end": 8}}, {"subject": {"text": "johnson et al", "start": 24, "end": 37, "i_start": 5, "i_end": 7}, "verb": {"text": "describe", "start": 156, "end": 164, "i_start": 29, "i_end": 29}}, {"character": {"text": "johnson", "start": 24, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "proposed", "start": 38, "end": 46, "i_start": 8, "i_end": 8}}, {"character": {"text": "task", "start": 65, "end": 69, "i_start": 12, "i_end": 12}, "action": {"text": "aims", "start": 78, "end": 82, "i_start": 15, "i_end": 15}}], "id": 3134}, {"sent": "training the neural network with adversarial examples is a popular defense method .", "tokens": ["training", "the", "neural", "network", "with", "adversarial", "examples", "is", "a", "popular", "defense", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "training the neural network with adversarial examples", "start": 0, "end": 53, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 54, "end": 56, "i_start": 7, "i_end": 7}}], "id": 3135}, {"sent": "we can prove that in this case this operator gives us twice the baryon number .", "tokens": ["we", "can", "prove", "that", "in", "this", "case", "this", "operator", "gives", "us", "twice", "the", "baryon", "number", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "can prove", "start": 3, "end": 12, "i_start": 1, "i_end": 2}}, {"subject": {"text": "this operator", "start": 31, "end": 44, "i_start": 7, "i_end": 8}, "verb": {"text": "gives", "start": 45, "end": 50, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "prove", "start": 7, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "this", "start": 21, "end": 25, "i_start": 5, "i_end": 5}, "action": {"text": "gives", "start": 45, "end": 50, "i_start": 9, "i_end": 9}}], "id": 3136}, {"sent": "the corresponding subgroups obtained by adding other connected components are d .", "tokens": ["the", "corresponding", "subgroups", "obtained", "by", "adding", "other", "connected", "components", "are", "d", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3137}, {"sent": "so the density wave must be considered in the relativistic region .", "tokens": ["so", "the", "density", "wave", "must", "be", "considered", "in", "the", "relativistic", "region", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the density wave", "start": 3, "end": 19, "i_start": 1, "i_end": 3}, "verb": {"text": "must be considered", "start": 20, "end": 38, "i_start": 4, "i_end": 6}}], "id": 3138}, {"sent": "predictions using two such models , referred to as model f , were employed with parameters for d .", "tokens": ["predictions", "using", "two", "such", "models", ",", "referred", "to", "as", "model", "f", ",", "were", "employed", "with", "parameters", "for", "d", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "predictions using two such models", "start": 0, "end": 33, "i_start": 0, "i_end": 4}, "verb": {"text": "referred", "start": 36, "end": 44, "i_start": 6, "i_end": 6}}, {"subject": {"text": "predictions using two such models", "start": 0, "end": 33, "i_start": 0, "i_end": 4}, "verb": {"text": "employed", "start": 66, "end": 74, "i_start": 13, "i_end": 13}}], "id": 3139}, {"sent": "convolutional neural networks have recently been applied to various computer vision tasks such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "been", "applied", "to", "various", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "been applied", "start": 44, "end": 56, "i_start": 5, "i_end": 6}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}], "id": 3140}, {"sent": "since impacts have been relatively much more extensively studied than ionizing radiation events , we will restrict our attention to the latter .", "tokens": ["since", "impacts", "have", "been", "relatively", "much", "more", "extensively", "studied", "than", "ionizing", "radiation", "events", ",", "we", "will", "restrict", "our", "attention", "to", "the", "latter", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 98, "end": 100, "i_start": 14, "i_end": 14}, "verb": {"text": "will restrict", "start": 101, "end": 114, "i_start": 15, "i_end": 16}}, {"character": {"text": "we", "start": 98, "end": 100, "i_start": 14, "i_end": 14}, "action": {"text": "restrict", "start": 106, "end": 114, "i_start": 16, "i_end": 16}}, {"character": {"text": "we", "start": 98, "end": 100, "i_start": 14, "i_end": 14}, "action": {"text": "attention", "start": 119, "end": 128, "i_start": 18, "i_end": 18}}], "id": 3141}, {"sent": "this data will be publically available from the irsa web site .", "tokens": ["this", "data", "will", "be", "publically", "available", "from", "the", "irsa", "web", "site", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this data", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "will be", "start": 10, "end": 17, "i_start": 2, "i_end": 3}}], "id": 3142}, {"sent": "the recent success of deep neural networks has greatly benefited from research into network architecture .", "tokens": ["the", "recent", "success", "of", "deep", "neural", "networks", "has", "greatly", "benefited", "from", "research", "into", "network", "architecture", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the recent success of deep neural networks", "start": 0, "end": 42, "i_start": 0, "i_end": 6}, "verb": {"text": "benefited", "start": 55, "end": 64, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the recent success of deep neural networks", "start": 0, "end": 42, "i_start": 0, "i_end": 6}, "verb": {"text": "has", "start": 43, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "research", "start": 70, "end": 78, "i_start": 11, "i_end": 11}, "action": {"text": "benefited", "start": 55, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 34, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3143}, {"sent": "deep learning has improved the state-of-the-art in automated tasks like image processing , and has already seen a wide range of applications in research and industry .", "tokens": ["deep", "learning", "has", "improved", "the", "state", "-", "of", "-", "the", "-", "art", "in", "automated", "tasks", "like", "image", "processing", ",", "and", "has", "already", "seen", "a", "wide", "range", "of", "applications", "in", "research", "and", "industry", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has improved", "start": 14, "end": 26, "i_start": 2, "i_end": 3}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "seen", "start": 107, "end": 111, "i_start": 22, "i_end": 22}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "improved", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "seen", "start": 107, "end": 111, "i_start": 22, "i_end": 22}}], "id": 3144}, {"sent": "in mathematics , banaszczyk firstly applied it to prove the transference theorems for lattices .", "tokens": ["in", "mathematics", ",", "banaszczyk", "firstly", "applied", "it", "to", "prove", "the", "transference", "theorems", "for", "lattices", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "banaszczyk", "start": 17, "end": 27, "i_start": 3, "i_end": 3}, "verb": {"text": "applied", "start": 36, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "banaszczyk", "start": 17, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "applied", "start": 36, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "banaszczyk", "start": 17, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "prove", "start": 50, "end": 55, "i_start": 8, "i_end": 8}}], "id": 3145}, {"sent": "learning in the dssm is slower than in the rbm , as reported with other models using dropconnect but it is effective in preventing overfitting .", "tokens": ["learning", "in", "the", "dssm", "is", "slower", "than", "in", "the", "rbm", ",", "as", "reported", "with", "other", "models", "using", "dropconnect", "but", "it", "is", "effective", "in", "preventing", "overfitting", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "learning in the dssm", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "it", "start": 101, "end": 103, "i_start": 19, "i_end": 19}, "action": {"text": "effective", "start": 107, "end": 116, "i_start": 21, "i_end": 21}}, {"character": {"text": "it", "start": 101, "end": 103, "i_start": 19, "i_end": 19}, "action": {"text": "preventing", "start": 120, "end": 130, "i_start": 23, "i_end": 23}}, {"character": {"text": "models", "start": 72, "end": 78, "i_start": 15, "i_end": 15}, "action": {"text": "reported", "start": 52, "end": 60, "i_start": 12, "i_end": 12}}, {"character": {"text": "models", "start": 72, "end": 78, "i_start": 15, "i_end": 15}, "action": {"text": "using", "start": 79, "end": 84, "i_start": 16, "i_end": 16}}], "id": 3146}, {"sent": "one possible answer comes from the study of the deviation to the fluctuation dissipation relation in an out of equilibrium system .", "tokens": ["one", "possible", "answer", "comes", "from", "the", "study", "of", "the", "deviation", "to", "the", "fluctuation", "dissipation", "relation", "in", "an", "out", "of", "equilibrium", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one possible answer", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "comes", "start": 20, "end": 25, "i_start": 3, "i_end": 3}}], "id": 3147}, {"sent": "in fitnet , a thick-shallow model is transformed to a thin-deep model .", "tokens": ["in", "fitnet", ",", "a", "thick", "-", "shallow", "model", "is", "transformed", "to", "a", "thin", "-", "deep", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a thick-shallow model", "start": 12, "end": 33, "i_start": 3, "i_end": 7}, "verb": {"text": "is transformed", "start": 34, "end": 48, "i_start": 8, "i_end": 9}}], "id": 3148}, {"sent": "general brane cosmologies and their global space time structure .", "tokens": ["general", "brane", "cosmologies", "and", "their", "global", "space", "time", "structure", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3149}, {"sent": "raizen , observation of the wannier-stark fan and the fractional ladder in an accelerating optical lattice , phys .", "tokens": ["raizen", ",", "observation", "of", "the", "wannier", "-", "stark", "fan", "and", "the", "fractional", "ladder", "in", "an", "accelerating", "optical", "lattice", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3150}, {"sent": "the first equality follows from an application of the chain rule for mutual information .", "tokens": ["the", "first", "equality", "follows", "from", "an", "application", "of", "the", "chain", "rule", "for", "mutual", "information", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the first equality", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "follows", "start": 19, "end": 26, "i_start": 3, "i_end": 3}}], "id": 3151}, {"sent": "haghighi et al proposed a generative model for inducing a bilingual lexicon from monolingual text by exploiting orthographic and contextual similarities among the words in two different languages .", "tokens": ["haghighi", "et", "al", "proposed", "a", "generative", "model", "for", "inducing", "a", "bilingual", "lexicon", "from", "monolingual", "text", "by", "exploiting", "orthographic", "and", "contextual", "similarities", "among", "the", "words", "in", "two", "different", "languages", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "haghighi et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "haghighi", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 3152}, {"sent": "in the special case when v arises from a time-invariant nonlinear control system , the complexity of our algorithm agrees with that of the well-known gs algorithm .", "tokens": ["in", "the", "special", "case", "when", "v", "arises", "from", "a", "time", "-", "invariant", "nonlinear", "control", "system", ",", "the", "complexity", "of", "our", "algorithm", "agrees", "with", "that", "of", "the", "well", "-", "known", "gs", "algorithm", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "the complexity of our algorithm", "start": 83, "end": 114, "i_start": 16, "i_end": 20}, "verb": {"text": "agrees", "start": 115, "end": 121, "i_start": 21, "i_end": 21}}, {"character": {"text": "complexity", "start": 87, "end": 97, "i_start": 17, "i_end": 17}, "action": {"text": "agrees", "start": 115, "end": 121, "i_start": 21, "i_end": 21}}, {"character": {"text": "system", "start": 74, "end": 80, "i_start": 14, "i_end": 14}, "action": {"text": "arises", "start": 27, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "system", "start": 74, "end": 80, "i_start": 14, "i_end": 14}, "action": {"text": "control", "start": 66, "end": 73, "i_start": 13, "i_end": 13}}, {"character": {"text": "system", "start": 74, "end": 80, "i_start": 14, "i_end": 14}, "action": {"text": "invariant", "start": 46, "end": 55, "i_start": 11, "i_end": 11}}], "id": 3153}, {"sent": "it is worth noting that there have been some attempts to apply deep generative models including vaes and generative adversarial networks .", "tokens": ["it", "is", "worth", "noting", "that", "there", "have", "been", "some", "attempts", "to", "apply", "deep", "generative", "models", "including", "vaes", "and", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}], "id": 3154}, {"sent": "in recent years , se methods based on deep learning have been proposed and investigated extensively , such as denoising autoencoders .", "tokens": ["in", "recent", "years", ",", "se", "methods", "based", "on", "deep", "learning", "have", "been", "proposed", "and", "investigated", "extensively", ",", "such", "as", "denoising", "autoencoders", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "se methods based on deep learning", "start": 18, "end": 51, "i_start": 4, "i_end": 9}, "verb": {"text": "have been proposed", "start": 52, "end": 70, "i_start": 10, "i_end": 12}}, {"subject": {"text": "se methods based on deep learning", "start": 18, "end": 51, "i_start": 4, "i_end": 9}, "verb": {"text": "investigated", "start": 75, "end": 87, "i_start": 14, "i_end": 14}}], "id": 3155}, {"sent": "here we assume that the quantum channel is the depolarizing channel with loss .", "tokens": ["here", "we", "assume", "that", "the", "quantum", "channel", "is", "the", "depolarizing", "channel", "with", "loss", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "assume", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "is", "start": 40, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "assume", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "channel", "start": 32, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "depolarizing", "start": 47, "end": 59, "i_start": 9, "i_end": 9}}], "id": 3156}, {"sent": "the most successful examples in this category include the restricted boltzmann machine , etc .", "tokens": ["the", "most", "successful", "examples", "in", "this", "category", "include", "the", "restricted", "boltzmann", "machine", ",", "etc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most successful examples in this category", "start": 0, "end": 45, "i_start": 0, "i_end": 6}, "verb": {"text": "include", "start": 46, "end": 53, "i_start": 7, "i_end": 7}}], "id": 3157}, {"sent": "however , in the general pseudo-riemanian case , the complete description of holonomy groups is a very difficult problem which still remains open , and even particular examples are of interest .", "tokens": ["however", ",", "in", "the", "general", "pseudo", "-", "riemanian", "case", ",", "the", "complete", "description", "of", "holonomy", "groups", "is", "a", "very", "difficult", "problem", "which", "still", "remains", "open", ",", "and", "even", "particular", "examples", "are", "of", "interest", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the complete description of holonomy groups", "start": 49, "end": 92, "i_start": 10, "i_end": 15}, "verb": {"text": "is", "start": 93, "end": 95, "i_start": 16, "i_end": 16}}], "id": 3158}, {"sent": "they continuously monitor the data plane connectivity of a prefix and raise an alarm for hijacking , when significant changes in the reachability of the prefix , are observed .", "tokens": ["they", "continuously", "monitor", "the", "data", "plane", "connectivity", "of", "a", "prefix", "and", "raise", "an", "alarm", "for", "hijacking", ",", "when", "significant", "changes", "in", "the", "reachability", "of", "the", "prefix", ",", "are", "observed", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "monitor", "start": 18, "end": 25, "i_start": 2, "i_end": 2}}, {"subject": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "raise", "start": 70, "end": 75, "i_start": 11, "i_end": 11}}, {"character": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "monitor", "start": 18, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "alarm", "start": 79, "end": 84, "i_start": 13, "i_end": 13}}], "id": 3159}, {"sent": "recently , generative adversarial networks has shown outstanding performance in conditional transfer of pixel-level knowledge .", "tokens": ["recently", ",", "generative", "adversarial", "networks", "has", "shown", "outstanding", "performance", "in", "conditional", "transfer", "of", "pixel", "-", "level", "knowledge", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 11, "end": 42, "i_start": 2, "i_end": 4}, "verb": {"text": "has shown", "start": 43, "end": 52, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 34, "end": 42, "i_start": 4, "i_end": 4}, "action": {"text": "shown", "start": 47, "end": 52, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 34, "end": 42, "i_start": 4, "i_end": 4}, "action": {"text": "performance", "start": 65, "end": 76, "i_start": 8, "i_end": 8}}], "id": 3160}, {"sent": "neutralino is the lightest stable supersymmetric particle in most models , so we focus on detection prospects of such a candidate , working either in the mssm or in the msugra frameworks .", "tokens": ["neutralino", "is", "the", "lightest", "stable", "supersymmetric", "particle", "in", "most", "models", ",", "so", "we", "focus", "on", "detection", "prospects", "of", "such", "a", "candidate", ",", "working", "either", "in", "the", "mssm", "or", "in", "the", "msugra", "frameworks", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 78, "end": 80, "i_start": 12, "i_end": 12}, "verb": {"text": "focus", "start": 81, "end": 86, "i_start": 13, "i_end": 13}}, {"subject": {"text": "we", "start": 78, "end": 80, "i_start": 12, "i_end": 12}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 1, "i_end": 1}}], "id": 3161}, {"sent": "hence , every involution has exactly one fixed point , which lies in an appropriate block .", "tokens": ["hence", ",", "every", "involution", "has", "exactly", "one", "fixed", "point", ",", "which", "lies", "in", "an", "appropriate", "block", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "every involution", "start": 8, "end": 24, "i_start": 2, "i_end": 3}, "verb": {"text": "has", "start": 25, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "involution", "start": 14, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "has", "start": 25, "end": 28, "i_start": 4, "i_end": 4}}], "id": 3162}, {"sent": "the 3jj qubit consists of a superconducting loop with small inductance l interrupted by three josephson junctions .", "tokens": ["the", "3jj", "qubit", "consists", "of", "a", "superconducting", "loop", "with", "small", "inductance", "l", "interrupted", "by", "three", "josephson", "junctions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the 3jj qubit", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "junctions", "start": 104, "end": 113, "i_start": 16, "i_end": 16}, "action": {"text": "interrupted", "start": 73, "end": 84, "i_start": 12, "i_end": 12}}], "id": 3163}, {"sent": "recently , motivated by this consideration , the non-hermitian topological nontrivial systems have been intensively investigated .", "tokens": ["recently", ",", "motivated", "by", "this", "consideration", ",", "the", "non", "-", "hermitian", "topological", "nontrivial", "systems", "have", "been", "intensively", "investigated", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the non-hermitian topological nontrivial systems", "start": 45, "end": 93, "i_start": 7, "i_end": 13}, "verb": {"text": "investigated", "start": 116, "end": 128, "i_start": 17, "i_end": 17}}, {"subject": {"text": "the non-hermitian topological nontrivial systems", "start": 45, "end": 93, "i_start": 7, "i_end": 13}, "verb": {"text": "have been", "start": 94, "end": 103, "i_start": 14, "i_end": 15}}, {"character": {"text": "consideration", "start": 29, "end": 42, "i_start": 5, "i_end": 5}, "action": {"text": "motivated", "start": 11, "end": 20, "i_start": 2, "i_end": 2}}], "id": 3164}, {"sent": "since quantum mechanics is a fundamentally probabilistic theory , the strategic notion of the payoff is the expected payoff .", "tokens": ["since", "quantum", "mechanics", "is", "a", "fundamentally", "probabilistic", "theory", ",", "the", "strategic", "notion", "of", "the", "payoff", "is", "the", "expected", "payoff", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the strategic notion of the payoff", "start": 66, "end": 100, "i_start": 9, "i_end": 14}, "verb": {"text": "is", "start": 101, "end": 103, "i_start": 15, "i_end": 15}}], "id": 3165}, {"sent": "deep convolutional neural networks have been successfully applied to a wide range of image classification tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successfully", "applied", "to", "a", "wide", "range", "of", "image", "classification", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "applied", "start": 58, "end": 65, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}], "id": 3166}, {"sent": "this is called the magnetorotational instability .", "tokens": ["this", "is", "called", "the", "magnetorotational", "instability", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is called", "start": 5, "end": 14, "i_start": 1, "i_end": 2}}], "id": 3167}, {"sent": "to this end , we implemented the vgg-face cnn cascaded with an long short-term memory network for the facial representations .", "tokens": ["to", "this", "end", ",", "we", "implemented", "the", "vgg", "-", "face", "cnn", "cascaded", "with", "an", "long", "short", "-", "term", "memory", "network", "for", "the", "facial", "representations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "verb": {"text": "implemented", "start": 17, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "implemented", "start": 17, "end": 28, "i_start": 5, "i_end": 5}}], "id": 3168}, {"sent": "deep neural networks have demonstrated dramatically accurate results for challenging tasks .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "dramatically", "accurate", "results", "for", "challenging", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}], "id": 3169}, {"sent": "supergravity is a motivation because its minimal multiplet has barely the number of degrees of freedom to store the information of the supersymmetric standard model , except for the higgs .", "tokens": ["supergravity", "is", "a", "motivation", "because", "its", "minimal", "multiplet", "has", "barely", "the", "number", "of", "degrees", "of", "freedom", "to", "store", "the", "information", "of", "the", "supersymmetric", "standard", "model", ",", "except", "for", "the", "higgs", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "supergravity", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "supergravity", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "action": {"text": "motivation", "start": 18, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "has", "start": 59, "end": 62, "i_start": 8, "i_end": 8}, "action": {"text": "because", "start": 29, "end": 36, "i_start": 4, "i_end": 4}}, {"character": {"text": "multiplet", "start": 49, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "has", "start": 59, "end": 62, "i_start": 8, "i_end": 8}}, {"character": {"text": "multiplet", "start": 49, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "store", "start": 106, "end": 111, "i_start": 17, "i_end": 17}}], "id": 3170}, {"sent": "we modified the resnet-50 architecture to take single or three-channel input image .", "tokens": ["we", "modified", "the", "resnet-50", "architecture", "to", "take", "single", "or", "three", "-", "channel", "input", "image", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "modified", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "modified", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "architecture", "start": 26, "end": 38, "i_start": 4, "i_end": 4}, "action": {"text": "take", "start": 42, "end": 46, "i_start": 6, "i_end": 6}}], "id": 3171}, {"sent": "moreover , dmso molecules do not penetrate to the region of the bound water as established from the dsc experiment .", "tokens": ["moreover", ",", "dmso", "molecules", "do", "not", "penetrate", "to", "the", "region", "of", "the", "bound", "water", "as", "established", "from", "the", "dsc", "experiment", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "dmso molecules", "start": 11, "end": 25, "i_start": 2, "i_end": 3}, "verb": {"text": "do not penetrate", "start": 26, "end": 42, "i_start": 4, "i_end": 6}}, {"character": {"text": "molecules", "start": 16, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "not penetrate", "start": 29, "end": 42, "i_start": 5, "i_end": 6}}, {"character": {"text": "experiment", "start": 104, "end": 114, "i_start": 19, "i_end": 19}, "action": {"text": "established", "start": 79, "end": 90, "i_start": 15, "i_end": 15}}], "id": 3172}, {"sent": "various conventional devices such as gratings , lenses , holograms , and planar filter arrays have been demonstrated using metasurfaces .", "tokens": ["various", "conventional", "devices", "such", "as", "gratings", ",", "lenses", ",", "holograms", ",", "and", "planar", "filter", "arrays", "have", "been", "demonstrated", "using", "metasurfaces", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "various conventional devices such as gratings", "start": 0, "end": 45, "i_start": 0, "i_end": 5}, "verb": {"text": "have been demonstrated", "start": 94, "end": 116, "i_start": 15, "i_end": 17}}], "id": 3173}, {"sent": "we use the implementation of these models in the open-source tensor2tensor library .", "tokens": ["we", "use", "the", "implementation", "of", "these", "models", "in", "the", "open", "-", "source", "tensor2tensor", "library", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 3174}, {"sent": "among them the coadjoint orbit method proposed by alekseev and shatashvili is the most geometrical .", "tokens": ["among", "them", "the", "coadjoint", "orbit", "method", "proposed", "by", "alekseev", "and", "shatashvili", "is", "the", "most", "geometrical", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the coadjoint orbit method proposed by alekseev and shatashvili", "start": 11, "end": 74, "i_start": 2, "i_end": 10}, "verb": {"text": "is", "start": 75, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "alekseev", "start": 50, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "proposed", "start": 38, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "shatashvili", "start": 63, "end": 74, "i_start": 10, "i_end": 10}, "action": {"text": "proposed", "start": 38, "end": 46, "i_start": 6, "i_end": 6}}], "id": 3175}, {"sent": "spin textures in slowly rotating bose-einstein condensates .", "tokens": ["spin", "textures", "in", "slowly", "rotating", "bose", "-", "einstein", "condensates", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3176}, {"sent": "if discrepancies occur between inferred predictions and experimental observations , a new set of information constraints must be chosen .", "tokens": ["if", "discrepancies", "occur", "between", "inferred", "predictions", "and", "experimental", "observations", ",", "a", "new", "set", "of", "information", "constraints", "must", "be", "chosen", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "a new set of information constraints", "start": 84, "end": 120, "i_start": 10, "i_end": 15}, "verb": {"text": "must be chosen", "start": 121, "end": 135, "i_start": 16, "i_end": 18}}], "id": 3177}, {"sent": "it was illustrated by ding et al that the complete weight enumerator can be applied to calculate the deception probabilities of certain authentication codes .", "tokens": ["it", "was", "illustrated", "by", "ding", "et", "al", "that", "the", "complete", "weight", "enumerator", "can", "be", "applied", "to", "calculate", "the", "deception", "probabilities", "of", "certain", "authentication", "codes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "was illustrated", "start": 3, "end": 18, "i_start": 1, "i_end": 2}}, {"subject": {"text": "the complete weight enumerator", "start": 38, "end": 68, "i_start": 8, "i_end": 11}, "verb": {"text": "applied", "start": 76, "end": 83, "i_start": 14, "i_end": 14}}, {"character": {"text": "ding", "start": 22, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "illustrated", "start": 7, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "enumerator", "start": 58, "end": 68, "i_start": 11, "i_end": 11}, "action": {"text": "calculate", "start": 87, "end": 96, "i_start": 16, "i_end": 16}}, {"character": {"text": "codes", "start": 151, "end": 156, "i_start": 23, "i_end": 23}, "action": {"text": "authentication", "start": 136, "end": 150, "i_start": 22, "i_end": 22}}], "id": 3178}, {"sent": "discovering hidden groups in communication networks .", "tokens": ["discovering", "hidden", "groups", "in", "communication", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3179}, {"sent": "although this paper focuses on the difficult cases that require substantial contributions , the lowcontribution cases can be largely explained in terms of recruitment into those groups , which has been studied by other researchers in a new way .", "tokens": ["although", "this", "paper", "focuses", "on", "the", "difficult", "cases", "that", "require", "substantial", "contributions", ",", "the", "lowcontribution", "cases", "can", "be", "largely", "explained", "in", "terms", "of", "recruitment", "into", "those", "groups", ",", "which", "has", "been", "studied", "by", "other", "researchers", "in", "a", "new", "way", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "the lowcontribution cases", "start": 92, "end": 117, "i_start": 13, "i_end": 15}, "verb": {"text": "explained", "start": 133, "end": 142, "i_start": 19, "i_end": 19}}, {"subject": {"text": "the lowcontribution cases", "start": 92, "end": 117, "i_start": 13, "i_end": 15}, "verb": {"text": "can be", "start": 118, "end": 124, "i_start": 16, "i_end": 17}}, {"character": {"text": "other", "start": 213, "end": 218, "i_start": 33, "i_end": 33}, "action": {"text": "studied", "start": 202, "end": 209, "i_start": 31, "i_end": 31}}, {"character": {"text": "paper", "start": 14, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "focuses", "start": 20, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "cases", "start": 112, "end": 117, "i_start": 15, "i_end": 15}, "action": {"text": "require", "start": 56, "end": 63, "i_start": 9, "i_end": 9}}], "id": 3180}, {"sent": "previous works on deep da learn domain invariant representations by exploiting different architectures , such as convolutional neural networks .", "tokens": ["previous", "works", "on", "deep", "da", "learn", "domain", "invariant", "representations", "by", "exploiting", "different", "architectures", ",", "such", "as", "convolutional", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "previous works on deep da", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "learn", "start": 26, "end": 31, "i_start": 5, "i_end": 5}}], "id": 3181}, {"sent": "typical examples include variational autoencoders and generative adversarial networks .", "tokens": ["typical", "examples", "include", "variational", "autoencoders", "and", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "typical examples", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "include", "start": 17, "end": 24, "i_start": 2, "i_end": 2}}], "id": 3182}, {"sent": "a g -isomorphism class of open immersions is called an open rigid subspace of g .", "tokens": ["a", "g", "-isomorphism", "class", "of", "open", "immersions", "is", "called", "an", "open", "rigid", "subspace", "of", "g", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a g -isomorphism class of open immersions", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "is called", "start": 42, "end": 51, "i_start": 7, "i_end": 8}}], "id": 3183}, {"sent": "applications such as , require us to not only decompose a graph and label its nodes but to also select a subgraph .", "tokens": ["applications", "such", "as", ",", "require", "us", "to", "not", "only", "decompose", "a", "graph", "and", "label", "its", "nodes", "but", "to", "also", "select", "a", "subgraph", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "applications such as", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "require", "start": 23, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "applications", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "action": {"text": "require", "start": 23, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "us", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "decompose", "start": 46, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "us", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "label", "start": 68, "end": 73, "i_start": 13, "i_end": 13}}, {"character": {"text": "us", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "select", "start": 96, "end": 102, "i_start": 19, "i_end": 19}}], "id": 3184}, {"sent": "hu et al proposed squeezeand-excitation block to model channel-wise relationships to obtain significant performance improvement for image classification .", "tokens": ["hu", "et", "al", "proposed", "squeezeand", "-", "excitation", "block", "to", "model", "channel", "-", "wise", "relationships", "to", "obtain", "significant", "performance", "improvement", "for", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hu et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "hu", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "hu", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "obtain", "start": 85, "end": 91, "i_start": 15, "i_end": 15}}], "id": 3185}, {"sent": "other works have explored optimal leader selection in leader-follower systems without stochastic disturbances .", "tokens": ["other", "works", "have", "explored", "optimal", "leader", "selection", "in", "leader", "-", "follower", "systems", "without", "stochastic", "disturbances", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "other works", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "have explored", "start": 12, "end": 25, "i_start": 2, "i_end": 3}}], "id": 3186}, {"sent": "electronic properties of low-dimensional systems have been the focus of intense research for several decades .", "tokens": ["electronic", "properties", "of", "low", "-", "dimensional", "systems", "have", "been", "the", "focus", "of", "intense", "research", "for", "several", "decades", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "electronic properties of low-dimensional systems", "start": 0, "end": 48, "i_start": 0, "i_end": 6}, "verb": {"text": "have been", "start": 49, "end": 58, "i_start": 7, "i_end": 8}}, {"character": {"text": "research", "start": 80, "end": 88, "i_start": 13, "i_end": 13}, "action": {"text": "focus", "start": 63, "end": 68, "i_start": 10, "i_end": 10}}], "id": 3187}, {"sent": "for every interval i of a we denote by mi the sub-structure of m with domain i .", "tokens": ["for", "every", "interval", "i", "of", "a", "we", "denote", "by", "mi", "the", "sub", "-", "structure", "of", "m", "with", "domain", "i", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 26, "end": 28, "i_start": 6, "i_end": 6}, "action": {"text": "denote", "start": 29, "end": 35, "i_start": 7, "i_end": 7}}], "id": 3188}, {"sent": "recently , many neural network models based on convolutional neural network exhibited excellent performances in various visual tasks such as image classification .", "tokens": ["recently", ",", "many", "neural", "network", "models", "based", "on", "convolutional", "neural", "network", "exhibited", "excellent", "performances", "in", "various", "visual", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "many neural network models based on convolutional neural network", "start": 11, "end": 75, "i_start": 2, "i_end": 10}, "verb": {"text": "exhibited", "start": 76, "end": 85, "i_start": 11, "i_end": 11}}, {"character": {"text": "models", "start": 31, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "exhibited", "start": 76, "end": 85, "i_start": 11, "i_end": 11}}], "id": 3189}, {"sent": "to make the generator and the discriminator be more balanced , metz et al created a unrolled objective function to enhance the generator .", "tokens": ["to", "make", "the", "generator", "and", "the", "discriminator", "be", "more", "balanced", ",", "metz", "et", "al", "created", "a", "unrolled", "objective", "function", "to", "enhance", "the", "generator", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "et al", "start": 68, "end": 73, "i_start": 12, "i_end": 13}, "verb": {"text": "created", "start": 74, "end": 81, "i_start": 14, "i_end": 14}}, {"character": {"text": "metz", "start": 63, "end": 67, "i_start": 11, "i_end": 11}, "action": {"text": "created", "start": 74, "end": 81, "i_start": 14, "i_end": 14}}, {"character": {"text": "metz", "start": 63, "end": 67, "i_start": 11, "i_end": 11}, "action": {"text": "enhance", "start": 115, "end": 122, "i_start": 20, "i_end": 20}}, {"character": {"text": "metz", "start": 63, "end": 67, "i_start": 11, "i_end": 11}, "action": {"text": "make", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3190}, {"sent": "zaslow , topological orbifold-models and quantum cohomology rings .", "tokens": ["zaslow", ",", "topological", "orbifold", "-", "models", "and", "quantum", "cohomology", "rings", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3191}, {"sent": "the contribution of the additional spin dependent force to the spin-faraday law is the same as that of the spin geometric phase .", "tokens": ["the", "contribution", "of", "the", "additional", "spin", "dependent", "force", "to", "the", "spin", "-", "faraday", "law", "is", "the", "same", "as", "that", "of", "the", "spin", "geometric", "phase", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the contribution of the additional spin dependent force to the spin-faraday law", "start": 0, "end": 79, "i_start": 0, "i_end": 13}, "verb": {"text": "is", "start": 80, "end": 82, "i_start": 14, "i_end": 14}}, {"character": {"text": "force", "start": 50, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "contribution", "start": 4, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "force", "start": 50, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "dependent", "start": 40, "end": 49, "i_start": 6, "i_end": 6}}], "id": 3192}, {"sent": "radiation consists of photon pairs , often called biphotons , that are correlated in frequency , wavevector , moment of birth , and polarization .", "tokens": ["radiation", "consists", "of", "photon", "pairs", ",", "often", "called", "biphotons", ",", "that", "are", "correlated", "in", "frequency", ",", "wavevector", ",", "moment", "of", "birth", ",", "and", "polarization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "radiation", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "consists", "start": 10, "end": 18, "i_start": 1, "i_end": 1}}], "id": 3193}, {"sent": "deep learning has succeeded in making hierarchical neural networks perform excellently in various practical applications .", "tokens": ["deep", "learning", "has", "succeeded", "in", "making", "hierarchical", "neural", "networks", "perform", "excellently", "in", "various", "practical", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has succeeded", "start": 14, "end": 27, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "succeeded", "start": 18, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "making", "start": 31, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 58, "end": 66, "i_start": 8, "i_end": 8}, "action": {"text": "perform", "start": 67, "end": 74, "i_start": 9, "i_end": 9}}], "id": 3194}, {"sent": "auctions were randomly assigned to an increased reserve price treatment , and the effect was estimated using difference-in-differences , which is a popular econometric method .", "tokens": ["auctions", "were", "randomly", "assigned", "to", "an", "increased", "reserve", "price", "treatment", ",", "and", "the", "effect", "was", "estimated", "using", "difference", "-", "in", "-", "differences", ",", "which", "is", "a", "popular", "econometric", "method", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the effect", "start": 78, "end": 88, "i_start": 12, "i_end": 13}, "verb": {"text": "assigned", "start": 23, "end": 31, "i_start": 3, "i_end": 3}}, {"subject": {"text": "auctions", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "were", "start": 9, "end": 13, "i_start": 1, "i_end": 1}}, {"subject": {"text": "auctions", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "estimated", "start": 93, "end": 102, "i_start": 15, "i_end": 15}}], "id": 3195}, {"sent": "all the models are trained for 20 epochs with a batch size of 1 using adam with default beta parameters .", "tokens": ["all", "the", "models", "are", "trained", "for", "20", "epochs", "with", "a", "batch", "size", "of", "1", "using", "adam", "with", "default", "beta", "parameters", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all the models", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "are trained", "start": 15, "end": 26, "i_start": 3, "i_end": 4}}], "id": 3196}, {"sent": "we will illustrate this situation by some simple examples .", "tokens": ["we", "will", "illustrate", "this", "situation", "by", "some", "simple", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will illustrate", "start": 3, "end": 18, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "illustrate", "start": 8, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3197}, {"sent": "in mechanics base manifold m is called configuration space , while tangent bundle t m is called phase space .", "tokens": ["in", "mechanics", "base", "manifold", "m", "is", "called", "configuration", "space", ",", "while", "tangent", "bundle", "t", "m", "is", "called", "phase", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "manifold m", "start": 18, "end": 28, "i_start": 3, "i_end": 4}, "verb": {"text": "is called", "start": 29, "end": 38, "i_start": 5, "i_end": 6}}, {"subject": {"text": "while tangent bundle t m", "start": 61, "end": 85, "i_start": 10, "i_end": 14}, "verb": {"text": "called", "start": 89, "end": 95, "i_start": 16, "i_end": 16}}], "id": 3198}, {"sent": "we have studied the su gauge theory in detail to clarify physical symmetry at low energies .", "tokens": ["we", "have", "studied", "the", "su", "gauge", "theory", "in", "detail", "to", "clarify", "physical", "symmetry", "at", "low", "energies", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have studied", "start": 3, "end": 15, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "studied", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "clarify", "start": 49, "end": 56, "i_start": 10, "i_end": 10}}], "id": 3199}, {"sent": "richter , preceedings of the international symposium on nuclear beta decays and neutrino , t .", "tokens": ["richter", ",", "preceedings", "of", "the", "international", "symposium", "on", "nuclear", "beta", "decays", "and", "neutrino", ",", "t", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "nuclear", "start": 56, "end": 63, "i_start": 8, "i_end": 8}, "action": {"text": "decays", "start": 69, "end": 75, "i_start": 10, "i_end": 10}}], "id": 3200}, {"sent": "we perform the optimization of the \u03c7 2 -values by using a powell minization method .", "tokens": ["we", "perform", "the", "optimization", "of", "the", "\u03c7", "2", "-values", "by", "using", "a", "powell", "minization", "method", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "perform", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimization", "start": 15, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 50, "end": 55, "i_start": 10, "i_end": 10}}], "id": 3201}, {"sent": "a robust and widely used method for discovering topics is latent dirichlet allocation .", "tokens": ["a", "robust", "and", "widely", "used", "method", "for", "discovering", "topics", "is", "latent", "dirichlet", "allocation", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a robust and widely used method for discovering topics", "start": 0, "end": 54, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 55, "end": 57, "i_start": 9, "i_end": 9}}], "id": 3202}, {"sent": "supervised training of deep convolution networks is clearly highly effective for image classification , as shown by results on imagenet .", "tokens": ["supervised", "training", "of", "deep", "convolution", "networks", "is", "clearly", "highly", "effective", "for", "image", "classification", ",", "as", "shown", "by", "results", "on", "imagenet", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "supervised training of deep convolution networks", "start": 0, "end": 48, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 49, "end": 51, "i_start": 6, "i_end": 6}}, {"character": {"text": "training", "start": 11, "end": 19, "i_start": 1, "i_end": 1}, "action": {"text": "effective", "start": 67, "end": 76, "i_start": 9, "i_end": 9}}, {"character": {"text": "results", "start": 116, "end": 123, "i_start": 17, "i_end": 17}, "action": {"text": "shown", "start": 107, "end": 112, "i_start": 15, "i_end": 15}}], "id": 3203}, {"sent": "on the other hand , inverse procedural modeling approaches process real-world data for generative representations .", "tokens": ["on", "the", "other", "hand", ",", "inverse", "procedural", "modeling", "approaches", "process", "real", "-", "world", "data", "for", "generative", "representations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "procedural modeling approaches", "start": 28, "end": 58, "i_start": 6, "i_end": 8}, "verb": {"text": "inverse", "start": 20, "end": 27, "i_start": 5, "i_end": 5}}, {"subject": {"text": "procedural modeling approaches", "start": 28, "end": 58, "i_start": 6, "i_end": 8}, "verb": {"text": "process", "start": 59, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "approaches", "start": 48, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "process", "start": 59, "end": 66, "i_start": 9, "i_end": 9}}], "id": 3204}, {"sent": "in order to derive more accurate implications for new physics from fine-tuning arguments , one must consider specific possibilities for np .", "tokens": ["in", "order", "to", "derive", "more", "accurate", "implications", "for", "new", "physics", "from", "fine", "-", "tuning", "arguments", ",", "one", "must", "consider", "specific", "possibilities", "for", "np", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "one", "start": 91, "end": 94, "i_start": 16, "i_end": 16}, "verb": {"text": "must consider", "start": 95, "end": 108, "i_start": 17, "i_end": 18}}, {"character": {"text": "one", "start": 91, "end": 94, "i_start": 16, "i_end": 16}, "action": {"text": "consider", "start": 100, "end": 108, "i_start": 18, "i_end": 18}}, {"character": {"text": "one", "start": 91, "end": 94, "i_start": 16, "i_end": 16}, "action": {"text": "derive", "start": 12, "end": 18, "i_start": 3, "i_end": 3}}], "id": 3205}, {"sent": "superscripts m will denote minkowski coordinates , while superscripts e will refer to euclidean coordinates .", "tokens": ["superscripts", "m", "will", "denote", "minkowski", "coordinates", ",", "while", "superscripts", "e", "will", "refer", "to", "euclidean", "coordinates", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "superscripts m", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "will denote", "start": 15, "end": 26, "i_start": 2, "i_end": 3}}, {"character": {"text": "superscripts", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 20, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "superscripts", "start": 57, "end": 69, "i_start": 8, "i_end": 8}, "action": {"text": "refer", "start": 77, "end": 82, "i_start": 11, "i_end": 11}}], "id": 3206}, {"sent": "we evaluate the performance of our scheme on two standard action recognition benchmarks , namely hmdb-51 .", "tokens": ["we", "evaluate", "the", "performance", "of", "our", "scheme", "on", "two", "standard", "action", "recognition", "benchmarks", ",", "namely", "hmdb-51", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "scheme", "start": 35, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 16, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "two standard action recognition benchmarks", "start": 45, "end": 87, "i_start": 8, "i_end": 12}, "action": {"text": "recognition", "start": 65, "end": 76, "i_start": 11, "i_end": 11}}], "id": 3207}, {"sent": "more quantitative studies of this phenomenon are needed .", "tokens": ["more", "quantitative", "studies", "of", "this", "phenomenon", "are", "needed", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "more quantitative studies of this phenomenon", "start": 0, "end": 44, "i_start": 0, "i_end": 5}, "verb": {"text": "are needed", "start": 45, "end": 55, "i_start": 6, "i_end": 7}}], "id": 3208}, {"sent": "we use madgraph 5 to generate both the background and the signal events .", "tokens": ["we", "use", "madgraph", "5", "to", "generate", "both", "the", "background", "and", "the", "signal", "events", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "generate", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}], "id": 3209}, {"sent": "here the superscripts denote the frequencies found by solving the eigenvalue problem and those by evolving the 2-dimensional perturbation equations , respectively .", "tokens": ["here", "the", "superscripts", "denote", "the", "frequencies", "found", "by", "solving", "the", "eigenvalue", "problem", "and", "those", "by", "evolving", "the", "2", "-", "dimensional", "perturbation", "equations", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the superscripts", "start": 5, "end": 21, "i_start": 1, "i_end": 2}, "verb": {"text": "denote", "start": 22, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "superscripts", "start": 9, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "denote", "start": 22, "end": 28, "i_start": 3, "i_end": 3}}], "id": 3210}, {"sent": "various generative target appearance modeling algorithms have been proposed including sparse representation .", "tokens": ["various", "generative", "target", "appearance", "modeling", "algorithms", "have", "been", "proposed", "including", "sparse", "representation", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "various generative target appearance modeling algorithms", "start": 0, "end": 56, "i_start": 0, "i_end": 5}, "verb": {"text": "have been proposed", "start": 57, "end": 75, "i_start": 6, "i_end": 8}}, {"character": {"text": "algorithms", "start": 46, "end": 56, "i_start": 5, "i_end": 5}, "action": {"text": "modeling", "start": 37, "end": 45, "i_start": 4, "i_end": 4}}], "id": 3211}, {"sent": "with the evolution of deep learning , deep neural network , especially convolutional neural network , has been successfully used in various fields , such as image classification and so on .", "tokens": ["with", "the", "evolution", "of", "deep", "learning", ",", "deep", "neural", "network", ",", "especially", "convolutional", "neural", "network", ",", "has", "been", "successfully", "used", "in", "various", "fields", ",", "such", "as", "image", "classification", "and", "so", "on", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3212}, {"sent": "h idden markov models are a standard tool in many applications , including signal processing .", "tokens": ["h", "idden", "markov", "models", "are", "a", "standard", "tool", "in", "many", "applications", ",", "including", "signal", "processing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "h idden markov models", "start": 0, "end": 21, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 22, "end": 25, "i_start": 4, "i_end": 4}}], "id": 3213}, {"sent": "we train two architectures for object detection , faster r-cnn with resnet101 , using the kittibox implementation .", "tokens": ["we", "train", "two", "architectures", "for", "object", "detection", ",", "faster", "r", "-", "cnn", "with", "resnet101", ",", "using", "the", "kittibox", "implementation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 80, "end": 85, "i_start": 15, "i_end": 15}}], "id": 3214}, {"sent": "in order to satisfy the requirements of massive connectivity and higher spectrum efficiency , noma has been identified as a proposing technique in 5g systems .", "tokens": ["in", "order", "to", "satisfy", "the", "requirements", "of", "massive", "connectivity", "and", "higher", "spectrum", "efficiency", ",", "noma", "has", "been", "identified", "as", "a", "proposing", "technique", "in", "5", "g", "systems", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "noma", "start": 94, "end": 98, "i_start": 14, "i_end": 14}, "verb": {"text": "has been identified", "start": 99, "end": 118, "i_start": 15, "i_end": 17}}, {"character": {"text": "technique", "start": 134, "end": 143, "i_start": 21, "i_end": 21}, "action": {"text": "satisfy", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}], "id": 3215}, {"sent": "they also use asp , which creates a different \u03c6 compared to the coded mask approach we use .", "tokens": ["they", "also", "use", "asp", ",", "which", "creates", "a", "different", "\u03c6", "compared", "to", "the", "coded", "mask", "approach", "we", "use", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 10, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 10, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "asp", "start": 14, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "creates", "start": 26, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 84, "end": 86, "i_start": 16, "i_end": 16}, "action": {"text": "use", "start": 87, "end": 90, "i_start": 17, "i_end": 17}}], "id": 3216}, {"sent": "recently , savary et al conducted a shared task for the identification of verbal mwes with a data set spanning 18 languages .", "tokens": ["recently", ",", "savary", "et", "al", "conducted", "a", "shared", "task", "for", "the", "identification", "of", "verbal", "mwes", "with", "a", "data", "set", "spanning", "18", "languages", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "savary et al", "start": 11, "end": 23, "i_start": 2, "i_end": 4}, "verb": {"text": "conducted", "start": 24, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "savary", "start": 11, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "conducted", "start": 24, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "set", "start": 98, "end": 101, "i_start": 18, "i_end": 18}, "action": {"text": "spanning", "start": 102, "end": 110, "i_start": 19, "i_end": 19}}], "id": 3217}, {"sent": "for the self-attention layer , we adopt the multi-head attention mechanism .", "tokens": ["for", "the", "self", "-", "attention", "layer", ",", "we", "adopt", "the", "multi", "-", "head", "attention", "mechanism", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 31, "end": 33, "i_start": 7, "i_end": 7}, "verb": {"text": "adopt", "start": 34, "end": 39, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 7, "i_end": 7}, "action": {"text": "adopt", "start": 34, "end": 39, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 7, "i_end": 7}, "action": {"text": "attention", "start": 13, "end": 22, "i_start": 4, "i_end": 4}}], "id": 3218}, {"sent": "deep neural networks have recently achieved huge success in various machine learning tasks .", "tokens": ["deep", "neural", "networks", "have", "recently", "achieved", "huge", "success", "in", "various", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 49, "end": 56, "i_start": 7, "i_end": 7}}], "id": 3219}, {"sent": "indeed , dense mmwave networks have been shown to be an attractive deployment option for outdoor urban areas .", "tokens": ["indeed", ",", "dense", "mmwave", "networks", "have", "been", "shown", "to", "be", "an", "attractive", "deployment", "option", "for", "outdoor", "urban", "areas", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dense mmwave networks", "start": 9, "end": 30, "i_start": 2, "i_end": 4}, "verb": {"text": "have been shown", "start": 31, "end": 46, "i_start": 5, "i_end": 7}}, {"character": {"text": "option", "start": 78, "end": 84, "i_start": 13, "i_end": 13}, "action": {"text": "attractive", "start": 56, "end": 66, "i_start": 11, "i_end": 11}}], "id": 3220}, {"sent": "offline , a particle-flow algorithm is used to reconstruct and identify each particle in an event based on a combination of information from the various cms subdetectors .", "tokens": ["offline", ",", "a", "particle", "-", "flow", "algorithm", "is", "used", "to", "reconstruct", "and", "identify", "each", "particle", "in", "an", "event", "based", "on", "a", "combination", "of", "information", "from", "the", "various", "cms", "subdetectors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "offline , a particle-flow algorithm", "start": 0, "end": 35, "i_start": 0, "i_end": 6}, "verb": {"text": "is used", "start": 36, "end": 43, "i_start": 7, "i_end": 8}}], "id": 3221}, {"sent": "an asterisk denotes the presence of a given harmonic .", "tokens": ["an", "asterisk", "denotes", "the", "presence", "of", "a", "given", "harmonic", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "an asterisk", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "denotes", "start": 12, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "asterisk", "start": 3, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "denotes", "start": 12, "end": 19, "i_start": 2, "i_end": 2}}], "id": 3222}, {"sent": "we use the variational graph auto-encoder framework and train the model in an unsupervised fashion using a subset of the links .", "tokens": ["we", "use", "the", "variational", "graph", "auto", "-", "encoder", "framework", "and", "train", "the", "model", "in", "an", "unsupervised", "fashion", "using", "a", "subset", "of", "the", "links", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 56, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 56, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 99, "end": 104, "i_start": 17, "i_end": 17}}], "id": 3223}, {"sent": "in recent years , deep convolutional neural networks have demonstrated dramatic improvements in performance for computer vision tasks such as object classification , detection , and segmentation .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "demonstrated", "dramatic", "improvements", "in", "performance", "for", "computer", "vision", "tasks", "such", "as", "object", "classification", ",", "detection", ",", "and", "segmentation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have demonstrated", "start": 53, "end": 70, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "demonstrated", "start": 58, "end": 70, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "improvements", "start": 80, "end": 92, "i_start": 11, "i_end": 11}}], "id": 3224}, {"sent": "it has high performance when interrupt driven .", "tokens": ["it", "has", "high", "performance", "when", "interrupt", "driven", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "performance", "start": 12, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "interrupt", "start": 29, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "driven", "start": 39, "end": 45, "i_start": 6, "i_end": 6}}], "id": 3225}, {"sent": "we implemented our approach in matlab and used matconvnet for implementing our networks .", "tokens": ["we", "implemented", "our", "approach", "in", "matlab", "and", "used", "matconvnet", "for", "implementing", "our", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implemented", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 42, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implemented", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "approach", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 42, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implementing", "start": 62, "end": 74, "i_start": 10, "i_end": 10}}], "id": 3226}, {"sent": "the library consists of 259 images of the desert landscape , most of them without vegetation and some with soils at different humidity levels .", "tokens": ["the", "library", "consists", "of", "259", "images", "of", "the", "desert", "landscape", ",", "most", "of", "them", "without", "vegetation", "and", "some", "with", "soils", "at", "different", "humidity", "levels", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the library", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 12, "end": 20, "i_start": 2, "i_end": 2}}], "id": 3227}, {"sent": "significant improvements have been obtained in various computer vision tasks by applying deep learning techniques , including image classification .", "tokens": ["significant", "improvements", "have", "been", "obtained", "in", "various", "computer", "vision", "tasks", "by", "applying", "deep", "learning", "techniques", ",", "including", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "significant improvements", "start": 0, "end": 24, "i_start": 0, "i_end": 1}, "verb": {"text": "have been obtained", "start": 25, "end": 43, "i_start": 2, "i_end": 4}}], "id": 3228}, {"sent": "transfer learning is an established technique in deep learning research .", "tokens": ["transfer", "learning", "is", "an", "established", "technique", "in", "deep", "learning", "research", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "transfer learning", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}], "id": 3229}, {"sent": "deep learning models have achieved remarkable success in computer vision .", "tokens": ["deep", "learning", "models", "have", "achieved", "remarkable", "success", "in", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning models", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "models", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "models", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "models", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 46, "end": 53, "i_start": 6, "i_end": 6}}], "id": 3230}, {"sent": "it is shown in that , by appropriately choosing a memory factor , the convergence of updating t is guaranteed at the expense of slowing down the convergence speed of algorithm i .", "tokens": ["it", "is", "shown", "in", "that", ",", "by", "appropriately", "choosing", "a", "memory", "factor", ",", "the", "convergence", "of", "updating", "t", "is", "guaranteed", "at", "the", "expense", "of", "slowing", "down", "the", "convergence", "speed", "of", "algorithm", "i", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is shown", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"subject": {"text": "the convergence of updating t", "start": 66, "end": 95, "i_start": 13, "i_end": 17}, "verb": {"text": "guaranteed", "start": 99, "end": 109, "i_start": 19, "i_end": 19}}], "id": 3231}, {"sent": "an isomorphism is a bijective morphism of laminations whose inverse is also a morphism of laminations 6 an embedding into itself .", "tokens": ["an", "isomorphism", "is", "a", "bijective", "morphism", "of", "laminations", "whose", "inverse", "is", "also", "a", "morphism", "of", "laminations", "6", "an", "embedding", "into", "itself", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an isomorphism", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 3232}, {"sent": "to tackle it , multi-column convolutional neural networks were recently adopted and have shown robust performance .", "tokens": ["to", "tackle", "it", ",", "multi", "-", "column", "convolutional", "neural", "networks", "were", "recently", "adopted", "and", "have", "shown", "robust", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "multi-column convolutional neural networks", "start": 15, "end": 57, "i_start": 4, "i_end": 9}, "verb": {"text": "adopted", "start": 72, "end": 79, "i_start": 12, "i_end": 12}}, {"subject": {"text": "multi-column convolutional neural networks", "start": 15, "end": 57, "i_start": 4, "i_end": 9}, "verb": {"text": "were", "start": 58, "end": 62, "i_start": 10, "i_end": 10}}, {"subject": {"text": "multi-column convolutional neural networks", "start": 15, "end": 57, "i_start": 4, "i_end": 9}, "verb": {"text": "shown", "start": 89, "end": 94, "i_start": 15, "i_end": 15}}, {"character": {"text": "networks", "start": 49, "end": 57, "i_start": 9, "i_end": 9}, "action": {"text": "shown", "start": 89, "end": 94, "i_start": 15, "i_end": 15}}, {"character": {"text": "networks", "start": 49, "end": 57, "i_start": 9, "i_end": 9}, "action": {"text": "performance", "start": 102, "end": 113, "i_start": 17, "i_end": 17}}, {"character": {"text": "networks", "start": 49, "end": 57, "i_start": 9, "i_end": 9}, "action": {"text": "tackle", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 3233}, {"sent": "a subsequent line of work that includes the works of koetter et al showed that random linear coding reaches maximum throughput for multicast networks .", "tokens": ["a", "subsequent", "line", "of", "work", "that", "includes", "the", "works", "of", "koetter", "et", "al", "showed", "that", "random", "linear", "coding", "reaches", "maximum", "throughput", "for", "multicast", "networks", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "a subsequent line of work that includes the works of koetter et al", "start": 0, "end": 66, "i_start": 0, "i_end": 12}, "verb": {"text": "showed", "start": 67, "end": 73, "i_start": 13, "i_end": 13}}, {"subject": {"text": "random linear coding", "start": 79, "end": 99, "i_start": 15, "i_end": 17}, "verb": {"text": "reaches", "start": 100, "end": 107, "i_start": 18, "i_end": 18}}, {"character": {"text": "line", "start": 13, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "showed", "start": 67, "end": 73, "i_start": 13, "i_end": 13}}, {"character": {"text": "koetter", "start": 53, "end": 60, "i_start": 10, "i_end": 10}, "action": {"text": "works", "start": 44, "end": 49, "i_start": 8, "i_end": 8}}], "id": 3234}, {"sent": "the use of millimeter-wave frequencies for cellular communications is one of the key technologies for greatly improving the capacity of future wireless networks .", "tokens": ["the", "use", "of", "millimeter", "-", "wave", "frequencies", "for", "cellular", "communications", "is", "one", "of", "the", "key", "technologies", "for", "greatly", "improving", "the", "capacity", "of", "future", "wireless", "networks", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the use of millimeter-wave frequencies for cellular communications", "start": 0, "end": 66, "i_start": 0, "i_end": 9}, "verb": {"text": "is", "start": 67, "end": 69, "i_start": 10, "i_end": 10}}], "id": 3235}, {"sent": "equations are called non-orientable of genus n .", "tokens": ["equations", "are", "called", "non", "-", "orientable", "of", "genus", "n", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "equations", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "are called", "start": 10, "end": 20, "i_start": 1, "i_end": 2}}], "id": 3236}, {"sent": "the mlp layer also utilizes batch normalization .", "tokens": ["the", "mlp", "layer", "also", "utilizes", "batch", "normalization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the mlp layer", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "utilizes", "start": 19, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "layer", "start": 8, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "utilizes", "start": 19, "end": 27, "i_start": 4, "i_end": 4}}], "id": 3237}, {"sent": "deep reinforcement learning has recently achieved great successes in solving computer games .", "tokens": ["deep", "reinforcement", "learning", "has", "recently", "achieved", "great", "successes", "in", "solving", "computer", "games", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep reinforcement learning", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 41, "end": 49, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep reinforcement learning", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "has", "start": 28, "end": 31, "i_start": 3, "i_end": 3}}, {"character": {"text": "learning", "start": 19, "end": 27, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 41, "end": 49, "i_start": 5, "i_end": 5}}, {"character": {"text": "learning", "start": 19, "end": 27, "i_start": 2, "i_end": 2}, "action": {"text": "successes", "start": 56, "end": 65, "i_start": 7, "i_end": 7}}, {"character": {"text": "learning", "start": 19, "end": 27, "i_start": 2, "i_end": 2}, "action": {"text": "solving", "start": 69, "end": 76, "i_start": 9, "i_end": 9}}], "id": 3238}, {"sent": "recent studies also suggest that even in a long term experimental set up only a few real falls may be captured .", "tokens": ["recent", "studies", "also", "suggest", "that", "even", "in", "a", "long", "term", "experimental", "set", "up", "only", "a", "few", "real", "falls", "may", "be", "captured", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent studies", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "suggest", "start": 20, "end": 27, "i_start": 3, "i_end": 3}}, {"subject": {"text": "experimental", "start": 53, "end": 65, "i_start": 10, "i_end": 10}, "verb": {"text": "set", "start": 66, "end": 69, "i_start": 11, "i_end": 11}}, {"subject": {"text": "only a few real falls", "start": 73, "end": 94, "i_start": 13, "i_end": 17}, "verb": {"text": "captured", "start": 102, "end": 110, "i_start": 20, "i_end": 20}}, {"character": {"text": "studies", "start": 7, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "suggest", "start": 20, "end": 27, "i_start": 3, "i_end": 3}}], "id": 3239}, {"sent": "the role of cutaneous feedback in haptics , compared to kinesthetic feedback , has been recently discussed and exploited , for example , in where the problem of missed kinesthetic feedback in wearable haptics is discussed .", "tokens": ["the", "role", "of", "cutaneous", "feedback", "in", "haptics", ",", "compared", "to", "kinesthetic", "feedback", ",", "has", "been", "recently", "discussed", "and", "exploited", ",", "for", "example", ",", "in", "where", "the", "problem", "of", "missed", "kinesthetic", "feedback", "in", "wearable", "haptics", "is", "discussed", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the role of cutaneous feedback in haptics", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "discussed", "start": 97, "end": 106, "i_start": 16, "i_end": 16}}, {"subject": {"text": "the role of cutaneous feedback in haptics", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "has been", "start": 79, "end": 87, "i_start": 13, "i_end": 14}}, {"subject": {"text": "the role of cutaneous feedback in haptics", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "exploited", "start": 111, "end": 120, "i_start": 18, "i_end": 18}}], "id": 3240}, {"sent": "belle is a general-purpose detector which includes a 1 5 t superconducting solenoid magnet that surrounds the kekb beam crossing point .", "tokens": ["belle", "is", "a", "general", "-", "purpose", "detector", "which", "includes", "a", "1", "5", "t", "superconducting", "solenoid", "magnet", "that", "surrounds", "the", "kekb", "beam", "crossing", "point", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "belle", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "magnet", "start": 84, "end": 90, "i_start": 15, "i_end": 15}, "action": {"text": "surrounds", "start": 96, "end": 105, "i_start": 17, "i_end": 17}}, {"character": {"text": "beam", "start": 115, "end": 119, "i_start": 20, "i_end": 20}, "action": {"text": "crossing", "start": 120, "end": 128, "i_start": 21, "i_end": 21}}], "id": 3241}, {"sent": "the dnn parameters are initialized according to the xavier initialization .", "tokens": ["the", "dnn", "parameters", "are", "initialized", "according", "to", "the", "xavier", "initialization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dnn parameters", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "are initialized", "start": 19, "end": 34, "i_start": 3, "i_end": 4}}], "id": 3242}, {"sent": "the bispectrum is a natural and widely studied tool for measuring the nongaussianity in a model-independent way .", "tokens": ["the", "bispectrum", "is", "a", "natural", "and", "widely", "studied", "tool", "for", "measuring", "the", "nongaussianity", "in", "a", "model", "-", "independent", "way", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the bispectrum", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "model", "start": 90, "end": 95, "i_start": 15, "i_end": 15}, "action": {"text": "-independent", "start": 95, "end": 107, "i_start": 16, "i_end": 17}}], "id": 3243}, {"sent": "we adapt the standard single-user soft input viterbi decoding algorithm for use in ncma .", "tokens": ["we", "adapt", "the", "standard", "single", "-", "user", "soft", "input", "viterbi", "decoding", "algorithm", "for", "use", "in", "ncma", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "adapt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adapt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3244}, {"sent": "exchangecorrelation functionals were used in the perdewburke-ernzerhof form within the generalized gradient approximation .", "tokens": ["exchangecorrelation", "functionals", "were", "used", "in", "the", "perdewburke", "-", "ernzerhof", "form", "within", "the", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "exchangecorrelation functionals", "start": 0, "end": 31, "i_start": 0, "i_end": 1}, "verb": {"text": "were used", "start": 32, "end": 41, "i_start": 2, "i_end": 3}}], "id": 3245}, {"sent": "lcd codes can be used against side-channel attacks and fault noninvasive attacks .", "tokens": ["lcd", "codes", "can", "be", "used", "against", "side", "-", "channel", "attacks", "and", "fault", "noninvasive", "attacks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "lcd codes", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "can be used", "start": 10, "end": 21, "i_start": 2, "i_end": 4}}, {"subject": {"text": "lcd codes", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "fault", "start": 55, "end": 60, "i_start": 11, "i_end": 11}}], "id": 3246}, {"sent": "we adopt the standard data augmentation scheme and preprocessing scheme .", "tokens": ["we", "adopt", "the", "standard", "data", "augmentation", "scheme", "and", "preprocessing", "scheme", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3247}, {"sent": "it is believed that deeper networks may produce better recognition results .", "tokens": ["it", "is", "believed", "that", "deeper", "networks", "may", "produce", "better", "recognition", "results", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is believed", "start": 3, "end": 14, "i_start": 1, "i_end": 2}}, {"subject": {"text": "deeper networks", "start": 20, "end": 35, "i_start": 4, "i_end": 5}, "verb": {"text": "produce", "start": 40, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 27, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "produce", "start": 40, "end": 47, "i_start": 7, "i_end": 7}}], "id": 3248}, {"sent": "deep learning has fueled great strides in a variety of computer vision problems , such as visual tracking .", "tokens": ["deep", "learning", "has", "fueled", "great", "strides", "in", "a", "variety", "of", "computer", "vision", "problems", ",", "such", "as", "visual", "tracking", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has fueled", "start": 14, "end": 24, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "fueled", "start": 18, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3249}, {"sent": "for this experiment , for the base network we choose to use the resnet-18 architecture .", "tokens": ["for", "this", "experiment", ",", "for", "the", "base", "network", "we", "choose", "to", "use", "the", "resnet-18", "architecture", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 43, "end": 45, "i_start": 8, "i_end": 8}, "action": {"text": "choose", "start": 46, "end": 52, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 43, "end": 45, "i_start": 8, "i_end": 8}, "action": {"text": "use", "start": 56, "end": 59, "i_start": 11, "i_end": 11}}], "id": 3250}, {"sent": "this impurity can be modelled at the on-site potential or at the coupling .", "tokens": ["this", "impurity", "can", "be", "modelled", "at", "the", "on", "-", "site", "potential", "or", "at", "the", "coupling", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this impurity", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "can be modelled", "start": 14, "end": 29, "i_start": 2, "i_end": 4}}], "id": 3251}, {"sent": "reed et al in propose a joint representation space to condition generative adversarial networks for synthesizing images from text descriptions .", "tokens": ["reed", "et", "al", "in", "propose", "a", "joint", "representation", "space", "to", "condition", "generative", "adversarial", "networks", "for", "synthesizing", "images", "from", "text", "descriptions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reed et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 14, "end": 21, "i_start": 4, "i_end": 4}}], "id": 3252}, {"sent": "be an infinite pure neutrosophic polynomial interval semiring .", "tokens": ["be", "an", "infinite", "pure", "neutrosophic", "polynomial", "interval", "semiring", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3253}, {"sent": "we refer readers to for details about the properties and significance of these contour properties .", "tokens": ["we", "refer", "readers", "to", "for", "details", "about", "the", "properties", "and", "significance", "of", "these", "contour", "properties", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3254}, {"sent": "previous work employs vhcs to stabilize desired closed orbits for underactuated mechanical systems .", "tokens": ["previous", "work", "employs", "vhcs", "to", "stabilize", "desired", "closed", "orbits", "for", "underactuated", "mechanical", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "previous work", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "employs", "start": 14, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "work", "start": 9, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "employs", "start": 14, "end": 21, "i_start": 2, "i_end": 2}}], "id": 3255}, {"sent": "if gravity is a classical phenomenon , as has been claimed for the de sitter space generated by \u03bb0 , then the proposed mechanism can be regarded to have naturalized the ccp since determination of \u03bb0 , in isolation , 20 from cosmological observations involves no fine-tuning at all .", "tokens": ["if", "gravity", "is", "a", "classical", "phenomenon", ",", "as", "has", "been", "claimed", "for", "the", "de", "sitter", "space", "generated", "by", "\u03bb0", ",", "then", "the", "proposed", "mechanism", "can", "be", "regarded", "to", "have", "naturalized", "the", "ccp", "since", "determination", "of", "\u03bb0", ",", "in", "isolation", ",", "20", "from", "cosmological", "observations", "involves", "no", "fine", "-", "tuning", "at", "all", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "20 from cosmological observations", "start": 216, "end": 249, "i_start": 40, "i_end": 43}, "verb": {"text": "can be regarded", "start": 129, "end": 144, "i_start": 24, "i_end": 26}}, {"subject": {"text": "the proposed mechanism", "start": 106, "end": 128, "i_start": 21, "i_end": 23}, "verb": {"text": "claimed", "start": 51, "end": 58, "i_start": 10, "i_end": 10}}, {"subject": {"text": "the proposed mechanism", "start": 106, "end": 128, "i_start": 21, "i_end": 23}, "verb": {"text": "involves", "start": 250, "end": 258, "i_start": 44, "i_end": 44}}, {"character": {"text": "mechanism", "start": 119, "end": 128, "i_start": 23, "i_end": 23}, "action": {"text": "naturalized", "start": 153, "end": 164, "i_start": 29, "i_end": 29}}], "id": 3256}, {"sent": "to represent bivariate kernels , we use the low rank approximations of , where expansions in chebyshev polynomials are constructed via sums of outer products of univariate chebyshev expansions .", "tokens": ["to", "represent", "bivariate", "kernels", ",", "we", "use", "the", "low", "rank", "approximations", "of", ",", "where", "expansions", "in", "chebyshev", "polynomials", "are", "constructed", "via", "sums", "of", "outer", "products", "of", "univariate", "chebyshev", "expansions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 33, "end": 35, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 36, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 33, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 36, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "expansions", "start": 182, "end": 192, "i_start": 28, "i_end": 28}, "action": {"text": "products", "start": 149, "end": 157, "i_start": 24, "i_end": 24}}], "id": 3257}, {"sent": "in the past few years , deep neural network has made significant progress in image processing area , like image classification .", "tokens": ["in", "the", "past", "few", "years", ",", "deep", "neural", "network", "has", "made", "significant", "progress", "in", "image", "processing", "area", ",", "like", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural network", "start": 24, "end": 43, "i_start": 6, "i_end": 8}, "verb": {"text": "has made", "start": 44, "end": 52, "i_start": 9, "i_end": 10}}], "id": 3258}, {"sent": "we refer to our algorithm as weighted k-means because it is based on k-means clustering .", "tokens": ["we", "refer", "to", "our", "algorithm", "as", "weighted", "k", "-", "means", "because", "it", "is", "based", "on", "k", "-", "means", "clustering", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "based", "start": 60, "end": 65, "i_start": 13, "i_end": 13}, "action": {"text": "because", "start": 46, "end": 53, "i_start": 10, "i_end": 10}}], "id": 3259}, {"sent": "this enhancement is a clear indication of a long-range effect in the theory that may result in color confinement .", "tokens": ["this", "enhancement", "is", "a", "clear", "indication", "of", "a", "long", "-", "range", "effect", "in", "the", "theory", "that", "may", "result", "in", "color", "confinement", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this enhancement", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "enhancement", "start": 5, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "indication", "start": 28, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "theory", "start": 69, "end": 75, "i_start": 14, "i_end": 14}, "action": {"text": "effect", "start": 55, "end": 61, "i_start": 11, "i_end": 11}}], "id": 3260}, {"sent": "a b \u00b5 category is called perfect if all its automorphisms are inner .", "tokens": ["a", "b", "\u00b5", "category", "is", "called", "perfect", "if", "all", "its", "automorphisms", "are", "inner", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a b \u00b5 category", "start": 0, "end": 14, "i_start": 0, "i_end": 3}, "verb": {"text": "is called", "start": 15, "end": 24, "i_start": 4, "i_end": 5}}], "id": 3261}, {"sent": "in that system one finds that the phase diagram depends only on the ratio of \u03c7 to the charge on the polymer , at least in the absence of fluctuations .", "tokens": ["in", "that", "system", "one", "finds", "that", "the", "phase", "diagram", "depends", "only", "on", "the", "ratio", "of", "\u03c7", "to", "the", "charge", "on", "the", "polymer", ",", "at", "least", "in", "the", "absence", "of", "fluctuations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 15, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "finds", "start": 19, "end": 24, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the phase diagram", "start": 30, "end": 47, "i_start": 6, "i_end": 8}, "verb": {"text": "depends", "start": 48, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "one", "start": 15, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "finds", "start": 19, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "diagram", "start": 40, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "depends", "start": 48, "end": 55, "i_start": 9, "i_end": 9}}], "id": 3262}, {"sent": "architectures based on neural networks have become an essential instrument in solving perception tasks and have shown to approach human-level accuracy in classifying images .", "tokens": ["architectures", "based", "on", "neural", "networks", "have", "become", "an", "essential", "instrument", "in", "solving", "perception", "tasks", "and", "have", "shown", "to", "approach", "human", "-", "level", "accuracy", "in", "classifying", "images", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "architectures based on neural networks", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "have become", "start": 39, "end": 50, "i_start": 5, "i_end": 6}}, {"subject": {"text": "architectures based on neural networks", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "shown", "start": 112, "end": 117, "i_start": 16, "i_end": 16}}], "id": 3263}, {"sent": "for the past several years , advances in deep neural networks have shown to be a powerful tool for a variety of machine learning problems in multiple domains , including computer vision .", "tokens": ["for", "the", "past", "several", "years", ",", "advances", "in", "deep", "neural", "networks", "have", "shown", "to", "be", "a", "powerful", "tool", "for", "a", "variety", "of", "machine", "learning", "problems", "in", "multiple", "domains", ",", "including", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "advances in deep neural networks", "start": 29, "end": 61, "i_start": 6, "i_end": 10}, "verb": {"text": "have shown", "start": 62, "end": 72, "i_start": 11, "i_end": 12}}], "id": 3264}, {"sent": "the weights of the convolution kernels were initialized with xavier weightings and 0 biases .", "tokens": ["the", "weights", "of", "the", "convolution", "kernels", "were", "initialized", "with", "xavier", "weightings", "and", "0", "biases", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the weights of the convolution kernels", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "were initialized", "start": 39, "end": 55, "i_start": 6, "i_end": 7}}], "id": 3265}, {"sent": "the averaged atomic displacement amplitude for phonons , u , can be calculated as function of t .", "tokens": ["the", "averaged", "atomic", "displacement", "amplitude", "for", "phonons", ",", "u", ",", "can", "be", "calculated", "as", "function", "of", "t", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the averaged atomic displacement amplitude for phonons", "start": 0, "end": 54, "i_start": 0, "i_end": 6}, "verb": {"text": "can be calculated", "start": 61, "end": 78, "i_start": 10, "i_end": 12}}], "id": 3266}, {"sent": "the computational power of symmetric hamiltonians .", "tokens": ["the", "computational", "power", "of", "symmetric", "hamiltonians", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3267}, {"sent": "low-density parity-check codes are a class of linear block codes represented by sparse parity-check matrices .", "tokens": ["low", "-", "density", "parity", "-", "check", "codes", "are", "a", "class", "of", "linear", "block", "codes", "represented", "by", "sparse", "parity", "-", "check", "matrices", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "low-density parity-check codes", "start": 0, "end": 30, "i_start": 0, "i_end": 6}, "verb": {"text": "are", "start": 31, "end": 34, "i_start": 7, "i_end": 7}}, {"character": {"text": "matrices", "start": 100, "end": 108, "i_start": 20, "i_end": 20}, "action": {"text": "represented", "start": 65, "end": 76, "i_start": 14, "i_end": 14}}, {"character": {"text": "codes", "start": 59, "end": 64, "i_start": 13, "i_end": 13}, "action": {"text": "check", "start": 19, "end": 24, "i_start": 5, "i_end": 5}}], "id": 3268}, {"sent": "among them , convolutional neural networks have been demonstrated to be extremely successful in computer vision .", "tokens": ["among", "them", ",", "convolutional", "neural", "networks", "have", "been", "demonstrated", "to", "be", "extremely", "successful", "in", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 13, "end": 42, "i_start": 3, "i_end": 5}, "verb": {"text": "have been demonstrated", "start": 43, "end": 65, "i_start": 6, "i_end": 8}}, {"character": {"text": "networks", "start": 34, "end": 42, "i_start": 5, "i_end": 5}, "action": {"text": "successful", "start": 82, "end": 92, "i_start": 12, "i_end": 12}}], "id": 3269}, {"sent": "we have 8 such coefficients which is the number of coefficients needed to describe a three-qubit state .", "tokens": ["we", "have", "8", "such", "coefficients", "which", "is", "the", "number", "of", "coefficients", "needed", "to", "describe", "a", "three", "-", "qubit", "state", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "have", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3270}, {"sent": "in recent years , convolutional neural networks have achieved significant success in many computer vision tasks , including the super-resolution problem .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "achieved", "significant", "success", "in", "many", "computer", "vision", "tasks", ",", "including", "the", "super", "-", "resolution", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 48, "end": 61, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 53, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 74, "end": 81, "i_start": 10, "i_end": 10}}], "id": 3271}, {"sent": "for style transfer tasks , affine parameters are spatially-invariant since they only control the global style of the output images .", "tokens": ["for", "style", "transfer", "tasks", ",", "affine", "parameters", "are", "spatially", "-", "invariant", "since", "they", "only", "control", "the", "global", "style", "of", "the", "output", "images", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "affine parameters", "start": 27, "end": 44, "i_start": 5, "i_end": 6}, "verb": {"text": "are", "start": 45, "end": 48, "i_start": 7, "i_end": 7}}, {"character": {"text": "parameters", "start": 34, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "control", "start": 85, "end": 92, "i_start": 14, "i_end": 14}}], "id": 3272}, {"sent": "the bypass connection structure has proven powerful in various computer vision tasks .", "tokens": ["the", "bypass", "connection", "structure", "has", "proven", "powerful", "in", "various", "computer", "vision", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the bypass connection structure", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "has proven", "start": 32, "end": 42, "i_start": 4, "i_end": 5}}], "id": 3273}, {"sent": "we will comment briefly on the extension of the analysis to higher dimensions for the black hole case .", "tokens": ["we", "will", "comment", "briefly", "on", "the", "extension", "of", "the", "analysis", "to", "higher", "dimensions", "for", "the", "black", "hole", "case", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will comment", "start": 3, "end": 15, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "comment", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}], "id": 3274}, {"sent": "very recently , deep convolutional neural networks have demonstrated promising results for single-label image classification .", "tokens": ["very", "recently", ",", "deep", "convolutional", "neural", "networks", "have", "demonstrated", "promising", "results", "for", "single", "-", "label", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 16, "end": 50, "i_start": 3, "i_end": 6}, "verb": {"text": "have demonstrated", "start": 51, "end": 68, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 42, "end": 50, "i_start": 6, "i_end": 6}, "action": {"text": "demonstrated", "start": 56, "end": 68, "i_start": 8, "i_end": 8}}, {"character": {"text": "results", "start": 79, "end": 86, "i_start": 10, "i_end": 10}, "action": {"text": "promising", "start": 69, "end": 78, "i_start": 9, "i_end": 9}}], "id": 3275}, {"sent": "the data underwent a standard data reduction with the miriad software package .", "tokens": ["the", "data", "underwent", "a", "standard", "data", "reduction", "with", "the", "miriad", "software", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "underwent", "start": 9, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "package", "start": 70, "end": 77, "i_start": 11, "i_end": 11}, "action": {"text": "reduction", "start": 35, "end": 44, "i_start": 6, "i_end": 6}}], "id": 3276}, {"sent": "convolutional neural networks have demonstrated impressive performance on computer vision tasks .", "tokens": ["convolutional", "neural", "networks", "have", "demonstrated", "impressive", "performance", "on", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 30, "end": 47, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 35, "end": 47, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 59, "end": 70, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 59, "end": 70, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 48, "end": 58, "i_start": 5, "i_end": 5}}], "id": 3277}, {"sent": "adiabatic invariance and the nonlinear landau-zener problem .", "tokens": ["adiabatic", "invariance", "and", "the", "nonlinear", "landau", "-", "zener", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3278}, {"sent": "non-orthogonal multiple access has been recognized as a promising multiple access technique for the fifth generation mobile networks , due to its superior spectral efficiency .", "tokens": ["non", "-", "orthogonal", "multiple", "access", "has", "been", "recognized", "as", "a", "promising", "multiple", "access", "technique", "for", "the", "fifth", "generation", "mobile", "networks", ",", "due", "to", "its", "superior", "spectral", "efficiency", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "non-orthogonal multiple access", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "has been recognized", "start": 31, "end": 50, "i_start": 5, "i_end": 7}}, {"character": {"text": "technique", "start": 82, "end": 91, "i_start": 13, "i_end": 13}, "action": {"text": "promising", "start": 56, "end": 65, "i_start": 10, "i_end": 10}}], "id": 3279}, {"sent": "a grope of height 1 is a capped surface , as described above .", "tokens": ["a", "grope", "of", "height", "1", "is", "a", "capped", "surface", ",", "as", "described", "above", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a grope of height 1", "start": 0, "end": 19, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 5, "i_end": 5}}], "id": 3280}, {"sent": "physically , string theory is a two-dimensional conformal field theory on a riemannian surface .", "tokens": ["physically", ",", "string", "theory", "is", "a", "two", "-", "dimensional", "conformal", "field", "theory", "on", "a", "riemannian", "surface", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "string theory", "start": 13, "end": 26, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 4, "i_end": 4}}], "id": 3281}, {"sent": "as performance benchmarks for algorithm 4 , we have included the performance of the algorithm in that maximizes the minimum value of h h nkw k w hk h n k instead .", "tokens": ["as", "performance", "benchmarks", "for", "algorithm", "4", ",", "we", "have", "included", "the", "performance", "of", "the", "algorithm", "in", "that", "maximizes", "the", "minimum", "value", "of", "h", "h", "n"], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 44, "end": 46, "i_start": 7, "i_end": 7}, "verb": {"text": "have included", "start": 47, "end": 60, "i_start": 8, "i_end": 9}}, {"subject": {"text": "we", "start": 44, "end": 46, "i_start": 7, "i_end": 7}, "verb": {"text": "maximizes", "start": 102, "end": 111, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 44, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "included", "start": 52, "end": 60, "i_start": 9, "i_end": 9}}, {"character": {"text": "algorithm 4", "start": 30, "end": 41, "i_start": 4, "i_end": 5}, "action": {"text": "performance", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}], "id": 3282}, {"sent": "then the rees algebra of the module m is defined to be the image of the natural homomorphism from sym a to sym a , which is a subalgebra of the polynomial ring over a .", "tokens": ["then", "the", "rees", "algebra", "of", "the", "module", "m", "is", "defined", "to", "be", "the", "image", "of", "the", "natural", "homomorphism", "from", "sym", "a", "to", "sym", "a", ",", "which", "is", "a", "subalgebra", "of", "the", "polynomial", "ring", "over", "a", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the rees algebra of the module m", "start": 5, "end": 37, "i_start": 1, "i_end": 7}, "verb": {"text": "is defined", "start": 38, "end": 48, "i_start": 8, "i_end": 9}}], "id": 3283}, {"sent": "in recent years , deep learning has become a popular approach , revolutionising various fields , including computer vision .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "has", "become", "a", "popular", "approach", ",", "revolutionising", "various", "fields", ",", "including", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 18, "end": 31, "i_start": 4, "i_end": 5}, "verb": {"text": "has become", "start": 32, "end": 42, "i_start": 6, "i_end": 7}}, {"character": {"text": "become", "start": 36, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "revolutionising", "start": 64, "end": 79, "i_start": 12, "i_end": 12}}], "id": 3284}, {"sent": "deep neural networks have achieved state-of-the-art performance on a wide variety of machine learning tasks .", "tokens": ["deep", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "a", "wide", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 52, "end": 63, "i_start": 12, "i_end": 12}}], "id": 3285}, {"sent": "to overcome this problem , some techniques infer 3d scene structure and use geometric transformations to achieve view invariance .", "tokens": ["to", "overcome", "this", "problem", ",", "some", "techniques", "infer", "3d", "scene", "structure", "and", "use", "geometric", "transformations", "to", "achieve", "view", "invariance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "some techniques", "start": 27, "end": 42, "i_start": 5, "i_end": 6}, "verb": {"text": "infer", "start": 43, "end": 48, "i_start": 7, "i_end": 7}}, {"subject": {"text": "some techniques", "start": 27, "end": 42, "i_start": 5, "i_end": 6}, "verb": {"text": "use", "start": 72, "end": 75, "i_start": 12, "i_end": 12}}, {"character": {"text": "techniques", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "infer", "start": 43, "end": 48, "i_start": 7, "i_end": 7}}, {"character": {"text": "techniques", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "use", "start": 72, "end": 75, "i_start": 12, "i_end": 12}}, {"character": {"text": "techniques", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "achieve", "start": 105, "end": 112, "i_start": 16, "i_end": 16}}], "id": 3286}, {"sent": "for unexplained terminology on vector and banach lattices we refer the reader to .", "tokens": ["for", "unexplained", "terminology", "on", "vector", "and", "banach", "lattices", "we", "refer", "the", "reader", "to", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 58, "end": 60, "i_start": 8, "i_end": 8}, "verb": {"text": "refer", "start": 61, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 58, "end": 60, "i_start": 8, "i_end": 8}, "action": {"text": "refer", "start": 61, "end": 66, "i_start": 9, "i_end": 9}}], "id": 3287}, {"sent": "this example is closely related to a quantum spectral problem in the topological string theory .", "tokens": ["this", "example", "is", "closely", "related", "to", "a", "quantum", "spectral", "problem", "in", "the", "topological", "string", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this example", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "related", "start": 24, "end": 31, "i_start": 4, "i_end": 4}}, {"subject": {"text": "this example", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 3288}, {"sent": "the first part of our paper is devoted to the study of induced generalized complex structures on subspaces of generalized complex vector spaces .", "tokens": ["the", "first", "part", "of", "our", "paper", "is", "devoted", "to", "the", "study", "of", "induced", "generalized", "complex", "structures", "on", "subspaces", "of", "generalized", "complex", "vector", "spaces", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the first part of our paper", "start": 0, "end": 27, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 6, "i_end": 6}}], "id": 3289}, {"sent": "convolutional neural networks have achieved state-of-the-art accuracy in computer vision tasks such as image recognition .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "accuracy", "in", "computer", "vision", "tasks", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 3290}, {"sent": "with the rise of exploring quantum computers , this kind of theoretical models was firstly studied by moore and crutchfield , .", "tokens": ["with", "the", "rise", "of", "exploring", "quantum", "computers", ",", "this", "kind", "of", "theoretical", "models", "was", "firstly", "studied", "by", "moore", "and", "crutchfield", ",", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this kind of theoretical models", "start": 47, "end": 78, "i_start": 8, "i_end": 12}, "verb": {"text": "studied", "start": 91, "end": 98, "i_start": 15, "i_end": 15}}, {"subject": {"text": "this kind of theoretical models", "start": 47, "end": 78, "i_start": 8, "i_end": 12}, "verb": {"text": "was", "start": 79, "end": 82, "i_start": 13, "i_end": 13}}, {"character": {"text": "moore", "start": 102, "end": 107, "i_start": 17, "i_end": 17}, "action": {"text": "studied", "start": 91, "end": 98, "i_start": 15, "i_end": 15}}, {"character": {"text": "crutchfield", "start": 112, "end": 123, "i_start": 19, "i_end": 19}, "action": {"text": "studied", "start": 91, "end": 98, "i_start": 15, "i_end": 15}}], "id": 3291}, {"sent": "renz , valuations on free resolutions and higher geometric invariants of groups , comment .", "tokens": ["renz", ",", "valuations", "on", "free", "resolutions", "and", "higher", "geometric", "invariants", "of", "groups", ",", "comment", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "renz", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "comment", "start": 82, "end": 89, "i_start": 13, "i_end": 13}}, {"character": {"text": "valuations", "start": 7, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "comment", "start": 82, "end": 89, "i_start": 13, "i_end": 13}}, {"character": {"text": "invariants", "start": 59, "end": 69, "i_start": 9, "i_end": 9}, "action": {"text": "comment", "start": 82, "end": 89, "i_start": 13, "i_end": 13}}, {"character": {"text": "geometric", "start": 49, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "comment", "start": 82, "end": 89, "i_start": 13, "i_end": 13}}, {"character": {"text": "geometric", "start": 49, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "comment", "start": 82, "end": 89, "i_start": 13, "i_end": 13}}, {"character": {"text": "geometric", "start": 49, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "comment", "start": 82, "end": 89, "i_start": 13, "i_end": 13}}, {"character": {"text": "geometric", "start": 49, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "comment", "start": 82, "end": 89, "i_start": 13, "i_end": 13}}, {"character": {"text": "groups", "start": 73, "end": 79, "i_start": 11, "i_end": 11}, "action": {"text": "comment", "start": 82, "end": 89, "i_start": 13, "i_end": 13}}, {"character": {"text": "groups", "start": 73, "end": 79, "i_start": 11, "i_end": 11}, "action": {"text": "comment", "start": 82, "end": 89, "i_start": 13, "i_end": 13}}, {"character": {"text": "groups", "start": 73, "end": 79, "i_start": 11, "i_end": 11}, "action": {"text": "comment", "start": 82, "end": 89, "i_start": 13, "i_end": 13}}, {"character": {"text": "groups", "start": 73, "end": 79, "i_start": 11, "i_end": 11}, "action": {"text": "comment", "start": 82, "end": 89, "i_start": 13, "i_end": 13}}], "id": 3292}, {"sent": "we see that this limit coincides exactly with the bfkl limit in eq .", "tokens": ["we", "see", "that", "this", "limit", "coincides", "exactly", "with", "the", "bfkl", "limit", "in", "eq", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "see", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "this limit", "start": 12, "end": 22, "i_start": 3, "i_end": 4}, "verb": {"text": "coincides", "start": 23, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "see", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 3293}, {"sent": "the parameters of our model can be estimated with an em algorithm .", "tokens": ["the", "parameters", "of", "our", "model", "can", "be", "estimated", "with", "an", "em", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the parameters of our model", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "can be estimated", "start": 28, "end": 44, "i_start": 5, "i_end": 7}}], "id": 3294}, {"sent": "for example , distmult simplifies rescal by restricting the matrices representing relations to diagonal matrices .", "tokens": ["for", "example", ",", "distmult", "simplifies", "rescal", "by", "restricting", "the", "matrices", "representing", "relations", "to", "diagonal", "matrices", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "distmult", "start": 14, "end": 22, "i_start": 3, "i_end": 3}, "verb": {"text": "simplifies", "start": 23, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "distmult", "start": 14, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "simplifies", "start": 23, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "distmult", "start": 14, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "restricting", "start": 44, "end": 55, "i_start": 7, "i_end": 7}}, {"character": {"text": "matrices", "start": 60, "end": 68, "i_start": 9, "i_end": 9}, "action": {"text": "representing", "start": 69, "end": 81, "i_start": 10, "i_end": 10}}], "id": 3295}, {"sent": "singular hypersurfaces and thin shells in general relativity .", "tokens": ["singular", "hypersurfaces", "and", "thin", "shells", "in", "general", "relativity", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3296}, {"sent": "deep neural networks , particularly convolutional neural networks have become exceptionally successful in a wide variety of visual object recognition and classification tasks .", "tokens": ["deep", "neural", "networks", ",", "particularly", "convolutional", "neural", "networks", "have", "become", "exceptionally", "successful", "in", "a", "wide", "variety", "of", "visual", "object", "recognition", "and", "classification", "tasks", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have become", "start": 66, "end": 77, "i_start": 8, "i_end": 9}}], "id": 3297}, {"sent": "the dynamics theorem for properly embedded minimal surfaces .", "tokens": ["the", "dynamics", "theorem", "for", "properly", "embedded", "minimal", "surfaces", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3298}, {"sent": "the 4he nucleus is a good test case , because an exact four-body calculation can be carried out .", "tokens": ["the", "4he", "nucleus", "is", "a", "good", "test", "case", ",", "because", "an", "exact", "four", "-", "body", "calculation", "can", "be", "carried", "out", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the 4he nucleus", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 3299}, {"sent": "the curves are normalized to the peak value .", "tokens": ["the", "curves", "are", "normalized", "to", "the", "peak", "value", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the curves", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "are normalized", "start": 11, "end": 25, "i_start": 2, "i_end": 3}}], "id": 3300}, {"sent": "a get doc transition results in the gworkingdoc client side variable attaining the value of the gdocument server side variable .", "tokens": ["a", "get", "doc", "transition", "results", "in", "the", "gworkingdoc", "client", "side", "variable", "attaining", "the", "value", "of", "the", "gdocument", "server", "side", "variable", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "variable", "start": 60, "end": 68, "i_start": 10, "i_end": 10}, "action": {"text": "attaining", "start": 69, "end": 78, "i_start": 11, "i_end": 11}}], "id": 3301}, {"sent": "in recent years , deep neural networks have achieved great success in a variety of machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "achieved", "great", "success", "in", "a", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}], "id": 3302}, {"sent": "a density functional theory for the ni transition in a 2d system of rods has been developed .", "tokens": ["a", "density", "functional", "theory", "for", "the", "ni", "transition", "in", "a", "2d", "system", "of", "rods", "has", "been", "developed", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a density functional theory for the ni transition in a 2d system of rods", "start": 0, "end": 72, "i_start": 0, "i_end": 13}, "verb": {"text": "has been developed", "start": 73, "end": 91, "i_start": 14, "i_end": 16}}], "id": 3303}, {"sent": "with the obtained pdf , by modeling the locations of users as a homogeneous poisson point process , the probability distribution of the number of users in each voronoi cell was derived .", "tokens": ["with", "the", "obtained", "pdf", ",", "by", "modeling", "the", "locations", "of", "users", "as", "a", "homogeneous", "poisson", "point", "process", ",", "the", "probability", "distribution", "of", "the", "number", "of", "users", "in", "each", "voronoi", "cell", "was", "derived", "."], "score": [1, 1, 1, 1, 0], "labels": [{"subject": {"text": "the probability distribution of the number of users in each voronoi cell", "start": 100, "end": 172, "i_start": 18, "i_end": 29}, "verb": {"text": "was derived", "start": 173, "end": 184, "i_start": 30, "i_end": 31}}], "id": 3304}, {"sent": "in particular , one could establish b-strong desingularization of generically reduced b-schemes .", "tokens": ["in", "particular", ",", "one", "could", "establish", "b", "-", "strong", "desingularization", "of", "generically", "reduced", "b", "-", "schemes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 16, "end": 19, "i_start": 3, "i_end": 3}, "verb": {"text": "could establish", "start": 20, "end": 35, "i_start": 4, "i_end": 5}}, {"character": {"text": "one", "start": 16, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "establish", "start": 26, "end": 35, "i_start": 5, "i_end": 5}}], "id": 3305}, {"sent": "considering the delays of the emission lines with respect to the continuum variations we verified an ionization stratification in the blr .", "tokens": ["considering", "the", "delays", "of", "the", "emission", "lines", "with", "respect", "to", "the", "continuum", "variations", "we", "verified", "an", "ionization", "stratification", "in", "the", "blr", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 86, "end": 88, "i_start": 13, "i_end": 13}, "action": {"text": "verified", "start": 89, "end": 97, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 86, "end": 88, "i_start": 13, "i_end": 13}, "action": {"text": "considering", "start": 0, "end": 11, "i_start": 0, "i_end": 0}}], "id": 3306}, {"sent": "more generally , it has been realized that noncommutative gauge theory arises as the worldvolume theory on d-branes in the presence of a constant background b field in string theory .", "tokens": ["more", "generally", ",", "it", "has", "been", "realized", "that", "noncommutative", "gauge", "theory", "arises", "as", "the", "worldvolume", "theory", "on", "d", "-", "branes", "in", "the", "presence", "of", "a", "constant", "background", "b", "field", "in", "string", "theory", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 17, "end": 19, "i_start": 3, "i_end": 3}, "verb": {"text": "has been realized", "start": 20, "end": 37, "i_start": 4, "i_end": 6}}, {"subject": {"text": "noncommutative gauge theory", "start": 43, "end": 70, "i_start": 8, "i_end": 10}, "verb": {"text": "arises", "start": 71, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "presence", "start": 123, "end": 131, "i_start": 22, "i_end": 22}, "action": {"text": "arises", "start": 71, "end": 77, "i_start": 11, "i_end": 11}}], "id": 3307}, {"sent": "the network was trained using the adam optimizer for 100 epochs at each iteration .", "tokens": ["the", "network", "was", "trained", "using", "the", "adam", "optimizer", "for", "100", "epochs", "at", "each", "iteration", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the network", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "was trained", "start": 12, "end": 23, "i_start": 2, "i_end": 3}}], "id": 3308}, {"sent": "recently , methods based on convolutional neural networks have achieved significant progress in semantic segmentation .", "tokens": ["recently", ",", "methods", "based", "on", "convolutional", "neural", "networks", "have", "achieved", "significant", "progress", "in", "semantic", "segmentation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "methods based on convolutional neural networks", "start": 11, "end": 57, "i_start": 2, "i_end": 7}, "verb": {"text": "have achieved", "start": 58, "end": 71, "i_start": 8, "i_end": 9}}, {"character": {"text": "methods", "start": 11, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 63, "end": 71, "i_start": 9, "i_end": 9}}], "id": 3309}, {"sent": "in fact , it is known that the jm functional gives rise to the right universal terms when used to compute holographic entanglement entropy 7 for these theories .", "tokens": ["in", "fact", ",", "it", "is", "known", "that", "the", "jm", "functional", "gives", "rise", "to", "the", "right", "universal", "terms", "when", "used", "to", "compute", "holographic", "entanglement", "entropy", "7", "for", "these", "theories", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 10, "end": 12, "i_start": 3, "i_end": 3}, "verb": {"text": "is known", "start": 13, "end": 21, "i_start": 4, "i_end": 5}}, {"subject": {"text": "the jm functional", "start": 27, "end": 44, "i_start": 7, "i_end": 9}, "verb": {"text": "gives", "start": 45, "end": 50, "i_start": 10, "i_end": 10}}, {"character": {"text": "functional", "start": 34, "end": 44, "i_start": 9, "i_end": 9}, "action": {"text": "rise", "start": 51, "end": 55, "i_start": 11, "i_end": 11}}, {"character": {"text": "functional", "start": 34, "end": 44, "i_start": 9, "i_end": 9}, "action": {"text": "compute", "start": 98, "end": 105, "i_start": 20, "i_end": 20}}], "id": 3310}, {"sent": "the simplest wilson loop on the lattice is called the plaquette .", "tokens": ["the", "simplest", "wilson", "loop", "on", "the", "lattice", "is", "called", "the", "plaquette", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the simplest wilson loop on the lattice", "start": 0, "end": 39, "i_start": 0, "i_end": 6}, "verb": {"text": "is called", "start": 40, "end": 49, "i_start": 7, "i_end": 8}}], "id": 3311}, {"sent": "in 2005 lim independently initiated the spectral theory of high order tensors .", "tokens": ["in", "2005", "lim", "independently", "initiated", "the", "spectral", "theory", "of", "high", "order", "tensors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "lim", "start": 8, "end": 11, "i_start": 2, "i_end": 2}, "verb": {"text": "initiated", "start": 26, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "lim", "start": 8, "end": 11, "i_start": 2, "i_end": 2}, "action": {"text": "initiated", "start": 26, "end": 35, "i_start": 4, "i_end": 4}}], "id": 3312}, {"sent": "the asterisks denote the nearby single-\u03b2 clusters .", "tokens": ["the", "asterisks", "denote", "the", "nearby", "single", "-", "\u03b2", "clusters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the asterisks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "denote", "start": 14, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "asterisks", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 14, "end": 20, "i_start": 2, "i_end": 2}}], "id": 3313}, {"sent": "it is known that some properties of high t c superconductors can be captured by the black hole physics in ads .", "tokens": ["it", "is", "known", "that", "some", "properties", "of", "high", "t", "c", "superconductors", "can", "be", "captured", "by", "the", "black", "hole", "physics", "in", "ads", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is known", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"subject": {"text": "some properties of high t c superconductors", "start": 17, "end": 60, "i_start": 4, "i_end": 10}, "verb": {"text": "captured", "start": 68, "end": 76, "i_start": 13, "i_end": 13}}, {"character": {"text": "physics", "start": 95, "end": 102, "i_start": 18, "i_end": 18}, "action": {"text": "captured", "start": 68, "end": 76, "i_start": 13, "i_end": 13}}], "id": 3314}, {"sent": "each convolutional block is a sequence of two convolutional layers , each one followed by a temporal batchnorm layer and an relu activation .", "tokens": ["each", "convolutional", "block", "is", "a", "sequence", "of", "two", "convolutional", "layers", ",", "each", "one", "followed", "by", "a", "temporal", "batchnorm", "layer", "and", "an", "relu", "activation", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "each convolutional block is a sequence of two convolutional layers , each one followed by a temporal batchnorm layer and an relu activation", "start": 0, "end": 139, "i_start": 0, "i_end": 22}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 3, "i_end": 3}}], "id": 3315}, {"sent": "then , the operation schedules of thermal plants were calculated to integrate pv output using our unit commitment model with the estimated forecast errors .", "tokens": ["then", ",", "the", "operation", "schedules", "of", "thermal", "plants", "were", "calculated", "to", "integrate", "pv", "output", "using", "our", "unit", "commitment", "model", "with", "the", "estimated", "forecast", "errors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the operation schedules of thermal plants", "start": 7, "end": 48, "i_start": 2, "i_end": 7}, "verb": {"text": "were calculated", "start": 49, "end": 64, "i_start": 8, "i_end": 9}}], "id": 3316}, {"sent": "in table 4 , we present the best results of meta-denoising and the other two learning algorithms , next to bm3d .", "tokens": ["in", "table", "4", ",", "we", "present", "the", "best", "results", "of", "meta", "-", "denoising", "and", "the", "other", "two", "learning", "algorithms", ",", "next", "to", "bm3d", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 13, "end": 15, "i_start": 4, "i_end": 4}, "verb": {"text": "present", "start": 16, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 4, "i_end": 4}, "action": {"text": "present", "start": 16, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "two learning algorithms", "start": 73, "end": 96, "i_start": 16, "i_end": 18}, "action": {"text": "learning", "start": 77, "end": 85, "i_start": 17, "i_end": 17}}], "id": 3317}, {"sent": "the first tensegrity structures appeared in art , with the sculptures of kenneth snelson 4 , 5 .", "tokens": ["the", "first", "tensegrity", "structures", "appeared", "in", "art", ",", "with", "the", "sculptures", "of", "kenneth", "snelson", "4", ",", "5", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the first tensegrity structures", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "appeared", "start": 32, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "kenneth snelson", "start": 73, "end": 88, "i_start": 12, "i_end": 13}, "action": {"text": "sculptures", "start": 59, "end": 69, "i_start": 10, "i_end": 10}}], "id": 3318}, {"sent": "in some other cases , a linear-regression straight line was fit by the least squares method , a procedure which can lead to substantial biases and wrong inferences .", "tokens": ["in", "some", "other", "cases", ",", "a", "linear", "-", "regression", "straight", "line", "was", "fit", "by", "the", "least", "squares", "method", ",", "a", "procedure", "which", "can", "lead", "to", "substantial", "biases", "and", "wrong", "inferences", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a linear-regression straight line", "start": 22, "end": 55, "i_start": 5, "i_end": 10}, "verb": {"text": "was", "start": 56, "end": 59, "i_start": 11, "i_end": 11}}, {"character": {"text": "method", "start": 85, "end": 91, "i_start": 17, "i_end": 17}, "action": {"text": "lead", "start": 116, "end": 120, "i_start": 23, "i_end": 23}}], "id": 3319}, {"sent": "the applications of such systems range from building long-ranged quantum networks .", "tokens": ["the", "applications", "of", "such", "systems", "range", "from", "building", "long", "-", "ranged", "quantum", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the applications of such systems", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "range", "start": 33, "end": 38, "i_start": 5, "i_end": 5}}], "id": 3320}, {"sent": "rifford , rj stern , feedback stabilization and lyapunov functions , siam j .", "tokens": ["rifford", ",", "rj", "stern", ",", "feedback", "stabilization", "and", "lyapunov", "functions", ",", "siam", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3321}, {"sent": "convolutional neural networks have recently become the par excellence base approach to deal with many computer vision tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "become", "the", "par", "excellence", "base", "approach", "to", "deal", "with", "many", "computer", "vision", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "become", "start": 44, "end": 50, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}], "id": 3322}, {"sent": "the ideas we use essentially come from bhamidi et al , where mixing times for the glauber dynamics of ergms are derived .", "tokens": ["the", "ideas", "we", "use", "essentially", "come", "from", "bhamidi", "et", "al", ",", "where", "mixing", "times", "for", "the", "glauber", "dynamics", "of", "ergms", "are", "derived", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ideas we use", "start": 0, "end": 16, "i_start": 0, "i_end": 3}, "verb": {"text": "come", "start": 29, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 13, "end": 16, "i_start": 3, "i_end": 3}}], "id": 3323}, {"sent": "recently , shen et al used kernels in structural equation models for identification of network topologies from graph signals .", "tokens": ["recently", ",", "shen", "et", "al", "used", "kernels", "in", "structural", "equation", "models", "for", "identification", "of", "network", "topologies", "from", "graph", "signals", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "shen et al", "start": 11, "end": 21, "i_start": 2, "i_end": 4}, "verb": {"text": "used", "start": 22, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "shen", "start": 11, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "used", "start": 22, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "shen", "start": 11, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "identification", "start": 69, "end": 83, "i_start": 12, "i_end": 12}}], "id": 3324}, {"sent": "the standard program is called a universal turing machine .", "tokens": ["the", "standard", "program", "is", "called", "a", "universal", "turing", "machine", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the standard program", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}], "id": 3325}, {"sent": "we detect layer communities using the louvain method and infomap .", "tokens": ["we", "detect", "layer", "communities", "using", "the", "louvain", "method", "and", "infomap", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "detect", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "detect", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 3326}, {"sent": "the standard factorization theorems of perturbative qcd are the main ingredients in many phenomenological calculations of high energy processes .", "tokens": ["the", "standard", "factorization", "theorems", "of", "perturbative", "qcd", "are", "the", "main", "ingredients", "in", "many", "phenomenological", "calculations", "of", "high", "energy", "processes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the standard factorization theorems of perturbative qcd", "start": 0, "end": 55, "i_start": 0, "i_end": 6}, "verb": {"text": "are", "start": 56, "end": 59, "i_start": 7, "i_end": 7}}], "id": 3327}, {"sent": "the dot line connecting the experimental points is only for eye guidance .", "tokens": ["the", "dot", "line", "connecting", "the", "experimental", "points", "is", "only", "for", "eye", "guidance", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dot line connecting the experimental points", "start": 0, "end": 47, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 48, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "line", "start": 8, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "guidance", "start": 64, "end": 72, "i_start": 11, "i_end": 11}}], "id": 3328}, {"sent": "deep neural networks have shown tremendous progress in computer vision and speech recognition tasks .", "tokens": ["deep", "neural", "networks", "have", "shown", "tremendous", "progress", "in", "computer", "vision", "and", "speech", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 26, "end": 31, "i_start": 4, "i_end": 4}}], "id": 3329}, {"sent": "the artificial compressibility approximation was introduced by chorin , in order to deal with the difficulty induced by the incompressibility constraints in the numerical approximations to the navier stokes equation .", "tokens": ["the", "artificial", "compressibility", "approximation", "was", "introduced", "by", "chorin", ",", "in", "order", "to", "deal", "with", "the", "difficulty", "induced", "by", "the", "incompressibility", "constraints", "in", "the", "numerical", "approximations", "to", "the", "navier", "stokes", "equation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the artificial compressibility approximation", "start": 0, "end": 44, "i_start": 0, "i_end": 3}, "verb": {"text": "was introduced", "start": 45, "end": 59, "i_start": 4, "i_end": 5}}, {"character": {"text": "constraints", "start": 142, "end": 153, "i_start": 20, "i_end": 20}, "action": {"text": "induced", "start": 109, "end": 116, "i_start": 16, "i_end": 16}}], "id": 3330}, {"sent": "lat is a pair-production telescope with a wide field-of-view , recording the direction , energy , and arrival time of each \u03b3-ray photon in the energy range of from below 20 mev to more than 300 gev .", "tokens": ["lat", "is", "a", "pair", "-", "production", "telescope", "with", "a", "wide", "field", "-", "of", "-", "view", ",", "recording", "the", "direction", ",", "energy", ",", "and", "arrival", "time", "of", "each", "\u03b3", "-", "ray", "photon", "in", "the", "energy", "range", "of", "from", "below", "20", "mev", "to", "more", "than", "300", "gev", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "lat", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 4, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "telescope", "start": 25, "end": 34, "i_start": 6, "i_end": 6}, "action": {"text": "recording", "start": 63, "end": 72, "i_start": 16, "i_end": 16}}], "id": 3331}, {"sent": "from quantum mechanics it is a postulate that to every observable there is an operator which is hermitian .", "tokens": ["from", "quantum", "mechanics", "it", "is", "a", "postulate", "that", "to", "every", "observable", "there", "is", "an", "operator", "which", "is", "hermitian", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 23, "end": 25, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 4, "i_end": 4}}], "id": 3332}, {"sent": "a property about memory scope forms is also given in this section .", "tokens": ["a", "property", "about", "memory", "scope", "forms", "is", "also", "given", "in", "this", "section", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a property about memory scope forms", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "given", "start": 44, "end": 49, "i_start": 8, "i_end": 8}}, {"subject": {"text": "a property about memory scope forms", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 36, "end": 38, "i_start": 6, "i_end": 6}}], "id": 3333}, {"sent": "the case of anisotropic plasma has been studied in and imaginary potential formula in a general curved background was obtained .", "tokens": ["the", "case", "of", "anisotropic", "plasma", "has", "been", "studied", "in", "and", "imaginary", "potential", "formula", "in", "a", "general", "curved", "background", "was", "obtained", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the case of anisotropic plasma", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "has been studied", "start": 31, "end": 47, "i_start": 5, "i_end": 7}}, {"subject": {"text": "imaginary potential formula in a general curved background", "start": 55, "end": 113, "i_start": 10, "i_end": 17}, "verb": {"text": "obtained", "start": 118, "end": 126, "i_start": 19, "i_end": 19}}], "id": 3334}, {"sent": "we also demonstrated that these families are guaranteed approximate bl-wolf-learnable with lower cost .", "tokens": ["we", "also", "demonstrated", "that", "these", "families", "are", "guaranteed", "approximate", "bl", "-", "wolf", "-", "learnable", "with", "lower", "cost", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "demonstrated", "start": 8, "end": 20, "i_start": 2, "i_end": 2}}, {"subject": {"text": "these families", "start": 26, "end": 40, "i_start": 4, "i_end": 5}, "verb": {"text": "guaranteed", "start": 45, "end": 55, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "demonstrated", "start": 8, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "families", "start": 32, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "learnable", "start": 76, "end": 85, "i_start": 13, "i_end": 13}}], "id": 3335}, {"sent": "deep convolutional networks have achieved impressive results for various computer vision tasks , such as image classification and segmentation .", "tokens": ["deep", "convolutional", "networks", "have", "achieved", "impressive", "results", "for", "various", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "and", "segmentation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional networks", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 28, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 19, "end": 27, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 33, "end": 41, "i_start": 4, "i_end": 4}}, {"character": {"text": "results", "start": 53, "end": 60, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 42, "end": 52, "i_start": 5, "i_end": 5}}], "id": 3336}, {"sent": "a set oriented approach to global optimal control .", "tokens": ["a", "set", "oriented", "approach", "to", "global", "optimal", "control", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3337}, {"sent": "then , the larger disparity in the boundary area is more likely to induce window violation , due to the limitation of visual field .", "tokens": ["then", ",", "the", "larger", "disparity", "in", "the", "boundary", "area", "is", "more", "likely", "to", "induce", "window", "violation", ",", "due", "to", "the", "limitation", "of", "visual", "field", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the larger disparity in the boundary area", "start": 7, "end": 48, "i_start": 2, "i_end": 8}, "verb": {"text": "is", "start": 49, "end": 51, "i_start": 9, "i_end": 9}}, {"character": {"text": "disparity", "start": 18, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "induce", "start": 67, "end": 73, "i_start": 13, "i_end": 13}}], "id": 3338}, {"sent": "the curvaton is a type of matter whose energy density is not diluted during inflation , and some or all of the present material in the universe may have survived inflation via the curvaton .", "tokens": ["the", "curvaton", "is", "a", "type", "of", "matter", "whose", "energy", "density", "is", "not", "diluted", "during", "inflation", ",", "and", "some", "or", "all", "of", "the", "present", "material", "in", "the", "universe", "may", "have", "survived", "inflation", "via", "the", "curvaton", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the curvaton", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"subject": {"text": "some or all of the present material in the universe", "start": 92, "end": 143, "i_start": 17, "i_end": 26}, "verb": {"text": "survived", "start": 153, "end": 161, "i_start": 29, "i_end": 29}}, {"character": {"text": "material", "start": 119, "end": 127, "i_start": 23, "i_end": 23}, "action": {"text": "survived", "start": 153, "end": 161, "i_start": 29, "i_end": 29}}], "id": 3339}, {"sent": "explicit examples can be found in where xor was obtained as a sub-result of the controlled-not gate operation .", "tokens": ["explicit", "examples", "can", "be", "found", "in", "where", "xor", "was", "obtained", "as", "a", "sub", "-", "result", "of", "the", "controlled", "-", "not", "gate", "operation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "explicit examples", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "can be found", "start": 18, "end": 30, "i_start": 2, "i_end": 4}}], "id": 3340}, {"sent": "vortex , which is a singular gauge transformation .", "tokens": ["vortex", ",", "which", "is", "a", "singular", "gauge", "transformation", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3341}, {"sent": "type iib supergravity is the effective field theory of the type iib superstring .", "tokens": ["type", "iib", "supergravity", "is", "the", "effective", "field", "theory", "of", "the", "type", "iib", "superstring", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "type iib supergravity", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "theory", "start": 45, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "effective", "start": 29, "end": 38, "i_start": 5, "i_end": 5}}], "id": 3342}, {"sent": "the colorization network is initialized with xavier initialization .", "tokens": ["the", "colorization", "network", "is", "initialized", "with", "xavier", "initialization", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the colorization network", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is initialized", "start": 25, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "network", "start": 17, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "colorization", "start": 4, "end": 16, "i_start": 1, "i_end": 1}}], "id": 3343}, {"sent": "the goal of generative adversarial networks is to find a generative model that produces samples from the distribution of real data .", "tokens": ["the", "goal", "of", "generative", "adversarial", "networks", "is", "to", "find", "a", "generative", "model", "that", "produces", "samples", "from", "the", "distribution", "of", "real", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the goal of generative adversarial networks", "start": 0, "end": 43, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 44, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "model", "start": 68, "end": 73, "i_start": 11, "i_end": 11}, "action": {"text": "produces", "start": 79, "end": 87, "i_start": 13, "i_end": 13}}], "id": 3344}, {"sent": "the hamiltonian h is a self-adjoint operator acting in h 1 l and is invariant under the algebra a .", "tokens": ["the", "hamiltonian", "h", "is", "a", "self", "-", "adjoint", "operator", "acting", "in", "h", "1", "l", "and", "is", "invariant", "under", "the", "algebra", "a", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the hamiltonian h", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "operator", "start": 36, "end": 44, "i_start": 8, "i_end": 8}, "action": {"text": "acting", "start": 45, "end": 51, "i_start": 9, "i_end": 9}}], "id": 3345}, {"sent": "the content encoder of mcnet is built with the same architecture as vgg16 up to the third pooling layer .", "tokens": ["the", "content", "encoder", "of", "mcnet", "is", "built", "with", "the", "same", "architecture", "as", "vgg16", "up", "to", "the", "third", "pooling", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the content encoder of mcnet", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "is built", "start": 29, "end": 37, "i_start": 5, "i_end": 6}}, {"character": {"text": "layer", "start": 98, "end": 103, "i_start": 18, "i_end": 18}, "action": {"text": "pooling", "start": 90, "end": 97, "i_start": 17, "i_end": 17}}], "id": 3346}, {"sent": "convolutional neural networks have recently provided state of the art results for several recognition tasks including object recognition .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "provided", "state", "of", "the", "art", "results", "for", "several", "recognition", "tasks", "including", "object", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "provided", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "provided", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}], "id": 3347}, {"sent": "at large densities , neutrino-neutrino refraction causes nonlinear flavor oscillation phenomena with sometimes perplexing results .", "tokens": ["at", "large", "densities", ",", "neutrino", "-", "neutrino", "refraction", "causes", "nonlinear", "flavor", "oscillation", "phenomena", "with", "sometimes", "perplexing", "results", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neutrino-neutrino refraction", "start": 21, "end": 49, "i_start": 4, "i_end": 7}, "verb": {"text": "causes", "start": 50, "end": 56, "i_start": 8, "i_end": 8}}, {"character": {"text": "refraction", "start": 39, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "causes", "start": 50, "end": 56, "i_start": 8, "i_end": 8}}, {"character": {"text": "causes", "start": 50, "end": 56, "i_start": 8, "i_end": 8}, "action": {"text": "perplexing", "start": 111, "end": 121, "i_start": 15, "i_end": 15}}], "id": 3348}, {"sent": "to solve the maximization problem of f , we utilize the nelder-mead method which ensures an efficient searching strategy and real-time performance .", "tokens": ["to", "solve", "the", "maximization", "problem", "of", "f", ",", "we", "utilize", "the", "nelder", "-", "mead", "method", "which", "ensures", "an", "efficient", "searching", "strategy", "and", "real", "-", "time", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 41, "end": 43, "i_start": 8, "i_end": 8}, "verb": {"text": "utilize", "start": 44, "end": 51, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 41, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "utilize", "start": 44, "end": 51, "i_start": 9, "i_end": 9}}, {"character": {"text": "method", "start": 68, "end": 74, "i_start": 14, "i_end": 14}, "action": {"text": "ensures", "start": 81, "end": 88, "i_start": 16, "i_end": 16}}], "id": 3349}, {"sent": "superconductivity is a phenomenon that is common to both nuclear physics and con densed matter systems .", "tokens": ["superconductivity", "is", "a", "phenomenon", "that", "is", "common", "to", "both", "nuclear", "physics", "and", "con", "densed", "matter", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "superconductivity", "start": 0, "end": 17, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 1, "i_end": 1}}], "id": 3350}, {"sent": "note that the vector and axial currents have vanishing anomalous dimensions .", "tokens": ["note", "that", "the", "vector", "and", "axial", "currents", "have", "vanishing", "anomalous", "dimensions", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the vector and axial currents", "start": 10, "end": 39, "i_start": 2, "i_end": 6}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "the vector and axial currents", "start": 10, "end": 39, "i_start": 2, "i_end": 6}, "verb": {"text": "vanishing", "start": 45, "end": 54, "i_start": 8, "i_end": 8}}, {"character": {"text": "currents", "start": 31, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "have", "start": 40, "end": 44, "i_start": 7, "i_end": 7}}, {"character": {"text": "vector", "start": 14, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "have", "start": 40, "end": 44, "i_start": 7, "i_end": 7}}, {"character": {"text": "axial", "start": 25, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "have", "start": 40, "end": 44, "i_start": 7, "i_end": 7}}], "id": 3351}, {"sent": "in this article we present results for the integrated and unintegrated gluon distribution functions obtained within the ldc formalism and make comparisons with the ccfm model and with results from other formalisms .", "tokens": ["in", "this", "article", "we", "present", "results", "for", "the", "integrated", "and", "unintegrated", "gluon", "distribution", "functions", "obtained", "within", "the", "ldc", "formalism", "and", "make", "comparisons", "with", "the", "ccfm", "model", "and", "with", "results", "from", "other", "formalisms", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "present", "start": 19, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "present", "start": 19, "end": 26, "i_start": 4, "i_end": 4}}], "id": 3352}, {"sent": "deep convolutional neural networks have achieved great success in various computer vision tasks , including object classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "various", "computer", "vision", "tasks", ",", "including", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}], "id": 3353}, {"sent": "in the rest of this section we use the properties of cluster red sequences to constrain the amounts of dust present in cluster galaxies .", "tokens": ["in", "the", "rest", "of", "this", "section", "we", "use", "the", "properties", "of", "cluster", "red", "sequences", "to", "constrain", "the", "amounts", "of", "dust", "present", "in", "cluster", "galaxies", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 28, "end": 30, "i_start": 6, "i_end": 6}, "verb": {"text": "use", "start": 31, "end": 34, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 28, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "use", "start": 31, "end": 34, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 28, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "constrain", "start": 78, "end": 87, "i_start": 15, "i_end": 15}}], "id": 3354}, {"sent": "over the past few years , convolutional neural networks have become the leading approach in many vision-related tasks .", "tokens": ["over", "the", "past", "few", "years", ",", "convolutional", "neural", "networks", "have", "become", "the", "leading", "approach", "in", "many", "vision", "-", "related", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 26, "end": 55, "i_start": 6, "i_end": 8}, "verb": {"text": "have become", "start": 56, "end": 67, "i_start": 9, "i_end": 10}}, {"character": {"text": "networks", "start": 47, "end": 55, "i_start": 8, "i_end": 8}, "action": {"text": "approach", "start": 80, "end": 88, "i_start": 13, "i_end": 13}}, {"character": {"text": "approach", "start": 80, "end": 88, "i_start": 13, "i_end": 13}, "action": {"text": "leading", "start": 72, "end": 79, "i_start": 12, "i_end": 12}}], "id": 3355}, {"sent": "a variety of cnn models have been introduced in the literatures , such as lenet and their variants and so on .", "tokens": ["a", "variety", "of", "cnn", "models", "have", "been", "introduced", "in", "the", "literatures", ",", "such", "as", "lenet", "and", "their", "variants", "and", "so", "on", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a variety of cnn models", "start": 0, "end": 23, "i_start": 0, "i_end": 4}, "verb": {"text": "have been introduced", "start": 24, "end": 44, "i_start": 5, "i_end": 7}}], "id": 3356}, {"sent": "kim , q-generalized euler numbers and polynomials , russian j .", "tokens": ["kim", ",", "q", "-", "generalized", "euler", "numbers", "and", "polynomials", ",", "russian", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3357}, {"sent": "much of the work with deep learning in natural language processing has involved the learning of word vector representations .", "tokens": ["much", "of", "the", "work", "with", "deep", "learning", "in", "natural", "language", "processing", "has", "involved", "the", "learning", "of", "word", "vector", "representations", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "much of the work with deep learning in natural language processing", "start": 0, "end": 66, "i_start": 0, "i_end": 10}, "verb": {"text": "has involved", "start": 67, "end": 79, "i_start": 11, "i_end": 12}}], "id": 3358}, {"sent": "the ellipses denote the other time-ordered diagram with the corresponding okubo-type correction .", "tokens": ["the", "ellipses", "denote", "the", "other", "time", "-", "ordered", "diagram", "with", "the", "corresponding", "okubo", "-", "type", "correction", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ellipses", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "denote", "start": 13, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "ellipses", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 13, "end": 19, "i_start": 2, "i_end": 2}}], "id": 3359}, {"sent": "these resonant inelastic light scattering experiments take advantage of breakdown of wave-vector conservation that occurs in the qh state due to residual disorder .", "tokens": ["these", "resonant", "inelastic", "light", "scattering", "experiments", "take", "advantage", "of", "breakdown", "of", "wave", "-", "vector", "conservation", "that", "occurs", "in", "the", "qh", "state", "due", "to", "residual", "disorder", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "these resonant inelastic light scattering experiments", "start": 0, "end": 53, "i_start": 0, "i_end": 5}, "verb": {"text": "take", "start": 54, "end": 58, "i_start": 6, "i_end": 6}}, {"character": {"text": "experiments", "start": 42, "end": 53, "i_start": 5, "i_end": 5}, "action": {"text": "take", "start": 54, "end": 58, "i_start": 6, "i_end": 6}}], "id": 3360}, {"sent": "we use the resnet-101 as the backbone convenet to extract the features from high and low resolution images .", "tokens": ["we", "use", "the", "resnet-101", "as", "the", "backbone", "convenet", "to", "extract", "the", "features", "from", "high", "and", "low", "resolution", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extract", "start": 50, "end": 57, "i_start": 9, "i_end": 9}}], "id": 3361}, {"sent": "the response of the sifcc detector to physics processes has been simulated using the simulator for the linear collider software , which was developed for the ilc project .", "tokens": ["the", "response", "of", "the", "sifcc", "detector", "to", "physics", "processes", "has", "been", "simulated", "using", "the", "simulator", "for", "the", "linear", "collider", "software", ",", "which", "was", "developed", "for", "the", "ilc", "project", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the response of the sifcc detector to physics processes", "start": 0, "end": 55, "i_start": 0, "i_end": 8}, "verb": {"text": "has been simulated", "start": 56, "end": 74, "i_start": 9, "i_end": 11}}], "id": 3362}, {"sent": "recently , deep neural networks are driving advances in image recognition related tasks in computer vision .", "tokens": ["recently", ",", "deep", "neural", "networks", "are", "driving", "advances", "in", "image", "recognition", "related", "tasks", "in", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "are driving", "start": 32, "end": 43, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "driving", "start": 36, "end": 43, "i_start": 6, "i_end": 6}}], "id": 3363}, {"sent": "recent development of deep convolutional neural networks has led to great success in a variety of tasks including image classfication and others .", "tokens": ["recent", "development", "of", "deep", "convolutional", "neural", "networks", "has", "led", "to", "great", "success", "in", "a", "variety", "of", "tasks", "including", "image", "classfication", "and", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent development of deep convolutional neural networks", "start": 0, "end": 56, "i_start": 0, "i_end": 6}, "verb": {"text": "has led", "start": 57, "end": 64, "i_start": 7, "i_end": 8}}, {"character": {"text": "development", "start": 7, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 61, "end": 64, "i_start": 8, "i_end": 8}}], "id": 3364}, {"sent": "moreover , we apply a batch normalization layer before each convolutional layer to improve the training speed and overall accuracy .", "tokens": ["moreover", ",", "we", "apply", "a", "batch", "normalization", "layer", "before", "each", "convolutional", "layer", "to", "improve", "the", "training", "speed", "and", "overall", "accuracy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "verb": {"text": "apply", "start": 14, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "apply", "start": 14, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "improve", "start": 83, "end": 90, "i_start": 13, "i_end": 13}}], "id": 3365}, {"sent": "this essential feature of quark dynamics is known as confinement .", "tokens": ["this", "essential", "feature", "of", "quark", "dynamics", "is", "known", "as", "confinement", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this essential feature of quark dynamics", "start": 0, "end": 40, "i_start": 0, "i_end": 5}, "verb": {"text": "is known", "start": 41, "end": 49, "i_start": 6, "i_end": 7}}], "id": 3366}, {"sent": "recent studies have demonstrated potential risks in applying neural networks for classification .", "tokens": ["recent", "studies", "have", "demonstrated", "potential", "risks", "in", "applying", "neural", "networks", "for", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent studies", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "have demonstrated", "start": 15, "end": 32, "i_start": 2, "i_end": 3}}, {"character": {"text": "studies", "start": 7, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "demonstrated", "start": 20, "end": 32, "i_start": 3, "i_end": 3}}], "id": 3367}, {"sent": "deep convolutional neural networks have brought impressive advances to the state of the art across a multitude of tasks in computer vision .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "brought", "impressive", "advances", "to", "the", "state", "of", "the", "art", "across", "a", "multitude", "of", "tasks", "in", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have brought", "start": 35, "end": 47, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "brought", "start": 40, "end": 47, "i_start": 5, "i_end": 5}}, {"character": {"text": "advances", "start": 59, "end": 67, "i_start": 7, "i_end": 7}, "action": {"text": "impressive", "start": 48, "end": 58, "i_start": 6, "i_end": 6}}], "id": 3368}, {"sent": "the number of states can be decreased if we apply reduction by means of the greatest left invariant fuzzy quasi-order .", "tokens": ["the", "number", "of", "states", "can", "be", "decreased", "if", "we", "apply", "reduction", "by", "means", "of", "the", "greatest", "left", "invariant", "fuzzy", "quasi", "-", "order", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the number of states", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "can be decreased", "start": 21, "end": 37, "i_start": 4, "i_end": 6}}, {"character": {"text": "we", "start": 41, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "apply", "start": 44, "end": 49, "i_start": 9, "i_end": 9}}], "id": 3369}, {"sent": "automatic generation of constraint propagation algorithms for small finite domains .", "tokens": ["automatic", "generation", "of", "constraint", "propagation", "algorithms", "for", "small", "finite", "domains", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3370}, {"sent": "recently , deep neural networks have demonstrated impressive results in image classification .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "demonstrated", "impressive", "results", "in", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have demonstrated", "start": 32, "end": 49, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "demonstrated", "start": 37, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "results", "start": 61, "end": 68, "i_start": 8, "i_end": 8}, "action": {"text": "impressive", "start": 50, "end": 60, "i_start": 7, "i_end": 7}}], "id": 3371}, {"sent": "watts and strogatz proposed the clustering coefficient of a graph in order to quantify the corresponding property of networks .", "tokens": ["watts", "and", "strogatz", "proposed", "the", "clustering", "coefficient", "of", "a", "graph", "in", "order", "to", "quantify", "the", "corresponding", "property", "of", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "watts and strogatz", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "watts", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "strogatz", "start": 10, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "proposed", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "watts", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "quantify", "start": 78, "end": 86, "i_start": 13, "i_end": 13}}, {"character": {"text": "strogatz", "start": 10, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "quantify", "start": 78, "end": 86, "i_start": 13, "i_end": 13}}], "id": 3372}, {"sent": "the fos spectra are presented by wills et al .", "tokens": ["the", "fos", "spectra", "are", "presented", "by", "wills", "et", "al", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the fos spectra", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "are presented", "start": 16, "end": 29, "i_start": 3, "i_end": 4}}, {"character": {"text": "wills", "start": 33, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "presented", "start": 20, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "et", "start": 39, "end": 41, "i_start": 7, "i_end": 7}, "action": {"text": "presented", "start": 20, "end": 29, "i_start": 4, "i_end": 4}}], "id": 3373}, {"sent": "the recent development of deep learning has boosted the performance of image classification tasks .", "tokens": ["the", "recent", "development", "of", "deep", "learning", "has", "boosted", "the", "performance", "of", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the recent development of deep learning", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "has boosted", "start": 40, "end": 51, "i_start": 6, "i_end": 7}}, {"character": {"text": "development", "start": 11, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "boosted", "start": 44, "end": 51, "i_start": 7, "i_end": 7}}], "id": 3374}, {"sent": "we see that the von neumann entropy is a monotonically increasing function of perimeter .", "tokens": ["we", "see", "that", "the", "von", "neumann", "entropy", "is", "a", "monotonically", "increasing", "function", "of", "perimeter", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "see", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 36, "end": 38, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "see", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "perimeter", "start": 78, "end": 87, "i_start": 13, "i_end": 13}, "action": {"text": "function", "start": 66, "end": 74, "i_start": 11, "i_end": 11}}], "id": 3375}, {"sent": "in particular , neither shows azimuthal symmetry , and the emission is not centered on the white dwarf but is primarily in the lowerleft quadrant .", "tokens": ["in", "particular", ",", "neither", "shows", "azimuthal", "symmetry", ",", "and", "the", "emission", "is", "not", "centered", "on", "the", "white", "dwarf", "but", "is", "primarily", "in", "the", "lowerleft", "quadrant", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neither", "start": 16, "end": 23, "i_start": 3, "i_end": 3}, "verb": {"text": "shows", "start": 24, "end": 29, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the emission", "start": 55, "end": 67, "i_start": 9, "i_end": 10}, "verb": {"text": "centered", "start": 75, "end": 83, "i_start": 13, "i_end": 13}}], "id": 3376}, {"sent": "deep learning techniques have shown promising results in many research fields such as computer vision .", "tokens": ["deep", "learning", "techniques", "have", "shown", "promising", "results", "in", "many", "research", "fields", "such", "as", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning techniques", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 25, "end": 35, "i_start": 3, "i_end": 4}}, {"character": {"text": "techniques", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 30, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "results", "start": 46, "end": 53, "i_start": 6, "i_end": 6}, "action": {"text": "promising", "start": 36, "end": 45, "i_start": 5, "i_end": 5}}], "id": 3377}, {"sent": "it is polynomial time solvable to find a maximum independent set in claw-free graphs .", "tokens": ["it", "is", "polynomial", "time", "solvable", "to", "find", "a", "maximum", "independent", "set", "in", "claw", "-", "free", "graphs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"character": {"text": "set", "start": 61, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "independent set in claw-", "start": 49, "end": 73, "i_start": 9, "i_end": 13}}], "id": 3378}, {"sent": "massive mimo is considered as a promising technique in 5g communication systems , which has a potential of increasing spectral and energy efficiency significantly with simple signal processing .", "tokens": ["massive", "mimo", "is", "considered", "as", "a", "promising", "technique", "in", "5", "g", "communication", "systems", ",", "which", "has", "a", "potential", "of", "increasing", "spectral", "and", "energy", "efficiency", "significantly", "with", "simple", "signal", "processing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "massive mimo", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is considered", "start": 13, "end": 26, "i_start": 2, "i_end": 3}}, {"character": {"text": "mimo", "start": 8, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "promising", "start": 32, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "technique", "start": 42, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "increasing", "start": 107, "end": 117, "i_start": 19, "i_end": 19}}], "id": 3379}, {"sent": "we used scikitlearn python library for implementing these classifiers .", "tokens": ["we", "used", "scikitlearn", "python", "library", "for", "implementing", "these", "classifiers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implementing", "start": 39, "end": 51, "i_start": 6, "i_end": 6}}], "id": 3380}, {"sent": "since the pioneering work by alamouti , complex orthogonal designs have become an effective technique for the design of space-time block codes .", "tokens": ["since", "the", "pioneering", "work", "by", "alamouti", ",", "complex", "orthogonal", "designs", "have", "become", "an", "effective", "technique", "for", "the", "design", "of", "space", "-", "time", "block", "codes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "complex orthogonal designs", "start": 40, "end": 66, "i_start": 7, "i_end": 9}, "verb": {"text": "have become", "start": 67, "end": 78, "i_start": 10, "i_end": 11}}, {"character": {"text": "technique", "start": 92, "end": 101, "i_start": 14, "i_end": 14}, "action": {"text": "effective", "start": 82, "end": 91, "i_start": 13, "i_end": 13}}], "id": 3381}, {"sent": "the observation of gravitational waves of a coalescence of neutron stars has not only opened up a new observational window to astrophysics , but also enabled theorists to finding clues to pending questions on the behavior of dense matter .", "tokens": ["the", "observation", "of", "gravitational", "waves", "of", "a", "coalescence", "of", "neutron", "stars", "has", "not", "only", "opened", "up", "a", "new", "observational", "window", "to", "astrophysics", ",", "but", "also", "enabled", "theorists", "to", "finding", "clues", "to", "pending", "questions", "on", "the", "behavior", "of", "dense", "matter", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the observation of gravitational waves of a coalescence of neutron stars", "start": 0, "end": 72, "i_start": 0, "i_end": 10}, "verb": {"text": "opened up", "start": 86, "end": 95, "i_start": 14, "i_end": 15}}, {"subject": {"text": "the observation of gravitational waves of a coalescence of neutron stars", "start": 0, "end": 72, "i_start": 0, "i_end": 10}, "verb": {"text": "has", "start": 73, "end": 76, "i_start": 11, "i_end": 11}}, {"subject": {"text": "the observation of gravitational waves of a coalescence of neutron stars", "start": 0, "end": 72, "i_start": 0, "i_end": 10}, "verb": {"text": "enabled", "start": 150, "end": 157, "i_start": 25, "i_end": 25}}, {"character": {"text": "observation", "start": 4, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "opened", "start": 86, "end": 92, "i_start": 14, "i_end": 14}}], "id": 3382}, {"sent": "by duality , there is a similar correspondence between right bol loops and right bol quasigroups .", "tokens": ["by", "duality", ",", "there", "is", "a", "similar", "correspondence", "between", "right", "bol", "loops", "and", "right", "bol", "quasigroups", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 13, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 4, "i_end": 4}}, {"character": {"text": "loops", "start": 65, "end": 70, "i_start": 11, "i_end": 11}, "action": {"text": "correspondence", "start": 32, "end": 46, "i_start": 7, "i_end": 7}}], "id": 3383}, {"sent": "epidemic outbreaks in complex heterogeneous networks .", "tokens": ["epidemic", "outbreaks", "in", "complex", "heterogeneous", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3384}, {"sent": "some of the most successful techniques include generative adversarial networks and variational autoencoders .", "tokens": ["some", "of", "the", "most", "successful", "techniques", "include", "generative", "adversarial", "networks", "and", "variational", "autoencoders", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "some of the most successful techniques", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "include", "start": 39, "end": 46, "i_start": 6, "i_end": 6}}], "id": 3385}, {"sent": "the analysis of the minimal model leading to these conclusions is carried out in the fundamental paper and is achieved by considering commutative graded differential algebras over q which are equipped with filtrations as a new structural ingredient .", "tokens": ["the", "analysis", "of", "the", "minimal", "model", "leading", "to", "these", "conclusions", "is", "carried", "out", "in", "the", "fundamental", "paper", "and", "is", "achieved", "by", "considering", "commutative", "graded", "differential", "algebras", "over", "q", "which", "are", "equipped", "with", "filtrations", "as", "a", "new", "structural", "ingredient", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the analysis of the minimal model leading to these conclusions", "start": 0, "end": 62, "i_start": 0, "i_end": 9}, "verb": {"text": "is carried out", "start": 63, "end": 77, "i_start": 10, "i_end": 12}}, {"subject": {"text": "the analysis of the minimal model leading to these conclusions", "start": 0, "end": 62, "i_start": 0, "i_end": 9}, "verb": {"text": "achieved", "start": 110, "end": 118, "i_start": 19, "i_end": 19}}, {"character": {"text": "model", "start": 28, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "leading", "start": 34, "end": 41, "i_start": 6, "i_end": 6}}], "id": 3386}, {"sent": "a popular related approach , initially developed by felzenszwalb et al , is called a deformable part model for object detection .", "tokens": ["a", "popular", "related", "approach", ",", "initially", "developed", "by", "felzenszwalb", "et", "al", ",", "is", "called", "a", "deformable", "part", "model", "for", "object", "detection", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "a popular related approach", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "is called", "start": 73, "end": 82, "i_start": 12, "i_end": 13}}, {"character": {"text": "felzenszwalb", "start": 52, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "developed", "start": 39, "end": 48, "i_start": 6, "i_end": 6}}], "id": 3387}, {"sent": "resnets have outperformed previous models at a variety of tasks , such as object detection .", "tokens": ["resnets", "have", "outperformed", "previous", "models", "at", "a", "variety", "of", "tasks", ",", "such", "as", "object", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "resnets", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "have outperformed", "start": 8, "end": 25, "i_start": 1, "i_end": 2}}], "id": 3388}, {"sent": "the chiral condensate is a non-conserved quantity .", "tokens": ["the", "chiral", "condensate", "is", "a", "non", "-", "conserved", "quantity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the chiral condensate", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3389}, {"sent": "the theory obtained from a self-consistent solution of the geometry of the spacetime and the quantum field is known as semiclassical gravity .", "tokens": ["the", "theory", "obtained", "from", "a", "self", "-", "consistent", "solution", "of", "the", "geometry", "of", "the", "spacetime", "and", "the", "quantum", "field", "is", "known", "as", "semiclassical", "gravity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the theory", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "obtained", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the quantum field", "start": 89, "end": 106, "i_start": 16, "i_end": 18}, "verb": {"text": "known", "start": 110, "end": 115, "i_start": 20, "i_end": 20}}], "id": 3390}, {"sent": "recently , deep convolutional neural networks have achieved great successes in computer vision topics such as image classification .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "achieved", "great", "successes", "in", "computer", "vision", "topics", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "successes", "start": 66, "end": 75, "i_start": 9, "i_end": 9}}], "id": 3391}, {"sent": "in this section we study the results of the proposed method on another brain imaging dataset , the autism brain imaging data exchange .", "tokens": ["in", "this", "section", "we", "study", "the", "results", "of", "the", "proposed", "method", "on", "another", "brain", "imaging", "dataset", ",", "the", "autism", "brain", "imaging", "data", "exchange", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "study", "start": 19, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "study", "start": 19, "end": 24, "i_start": 4, "i_end": 4}}], "id": 3392}, {"sent": "cosmic strings are one-dimensional topological defects which are solutions of the field equations in many theories beyond the standard model of particle physics .", "tokens": ["cosmic", "strings", "are", "one", "-", "dimensional", "topological", "defects", "which", "are", "solutions", "of", "the", "field", "equations", "in", "many", "theories", "beyond", "the", "standard", "model", "of", "particle", "physics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3393}, {"sent": "in this sense , a virtual link is an equivalence class of gauss diagrams up to reidemeister moves r1-r3 .", "tokens": ["in", "this", "sense", ",", "a", "virtual", "link", "is", "an", "equivalence", "class", "of", "gauss", "diagrams", "up", "to", "reidemeister", "moves", "r1", "-", "r3", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a virtual link", "start": 16, "end": 30, "i_start": 4, "i_end": 6}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 7, "i_end": 7}}], "id": 3394}, {"sent": "standard medication paths can not be easily achieved , as the course and symptoms of the disease vary significantly among patients .", "tokens": ["standard", "medication", "paths", "can", "not", "be", "easily", "achieved", ",", "as", "the", "course", "and", "symptoms", "of", "the", "disease", "vary", "significantly", "among", "patients", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "standard medication paths", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 44, "end": 52, "i_start": 7, "i_end": 7}}, {"subject": {"text": "standard medication paths", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "can not be", "start": 26, "end": 36, "i_start": 3, "i_end": 5}}], "id": 3395}, {"sent": "the extended yale b database consists of 2414 frontal-face images of 38 subjects .", "tokens": ["the", "extended", "yale", "b", "database", "consists", "of", "2414", "frontal", "-", "face", "images", "of", "38", "subjects", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the extended yale b database", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "consists", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}], "id": 3396}, {"sent": "they are efficiently classically simulable , thanks to the gottesman-knill theorem .", "tokens": ["they", "are", "efficiently", "classically", "simulable", ",", "thanks", "to", "the", "gottesman", "-", "knill", "theorem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 5, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3397}, {"sent": "the mean squared error loss , along with the adam optimizer , was used for training .", "tokens": ["the", "mean", "squared", "error", "loss", ",", "along", "with", "the", "adam", "optimizer", ",", "was", "used", "for", "training", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the mean squared error loss", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "was used", "start": 62, "end": 70, "i_start": 12, "i_end": 13}}], "id": 3398}, {"sent": "this manipulation allows us to express the canonical ensemble in terms of the empirical means , or spin per site , of the spin random variables .", "tokens": ["this", "manipulation", "allows", "us", "to", "express", "the", "canonical", "ensemble", "in", "terms", "of", "the", "empirical", "means", ",", "or", "spin", "per", "site", ",", "of", "the", "spin", "random", "variables", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this manipulation", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "allows", "start": 18, "end": 24, "i_start": 2, "i_end": 2}}, {"subject": {"text": "us", "start": 25, "end": 27, "i_start": 3, "i_end": 3}, "verb": {"text": "express", "start": 31, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "manipulation", "start": 5, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "allows", "start": 18, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 25, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "express", "start": 31, "end": 38, "i_start": 5, "i_end": 5}}], "id": 3399}, {"sent": "in recent years , convolutional neural networks have achieved significant success in many computer vision tasks , including the super-resolution problem .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "achieved", "significant", "success", "in", "many", "computer", "vision", "tasks", ",", "including", "the", "super", "-", "resolution", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 48, "end": 61, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 53, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 74, "end": 81, "i_start": 10, "i_end": 10}}], "id": 3400}, {"sent": "in recent years , numerous object detectors have been proposed by the deep learning community , including faster r-cnn .", "tokens": ["in", "recent", "years", ",", "numerous", "object", "detectors", "have", "been", "proposed", "by", "the", "deep", "learning", "community", ",", "including", "faster", "r", "-", "cnn", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "numerous object detectors", "start": 18, "end": 43, "i_start": 4, "i_end": 6}, "verb": {"text": "have been proposed", "start": 44, "end": 62, "i_start": 7, "i_end": 9}}, {"character": {"text": "community", "start": 84, "end": 93, "i_start": 14, "i_end": 14}, "action": {"text": "proposed", "start": 54, "end": 62, "i_start": 9, "i_end": 9}}, {"character": {"text": "community", "start": 84, "end": 93, "i_start": 14, "i_end": 14}, "action": {"text": "learning", "start": 75, "end": 83, "i_start": 13, "i_end": 13}}], "id": 3401}, {"sent": "neural machine translation has achieved substantial improvements in translation quality over traditional rule-based and phrase-based translation in recent years .", "tokens": ["neural", "machine", "translation", "has", "achieved", "substantial", "improvements", "in", "translation", "quality", "over", "traditional", "rule", "-", "based", "and", "phrase", "-", "based", "translation", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural machine translation", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "has achieved", "start": 27, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "translation", "start": 15, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 31, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "translation", "start": 15, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "improvements", "start": 52, "end": 64, "i_start": 6, "i_end": 6}}], "id": 3402}, {"sent": "the decoder is a fixed section of code which runs on the native hardware .", "tokens": ["the", "decoder", "is", "a", "fixed", "section", "of", "code", "which", "runs", "on", "the", "native", "hardware", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the decoder", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "hardware", "start": 64, "end": 72, "i_start": 13, "i_end": 13}, "action": {"text": "runs", "start": 45, "end": 49, "i_start": 9, "i_end": 9}}], "id": 3403}, {"sent": "the dashed curves denote the corresponding gravitational waveforms by the quadrupole formula .", "tokens": ["the", "dashed", "curves", "denote", "the", "corresponding", "gravitational", "waveforms", "by", "the", "quadrupole", "formula", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the dashed curves", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "denote", "start": 18, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "curves", "start": 11, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "denote", "start": 18, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3404}, {"sent": "farabet et al have pioneered to apply cnns to scene labeling tasks .", "tokens": ["farabet", "et", "al", "have", "pioneered", "to", "apply", "cnns", "to", "scene", "labeling", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "farabet et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "have pioneered", "start": 14, "end": 28, "i_start": 3, "i_end": 4}}, {"character": {"text": "farabet", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "pioneered", "start": 19, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "farabet", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "apply", "start": 32, "end": 37, "i_start": 6, "i_end": 6}}], "id": 3405}, {"sent": "in such a case , it is possible to show that n miis exactly equal to 1 .", "tokens": ["in", "such", "a", "case", ",", "it", "is", "possible", "to", "show", "that", "n", "miis", "exactly", "equal", "to", "1", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 17, "end": 19, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 6, "i_end": 6}}], "id": 3406}, {"sent": "applications of dec-pomdps include coordinating planetary rovers , multi-robot coordination and throughput optimization in wireless network .", "tokens": ["applications", "of", "dec", "-", "pomdps", "include", "coordinating", "planetary", "rovers", ",", "multi", "-", "robot", "coordination", "and", "throughput", "optimization", "in", "wireless", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "applications of dec-pomdps", "start": 0, "end": 26, "i_start": 0, "i_end": 4}, "verb": {"text": "include", "start": 27, "end": 34, "i_start": 5, "i_end": 5}}], "id": 3407}, {"sent": "in this paper , we choose the universal sentence encoder since semantic embeddings can be obtained for either words or sentences , especially for some terminologies .", "tokens": ["in", "this", "paper", ",", "we", "choose", "the", "universal", "sentence", "encoder", "since", "semantic", "embeddings", "can", "be", "obtained", "for", "either", "words", "or", "sentences", ",", "especially", "for", "some", "terminologies", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "choose", "start": 19, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "choose", "start": 19, "end": 25, "i_start": 5, "i_end": 5}}], "id": 3408}, {"sent": "convolutional neural networks have achieved unprecedented performance in a wide variety of applications , in particular for image analysis , enhancement and editing -eg , classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "unprecedented", "performance", "in", "a", "wide", "variety", "of", "applications", ",", "in", "particular", "for", "image", "analysis", ",", "enhancement", "and", "editing", "-eg", ",", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 58, "end": 69, "i_start": 6, "i_end": 6}}], "id": 3409}, {"sent": "in the body-vector representation , the cartesian coordinates of three principal axes xy z of the molecule are assumed to be orientational variables .", "tokens": ["in", "the", "body", "-", "vector", "representation", ",", "the", "cartesian", "coordinates", "of", "three", "principal", "axes", "xy", "z", "of", "the", "molecule", "are", "assumed", "to", "be", "orientational", "variables", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the cartesian coordinates of three principal axes xy z of the molecule", "start": 36, "end": 106, "i_start": 7, "i_end": 18}, "verb": {"text": "are assumed", "start": 107, "end": 118, "i_start": 19, "i_end": 20}}], "id": 3410}, {"sent": "spronk , operator weak amenability of the fourier algebra .", "tokens": ["spronk", ",", "operator", "weak", "amenability", "of", "the", "fourier", "algebra", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3411}, {"sent": "now we proceed on to define the smarandache analogue .", "tokens": ["now", "we", "proceed", "on", "to", "define", "the", "smarandache", "analogue", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed on", "start": 7, "end": 17, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 3412}, {"sent": "the benefits of multi-operator collaboration for data and spectrum trading are described in for different networks .", "tokens": ["the", "benefits", "of", "multi", "-", "operator", "collaboration", "for", "data", "and", "spectrum", "trading", "are", "described", "in", "for", "different", "networks", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the benefits of multi-operator collaboration for data and spectrum trading", "start": 0, "end": 74, "i_start": 0, "i_end": 11}, "verb": {"text": "are described", "start": 75, "end": 88, "i_start": 12, "i_end": 13}}, {"character": {"text": "collaboration", "start": 31, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "benefits", "start": 4, "end": 12, "i_start": 1, "i_end": 1}}], "id": 3413}, {"sent": "an isomorphism is a bijective morphism of laminations whose inverse is also a morphism of laminations 6 an embedding into itself .", "tokens": ["an", "isomorphism", "is", "a", "bijective", "morphism", "of", "laminations", "whose", "inverse", "is", "also", "a", "morphism", "of", "laminations", "6", "an", "embedding", "into", "itself", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an isomorphism", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 3414}, {"sent": "maximum likelihood estimation based on the extended kalman filter is usually applied to estimate the parameters in sde models , such as and the references therein .", "tokens": ["maximum", "likelihood", "estimation", "based", "on", "the", "extended", "kalman", "filter", "is", "usually", "applied", "to", "estimate", "the", "parameters", "in", "sde", "models", ",", "such", "as", "and", "the", "references", "therein", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "maximum likelihood estimation based on the extended kalman filter", "start": 0, "end": 65, "i_start": 0, "i_end": 8}, "verb": {"text": "applied", "start": 77, "end": 84, "i_start": 11, "i_end": 11}}, {"subject": {"text": "maximum likelihood estimation based on the extended kalman filter", "start": 0, "end": 65, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 66, "end": 68, "i_start": 9, "i_end": 9}}], "id": 3415}, {"sent": "duality and reflexivity in grand lebesgue spaces .", "tokens": ["duality", "and", "reflexivity", "in", "grand", "lebesgue", "spaces", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3416}, {"sent": "the set of differentiable curves will be denoted by ggg .", "tokens": ["the", "set", "of", "differentiable", "curves", "will", "be", "denoted", "by", "ggg", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the set of differentiable curves", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "will be denoted", "start": 33, "end": 48, "i_start": 5, "i_end": 7}}, {"character": {"text": "ggg", "start": 52, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "denoted", "start": 41, "end": 48, "i_start": 7, "i_end": 7}}], "id": 3417}, {"sent": "in the future , we will explore the application of generative adversarial networks to the task of fall detection in an unsupervised setting .", "tokens": ["in", "the", "future", ",", "we", "will", "explore", "the", "application", "of", "generative", "adversarial", "networks", "to", "the", "task", "of", "fall", "detection", "in", "an", "unsupervised", "setting", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "will explore", "start": 19, "end": 31, "i_start": 5, "i_end": 6}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "explore", "start": 24, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "application", "start": 36, "end": 47, "i_start": 8, "i_end": 8}}], "id": 3418}, {"sent": "in a different paper , the authors have shown that the graph-theoretic community structure strongly influences the running time of cdcl sat solvers .", "tokens": ["in", "a", "different", "paper", ",", "the", "authors", "have", "shown", "that", "the", "graph", "-", "theoretic", "community", "structure", "strongly", "influences", "the", "running", "time", "of", "cdcl", "sat", "solvers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 23, "end": 34, "i_start": 5, "i_end": 6}, "verb": {"text": "have shown", "start": 35, "end": 45, "i_start": 7, "i_end": 8}}, {"subject": {"text": "the graph-theoretic community structure", "start": 51, "end": 90, "i_start": 10, "i_end": 15}, "verb": {"text": "influences", "start": 100, "end": 110, "i_start": 17, "i_end": 17}}, {"character": {"text": "structure", "start": 81, "end": 90, "i_start": 15, "i_end": 15}, "action": {"text": "influences", "start": 100, "end": 110, "i_start": 17, "i_end": 17}}], "id": 3419}, {"sent": "therefore the choice of the transforming operators ga can be completely arbitrary .", "tokens": ["therefore", "the", "choice", "of", "the", "transforming", "operators", "ga", "can", "be", "completely", "arbitrary", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the choice of the transforming operators ga", "start": 10, "end": 53, "i_start": 1, "i_end": 7}, "verb": {"text": "can be", "start": 54, "end": 60, "i_start": 8, "i_end": 9}}, {"character": {"text": "completely", "start": 61, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "operators", "start": 41, "end": 50, "i_start": 6, "i_end": 6}}, {"character": {"text": "completely", "start": 61, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "transforming", "start": 28, "end": 40, "i_start": 5, "i_end": 5}}], "id": 3420}, {"sent": "meyer , in valence fluctuation in solids , edited by l .", "tokens": ["meyer", ",", "in", "valence", "fluctuation", "in", "solids", ",", "edited", "by", "l", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "meyer", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "edited", "start": 43, "end": 49, "i_start": 8, "i_end": 8}}], "id": 3421}, {"sent": "the stability of the bifurcating periodic solutions and the direction of the hopf bifurcation are determined by applying the normal form theory .", "tokens": ["the", "stability", "of", "the", "bifurcating", "periodic", "solutions", "and", "the", "direction", "of", "the", "hopf", "bifurcation", "are", "determined", "by", "applying", "the", "normal", "form", "theory", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "the stability of the bifurcating periodic solutions and the direction of the hopf bifurcation", "start": 0, "end": 93, "i_start": 0, "i_end": 13}, "verb": {"text": "are determined", "start": 94, "end": 108, "i_start": 14, "i_end": 15}}, {"character": {"text": "applying", "start": 112, "end": 120, "i_start": 17, "i_end": 17}, "action": {"text": "determined", "start": 98, "end": 108, "i_start": 15, "i_end": 15}}], "id": 3422}, {"sent": "using the output of the game environment , reference generation block within the control architecture uses the algorithms developed by the authors for generating human-like motions considering the scapulohumeral rhythms .", "tokens": ["using", "the", "output", "of", "the", "game", "environment", ",", "reference", "generation", "block", "within", "the", "control", "architecture", "uses", "the", "algorithms", "developed", "by", "the", "authors", "for", "generating", "human", "-", "like", "motions", "considering", "the", "scapulohumeral", "rhythms", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "reference generation block within the control architecture", "start": 43, "end": 101, "i_start": 8, "i_end": 14}, "verb": {"text": "uses", "start": 102, "end": 106, "i_start": 15, "i_end": 15}}, {"character": {"text": "block", "start": 64, "end": 69, "i_start": 10, "i_end": 10}, "action": {"text": "using", "start": 0, "end": 5, "i_start": 0, "i_end": 0}}, {"character": {"text": "block", "start": 64, "end": 69, "i_start": 10, "i_end": 10}, "action": {"text": "generating", "start": 151, "end": 161, "i_start": 23, "i_end": 23}}, {"character": {"text": "block", "start": 64, "end": 69, "i_start": 10, "i_end": 10}, "action": {"text": "uses", "start": 102, "end": 106, "i_start": 15, "i_end": 15}}], "id": 3423}, {"sent": "convolutional neural networks have achieved state-of-the-art accuracy in computer vision tasks such as image recognition .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "accuracy", "in", "computer", "vision", "tasks", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 3424}, {"sent": "although not every graph property has a threshold in a random graph , it is a well-known fact that every monotonic graph property does .", "tokens": ["although", "not", "every", "graph", "property", "has", "a", "threshold", "in", "a", "random", "graph", ",", "it", "is", "a", "well", "-", "known", "fact", "that", "every", "monotonic", "graph", "property", "does", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 70, "end": 72, "i_start": 13, "i_end": 13}, "verb": {"text": "is", "start": 73, "end": 75, "i_start": 14, "i_end": 14}}, {"character": {"text": "property", "start": 121, "end": 129, "i_start": 24, "i_end": 24}, "action": {"text": "not", "start": 9, "end": 12, "i_start": 1, "i_end": 1}}], "id": 3425}, {"sent": "then , hou et al introduce dense short connections to the skip-layers within the holistically-nested edge detection architecture to get rich multi-scale features for sod .", "tokens": ["then", ",", "hou", "et", "al", "introduce", "dense", "short", "connections", "to", "the", "skip", "-", "layers", "within", "the", "holistically", "-", "nested", "edge", "detection", "architecture", "to", "get", "rich", "multi", "-", "scale", "features", "for", "sod", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hou et al", "start": 7, "end": 16, "i_start": 2, "i_end": 4}, "verb": {"text": "introduce", "start": 17, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "hou", "start": 7, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "introduce", "start": 17, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "architecture", "start": 116, "end": 128, "i_start": 21, "i_end": 21}, "action": {"text": "detection", "start": 106, "end": 115, "i_start": 20, "i_end": 20}}, {"character": {"text": "hou", "start": 7, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "get", "start": 132, "end": 135, "i_start": 23, "i_end": 23}}], "id": 3426}, {"sent": "the models were trained end-to-end using the adam optimizer with a mini-batch size of 256 .", "tokens": ["the", "models", "were", "trained", "end", "-", "to", "-", "end", "using", "the", "adam", "optimizer", "with", "a", "mini", "-", "batch", "size", "of", "256", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the models", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "were trained", "start": 11, "end": 23, "i_start": 2, "i_end": 3}}], "id": 3427}, {"sent": "the move of the right is understood to be between arcs of different colors .", "tokens": ["the", "move", "of", "the", "right", "is", "understood", "to", "be", "between", "arcs", "of", "different", "colors", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the move of the right", "start": 0, "end": 21, "i_start": 0, "i_end": 4}, "verb": {"text": "is understood", "start": 22, "end": 35, "i_start": 5, "i_end": 6}}, {"character": {"text": "right", "start": 16, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "move", "start": 4, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3428}, {"sent": "the analysis makes use of the particle-flow event algorithm , which reconstructs and identifies each individual particle with an optimized combination of information from the various elements of the cms detector .", "tokens": ["the", "analysis", "makes", "use", "of", "the", "particle", "-", "flow", "event", "algorithm", ",", "which", "reconstructs", "and", "identifies", "each", "individual", "particle", "with", "an", "optimized", "combination", "of", "information", "from", "the", "various", "elements", "of", "the", "cms", "detector", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the analysis", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "makes", "start": 13, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "analysis", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "use", "start": 19, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithm", "start": 50, "end": 59, "i_start": 10, "i_end": 10}, "action": {"text": "reconstructs", "start": 68, "end": 80, "i_start": 13, "i_end": 13}}, {"character": {"text": "algorithm", "start": 50, "end": 59, "i_start": 10, "i_end": 10}, "action": {"text": "identifies", "start": 85, "end": 95, "i_start": 15, "i_end": 15}}], "id": 3429}, {"sent": "if \u03c3 is inverible , it is called an isomorphism .", "tokens": ["if", "\u03c3", "is", "inverible", ",", "it", "is", "called", "an", "isomorphism", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 20, "end": 22, "i_start": 5, "i_end": 5}, "verb": {"text": "is called", "start": 23, "end": 32, "i_start": 6, "i_end": 7}}], "id": 3430}, {"sent": "the generative adversarial network is an emerging deep learning technique aimed at modeling highdimensional data distributions .", "tokens": ["the", "generative", "adversarial", "network", "is", "an", "emerging", "deep", "learning", "technique", "aimed", "at", "modeling", "highdimensional", "data", "distributions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the generative adversarial network", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "technique", "start": 64, "end": 73, "i_start": 9, "i_end": 9}, "action": {"text": "aimed", "start": 74, "end": 79, "i_start": 10, "i_end": 10}}, {"character": {"text": "technique", "start": 64, "end": 73, "i_start": 9, "i_end": 9}, "action": {"text": "emerging", "start": 41, "end": 49, "i_start": 6, "i_end": 6}}], "id": 3431}, {"sent": "introduction to the theory of linear nonselfadjoint operators .", "tokens": ["introduction", "to", "the", "theory", "of", "linear", "nonselfadjoint", "operators", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3432}, {"sent": "thus , the limit zero distributions of the heine-stieltjes polynomials are given by continuous critical measures .", "tokens": ["thus", ",", "the", "limit", "zero", "distributions", "of", "the", "heine", "-", "stieltjes", "polynomials", "are", "given", "by", "continuous", "critical", "measures", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the limit zero distributions of the heine-stieltjes polynomials", "start": 7, "end": 70, "i_start": 2, "i_end": 11}, "verb": {"text": "are given", "start": 71, "end": 80, "i_start": 12, "i_end": 13}}], "id": 3433}, {"sent": "another distinct feature of the quantum kicked rotor is the effect of quantum resonance .", "tokens": ["another", "distinct", "feature", "of", "the", "quantum", "kicked", "rotor", "is", "the", "effect", "of", "quantum", "resonance", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another distinct feature of the quantum kicked rotor", "start": 0, "end": 52, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 53, "end": 55, "i_start": 8, "i_end": 8}}], "id": 3434}, {"sent": "from these examples it is clear that we can have pure neutrosophic interval polynomial subsemigroups which are not ideals .", "tokens": ["from", "these", "examples", "it", "is", "clear", "that", "we", "can", "have", "pure", "neutrosophic", "interval", "polynomial", "subsemigroups", "which", "are", "not", "ideals", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 4, "i_end": 4}}, {"subject": {"text": "we", "start": 37, "end": 39, "i_start": 7, "i_end": 7}, "verb": {"text": "have", "start": 44, "end": 48, "i_start": 9, "i_end": 9}}, {"character": {"text": "examples", "start": 11, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "clear", "start": 26, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 37, "end": 39, "i_start": 7, "i_end": 7}, "action": {"text": "have", "start": 44, "end": 48, "i_start": 9, "i_end": 9}}], "id": 3435}, {"sent": "the weyl calculus of pseudo-differential operators .", "tokens": ["the", "weyl", "calculus", "of", "pseudo", "-", "differential", "operators", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3436}, {"sent": "note that dls are decidable fragments of first order logic that are incomparable with horn clausal logic as regards the expressive power and the semantics .", "tokens": ["note", "that", "dls", "are", "decidable", "fragments", "of", "first", "order", "logic", "that", "are", "incomparable", "with", "horn", "clausal", "logic", "as", "regards", "the", "expressive", "power", "and", "the", "semantics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "power", "start": 131, "end": 136, "i_start": 21, "i_end": 21}, "action": {"text": "expressive", "start": 120, "end": 130, "i_start": 20, "i_end": 20}}], "id": 3437}, {"sent": "the derivation , outlined in , is based on the iterated mayer expansion for a one-dimensional non-ideal gas .", "tokens": ["the", "derivation", ",", "outlined", "in", ",", "is", "based", "on", "the", "iterated", "mayer", "expansion", "for", "a", "one", "-", "dimensional", "non", "-", "ideal", "gas", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the derivation", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is based", "start": 31, "end": 39, "i_start": 6, "i_end": 7}}], "id": 3438}, {"sent": "a method for producing and evaluating probabilistic forecasts from ensemble model integrations .", "tokens": ["a", "method", "for", "producing", "and", "evaluating", "probabilistic", "forecasts", "from", "ensemble", "model", "integrations", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3439}, {"sent": "this allows us to maximize the log posterior distribution using the e-m algorithm .", "tokens": ["this", "allows", "us", "to", "maximize", "the", "log", "posterior", "distribution", "using", "the", "e", "-", "m", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "allows", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}, {"subject": {"text": "us", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "maximize", "start": 18, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "allows", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "us", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "maximize", "start": 18, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "us", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "using", "start": 58, "end": 63, "i_start": 9, "i_end": 9}}], "id": 3440}, {"sent": "cosmic strings are topological defects that may have formed at phase transitions as the universe expanded and cooled .", "tokens": ["cosmic", "strings", "are", "topological", "defects", "that", "may", "have", "formed", "at", "phase", "transitions", "as", "the", "universe", "expanded", "and", "cooled", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3441}, {"sent": "the interactions between the ions and the electrons are described by the projectoraugmented wave method with a cutoff energy of 600 ev .", "tokens": ["the", "interactions", "between", "the", "ions", "and", "the", "electrons", "are", "described", "by", "the", "projectoraugmented", "wave", "method", "with", "a", "cutoff", "energy", "of", "600", "ev", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the interactions between the ions and the electrons", "start": 0, "end": 51, "i_start": 0, "i_end": 7}, "verb": {"text": "are described", "start": 52, "end": 65, "i_start": 8, "i_end": 9}}, {"character": {"text": "method", "start": 97, "end": 103, "i_start": 14, "i_end": 14}, "action": {"text": "described", "start": 56, "end": 65, "i_start": 9, "i_end": 9}}, {"character": {"text": "ions", "start": 29, "end": 33, "i_start": 4, "i_end": 4}, "action": {"text": "interactions", "start": 4, "end": 16, "i_start": 1, "i_end": 1}}], "id": 3442}, {"sent": "on the kp-i transonic limit of two-dimensional gross-pitaevskii travelling waves .", "tokens": ["on", "the", "kp", "-", "i", "transonic", "limit", "of", "two", "-", "dimensional", "gross", "-", "pitaevskii", "travelling", "waves", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "waves", "start": 75, "end": 80, "i_start": 15, "i_end": 15}, "action": {"text": "travelling", "start": 64, "end": 74, "i_start": 14, "i_end": 14}}], "id": 3443}, {"sent": "also , a fock state and a superposition of fock states of a single microwave resonator has been created experimentally .", "tokens": ["also", ",", "a", "fock", "state", "and", "a", "superposition", "of", "fock", "states", "of", "a", "single", "microwave", "resonator", "has", "been", "created", "experimentally", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a fock state and a superposition of fock states of a single microwave resonator", "start": 7, "end": 86, "i_start": 2, "i_end": 15}, "verb": {"text": "has been created", "start": 87, "end": 103, "i_start": 16, "i_end": 18}}], "id": 3444}, {"sent": "the evolution of convolutional neural networks has constantly pushed the boundaries of complex vision tasks .", "tokens": ["the", "evolution", "of", "convolutional", "neural", "networks", "has", "constantly", "pushed", "the", "boundaries", "of", "complex", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the evolution of convolutional neural networks", "start": 0, "end": 46, "i_start": 0, "i_end": 5}, "verb": {"text": "pushed", "start": 62, "end": 68, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the evolution of convolutional neural networks", "start": 0, "end": 46, "i_start": 0, "i_end": 5}, "verb": {"text": "has", "start": 47, "end": 50, "i_start": 6, "i_end": 6}}, {"character": {"text": "evolution", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "pushed", "start": 62, "end": 68, "i_start": 8, "i_end": 8}}], "id": 3445}, {"sent": "further results include work on controllable discrete-time linear systems .", "tokens": ["further", "results", "include", "work", "on", "controllable", "discrete", "-", "time", "linear", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "further results", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "include", "start": 16, "end": 23, "i_start": 2, "i_end": 2}}], "id": 3446}, {"sent": "we therefore conclude that clonal interference likely occurs in neoplasms related to colon cancer , and possibly in other pre-cancerous tissues with spatial character .", "tokens": ["we", "therefore", "conclude", "that", "clonal", "interference", "likely", "occurs", "in", "neoplasms", "related", "to", "colon", "cancer", ",", "and", "possibly", "in", "other", "pre", "-", "cancerous", "tissues", "with", "spatial", "character", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "conclude", "start": 13, "end": 21, "i_start": 2, "i_end": 2}}, {"subject": {"text": "clonal interference", "start": 27, "end": 46, "i_start": 4, "i_end": 5}, "verb": {"text": "occurs", "start": 54, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "conclude", "start": 13, "end": 21, "i_start": 2, "i_end": 2}}], "id": 3447}, {"sent": "a class of fully nonlinear bspdes , the so-called backward stochastic hamilton-jacobi-bellman equations , appear naturally in the dynamic programming theory of controlled non-markovian processes .", "tokens": ["a", "class", "of", "fully", "nonlinear", "bspdes", ",", "the", "so", "-", "called", "backward", "stochastic", "hamilton", "-", "jacobi", "-", "bellman", "equations", ",", "appear", "naturally", "in", "the", "dynamic", "programming", "theory", "of", "controlled", "non", "-", "markovian", "processes", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "a class of fully nonlinear bspdes", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "appear", "start": 106, "end": 112, "i_start": 20, "i_end": 20}}], "id": 3448}, {"sent": "for the decision trees as well as the random forests , we use the the scikit-learn implementation .", "tokens": ["for", "the", "decision", "trees", "as", "well", "as", "the", "random", "forests", ",", "we", "use", "the", "the", "scikit", "-", "learn", "implementation", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 55, "end": 57, "i_start": 11, "i_end": 11}, "verb": {"text": "use", "start": 58, "end": 61, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 55, "end": 57, "i_start": 11, "i_end": 11}, "action": {"text": "use", "start": 58, "end": 61, "i_start": 12, "i_end": 12}}], "id": 3449}, {"sent": "with the availability of large amount of training data and powerful gpus , convolutional neural networks have achieved breakthroughs in visual recognition , and these deep networks are used for image feature learning .", "tokens": ["with", "the", "availability", "of", "large", "amount", "of", "training", "data", "and", "powerful", "gpus", ",", "convolutional", "neural", "networks", "have", "achieved", "breakthroughs", "in", "visual", "recognition", ",", "and", "these", "deep", "networks", "are", "used", "for", "image", "feature", "learning", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 75, "end": 104, "i_start": 13, "i_end": 15}, "verb": {"text": "have achieved", "start": 105, "end": 118, "i_start": 16, "i_end": 17}}, {"subject": {"text": "these deep networks", "start": 161, "end": 180, "i_start": 24, "i_end": 26}, "verb": {"text": "used", "start": 185, "end": 189, "i_start": 28, "i_end": 28}}, {"character": {"text": "networks", "start": 96, "end": 104, "i_start": 15, "i_end": 15}, "action": {"text": "achieved", "start": 110, "end": 118, "i_start": 17, "i_end": 17}}, {"character": {"text": "networks", "start": 96, "end": 104, "i_start": 15, "i_end": 15}, "action": {"text": "breakthroughs", "start": 119, "end": 132, "i_start": 18, "i_end": 18}}], "id": 3450}, {"sent": "the foliation induced by this line field is called the characteristic foliation .", "tokens": ["the", "foliation", "induced", "by", "this", "line", "field", "is", "called", "the", "characteristic", "foliation", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the foliation induced by this line field", "start": 0, "end": 40, "i_start": 0, "i_end": 6}, "verb": {"text": "is called", "start": 41, "end": 50, "i_start": 7, "i_end": 8}}, {"character": {"text": "field", "start": 35, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "induced", "start": 14, "end": 21, "i_start": 2, "i_end": 2}}], "id": 3451}, {"sent": "floer homology for manifolds with contact type boundary or symplectic homology .", "tokens": ["floer", "homology", "for", "manifolds", "with", "contact", "type", "boundary", "or", "symplectic", "homology", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3452}, {"sent": "the electronelectron exchange and correlation functional was described with the perdew-burke-ernzerhof 22 parametrization of the generalized gradient approximation .", "tokens": ["the", "electronelectron", "exchange", "and", "correlation", "functional", "was", "described", "with", "the", "perdew", "-", "burke", "-", "ernzerhof", "22", "parametrization", "of", "the", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electronelectron exchange and correlation functional", "start": 0, "end": 56, "i_start": 0, "i_end": 5}, "verb": {"text": "was described", "start": 57, "end": 70, "i_start": 6, "i_end": 7}}], "id": 3453}, {"sent": "irl is a popular framework for learning reward functions from human demonstrations .", "tokens": ["irl", "is", "a", "popular", "framework", "for", "learning", "reward", "functions", "from", "human", "demonstrations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "irl", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 4, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "human", "start": 62, "end": 67, "i_start": 10, "i_end": 10}, "action": {"text": "demonstrations", "start": 68, "end": 82, "i_start": 11, "i_end": 11}}], "id": 3454}, {"sent": "piewak et al trained a neural network to reduce false positive velocity estimation in a dogma sequence .", "tokens": ["piewak", "et", "al", "trained", "a", "neural", "network", "to", "reduce", "false", "positive", "velocity", "estimation", "in", "a", "dogma", "sequence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "piewak et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "trained", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "piewak", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "trained", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "network", "start": 30, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "reduce", "start": 41, "end": 47, "i_start": 8, "i_end": 8}}], "id": 3455}, {"sent": "the parameter cpnc is used in the modeling the nuclear density function in the pnc hamiltonian .", "tokens": ["the", "parameter", "cpnc", "is", "used", "in", "the", "modeling", "the", "nuclear", "density", "function", "in", "the", "pnc", "hamiltonian", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the parameter cpnc", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is used", "start": 19, "end": 26, "i_start": 3, "i_end": 4}}], "id": 3456}, {"sent": "abnormal event detection is commonly formalized as an outlier detection task , in which the main approach is to learn a model of familiarity from training videos and label the detected outliers as abnormal .", "tokens": ["abnormal", "event", "detection", "is", "commonly", "formalized", "as", "an", "outlier", "detection", "task", ",", "in", "which", "the", "main", "approach", "is", "to", "learn", "a", "model", "of", "familiarity", "from", "training", "videos", "and", "label", "the", "detected", "outliers", "as", "abnormal", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "abnormal event detection", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "formalized", "start": 37, "end": 47, "i_start": 5, "i_end": 5}}, {"subject": {"text": "abnormal event detection", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 3, "i_end": 3}}], "id": 3457}, {"sent": "each convolutional layer is followed by a batch normalization operation .", "tokens": ["each", "convolutional", "layer", "is", "followed", "by", "a", "batch", "normalization", "operation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each convolutional layer", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is followed", "start": 25, "end": 36, "i_start": 3, "i_end": 4}}], "id": 3458}, {"sent": "recently , deep neural network has been successfully used to interpret complicated data sets and applied to tasks with pattern recognition , such as image recognition , speech recognition and natural language processing .", "tokens": ["recently", ",", "deep", "neural", "network", "has", "been", "successfully", "used", "to", "interpret", "complicated", "data", "sets", "and", "applied", "to", "tasks", "with", "pattern", "recognition", ",", "such", "as", "image", "recognition", ",", "speech", "recognition", "and", "natural", "language", "processing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural network", "start": 11, "end": 30, "i_start": 2, "i_end": 4}, "verb": {"text": "used", "start": 53, "end": 57, "i_start": 8, "i_end": 8}}, {"subject": {"text": "deep neural network", "start": 11, "end": 30, "i_start": 2, "i_end": 4}, "verb": {"text": "has been", "start": 31, "end": 39, "i_start": 5, "i_end": 6}}, {"subject": {"text": "deep neural network", "start": 11, "end": 30, "i_start": 2, "i_end": 4}, "verb": {"text": "applied", "start": 97, "end": 104, "i_start": 15, "i_end": 15}}], "id": 3459}, {"sent": "deep convolutional networks are now commonly used to learn state-of-the-art models for visual recognition , including image classification .", "tokens": ["deep", "convolutional", "networks", "are", "now", "commonly", "used", "to", "learn", "state", "-", "of", "-", "the", "-", "art", "models", "for", "visual", "recognition", ",", "including", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional networks", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 45, "end": 49, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional networks", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 28, "end": 31, "i_start": 3, "i_end": 3}}], "id": 3460}, {"sent": "a resource derivation is total if its assignment of the boolean variables is total .", "tokens": ["a", "resource", "derivation", "is", "total", "if", "its", "assignment", "of", "the", "boolean", "variables", "is", "total", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a resource derivation", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "derivation", "start": 11, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "assignment", "start": 38, "end": 48, "i_start": 7, "i_end": 7}}], "id": 3461}, {"sent": "the most common criteria are capacity maximization and data mean-square-error minimization .", "tokens": ["the", "most", "common", "criteria", "are", "capacity", "maximization", "and", "data", "mean", "-", "square", "-", "error", "minimization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most common criteria", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 25, "end": 28, "i_start": 4, "i_end": 4}}], "id": 3462}, {"sent": "hill et al proposed the sequential denoising autoencoder , which slightly corrupts the input sentence by adding random noise .", "tokens": ["hill", "et", "al", "proposed", "the", "sequential", "denoising", "autoencoder", ",", "which", "slightly", "corrupts", "the", "input", "sentence", "by", "adding", "random", "noise", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hill et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "hill", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "autoencoder", "start": 45, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "denoising", "start": 35, "end": 44, "i_start": 6, "i_end": 6}}, {"character": {"text": "autoencoder", "start": 45, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "corrupts", "start": 74, "end": 82, "i_start": 11, "i_end": 11}}, {"character": {"text": "autoencoder", "start": 45, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "adding", "start": 105, "end": 111, "i_start": 16, "i_end": 16}}], "id": 3463}, {"sent": "bengio et al first proposed the concept of a neural language model , and this concept has been explored mainly with recurrent neural networks .", "tokens": ["bengio", "et", "al", "first", "proposed", "the", "concept", "of", "a", "neural", "language", "model", ",", "and", "this", "concept", "has", "been", "explored", "mainly", "with", "recurrent", "neural", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bengio et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 19, "end": 27, "i_start": 4, "i_end": 4}}, {"subject": {"text": "this concept", "start": 73, "end": 85, "i_start": 14, "i_end": 15}, "verb": {"text": "explored", "start": 95, "end": 103, "i_start": 18, "i_end": 18}}, {"character": {"text": "bengio", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 19, "end": 27, "i_start": 4, "i_end": 4}}], "id": 3464}, {"sent": "the data were calibrated and reduced using the miriad 2 software package .", "tokens": ["the", "data", "were", "calibrated", "and", "reduced", "using", "the", "miriad", "2", "software", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "were calibrated", "start": 9, "end": 24, "i_start": 2, "i_end": 3}}, {"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "reduced", "start": 29, "end": 36, "i_start": 5, "i_end": 5}}], "id": 3465}, {"sent": "we also used the risk factors of fama and french , that is , the size factor , value factor and a short-term reversal factor .", "tokens": ["we", "also", "used", "the", "risk", "factors", "of", "fama", "and", "french", ",", "that", "is", ",", "the", "size", "factor", ",", "value", "factor", "and", "a", "short", "-", "term", "reversal", "factor", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}], "id": 3466}, {"sent": "the entropy of the simplest structure becomes log gdof because there is gdof flavors of the scalar fields in the theory and the single quantum belongs to one of the gdof flavors .", "tokens": ["the", "entropy", "of", "the", "simplest", "structure", "becomes", "log", "gdof", "because", "there", "is", "gdof", "flavors", "of", "the", "scalar", "fields", "in", "the", "theory", "and", "the", "single", "quantum", "belongs", "to", "one", "of", "the", "gdof", "flavors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the entropy of the simplest structure", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "becomes", "start": 38, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "flavors", "start": 77, "end": 84, "i_start": 13, "i_end": 13}, "action": {"text": "because", "start": 55, "end": 62, "i_start": 9, "i_end": 9}}, {"character": {"text": "gdof", "start": 50, "end": 54, "i_start": 8, "i_end": 8}, "action": {"text": "because", "start": 55, "end": 62, "i_start": 9, "i_end": 9}}, {"character": {"text": "fields", "start": 99, "end": 105, "i_start": 17, "i_end": 17}, "action": {"text": "because", "start": 55, "end": 62, "i_start": 9, "i_end": 9}}, {"character": {"text": "scalar", "start": 92, "end": 98, "i_start": 16, "i_end": 16}, "action": {"text": "because", "start": 55, "end": 62, "i_start": 9, "i_end": 9}}, {"character": {"text": "theory", "start": 113, "end": 119, "i_start": 20, "i_end": 20}, "action": {"text": "because", "start": 55, "end": 62, "i_start": 9, "i_end": 9}}, {"character": {"text": "quantum", "start": 135, "end": 142, "i_start": 24, "i_end": 24}, "action": {"text": "belongs", "start": 143, "end": 150, "i_start": 25, "i_end": 25}}], "id": 3467}, {"sent": "multi-task learning aims at improving the generalization performance of a task using related tasks .", "tokens": ["multi", "-", "task", "learning", "aims", "at", "improving", "the", "generalization", "performance", "of", "a", "task", "using", "related", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "multi-task learning", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "aims", "start": 20, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 11, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "aims", "start": 20, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 11, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "improving", "start": 28, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "task", "start": 74, "end": 78, "i_start": 12, "i_end": 12}, "action": {"text": "performance", "start": 57, "end": 68, "i_start": 9, "i_end": 9}}, {"character": {"text": "task", "start": 74, "end": 78, "i_start": 12, "i_end": 12}, "action": {"text": "using", "start": 79, "end": 84, "i_start": 13, "i_end": 13}}], "id": 3468}, {"sent": "it is easily seen that -map graphs are precisely the graphs of euler genus at most g .", "tokens": ["it", "is", "easily", "seen", "that", "-map", "graphs", "are", "precisely", "the", "graphs", "of", "euler", "genus", "at", "most", "g", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "seen", "start": 13, "end": 17, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 35, "end": 38, "i_start": 7, "i_end": 7}}], "id": 3469}, {"sent": "the original model by steels , was constructed to account for the emergence of shared vocabularies or conventions in a community of interacting agents .", "tokens": ["the", "original", "model", "by", "steels", ",", "was", "constructed", "to", "account", "for", "the", "emergence", "of", "shared", "vocabularies", "or", "conventions", "in", "a", "community", "of", "interacting", "agents", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the original model by steels", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "was constructed", "start": 31, "end": 46, "i_start": 6, "i_end": 7}}, {"character": {"text": "model", "start": 13, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "account", "start": 50, "end": 57, "i_start": 9, "i_end": 9}}, {"character": {"text": "community", "start": 119, "end": 128, "i_start": 20, "i_end": 20}, "action": {"text": "emergence", "start": 66, "end": 75, "i_start": 12, "i_end": 12}}, {"character": {"text": "agents", "start": 144, "end": 150, "i_start": 23, "i_end": 23}, "action": {"text": "interacting", "start": 132, "end": 143, "i_start": 22, "i_end": 22}}], "id": 3470}, {"sent": "the universal approximation theorem establishes that every continuous function on a compact domain can be uniformly approximated by neural networks .", "tokens": ["the", "universal", "approximation", "theorem", "establishes", "that", "every", "continuous", "function", "on", "a", "compact", "domain", "can", "be", "uniformly", "approximated", "by", "neural", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the universal approximation theorem", "start": 0, "end": 35, "i_start": 0, "i_end": 3}, "verb": {"text": "establishes", "start": 36, "end": 47, "i_start": 4, "i_end": 4}}, {"subject": {"text": "every continuous function on a compact domain", "start": 53, "end": 98, "i_start": 6, "i_end": 12}, "verb": {"text": "approximated", "start": 116, "end": 128, "i_start": 16, "i_end": 16}}, {"character": {"text": "theorem", "start": 28, "end": 35, "i_start": 3, "i_end": 3}, "action": {"text": "establishes", "start": 36, "end": 47, "i_start": 4, "i_end": 4}}], "id": 3471}, {"sent": "the first approach utilizes 3d models for each face in the gallery , either inferred statistically .", "tokens": ["the", "first", "approach", "utilizes", "3d", "models", "for", "each", "face", "in", "the", "gallery", ",", "either", "inferred", "statistically", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the first approach", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "utilizes", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "approach", "start": 10, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "utilizes", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}], "id": 3472}, {"sent": "in fact it was shown in that the master space for four dimensional seiberg dual theories are not in general isomorphic .", "tokens": ["in", "fact", "it", "was", "shown", "in", "that", "the", "master", "space", "for", "four", "dimensional", "seiberg", "dual", "theories", "are", "not", "in", "general", "isomorphic", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "was shown", "start": 11, "end": 20, "i_start": 3, "i_end": 4}}, {"subject": {"text": "it", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "are", "start": 89, "end": 92, "i_start": 16, "i_end": 16}}], "id": 3473}, {"sent": "an algorithm very commonly used in practice to determine the total space of possible resultant wrenches as long as each individual contact force obeys friction constraints was introduced by ferrari and canny .", "tokens": ["an", "algorithm", "very", "commonly", "used", "in", "practice", "to", "determine", "the", "total", "space", "of", "possible", "resultant", "wrenches", "as", "long", "as", "each", "individual", "contact", "force", "obeys", "friction", "constraints", "was", "introduced", "by", "ferrari", "and", "canny", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "an algorithm very commonly used in practice to determine the total space of possible resultant wrenches as long as each individual contact force obeys friction constraints", "start": 0, "end": 171, "i_start": 0, "i_end": 25}, "verb": {"text": "was introduced", "start": 172, "end": 186, "i_start": 26, "i_end": 27}}, {"character": {"text": "ferrari", "start": 190, "end": 197, "i_start": 29, "i_end": 29}, "action": {"text": "introduced", "start": 176, "end": 186, "i_start": 27, "i_end": 27}}, {"character": {"text": "canny", "start": 202, "end": 207, "i_start": 31, "i_end": 31}, "action": {"text": "introduced", "start": 176, "end": 186, "i_start": 27, "i_end": 27}}, {"character": {"text": "force", "start": 139, "end": 144, "i_start": 22, "i_end": 22}, "action": {"text": "obeys", "start": 145, "end": 150, "i_start": 23, "i_end": 23}}, {"character": {"text": "force", "start": 139, "end": 144, "i_start": 22, "i_end": 22}, "action": {"text": "contact", "start": 131, "end": 138, "i_start": 21, "i_end": 21}}], "id": 3474}, {"sent": "note that the circular trajectory is considered since it not only enables the uav to serve the cell-edge users cyclically , but is also one practical trajectory adopted to save the uav energy consumption .", "tokens": ["note", "that", "the", "circular", "trajectory", "is", "considered", "since", "it", "not", "only", "enables", "the", "uav", "to", "serve", "the", "cell", "-", "edge", "users", "cyclically", ",", "but", "is", "also", "one", "practical", "trajectory", "adopted", "to", "save", "the", "uav", "energy", "consumption", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the circular trajectory", "start": 10, "end": 33, "i_start": 2, "i_end": 4}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "the circular trajectory", "start": 10, "end": 33, "i_start": 2, "i_end": 4}, "verb": {"text": "considered", "start": 37, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "trajectory", "start": 23, "end": 33, "i_start": 4, "i_end": 4}, "action": {"text": "enables", "start": 66, "end": 73, "i_start": 11, "i_end": 11}}], "id": 3475}, {"sent": "section 3 discusses the issues of the method in chen and zhang when the sequence is locally dependent , and proposes a new permutation framework to address the issue .", "tokens": ["section", "3", "discusses", "the", "issues", "of", "the", "method", "in", "chen", "and", "zhang", "when", "the", "sequence", "is", "locally", "dependent", ",", "and", "proposes", "a", "new", "permutation", "framework", "to", "address", "the", "issue", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "section 3", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "discusses", "start": 10, "end": 19, "i_start": 2, "i_end": 2}}, {"subject": {"text": "section 3", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "proposes", "start": 108, "end": 116, "i_start": 20, "i_end": 20}}, {"character": {"text": "section 3", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "action": {"text": "discusses", "start": 10, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "method", "start": 38, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "issues", "start": 24, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "sequence", "start": 72, "end": 80, "i_start": 14, "i_end": 14}, "action": {"text": "dependent", "start": 92, "end": 101, "i_start": 17, "i_end": 17}}], "id": 3476}, {"sent": "characterize those s-group rings which are s-artinian .", "tokens": ["characterize", "those", "s", "-", "group", "rings", "which", "are", "s", "-", "artinian", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3477}, {"sent": "quasi-einstein manifolds satisfying some pseudosymmetry type conditions were investigated among others in .", "tokens": ["quasi", "-", "einstein", "manifolds", "satisfying", "some", "pseudosymmetry", "type", "conditions", "were", "investigated", "among", "others", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "quasi-einstein manifolds", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "satisfying", "start": 25, "end": 35, "i_start": 4, "i_end": 4}}, {"subject": {"text": "quasi-einstein manifolds", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "investigated", "start": 77, "end": 89, "i_start": 10, "i_end": 10}}, {"character": {"text": "manifolds", "start": 15, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "satisfying", "start": 25, "end": 35, "i_start": 4, "i_end": 4}}], "id": 3478}, {"sent": "adaptive estimation of analytic functions on an interval .", "tokens": ["adaptive", "estimation", "of", "analytic", "functions", "on", "an", "interval", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3479}, {"sent": "to do this , we first use reduze2 to shift loop momenta to get suitable integral classes .", "tokens": ["to", "do", "this", ",", "we", "first", "use", "reduze2", "to", "shift", "loop", "momenta", "to", "get", "suitable", "integral", "classes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 13, "end": 15, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 22, "end": 25, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 22, "end": 25, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 4, "i_end": 4}, "action": {"text": "shift", "start": 37, "end": 42, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 4, "i_end": 4}, "action": {"text": "get", "start": 59, "end": 62, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 4, "i_end": 4}, "action": {"text": "do", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}], "id": 3480}, {"sent": "differential privacy constitutes a strong standard for privacy guarantees in statistical databases .", "tokens": ["differential", "privacy", "constitutes", "a", "strong", "standard", "for", "privacy", "guarantees", "in", "statistical", "databases", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "differential privacy", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "constitutes", "start": 21, "end": 32, "i_start": 2, "i_end": 2}}, {"character": {"text": "privacy", "start": 13, "end": 20, "i_start": 1, "i_end": 1}, "action": {"text": "constitutes", "start": 21, "end": 32, "i_start": 2, "i_end": 2}}], "id": 3481}, {"sent": "yu et al improved this by replacing the null symbol with a dedicated learned transition probability .", "tokens": ["yu", "et", "al", "improved", "this", "by", "replacing", "the", "null", "symbol", "with", "a", "dedicated", "learned", "transition", "probability", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "yu et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "improved", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}], "id": 3482}, {"sent": "in recent years , the deep learning models like the cnns have been shown to achieve superior performance in numerous visual perception tasks .", "tokens": ["in", "recent", "years", ",", "the", "deep", "learning", "models", "like", "the", "cnns", "have", "been", "shown", "to", "achieve", "superior", "performance", "in", "numerous", "visual", "perception", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the deep learning models like the cnns", "start": 18, "end": 56, "i_start": 4, "i_end": 10}, "verb": {"text": "have been shown", "start": 57, "end": 72, "i_start": 11, "i_end": 13}}, {"character": {"text": "models", "start": 36, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "achieve", "start": 76, "end": 83, "i_start": 15, "i_end": 15}}, {"character": {"text": "models", "start": 36, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "learning", "start": 27, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "models", "start": 36, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "performance", "start": 93, "end": 104, "i_start": 17, "i_end": 17}}], "id": 3483}, {"sent": "the density space with this metric forms an infinite-dimensional riemannian manifold , named density manifold .", "tokens": ["the", "density", "space", "with", "this", "metric", "forms", "an", "infinite", "-", "dimensional", "riemannian", "manifold", ",", "named", "density", "manifold", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "space", "start": 12, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "forms", "start": 35, "end": 40, "i_start": 6, "i_end": 6}}], "id": 3484}, {"sent": "generative adversarial networks have provided very powerful and efficient solutions for learning the generative model .", "tokens": ["generative", "adversarial", "networks", "have", "provided", "very", "powerful", "and", "efficient", "solutions", "for", "learning", "the", "generative", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "have provided", "start": 32, "end": 45, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "provided", "start": 37, "end": 45, "i_start": 4, "i_end": 4}}], "id": 3485}, {"sent": "each of the layers from l1 to l7 is followed by batch normalization .", "tokens": ["each", "of", "the", "layers", "from", "l1", "to", "l7", "is", "followed", "by", "batch", "normalization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each of the layers from l1 to l7", "start": 0, "end": 32, "i_start": 0, "i_end": 7}, "verb": {"text": "is followed", "start": 33, "end": 44, "i_start": 8, "i_end": 9}}], "id": 3486}, {"sent": "in deep learning for computer vision , object classification and other tasks have improved performance for image understanding .", "tokens": ["in", "deep", "learning", "for", "computer", "vision", ",", "object", "classification", "and", "other", "tasks", "have", "improved", "performance", "for", "image", "understanding", "."], "score": [1, 0, 0, 0, 1], "labels": [{"subject": {"text": "in deep learning for computer vision", "start": 0, "end": 36, "i_start": 0, "i_end": 5}, "verb": {"text": "have improved", "start": 77, "end": 90, "i_start": 12, "i_end": 13}}, {"character": {"text": "classification", "start": 46, "end": 60, "i_start": 8, "i_end": 8}, "action": {"text": "improved", "start": 82, "end": 90, "i_start": 13, "i_end": 13}}, {"character": {"text": "tasks", "start": 71, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "improved", "start": 82, "end": 90, "i_start": 13, "i_end": 13}}, {"character": {"text": "other", "start": 65, "end": 70, "i_start": 10, "i_end": 10}, "action": {"text": "improved", "start": 82, "end": 90, "i_start": 13, "i_end": 13}}], "id": 3487}, {"sent": "reinforcement learning is learning to map situations to actions that maximize a long term objective .", "tokens": ["reinforcement", "learning", "is", "learning", "to", "map", "situations", "to", "actions", "that", "maximize", "a", "long", "term", "objective", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is learning", "start": 23, "end": 34, "i_start": 2, "i_end": 3}}], "id": 3488}, {"sent": "monte carlo simulation is a randomized technique , and thus there is always a nonzero probability that the price obtained by polynomial-time monte carlo simulation is not accurate enough .", "tokens": ["monte", "carlo", "simulation", "is", "a", "randomized", "technique", ",", "and", "thus", "there", "is", "always", "a", "nonzero", "probability", "that", "the", "price", "obtained", "by", "polynomial", "-", "time", "monte", "carlo", "simulation", "is", "not", "accurate", "enough", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "monte carlo simulation", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}, {"subject": {"text": "there", "start": 60, "end": 65, "i_start": 10, "i_end": 10}, "verb": {"text": "is", "start": 66, "end": 68, "i_start": 11, "i_end": 11}}, {"character": {"text": "simulation", "start": 153, "end": 163, "i_start": 26, "i_end": 26}, "action": {"text": "obtained", "start": 113, "end": 121, "i_start": 19, "i_end": 19}}], "id": 3489}, {"sent": "tucker decomposition is a generalization of parafac which computes all interactions between the factor matrices .", "tokens": ["tucker", "decomposition", "is", "a", "generalization", "of", "parafac", "which", "computes", "all", "interactions", "between", "the", "factor", "matrices", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "tucker decomposition", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "tucker", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "decomposition", "start": 7, "end": 20, "i_start": 1, "i_end": 1}}, {"character": {"text": "matrices", "start": 103, "end": 111, "i_start": 14, "i_end": 14}, "action": {"text": "interactions", "start": 71, "end": 83, "i_start": 10, "i_end": 10}}], "id": 3490}, {"sent": "convolutional neural networks have achieved state-of-the-art performance on visual tasks such as image and video recognition in the last few years .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "visual", "tasks", "such", "as", "image", "and", "video", "recognition", "in", "the", "last", "few", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 61, "end": 72, "i_start": 12, "i_end": 12}}], "id": 3491}, {"sent": "to enhance the model , we leverage high-quality dense masks obtained automatically from weak recist labels using grabcut .", "tokens": ["to", "enhance", "the", "model", ",", "we", "leverage", "high", "-", "quality", "dense", "masks", "obtained", "automatically", "from", "weak", "recist", "labels", "using", "grabcut", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "verb": {"text": "leverage", "start": 26, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "action": {"text": "leverage", "start": 26, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "action": {"text": "enhance", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 3492}, {"sent": "the most striking difference is the decrease in strength of the wind features with decreasing metallicity .", "tokens": ["the", "most", "striking", "difference", "is", "the", "decrease", "in", "strength", "of", "the", "wind", "features", "with", "decreasing", "metallicity", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most striking difference", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "difference", "start": 18, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "striking", "start": 9, "end": 17, "i_start": 2, "i_end": 2}}], "id": 3493}, {"sent": "in the recent years , deep convolutional networks have achieved remarkable results in a wide array of computer vision tasks .", "tokens": ["in", "the", "recent", "years", ",", "deep", "convolutional", "networks", "have", "achieved", "remarkable", "results", "in", "a", "wide", "array", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional networks", "start": 22, "end": 49, "i_start": 5, "i_end": 7}, "verb": {"text": "have achieved", "start": 50, "end": 63, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 41, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 55, "end": 63, "i_start": 9, "i_end": 9}}], "id": 3494}, {"sent": "deep convolutional neural networks have been used to great effect in image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "used", "to", "great", "effect", "in", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been used", "start": 35, "end": 49, "i_start": 4, "i_end": 6}}], "id": 3495}, {"sent": "cosmological constant is the most straightforward candidate , however it is ruled out since its observational value but none of them seems to be directly related to some fundamental quantum field theory .", "tokens": ["cosmological", "constant", "is", "the", "most", "straightforward", "candidate", ",", "however", "it", "is", "ruled", "out", "since", "its", "observational", "value", "but", "none", "of", "them", "seems", "to", "be", "directly", "related", "to", "some", "fundamental", "quantum", "field", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmological constant", "start": 0, "end": 21, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 2, "i_end": 2}}, {"subject": {"text": "none of them", "start": 120, "end": 132, "i_start": 18, "i_end": 20}, "verb": {"text": "seems", "start": 133, "end": 138, "i_start": 21, "i_end": 21}}], "id": 3496}, {"sent": "generalized kripke models for epistemic logic .", "tokens": ["generalized", "kripke", "models", "for", "epistemic", "logic", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3497}, {"sent": "now we estimate the holomorphic sectional curvature .", "tokens": ["now", "we", "estimate", "the", "holomorphic", "sectional", "curvature", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "estimate", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "estimate", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}], "id": 3498}, {"sent": "polar codes , first introduced in , were shown to be capacity-achieving for binary input memoryless output symmetric channels .", "tokens": ["polar", "codes", ",", "first", "introduced", "in", ",", "were", "shown", "to", "be", "capacity", "-", "achieving", "for", "binary", "input", "memoryless", "output", "symmetric", "channels", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "polar codes", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "were shown", "start": 36, "end": 46, "i_start": 7, "i_end": 8}}, {"character": {"text": "codes", "start": 6, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "achieving", "start": 62, "end": 71, "i_start": 13, "i_end": 13}}, {"character": {"text": "channels", "start": 117, "end": 125, "i_start": 20, "i_end": 20}, "action": {"text": "-", "start": 61, "end": 62, "i_start": 12, "i_end": 12}}], "id": 3499}, {"sent": "the hilbert series and hwg for nilpotent orbit closures of classical and exceptional groups have been systematically studied in .", "tokens": ["the", "hilbert", "series", "and", "hwg", "for", "nilpotent", "orbit", "closures", "of", "classical", "and", "exceptional", "groups", "have", "been", "systematically", "studied", "in", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the hilbert series and hwg for nilpotent orbit closures of classical and exceptional groups", "start": 0, "end": 91, "i_start": 0, "i_end": 13}, "verb": {"text": "studied", "start": 117, "end": 124, "i_start": 17, "i_end": 17}}, {"subject": {"text": "the hilbert series and hwg for nilpotent orbit closures of classical and exceptional groups", "start": 0, "end": 91, "i_start": 0, "i_end": 13}, "verb": {"text": "have been", "start": 92, "end": 101, "i_start": 14, "i_end": 15}}, {"character": {"text": "groups", "start": 85, "end": 91, "i_start": 13, "i_end": 13}, "action": {"text": "orbit", "start": 41, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "classical", "start": 59, "end": 68, "i_start": 10, "i_end": 10}, "action": {"text": "orbit", "start": 41, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "exceptional", "start": 73, "end": 84, "i_start": 12, "i_end": 12}, "action": {"text": "orbit", "start": 41, "end": 46, "i_start": 7, "i_end": 7}}], "id": 3500}, {"sent": "deep convolutional neural networks have made significant progress in classification problems , which have shown to generate good results when provided sufficient data .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "significant", "progress", "in", "classification", "problems", ",", "which", "have", "shown", "to", "generate", "good", "results", "when", "provided", "sufficient", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "problems", "start": 84, "end": 92, "i_start": 10, "i_end": 10}, "action": {"text": "generate", "start": 115, "end": 123, "i_start": 16, "i_end": 16}}, {"character": {"text": "data", "start": 162, "end": 166, "i_start": 22, "i_end": 22}, "action": {"text": "sufficient", "start": 151, "end": 161, "i_start": 21, "i_end": 21}}], "id": 3501}, {"sent": "recently a great deal of progress has been made in understanding the general structure of supersymmetric solutions of supergravity theories .", "tokens": ["recently", "a", "great", "deal", "of", "progress", "has", "been", "made", "in", "understanding", "the", "general", "structure", "of", "supersymmetric", "solutions", "of", "supergravity", "theories", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a great deal of progress", "start": 9, "end": 33, "i_start": 1, "i_end": 5}, "verb": {"text": "has been made", "start": 34, "end": 47, "i_start": 6, "i_end": 8}}], "id": 3502}, {"sent": "kamowitz , compact endomorphisms of banach algebras , pac .", "tokens": ["kamowitz", ",", "compact", "endomorphisms", "of", "banach", "algebras", ",", "pac", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3503}, {"sent": "there is a substantial body of work that deals with the learning of various types of single agent mab problems .", "tokens": ["there", "is", "a", "substantial", "body", "of", "work", "that", "deals", "with", "the", "learning", "of", "various", "types", "of", "single", "agent", "mab", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "body", "start": 23, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "deals", "start": 41, "end": 46, "i_start": 8, "i_end": 8}}], "id": 3504}, {"sent": "it is well known that s 1 and s 3 are the only compact connected lie groups which have free differentiable actions on homotopy spheres , .", "tokens": ["it", "is", "well", "known", "that", "s", "1", "and", "s", "3", "are", "the", "only", "compact", "connected", "lie", "groups", "which", "have", "free", "differentiable", "actions", "on", "homotopy", "spheres", ",", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"character": {"text": "groups", "start": 69, "end": 75, "i_start": 16, "i_end": 16}, "action": {"text": "lie", "start": 65, "end": 68, "i_start": 15, "i_end": 15}}, {"character": {"text": "groups", "start": 69, "end": 75, "i_start": 16, "i_end": 16}, "action": {"text": "have", "start": 82, "end": 86, "i_start": 18, "i_end": 18}}], "id": 3505}, {"sent": "the most outstanding feature is the possibility of playing net games against other players .", "tokens": ["the", "most", "outstanding", "feature", "is", "the", "possibility", "of", "playing", "net", "games", "against", "other", "players", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most outstanding feature", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 4, "i_end": 4}}], "id": 3506}, {"sent": "this proves the statement in the first case .", "tokens": ["this", "proves", "the", "statement", "in", "the", "first", "case", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "proves", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proves", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}], "id": 3507}, {"sent": "one popular method in this class is locality sensitive hashing .", "tokens": ["one", "popular", "method", "in", "this", "class", "is", "locality", "sensitive", "hashing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one popular method in this class", "start": 0, "end": 32, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "hashing", "start": 55, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "sensitive", "start": 45, "end": 54, "i_start": 8, "i_end": 8}}], "id": 3508}, {"sent": "in , image region forgery detection has been performed using a stacked auto-encoder model .", "tokens": ["in", ",", "image", "region", "forgery", "detection", "has", "been", "performed", "using", "a", "stacked", "auto", "-", "encoder", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "image region forgery detection", "start": 5, "end": 35, "i_start": 2, "i_end": 5}, "verb": {"text": "has been performed", "start": 36, "end": 54, "i_start": 6, "i_end": 8}}], "id": 3509}, {"sent": "the phase space is the cotangent bundle over it with conjugate momenta denoted by pi .", "tokens": ["the", "phase", "space", "is", "the", "cotangent", "bundle", "over", "it", "with", "conjugate", "momenta", "denoted", "by", "pi", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the phase space", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 3510}, {"sent": "deep neural networks have significantly advanced the state-of-the-art performance for various machine learning problems .", "tokens": ["deep", "neural", "networks", "have", "significantly", "advanced", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "for", "various", "machine", "learning", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "advanced", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "advanced", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}], "id": 3511}, {"sent": "recently , significant progress has been made on generating realistic images based on generative adversarial nets .", "tokens": ["recently", ",", "significant", "progress", "has", "been", "made", "on", "generating", "realistic", "images", "based", "on", "generative", "adversarial", "nets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "significant progress", "start": 11, "end": 31, "i_start": 2, "i_end": 3}, "verb": {"text": "has been made", "start": 32, "end": 45, "i_start": 4, "i_end": 6}}], "id": 3512}, {"sent": "all models were trained using adam optimizer for 20 epochs with a batch size of 50 .", "tokens": ["all", "models", "were", "trained", "using", "adam", "optimizer", "for", "20", "epochs", "with", "a", "batch", "size", "of", "50", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all models", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "were trained", "start": 11, "end": 23, "i_start": 2, "i_end": 3}}], "id": 3513}, {"sent": "we evaluate the pipeline on several indoor and outdoor images from open-source benchmark sequences .", "tokens": ["we", "evaluate", "the", "pipeline", "on", "several", "indoor", "and", "outdoor", "images", "from", "open", "-", "source", "benchmark", "sequences", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 3514}, {"sent": "their potentials comprise a spatially symmetric real well plus its purely imaginary antisymmetric complement .", "tokens": ["their", "potentials", "comprise", "a", "spatially", "symmetric", "real", "well", "plus", "its", "purely", "imaginary", "antisymmetric", "complement", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "their potentials", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "comprise", "start": 17, "end": 25, "i_start": 2, "i_end": 2}}], "id": 3515}, {"sent": "we initialize network weights with xavier initialisation and use batch normalization .", "tokens": ["we", "initialize", "network", "weights", "with", "xavier", "initialisation", "and", "use", "batch", "normalization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "initialize", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 61, "end": 64, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "initialize", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 61, "end": 64, "i_start": 8, "i_end": 8}}], "id": 3516}, {"sent": "voloshin , semiclassical suppression of black hole production in particle collisions , phys .", "tokens": ["voloshin", ",", "semiclassical", "suppression", "of", "black", "hole", "production", "in", "particle", "collisions", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3517}, {"sent": "the low energy properties of systems of interacting fermions in one dimension are commonly described in the framework of the luttinger liquid theory .", "tokens": ["the", "low", "energy", "properties", "of", "systems", "of", "interacting", "fermions", "in", "one", "dimension", "are", "commonly", "described", "in", "the", "framework", "of", "the", "luttinger", "liquid", "theory", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the low energy properties of systems of interacting fermions in one dimension", "start": 0, "end": 77, "i_start": 0, "i_end": 11}, "verb": {"text": "described", "start": 91, "end": 100, "i_start": 14, "i_end": 14}}, {"subject": {"text": "the low energy properties of systems of interacting fermions in one dimension", "start": 0, "end": 77, "i_start": 0, "i_end": 11}, "verb": {"text": "are", "start": 78, "end": 81, "i_start": 12, "i_end": 12}}, {"character": {"text": "fermions", "start": 52, "end": 60, "i_start": 8, "i_end": 8}, "action": {"text": "interacting", "start": 40, "end": 51, "i_start": 7, "i_end": 7}}], "id": 3518}, {"sent": "we first review the approach to modeling human movements that we developed in .", "tokens": ["we", "first", "review", "the", "approach", "to", "modeling", "human", "movements", "that", "we", "developed", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "review", "start": 9, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "review", "start": 9, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "developed", "start": 65, "end": 74, "i_start": 11, "i_end": 11}}], "id": 3519}, {"sent": "the implementation is done through the gradient boosted classifier of the scikit-learn library .", "tokens": ["the", "implementation", "is", "done", "through", "the", "gradient", "boosted", "classifier", "of", "the", "scikit", "-", "learn", "library", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the implementation", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is done", "start": 19, "end": 26, "i_start": 2, "i_end": 3}}, {"character": {"text": "gradient", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "boosted", "start": 48, "end": 55, "i_start": 7, "i_end": 7}}], "id": 3520}, {"sent": "similarly , for the reduction time tr in seconds in the body of the table , versus the dark matter mass and its rm s .", "tokens": ["similarly", ",", "for", "the", "reduction", "time", "tr", "in", "seconds", "in", "the", "body", "of", "the", "table", ",", "versus", "the", "dark", "matter", "mass", "and", "its", "rm", "s", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3521}, {"sent": "fully convolutional neural networks have become the tool of choice for many image segmentation tasks in medical imaging .", "tokens": ["fully", "convolutional", "neural", "networks", "have", "become", "the", "tool", "of", "choice", "for", "many", "image", "segmentation", "tasks", "in", "medical", "imaging", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "fully convolutional neural networks", "start": 0, "end": 35, "i_start": 0, "i_end": 3}, "verb": {"text": "have become", "start": 36, "end": 47, "i_start": 4, "i_end": 5}}], "id": 3522}, {"sent": "discussions in show that in a network with delays , anc gives rise to random processes which can be written algebraically in terms of a delay variable z .", "tokens": ["discussions", "in", "show", "that", "in", "a", "network", "with", "delays", ",", "anc", "gives", "rise", "to", "random", "processes", "which", "can", "be", "written", "algebraically", "in", "terms", "of", "a", "delay", "variable", "z", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "discussions", "start": 0, "end": 11, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 15, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "anc", "start": 52, "end": 55, "i_start": 10, "i_end": 10}, "action": {"text": "rise", "start": 62, "end": 66, "i_start": 12, "i_end": 12}}, {"character": {"text": "network", "start": 30, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "delay", "start": 136, "end": 141, "i_start": 25, "i_end": 25}}], "id": 3523}, {"sent": "the last three columns give the same information for the component b .", "tokens": ["the", "last", "three", "columns", "give", "the", "same", "information", "for", "the", "component", "b", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the last three columns", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "give", "start": 23, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "three columns", "start": 9, "end": 22, "i_start": 2, "i_end": 3}, "action": {"text": "give", "start": 23, "end": 27, "i_start": 4, "i_end": 4}}], "id": 3524}, {"sent": "so the orientation is the process that the current message holder i sends the message to its neighbor h , which has the most intimacy degree with the target t .", "tokens": ["so", "the", "orientation", "is", "the", "process", "that", "the", "current", "message", "holder", "i", "sends", "the", "message", "to", "its", "neighbor", "h", ",", "which", "has", "the", "most", "intimacy", "degree", "with", "the", "target", "t", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the orientation", "start": 3, "end": 18, "i_start": 1, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "current", "start": 43, "end": 50, "i_start": 8, "i_end": 8}, "action": {"text": "sends", "start": 68, "end": 73, "i_start": 12, "i_end": 12}}, {"character": {"text": "i", "start": 66, "end": 67, "i_start": 11, "i_end": 11}, "action": {"text": "sends", "start": 68, "end": 73, "i_start": 12, "i_end": 12}}], "id": 3525}, {"sent": "thus , several methods have been proposed recently to stabilize training .", "tokens": ["thus", ",", "several", "methods", "have", "been", "proposed", "recently", "to", "stabilize", "training", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "several methods", "start": 7, "end": 22, "i_start": 2, "i_end": 3}, "verb": {"text": "have been proposed", "start": 23, "end": 41, "i_start": 4, "i_end": 6}}], "id": 3526}, {"sent": "this is the reason why the traditional external penalty method can be used mainly for linear constrained problems .", "tokens": ["this", "is", "the", "reason", "why", "the", "traditional", "external", "penalty", "method", "can", "be", "used", "mainly", "for", "linear", "constrained", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3527}, {"sent": "for both parameters , smaller values correspond to higher privacy .", "tokens": ["for", "both", "parameters", ",", "smaller", "values", "correspond", "to", "higher", "privacy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "smaller values", "start": 22, "end": 36, "i_start": 4, "i_end": 5}, "verb": {"text": "correspond", "start": 37, "end": 47, "i_start": 6, "i_end": 6}}], "id": 3528}, {"sent": "it is proven in , proposition 2 , that the jenkins-serrin problem on this unbounded sector has no solution .", "tokens": ["it", "is", "proven", "in", ",", "proposition", "2", ",", "that", "the", "jenkins", "-", "serrin", "problem", "on", "this", "unbounded", "sector", "has", "no", "solution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is proven in", "start": 3, "end": 15, "i_start": 1, "i_end": 3}}, {"subject": {"text": "the jenkins-serrin problem on this unbounded sector", "start": 39, "end": 90, "i_start": 9, "i_end": 17}, "verb": {"text": "has", "start": 91, "end": 94, "i_start": 18, "i_end": 18}}], "id": 3529}, {"sent": "in the case of the bg model , the zero temperature dynamics can not be closed exactly .", "tokens": ["in", "the", "case", "of", "the", "bg", "model", ",", "the", "zero", "temperature", "dynamics", "can", "not", "be", "closed", "exactly", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the zero temperature dynamics", "start": 30, "end": 59, "i_start": 8, "i_end": 11}, "verb": {"text": "can not be closed", "start": 60, "end": 77, "i_start": 12, "i_end": 15}}], "id": 3530}, {"sent": "in particular we allow expanding thurston maps that have periodic critical points .", "tokens": ["in", "particular", "we", "allow", "expanding", "thurston", "maps", "that", "have", "periodic", "critical", "points", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "allow", "start": 17, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "allow", "start": 17, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "maps", "start": 42, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "have", "start": 52, "end": 56, "i_start": 8, "i_end": 8}}], "id": 3531}, {"sent": "the particles in each cube are used to produce a three-dimensional density field , by interpolating their position on a grid of 512 3 cells using the triangular shaped cloud method .", "tokens": ["the", "particles", "in", "each", "cube", "are", "used", "to", "produce", "a", "three", "-", "dimensional", "density", "field", ",", "by", "interpolating", "their", "position", "on", "a", "grid", "of", "512", "3", "cells", "using", "the", "triangular", "shaped", "cloud", "method", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the particles in each cube", "start": 0, "end": 26, "i_start": 0, "i_end": 4}, "verb": {"text": "are used", "start": 27, "end": 35, "i_start": 5, "i_end": 6}}, {"character": {"text": "particles", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "produce", "start": 39, "end": 46, "i_start": 8, "i_end": 8}}], "id": 3532}, {"sent": "there has also been much work on efficiently answering other types of queries over probabilistic databases , including top-k queries , and so on .", "tokens": ["there", "has", "also", "been", "much", "work", "on", "efficiently", "answering", "other", "types", "of", "queries", "over", "probabilistic", "databases", ",", "including", "top", "-", "k", "queries", ",", "and", "so", "on", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "been", "start": 15, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "has", "start": 6, "end": 9, "i_start": 1, "i_end": 1}}], "id": 3533}, {"sent": "now we proceed on to define smarandache non-associative seminear-ring ii .", "tokens": ["now", "we", "proceed", "on", "to", "define", "smarandache", "non", "-", "associative", "seminear", "-", "ring", "ii", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed on", "start": 7, "end": 17, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 3534}, {"sent": "we compare the proposed rlsd model with previous mentioned methods including metric learning .", "tokens": ["we", "compare", "the", "proposed", "rlsd", "model", "with", "previous", "mentioned", "methods", "including", "metric", "learning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 3535}, {"sent": "the model was trained for 3000 epochs with stochastic gradient descent using the adam optimiser .", "tokens": ["the", "model", "was", "trained", "for", "3000", "epochs", "with", "stochastic", "gradient", "descent", "using", "the", "adam", "optimiser", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "was trained", "start": 10, "end": 21, "i_start": 2, "i_end": 3}}], "id": 3536}, {"sent": "the best interleaver matrix is the one that evenly distributes the interference over all symbols , and can be found using binary linear programming .", "tokens": ["the", "best", "interleaver", "matrix", "is", "the", "one", "that", "evenly", "distributes", "the", "interference", "over", "all", "symbols", ",", "and", "can", "be", "found", "using", "binary", "linear", "programming", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the best interleaver matrix", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the best interleaver matrix", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "found", "start": 110, "end": 115, "i_start": 19, "i_end": 19}}, {"character": {"text": "matrix", "start": 21, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "distributes", "start": 51, "end": 62, "i_start": 9, "i_end": 9}}], "id": 3537}, {"sent": "iii , we solve the skyrme model and discuss the simplest solution .", "tokens": ["iii", ",", "we", "solve", "the", "skyrme", "model", "and", "discuss", "the", "simplest", "solution", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "verb": {"text": "solve", "start": 9, "end": 14, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "verb": {"text": "discuss", "start": 36, "end": 43, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "solve", "start": 9, "end": 14, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "discuss", "start": 36, "end": 43, "i_start": 8, "i_end": 8}}], "id": 3538}, {"sent": "yang et al proposed a word and sentence-level hierarchical attention network for document classification .", "tokens": ["yang", "et", "al", "proposed", "a", "word", "and", "sentence", "-", "level", "hierarchical", "attention", "network", "for", "document", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "yang et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "yang", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}], "id": 3539}, {"sent": "recurrent neural networks have been widely used in vision and language tasks , starting from image captioning tasks .", "tokens": ["recurrent", "neural", "networks", "have", "been", "widely", "used", "in", "vision", "and", "language", "tasks", ",", "starting", "from", "image", "captioning", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "recurrent neural networks", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 43, "end": 47, "i_start": 6, "i_end": 6}}, {"subject": {"text": "recurrent neural networks", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 26, "end": 35, "i_start": 3, "i_end": 4}}], "id": 3540}, {"sent": "in both figures there is a noticeable slowdown as the vehicles pass the obstacle .", "tokens": ["in", "both", "figures", "there", "is", "a", "noticeable", "slowdown", "as", "the", "vehicles", "pass", "the", "obstacle", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 16, "end": 21, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "vehicles", "start": 54, "end": 62, "i_start": 10, "i_end": 10}, "action": {"text": "pass", "start": 63, "end": 67, "i_start": 11, "i_end": 11}}], "id": 3541}, {"sent": "convolutional neural networks are the state of the art in image classification problems .", "tokens": ["convolutional", "neural", "networks", "are", "the", "state", "of", "the", "art", "in", "image", "classification", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 3, "i_end": 3}}], "id": 3542}, {"sent": "in blind deblurring , schuler et al employ neural networks as feature extraction modules towards a trainable deblurring system .", "tokens": ["in", "blind", "deblurring", ",", "schuler", "et", "al", "employ", "neural", "networks", "as", "feature", "extraction", "modules", "towards", "a", "trainable", "deblurring", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "schuler et al", "start": 22, "end": 35, "i_start": 4, "i_end": 6}, "verb": {"text": "employ", "start": 36, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "schuler", "start": 22, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "employ", "start": 36, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "system", "start": 120, "end": 126, "i_start": 18, "i_end": 18}, "action": {"text": "deblurring", "start": 9, "end": 19, "i_start": 2, "i_end": 2}}], "id": 3543}, {"sent": "we mention , at this point , that one can derive this type of equations from newtonian mechanics at least formally .", "tokens": ["we", "mention", ",", "at", "this", "point", ",", "that", "one", "can", "derive", "this", "type", "of", "equations", "from", "newtonian", "mechanics", "at", "least", "formally", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "mention", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "one", "start": 34, "end": 37, "i_start": 8, "i_end": 8}, "verb": {"text": "derive", "start": 42, "end": 48, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "mention", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "one", "start": 34, "end": 37, "i_start": 8, "i_end": 8}, "action": {"text": "derive", "start": 42, "end": 48, "i_start": 10, "i_end": 10}}], "id": 3544}, {"sent": "pietersz this vector field is called the gradient of f .", "tokens": ["pietersz", "this", "vector", "field", "is", "called", "the", "gradient", "of", "f", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3545}, {"sent": "duts is a large scale dataset containing 10,533 training images and 5,019 testing images .", "tokens": ["duts", "is", "a", "large", "scale", "dataset", "containing", "10,533", "training", "images", "and", "5,019", "testing", "images", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "duts", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "dataset", "start": 22, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "containing", "start": 30, "end": 40, "i_start": 6, "i_end": 6}}], "id": 3546}, {"sent": "generative adversarial network has shown a powerful capability in generating realistic natural images .", "tokens": ["generative", "adversarial", "network", "has", "shown", "a", "powerful", "capability", "in", "generating", "realistic", "natural", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial network", "start": 0, "end": 30, "i_start": 0, "i_end": 2}, "verb": {"text": "has shown", "start": 31, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "network", "start": 23, "end": 30, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 35, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "network", "start": 23, "end": 30, "i_start": 2, "i_end": 2}, "action": {"text": "generating", "start": 66, "end": 76, "i_start": 9, "i_end": 9}}], "id": 3547}, {"sent": "deep learning , implemented through deep neural networks , represents a machine-learning paradigm that has been extremely successful in the last decade , especially in computer vision and natural language processing applications .", "tokens": ["deep", "learning", ",", "implemented", "through", "deep", "neural", "networks", ",", "represents", "a", "machine", "-", "learning", "paradigm", "that", "has", "been", "extremely", "successful", "in", "the", "last", "decade", ",", "especially", "in", "computer", "vision", "and", "natural", "language", "processing", "applications", "."], "score": [1, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "represents", "start": 59, "end": 69, "i_start": 9, "i_end": 9}}, {"character": {"text": "learning", "start": 80, "end": 88, "i_start": 13, "i_end": 13}, "action": {"text": "represents", "start": 59, "end": 69, "i_start": 9, "i_end": 9}}], "id": 3548}, {"sent": "we would also like to thank george foster for making his statistical mt toolkit available and for many interesting discussions .", "tokens": ["we", "would", "also", "like", "to", "thank", "george", "foster", "for", "making", "his", "statistical", "mt", "toolkit", "available", "and", "for", "many", "interesting", "discussions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "like", "start": 14, "end": 18, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "would", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "like", "start": 14, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "thank", "start": 22, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "george foster", "start": 28, "end": 41, "i_start": 6, "i_end": 7}, "action": {"text": "making", "start": 46, "end": 52, "i_start": 9, "i_end": 9}}, {"character": {"text": "george foster", "start": 28, "end": 41, "i_start": 6, "i_end": 7}, "action": {"text": "discussions", "start": 115, "end": 126, "i_start": 19, "i_end": 19}}], "id": 3549}, {"sent": "in particular , convolutional neural networks have achieved impressive accuracy on the challenging imagenet classification benchmark .", "tokens": ["in", "particular", ",", "convolutional", "neural", "networks", "have", "achieved", "impressive", "accuracy", "on", "the", "challenging", "imagenet", "classification", "benchmark", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "accuracy", "start": 71, "end": 79, "i_start": 9, "i_end": 9}, "action": {"text": "impressive", "start": 60, "end": 70, "i_start": 8, "i_end": 8}}, {"character": {"text": "benchmark", "start": 123, "end": 132, "i_start": 15, "i_end": 15}, "action": {"text": "challenging", "start": 87, "end": 98, "i_start": 12, "i_end": 12}}], "id": 3550}, {"sent": "we refer the reader to the appendix a in for the detailed description of this scheme .", "tokens": ["we", "refer", "the", "reader", "to", "the", "appendix", "a", "in", "for", "the", "detailed", "description", "of", "this", "scheme", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3551}, {"sent": "meta-surfaces , in particular , are thin meta-material layers that are capable of shaping the propagation of radio waves in fully customizable ways .", "tokens": ["meta", "-", "surfaces", ",", "in", "particular", ",", "are", "thin", "meta", "-", "material", "layers", "that", "are", "capable", "of", "shaping", "the", "propagation", "of", "radio", "waves", "in", "fully", "customizable", "ways", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "meta-surfaces", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 7, "i_end": 7}}, {"character": {"text": "surfaces", "start": 5, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "shaping", "start": 82, "end": 89, "i_start": 17, "i_end": 17}}], "id": 3552}, {"sent": "deep convolutional neural networks have been used to achieve state-of-the-art performances in many supervised computer vision tasks such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "used", "to", "achieve", "state", "-", "of", "-", "the", "-", "art", "performances", "in", "many", "supervised", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been used", "start": 35, "end": 49, "i_start": 4, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieve", "start": 53, "end": 60, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performances", "start": 78, "end": 90, "i_start": 16, "i_end": 16}}], "id": 3553}, {"sent": "a model of the electrophysiological properties of thalamocortical relay neurons .", "tokens": ["a", "model", "of", "the", "electrophysiological", "properties", "of", "thalamocortical", "relay", "neurons", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "neurons", "start": 72, "end": 79, "i_start": 9, "i_end": 9}, "action": {"text": "relay", "start": 66, "end": 71, "i_start": 8, "i_end": 8}}], "id": 3554}, {"sent": "the asterisks denote the nearby single-\u03b2 clusters .", "tokens": ["the", "asterisks", "denote", "the", "nearby", "single", "-", "\u03b2", "clusters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the asterisks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "denote", "start": 14, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "asterisks", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 14, "end": 20, "i_start": 2, "i_end": 2}}], "id": 3555}, {"sent": "for the lines which are not resolved in \u03b3 cyg spectrum , the gf -values are adopted from the solar spectrum .", "tokens": ["for", "the", "lines", "which", "are", "not", "resolved", "in", "\u03b3", "cyg", "spectrum", ",", "the", "gf", "-values", "are", "adopted", "from", "the", "solar", "spectrum", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the gf -values", "start": 57, "end": 71, "i_start": 12, "i_end": 14}, "verb": {"text": "are adopted", "start": 72, "end": 83, "i_start": 15, "i_end": 16}}], "id": 3556}, {"sent": "they have been used in various applications such as image super resolution , image synthesis and image translation using conditional gans and cyclic gans .", "tokens": ["they", "have", "been", "used", "in", "various", "applications", "such", "as", "image", "super", "resolution", ",", "image", "synthesis", "and", "image", "translation", "using", "conditional", "gans", "and", "cyclic", "gans", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "have been used", "start": 5, "end": 19, "i_start": 1, "i_end": 3}}], "id": 3557}, {"sent": "we evaluate our algorithms on the challenging kitti tracking benchmarks .", "tokens": ["we", "evaluate", "our", "algorithms", "on", "the", "challenging", "kitti", "tracking", "benchmarks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "benchmarks", "start": 61, "end": 71, "i_start": 9, "i_end": 9}, "action": {"text": "tracking", "start": 52, "end": 60, "i_start": 8, "i_end": 8}}, {"character": {"text": "benchmarks", "start": 61, "end": 71, "i_start": 9, "i_end": 9}, "action": {"text": "challenging", "start": 34, "end": 45, "i_start": 6, "i_end": 6}}], "id": 3558}, {"sent": "we observe the smaller variance of the teleported squeezed state than that for the vacuum state input .", "tokens": ["we", "observe", "the", "smaller", "variance", "of", "the", "teleported", "squeezed", "state", "than", "that", "for", "the", "vacuum", "state", "input", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "observe", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "observe", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 3559}, {"sent": "the dashed lines show the results obtained with the measured deformation parameters for the noncollective excitations , while the solid lines show the results obtained using the random-matrix approximation .", "tokens": ["the", "dashed", "lines", "show", "the", "results", "obtained", "with", "the", "measured", "deformation", "parameters", "for", "the", "noncollective", "excitations", ",", "while", "the", "solid", "lines", "show", "the", "results", "obtained", "using", "the", "random", "-", "matrix", "approximation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the dashed lines", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "show", "start": 17, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "lines", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 17, "end": 21, "i_start": 3, "i_end": 3}}], "id": 3560}, {"sent": "the symbol p denotes the cauchy principal value .", "tokens": ["the", "symbol", "p", "denotes", "the", "cauchy", "principal", "value", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the symbol p", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "denotes", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "p", "start": 11, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "denotes", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}], "id": 3561}, {"sent": "the radiation pattern of an accelerated charge has a sin 2 \u03c6 dependence about the direction of acceleration .", "tokens": ["the", "radiation", "pattern", "of", "an", "accelerated", "charge", "has", "a", "sin", "2", "\u03c6", "dependence", "about", "the", "direction", "of", "acceleration", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the radiation pattern of an accelerated charge", "start": 0, "end": 46, "i_start": 0, "i_end": 6}, "verb": {"text": "has", "start": 47, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "pattern", "start": 14, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "dependence", "start": 61, "end": 71, "i_start": 12, "i_end": 12}}, {"character": {"text": "charge", "start": 40, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "radiation", "start": 4, "end": 13, "i_start": 1, "i_end": 1}}], "id": 3562}, {"sent": "convolutional neural networks are enabling major advancements in a range of machine learning problems .", "tokens": ["convolutional", "neural", "networks", "are", "enabling", "major", "advancements", "in", "a", "range", "of", "machine", "learning", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "are enabling", "start": 30, "end": 42, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "enabling", "start": 34, "end": 42, "i_start": 4, "i_end": 4}}], "id": 3563}, {"sent": "in both calculations , there is a clear linear correlation between the time an object spends accreting and its final mass .", "tokens": ["in", "both", "calculations", ",", "there", "is", "a", "clear", "linear", "correlation", "between", "the", "time", "an", "object", "spends", "accreting", "and", "its", "final", "mass", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 23, "end": 28, "i_start": 4, "i_end": 4}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "object", "start": 79, "end": 85, "i_start": 14, "i_end": 14}, "action": {"text": "spends", "start": 86, "end": 92, "i_start": 15, "i_end": 15}}, {"character": {"text": "object", "start": 79, "end": 85, "i_start": 14, "i_end": 14}, "action": {"text": "accreting", "start": 93, "end": 102, "i_start": 16, "i_end": 16}}], "id": 3564}, {"sent": "that is , the gluon is a nonpropagating mode in the gluon condensate .", "tokens": ["that", "is", ",", "the", "gluon", "is", "a", "nonpropagating", "mode", "in", "the", "gluon", "condensate", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the gluon", "start": 10, "end": 19, "i_start": 3, "i_end": 4}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 5, "i_end": 5}}], "id": 3565}, {"sent": "one can recognize that the overall structure of the above algorithm resembles a rotational incremental pressure correction-type strategy .", "tokens": ["one", "can", "recognize", "that", "the", "overall", "structure", "of", "the", "above", "algorithm", "resembles", "a", "rotational", "incremental", "pressure", "correction", "-", "type", "strategy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "can recognize", "start": 4, "end": 17, "i_start": 1, "i_end": 2}}, {"subject": {"text": "the overall structure of the above algorithm", "start": 23, "end": 67, "i_start": 4, "i_end": 10}, "verb": {"text": "resembles", "start": 68, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "recognize", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}], "id": 3566}, {"sent": "the electronic exchange and correlation effects were treated by the generalized gradient approximation in the perdew , burke , and ernzerhof form .", "tokens": ["the", "electronic", "exchange", "and", "correlation", "effects", "were", "treated", "by", "the", "generalized", "gradient", "approximation", "in", "the", "perdew", ",", "burke", ",", "and", "ernzerhof", "form", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electronic exchange and correlation effects", "start": 0, "end": 47, "i_start": 0, "i_end": 5}, "verb": {"text": "were treated", "start": 48, "end": 60, "i_start": 6, "i_end": 7}}], "id": 3567}, {"sent": "we choose instead to solve the delay pde numerically by adapting the finite-difference-time-domain method .", "tokens": ["we", "choose", "instead", "to", "solve", "the", "delay", "pde", "numerically", "by", "adapting", "the", "finite", "-", "difference", "-", "time", "-", "domain", "method", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "choose", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "choose", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "solve", "start": 21, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adapting", "start": 56, "end": 64, "i_start": 10, "i_end": 10}}], "id": 3568}, {"sent": "we show results on the classification task of the imagenet data set .", "tokens": ["we", "show", "results", "on", "the", "classification", "task", "of", "the", "imagenet", "data", "set", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3569}, {"sent": "recent advances in unsupervised learning have led to better architectures for modeling the statistical image generation process , primary among them being generative adversarial networks and variational autoencoders .", "tokens": ["recent", "advances", "in", "unsupervised", "learning", "have", "led", "to", "better", "architectures", "for", "modeling", "the", "statistical", "image", "generation", "process", ",", "primary", "among", "them", "being", "generative", "adversarial", "networks", "and", "variational", "autoencoders", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent advances in unsupervised learning", "start": 0, "end": 40, "i_start": 0, "i_end": 4}, "verb": {"text": "have led", "start": 41, "end": 49, "i_start": 5, "i_end": 6}}, {"subject": {"text": "recent advances in unsupervised learning", "start": 0, "end": 40, "i_start": 0, "i_end": 4}, "verb": {"text": "being", "start": 149, "end": 154, "i_start": 21, "i_end": 21}}, {"character": {"text": "advances", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 46, "end": 49, "i_start": 6, "i_end": 6}}], "id": 3570}, {"sent": "we assume that an energy \u03beeeb goes into the accelerating electrons .", "tokens": ["we", "assume", "that", "an", "energy", "\u03beeeb", "goes", "into", "the", "accelerating", "electrons", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "an energy \u03beeeb", "start": 15, "end": 29, "i_start": 3, "i_end": 5}, "verb": {"text": "goes", "start": 30, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 3571}, {"sent": "the mc yields are normalized to the integrated luminosity of the data using next-to-leading order cross sections .", "tokens": ["the", "mc", "yields", "are", "normalized", "to", "the", "integrated", "luminosity", "of", "the", "data", "using", "next", "-", "to", "-", "leading", "order", "cross", "sections", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the mc yields", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "are normalized", "start": 14, "end": 28, "i_start": 3, "i_end": 4}}], "id": 3572}, {"sent": "recently , the use of deep convolutional neural networks has shown promising results for many vision-based tasks including image classification .", "tokens": ["recently", ",", "the", "use", "of", "deep", "convolutional", "neural", "networks", "has", "shown", "promising", "results", "for", "many", "vision", "-", "based", "tasks", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the use of deep convolutional neural networks", "start": 11, "end": 56, "i_start": 2, "i_end": 8}, "verb": {"text": "has shown", "start": 57, "end": 66, "i_start": 9, "i_end": 10}}, {"character": {"text": "use", "start": 15, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 61, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "results", "start": 77, "end": 84, "i_start": 12, "i_end": 12}, "action": {"text": "promising", "start": 67, "end": 76, "i_start": 11, "i_end": 11}}], "id": 3573}, {"sent": "a deterministic local broadcasting , in which nodes have to inform only their neighbors in the corresponding reachability graph , was studied in .", "tokens": ["a", "deterministic", "local", "broadcasting", ",", "in", "which", "nodes", "have", "to", "inform", "only", "their", "neighbors", "in", "the", "corresponding", "reachability", "graph", ",", "was", "studied", "in", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "a deterministic local broadcasting", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "was studied", "start": 130, "end": 141, "i_start": 20, "i_end": 21}}, {"character": {"text": "broadcasting", "start": 22, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "deterministic", "start": 2, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "nodes", "start": 46, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "inform", "start": 60, "end": 66, "i_start": 10, "i_end": 10}}], "id": 3574}, {"sent": "since the electric charge is a gauge generator , it would be impossible to have non-zero electric charge in the brst cohomology .", "tokens": ["since", "the", "electric", "charge", "is", "a", "gauge", "generator", ",", "it", "would", "be", "impossible", "to", "have", "non", "-", "zero", "electric", "charge", "in", "the", "brst", "cohomology", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "verb": {"text": "would be", "start": 52, "end": 60, "i_start": 10, "i_end": 11}}], "id": 3575}, {"sent": "this problem was first studied in where wyner proposed a wiretap channel model .", "tokens": ["this", "problem", "was", "first", "studied", "in", "where", "wyner", "proposed", "a", "wiretap", "channel", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this problem", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "studied", "start": 23, "end": 30, "i_start": 4, "i_end": 4}}, {"subject": {"text": "this problem", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "was", "start": 13, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "wyner", "start": 40, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "proposed", "start": 46, "end": 54, "i_start": 8, "i_end": 8}}], "id": 3576}, {"sent": "the exchange-correlation energy was described by the revised perdew-burke-ernzerhof exchange functional .", "tokens": ["the", "exchange", "-", "correlation", "energy", "was", "described", "by", "the", "revised", "perdew", "-", "burke", "-", "ernzerhof", "exchange", "functional", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the exchange-correlation energy", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "was described", "start": 32, "end": 45, "i_start": 5, "i_end": 6}}, {"character": {"text": "functional", "start": 93, "end": 103, "i_start": 16, "i_end": 16}, "action": {"text": "described", "start": 36, "end": 45, "i_start": 6, "i_end": 6}}], "id": 3577}, {"sent": "smale , stable manifolds for di eomorphisms .", "tokens": ["smale", ",", "stable", "manifolds", "for", "di", "eomorphisms", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3578}, {"sent": "neural networks recently have been used to solve many real-world tasks such as image recognition and can achieve high effectiveness on these tasks .", "tokens": ["neural", "networks", "recently", "have", "been", "used", "to", "solve", "many", "real", "-", "world", "tasks", "such", "as", "image", "recognition", "and", "can", "achieve", "high", "effectiveness", "on", "these", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have been used", "start": 25, "end": 39, "i_start": 3, "i_end": 5}}, {"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "achieve", "start": 105, "end": 112, "i_start": 19, "i_end": 19}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "solve", "start": 43, "end": 48, "i_start": 7, "i_end": 7}}], "id": 3579}, {"sent": "the generalized gradient approximation is used to describe the exchangecorrelation functional as parameterized by perdew-burkeernzerhof .", "tokens": ["the", "generalized", "gradient", "approximation", "is", "used", "to", "describe", "the", "exchangecorrelation", "functional", "as", "parameterized", "by", "perdew", "-", "burkeernzerhof", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation", "start": 0, "end": 38, "i_start": 0, "i_end": 3}, "verb": {"text": "is used", "start": 39, "end": 46, "i_start": 4, "i_end": 5}}, {"character": {"text": "approximation", "start": 25, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "describe", "start": 50, "end": 58, "i_start": 7, "i_end": 7}}], "id": 3580}, {"sent": "deep convolutional neural networks have achieved great success in various computer vision tasks , including object classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "various", "computer", "vision", "tasks", ",", "including", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}], "id": 3581}, {"sent": "the ising model is the simplest model of nearest-neighbor ferromagnetic interactions where the collective features are studied .", "tokens": ["the", "ising", "model", "is", "the", "simplest", "model", "of", "nearest", "-", "neighbor", "ferromagnetic", "interactions", "where", "the", "collective", "features", "are", "studied", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ising model", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "model", "start": 32, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "model", "start": 10, "end": 15, "i_start": 2, "i_end": 2}}], "id": 3582}, {"sent": "it is clear that qm is compact for every m .", "tokens": ["it", "is", "clear", "that", "qm", "is", "compact", "for", "every", "m", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 5, "i_end": 5}}], "id": 3583}, {"sent": "generative adversarial networks are among the most powerful generative models that capture data distribution .", "tokens": ["generative", "adversarial", "networks", "are", "among", "the", "most", "powerful", "generative", "models", "that", "capture", "data", "distribution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 71, "end": 77, "i_start": 9, "i_end": 9}, "action": {"text": "capture", "start": 83, "end": 90, "i_start": 11, "i_end": 11}}], "id": 3584}, {"sent": "then , the free energy is the function of the condensate v .", "tokens": ["then", ",", "the", "free", "energy", "is", "the", "function", "of", "the", "condensate", "v", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the free energy", "start": 7, "end": 22, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 5, "i_end": 5}}], "id": 3585}, {"sent": "theory of decoherencefree fault-tolerant universal quantum computation .", "tokens": ["theory", "of", "decoherencefree", "fault", "-", "tolerant", "universal", "quantum", "computation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "computation", "start": 59, "end": 70, "i_start": 8, "i_end": 8}, "action": {"text": "tolerant", "start": 32, "end": 40, "i_start": 5, "i_end": 5}}], "id": 3586}, {"sent": "on the martingale property of stochastic exponen tials .", "tokens": ["on", "the", "martingale", "property", "of", "stochastic", "exponen", "tials", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3587}, {"sent": "this part in the energy dependent conductance plot increases for larger sample length .", "tokens": ["this", "part", "in", "the", "energy", "dependent", "conductance", "plot", "increases", "for", "larger", "sample", "length", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "conductance", "start": 34, "end": 45, "i_start": 6, "i_end": 6}, "action": {"text": "dependent", "start": 24, "end": 33, "i_start": 5, "i_end": 5}}], "id": 3588}, {"sent": "generative adversarial networks are one of the main groups of methods used to learn generative models from complicated real-world data .", "tokens": ["generative", "adversarial", "networks", "are", "one", "of", "the", "main", "groups", "of", "methods", "used", "to", "learn", "generative", "models", "from", "complicated", "real", "-", "world", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}], "id": 3589}, {"sent": "these correlators have been evaluated for the case of the ultrarelativistic electron-positron plasma .", "tokens": ["these", "correlators", "have", "been", "evaluated", "for", "the", "case", "of", "the", "ultrarelativistic", "electron", "-", "positron", "plasma", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these correlators", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "have been evaluated", "start": 18, "end": 37, "i_start": 2, "i_end": 4}}], "id": 3590}, {"sent": "in doing so , although we follow arguments of refs , some of our derivations are original .", "tokens": ["in", "doing", "so", ",", "although", "we", "follow", "arguments", "of", "refs", ",", "some", "of", "our", "derivations", "are", "original", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "some of our derivations", "start": 53, "end": 76, "i_start": 11, "i_end": 14}, "verb": {"text": "are", "start": 77, "end": 80, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "action": {"text": "derivations", "start": 65, "end": 76, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "action": {"text": "follow", "start": 26, "end": 32, "i_start": 6, "i_end": 6}}], "id": 3591}, {"sent": "a saturation of 1 is a maximum saturated color , ie it has one rgb value equal to zero and is therefore a mixture of only two rgb basic colors .", "tokens": ["a", "saturation", "of", "1", "is", "a", "maximum", "saturated", "color", ",", "ie", "it", "has", "one", "rgb", "value", "equal", "to", "zero", "and", "is", "therefore", "a", "mixture", "of", "only", "two", "rgb", "basic", "colors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a saturation of 1", "start": 0, "end": 17, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 4, "i_end": 4}}, {"subject": {"text": "it", "start": 52, "end": 54, "i_start": 11, "i_end": 11}, "verb": {"text": "has", "start": 55, "end": 58, "i_start": 12, "i_end": 12}}], "id": 3592}, {"sent": "quantum mechanics and molecular mechanics coupling methods have been widely used for simulations of large systems in materials science and biology .", "tokens": ["quantum", "mechanics", "and", "molecular", "mechanics", "coupling", "methods", "have", "been", "widely", "used", "for", "simulations", "of", "large", "systems", "in", "materials", "science", "and", "biology", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum mechanics and molecular mechanics coupling methods", "start": 0, "end": 58, "i_start": 0, "i_end": 6}, "verb": {"text": "used", "start": 76, "end": 80, "i_start": 10, "i_end": 10}}, {"subject": {"text": "quantum mechanics and molecular mechanics coupling methods", "start": 0, "end": 58, "i_start": 0, "i_end": 6}, "verb": {"text": "have been", "start": 59, "end": 68, "i_start": 7, "i_end": 8}}], "id": 3593}, {"sent": "deep neural networks have had great success in learning to predict various quantities from images , eg , object classes .", "tokens": ["deep", "neural", "networks", "have", "had", "great", "success", "in", "learning", "to", "predict", "various", "quantities", "from", "images", ",", "eg", ",", "object", "classes", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have had", "start": 21, "end": 29, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 36, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "learning", "start": 47, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "predict", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}], "id": 3594}, {"sent": "market-based reinforcement learning in partially observable worlds .", "tokens": ["market", "-", "based", "reinforcement", "learning", "in", "partially", "observable", "worlds", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3595}, {"sent": "can be considered as a hybrid approach that use multiple normal distributions to estimate the probability distributions and can approximate any probability density function .", "tokens": ["can", "be", "considered", "as", "a", "hybrid", "approach", "that", "use", "multiple", "normal", "distributions", "to", "estimate", "the", "probability", "distributions", "and", "can", "approximate", "any", "probability", "density", "function", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "approach", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "use", "start": 44, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "approach", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "approximate", "start": 128, "end": 139, "i_start": 19, "i_end": 19}}], "id": 3596}, {"sent": "massive multiple-input multiple-output has become a candidate technique for the fifth generation wireless communication system .", "tokens": ["massive", "multiple", "-", "input", "multiple", "-", "output", "has", "become", "a", "candidate", "technique", "for", "the", "fifth", "generation", "wireless", "communication", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "massive multiple-input multiple-output", "start": 0, "end": 38, "i_start": 0, "i_end": 6}, "verb": {"text": "has become", "start": 39, "end": 49, "i_start": 7, "i_end": 8}}], "id": 3597}, {"sent": "recently , deep convolutional neural networks have achieved great successes in computer vision topics such as image classification .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "achieved", "great", "successes", "in", "computer", "vision", "topics", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "successes", "start": 66, "end": 75, "i_start": 9, "i_end": 9}}], "id": 3598}, {"sent": "it is clear that for the both midpoint box scheme for hamiltonian field theory and for the type of hamiltonian-like pdes the discrete multisymplectic structure preserving law holds in function space with the discrete closed euler-lagrange condition in general and can also be required in the solution space in each case .", "tokens": ["it", "is", "clear", "that", "for", "the", "both", "midpoint", "box", "scheme", "for", "hamiltonian", "field", "theory", "and", "for", "the", "type", "of", "hamiltonian", "-", "like", "pdes", "the", "discrete", "multisymplectic", "structure", "preserving", "law", "holds", "in", "function", "space", "with", "the", "discrete", "closed", "euler", "-", "lagrange", "condition", "in", "general", "and", "can", "also", "be", "required", "in", "the", "solution", "space", "in", "each", "case", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the both midpoint box scheme for hamiltonian field theory and for the type of hamiltonian-like pdes the discrete multisymplectic structure preserving law", "start": 21, "end": 174, "i_start": 5, "i_end": 28}, "verb": {"text": "holds", "start": 175, "end": 180, "i_start": 29, "i_end": 29}}, {"character": {"text": "law", "start": 171, "end": 174, "i_start": 28, "i_end": 28}, "action": {"text": "preserving", "start": 160, "end": 170, "i_start": 27, "i_end": 27}}], "id": 3599}, {"sent": "there has been active research on solving convex-concave saddle point problems min x max y l .", "tokens": ["there", "has", "been", "active", "research", "on", "solving", "convex", "-", "concave", "saddle", "point", "problems", "min", "x", "max", "y", "l", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "has been", "start": 6, "end": 14, "i_start": 1, "i_end": 2}}], "id": 3600}, {"sent": "buttafava et al solved this system using variants of the backprojection algorithm .", "tokens": ["buttafava", "et", "al", "solved", "this", "system", "using", "variants", "of", "the", "backprojection", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "buttafava et al", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "solved", "start": 16, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "buttafava", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "solved", "start": 16, "end": 22, "i_start": 3, "i_end": 3}}], "id": 3601}, {"sent": "this is motivated from the general expectation that noncommutative geometry provides a crucial link to string theory .", "tokens": ["this", "is", "motivated", "from", "the", "general", "expectation", "that", "noncommutative", "geometry", "provides", "a", "crucial", "link", "to", "string", "theory", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is motivated", "start": 5, "end": 17, "i_start": 1, "i_end": 2}}, {"character": {"text": "expectation", "start": 35, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "motivated", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "geometry", "start": 67, "end": 75, "i_start": 9, "i_end": 9}, "action": {"text": "provides", "start": 76, "end": 84, "i_start": 10, "i_end": 10}}], "id": 3602}, {"sent": "the ab initio calculations are performed based on the density functional theory by using the plane-wave basis set and the projector-augmented-wave method as implemented in the vienna simulation package code .", "tokens": ["the", "ab", "initio", "calculations", "are", "performed", "based", "on", "the", "density", "functional", "theory", "by", "using", "the", "plane", "-", "wave", "basis", "set", "and", "the", "projector", "-", "augmented", "-", "wave", "method", "as", "implemented", "in", "the", "vienna", "simulation", "package", "code", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ab initio calculations", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "are performed", "start": 27, "end": 40, "i_start": 4, "i_end": 5}}], "id": 3603}, {"sent": "a temporal concurrent constraint programming calculus .", "tokens": ["a", "temporal", "concurrent", "constraint", "programming", "calculus", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3604}, {"sent": "the data were reduced using the common astronomy software application package with a standard pipeline .", "tokens": ["the", "data", "were", "reduced", "using", "the", "common", "astronomy", "software", "application", "package", "with", "a", "standard", "pipeline", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "were reduced", "start": 9, "end": 21, "i_start": 2, "i_end": 3}}], "id": 3605}, {"sent": "batch normalization is applied after every convolutional layer in order to accelerate training .", "tokens": ["batch", "normalization", "is", "applied", "after", "every", "convolutional", "layer", "in", "order", "to", "accelerate", "training", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "batch normalization", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is applied", "start": 20, "end": 30, "i_start": 2, "i_end": 3}}, {"character": {"text": "applied", "start": 23, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "accelerate", "start": 75, "end": 85, "i_start": 11, "i_end": 11}}], "id": 3606}, {"sent": "topological fault-tolerance in cluster state quantum computation .", "tokens": ["topological", "fault", "-", "tolerance", "in", "cluster", "state", "quantum", "computation", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3607}, {"sent": "instead , we exploit generative adversarial networks , which have proven to be successful in the generation of realistic images .", "tokens": ["instead", ",", "we", "exploit", "generative", "adversarial", "networks", ",", "which", "have", "proven", "to", "be", "successful", "in", "the", "generation", "of", "realistic", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "exploit", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "exploit", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "successful", "start": 79, "end": 89, "i_start": 13, "i_end": 13}}], "id": 3608}, {"sent": "then the clustering can be quantified as where c is called clustering coefficient .", "tokens": ["then", "the", "clustering", "can", "be", "quantified", "as", "where", "c", "is", "called", "clustering", "coefficient", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the clustering", "start": 5, "end": 19, "i_start": 1, "i_end": 2}, "verb": {"text": "can be quantified", "start": 20, "end": 37, "i_start": 3, "i_end": 5}}], "id": 3609}, {"sent": "an alternative method to achieve the uniform rate region of multiple access channels is by rate splitting between the users .", "tokens": ["an", "alternative", "method", "to", "achieve", "the", "uniform", "rate", "region", "of", "multiple", "access", "channels", "is", "by", "rate", "splitting", "between", "the", "users", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "an alternative method to achieve the uniform rate region of multiple access channels", "start": 0, "end": 84, "i_start": 0, "i_end": 12}, "verb": {"text": "is", "start": 85, "end": 87, "i_start": 13, "i_end": 13}}], "id": 3610}, {"sent": "for feature extraction we use resnet50 model pre-trained with imagenet weights .", "tokens": ["for", "feature", "extraction", "we", "use", "resnet50", "model", "pre", "-", "trained", "with", "imagenet", "weights", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 23, "end": 25, "i_start": 3, "i_end": 3}, "verb": {"text": "use", "start": 26, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 26, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "extraction", "start": 12, "end": 22, "i_start": 2, "i_end": 2}}], "id": 3611}, {"sent": "the capacitance c 3d is a function of the e eff at which the capacitance diverges .", "tokens": ["the", "capacitance", "c", "3d", "is", "a", "function", "of", "the", "e", "eff", "at", "which", "the", "capacitance", "diverges", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the capacitance c 3d", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "eff", "start": 44, "end": 47, "i_start": 10, "i_end": 10}, "action": {"text": "function", "start": 26, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "capacitance", "start": 4, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "diverges", "start": 73, "end": 81, "i_start": 15, "i_end": 15}}], "id": 3612}, {"sent": "photoacoustic tomography is a recent hybrid imaging modality that attempts to reconstruct high-resolution images of optical properties of heterogeneous media .", "tokens": ["photoacoustic", "tomography", "is", "a", "recent", "hybrid", "imaging", "modality", "that", "attempts", "to", "reconstruct", "high", "-", "resolution", "images", "of", "optical", "properties", "of", "heterogeneous", "media", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "photoacoustic tomography", "start": 0, "end": 24, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 2, "i_end": 2}}, {"character": {"text": "modality", "start": 52, "end": 60, "i_start": 7, "i_end": 7}, "action": {"text": "attempts", "start": 66, "end": 74, "i_start": 9, "i_end": 9}}], "id": 3613}, {"sent": "the parafermionic case follows by the jw-transformation .", "tokens": ["the", "parafermionic", "case", "follows", "by", "the", "jw", "-", "transformation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the parafermionic case", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "follows", "start": 23, "end": 30, "i_start": 3, "i_end": 3}}], "id": 3614}, {"sent": "the authors also present a very deep end-to-end persistent memory network for image restoration task , which tackles the long-term dependency problem in the previous cnn architectures .", "tokens": ["the", "authors", "also", "present", "a", "very", "deep", "end", "-", "to", "-", "end", "persistent", "memory", "network", "for", "image", "restoration", "task", ",", "which", "tackles", "the", "long", "-", "term", "dependency", "problem", "in", "the", "previous", "cnn", "architectures", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "present", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "persistent", "start": 48, "end": 58, "i_start": 12, "i_end": 12}, "action": {"text": "authors", "start": 4, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "network", "start": 66, "end": 73, "i_start": 14, "i_end": 14}, "action": {"text": "tackles", "start": 109, "end": 116, "i_start": 21, "i_end": 21}}], "id": 3615}, {"sent": "thus the phase space of the bulk theory is that of general relativity in hamiltonian form .", "tokens": ["thus", "the", "phase", "space", "of", "the", "bulk", "theory", "is", "that", "of", "general", "relativity", "in", "hamiltonian", "form", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the phase space of the bulk theory", "start": 5, "end": 39, "i_start": 1, "i_end": 7}, "verb": {"text": "is", "start": 40, "end": 42, "i_start": 8, "i_end": 8}}], "id": 3616}, {"sent": "now this point of view is extended in one dimension and is known as string theory .", "tokens": ["now", "this", "point", "of", "view", "is", "extended", "in", "one", "dimension", "and", "is", "known", "as", "string", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this point of view", "start": 4, "end": 22, "i_start": 1, "i_end": 4}, "verb": {"text": "is extended", "start": 23, "end": 34, "i_start": 5, "i_end": 6}}, {"subject": {"text": "this point of view", "start": 4, "end": 22, "i_start": 1, "i_end": 4}, "verb": {"text": "known", "start": 59, "end": 64, "i_start": 12, "i_end": 12}}], "id": 3617}, {"sent": "in our experiments , we explore resnet for the cnn component of the model .", "tokens": ["in", "our", "experiments", ",", "we", "explore", "resnet", "for", "the", "cnn", "component", "of", "the", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "explore", "start": 24, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "explore", "start": 24, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "experiments", "start": 7, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3618}, {"sent": "the asterisks denote the final value from the simulation rather than a minimum .", "tokens": ["the", "asterisks", "denote", "the", "final", "value", "from", "the", "simulation", "rather", "than", "a", "minimum", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the asterisks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "denote", "start": 14, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "asterisks", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 14, "end": 20, "i_start": 2, "i_end": 2}}], "id": 3619}, {"sent": "the artificial compressibility approximation was introduced by chorin , in order to deal with the difficulty induced by the incompressibility constraints in the numerical approximation .", "tokens": ["the", "artificial", "compressibility", "approximation", "was", "introduced", "by", "chorin", ",", "in", "order", "to", "deal", "with", "the", "difficulty", "induced", "by", "the", "incompressibility", "constraints", "in", "the", "numerical", "approximation", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the artificial compressibility approximation", "start": 0, "end": 44, "i_start": 0, "i_end": 3}, "verb": {"text": "was introduced", "start": 45, "end": 59, "i_start": 4, "i_end": 5}}, {"character": {"text": "chorin", "start": 63, "end": 69, "i_start": 7, "i_end": 7}, "action": {"text": "introduced", "start": 49, "end": 59, "i_start": 5, "i_end": 5}}, {"character": {"text": "chorin", "start": 63, "end": 69, "i_start": 7, "i_end": 7}, "action": {"text": "deal", "start": 84, "end": 88, "i_start": 12, "i_end": 12}}, {"character": {"text": "constraints", "start": 142, "end": 153, "i_start": 20, "i_end": 20}, "action": {"text": "induced", "start": 109, "end": 116, "i_start": 16, "i_end": 16}}], "id": 3620}, {"sent": "whether it is associated with the bal outflow is unclear .", "tokens": ["whether", "it", "is", "associated", "with", "the", "bal", "outflow", "is", "unclear", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "whether it is associated with the bal outflow", "start": 0, "end": 45, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 46, "end": 48, "i_start": 8, "i_end": 8}}], "id": 3621}, {"sent": "let ui be the primitive integral vector in the direction of ei .", "tokens": ["let", "ui", "be", "the", "primitive", "integral", "vector", "in", "the", "direction", "of", "ei", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3622}, {"sent": "deep learning methods in nlp which learn vector representations for words have seen successful uses in recent years on increasingly sophisticated tasks .", "tokens": ["deep", "learning", "methods", "in", "nlp", "which", "learn", "vector", "representations", "for", "words", "have", "seen", "successful", "uses", "in", "recent", "years", "on", "increasingly", "sophisticated", "tasks", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "deep learning methods in nlp which learn vector representations for words", "start": 0, "end": 73, "i_start": 0, "i_end": 10}, "verb": {"text": "have seen", "start": 74, "end": 83, "i_start": 11, "i_end": 12}}, {"character": {"text": "methods", "start": 14, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}}], "id": 3623}, {"sent": "to train these models , we applied adam optimizer with stochastic gradient descent .", "tokens": ["to", "train", "these", "models", ",", "we", "applied", "adam", "optimizer", "with", "stochastic", "gradient", "descent", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "verb": {"text": "applied", "start": 27, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "applied", "start": 27, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "optimizer", "start": 40, "end": 49, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3624}, {"sent": "for our evaluation , we make use of pascal voc 2012 segmentation benchmark .", "tokens": ["for", "our", "evaluation", ",", "we", "make", "use", "of", "pascal", "voc", "2012", "segmentation", "benchmark", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "make", "start": 24, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 29, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "evaluation", "start": 8, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3625}, {"sent": "beta and \u03b3-ray decay curves were measured following the irradiation .", "tokens": ["beta", "and", "\u03b3", "-", "ray", "decay", "curves", "were", "measured", "following", "the", "irradiation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "beta and \u03b3-ray decay curves", "start": 0, "end": 27, "i_start": 0, "i_end": 6}, "verb": {"text": "were measured", "start": 28, "end": 41, "i_start": 7, "i_end": 8}}], "id": 3626}, {"sent": "we used adam as our first-order optimizer for both vq-vae and the code2spec inverter .", "tokens": ["we", "used", "adam", "as", "our", "first", "-", "order", "optimizer", "for", "both", "vq", "-", "vae", "and", "the", "code2spec", "inverter", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3627}, {"sent": "precise estimation of the forces acting on the needle tip is particularly interesting , eg , for monitoring the needle-tissue interaction and detecting tissue ruptures , or to generate feedback during an intervention .", "tokens": ["precise", "estimation", "of", "the", "forces", "acting", "on", "the", "needle", "tip", "is", "particularly", "interesting", ",", "eg", ",", "for", "monitoring", "the", "needle", "-", "tissue", "interaction", "and", "detecting", "tissue", "ruptures", ",", "or", "to", "generate", "feedback", "during", "an", "intervention", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "precise estimation of the forces acting on the needle tip", "start": 0, "end": 57, "i_start": 0, "i_end": 9}, "verb": {"text": "is", "start": 58, "end": 60, "i_start": 10, "i_end": 10}}, {"character": {"text": "forces", "start": 26, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "acting", "start": 33, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "needle", "start": 47, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "interaction", "start": 126, "end": 137, "i_start": 22, "i_end": 22}}], "id": 3628}, {"sent": "the convolutional neural network in particular is a deep learning architecture which has shown its promise for image classification tasks .", "tokens": ["the", "convolutional", "neural", "network", "in", "particular", "is", "a", "deep", "learning", "architecture", "which", "has", "shown", "its", "promise", "for", "image", "classification", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the convolutional neural network in particular", "start": 0, "end": 46, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 47, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "architecture", "start": 66, "end": 78, "i_start": 10, "i_end": 10}, "action": {"text": "shown", "start": 89, "end": 94, "i_start": 13, "i_end": 13}}], "id": 3629}, {"sent": "further , the authors in have also shown that any bounded above , resp .", "tokens": ["further", ",", "the", "authors", "in", "have", "also", "shown", "that", "any", "bounded", "above", ",", "resp", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors in", "start": 10, "end": 24, "i_start": 2, "i_end": 4}, "verb": {"text": "shown", "start": 35, "end": 40, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the authors in", "start": 10, "end": 24, "i_start": 2, "i_end": 4}, "verb": {"text": "have", "start": 25, "end": 29, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the authors in", "start": 10, "end": 24, "i_start": 2, "i_end": 4}, "verb": {"text": "bounded", "start": 50, "end": 57, "i_start": 10, "i_end": 10}}], "id": 3630}, {"sent": "we evaluated summarization quality automatically using rouge .", "tokens": ["we", "evaluated", "summarization", "quality", "automatically", "using", "rouge", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluated", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluated", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 49, "end": 54, "i_start": 5, "i_end": 5}}], "id": 3631}, {"sent": "within this setting , there exist algorithms that recover s 1 , s 2 , along with convergence rates for estimating f , in the limit of large n .", "tokens": ["within", "this", "setting", ",", "there", "exist", "algorithms", "that", "recover", "s", "1", ",", "s", "2", ",", "along", "with", "convergence", "rates", "for", "estimating", "f", ",", "in", "the", "limit", "of", "large", "n", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 22, "end": 27, "i_start": 4, "i_end": 4}, "verb": {"text": "exist", "start": 28, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "algorithms", "start": 34, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "recover", "start": 50, "end": 57, "i_start": 8, "i_end": 8}}], "id": 3632}, {"sent": "variable-speed-of-light cosmological models were proposed for solving the cosmological problems of the standard big bang model .", "tokens": ["variable", "-", "speed", "-", "of", "-", "light", "cosmological", "models", "were", "proposed", "for", "solving", "the", "cosmological", "problems", "of", "the", "standard", "big", "bang", "model", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "variable-speed-of-light cosmological models", "start": 0, "end": 43, "i_start": 0, "i_end": 8}, "verb": {"text": "were proposed", "start": 44, "end": 57, "i_start": 9, "i_end": 10}}, {"character": {"text": "models", "start": 37, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "solving", "start": 62, "end": 69, "i_start": 12, "i_end": 12}}], "id": 3633}, {"sent": "phase synchronization of chaotic oscillators by external driving .", "tokens": ["phase", "synchronization", "of", "chaotic", "oscillators", "by", "external", "driving", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "external", "start": 48, "end": 56, "i_start": 6, "i_end": 6}, "action": {"text": "driving", "start": 57, "end": 64, "i_start": 7, "i_end": 7}}], "id": 3634}, {"sent": "feedback control of quantum state reduction .", "tokens": ["feedback", "control", "of", "quantum", "state", "reduction", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3635}, {"sent": "the perdew-burke-ernzerhof scheme of the generalized gradient approximation is adopted to describe the exchange-correlation effect among electrons .", "tokens": ["the", "perdew", "-", "burke", "-", "ernzerhof", "scheme", "of", "the", "generalized", "gradient", "approximation", "is", "adopted", "to", "describe", "the", "exchange", "-", "correlation", "effect", "among", "electrons", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the perdew-burke-ernzerhof scheme of the generalized gradient approximation", "start": 0, "end": 75, "i_start": 0, "i_end": 11}, "verb": {"text": "is adopted", "start": 76, "end": 86, "i_start": 12, "i_end": 13}}, {"character": {"text": "scheme", "start": 27, "end": 33, "i_start": 6, "i_end": 6}, "action": {"text": "describe", "start": 90, "end": 98, "i_start": 15, "i_end": 15}}, {"character": {"text": "electrons", "start": 137, "end": 146, "i_start": 22, "i_end": 22}, "action": {"text": "effect", "start": 124, "end": 130, "i_start": 20, "i_end": 20}}], "id": 3636}, {"sent": "next is the substitution rule for the refinement riemann-stieltjes integrals .", "tokens": ["next", "is", "the", "substitution", "rule", "for", "the", "refinement", "riemann", "-", "stieltjes", "integrals", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the substitution rule for the refinement riemann-stieltjes integrals", "start": 8, "end": 76, "i_start": 2, "i_end": 11}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3637}, {"sent": "each module comprises a convolution , batch normalization , rectified linear unit non-linearity , and skip connections .", "tokens": ["each", "module", "comprises", "a", "convolution", ",", "batch", "normalization", ",", "rectified", "linear", "unit", "non", "-", "linearity", ",", "and", "skip", "connections", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each module", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "comprises", "start": 12, "end": 21, "i_start": 2, "i_end": 2}}], "id": 3638}, {"sent": "then , the te modes can be obtained by use of the vector potential .", "tokens": ["then", ",", "the", "te", "modes", "can", "be", "obtained", "by", "use", "of", "the", "vector", "potential", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the te modes", "start": 7, "end": 19, "i_start": 2, "i_end": 4}, "verb": {"text": "can be obtained", "start": 20, "end": 35, "i_start": 5, "i_end": 7}}], "id": 3639}, {"sent": "dft calculations were performed using the vienna ab initio simulation package .", "tokens": ["dft", "calculations", "were", "performed", "using", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dft calculations", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were performed", "start": 17, "end": 31, "i_start": 2, "i_end": 3}}], "id": 3640}, {"sent": "the dynamics of this model is a stochastic sequential growth dynamics .", "tokens": ["the", "dynamics", "of", "this", "model", "is", "a", "stochastic", "sequential", "growth", "dynamics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dynamics of this model", "start": 0, "end": 26, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 5, "i_end": 5}}], "id": 3641}, {"sent": "otherwise , the orbit contains only one element and is called a fixed orbit .", "tokens": ["otherwise", ",", "the", "orbit", "contains", "only", "one", "element", "and", "is", "called", "a", "fixed", "orbit", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the orbit", "start": 12, "end": 21, "i_start": 2, "i_end": 3}, "verb": {"text": "contains", "start": 22, "end": 30, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the orbit", "start": 12, "end": 21, "i_start": 2, "i_end": 3}, "verb": {"text": "called", "start": 55, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "orbit", "start": 16, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "contains", "start": 22, "end": 30, "i_start": 4, "i_end": 4}}], "id": 3642}, {"sent": "deep neural networks have been showing impressive performance in a variety of applications in multiple domains .", "tokens": ["deep", "neural", "networks", "have", "been", "showing", "impressive", "performance", "in", "a", "variety", "of", "applications", "in", "multiple", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been showing", "start": 21, "end": 38, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "showing", "start": 31, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 50, "end": 61, "i_start": 7, "i_end": 7}}, {"character": {"text": "performance", "start": 50, "end": 61, "i_start": 7, "i_end": 7}, "action": {"text": "impressive", "start": 39, "end": 49, "i_start": 6, "i_end": 6}}], "id": 3643}, {"sent": "convolutional neural networks have been proven to achieve astonishing results in different research areas such as face recognition .", "tokens": ["convolutional", "neural", "networks", "have", "been", "proven", "to", "achieve", "astonishing", "results", "in", "different", "research", "areas", "such", "as", "face", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been proven", "start": 30, "end": 46, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 50, "end": 57, "i_start": 7, "i_end": 7}}, {"character": {"text": "results", "start": 70, "end": 77, "i_start": 9, "i_end": 9}, "action": {"text": "astonishing", "start": 58, "end": 69, "i_start": 8, "i_end": 8}}], "id": 3644}, {"sent": "independent of segmentation masks , liao et al find dense correspondence between two images using deep features , yielding the results that are more similar to ours .", "tokens": ["independent", "of", "segmentation", "masks", ",", "liao", "et", "al", "find", "dense", "correspondence", "between", "two", "images", "using", "deep", "features", ",", "yielding", "the", "results", "that", "are", "more", "similar", "to", "ours", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "liao et al", "start": 36, "end": 46, "i_start": 5, "i_end": 7}, "verb": {"text": "find", "start": 47, "end": 51, "i_start": 8, "i_end": 8}}, {"character": {"text": "liao", "start": 36, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "find", "start": 47, "end": 51, "i_start": 8, "i_end": 8}}, {"character": {"text": "two images", "start": 81, "end": 91, "i_start": 12, "i_end": 13}, "action": {"text": "correspondence", "start": 58, "end": 72, "i_start": 10, "i_end": 10}}, {"character": {"text": "correspondence", "start": 58, "end": 72, "i_start": 10, "i_end": 10}, "action": {"text": "using", "start": 92, "end": 97, "i_start": 14, "i_end": 14}}, {"character": {"text": "correspondence", "start": 58, "end": 72, "i_start": 10, "i_end": 10}, "action": {"text": "yielding", "start": 114, "end": 122, "i_start": 18, "i_end": 18}}], "id": 3645}, {"sent": "recently , the biologically inspired deep learning network has resulted in significant advances in many computer vision tasks .", "tokens": ["recently", ",", "the", "biologically", "inspired", "deep", "learning", "network", "has", "resulted", "in", "significant", "advances", "in", "many", "computer", "vision", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the biologically inspired deep learning network", "start": 11, "end": 58, "i_start": 2, "i_end": 7}, "verb": {"text": "has resulted", "start": 59, "end": 71, "i_start": 8, "i_end": 9}}, {"character": {"text": "network", "start": 51, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "learning", "start": 42, "end": 50, "i_start": 6, "i_end": 6}}, {"character": {"text": "biologically", "start": 15, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "inspired", "start": 28, "end": 36, "i_start": 4, "i_end": 4}}], "id": 3646}, {"sent": "the tensor jkl and rij be the curvature and the is called the projective weyl tensor .", "tokens": ["the", "tensor", "jkl", "and", "rij", "be", "the", "curvature", "and", "the", "is", "called", "the", "projective", "weyl", "tensor", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the tensor jkl and rij", "start": 0, "end": 22, "i_start": 0, "i_end": 4}, "verb": {"text": "be", "start": 23, "end": 25, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the", "start": 44, "end": 47, "i_start": 9, "i_end": 9}, "verb": {"text": "called", "start": 51, "end": 57, "i_start": 11, "i_end": 11}}], "id": 3647}, {"sent": "the constant-time section of three-dimensional cubic lattice is known as the kagome lattice .", "tokens": ["the", "constant", "-", "time", "section", "of", "three", "-", "dimensional", "cubic", "lattice", "is", "known", "as", "the", "kagome", "lattice", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the constant-time section of three-dimensional cubic lattice", "start": 0, "end": 60, "i_start": 0, "i_end": 10}, "verb": {"text": "is known", "start": 61, "end": 69, "i_start": 11, "i_end": 12}}], "id": 3648}, {"sent": "to analyze data streams in this way , in we develop an approach to ultrametric embedding of time-varying signals , including biomedical , meteorological , financial and other .", "tokens": ["to", "analyze", "data", "streams", "in", "this", "way", ",", "in", "we", "develop", "an", "approach", "to", "ultrametric", "embedding", "of", "time", "-", "varying", "signals", ",", "including", "biomedical", ",", "meteorological", ",", "financial", "and", "other", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 41, "end": 43, "i_start": 9, "i_end": 9}, "verb": {"text": "develop", "start": 44, "end": 51, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 41, "end": 43, "i_start": 9, "i_end": 9}, "action": {"text": "develop", "start": 44, "end": 51, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 41, "end": 43, "i_start": 9, "i_end": 9}, "action": {"text": "approach", "start": 55, "end": 63, "i_start": 12, "i_end": 12}}, {"character": {"text": "signals", "start": 105, "end": 112, "i_start": 20, "i_end": 20}, "action": {"text": "varying", "start": 97, "end": 104, "i_start": 19, "i_end": 19}}], "id": 3649}, {"sent": "in particular , in recent years , convolutional neural networks have been successful for image classification in various important real-world applications such as medical imaging .", "tokens": ["in", "particular", ",", "in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "been", "successful", "for", "image", "classification", "in", "various", "important", "real", "-", "world", "applications", "such", "as", "medical", "imaging", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 34, "end": 63, "i_start": 7, "i_end": 9}, "verb": {"text": "have been", "start": 64, "end": 73, "i_start": 10, "i_end": 11}}, {"character": {"text": "networks", "start": 55, "end": 63, "i_start": 9, "i_end": 9}, "action": {"text": "successful", "start": 74, "end": 84, "i_start": 12, "i_end": 12}}], "id": 3650}, {"sent": "a naked singularity is a curvature singularity from which information can travel to a distant observer .", "tokens": ["a", "naked", "singularity", "is", "a", "curvature", "singularity", "from", "which", "information", "can", "travel", "to", "a", "distant", "observer", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a naked singularity", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "singularity", "start": 8, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "travel", "start": 74, "end": 80, "i_start": 11, "i_end": 11}}], "id": 3651}, {"sent": "we used batch normalization with every convolution layer so as to make the network converge faster .", "tokens": ["we", "used", "batch", "normalization", "with", "every", "convolution", "layer", "so", "as", "to", "make", "the", "network", "converge", "faster", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "make", "start": 66, "end": 70, "i_start": 11, "i_end": 11}}, {"character": {"text": "network", "start": 75, "end": 82, "i_start": 13, "i_end": 13}, "action": {"text": "converge", "start": 83, "end": 91, "i_start": 14, "i_end": 14}}], "id": 3652}, {"sent": "in recent years , deep convolutional networks have achieved remarkable results in many computer vision tasks .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "networks", "have", "achieved", "remarkable", "results", "in", "many", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional networks", "start": 18, "end": 45, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 8, "i_end": 8}}], "id": 3653}, {"sent": "since the inflaton s is a bulk superfield , it participates in both superpotentials .", "tokens": ["since", "the", "inflaton", "s", "is", "a", "bulk", "superfield", ",", "it", "participates", "in", "both", "superpotentials", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 44, "end": 46, "i_start": 9, "i_end": 9}, "verb": {"text": "participates", "start": 47, "end": 59, "i_start": 10, "i_end": 10}}, {"character": {"text": "inflaton", "start": 10, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "participates", "start": 47, "end": 59, "i_start": 10, "i_end": 10}}], "id": 3654}, {"sent": "the next section describes the particle fitness functions used in all the simulations .", "tokens": ["the", "next", "section", "describes", "the", "particle", "fitness", "functions", "used", "in", "all", "the", "simulations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the next section", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "describes", "start": 17, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "section", "start": 9, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "describes", "start": 17, "end": 26, "i_start": 3, "i_end": 3}}], "id": 3655}, {"sent": "the surviving properties appear in figure , 1 , where an arrow denotes implication .", "tokens": ["the", "surviving", "properties", "appear", "in", "figure", ",", "1", ",", "where", "an", "arrow", "denotes", "implication", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the surviving properties", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "appear", "start": 25, "end": 31, "i_start": 3, "i_end": 3}}, {"character": {"text": "properties", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "surviving", "start": 4, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "arrow", "start": 57, "end": 62, "i_start": 11, "i_end": 11}, "action": {"text": "denotes", "start": 63, "end": 70, "i_start": 12, "i_end": 12}}], "id": 3656}, {"sent": "reconstructing the velocity distribution of wimps from direct dark matter detection data .", "tokens": ["reconstructing", "the", "velocity", "distribution", "of", "wimps", "from", "direct", "dark", "matter", "detection", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3657}, {"sent": "br ( b s\u03b3 ) is smaller than the lower limit of the cleo result .", "tokens": ["br", "(", "b", "s\u03b3", ")", "is", "smaller", "than", "the", "lower", "limit", "of", "the", "cleo", "result", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "br ( b s\u03b3 )", "start": 0, "end": 11, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 5, "i_end": 5}}], "id": 3658}, {"sent": "the expectation-maximization algorithm has been widely applied for solving the decipherment problem .", "tokens": ["the", "expectation", "-", "maximization", "algorithm", "has", "been", "widely", "applied", "for", "solving", "the", "decipherment", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the expectation-maximization algorithm", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "applied", "start": 55, "end": 62, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the expectation-maximization algorithm", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "has been", "start": 39, "end": 47, "i_start": 5, "i_end": 6}}], "id": 3659}, {"sent": "zwanziger , gauge and topological symmetries in the bulk quantization of gauge theories , nucl .", "tokens": ["zwanziger", ",", "gauge", "and", "topological", "symmetries", "in", "the", "bulk", "quantization", "of", "gauge", "theories", ",", "nucl", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3660}, {"sent": "the last key technique is to use level sets of the plurisubharmonic measure .", "tokens": ["the", "last", "key", "technique", "is", "to", "use", "level", "sets", "of", "the", "plurisubharmonic", "measure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the last key technique", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 4, "i_end": 4}}], "id": 3661}, {"sent": "on recent intermittency models of turbulence .", "tokens": ["on", "recent", "intermittency", "models", "of", "turbulence", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3662}, {"sent": "the mass of a particle is the result of the total motion of the charge or alternatively the waves of the particle against a frictional vacuum .", "tokens": ["the", "mass", "of", "a", "particle", "is", "the", "result", "of", "the", "total", "motion", "of", "the", "charge", "or", "alternatively", "the", "waves", "of", "the", "particle", "against", "a", "frictional", "vacuum", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the mass of a particle", "start": 0, "end": 22, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 5, "i_end": 5}}], "id": 3663}, {"sent": "the result is expressed in the following theorem .", "tokens": ["the", "result", "is", "expressed", "in", "the", "following", "theorem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the result", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is expressed", "start": 11, "end": 23, "i_start": 2, "i_end": 3}}], "id": 3664}, {"sent": "imputation is a term that denotes the the missing values by procedure considering the observations .", "tokens": ["imputation", "is", "a", "term", "that", "denotes", "the", "the", "missing", "values", "by", "procedure", "considering", "the", "observations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "imputation", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "term", "start": 16, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "denotes", "start": 26, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "procedure", "start": 60, "end": 69, "i_start": 11, "i_end": 11}, "action": {"text": "considering", "start": 70, "end": 81, "i_start": 12, "i_end": 12}}], "id": 3665}, {"sent": "but the orbit through is a torus-knot which is not taut .", "tokens": ["but", "the", "orbit", "through", "is", "a", "torus", "-", "knot", "which", "is", "not", "taut", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the orbit through", "start": 4, "end": 21, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}], "id": 3666}, {"sent": "the mwa data were calibrated with the common astronomy software applications , using observations of a calibrator source .", "tokens": ["the", "mwa", "data", "were", "calibrated", "with", "the", "common", "astronomy", "software", "applications", ",", "using", "observations", "of", "a", "calibrator", "source", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the mwa data", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "were calibrated", "start": 13, "end": 28, "i_start": 3, "i_end": 4}}, {"character": {"text": "source", "start": 114, "end": 120, "i_start": 17, "i_end": 17}, "action": {"text": "observations", "start": 85, "end": 97, "i_start": 13, "i_end": 13}}], "id": 3667}, {"sent": "the orbifold consists of an aggregation of 32 regions such as the one shown in this figure .", "tokens": ["the", "orbifold", "consists", "of", "an", "aggregation", "of", "32", "regions", "such", "as", "the", "one", "shown", "in", "this", "figure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the orbifold", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 13, "end": 21, "i_start": 2, "i_end": 2}}], "id": 3668}, {"sent": "in section 5 we present a detailed comparison between the non-linear 6-parametric plate and the cosserat plate model proposed and investigated by the second author in .", "tokens": ["in", "section", "5", "we", "present", "a", "detailed", "comparison", "between", "the", "non", "-", "linear", "6", "-", "parametric", "plate", "and", "the", "cosserat", "plate", "model", "proposed", "and", "investigated", "by", "the", "second", "author", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "present", "start": 16, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "present", "start": 16, "end": 23, "i_start": 4, "i_end": 4}}], "id": 3669}, {"sent": "in particular , macroscopic models derived by closing the mass conservation equation with suitable relations for the velocity follow the ideas outlined above , see eg , coscia and canavesio .", "tokens": ["in", "particular", ",", "macroscopic", "models", "derived", "by", "closing", "the", "mass", "conservation", "equation", "with", "suitable", "relations", "for", "the", "velocity", "follow", "the", "ideas", "outlined", "above", ",", "see", "eg", ",", "coscia", "and", "canavesio", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "macroscopic models derived by closing the mass conservation equation with suitable relations for the velocity", "start": 16, "end": 125, "i_start": 3, "i_end": 17}, "verb": {"text": "follow", "start": 126, "end": 132, "i_start": 18, "i_end": 18}}, {"character": {"text": "models", "start": 28, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "follow", "start": 126, "end": 132, "i_start": 18, "i_end": 18}}], "id": 3670}, {"sent": "in recent years , convolutional neural networks have achieved superior performance in many visual tasks , such as object classification and detection .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "classification", "and", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 48, "end": 61, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 53, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 71, "end": 82, "i_start": 10, "i_end": 10}}], "id": 3671}, {"sent": "in recent years , convolutional neural networks has achieved remarkable results in a wide range of computer vision applications .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "has", "achieved", "remarkable", "results", "in", "a", "wide", "range", "of", "computer", "vision", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "has achieved", "start": 48, "end": 60, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 52, "end": 60, "i_start": 8, "i_end": 8}}], "id": 3672}, {"sent": "up to this point , we have analyzed all proper subsets of as the first one and the second identity only on p .", "tokens": ["up", "to", "this", "point", ",", "we", "have", "analyzed", "all", "proper", "subsets", "of", "as", "the", "first", "one", "and", "the", "second", "identity", "only", "on", "p", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 5, "i_end": 5}, "verb": {"text": "have analyzed", "start": 22, "end": 35, "i_start": 6, "i_end": 7}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 5, "i_end": 5}, "action": {"text": "analyzed", "start": 27, "end": 35, "i_start": 7, "i_end": 7}}], "id": 3673}, {"sent": "two notable approaches in this area are variational auto-encoders as well as generative adversarial networks .", "tokens": ["two", "notable", "approaches", "in", "this", "area", "are", "variational", "auto", "-", "encoders", "as", "well", "as", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "two notable approaches in this area", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 36, "end": 39, "i_start": 6, "i_end": 6}}], "id": 3674}, {"sent": "this degeneracy is a result of the invariance of the linearized hamiltonian under the symmetry operation tdirac .", "tokens": ["this", "degeneracy", "is", "a", "result", "of", "the", "invariance", "of", "the", "linearized", "hamiltonian", "under", "the", "symmetry", "operation", "tdirac", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this degeneracy", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3675}, {"sent": "its only prerequisite is the 1 knowledge of at least one reactive dynamical trajectory .", "tokens": ["its", "only", "prerequisite", "is", "the", "1", "knowledge", "of", "at", "least", "one", "reactive", "dynamical", "trajectory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "its only prerequisite", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "trajectory", "start": 76, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "reactive", "start": 57, "end": 65, "i_start": 11, "i_end": 11}}], "id": 3676}, {"sent": "if the higgs boson is a very narrow resonance , we will observe a rapid increase in the visible cross section of the higgs production during energy scanning .", "tokens": ["if", "the", "higgs", "boson", "is", "a", "very", "narrow", "resonance", ",", "we", "will", "observe", "a", "rapid", "increase", "in", "the", "visible", "cross", "section", "of", "the", "higgs", "production", "during", "energy", "scanning", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 48, "end": 50, "i_start": 10, "i_end": 10}, "verb": {"text": "will observe", "start": 51, "end": 63, "i_start": 11, "i_end": 12}}, {"character": {"text": "we", "start": 48, "end": 50, "i_start": 10, "i_end": 10}, "action": {"text": "observe", "start": 56, "end": 63, "i_start": 12, "i_end": 12}}], "id": 3677}, {"sent": "henceforth , there is a need to extend the contemporary areas of quantum chemistry to the realm of , for instance , finite temperature .", "tokens": ["henceforth", ",", "there", "is", "a", "need", "to", "extend", "the", "contemporary", "areas", "of", "quantum", "chemistry", "to", "the", "realm", "of", ",", "for", "instance", ",", "finite", "temperature", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 13, "end": 18, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 3678}, {"sent": "the the coefficient a is a function of the velocity and the hydrodynamic fields x1 and t .", "tokens": ["the", "the", "coefficient", "a", "is", "a", "function", "of", "the", "velocity", "and", "the", "hydrodynamic", "fields", "x1", "and", "t", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the the coefficient a", "start": 0, "end": 21, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "velocity", "start": 43, "end": 51, "i_start": 9, "i_end": 9}, "action": {"text": "function", "start": 27, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "fields", "start": 73, "end": 79, "i_start": 13, "i_end": 13}, "action": {"text": "function", "start": 27, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "hydrodynamic", "start": 60, "end": 72, "i_start": 12, "i_end": 12}, "action": {"text": "function", "start": 27, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "x1", "start": 80, "end": 82, "i_start": 14, "i_end": 14}, "action": {"text": "function", "start": 27, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "t", "start": 87, "end": 88, "i_start": 16, "i_end": 16}, "action": {"text": "function", "start": 27, "end": 35, "i_start": 6, "i_end": 6}}], "id": 3679}, {"sent": "similar plots have been obtained for the other proton angles .", "tokens": ["similar", "plots", "have", "been", "obtained", "for", "the", "other", "proton", "angles", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "similar plots", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "have been obtained", "start": 14, "end": 32, "i_start": 2, "i_end": 4}}], "id": 3680}, {"sent": "the crystal was found to consist of a single ferroelectric domain in thz wave emission experiments27 , in which the orientation of the ferroelectric c axis was also determined .", "tokens": ["the", "crystal", "was", "found", "to", "consist", "of", "a", "single", "ferroelectric", "domain", "in", "thz", "wave", "emission", "experiments27", ",", "in", "which", "the", "orientation", "of", "the", "ferroelectric", "c", "axis", "was", "also", "determined", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the crystal", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "was found", "start": 12, "end": 21, "i_start": 2, "i_end": 3}}], "id": 3681}, {"sent": "the jobrequestanalyzer interface defines the analyze method to encapsulate the task of jobrequest analysis .", "tokens": ["the", "jobrequestanalyzer", "interface", "defines", "the", "analyze", "method", "to", "encapsulate", "the", "task", "of", "jobrequest", "analysis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the jobrequestanalyzer interface", "start": 0, "end": 32, "i_start": 0, "i_end": 2}, "verb": {"text": "defines", "start": 33, "end": 40, "i_start": 3, "i_end": 3}}, {"character": {"text": "interface", "start": 23, "end": 32, "i_start": 2, "i_end": 2}, "action": {"text": "defines", "start": 33, "end": 40, "i_start": 3, "i_end": 3}}], "id": 3682}, {"sent": "in recent years , deep neural networks have revolutionized machine-learning tasks such as image classification , speech recognition and language translation .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "revolutionized", "machine", "-", "learning", "tasks", "such", "as", "image", "classification", ",", "speech", "recognition", "and", "language", "translation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have revolutionized", "start": 39, "end": 58, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "revolutionized", "start": 44, "end": 58, "i_start": 8, "i_end": 8}}], "id": 3683}, {"sent": "deep convolutional neural networks have achieved great success in various computer vision tasks , including object classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "various", "computer", "vision", "tasks", ",", "including", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}], "id": 3684}, {"sent": "the physical mechanism behind interference stabilization is associated with multiple raman-type transitions between the rydberg levels and the common continuum .", "tokens": ["the", "physical", "mechanism", "behind", "interference", "stabilization", "is", "associated", "with", "multiple", "raman", "-", "type", "transitions", "between", "the", "rydberg", "levels", "and", "the", "common", "continuum", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the physical mechanism behind interference stabilization", "start": 0, "end": 56, "i_start": 0, "i_end": 5}, "verb": {"text": "is associated", "start": 57, "end": 70, "i_start": 6, "i_end": 7}}], "id": 3685}, {"sent": "recent years have seen improvement in the generalizability of passive perception systems , in domains such as computer vision , natural language processing , and speech recognition through the use of deep learning techniques .", "tokens": ["recent", "years", "have", "seen", "improvement", "in", "the", "generalizability", "of", "passive", "perception", "systems", ",", "in", "domains", "such", "as", "computer", "vision", ",", "natural", "language", "processing", ",", "and", "speech", "recognition", "through", "the", "use", "of", "deep", "learning", "techniques", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent years", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "have seen", "start": 13, "end": 22, "i_start": 2, "i_end": 3}}, {"character": {"text": "years", "start": 7, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "seen", "start": 18, "end": 22, "i_start": 3, "i_end": 3}}], "id": 3686}, {"sent": "a recent estimate places the worldwide burden of dengue at 390 million infections per year , of which 96 million manifest clinically .", "tokens": ["a", "recent", "estimate", "places", "the", "worldwide", "burden", "of", "dengue", "at", "390", "million", "infections", "per", "year", ",", "of", "which", "96", "million", "manifest", "clinically", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a recent estimate", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "places", "start": 18, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "estimate", "start": 9, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "places", "start": 18, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3687}, {"sent": "the theoretical calculations are performed within the projector augmented wave method and the density functional theory framework as implemented in the vienna ab-initio simulation package .", "tokens": ["the", "theoretical", "calculations", "are", "performed", "within", "the", "projector", "augmented", "wave", "method", "and", "the", "density", "functional", "theory", "framework", "as", "implemented", "in", "the", "vienna", "ab", "-", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the theoretical calculations", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "are performed", "start": 29, "end": 42, "i_start": 3, "i_end": 4}}], "id": 3688}, {"sent": "this strategy was employed by maiorca et al , to generate js and pdf embedding attacks .", "tokens": ["this", "strategy", "was", "employed", "by", "maiorca", "et", "al", ",", "to", "generate", "js", "and", "pdf", "embedding", "attacks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this strategy", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "was employed", "start": 14, "end": 26, "i_start": 2, "i_end": 3}}, {"character": {"text": "maiorca", "start": 30, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "employed", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "maiorca", "start": 30, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "generate", "start": 49, "end": 57, "i_start": 10, "i_end": 10}}], "id": 3689}, {"sent": "a quantum computer has the potential to solve certain problems and implement simulations faster than any classical computer .", "tokens": ["a", "quantum", "computer", "has", "the", "potential", "to", "solve", "certain", "problems", "and", "implement", "simulations", "faster", "than", "any", "classical", "computer", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a quantum computer", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "has", "start": 19, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "computer", "start": 10, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "solve", "start": 40, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "computer", "start": 10, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "implement", "start": 67, "end": 76, "i_start": 11, "i_end": 11}}], "id": 3690}, {"sent": "one of those effects is the unruh one seen by a uniformly accelerating observer .", "tokens": ["one", "of", "those", "effects", "is", "the", "unruh", "one", "seen", "by", "a", "uniformly", "accelerating", "observer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one of those effects", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 4, "i_end": 4}}], "id": 3691}, {"sent": "in fact , the analysis of the quantization process has gained a lot of attention in the academic research due to its practical relevance .", "tokens": ["in", "fact", ",", "the", "analysis", "of", "the", "quantization", "process", "has", "gained", "a", "lot", "of", "attention", "in", "the", "academic", "research", "due", "to", "its", "practical", "relevance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the analysis of the quantization process", "start": 10, "end": 50, "i_start": 3, "i_end": 8}, "verb": {"text": "has gained", "start": 51, "end": 61, "i_start": 9, "i_end": 10}}, {"character": {"text": "analysis", "start": 14, "end": 22, "i_start": 4, "i_end": 4}, "action": {"text": "gained", "start": 55, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "research", "start": 97, "end": 105, "i_start": 18, "i_end": 18}, "action": {"text": "attention", "start": 71, "end": 80, "i_start": 14, "i_end": 14}}], "id": 3692}, {"sent": "the design of compact gks based on the cell averaged and cell interface values has been conducted before .", "tokens": ["the", "design", "of", "compact", "gks", "based", "on", "the", "cell", "averaged", "and", "cell", "interface", "values", "has", "been", "conducted", "before", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the design of compact gks based on the cell", "start": 0, "end": 43, "i_start": 0, "i_end": 8}, "verb": {"text": "averaged", "start": 44, "end": 52, "i_start": 9, "i_end": 9}}, {"subject": {"text": "cell interface values", "start": 57, "end": 78, "i_start": 11, "i_end": 13}, "verb": {"text": "conducted", "start": 88, "end": 97, "i_start": 16, "i_end": 16}}], "id": 3693}, {"sent": "if the diquark model is correct , pentaquarks can be related to anti-baryons through replacing two diquarks by two anti-quarks .", "tokens": ["if", "the", "diquark", "model", "is", "correct", ",", "pentaquarks", "can", "be", "related", "to", "anti", "-", "baryons", "through", "replacing", "two", "diquarks", "by", "two", "anti", "-", "quarks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "pentaquarks", "start": 34, "end": 45, "i_start": 7, "i_end": 7}, "verb": {"text": "can be related", "start": 46, "end": 60, "i_start": 8, "i_end": 10}}, {"character": {"text": "diquark model is correct , pentaquarks can be related to anti-baryons through replacing two", "start": 7, "end": 98, "i_start": 2, "i_end": 17}, "action": {"text": "anti", "start": 115, "end": 119, "i_start": 21, "i_end": 21}}], "id": 3694}, {"sent": "neutrino oscillations in the early universe .", "tokens": ["neutrino", "oscillations", "in", "the", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3695}, {"sent": "subsequently , we derive an asymptotic local minimax lower bound on the optimal estimation rate for f .", "tokens": ["subsequently", ",", "we", "derive", "an", "asymptotic", "local", "minimax", "lower", "bound", "on", "the", "optimal", "estimation", "rate", "for", "f", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "derive", "start": 18, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "derive", "start": 18, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3696}, {"sent": "this algebra is commutative and satisfies identity .", "tokens": ["this", "algebra", "is", "commutative", "and", "satisfies", "identity", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this algebra", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "algebra", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "satisfies", "start": 32, "end": 41, "i_start": 5, "i_end": 5}}], "id": 3697}, {"sent": "we consider the possibility that the repulsion is eliminated through the presence in the interior of the q-ball of fermions with charge opposite to that of the scalar condensate .", "tokens": ["we", "consider", "the", "possibility", "that", "the", "repulsion", "is", "eliminated", "through", "the", "presence", "in", "the", "interior", "of", "the", "q", "-", "ball", "of", "fermions", "with", "charge", "opposite", "to", "that", "of", "the", "scalar", "condensate", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "consider", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "consider", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "presence", "start": 73, "end": 81, "i_start": 11, "i_end": 11}, "action": {"text": "eliminated", "start": 50, "end": 60, "i_start": 8, "i_end": 8}}], "id": 3698}, {"sent": "elschenbroich , for the hermes collaboration , these proceedings .", "tokens": ["elschenbroich", ",", "for", "the", "hermes", "collaboration", ",", "these", "proceedings", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3699}, {"sent": "these terms appear in sequence a000975 of the on-line encyclopedia of integer sequences .", "tokens": ["these", "terms", "appear", "in", "sequence", "a000975", "of", "the", "on", "-", "line", "encyclopedia", "of", "integer", "sequences", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these terms", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "appear", "start": 12, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3700}, {"sent": "gravity is a long range force , and every particle interacts pairwise with every other particle .", "tokens": ["gravity", "is", "a", "long", "range", "force", ",", "and", "every", "particle", "interacts", "pairwise", "with", "every", "other", "particle", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "gravity", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "every particle", "start": 36, "end": 50, "i_start": 8, "i_end": 9}, "verb": {"text": "interacts", "start": 51, "end": 60, "i_start": 10, "i_end": 10}}, {"character": {"text": "gravity", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "force", "start": 24, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "particle", "start": 42, "end": 50, "i_start": 9, "i_end": 9}, "action": {"text": "interacts", "start": 51, "end": 60, "i_start": 10, "i_end": 10}}], "id": 3701}, {"sent": "powerful deep neural networks have been created and investigated for high-level computer vision tasks such as image classification .", "tokens": ["powerful", "deep", "neural", "networks", "have", "been", "created", "and", "investigated", "for", "high", "-", "level", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "powerful deep neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "have been created", "start": 30, "end": 47, "i_start": 4, "i_end": 6}}, {"subject": {"text": "powerful deep neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "investigated", "start": 52, "end": 64, "i_start": 8, "i_end": 8}}], "id": 3702}, {"sent": "these methods to some extent are complementary .", "tokens": ["these", "methods", "to", "some", "extent", "are", "complementary", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "these methods to some extent", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "are", "start": 29, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "methods", "start": 6, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "complementary", "start": 33, "end": 46, "i_start": 6, "i_end": 6}}], "id": 3703}, {"sent": "the generalized gradient approximation parametrized by perdew-burke-ernzerhof was employed for the evaluation of the exchange-correlation functional .", "tokens": ["the", "generalized", "gradient", "approximation", "parametrized", "by", "perdew", "-", "burke", "-", "ernzerhof", "was", "employed", "for", "the", "evaluation", "of", "the", "exchange", "-", "correlation", "functional", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation parametrized by perdew-burke-ernzerhof", "start": 0, "end": 77, "i_start": 0, "i_end": 10}, "verb": {"text": "was employed", "start": 78, "end": 90, "i_start": 11, "i_end": 12}}, {"character": {"text": "perdew", "start": 55, "end": 61, "i_start": 6, "i_end": 6}, "action": {"text": "parametrized", "start": 39, "end": 51, "i_start": 4, "i_end": 4}}], "id": 3704}, {"sent": "the operad comtridend is the trisuccessor of the operad comm .", "tokens": ["the", "operad", "comtridend", "is", "the", "trisuccessor", "of", "the", "operad", "comm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the operad comtridend", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3705}, {"sent": "deep neural networks trained with millions of parameters have achieved tremendous success in various machine learning tasks including speech , natural language and image processing .", "tokens": ["deep", "neural", "networks", "trained", "with", "millions", "of", "parameters", "have", "achieved", "tremendous", "success", "in", "various", "machine", "learning", "tasks", "including", "speech", ",", "natural", "language", "and", "image", "processing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks trained with millions of parameters", "start": 0, "end": 56, "i_start": 0, "i_end": 7}, "verb": {"text": "have achieved", "start": 57, "end": 70, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 82, "end": 89, "i_start": 11, "i_end": 11}}], "id": 3706}, {"sent": "the duality is the interchange between riemann and its double dual .", "tokens": ["the", "duality", "is", "the", "interchange", "between", "riemann", "and", "its", "double", "dual", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the duality", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 3707}, {"sent": "now we proceed on to give examples of non-commutative bisemirings .", "tokens": ["now", "we", "proceed", "on", "to", "give", "examples", "of", "non", "-", "commutative", "bisemirings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed on", "start": 7, "end": 17, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "give", "start": 21, "end": 25, "i_start": 5, "i_end": 5}}], "id": 3708}, {"sent": "in thermodynamics this is a reflection of the fact that the chemical potential has the same form for liquids and gases .", "tokens": ["in", "thermodynamics", "this", "is", "a", "reflection", "of", "the", "fact", "that", "the", "chemical", "potential", "has", "the", "same", "form", "for", "liquids", "and", "gases", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 18, "end": 22, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "potential", "start": 69, "end": 78, "i_start": 12, "i_end": 12}, "action": {"text": "has", "start": 79, "end": 82, "i_start": 13, "i_end": 13}}], "id": 3709}, {"sent": "deep neural networks have been widely used in many artificial intelligence applications including computer vision .", "tokens": ["deep", "neural", "networks", "have", "been", "widely", "used", "in", "many", "artificial", "intelligence", "applications", "including", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 38, "end": 42, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}], "id": 3710}, {"sent": "consequently , the stable island is known as a dynamical barrier .", "tokens": ["consequently", ",", "the", "stable", "island", "is", "known", "as", "a", "dynamical", "barrier", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the stable island", "start": 15, "end": 32, "i_start": 2, "i_end": 4}, "verb": {"text": "is known", "start": 33, "end": 41, "i_start": 5, "i_end": 6}}], "id": 3711}, {"sent": "we use the resnet50 model and extract the features from the third convolutional block .", "tokens": ["we", "use", "the", "resnet50", "model", "and", "extract", "the", "features", "from", "the", "third", "convolutional", "block", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "extract", "start": 30, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extract", "start": 30, "end": 37, "i_start": 6, "i_end": 6}}], "id": 3712}, {"sent": "we use the model in neural image caption , a large-scale dataset for the object detection , segmentation , and captioning .", "tokens": ["we", "use", "the", "model", "in", "neural", "image", "caption", ",", "a", "large", "-", "scale", "dataset", "for", "the", "object", "detection", ",", "segmentation", ",", "and", "captioning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 3713}, {"sent": "deep neural networks have shown considerable capabilities for handling specific complex tasks such as speech recognition .", "tokens": ["deep", "neural", "networks", "have", "shown", "considerable", "capabilities", "for", "handling", "specific", "complex", "tasks", "such", "as", "speech", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "handling", "start": 62, "end": 70, "i_start": 8, "i_end": 8}}], "id": 3714}, {"sent": "in , allen gave an alternative proof , which gave a better bound on n .", "tokens": ["in", ",", "allen", "gave", "an", "alternative", "proof", ",", "which", "gave", "a", "better", "bound", "on", "n", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "allen", "start": 5, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "gave", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}], "id": 3715}, {"sent": "convolutional neural networks have achieved great success on visual recognition tasks .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "great", "success", "on", "visual", "recognition", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}], "id": 3716}, {"sent": "in , the authors studied the energy efficiency of comp multi-cell networks with capacity constrained backhaul links .", "tokens": ["in", ",", "the", "authors", "studied", "the", "energy", "efficiency", "of", "comp", "multi", "-", "cell", "networks", "with", "capacity", "constrained", "backhaul", "links", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 5, "end": 16, "i_start": 2, "i_end": 3}, "verb": {"text": "studied", "start": 17, "end": 24, "i_start": 4, "i_end": 4}}], "id": 3717}, {"sent": "many networks seen in the real world have a degree distribution which is a power-law for large degrees , at least to some approximation .", "tokens": ["many", "networks", "seen", "in", "the", "real", "world", "have", "a", "degree", "distribution", "which", "is", "a", "power", "-", "law", "for", "large", "degrees", ",", "at", "least", "to", "some", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many networks seen in the real world", "start": 0, "end": 36, "i_start": 0, "i_end": 6}, "verb": {"text": "have", "start": 37, "end": 41, "i_start": 7, "i_end": 7}}], "id": 3718}, {"sent": "deep neural networks have shown significant improvements in many application domains , ranging from computer vision .", "tokens": ["deep", "neural", "networks", "have", "shown", "significant", "improvements", "in", "many", "application", "domains", ",", "ranging", "from", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 26, "end": 31, "i_start": 4, "i_end": 4}}], "id": 3719}, {"sent": "its quantum counterpart is the integration of the electrostatic interactions which give rise to 3 an atomic bound state in a two-level atom .", "tokens": ["its", "quantum", "counterpart", "is", "the", "integration", "of", "the", "electrostatic", "interactions", "which", "give", "rise", "to", "3", "an", "atomic", "bound", "state", "in", "a", "two", "-", "level", "atom", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "its quantum counterpart", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "interactions", "start": 64, "end": 76, "i_start": 9, "i_end": 9}, "action": {"text": "rise", "start": 88, "end": 92, "i_start": 12, "i_end": 12}}], "id": 3720}, {"sent": "current-driven magnetic excitations in permalloy-based multilayer nanopillars .", "tokens": ["current", "-", "driven", "magnetic", "excitations", "in", "permalloy", "-", "based", "multilayer", "nanopillars", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "current", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "driven", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}], "id": 3721}, {"sent": "tf analysis based on different principals has attracted a lot of attention in the field and many variations are available .", "tokens": ["tf", "analysis", "based", "on", "different", "principals", "has", "attracted", "a", "lot", "of", "attention", "in", "the", "field", "and", "many", "variations", "are", "available", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "tf analysis based on different principals", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "has attracted", "start": 42, "end": 55, "i_start": 6, "i_end": 7}}, {"character": {"text": "analysis", "start": 3, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "attracted", "start": 46, "end": 55, "i_start": 7, "i_end": 7}}], "id": 3722}, {"sent": "deep neural networks have garnered interest from many researchers after being successfully applied in image classification .", "tokens": ["deep", "neural", "networks", "have", "garnered", "interest", "from", "many", "researchers", "after", "being", "successfully", "applied", "in", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have garnered", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "garnered", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successfully", "start": 78, "end": 90, "i_start": 11, "i_end": 11}}], "id": 3723}, {"sent": "each of these settings is a vector of two phases .", "tokens": ["each", "of", "these", "settings", "is", "a", "vector", "of", "two", "phases", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each of these settings", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 4, "i_end": 4}}], "id": 3724}, {"sent": "whilst this is a satisfying exercise , it is not clear that it introduces any benefits beyond putting the equations in a manifestly coordinate invariant form .", "tokens": ["whilst", "this", "is", "a", "satisfying", "exercise", ",", "it", "is", "not", "clear", "that", "it", "introduces", "any", "benefits", "beyond", "putting", "the", "equations", "in", "a", "manifestly", "coordinate", "invariant", "form", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 39, "end": 41, "i_start": 7, "i_end": 7}, "verb": {"text": "is not", "start": 42, "end": 48, "i_start": 8, "i_end": 9}}, {"subject": {"text": "it", "start": 60, "end": 62, "i_start": 12, "i_end": 12}, "verb": {"text": "introduces", "start": 63, "end": 73, "i_start": 13, "i_end": 13}}, {"character": {"text": "this", "start": 7, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "introduces", "start": 63, "end": 73, "i_start": 13, "i_end": 13}}], "id": 3725}, {"sent": "empowered by recent hardware advance , deep neural networks of various architectures have been harnessed to solve many long-standing computer vision problems such as recognition .", "tokens": ["empowered", "by", "recent", "hardware", "advance", ",", "deep", "neural", "networks", "of", "various", "architectures", "have", "been", "harnessed", "to", "solve", "many", "long", "-", "standing", "computer", "vision", "problems", "such", "as", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks of various architectures", "start": 39, "end": 84, "i_start": 6, "i_end": 11}, "verb": {"text": "have been harnessed", "start": 85, "end": 104, "i_start": 12, "i_end": 14}}, {"character": {"text": "networks", "start": 51, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "solve", "start": 108, "end": 113, "i_start": 16, "i_end": 16}}], "id": 3726}, {"sent": "path loss was calculated based on the ci los path loss model , with a tr separation distance equal to the total propagated ray length .", "tokens": ["path", "loss", "was", "calculated", "based", "on", "the", "ci", "los", "path", "loss", "model", ",", "with", "a", "tr", "separation", "distance", "equal", "to", "the", "total", "propagated", "ray", "length", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "path loss", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "was calculated", "start": 10, "end": 24, "i_start": 2, "i_end": 3}}, {"character": {"text": "ray", "start": 123, "end": 126, "i_start": 23, "i_end": 23}, "action": {"text": "propagated", "start": 112, "end": 122, "i_start": 22, "i_end": 22}}], "id": 3727}, {"sent": "a quantum network consists of wires that connect successive quan tum gates .", "tokens": ["a", "quantum", "network", "consists", "of", "wires", "that", "connect", "successive", "quan", "tum", "gates", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a quantum network", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "wires", "start": 30, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "connect", "start": 41, "end": 48, "i_start": 7, "i_end": 7}}], "id": 3728}, {"sent": "sbft is deterministic so lacks liveness in the asynchronous mode , due to flp .", "tokens": ["sbft", "is", "deterministic", "so", "lacks", "liveness", "in", "the", "asynchronous", "mode", ",", "due", "to", "flp", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "sbft", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3729}, {"sent": "in image cs recovery , we compare the proposed gscw p with eight other competing methods including bcs .", "tokens": ["in", "image", "cs", "recovery", ",", "we", "compare", "the", "proposed", "gscw", "p", "with", "eight", "other", "competing", "methods", "including", "bcs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "verb": {"text": "compare", "start": 26, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "action": {"text": "compare", "start": 26, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "eight", "start": 59, "end": 64, "i_start": 12, "i_end": 12}, "action": {"text": "competing", "start": 71, "end": 80, "i_start": 14, "i_end": 14}}], "id": 3730}, {"sent": "as shown in , the sources and sinks in the species continuity equations that arise from ionization and recombination reactions can be evaluated by taking the zeroth moments of the collision operators pertaining to ionization and recombination collisions .", "tokens": ["as", "shown", "in", ",", "the", "sources", "and", "sinks", "in", "the", "species", "continuity", "equations", "that", "arise", "from", "ionization", "and", "recombination", "reactions", "can", "be", "evaluated", "by", "taking", "the", "zeroth", "moments", "of", "the", "collision", "operators", "pertaining", "to", "ionization", "and", "recombination", "collisions", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the sources and sinks in the species continuity equations that arise from ionization and recombination reactions", "start": 14, "end": 126, "i_start": 4, "i_end": 19}, "verb": {"text": "can be evaluated", "start": 127, "end": 143, "i_start": 20, "i_end": 22}}, {"character": {"text": "reactions", "start": 117, "end": 126, "i_start": 19, "i_end": 19}, "action": {"text": "arise", "start": 77, "end": 82, "i_start": 14, "i_end": 14}}, {"character": {"text": "moments", "start": 165, "end": 172, "i_start": 27, "i_end": 27}, "action": {"text": "pertaining", "start": 200, "end": 210, "i_start": 32, "i_end": 32}}], "id": 3731}, {"sent": "the smart contract enabled security mechanism for iot systems has been a hot topic and some efforts have been reported recently , for example , data protection .", "tokens": ["the", "smart", "contract", "enabled", "security", "mechanism", "for", "iot", "systems", "has", "been", "a", "hot", "topic", "and", "some", "efforts", "have", "been", "reported", "recently", ",", "for", "example", ",", "data", "protection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the smart contract", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "enabled", "start": 19, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "contract", "start": 10, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "enabled", "start": 19, "end": 26, "i_start": 3, "i_end": 3}}], "id": 3732}, {"sent": "deep learning is an emerging branch of machine learning and has found tremendous success in the areas of image and text processing .", "tokens": ["deep", "learning", "is", "an", "emerging", "branch", "of", "machine", "learning", "and", "has", "found", "tremendous", "success", "in", "the", "areas", "of", "image", "and", "text", "processing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "found", "start": 64, "end": 69, "i_start": 11, "i_end": 11}}, {"character": {"text": "branch", "start": 29, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "emerging", "start": 20, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "success", "start": 81, "end": 88, "i_start": 13, "i_end": 13}}], "id": 3733}, {"sent": "this confluence has enabled the development of api mining methods , so far api mining tools have not been successful at gaining wide-spread adoption in development environments .", "tokens": ["this", "confluence", "has", "enabled", "the", "development", "of", "api", "mining", "methods", ",", "so", "far", "api", "mining", "tools", "have", "not", "been", "successful", "at", "gaining", "wide", "-", "spread", "adoption", "in", "development", "environments", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "api mining tools", "start": 75, "end": 91, "i_start": 13, "i_end": 15}, "verb": {"text": "have not been", "start": 92, "end": 105, "i_start": 16, "i_end": 18}}, {"subject": {"text": "this confluence", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "enabled", "start": 20, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "confluence", "start": 5, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "enabled", "start": 20, "end": 27, "i_start": 3, "i_end": 3}}], "id": 3734}, {"sent": "for example , a three-step approach has been proposed in to design power control and spectrum allocation to maximize system throughput with a minimum signal-to-interference-plus-noise ratio guarantee for both cellular and d2d links .", "tokens": ["for", "example", ",", "a", "three", "-", "step", "approach", "has", "been", "proposed", "in", "to", "design", "power", "control", "and", "spectrum", "allocation", "to", "maximize", "system", "throughput", "with", "a", "minimum", "signal", "-", "to", "-", "interference", "-", "plus", "-", "noise", "ratio", "guarantee", "for", "both", "cellular", "and", "d2d", "links", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a three-step approach", "start": 14, "end": 35, "i_start": 3, "i_end": 7}, "verb": {"text": "has been proposed", "start": 36, "end": 53, "i_start": 8, "i_end": 10}}], "id": 3735}, {"sent": "deep learning techniques have shown promising results in many research fields such as computer vision .", "tokens": ["deep", "learning", "techniques", "have", "shown", "promising", "results", "in", "many", "research", "fields", "such", "as", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning techniques", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 25, "end": 35, "i_start": 3, "i_end": 4}}, {"character": {"text": "techniques", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 30, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "results", "start": 46, "end": 53, "i_start": 6, "i_end": 6}, "action": {"text": "promising", "start": 36, "end": 45, "i_start": 5, "i_end": 5}}], "id": 3736}, {"sent": "a uav based mobile cloud computing system is proposed in where uavs offer computation offloading opportunities to mobile stations with limited local processing capabilities .", "tokens": ["a", "uav", "based", "mobile", "cloud", "computing", "system", "is", "proposed", "in", "where", "uavs", "offer", "computation", "offloading", "opportunities", "to", "mobile", "stations", "with", "limited", "local", "processing", "capabilities", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a uav based mobile cloud computing system", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "is proposed", "start": 42, "end": 53, "i_start": 7, "i_end": 8}}], "id": 3737}, {"sent": "a higgs bundle consists of a holomorphic bundle together with a higgs field , ie a section of a certain associated vector bundle .", "tokens": ["a", "higgs", "bundle", "consists", "of", "a", "holomorphic", "bundle", "together", "with", "a", "higgs", "field", ",", "ie", "a", "section", "of", "a", "certain", "associated", "vector", "bundle", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a higgs bundle", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 3738}, {"sent": "powers of codes are also studied in the context of secure multi-party computation .", "tokens": ["powers", "of", "codes", "are", "also", "studied", "in", "the", "context", "of", "secure", "multi", "-", "party", "computation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "powers of codes", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "studied", "start": 25, "end": 32, "i_start": 5, "i_end": 5}}, {"subject": {"text": "powers of codes", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 16, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "party", "start": 64, "end": 69, "i_start": 13, "i_end": 13}, "action": {"text": "computation", "start": 70, "end": 81, "i_start": 14, "i_end": 14}}], "id": 3739}, {"sent": "we note that signatures of lifshitz transitions were recently found in tetralayer graphene at zero magnetic field , but no direct compressibility measurements of lifshitz transitions have been reported .", "tokens": ["we", "note", "that", "signatures", "of", "lifshitz", "transitions", "were", "recently", "found", "in", "tetralayer", "graphene", "at", "zero", "magnetic", "field", ",", "but", "no", "direct", "compressibility", "measurements", "of", "lifshitz", "transitions", "have", "been", "reported", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "note", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "signatures of lifshitz transitions", "start": 13, "end": 47, "i_start": 3, "i_end": 6}, "verb": {"text": "found", "start": 62, "end": 67, "i_start": 9, "i_end": 9}}, {"subject": {"text": "no direct compressibility measurements of lifshitz transitions", "start": 120, "end": 182, "i_start": 19, "i_end": 25}, "verb": {"text": "reported", "start": 193, "end": 201, "i_start": 28, "i_end": 28}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "note", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3740}, {"sent": "deep convolutional neural networks have shown promising performances on various computer vision problems such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "shown", "promising", "performances", "on", "various", "computer", "vision", "problems", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have shown", "start": 35, "end": 45, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 40, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performances", "start": 56, "end": 68, "i_start": 7, "i_end": 7}}, {"character": {"text": "performances", "start": 56, "end": 68, "i_start": 7, "i_end": 7}, "action": {"text": "promising", "start": 46, "end": 55, "i_start": 6, "i_end": 6}}], "id": 3741}, {"sent": "since the alexnet proposed by krizhevsky et al achieved breakthrough results in the 2012 imagenet challenge , deeper and larger convolutional neural networks have become a ubiquitous setting for better performance , especially on tasks with big data .", "tokens": ["since", "the", "alexnet", "proposed", "by", "krizhevsky", "et", "al", "achieved", "breakthrough", "results", "in", "the", "2012", "imagenet", "challenge", ",", "deeper", "and", "larger", "convolutional", "neural", "networks", "have", "become", "a", "ubiquitous", "setting", "for", "better", "performance", ",", "especially", "on", "tasks", "with", "big", "data", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "deeper and larger convolutional neural networks", "start": 110, "end": 157, "i_start": 17, "i_end": 22}, "verb": {"text": "have become", "start": 158, "end": 169, "i_start": 23, "i_end": 24}}], "id": 3742}, {"sent": "we also use dropout on top of the embedding \u03c6 w during meta-training .", "tokens": ["we", "also", "use", "dropout", "on", "top", "of", "the", "embedding", "\u03c6", "w", "during", "meta", "-", "training", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}], "id": 3743}, {"sent": "we evolve the field equations in the generalized harmonic formulation using the code described in .", "tokens": ["we", "evolve", "the", "field", "equations", "in", "the", "generalized", "harmonic", "formulation", "using", "the", "code", "described", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evolve", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evolve", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 70, "end": 75, "i_start": 10, "i_end": 10}}], "id": 3744}, {"sent": "here , exploiting channel reciprocity in the adopted time-division duplex mode , we can divide each coherence block into two phases , namely ce and information transfer .", "tokens": ["here", ",", "exploiting", "channel", "reciprocity", "in", "the", "adopted", "time", "-", "division", "duplex", "mode", ",", "we", "can", "divide", "each", "coherence", "block", "into", "two", "phases", ",", "namely", "ce", "and", "information", "transfer", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 81, "end": 83, "i_start": 14, "i_end": 14}, "verb": {"text": "can divide", "start": 84, "end": 94, "i_start": 15, "i_end": 16}}, {"character": {"text": "we", "start": 81, "end": 83, "i_start": 14, "i_end": 14}, "action": {"text": "divide", "start": 88, "end": 94, "i_start": 16, "i_end": 16}}, {"character": {"text": "we", "start": 81, "end": 83, "i_start": 14, "i_end": 14}, "action": {"text": "exploiting", "start": 7, "end": 17, "i_start": 2, "i_end": 2}}], "id": 3745}, {"sent": "mania et al mania et al proposed a perturbed iterate framework to analyze the asynchronous parallel algorithms of sgd , scd and sparse svrg .", "tokens": ["mania", "et", "al", "mania", "et", "al", "proposed", "a", "perturbed", "iterate", "framework", "to", "analyze", "the", "asynchronous", "parallel", "algorithms", "of", "sgd", ",", "scd", "and", "sparse", "svrg", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "mania et al mania et al", "start": 0, "end": 23, "i_start": 0, "i_end": 5}, "verb": {"text": "proposed", "start": 24, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "mania", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 24, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "et al mania et al", "start": 6, "end": 23, "i_start": 1, "i_end": 5}, "action": {"text": "proposed", "start": 24, "end": 32, "i_start": 6, "i_end": 6}}], "id": 3746}, {"sent": "tissue microarray technology was first described by wan et al in 1998 as a highthroughput technology for the assessment of histology-based laboratory tests .", "tokens": ["tissue", "microarray", "technology", "was", "first", "described", "by", "wan", "et", "al", "in", "1998", "as", "a", "highthroughput", "technology", "for", "the", "assessment", "of", "histology", "-", "based", "laboratory", "tests", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "tissue microarray technology", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "described", "start": 39, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "tissue microarray technology", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "was", "start": 29, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "wan", "start": 52, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "described", "start": 39, "end": 48, "i_start": 5, "i_end": 5}}], "id": 3747}, {"sent": "dropout regularization is employed on the word embedding layer and final mlp layer , with dropout rate selected from the set .", "tokens": ["dropout", "regularization", "is", "employed", "on", "the", "word", "embedding", "layer", "and", "final", "mlp", "layer", ",", "with", "dropout", "rate", "selected", "from", "the", "set", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dropout regularization", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is employed", "start": 23, "end": 34, "i_start": 2, "i_end": 3}}], "id": 3748}, {"sent": "because of the characterization of corson compact spaces obtained in , the space x has a full r-skeleton .", "tokens": ["because", "of", "the", "characterization", "of", "corson", "compact", "spaces", "obtained", "in", ",", "the", "space", "x", "has", "a", "full", "r", "-", "skeleton", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "the space", "start": 71, "end": 80, "i_start": 11, "i_end": 12}, "verb": {"text": "has", "start": 83, "end": 86, "i_start": 14, "i_end": 14}}, {"character": {"text": "space", "start": 75, "end": 80, "i_start": 12, "i_end": 12}, "action": {"text": "has", "start": 83, "end": 86, "i_start": 14, "i_end": 14}}, {"character": {"text": "characterization", "start": 15, "end": 31, "i_start": 3, "i_end": 3}, "action": {"text": "because", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}], "id": 3749}, {"sent": "solecki derived his result from an extension theorem of herwig and lascar .", "tokens": ["solecki", "derived", "his", "result", "from", "an", "extension", "theorem", "of", "herwig", "and", "lascar", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "solecki", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "derived", "start": 8, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "solecki", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "derived", "start": 8, "end": 15, "i_start": 1, "i_end": 1}}], "id": 3750}, {"sent": "comparing with the original sat theorem , the homomorphism version of sat is on a more abstract level .", "tokens": ["comparing", "with", "the", "original", "sat", "theorem", ",", "the", "homomorphism", "version", "of", "sat", "is", "on", "a", "more", "abstract", "level", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the homomorphism version of sat", "start": 42, "end": 73, "i_start": 7, "i_end": 11}, "verb": {"text": "is", "start": 74, "end": 76, "i_start": 12, "i_end": 12}}], "id": 3751}, {"sent": "there are many weakly supervised object detection methods , that aim to alleviate the heavy burdens of data annotation .", "tokens": ["there", "are", "many", "weakly", "supervised", "object", "detection", "methods", ",", "that", "aim", "to", "alleviate", "the", "heavy", "burdens", "of", "data", "annotation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 6, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "methods", "start": 50, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "aim", "start": 65, "end": 68, "i_start": 10, "i_end": 10}}, {"character": {"text": "methods", "start": 50, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "alleviate", "start": 72, "end": 81, "i_start": 12, "i_end": 12}}], "id": 3752}, {"sent": "the complexity level for eis , eos and eqs appears according to the number of ftrs and dets .", "tokens": ["the", "complexity", "level", "for", "eis", ",", "eos", "and", "eqs", "appears", "according", "to", "the", "number", "of", "ftrs", "and", "dets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the complexity level for eis", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "appears", "start": 43, "end": 50, "i_start": 9, "i_end": 9}}], "id": 3753}, {"sent": "show that quotients of amenable groups are amenable .", "tokens": ["show", "that", "quotients", "of", "amenable", "groups", "are", "amenable", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3754}, {"sent": "the pilot overhead required for channel estimation is proportional to the number of transmit antennas , which can be excessive in massive mimo systems .", "tokens": ["the", "pilot", "overhead", "required", "for", "channel", "estimation", "is", "proportional", "to", "the", "number", "of", "transmit", "antennas", ",", "which", "can", "be", "excessive", "in", "massive", "mimo", "systems", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the pilot overhead required for channel estimation", "start": 0, "end": 50, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 51, "end": 53, "i_start": 7, "i_end": 7}}, {"character": {"text": "overhead", "start": 10, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "pilot", "start": 4, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "antennas", "start": 93, "end": 101, "i_start": 14, "i_end": 14}, "action": {"text": "transmit", "start": 84, "end": 92, "i_start": 13, "i_end": 13}}], "id": 3755}, {"sent": "it might be important to refer to some recent investigations which argue that if the spin connection is also considered along with the pure-tetrad formalism for the teleparallel gravity the local invariance problem might be resolved .", "tokens": ["it", "might", "be", "important", "to", "refer", "to", "some", "recent", "investigations", "which", "argue", "that", "if", "the", "spin", "connection", "is", "also", "considered", "along", "with", "the", "pure", "-", "tetrad", "formalism", "for", "the", "teleparallel", "gravity", "the", "local", "invariance", "problem", "might", "be", "resolved", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "might be", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"character": {"text": "investigations", "start": 46, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "argue", "start": 67, "end": 72, "i_start": 11, "i_end": 11}}], "id": 3756}, {"sent": "this problem has proved important in a vast number of applications , such as computational biology , economics , sociology , and computer vision .", "tokens": ["this", "problem", "has", "proved", "important", "in", "a", "vast", "number", "of", "applications", ",", "such", "as", "computational", "biology", ",", "economics", ",", "sociology", ",", "and", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this problem", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "has proved", "start": 13, "end": 23, "i_start": 2, "i_end": 3}}], "id": 3757}, {"sent": "following the pioneering work of that the k-nn classifier is universally strongly bayes consistent in .", "tokens": ["following", "the", "pioneering", "work", "of", "that", "the", "k", "-", "nn", "classifier", "is", "universally", "strongly", "bayes", "consistent", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the k-nn classifier", "start": 38, "end": 57, "i_start": 6, "i_end": 10}, "verb": {"text": "is", "start": 58, "end": 60, "i_start": 11, "i_end": 11}}, {"character": {"text": "that", "start": 33, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "work", "start": 25, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "work", "start": 25, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "pioneering", "start": 14, "end": 24, "i_start": 2, "i_end": 2}}], "id": 3758}, {"sent": "circles mark out the assumed parameter values characteristic of four different p .", "tokens": ["circles", "mark", "out", "the", "assumed", "parameter", "values", "characteristic", "of", "four", "different", "p", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "circles", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "mark out", "start": 8, "end": 16, "i_start": 1, "i_end": 2}}, {"character": {"text": "circles", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "mark", "start": 8, "end": 12, "i_start": 1, "i_end": 1}}], "id": 3759}, {"sent": "an operad is a multicategory with only one object .", "tokens": ["an", "operad", "is", "a", "multicategory", "with", "only", "one", "object", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an operad", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}], "id": 3760}, {"sent": "for that purpose , we extend the skip-gram model to simultaneously learn word and phrase embeddings , and map them to a cross-lingual space adapting previous unsupervised techniques .", "tokens": ["for", "that", "purpose", ",", "we", "extend", "the", "skip", "-", "gram", "model", "to", "simultaneously", "learn", "word", "and", "phrase", "embeddings", ",", "and", "map", "them", "to", "a", "cross", "-", "lingual", "space", "adapting", "previous", "unsupervised", "techniques", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "verb": {"text": "extend", "start": 22, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "extend", "start": 22, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "learn", "start": 67, "end": 72, "i_start": 13, "i_end": 13}}], "id": 3761}, {"sent": "the electric charge is the noether charge that corresponds to a global u gauge field .", "tokens": ["the", "electric", "charge", "is", "the", "noether", "charge", "that", "corresponds", "to", "a", "global", "u", "gauge", "field", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electric charge", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 3762}, {"sent": "later in , venugopalan et al presented an end-to-end neural networks to generate video descriptions , which only reads the sequence of video frames .", "tokens": ["later", "in", ",", "venugopalan", "et", "al", "presented", "an", "end", "-", "to", "-", "end", "neural", "networks", "to", "generate", "video", "descriptions", ",", "which", "only", "reads", "the", "sequence", "of", "video", "frames", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "venugopalan et al", "start": 11, "end": 28, "i_start": 3, "i_end": 5}, "verb": {"text": "presented", "start": 29, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "venugopalan", "start": 11, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "presented", "start": 29, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 60, "end": 68, "i_start": 14, "i_end": 14}, "action": {"text": "generate", "start": 72, "end": 80, "i_start": 16, "i_end": 16}}, {"character": {"text": "networks", "start": 60, "end": 68, "i_start": 14, "i_end": 14}, "action": {"text": "reads", "start": 113, "end": 118, "i_start": 22, "i_end": 22}}], "id": 3763}, {"sent": "firstly , we compare fd-mobilenet with other state-of-the-art compact networks on the ilsvrc 2012 dataset .", "tokens": ["firstly", ",", "we", "compare", "fd", "-", "mobilenet", "with", "other", "state", "-", "of", "-", "the", "-", "art", "compact", "networks", "on", "the", "ilsvrc", "2012", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "compare", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "compare", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}], "id": 3764}, {"sent": "this last method , with the right matter terms , is known as spontaneous compactification .", "tokens": ["this", "last", "method", ",", "with", "the", "right", "matter", "terms", ",", "is", "known", "as", "spontaneous", "compactification", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "this last method", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is known", "start": 49, "end": 57, "i_start": 10, "i_end": 11}}], "id": 3765}, {"sent": "the dynamic semantics integrate change propagation and evaluation to ensure correct reuse of computations under mutations .", "tokens": ["the", "dynamic", "semantics", "integrate", "change", "propagation", "and", "evaluation", "to", "ensure", "correct", "reuse", "of", "computations", "under", "mutations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the dynamic semantics", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "integrate", "start": 22, "end": 31, "i_start": 3, "i_end": 3}}, {"character": {"text": "semantics", "start": 12, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "integrate", "start": 22, "end": 31, "i_start": 3, "i_end": 3}}, {"character": {"text": "semantics", "start": 12, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "ensure", "start": 69, "end": 75, "i_start": 9, "i_end": 9}}], "id": 3766}, {"sent": "kontsevich has found an explicit formula for the star product on poisson manifolds .", "tokens": ["kontsevich", "has", "found", "an", "explicit", "formula", "for", "the", "star", "product", "on", "poisson", "manifolds", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "kontsevich", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "verb": {"text": "has found", "start": 11, "end": 20, "i_start": 1, "i_end": 2}}, {"character": {"text": "kontsevich", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "found", "start": 15, "end": 20, "i_start": 2, "i_end": 2}}], "id": 3767}, {"sent": "for a given number of features p , we employ the preferential attachment algorithm proposed by to generate a scale-free feature graph .", "tokens": ["for", "a", "given", "number", "of", "features", "p", ",", "we", "employ", "the", "preferential", "attachment", "algorithm", "proposed", "by", "to", "generate", "a", "scale", "-", "free", "feature", "graph", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 35, "end": 37, "i_start": 8, "i_end": 8}, "verb": {"text": "employ", "start": 38, "end": 44, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 35, "end": 37, "i_start": 8, "i_end": 8}, "action": {"text": "employ", "start": 38, "end": 44, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 35, "end": 37, "i_start": 8, "i_end": 8}, "action": {"text": "generate", "start": 98, "end": 106, "i_start": 17, "i_end": 17}}], "id": 3768}, {"sent": "the network parameters are initialized using the xavier initialization .", "tokens": ["the", "network", "parameters", "are", "initialized", "using", "the", "xavier", "initialization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the network parameters", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "are initialized", "start": 23, "end": 38, "i_start": 3, "i_end": 4}}], "id": 3769}, {"sent": "data are represented by spatial configurations of attractants and repellents , and results of computation by structures of protoplasmic network formed by the plasmodium on the data sites .", "tokens": ["data", "are", "represented", "by", "spatial", "configurations", "of", "attractants", "and", "repellents", ",", "and", "results", "of", "computation", "by", "structures", "of", "protoplasmic", "network", "formed", "by", "the", "plasmodium", "on", "the", "data", "sites", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "data", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "are represented", "start": 5, "end": 20, "i_start": 1, "i_end": 2}}, {"character": {"text": "configurations", "start": 32, "end": 46, "i_start": 5, "i_end": 5}, "action": {"text": "represented", "start": 9, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "attractants", "start": 50, "end": 61, "i_start": 7, "i_end": 7}, "action": {"text": "represented", "start": 9, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "repellents", "start": 66, "end": 76, "i_start": 9, "i_end": 9}, "action": {"text": "represented", "start": 9, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "results", "start": 83, "end": 90, "i_start": 12, "i_end": 12}, "action": {"text": "represented", "start": 9, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "network", "start": 136, "end": 143, "i_start": 19, "i_end": 19}, "action": {"text": "represented", "start": 9, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "protoplasmic", "start": 123, "end": 135, "i_start": 18, "i_end": 18}, "action": {"text": "represented", "start": 9, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "sites", "start": 181, "end": 186, "i_start": 27, "i_end": 27}, "action": {"text": "represented", "start": 9, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "data", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "represented", "start": 9, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "plasmodium", "start": 158, "end": 168, "i_start": 23, "i_end": 23}, "action": {"text": "formed", "start": 144, "end": 150, "i_start": 20, "i_end": 20}}], "id": 3770}, {"sent": "in recent years , deep convolutional neural networks have proven to be highly effective general models for a multitude of computer vision problems .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "proven", "to", "be", "highly", "effective", "general", "models", "for", "a", "multitude", "of", "computer", "vision", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have proven", "start": 53, "end": 64, "i_start": 8, "i_end": 9}}, {"character": {"text": "models", "start": 96, "end": 102, "i_start": 15, "i_end": 15}, "action": {"text": "effective", "start": 78, "end": 87, "i_start": 13, "i_end": 13}}], "id": 3771}, {"sent": "in the discussion of piston theory , we mention the modern engineering references .", "tokens": ["in", "the", "discussion", "of", "piston", "theory", ",", "we", "mention", "the", "modern", "engineering", "references", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 37, "end": 39, "i_start": 7, "i_end": 7}, "verb": {"text": "mention", "start": 40, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 37, "end": 39, "i_start": 7, "i_end": 7}, "action": {"text": "mention", "start": 40, "end": 47, "i_start": 8, "i_end": 8}}], "id": 3772}, {"sent": "recent successes in deep learning has revolutionized the field of machine learning and pattern recognition .", "tokens": ["recent", "successes", "in", "deep", "learning", "has", "revolutionized", "the", "field", "of", "machine", "learning", "and", "pattern", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent successes in deep learning", "start": 0, "end": 33, "i_start": 0, "i_end": 4}, "verb": {"text": "has revolutionized", "start": 34, "end": 52, "i_start": 5, "i_end": 6}}, {"character": {"text": "successes", "start": 7, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "revolutionized", "start": 38, "end": 52, "i_start": 6, "i_end": 6}}], "id": 3773}, {"sent": "in recent years , cognitive radio has attracted intensive research because of pressing demand for efficient frequency spectrum usage .", "tokens": ["in", "recent", "years", ",", "cognitive", "radio", "has", "attracted", "intensive", "research", "because", "of", "pressing", "demand", "for", "efficient", "frequency", "spectrum", "usage", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "cognitive radio", "start": 18, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "has attracted", "start": 34, "end": 47, "i_start": 6, "i_end": 7}}, {"character": {"text": "radio", "start": 28, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "attracted", "start": 38, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "pressing", "start": 78, "end": 86, "i_start": 12, "i_end": 12}, "action": {"text": "because", "start": 67, "end": 74, "i_start": 10, "i_end": 10}}], "id": 3774}, {"sent": "due to the popularity of deep learning in recent years and its significant impact on the computer vision field , deep convolutional neural networks based approaches have also been adopted for ear recognition .", "tokens": ["due", "to", "the", "popularity", "of", "deep", "learning", "in", "recent", "years", "and", "its", "significant", "impact", "on", "the", "computer", "vision", "field", ",", "deep", "convolutional", "neural", "networks", "based", "approaches", "have", "also", "been", "adopted", "for", "ear", "recognition", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "deep convolutional neural networks based approaches", "start": 113, "end": 164, "i_start": 20, "i_end": 25}, "verb": {"text": "been adopted", "start": 175, "end": 187, "i_start": 28, "i_end": 29}}, {"subject": {"text": "deep convolutional neural networks based approaches", "start": 113, "end": 164, "i_start": 20, "i_end": 25}, "verb": {"text": "have", "start": 165, "end": 169, "i_start": 26, "i_end": 26}}, {"character": {"text": "learning", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "impact", "start": 75, "end": 81, "i_start": 13, "i_end": 13}}], "id": 3775}, {"sent": "dust extinction is a far less serious problem when counting pne in nearby external galaxies , especially early-types , as a guide .", "tokens": ["dust", "extinction", "is", "a", "far", "less", "serious", "problem", "when", "counting", "pne", "in", "nearby", "external", "galaxies", ",", "especially", "early", "-", "types", ",", "as", "a", "guide", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dust extinction", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3776}, {"sent": "in , a stochastic multi-period opf model is presented which consists of an offshore wind farm connected to the grid by a line-commutated converter hvdc link .", "tokens": ["in", ",", "a", "stochastic", "multi", "-", "period", "opf", "model", "is", "presented", "which", "consists", "of", "an", "offshore", "wind", "farm", "connected", "to", "the", "grid", "by", "a", "line", "-", "commutated", "converter", "hvdc", "link", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a stochastic multi-period opf model", "start": 5, "end": 40, "i_start": 2, "i_end": 8}, "verb": {"text": "is presented", "start": 41, "end": 53, "i_start": 9, "i_end": 10}}, {"subject": {"text": "which", "start": 54, "end": 59, "i_start": 11, "i_end": 11}, "verb": {"text": "consists", "start": 60, "end": 68, "i_start": 12, "i_end": 12}}], "id": 3777}, {"sent": "specifically , we choose a resnet-152 model pretrained on imagenet as the image encoder .", "tokens": ["specifically", ",", "we", "choose", "a", "resnet-152", "model", "pretrained", "on", "imagenet", "as", "the", "image", "encoder", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "choose", "start": 18, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "choose", "start": 18, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3778}, {"sent": "diamonds denote the offsets for the 14 radio sources which we later claim are the correct identifications to sub-mm sources in the hdf-n .", "tokens": ["diamonds", "denote", "the", "offsets", "for", "the", "14", "radio", "sources", "which", "we", "later", "claim", "are", "the", "correct", "identifications", "to", "sub", "-", "mm", "sources", "in", "the", "hdf", "-", "n", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "diamonds", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "denote", "start": 9, "end": 15, "i_start": 1, "i_end": 1}}, {"subject": {"text": "diamonds", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 74, "end": 77, "i_start": 13, "i_end": 13}}, {"character": {"text": "diamonds", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 9, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 59, "end": 61, "i_start": 10, "i_end": 10}, "action": {"text": "claim", "start": 68, "end": 73, "i_start": 12, "i_end": 12}}], "id": 3779}, {"sent": "each convolutional layer is followed by batch normalization and relu .", "tokens": ["each", "convolutional", "layer", "is", "followed", "by", "batch", "normalization", "and", "relu", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each convolutional layer", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is followed", "start": 25, "end": 36, "i_start": 3, "i_end": 4}}], "id": 3780}, {"sent": "reinforcement learning is a type of machine learning in which an agent learns from its experience in an environment to maximize some cumulative reward .", "tokens": ["reinforcement", "learning", "is", "a", "type", "of", "machine", "learning", "in", "which", "an", "agent", "learns", "from", "its", "experience", "in", "an", "environment", "to", "maximize", "some", "cumulative", "reward", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "agent", "start": 65, "end": 70, "i_start": 11, "i_end": 11}, "action": {"text": "learning", "start": 14, "end": 22, "i_start": 1, "i_end": 1}}, {"character": {"text": "agent", "start": 65, "end": 70, "i_start": 11, "i_end": 11}, "action": {"text": "experience", "start": 87, "end": 97, "i_start": 15, "i_end": 15}}, {"character": {"text": "agent", "start": 65, "end": 70, "i_start": 11, "i_end": 11}, "action": {"text": "maximize", "start": 119, "end": 127, "i_start": 20, "i_end": 20}}], "id": 3781}, {"sent": "the generalized gradient approximation with perdew-burke-ernzerhof exchange-correlation energy functional is used .", "tokens": ["the", "generalized", "gradient", "approximation", "with", "perdew", "-", "burke", "-", "ernzerhof", "exchange", "-", "correlation", "energy", "functional", "is", "used", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation with perdew-burke-ernzerhof exchange-correlation energy functional", "start": 0, "end": 105, "i_start": 0, "i_end": 14}, "verb": {"text": "is used", "start": 106, "end": 113, "i_start": 15, "i_end": 16}}], "id": 3782}, {"sent": "for further structural results about graph inverse semigroups , we refer to .", "tokens": ["for", "further", "structural", "results", "about", "graph", "inverse", "semigroups", ",", "we", "refer", "to", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 64, "end": 66, "i_start": 9, "i_end": 9}, "verb": {"text": "refer", "start": 67, "end": 72, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 9, "i_end": 9}, "action": {"text": "refer", "start": 67, "end": 72, "i_start": 10, "i_end": 10}}], "id": 3783}, {"sent": "one of the most succesful approaches in generative models are generative adversarial networks .", "tokens": ["one", "of", "the", "most", "succesful", "approaches", "in", "generative", "models", "are", "generative", "adversarial", "networks", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "one of the most succesful approaches in generative models", "start": 0, "end": 57, "i_start": 0, "i_end": 8}, "verb": {"text": "are", "start": 58, "end": 61, "i_start": 9, "i_end": 9}}], "id": 3784}, {"sent": "in the backbone , we use the feature pyramid network to improve detection accuracy .", "tokens": ["in", "the", "backbone", ",", "we", "use", "the", "feature", "pyramid", "network", "to", "improve", "detection", "accuracy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 21, "end": 24, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 21, "end": 24, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "improve", "start": 56, "end": 63, "i_start": 11, "i_end": 11}}], "id": 3785}, {"sent": "we introduce new criteria useful for analyzing quantum and classical spin transport phenomena and the relationships between them .", "tokens": ["we", "introduce", "new", "criteria", "useful", "for", "analyzing", "quantum", "and", "classical", "spin", "transport", "phenomena", "and", "the", "relationships", "between", "them", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "introduce", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "introduce", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}], "id": 3786}, {"sent": "aktas et al measurement of deeply virtual compton scattering at hera .", "tokens": ["aktas", "et", "al", "measurement", "of", "deeply", "virtual", "compton", "scattering", "at", "hera", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "aktas", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "measurement", "start": 12, "end": 23, "i_start": 3, "i_end": 3}}], "id": 3787}, {"sent": "deep neural networks have achieved impressive performance on tasks across a variety of domains , including vision .", "tokens": ["deep", "neural", "networks", "have", "achieved", "impressive", "performance", "on", "tasks", "across", "a", "variety", "of", "domains", ",", "including", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 46, "end": 57, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 46, "end": 57, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 35, "end": 45, "i_start": 5, "i_end": 5}}], "id": 3788}, {"sent": "next , we consider the outer bound we proposed for the degraded discrete memoryless channel .", "tokens": ["next", ",", "we", "consider", "the", "outer", "bound", "we", "proposed", "for", "the", "degraded", "discrete", "memoryless", "channel", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "consider", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "bound", "start": 29, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "consider", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "proposed", "start": 38, "end": 46, "i_start": 8, "i_end": 8}}], "id": 3789}, {"sent": "to evaluate the restoration performance of the traditional image denoising techniques and the proposed ca , we used the peak signal to noise ratio and the structural similarity index metric .", "tokens": ["to", "evaluate", "the", "restoration", "performance", "of", "the", "traditional", "image", "denoising", "techniques", "and", "the", "proposed", "ca", ",", "we", "used", "the", "peak", "signal", "to", "noise", "ratio", "and", "the", "structural", "similarity", "index", "metric", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 108, "end": 110, "i_start": 16, "i_end": 16}, "verb": {"text": "used", "start": 111, "end": 115, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 108, "end": 110, "i_start": 16, "i_end": 16}, "action": {"text": "used", "start": 111, "end": 115, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 108, "end": 110, "i_start": 16, "i_end": 16}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "techniques", "start": 75, "end": 85, "i_start": 10, "i_end": 10}, "action": {"text": "performance", "start": 28, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "traditional", "start": 47, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "performance", "start": 28, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "ca", "start": 103, "end": 105, "i_start": 14, "i_end": 14}, "action": {"text": "performance", "start": 28, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "techniques", "start": 75, "end": 85, "i_start": 10, "i_end": 10}, "action": {"text": "denoising", "start": 65, "end": 74, "i_start": 9, "i_end": 9}}], "id": 3790}, {"sent": "we experiment with the resnet-50 model on the large-scale imagenet dataset .", "tokens": ["we", "experiment", "with", "the", "resnet-50", "model", "on", "the", "large", "-", "scale", "imagenet", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "experiment", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "experiment", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}], "id": 3791}, {"sent": "overlaid is a grid of the loci of a simple absorbed power law model as \u03b3 and nh vary .", "tokens": ["overlaid", "is", "a", "grid", "of", "the", "loci", "of", "a", "simple", "absorbed", "power", "law", "model", "as", "\u03b3", "and", "nh", "vary", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "overlaid", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}], "id": 3792}, {"sent": "end for end if end if end if message blockack over port l .", "tokens": ["end", "for", "end", "if", "end", "if", "end", "if", "message", "blockack", "over", "port", "l", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3793}, {"sent": "so , we see that if neutrino is a majorana particle , then the neutrinoless double decay will take place .", "tokens": ["so", ",", "we", "see", "that", "if", "neutrino", "is", "a", "majorana", "particle", ",", "then", "the", "neutrinoless", "double", "decay", "will", "take", "place", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "verb": {"text": "see", "start": 8, "end": 11, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the neutrinoless double decay", "start": 59, "end": 88, "i_start": 13, "i_end": 16}, "verb": {"text": "take", "start": 94, "end": 98, "i_start": 18, "i_end": 18}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "action": {"text": "see", "start": 8, "end": 11, "i_start": 3, "i_end": 3}}], "id": 3794}, {"sent": "deep convolutional neural networks have emerged as highly effective models for these large-scale visual recognition tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "emerged", "as", "highly", "effective", "models", "for", "these", "large", "-", "scale", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have emerged", "start": 35, "end": 47, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "emerged", "start": 40, "end": 47, "i_start": 5, "i_end": 5}}, {"character": {"text": "models", "start": 68, "end": 74, "i_start": 9, "i_end": 9}, "action": {"text": "effective", "start": 58, "end": 67, "i_start": 8, "i_end": 8}}], "id": 3795}, {"sent": "recently , we have witnessed deep neural networks have delivered super-human accuracy in a variety of practical uses , such as facial recognition .", "tokens": ["recently", ",", "we", "have", "witnessed", "deep", "neural", "networks", "have", "delivered", "super", "-", "human", "accuracy", "in", "a", "variety", "of", "practical", "uses", ",", "such", "as", "facial", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "verb": {"text": "have witnessed", "start": 14, "end": 28, "i_start": 3, "i_end": 4}}, {"subject": {"text": "deep neural networks", "start": 29, "end": 49, "i_start": 5, "i_end": 7}, "verb": {"text": "delivered", "start": 55, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "witnessed", "start": 19, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 41, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "delivered", "start": 55, "end": 64, "i_start": 9, "i_end": 9}}], "id": 3796}, {"sent": "in order to emphasize specific regions of interests , in particular the tails , gneiting and ranjan and diks et al combined scoring rules with weight functions .", "tokens": ["in", "order", "to", "emphasize", "specific", "regions", "of", "interests", ",", "in", "particular", "the", "tails", ",", "gneiting", "and", "ranjan", "and", "diks", "et", "al", "combined", "scoring", "rules", "with", "weight", "functions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "ranjan", "start": 93, "end": 99, "i_start": 16, "i_end": 16}, "action": {"text": "combined", "start": 115, "end": 123, "i_start": 21, "i_end": 21}}, {"character": {"text": "diks", "start": 104, "end": 108, "i_start": 18, "i_end": 18}, "action": {"text": "combined", "start": 115, "end": 123, "i_start": 21, "i_end": 21}}], "id": 3797}, {"sent": "more recently , convolutional neural networks have been shown to work very well for this challenging task , either in a fully supervised fashion .", "tokens": ["more", "recently", ",", "convolutional", "neural", "networks", "have", "been", "shown", "to", "work", "very", "well", "for", "this", "challenging", "task", ",", "either", "in", "a", "fully", "supervised", "fashion", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "have been shown", "start": 46, "end": 61, "i_start": 6, "i_end": 8}}, {"character": {"text": "task", "start": 101, "end": 105, "i_start": 16, "i_end": 16}, "action": {"text": "challenging", "start": 89, "end": 100, "i_start": 15, "i_end": 15}}], "id": 3798}, {"sent": "ensemble models of decision trees such as random forests and boosted trees are popular machine learning models , especially for prediction tasks .", "tokens": ["ensemble", "models", "of", "decision", "trees", "such", "as", "random", "forests", "and", "boosted", "trees", "are", "popular", "machine", "learning", "models", ",", "especially", "for", "prediction", "tasks", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "ensemble models of decision trees such as random forests and boosted trees", "start": 0, "end": 74, "i_start": 0, "i_end": 11}, "verb": {"text": "are", "start": 75, "end": 78, "i_start": 12, "i_end": 12}}, {"character": {"text": "trees", "start": 28, "end": 33, "i_start": 4, "i_end": 4}, "action": {"text": "decision", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}], "id": 3799}, {"sent": "toffoli-hadamard quantum mechanics is also known to be approximately universal for quantum computing .", "tokens": ["toffoli", "-", "hadamard", "quantum", "mechanics", "is", "also", "known", "to", "be", "approximately", "universal", "for", "quantum", "computing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "toffoli-hadamard quantum mechanics", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "known", "start": 43, "end": 48, "i_start": 7, "i_end": 7}}, {"subject": {"text": "toffoli-hadamard quantum mechanics", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 5, "i_end": 5}}], "id": 3800}, {"sent": "in machine learning , deep learning has become a popular method for learning signal representations from data .", "tokens": ["in", "machine", "learning", ",", "deep", "learning", "has", "become", "a", "popular", "method", "for", "learning", "signal", "representations", "from", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 22, "end": 35, "i_start": 4, "i_end": 5}, "verb": {"text": "has become", "start": 36, "end": 46, "i_start": 6, "i_end": 7}}], "id": 3801}, {"sent": "low-density parity-check codes have found widespread acceptance in different areas due to their superior performance and low complexity decoding .", "tokens": ["low", "-", "density", "parity", "-", "check", "codes", "have", "found", "widespread", "acceptance", "in", "different", "areas", "due", "to", "their", "superior", "performance", "and", "low", "complexity", "decoding", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "low-density parity-check codes", "start": 0, "end": 30, "i_start": 0, "i_end": 6}, "verb": {"text": "have found", "start": 31, "end": 41, "i_start": 7, "i_end": 8}}, {"character": {"text": "codes", "start": 25, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "found", "start": 36, "end": 41, "i_start": 8, "i_end": 8}}, {"character": {"text": "codes", "start": 25, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "check", "start": 19, "end": 24, "i_start": 5, "i_end": 5}}, {"character": {"text": "codes", "start": 25, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 105, "end": 116, "i_start": 18, "i_end": 18}}, {"character": {"text": "codes", "start": 25, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "decoding", "start": 136, "end": 144, "i_start": 22, "i_end": 22}}], "id": 3802}, {"sent": "this invariance is a local symmetry , analogous to the gauge invariance of the other three forces and one could be tempted to view it as a gauge symmetry , with interesting consequences .", "tokens": ["this", "invariance", "is", "a", "local", "symmetry", ",", "analogous", "to", "the", "gauge", "invariance", "of", "the", "other", "three", "forces", "and", "one", "could", "be", "tempted", "to", "view", "it", "as", "a", "gauge", "symmetry", ",", "with", "interesting", "consequences", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this invariance", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3803}, {"sent": "physically , string theory is a two-dimensional conformal field theory on a riemannian surface .", "tokens": ["physically", ",", "string", "theory", "is", "a", "two", "-", "dimensional", "conformal", "field", "theory", "on", "a", "riemannian", "surface", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "string theory", "start": 13, "end": 26, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 4, "i_end": 4}}], "id": 3804}, {"sent": "as an example , the exchange of robots 4 and 9 can be carried out using a 2-switch sequence , of which each individual pair consists of two adjacent robots after the previous 2-switch is completed .", "tokens": ["as", "an", "example", ",", "the", "exchange", "of", "robots", "4", "and", "9", "can", "be", "carried", "out", "using", "a", "2", "-", "switch", "sequence", ",", "of", "which", "each", "individual", "pair", "consists", "of", "two", "adjacent", "robots", "after", "the", "previous", "2", "-", "switch", "is", "completed", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange of robots 4 and 9", "start": 16, "end": 46, "i_start": 4, "i_end": 10}, "verb": {"text": "can be carried out", "start": 47, "end": 65, "i_start": 11, "i_end": 14}}], "id": 3805}, {"sent": "metasurfaces are two dimensional arrays of subwavelength structures capable of controlling the phase , amplitude , and polarization of light .", "tokens": ["metasurfaces", "are", "two", "dimensional", "arrays", "of", "subwavelength", "structures", "capable", "of", "controlling", "the", "phase", ",", "amplitude", ",", "and", "polarization", "of", "light", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "metasurfaces", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 13, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "structures", "start": 57, "end": 67, "i_start": 7, "i_end": 7}, "action": {"text": "controlling", "start": 79, "end": 90, "i_start": 10, "i_end": 10}}], "id": 3806}, {"sent": "in this case the dual gauge theory is the conformal limit of the world volume theory on a stack of n d3-branes placed at the singularity of the conifold .", "tokens": ["in", "this", "case", "the", "dual", "gauge", "theory", "is", "the", "conformal", "limit", "of", "the", "world", "volume", "theory", "on", "a", "stack", "of", "n", "d3", "-", "branes", "placed", "at", "the", "singularity", "of", "the", "conifold", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dual gauge theory", "start": 13, "end": 34, "i_start": 3, "i_end": 6}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 7, "i_end": 7}}, {"character": {"text": "stack", "start": 90, "end": 95, "i_start": 18, "i_end": 18}, "action": {"text": "limit", "start": 52, "end": 57, "i_start": 10, "i_end": 10}}], "id": 3807}, {"sent": "we note that these approaches are also closely related to hashing methods .", "tokens": ["we", "note", "that", "these", "approaches", "are", "also", "closely", "related", "to", "hashing", "methods", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "note", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "note", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3808}, {"sent": "now we want to consider the three-point functions of logarithmic fields .", "tokens": ["now", "we", "want", "to", "consider", "the", "three", "-", "point", "functions", "of", "logarithmic", "fields", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "want", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "want", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "consider", "start": 15, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "fields", "start": 65, "end": 71, "i_start": 12, "i_end": 12}, "action": {"text": "functions", "start": 40, "end": 49, "i_start": 9, "i_end": 9}}], "id": 3809}, {"sent": "one of these invariants is the line element ds2 , where coordinates enter via differentials .", "tokens": ["one", "of", "these", "invariants", "is", "the", "line", "element", "ds2", ",", "where", "coordinates", "enter", "via", "differentials", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one of these invariants", "start": 0, "end": 23, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 4, "i_end": 4}}], "id": 3810}, {"sent": "in , egc performance was determined by approximating the moment generating function of its output snr , where the moments are determined exactly for exponentially correlated nakagami channels in terms of multi-fold infinite series .", "tokens": ["in", ",", "egc", "performance", "was", "determined", "by", "approximating", "the", "moment", "generating", "function", "of", "its", "output", "snr", ",", "where", "the", "moments", "are", "determined", "exactly", "for", "exponentially", "correlated", "nakagami", "channels", "in", "terms", "of", "multi", "-", "fold", "infinite", "series", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "egc performance", "start": 5, "end": 20, "i_start": 2, "i_end": 3}, "verb": {"text": "was determined", "start": 21, "end": 35, "i_start": 4, "i_end": 5}}], "id": 3811}, {"sent": "since t admits a majority polymorphism , from lemma 3 , it follows from that qcspreduces to the verification of a polynomial number of instances of csp , each of which is in nl by .", "tokens": ["since", "t", "admits", "a", "majority", "polymorphism", ",", "from", "lemma", "3", ",", "it", "follows", "from", "that", "qcspreduces", "to", "the", "verification", "of", "a", "polynomial", "number", "of", "instances", "of", "csp", ",", "each", "of", "which", "is", "in", "nl", "by", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 56, "end": 58, "i_start": 11, "i_end": 11}, "verb": {"text": "follows", "start": 59, "end": 66, "i_start": 12, "i_end": 12}}], "id": 3812}, {"sent": "this is the contribution of the fibre plane resolution to the overall resolution , which is what can be measured in the experimental setup .", "tokens": ["this", "is", "the", "contribution", "of", "the", "fibre", "plane", "resolution", "to", "the", "overall", "resolution", ",", "which", "is", "what", "can", "be", "measured", "in", "the", "experimental", "setup", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "resolution", "start": 44, "end": 54, "i_start": 8, "i_end": 8}, "action": {"text": "contribution", "start": 12, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3813}, {"sent": "belinkov and bisk recently showed that character-based models fail to translate noisy text that humans can handle easily .", "tokens": ["belinkov", "and", "bisk", "recently", "showed", "that", "character", "-", "based", "models", "fail", "to", "translate", "noisy", "text", "that", "humans", "can", "handle", "easily", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "belinkov and bisk", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 27, "end": 33, "i_start": 4, "i_end": 4}}, {"subject": {"text": "character-based models", "start": 39, "end": 61, "i_start": 6, "i_end": 9}, "verb": {"text": "fail", "start": 62, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "belinkov", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 27, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "bisk", "start": 13, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "showed", "start": 27, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "models", "start": 55, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "translate", "start": 70, "end": 79, "i_start": 12, "i_end": 12}}, {"character": {"text": "humans", "start": 96, "end": 102, "i_start": 16, "i_end": 16}, "action": {"text": "handle", "start": 107, "end": 113, "i_start": 18, "i_end": 18}}], "id": 3814}, {"sent": "fluid flow through a porous medium is of importance in many practical situations ranging from oil recovery to chemical reactors and has been studied experimentally and theoretically for a long time .", "tokens": ["fluid", "flow", "through", "a", "porous", "medium", "is", "of", "importance", "in", "many", "practical", "situations", "ranging", "from", "oil", "recovery", "to", "chemical", "reactors", "and", "has", "been", "studied", "experimentally", "and", "theoretically", "for", "a", "long", "time", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "fluid flow through a porous medium", "start": 0, "end": 34, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 6, "i_end": 6}}, {"subject": {"text": "fluid flow through a porous medium", "start": 0, "end": 34, "i_start": 0, "i_end": 5}, "verb": {"text": "studied", "start": 141, "end": 148, "i_start": 23, "i_end": 23}}], "id": 3815}, {"sent": "we show that the dm interaction leads to helical spin fluctuations which may be observed by the polarized neutron scattering .", "tokens": ["we", "show", "that", "the", "dm", "interaction", "leads", "to", "helical", "spin", "fluctuations", "which", "may", "be", "observed", "by", "the", "polarized", "neutron", "scattering", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the dm interaction", "start": 13, "end": 31, "i_start": 3, "i_end": 5}, "verb": {"text": "leads", "start": 32, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "interaction", "start": 20, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "leads", "start": 32, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "scattering", "start": 114, "end": 124, "i_start": 19, "i_end": 19}, "action": {"text": "observed", "start": 80, "end": 88, "i_start": 14, "i_end": 14}}], "id": 3816}, {"sent": "field theories on noncommutative space-time have received a great deal of attention , not least because they arise naturally in a particular seiberg-witten limit , for reviews .", "tokens": ["field", "theories", "on", "noncommutative", "space", "-", "time", "have", "received", "a", "great", "deal", "of", "attention", ",", "not", "least", "because", "they", "arise", "naturally", "in", "a", "particular", "seiberg", "-", "witten", "limit", ",", "for", "reviews", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "field theories on noncommutative space-time", "start": 0, "end": 43, "i_start": 0, "i_end": 6}, "verb": {"text": "have received", "start": 44, "end": 57, "i_start": 7, "i_end": 8}}, {"character": {"text": "theories", "start": 6, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "received", "start": 49, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "arise", "start": 109, "end": 114, "i_start": 19, "i_end": 19}, "action": {"text": "because", "start": 96, "end": 103, "i_start": 17, "i_end": 17}}], "id": 3817}, {"sent": "specifically , convolutional neural networks have shown their powerful abilities on image representation .", "tokens": ["specifically", ",", "convolutional", "neural", "networks", "have", "shown", "their", "powerful", "abilities", "on", "image", "representation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 15, "end": 44, "i_start": 2, "i_end": 4}, "verb": {"text": "have shown", "start": 45, "end": 55, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 36, "end": 44, "i_start": 4, "i_end": 4}, "action": {"text": "shown", "start": 50, "end": 55, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 36, "end": 44, "i_start": 4, "i_end": 4}, "action": {"text": "representation", "start": 90, "end": 104, "i_start": 12, "i_end": 12}}], "id": 3818}, {"sent": "in quantum mechanics , there is a lower limit to this process , set by the size of the planck cell , and this reduces the complexity of quantum motion as compared to classical motion .", "tokens": ["in", "quantum", "mechanics", ",", "there", "is", "a", "lower", "limit", "to", "this", "process", ",", "set", "by", "the", "size", "of", "the", "planck", "cell", ",", "and", "this", "reduces", "the", "complexity", "of", "quantum", "motion", "as", "compared", "to", "classical", "motion", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 23, "end": 28, "i_start": 4, "i_end": 4}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 5, "i_end": 5}}, {"subject": {"text": "this", "start": 105, "end": 109, "i_start": 23, "i_end": 23}, "verb": {"text": "reduces", "start": 110, "end": 117, "i_start": 24, "i_end": 24}}, {"character": {"text": "size", "start": 75, "end": 79, "i_start": 16, "i_end": 16}, "action": {"text": "set", "start": 64, "end": 67, "i_start": 13, "i_end": 13}}, {"character": {"text": "limit", "start": 40, "end": 45, "i_start": 8, "i_end": 8}, "action": {"text": "reduces", "start": 110, "end": 117, "i_start": 24, "i_end": 24}}], "id": 3819}, {"sent": "in the recent years deep neural networks have been used to achieve state-of-the-art results in image recognition , speech recognition and many other fields .", "tokens": ["in", "the", "recent", "years", "deep", "neural", "networks", "have", "been", "used", "to", "achieve", "state", "-", "of", "-", "the", "-", "art", "results", "in", "image", "recognition", ",", "speech", "recognition", "and", "many", "other", "fields", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 25, "end": 40, "i_start": 5, "i_end": 6}, "verb": {"text": "have been used", "start": 41, "end": 55, "i_start": 7, "i_end": 9}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "achieve", "start": 59, "end": 66, "i_start": 11, "i_end": 11}}], "id": 3820}, {"sent": "shahroudy et al introduced a part-aware lstm model to push the network towards learning long-term context representations of different body parts separately .", "tokens": ["shahroudy", "et", "al", "introduced", "a", "part", "-", "aware", "lstm", "model", "to", "push", "the", "network", "towards", "learning", "long", "-", "term", "context", "representations", "of", "different", "body", "parts", "separately", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 10, "end": 15, "i_start": 1, "i_end": 2}, "verb": {"text": "introduced", "start": 16, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "shahroudy", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 16, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "shahroudy", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "push", "start": 54, "end": 58, "i_start": 11, "i_end": 11}}], "id": 3821}, {"sent": "in particular , convolutional neural networks has been popular in vision and audio recognition areas .", "tokens": ["in", "particular", ",", "convolutional", "neural", "networks", "has", "been", "popular", "in", "vision", "and", "audio", "recognition", "areas", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "has been", "start": 46, "end": 54, "i_start": 6, "i_end": 7}}], "id": 3822}, {"sent": "recently , region-based convolutional neural networks have achieved state-of-the-art performance on generic object detection .", "tokens": ["recently", ",", "region", "-", "based", "convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "generic", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "region-based convolutional neural networks", "start": 11, "end": 53, "i_start": 2, "i_end": 7}, "verb": {"text": "have achieved", "start": 54, "end": 67, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 45, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 59, "end": 67, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 45, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "performance", "start": 85, "end": 96, "i_start": 17, "i_end": 17}}], "id": 3823}, {"sent": "in this paper we are aiming at solving the geodesic equation exactly by using numerical techniques and at exploring the complete set of solutions of the geodesic equation .", "tokens": ["in", "this", "paper", "we", "are", "aiming", "at", "solving", "the", "geodesic", "equation", "exactly", "by", "using", "numerical", "techniques", "and", "at", "exploring", "the", "complete", "set", "of", "solutions", "of", "the", "geodesic", "equation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "are aiming", "start": 17, "end": 27, "i_start": 4, "i_end": 5}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "aiming", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "solving", "start": 31, "end": 38, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "using", "start": 72, "end": 77, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "exploring", "start": 106, "end": 115, "i_start": 18, "i_end": 18}}], "id": 3824}, {"sent": "leptogenesis is one of the most attractive mechanisms to explain the origin of the matterantimatter asymmetry of the universe .", "tokens": ["leptogenesis", "is", "one", "of", "the", "most", "attractive", "mechanisms", "to", "explain", "the", "origin", "of", "the", "matterantimatter", "asymmetry", "of", "the", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "leptogenesis", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "mechanisms", "start": 43, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "attractive", "start": 32, "end": 42, "i_start": 6, "i_end": 6}}], "id": 3825}, {"sent": "more precisely , comparing with , we remove the dependence on inverse powers on \u03bd on the error constants of the galerkin method with grad-div stabilization .", "tokens": ["more", "precisely", ",", "comparing", "with", ",", "we", "remove", "the", "dependence", "on", "inverse", "powers", "on", "\u03bd", "on", "the", "error", "constants", "of", "the", "galerkin", "method", "with", "grad", "-", "div", "stabilization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "verb": {"text": "remove", "start": 37, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "remove", "start": 37, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "powers", "start": 70, "end": 76, "i_start": 12, "i_end": 12}, "action": {"text": "dependence", "start": 48, "end": 58, "i_start": 9, "i_end": 9}}], "id": 3826}, {"sent": "the pre-trained word-embeddings have been successfully used in numerous natural language processing applications and the induced vector-space is known to capture the graded similarities between words with reasonable accuracy .", "tokens": ["the", "pre", "-", "trained", "word", "-", "embeddings", "have", "been", "successfully", "used", "in", "numerous", "natural", "language", "processing", "applications", "and", "the", "induced", "vector", "-", "space", "is", "known", "to", "capture", "the", "graded", "similarities", "between", "words", "with", "reasonable", "accuracy", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "the induced vector-space", "start": 117, "end": 141, "i_start": 18, "i_end": 22}, "verb": {"text": "used", "start": 55, "end": 59, "i_start": 10, "i_end": 10}}, {"subject": {"text": "the pre-trained word-embeddings", "start": 0, "end": 31, "i_start": 0, "i_end": 6}, "verb": {"text": "have been", "start": 32, "end": 41, "i_start": 7, "i_end": 8}}, {"subject": {"text": "the pre-trained word-embeddings", "start": 0, "end": 31, "i_start": 0, "i_end": 6}, "verb": {"text": "known", "start": 145, "end": 150, "i_start": 24, "i_end": 24}}, {"character": {"text": "space", "start": 136, "end": 141, "i_start": 22, "i_end": 22}, "action": {"text": "capture", "start": 154, "end": 161, "i_start": 26, "i_end": 26}}], "id": 3827}, {"sent": "convolutional networks are a powerful model for learning feature extractors and visual models .", "tokens": ["convolutional", "networks", "are", "a", "powerful", "model", "for", "learning", "feature", "extractors", "and", "visual", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional networks", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 23, "end": 26, "i_start": 2, "i_end": 2}}], "id": 3828}, {"sent": "first we describe a more general sperner lemma-type of result for polytopes , following .", "tokens": ["first", "we", "describe", "a", "more", "general", "sperner", "lemma", "-", "type", "of", "result", "for", "polytopes", ",", "following", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 6, "end": 8, "i_start": 1, "i_end": 1}, "verb": {"text": "describe", "start": 9, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "describe", "start": 9, "end": 17, "i_start": 2, "i_end": 2}}], "id": 3829}, {"sent": "a striking result first observed in is that noncommutative world volume field theories living on noncommutative tori are invariant under duality transformations generated by morita equivalences of noncommutative tori .", "tokens": ["a", "striking", "result", "first", "observed", "in", "is", "that", "noncommutative", "world", "volume", "field", "theories", "living", "on", "noncommutative", "tori", "are", "invariant", "under", "duality", "transformations", "generated", "by", "morita", "equivalences", "of", "noncommutative", "tori", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a striking result first observed in", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 36, "end": 38, "i_start": 6, "i_end": 6}}, {"subject": {"text": "a striking result first observed in", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 117, "end": 120, "i_start": 17, "i_end": 17}}, {"character": {"text": "theories", "start": 78, "end": 86, "i_start": 12, "i_end": 12}, "action": {"text": "living", "start": 87, "end": 93, "i_start": 13, "i_end": 13}}, {"character": {"text": "equivalences", "start": 181, "end": 193, "i_start": 25, "i_end": 25}, "action": {"text": "generated", "start": 161, "end": 170, "i_start": 22, "i_end": 22}}], "id": 3830}, {"sent": "the element resolution of lemt up through fe is shown in detail by reames .", "tokens": ["the", "element", "resolution", "of", "lemt", "up", "through", "fe", "is", "shown", "in", "detail", "by", "reames", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the element resolution of lemt up through fe", "start": 0, "end": 44, "i_start": 0, "i_end": 7}, "verb": {"text": "is shown", "start": 45, "end": 53, "i_start": 8, "i_end": 9}}, {"character": {"text": "reames", "start": 67, "end": 73, "i_start": 13, "i_end": 13}, "action": {"text": "shown", "start": 48, "end": 53, "i_start": 9, "i_end": 9}}], "id": 3831}, {"sent": "a natural generalization is the complete set of n -point correlation functions which provide a full characterization of a distribution .", "tokens": ["a", "natural", "generalization", "is", "the", "complete", "set", "of", "n", "-point", "correlation", "functions", "which", "provide", "a", "full", "characterization", "of", "a", "distribution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a natural generalization", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "functions", "start": 69, "end": 78, "i_start": 11, "i_end": 11}, "action": {"text": "provide", "start": 85, "end": 92, "i_start": 13, "i_end": 13}}, {"character": {"text": "functions", "start": 69, "end": 78, "i_start": 11, "i_end": 11}, "action": {"text": "characterization", "start": 100, "end": 116, "i_start": 16, "i_end": 16}}], "id": 3832}, {"sent": "since the number of string states rises exponentially with energy , there is a maximal temperature which the thermal string gas can reach , the so-called hagedorn temperature t h .", "tokens": ["since", "the", "number", "of", "string", "states", "rises", "exponentially", "with", "energy", ",", "there", "is", "a", "maximal", "temperature", "which", "the", "thermal", "string", "gas", "can", "reach", ",", "the", "so", "-", "called", "hagedorn", "temperature", "t", "h", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "there", "start": 68, "end": 73, "i_start": 11, "i_end": 11}, "verb": {"text": "is", "start": 74, "end": 76, "i_start": 12, "i_end": 12}}, {"character": {"text": "gas", "start": 124, "end": 127, "i_start": 20, "i_end": 20}, "action": {"text": "reach", "start": 132, "end": 137, "i_start": 22, "i_end": 22}}], "id": 3833}, {"sent": "similar to li et al , we apply the reinforce algorithm to learn the optimal weights for each input .", "tokens": ["similar", "to", "li", "et", "al", ",", "we", "apply", "the", "reinforce", "algorithm", "to", "learn", "the", "optimal", "weights", "for", "each", "input", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 22, "end": 24, "i_start": 6, "i_end": 6}, "verb": {"text": "apply", "start": 25, "end": 30, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 6, "i_end": 6}, "action": {"text": "apply", "start": 25, "end": 30, "i_start": 7, "i_end": 7}}, {"character": {"text": "algorithm", "start": 45, "end": 54, "i_start": 10, "i_end": 10}, "action": {"text": "reinforce", "start": 35, "end": 44, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 6, "i_end": 6}, "action": {"text": "learn", "start": 58, "end": 63, "i_start": 12, "i_end": 12}}], "id": 3834}, {"sent": "furthermore , this foliation is a riemannian foliation whose transverse metric coincides with the metric of v .", "tokens": ["furthermore", ",", "this", "foliation", "is", "a", "riemannian", "foliation", "whose", "transverse", "metric", "coincides", "with", "the", "metric", "of", "v", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this foliation", "start": 14, "end": 28, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 4, "i_end": 4}}], "id": 3835}, {"sent": "we explain that consideration of the theory in euclidean signature is important from the perspective of fuzzy sphere solutions of matrix theory .", "tokens": ["we", "explain", "that", "consideration", "of", "the", "theory", "in", "euclidean", "signature", "is", "important", "from", "the", "perspective", "of", "fuzzy", "sphere", "solutions", "of", "matrix", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "explain", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 67, "end": 69, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "explain", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 3836}, {"sent": "ding et al uses the faster r-cnn to generate candidate nodules , followed by 3d convolutional networks to remove false positive nodules .", "tokens": ["ding", "et", "al", "uses", "the", "faster", "r", "-", "cnn", "to", "generate", "candidate", "nodules", ",", "followed", "by", "3d", "convolutional", "networks", "to", "remove", "false", "positive", "nodules", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "ding et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "uses", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "ding", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "uses", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "ding", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "generate", "start": 36, "end": 44, "i_start": 10, "i_end": 10}}, {"character": {"text": "networks", "start": 94, "end": 102, "i_start": 18, "i_end": 18}, "action": {"text": "remove", "start": 106, "end": 112, "i_start": 20, "i_end": 20}}], "id": 3837}, {"sent": "deep neural networks have exhibited great performance in computer vision tasks in recent years .", "tokens": ["deep", "neural", "networks", "have", "exhibited", "great", "performance", "in", "computer", "vision", "tasks", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have exhibited", "start": 21, "end": 35, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "exhibited", "start": 26, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 42, "end": 53, "i_start": 6, "i_end": 6}}], "id": 3838}, {"sent": "in the remainder of this section , let us study how our perturbation method works to achieve this goal .", "tokens": ["in", "the", "remainder", "of", "this", "section", ",", "let", "us", "study", "how", "our", "perturbation", "method", "works", "to", "achieve", "this", "goal", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 39, "end": 41, "i_start": 8, "i_end": 8}, "verb": {"text": "let", "start": 35, "end": 38, "i_start": 7, "i_end": 7}}, {"subject": {"text": "us", "start": 39, "end": 41, "i_start": 8, "i_end": 8}, "verb": {"text": "study", "start": 42, "end": 47, "i_start": 9, "i_end": 9}}, {"character": {"text": "us", "start": 39, "end": 41, "i_start": 8, "i_end": 8}, "action": {"text": "let", "start": 35, "end": 38, "i_start": 7, "i_end": 7}}, {"character": {"text": "us", "start": 39, "end": 41, "i_start": 8, "i_end": 8}, "action": {"text": "study", "start": 42, "end": 47, "i_start": 9, "i_end": 9}}, {"character": {"text": "us", "start": 39, "end": 41, "i_start": 8, "i_end": 8}, "action": {"text": "achieve", "start": 85, "end": 92, "i_start": 16, "i_end": 16}}], "id": 3839}, {"sent": "node cooperation has been shown to be an effective way of providing diversity in wireless fading networks .", "tokens": ["node", "cooperation", "has", "been", "shown", "to", "be", "an", "effective", "way", "of", "providing", "diversity", "in", "wireless", "fading", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "node cooperation", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "has been shown", "start": 17, "end": 31, "i_start": 2, "i_end": 4}}, {"character": {"text": "networks", "start": 97, "end": 105, "i_start": 16, "i_end": 16}, "action": {"text": "cooperation", "start": 5, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "way", "start": 51, "end": 54, "i_start": 9, "i_end": 9}, "action": {"text": "effective", "start": 41, "end": 50, "i_start": 8, "i_end": 8}}], "id": 3840}, {"sent": "the optimization is conducted using the adam optimizer with mini-batch training .", "tokens": ["the", "optimization", "is", "conducted", "using", "the", "adam", "optimizer", "with", "mini", "-", "batch", "training", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the optimization", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is conducted", "start": 17, "end": 29, "i_start": 2, "i_end": 3}}], "id": 3841}, {"sent": "in addition to old and new security threats , mcdaniel and mclaughlin discuss the privacy concerns of energy usage profiling that smart grids could potentially enable .", "tokens": ["in", "addition", "to", "old", "and", "new", "security", "threats", ",", "mcdaniel", "and", "mclaughlin", "discuss", "the", "privacy", "concerns", "of", "energy", "usage", "profiling", "that", "smart", "grids", "could", "potentially", "enable", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "mcdaniel and mclaughlin", "start": 46, "end": 69, "i_start": 9, "i_end": 11}, "verb": {"text": "discuss", "start": 70, "end": 77, "i_start": 12, "i_end": 12}}, {"character": {"text": "mcdaniel", "start": 46, "end": 54, "i_start": 9, "i_end": 9}, "action": {"text": "discuss", "start": 70, "end": 77, "i_start": 12, "i_end": 12}}, {"character": {"text": "mclaughlin", "start": 59, "end": 69, "i_start": 11, "i_end": 11}, "action": {"text": "discuss", "start": 70, "end": 77, "i_start": 12, "i_end": 12}}, {"character": {"text": "profiling", "start": 115, "end": 124, "i_start": 19, "i_end": 19}, "action": {"text": "concerns", "start": 90, "end": 98, "i_start": 15, "i_end": 15}}, {"character": {"text": "grids", "start": 136, "end": 141, "i_start": 22, "i_end": 22}, "action": {"text": "enable", "start": 160, "end": 166, "i_start": 25, "i_end": 25}}], "id": 3842}, {"sent": "we compare the proposed scheme with the full-rank with d coefficients provides an estimate of the desired symbol for the desired used using the signal-to-interference-plus-noise ratio .", "tokens": ["we", "compare", "the", "proposed", "scheme", "with", "the", "full", "-", "rank", "with", "d", "coefficients", "provides", "an", "estimate", "of", "the", "desired", "symbol", "for", "the", "desired", "used", "using", "the", "signal", "-", "to", "-", "interference", "-", "plus", "-", "noise", "ratio", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "provides", "start": 70, "end": 78, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "coefficients", "start": 57, "end": 69, "i_start": 12, "i_end": 12}, "action": {"text": "provides", "start": 70, "end": 78, "i_start": 13, "i_end": 13}}], "id": 3843}, {"sent": "in recent years , deep neural networks have achieved great success in a variety of machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "achieved", "great", "success", "in", "a", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}], "id": 3844}, {"sent": "the simplest modification is a noncovariant frequency cutoff .", "tokens": ["the", "simplest", "modification", "is", "a", "noncovariant", "frequency", "cutoff", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the simplest modification", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 3, "i_end": 3}}], "id": 3845}, {"sent": "neural network-based architectures have recently had great success in significantly advancing the state of the art on challenging image classification and object detection datasets .", "tokens": ["neural", "network", "-", "based", "architectures", "have", "recently", "had", "great", "success", "in", "significantly", "advancing", "the", "state", "of", "the", "art", "on", "challenging", "image", "classification", "and", "object", "detection", "datasets", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural network-based architectures", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "had", "start": 49, "end": 52, "i_start": 7, "i_end": 7}}, {"subject": {"text": "neural network-based architectures", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "architectures", "start": 21, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "architectures", "start": 21, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "advancing", "start": 84, "end": 93, "i_start": 12, "i_end": 12}}, {"character": {"text": "architectures", "start": 21, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "challenging", "start": 118, "end": 129, "i_start": 19, "i_end": 19}}, {"character": {"text": "datasets", "start": 172, "end": 180, "i_start": 25, "i_end": 25}, "action": {"text": "classification", "start": 136, "end": 150, "i_start": 21, "i_end": 21}}], "id": 3846}, {"sent": "in 1987 , affleck , kennedy , lieb , and tasaki introduced a novel quantum spin chain and rigorously proved that it exhibits a spectral gap above the ground state sector .", "tokens": ["in", "1987", ",", "affleck", ",", "kennedy", ",", "lieb", ",", "and", "tasaki", "introduced", "a", "novel", "quantum", "spin", "chain", "and", "rigorously", "proved", "that", "it", "exhibits", "a", "spectral", "gap", "above", "the", "ground", "state", "sector", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "affleck", "start": 10, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "introduced", "start": 48, "end": 58, "i_start": 11, "i_end": 11}}, {"subject": {"text": "affleck", "start": 10, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "proved", "start": 101, "end": 107, "i_start": 19, "i_end": 19}}, {"character": {"text": "affleck", "start": 10, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "introduced", "start": 48, "end": 58, "i_start": 11, "i_end": 11}}, {"character": {"text": "kennedy", "start": 20, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 48, "end": 58, "i_start": 11, "i_end": 11}}, {"character": {"text": "lieb", "start": 30, "end": 34, "i_start": 7, "i_end": 7}, "action": {"text": "introduced", "start": 48, "end": 58, "i_start": 11, "i_end": 11}}, {"character": {"text": "tasaki", "start": 41, "end": 47, "i_start": 10, "i_end": 10}, "action": {"text": "introduced", "start": 48, "end": 58, "i_start": 11, "i_end": 11}}], "id": 3847}, {"sent": "the cofibration is called closed , if a is a closed subspace .", "tokens": ["the", "cofibration", "is", "called", "closed", ",", "if", "a", "is", "a", "closed", "subspace", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the cofibration", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is called", "start": 16, "end": 25, "i_start": 2, "i_end": 3}}], "id": 3848}, {"sent": "meeting our life science students where they are means leveraging the resources that they bring to ipls courses from their experiences in biology and chemistry courses .", "tokens": ["meeting", "our", "life", "science", "students", "where", "they", "are", "means", "leveraging", "the", "resources", "that", "they", "bring", "to", "ipls", "courses", "from", "their", "experiences", "in", "biology", "and", "chemistry", "courses", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3849}, {"sent": "the notion of a rook strip was introduced by buch in the study of the littlewoodrichardson rule for stable grothendieck polynomials .", "tokens": ["the", "notion", "of", "a", "rook", "strip", "was", "introduced", "by", "buch", "in", "the", "study", "of", "the", "littlewoodrichardson", "rule", "for", "stable", "grothendieck", "polynomials", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the notion of a rook strip", "start": 0, "end": 26, "i_start": 0, "i_end": 5}, "verb": {"text": "was introduced", "start": 27, "end": 41, "i_start": 6, "i_end": 7}}, {"character": {"text": "buch", "start": 45, "end": 49, "i_start": 9, "i_end": 9}, "action": {"text": "introduced", "start": 31, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "littlewoodrichardson", "start": 70, "end": 90, "i_start": 15, "i_end": 15}, "action": {"text": "rule", "start": 91, "end": 95, "i_start": 16, "i_end": 16}}], "id": 3850}, {"sent": "in an n-body simulation a given density-velocity field is represented by a set of particles .", "tokens": ["in", "an", "n", "-", "body", "simulation", "a", "given", "density", "-", "velocity", "field", "is", "represented", "by", "a", "set", "of", "particles", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "a given density-velocity field", "start": 24, "end": 54, "i_start": 6, "i_end": 11}, "verb": {"text": "is represented", "start": 55, "end": 69, "i_start": 12, "i_end": 13}}, {"character": {"text": "set", "start": 75, "end": 78, "i_start": 16, "i_end": 16}, "action": {"text": "represented", "start": 58, "end": 69, "i_start": 13, "i_end": 13}}], "id": 3851}, {"sent": "this is different from the standard practice where chance constraints are placed on every bus of the network .", "tokens": ["this", "is", "different", "from", "the", "standard", "practice", "where", "chance", "constraints", "are", "placed", "on", "every", "bus", "of", "the", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3852}, {"sent": "one of the earlier methods for jointly learning face detection , landmarks localization and pose estimation was proposed in .", "tokens": ["one", "of", "the", "earlier", "methods", "for", "jointly", "learning", "face", "detection", ",", "landmarks", "localization", "and", "pose", "estimation", "was", "proposed", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "one of the earlier methods for jointly learning face detection , landmarks localization and pose estimation", "start": 0, "end": 107, "i_start": 0, "i_end": 15}, "verb": {"text": "was proposed", "start": 108, "end": 120, "i_start": 16, "i_end": 17}}], "id": 3853}, {"sent": "discrete breathers are known as time-periodic and spatially localized solutions of nonlinear discrete systems .", "tokens": ["discrete", "breathers", "are", "known", "as", "time", "-", "periodic", "and", "spatially", "localized", "solutions", "of", "nonlinear", "discrete", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "discrete breathers", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "are known", "start": 19, "end": 28, "i_start": 2, "i_end": 3}}], "id": 3854}, {"sent": "all non-recurrent matrices were initialized following the method of glorot and bengio .", "tokens": ["all", "non", "-", "recurrent", "matrices", "were", "initialized", "following", "the", "method", "of", "glorot", "and", "bengio", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all non-recurrent matrices", "start": 0, "end": 26, "i_start": 0, "i_end": 4}, "verb": {"text": "were initialized", "start": 27, "end": 43, "i_start": 5, "i_end": 6}}], "id": 3855}, {"sent": "it is known that the number of csi feedback bits per user should increase linearly with respect to snr in log scale in order to achieve full multiplexing gain for miso bcs .", "tokens": ["it", "is", "known", "that", "the", "number", "of", "csi", "feedback", "bits", "per", "user", "should", "increase", "linearly", "with", "respect", "to", "snr", "in", "log", "scale", "in", "order", "to", "achieve", "full", "multiplexing", "gain", "for", "miso", "bcs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is known", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"subject": {"text": "the number of csi feedback bits per user", "start": 17, "end": 57, "i_start": 4, "i_end": 11}, "verb": {"text": "increase", "start": 65, "end": 73, "i_start": 13, "i_end": 13}}], "id": 3856}, {"sent": "we use adaptive moment estimation with different learning rate for different parts of the model as our optimizer .", "tokens": ["we", "use", "adaptive", "moment", "estimation", "with", "different", "learning", "rate", "for", "different", "parts", "of", "the", "model", "as", "our", "optimizer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimizer", "start": 103, "end": 112, "i_start": 17, "i_end": 17}}], "id": 3857}, {"sent": "recently , convolutional neural network has achieved great success in computer vision tasks such as image classification in recent years .", "tokens": ["recently", ",", "convolutional", "neural", "network", "has", "achieved", "great", "success", "in", "computer", "vision", "tasks", "such", "as", "image", "classification", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural network", "start": 11, "end": 39, "i_start": 2, "i_end": 4}, "verb": {"text": "has achieved", "start": 40, "end": 52, "i_start": 5, "i_end": 6}}, {"character": {"text": "network", "start": 32, "end": 39, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 6, "i_end": 6}}, {"character": {"text": "network", "start": 32, "end": 39, "i_start": 4, "i_end": 4}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 8, "i_end": 8}}], "id": 3858}, {"sent": "reinforcement learning consists on learning how to map situations to actions in order to maximize a numerical reward .", "tokens": ["reinforcement", "learning", "consists", "on", "learning", "how", "to", "map", "situations", "to", "actions", "in", "order", "to", "maximize", "a", "numerical", "reward", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 23, "end": 31, "i_start": 2, "i_end": 2}}], "id": 3859}, {"sent": "this study indicates that the quality of night-sky in hong kong is strongly associated with human presence and human activities , as predicted by the different land utilizations .", "tokens": ["this", "study", "indicates", "that", "the", "quality", "of", "night", "-", "sky", "in", "hong", "kong", "is", "strongly", "associated", "with", "human", "presence", "and", "human", "activities", ",", "as", "predicted", "by", "the", "different", "land", "utilizations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this study", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "indicates", "start": 11, "end": 20, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the quality of night-sky in hong kong", "start": 26, "end": 63, "i_start": 4, "i_end": 12}, "verb": {"text": "associated", "start": 76, "end": 86, "i_start": 15, "i_end": 15}}, {"character": {"text": "study", "start": 5, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "indicates", "start": 11, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "utilizations", "start": 165, "end": 177, "i_start": 29, "i_end": 29}, "action": {"text": "predicted", "start": 133, "end": 142, "i_start": 24, "i_end": 24}}], "id": 3860}, {"sent": "the focus in was on channel conditions where interference alignment is necessary .", "tokens": ["the", "focus", "in", "was", "on", "channel", "conditions", "where", "interference", "alignment", "is", "necessary", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the focus in", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "was", "start": 13, "end": 16, "i_start": 3, "i_end": 3}}], "id": 3861}, {"sent": "find conditions on the semigroup ring fs so that fs has units which are s-units .", "tokens": ["find", "conditions", "on", "the", "semigroup", "ring", "fs", "so", "that", "fs", "has", "units", "which", "are", "s", "-", "units", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "ring", "start": 33, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "has", "start": 52, "end": 55, "i_start": 10, "i_end": 10}}], "id": 3862}, {"sent": "cosmic strings are line-like concentrations of energy that can arise as topological defects in cosmological phase transitions in the early universe .", "tokens": ["cosmic", "strings", "are", "line", "-", "like", "concentrations", "of", "energy", "that", "can", "arise", "as", "topological", "defects", "in", "cosmological", "phase", "transitions", "in", "the", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "defects", "start": 84, "end": 91, "i_start": 14, "i_end": 14}, "action": {"text": "arise", "start": 63, "end": 68, "i_start": 11, "i_end": 11}}], "id": 3863}, {"sent": "in the context of poisson inverse problems , this approach was originally proposed by mcclure for tomographic image reconstruction and later studied and extended by saquib et al , but has received little attention since then .", "tokens": ["in", "the", "context", "of", "poisson", "inverse", "problems", ",", "this", "approach", "was", "originally", "proposed", "by", "mcclure", "for", "tomographic", "image", "reconstruction", "and", "later", "studied", "and", "extended", "by", "saquib", "et", "al", ",", "but", "has", "received", "little", "attention", "since", "then", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this approach", "start": 45, "end": 58, "i_start": 8, "i_end": 9}, "verb": {"text": "proposed", "start": 74, "end": 82, "i_start": 12, "i_end": 12}}, {"subject": {"text": "this approach", "start": 45, "end": 58, "i_start": 8, "i_end": 9}, "verb": {"text": "was", "start": 59, "end": 62, "i_start": 10, "i_end": 10}}, {"subject": {"text": "this approach", "start": 45, "end": 58, "i_start": 8, "i_end": 9}, "verb": {"text": "studied", "start": 141, "end": 148, "i_start": 21, "i_end": 21}}, {"subject": {"text": "this approach", "start": 45, "end": 58, "i_start": 8, "i_end": 9}, "verb": {"text": "received", "start": 188, "end": 196, "i_start": 31, "i_end": 31}}, {"character": {"text": "saquib", "start": 165, "end": 171, "i_start": 25, "i_end": 25}, "action": {"text": "studied", "start": 141, "end": 148, "i_start": 21, "i_end": 21}}, {"character": {"text": "saquib", "start": 165, "end": 171, "i_start": 25, "i_end": 25}, "action": {"text": "extended", "start": 153, "end": 161, "i_start": 23, "i_end": 23}}], "id": 3864}, {"sent": "all convolutions are followed by batch normalization and relu , with the exception at the last layer .", "tokens": ["all", "convolutions", "are", "followed", "by", "batch", "normalization", "and", "relu", ",", "with", "the", "exception", "at", "the", "last", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all convolutions", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "are followed", "start": 17, "end": 29, "i_start": 2, "i_end": 3}}], "id": 3865}, {"sent": "a major appeal of deep neural networks is their ability to attain remarkably high accuracy on a variety of tasks .", "tokens": ["a", "major", "appeal", "of", "deep", "neural", "networks", "is", "their", "ability", "to", "attain", "remarkably", "high", "accuracy", "on", "a", "variety", "of", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a major appeal of deep neural networks", "start": 0, "end": 38, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "attain", "start": 59, "end": 65, "i_start": 11, "i_end": 11}}], "id": 3866}, {"sent": "neural networks have achieved state-of-the-art results in a wide variety of supervised learning tasks , such as image recognition .", "tokens": ["neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "results", "in", "a", "wide", "variety", "of", "supervised", "learning", "tasks", ",", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have achieved", "start": 16, "end": 29, "i_start": 2, "i_end": 3}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "achieved", "start": 21, "end": 29, "i_start": 3, "i_end": 3}}], "id": 3867}, {"sent": "quantum computation consists of single-qubit measurements on the graph states and every quantum algorithm is encoded in a measurement blueprint .", "tokens": ["quantum", "computation", "consists", "of", "single", "-", "qubit", "measurements", "on", "the", "graph", "states", "and", "every", "quantum", "algorithm", "is", "encoded", "in", "a", "measurement", "blueprint", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum computation", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 20, "end": 28, "i_start": 2, "i_end": 2}}, {"subject": {"text": "quantum computation", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "encoded", "start": 109, "end": 116, "i_start": 17, "i_end": 17}}], "id": 3868}, {"sent": "the rest of the argument is the same as in the case of linear discrete connection .", "tokens": ["the", "rest", "of", "the", "argument", "is", "the", "same", "as", "in", "the", "case", "of", "linear", "discrete", "connection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the rest of the argument", "start": 0, "end": 24, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 5, "i_end": 5}}], "id": 3869}, {"sent": "using space embeddings , jiang et al gave a method in to construct charge-constrained rank-modulation codes from lee error-correcting codes , which could be employed for flash memories .", "tokens": ["using", "space", "embeddings", ",", "jiang", "et", "al", "gave", "a", "method", "in", "to", "construct", "charge", "-", "constrained", "rank", "-", "modulation", "codes", "from", "lee", "error", "-", "correcting", "codes", ",", "which", "could", "be", "employed", "for", "flash", "memories", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "jiang et al", "start": 25, "end": 36, "i_start": 4, "i_end": 6}, "verb": {"text": "gave", "start": 37, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "jiang", "start": 25, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "construct", "start": 57, "end": 66, "i_start": 12, "i_end": 12}}, {"character": {"text": "codes", "start": 134, "end": 139, "i_start": 25, "i_end": 25}, "action": {"text": "correcting", "start": 123, "end": 133, "i_start": 24, "i_end": 24}}, {"character": {"text": "jiang", "start": 25, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "using", "start": 0, "end": 5, "i_start": 0, "i_end": 0}}], "id": 3870}, {"sent": "gravity is the only long range force that can not be screened .", "tokens": ["gravity", "is", "the", "only", "long", "range", "force", "that", "can", "not", "be", "screened", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "gravity", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}], "id": 3871}, {"sent": "the catenoid is the minimal surface in r3 given by ( cosh s cos t , cosh s sin t , s ) , where s , t r .", "tokens": ["the", "catenoid", "is", "the", "minimal", "surface", "in", "r3", "given", "by", "(", "cosh", "s", "cos", "t", ",", "cosh", "s", "sin", "t", ",", "s", ")", ",", "where", "s", ",", "t", "r", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the catenoid", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "cosh", "start": 53, "end": 57, "i_start": 11, "i_end": 11}, "action": {"text": "given", "start": 42, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "cos", "start": 60, "end": 63, "i_start": 13, "i_end": 13}, "action": {"text": "given", "start": 42, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "cosh", "start": 68, "end": 72, "i_start": 16, "i_end": 16}, "action": {"text": "given", "start": 42, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "sin", "start": 75, "end": 78, "i_start": 18, "i_end": 18}, "action": {"text": "given", "start": 42, "end": 47, "i_start": 8, "i_end": 8}}], "id": 3872}, {"sent": "for the self-adjoint linear system above , the stable , efficient and accurate conjugate gradient method may be used .", "tokens": ["for", "the", "self", "-", "adjoint", "linear", "system", "above", ",", "the", "stable", ",", "efficient", "and", "accurate", "conjugate", "gradient", "method", "may", "be", "used", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the stable", "start": 43, "end": 53, "i_start": 9, "i_end": 10}, "verb": {"text": "may be used", "start": 105, "end": 116, "i_start": 18, "i_end": 20}}], "id": 3873}, {"sent": "a detailed description of the cms detector , together with the coordinate system and the standard kinematic variables , can be found in ref .", "tokens": ["a", "detailed", "description", "of", "the", "cms", "detector", ",", "together", "with", "the", "coordinate", "system", "and", "the", "standard", "kinematic", "variables", ",", "can", "be", "found", "in", "ref", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "a detailed description of the cms detector", "start": 0, "end": 42, "i_start": 0, "i_end": 6}, "verb": {"text": "can be found", "start": 120, "end": 132, "i_start": 19, "i_end": 21}}], "id": 3874}, {"sent": "deep neural networks are powerful learning models which have been successfully applied to vision , speech and many other tasks .", "tokens": ["deep", "neural", "networks", "are", "powerful", "learning", "models", "which", "have", "been", "successfully", "applied", "to", "vision", ",", "speech", "and", "many", "other", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3875}, {"sent": "convolutional neural networks have seen tremendous success across different problems including image classification .", "tokens": ["convolutional", "neural", "networks", "have", "seen", "tremendous", "success", "across", "different", "problems", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have seen", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "seen", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 51, "end": 58, "i_start": 6, "i_end": 6}}], "id": 3876}, {"sent": "it is well-known that feedback does not increase the capacity of point-to-point channels .", "tokens": ["it", "is", "well", "-", "known", "that", "feedback", "does", "not", "increase", "the", "capacity", "of", "point", "-", "to", "-", "point", "channels", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "feedback", "start": 22, "end": 30, "i_start": 6, "i_end": 6}, "verb": {"text": "increase", "start": 40, "end": 48, "i_start": 9, "i_end": 9}}, {"character": {"text": "feedback", "start": 22, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "-known that feedback does not increase", "start": 10, "end": 48, "i_start": 3, "i_end": 9}}], "id": 3877}, {"sent": "stable models and an alternative logic programming paradigm .", "tokens": ["stable", "models", "and", "an", "alternative", "logic", "programming", "paradigm", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3878}, {"sent": "periodic solutions of the planetary n-body problem .", "tokens": ["periodic", "solutions", "of", "the", "planetary", "n", "-", "body", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3879}, {"sent": "we use the generalized gradient approximation exchange and correlation functional .", "tokens": ["we", "use", "the", "generalized", "gradient", "approximation", "exchange", "and", "correlation", "functional", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 3880}, {"sent": "another option is creating efficient architectures such as squeezenet .", "tokens": ["another", "option", "is", "creating", "efficient", "architectures", "such", "as", "squeezenet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another option", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is creating", "start": 15, "end": 26, "i_start": 2, "i_end": 3}}], "id": 3881}, {"sent": "the calibrated visibility data were fourier-transformed and cleaned with miriad to produce images .", "tokens": ["the", "calibrated", "visibility", "data", "were", "fourier", "-", "transformed", "and", "cleaned", "with", "miriad", "to", "produce", "images", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the calibrated visibility data", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "were", "start": 31, "end": 35, "i_start": 4, "i_end": 4}}], "id": 3882}, {"sent": "wang et al introduce a fully convolutional neural network tracking approach by transferring the pre-trained deep features to improve tracking accuracy .", "tokens": ["wang", "et", "al", "introduce", "a", "fully", "convolutional", "neural", "network", "tracking", "approach", "by", "transferring", "the", "pre", "-", "trained", "deep", "features", "to", "improve", "tracking", "accuracy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "wang et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "introduce", "start": 11, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "wang", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "introduce", "start": 11, "end": 20, "i_start": 3, "i_end": 3}}], "id": 3883}, {"sent": "honore et al , lee and lee , blundell and powell , and frandsen .", "tokens": ["honore", "et", "al", ",", "lee", "and", "lee", ",", "blundell", "and", "powell", ",", "and", "frandsen", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3884}, {"sent": "among others , the two-dimensional case arises in pat with so called integrating line detectors .", "tokens": ["among", "others", ",", "the", "two", "-", "dimensional", "case", "arises", "in", "pat", "with", "so", "called", "integrating", "line", "detectors", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the two-dimensional case", "start": 15, "end": 39, "i_start": 3, "i_end": 7}, "verb": {"text": "arises", "start": 40, "end": 46, "i_start": 8, "i_end": 8}}, {"character": {"text": "integrating", "start": 69, "end": 80, "i_start": 14, "i_end": 14}, "action": {"text": "arises", "start": 40, "end": 46, "i_start": 8, "i_end": 8}}], "id": 3885}, {"sent": "for example , socher et al introduced a recursive deep model to understand and leverage compositionality in tasks such as sentiment detection .", "tokens": ["for", "example", ",", "socher", "et", "al", "introduced", "a", "recursive", "deep", "model", "to", "understand", "and", "leverage", "compositionality", "in", "tasks", "such", "as", "sentiment", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "socher et al", "start": 14, "end": 26, "i_start": 3, "i_end": 5}, "verb": {"text": "introduced", "start": 27, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "socher", "start": 14, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "introduced", "start": 27, "end": 37, "i_start": 6, "i_end": 6}}], "id": 3886}, {"sent": "the stabilization of these remaining moduli might however be achieved by incorporating in addition h-flux superpotentials which we will outline in the last part of the paper .", "tokens": ["the", "stabilization", "of", "these", "remaining", "moduli", "might", "however", "be", "achieved", "by", "incorporating", "in", "addition", "h", "-", "flux", "superpotentials", "which", "we", "will", "outline", "in", "the", "last", "part", "of", "the", "paper", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the stabilization of these remaining moduli", "start": 0, "end": 43, "i_start": 0, "i_end": 5}, "verb": {"text": "be achieved", "start": 58, "end": 69, "i_start": 8, "i_end": 9}}, {"subject": {"text": "the stabilization of these remaining moduli", "start": 0, "end": 43, "i_start": 0, "i_end": 5}, "verb": {"text": "might", "start": 44, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 128, "end": 130, "i_start": 19, "i_end": 19}, "action": {"text": "outline", "start": 136, "end": 143, "i_start": 21, "i_end": 21}}], "id": 3887}, {"sent": "for making the images , we used the polyhedron method to minimize the effects of noncoplanar baselines .", "tokens": ["for", "making", "the", "images", ",", "we", "used", "the", "polyhedron", "method", "to", "minimize", "the", "effects", "of", "noncoplanar", "baselines", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "verb": {"text": "used", "start": 27, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "used", "start": 27, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "minimize", "start": 57, "end": 65, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "making", "start": 4, "end": 10, "i_start": 1, "i_end": 1}}], "id": 3888}, {"sent": "this fundamental problem of comparing multiple distributions is a classical topic in statistics with a wide range of applications .", "tokens": ["this", "fundamental", "problem", "of", "comparing", "multiple", "distributions", "is", "a", "classical", "topic", "in", "statistics", "with", "a", "wide", "range", "of", "applications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this fundamental problem of comparing multiple distributions", "start": 0, "end": 60, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 61, "end": 63, "i_start": 7, "i_end": 7}}], "id": 3889}, {"sent": "a priori , it might not be clear why this is a natural diophantine problem .", "tokens": ["a", "priori", ",", "it", "might", "not", "be", "clear", "why", "this", "is", "a", "natural", "diophantine", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 11, "end": 13, "i_start": 3, "i_end": 3}, "verb": {"text": "might not be", "start": 14, "end": 26, "i_start": 4, "i_end": 6}}], "id": 3890}, {"sent": "recently a new method has become known , namely the multiparticle effective field method was put forward and developed by the author .", "tokens": ["recently", "a", "new", "method", "has", "become", "known", ",", "namely", "the", "multiparticle", "effective", "field", "method", "was", "put", "forward", "and", "developed", "by", "the", "author", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "namely the multiparticle effective field method", "start": 41, "end": 88, "i_start": 8, "i_end": 13}, "verb": {"text": "was put", "start": 89, "end": 96, "i_start": 14, "i_end": 15}}, {"subject": {"text": "namely the multiparticle effective field method", "start": 41, "end": 88, "i_start": 8, "i_end": 13}, "verb": {"text": "developed", "start": 109, "end": 118, "i_start": 18, "i_end": 18}}, {"character": {"text": "method", "start": 82, "end": 88, "i_start": 13, "i_end": 13}, "action": {"text": "effective", "start": 66, "end": 75, "i_start": 11, "i_end": 11}}], "id": 3891}, {"sent": "this system is implemented in python using the pytorch deep learning framework .", "tokens": ["this", "system", "is", "implemented", "in", "python", "using", "the", "pytorch", "deep", "learning", "framework", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this system", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is implemented", "start": 12, "end": 26, "i_start": 2, "i_end": 3}}], "id": 3892}, {"sent": "we will return to address this analysis elsewhere .", "tokens": ["we", "will", "return", "to", "address", "this", "analysis", "elsewhere", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will return", "start": 3, "end": 14, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "address", "start": 18, "end": 25, "i_start": 4, "i_end": 4}}], "id": 3893}, {"sent": "in the first approach , we apply sscnet without the flipped tsdf as input feature .", "tokens": ["in", "the", "first", "approach", ",", "we", "apply", "sscnet", "without", "the", "flipped", "tsdf", "as", "input", "feature", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "verb": {"text": "apply", "start": 27, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "apply", "start": 27, "end": 32, "i_start": 6, "i_end": 6}}], "id": 3894}, {"sent": "for the exchange-correlation functional we employed the generalized gradient approximation functionals .", "tokens": ["for", "the", "exchange", "-", "correlation", "functional", "we", "employed", "the", "generalized", "gradient", "approximation", "functionals", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 40, "end": 42, "i_start": 6, "i_end": 6}, "verb": {"text": "employed", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}], "id": 3895}, {"sent": "convolutional neural networks have had huge successes since krizhevsky et al , especially in computer vision applications .", "tokens": ["convolutional", "neural", "networks", "have", "had", "huge", "successes", "since", "krizhevsky", "et", "al", ",", "especially", "in", "computer", "vision", "applications", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have had", "start": 30, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successes", "start": 44, "end": 53, "i_start": 6, "i_end": 6}}], "id": 3896}, {"sent": "deep convolutional neural networks have emerged as highly effective models for these large-scale visual recognition tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "emerged", "as", "highly", "effective", "models", "for", "these", "large", "-", "scale", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have emerged", "start": 35, "end": 47, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "emerged", "start": 40, "end": 47, "i_start": 5, "i_end": 5}}, {"character": {"text": "models", "start": 68, "end": 74, "i_start": 9, "i_end": 9}, "action": {"text": "effective", "start": 58, "end": 67, "i_start": 8, "i_end": 8}}], "id": 3897}, {"sent": "a nonlinear theory of elastic materials with voids .", "tokens": ["a", "nonlinear", "theory", "of", "elastic", "materials", "with", "voids", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3898}, {"sent": "deep neural networks have been very successful in large-scale recognition and classification tasks , some even surpassing human-level accuracy .", "tokens": ["deep", "neural", "networks", "have", "been", "very", "successful", "in", "large", "-", "scale", "recognition", "and", "classification", "tasks", ",", "some", "even", "surpassing", "human", "-", "level", "accuracy", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 36, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "surpassing", "start": 111, "end": 121, "i_start": 18, "i_end": 18}}], "id": 3899}, {"sent": "quantum entanglement , which is the basic ingredient of quantum information theory , is yet to be understood completely in the context of such systems .", "tokens": ["quantum", "entanglement", ",", "which", "is", "the", "basic", "ingredient", "of", "quantum", "information", "theory", ",", "is", "yet", "to", "be", "understood", "completely", "in", "the", "context", "of", "such", "systems", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "quantum entanglement", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 85, "end": 87, "i_start": 13, "i_end": 13}}], "id": 3900}, {"sent": "because hydrogen is the lightest substance and therefore consists of the fastest-moving particles at any temperature , it is the best 93 working fluid to use .", "tokens": ["because", "hydrogen", "is", "the", "lightest", "substance", "and", "therefore", "consists", "of", "the", "fastest", "-", "moving", "particles", "at", "any", "temperature", ",", "it", "is", "the", "best", "93", "working", "fluid", "to", "use", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 119, "end": 121, "i_start": 19, "i_end": 19}, "verb": {"text": "is", "start": 122, "end": 124, "i_start": 20, "i_end": 20}}, {"character": {"text": "substance", "start": 33, "end": 42, "i_start": 5, "i_end": 5}, "action": {"text": "because", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}], "id": 3901}, {"sent": "based on the manifold model , the pointwise convergence of the gl to the laplace-beltrami operator of the associated manifold is studied in .", "tokens": ["based", "on", "the", "manifold", "model", ",", "the", "pointwise", "convergence", "of", "the", "gl", "to", "the", "laplace", "-", "beltrami", "operator", "of", "the", "associated", "manifold", "is", "studied", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the pointwise convergence of the gl to the laplace-beltrami operator of the associated manifold", "start": 30, "end": 125, "i_start": 6, "i_end": 21}, "verb": {"text": "is studied", "start": 126, "end": 136, "i_start": 22, "i_end": 23}}], "id": 3902}, {"sent": "each orbit is a homogeneous riemannian manifold and therefore isometric to a copy of g equipped with a left invariant riemannian metric , namely the pullback of the induced spatial metric on the orbit .", "tokens": ["each", "orbit", "is", "a", "homogeneous", "riemannian", "manifold", "and", "therefore", "isometric", "to", "a", "copy", "of", "g", "equipped", "with", "a", "left", "invariant", "riemannian", "metric", ",", "namely", "the", "pullback", "of", "the", "induced", "spatial", "metric", "on", "the", "orbit", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each orbit", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}], "id": 3903}, {"sent": "recently convolutional neural networks have performed very well on image classification tasks and are pervasive in machine learning and computer vision .", "tokens": ["recently", "convolutional", "neural", "networks", "have", "performed", "very", "well", "on", "image", "classification", "tasks", "and", "are", "pervasive", "in", "machine", "learning", "and", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 9, "end": 38, "i_start": 1, "i_end": 3}, "verb": {"text": "have performed", "start": 39, "end": 53, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "performed", "start": 44, "end": 53, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "pervasive", "start": 102, "end": 111, "i_start": 14, "i_end": 14}}], "id": 3904}, {"sent": "for example , lorentz violation can have consequences for neutrino oscillation experiments , in particular that neutrino oscillation still occurs even if the mass is zero .", "tokens": ["for", "example", ",", "lorentz", "violation", "can", "have", "consequences", "for", "neutrino", "oscillation", "experiments", ",", "in", "particular", "that", "neutrino", "oscillation", "still", "occurs", "even", "if", "the", "mass", "is", "zero", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "lorentz violation", "start": 14, "end": 31, "i_start": 3, "i_end": 4}, "verb": {"text": "can have", "start": 32, "end": 40, "i_start": 5, "i_end": 6}}, {"subject": {"text": "neutrino oscillation", "start": 112, "end": 132, "i_start": 16, "i_end": 17}, "verb": {"text": "occurs", "start": 139, "end": 145, "i_start": 19, "i_end": 19}}], "id": 3905}, {"sent": "now we prove the main theorem of this section .", "tokens": ["now", "we", "prove", "the", "main", "theorem", "of", "this", "section", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "prove", "start": 7, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "prove", "start": 7, "end": 12, "i_start": 2, "i_end": 2}}], "id": 3906}, {"sent": "our method shares a similar idea as revealed in the spatial transformation network .", "tokens": ["our", "method", "shares", "a", "similar", "idea", "as", "revealed", "in", "the", "spatial", "transformation", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our method", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "shares", "start": 11, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "method", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "shares", "start": 11, "end": 17, "i_start": 2, "i_end": 2}}], "id": 3907}, {"sent": "some methods used , such as cryptographic , authentication and other mechanisms , do not entirely solve the problem .", "tokens": ["some", "methods", "used", ",", "such", "as", "cryptographic", ",", "authentication", "and", "other", "mechanisms", ",", "do", "not", "entirely", "solve", "the", "problem", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "some methods used", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "solve", "start": 98, "end": 103, "i_start": 16, "i_end": 16}}, {"subject": {"text": "some methods used", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "do not", "start": 82, "end": 88, "i_start": 13, "i_end": 14}}, {"character": {"text": "methods", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "not entirely solve", "start": 85, "end": 103, "i_start": 14, "i_end": 16}}], "id": 3908}, {"sent": "moreover , the misalignment is a function of mn local moment concentration , hole density and temperature .", "tokens": ["moreover", ",", "the", "misalignment", "is", "a", "function", "of", "mn", "local", "moment", "concentration", ",", "hole", "density", "and", "temperature", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the misalignment", "start": 11, "end": 27, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "concentration", "start": 61, "end": 74, "i_start": 11, "i_end": 11}, "action": {"text": "function", "start": 33, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "density", "start": 82, "end": 89, "i_start": 14, "i_end": 14}, "action": {"text": "function", "start": 33, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "hole", "start": 77, "end": 81, "i_start": 13, "i_end": 13}, "action": {"text": "function", "start": 33, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "temperature", "start": 94, "end": 105, "i_start": 16, "i_end": 16}, "action": {"text": "function", "start": 33, "end": 41, "i_start": 6, "i_end": 6}}], "id": 3909}, {"sent": "queen utilizes recursive dns queries to estimate the packet loss between a pair of arbitrary hosts by measuring the packet loss between their respective dns servers .", "tokens": ["queen", "utilizes", "recursive", "dns", "queries", "to", "estimate", "the", "packet", "loss", "between", "a", "pair", "of", "arbitrary", "hosts", "by", "measuring", "the", "packet", "loss", "between", "their", "respective", "dns", "servers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "queen", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "utilizes", "start": 6, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "queen", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "utilizes", "start": 6, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "queen", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "estimate", "start": 40, "end": 48, "i_start": 6, "i_end": 6}}, {"character": {"text": "queen", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "measuring", "start": 102, "end": 111, "i_start": 17, "i_end": 17}}], "id": 3910}, {"sent": "for high energy jets , resolutions are limited by the confusion .", "tokens": ["for", "high", "energy", "jets", ",", "resolutions", "are", "limited", "by", "the", "confusion", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "resolutions", "start": 23, "end": 34, "i_start": 5, "i_end": 5}, "verb": {"text": "are limited", "start": 35, "end": 46, "i_start": 6, "i_end": 7}}, {"character": {"text": "confusion", "start": 54, "end": 63, "i_start": 10, "i_end": 10}, "action": {"text": "limited", "start": 39, "end": 46, "i_start": 7, "i_end": 7}}], "id": 3911}, {"sent": "peer to peer networks will likely become an important distribution channel for consumer .", "tokens": ["peer", "to", "peer", "networks", "will", "likely", "become", "an", "important", "distribution", "channel", "for", "consumer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "peer to peer networks", "start": 0, "end": 21, "i_start": 0, "i_end": 3}, "verb": {"text": "become", "start": 34, "end": 40, "i_start": 6, "i_end": 6}}, {"subject": {"text": "peer to peer networks", "start": 0, "end": 21, "i_start": 0, "i_end": 3}, "verb": {"text": "will", "start": 22, "end": 26, "i_start": 4, "i_end": 4}}], "id": 3912}, {"sent": "the phase space consists of m such unit cells side by side .", "tokens": ["the", "phase", "space", "consists", "of", "m", "such", "unit", "cells", "side", "by", "side", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the phase space", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3913}, {"sent": "schweigert , correspondences of ribbon categories , phisms , nucl .", "tokens": ["schweigert", ",", "correspondences", "of", "ribbon", "categories", ",", "phisms", ",", "nucl", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3914}, {"sent": "dynamical properties of dipolar fermi gases .", "tokens": ["dynamical", "properties", "of", "dipolar", "fermi", "gases", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3915}, {"sent": "if x carries a strong torus action , then the gromov-witten theory of x is reduced to hodge integrals on m g , n via localization of the virtual class .", "tokens": ["if", "x", "carries", "a", "strong", "torus", "action", ",", "then", "the", "gromov", "-", "witten", "theory", "of", "x", "is", "reduced", "to", "hodge", "integrals", "on", "m", "g", ",", "n", "via", "localization", "of", "the", "virtual", "class", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the gromov-witten theory of x", "start": 42, "end": 71, "i_start": 9, "i_end": 15}, "verb": {"text": "is reduced", "start": 72, "end": 82, "i_start": 16, "i_end": 17}}, {"character": {"text": "integrals", "start": 92, "end": 101, "i_start": 20, "i_end": 20}, "action": {"text": "carries", "start": 5, "end": 12, "i_start": 2, "i_end": 2}}], "id": 3916}, {"sent": "even checking whether a given point is a local minimum turns out to be np-complete .", "tokens": ["even", "checking", "whether", "a", "given", "point", "is", "a", "local", "minimum", "turns", "out", "to", "be", "np", "-", "complete", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a local minimum", "start": 39, "end": 54, "i_start": 7, "i_end": 9}, "verb": {"text": "turns out", "start": 55, "end": 64, "i_start": 10, "i_end": 11}}], "id": 3917}, {"sent": "in the figures , we denote the negative half cycle of the e field vectors using a saturated orange color .", "tokens": ["in", "the", "figures", ",", "we", "denote", "the", "negative", "half", "cycle", "of", "the", "e", "field", "vectors", "using", "a", "saturated", "orange", "color", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 17, "end": 19, "i_start": 4, "i_end": 4}, "verb": {"text": "denote", "start": 20, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 17, "end": 19, "i_start": 4, "i_end": 4}, "action": {"text": "denote", "start": 20, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 17, "end": 19, "i_start": 4, "i_end": 4}, "action": {"text": "using", "start": 74, "end": 79, "i_start": 15, "i_end": 15}}], "id": 3918}, {"sent": "to increase network capacity , the deployment of small cells has been proposed and is currently taking place .", "tokens": ["to", "increase", "network", "capacity", ",", "the", "deployment", "of", "small", "cells", "has", "been", "proposed", "and", "is", "currently", "taking", "place", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the deployment of small cells", "start": 31, "end": 60, "i_start": 5, "i_end": 9}, "verb": {"text": "has been proposed", "start": 61, "end": 78, "i_start": 10, "i_end": 12}}, {"subject": {"text": "the deployment of small cells", "start": 31, "end": 60, "i_start": 5, "i_end": 9}, "verb": {"text": "taking", "start": 96, "end": 102, "i_start": 16, "i_end": 16}}], "id": 3919}, {"sent": "srivastava et al fuse bi-modal image-text and audio-video data using deep boltzman machines .", "tokens": ["srivastava", "et", "al", "fuse", "bi", "-", "modal", "image", "-", "text", "and", "audio", "-", "video", "data", "using", "deep", "boltzman", "machines", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "srivastava et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "fuse", "start": 17, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "srivastava", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "fuse", "start": 17, "end": 21, "i_start": 3, "i_end": 3}}], "id": 3920}, {"sent": "the fc layers following the feature concatenation are initialized with the xavier method .", "tokens": ["the", "fc", "layers", "following", "the", "feature", "concatenation", "are", "initialized", "with", "the", "xavier", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the fc layers following the feature concatenation", "start": 0, "end": 49, "i_start": 0, "i_end": 6}, "verb": {"text": "are initialized", "start": 50, "end": 65, "i_start": 7, "i_end": 8}}], "id": 3921}, {"sent": "the multi-instance problem was first introduced by dietterich in the study of drug activity prediction .", "tokens": ["the", "multi", "-", "instance", "problem", "was", "first", "introduced", "by", "dietterich", "in", "the", "study", "of", "drug", "activity", "prediction", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the multi-instance problem", "start": 0, "end": 26, "i_start": 0, "i_end": 4}, "verb": {"text": "introduced", "start": 37, "end": 47, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the multi-instance problem", "start": 0, "end": 26, "i_start": 0, "i_end": 4}, "verb": {"text": "was", "start": 27, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "dietterich", "start": 51, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "introduced", "start": 37, "end": 47, "i_start": 7, "i_end": 7}}], "id": 3922}, {"sent": "ac magnetic field is applied parallel to the ab plane .", "tokens": ["ac", "magnetic", "field", "is", "applied", "parallel", "to", "the", "ab", "plane", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "ac magnetic field", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is applied", "start": 18, "end": 28, "i_start": 3, "i_end": 4}}], "id": 3923}, {"sent": "the corresponding theory is known as bimetric gravity .", "tokens": ["the", "corresponding", "theory", "is", "known", "as", "bimetric", "gravity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the corresponding theory", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is known", "start": 25, "end": 33, "i_start": 3, "i_end": 4}}], "id": 3924}, {"sent": "for the exchange-correlation interaction between the valence electrons , the perdew-burke-ernzerhof functional within generalized gradient approximation was used .", "tokens": ["for", "the", "exchange", "-", "correlation", "interaction", "between", "the", "valence", "electrons", ",", "the", "perdew", "-", "burke", "-", "ernzerhof", "functional", "within", "generalized", "gradient", "approximation", "was", "used", "."], "score": [1, 1, 1, 1, 0], "labels": [{"subject": {"text": "the perdew-burke-ernzerhof functional within generalized gradient approximation", "start": 73, "end": 152, "i_start": 11, "i_end": 21}, "verb": {"text": "was used", "start": 153, "end": 161, "i_start": 22, "i_end": 23}}, {"character": {"text": "electrons", "start": 61, "end": 70, "i_start": 9, "i_end": 9}, "action": {"text": "interaction", "start": 29, "end": 40, "i_start": 5, "i_end": 5}}], "id": 3925}, {"sent": "the propagator s is the summed propagator including all radiative corrections .", "tokens": ["the", "propagator", "s", "is", "the", "summed", "propagator", "including", "all", "radiative", "corrections", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the propagator s", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 3926}, {"sent": "using this model , the authors of derive an estimator to estimate the pass rate of a path connecting the source to a node .", "tokens": ["using", "this", "model", ",", "the", "authors", "of", "derive", "an", "estimator", "to", "estimate", "the", "pass", "rate", "of", "a", "path", "connecting", "the", "source", "to", "a", "node", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the authors of", "start": 19, "end": 33, "i_start": 4, "i_end": 6}, "verb": {"text": "derive", "start": 34, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "this", "start": 6, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "derive", "start": 34, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "path", "start": 85, "end": 89, "i_start": 17, "i_end": 17}, "action": {"text": "connecting", "start": 90, "end": 100, "i_start": 18, "i_end": 18}}, {"character": {"text": "this", "start": 6, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "using", "start": 0, "end": 5, "i_start": 0, "i_end": 0}}], "id": 3927}, {"sent": "the abscissa and ordinate denote the time in jd and the rc magnitude , respectively .", "tokens": ["the", "abscissa", "and", "ordinate", "denote", "the", "time", "in", "jd", "and", "the", "rc", "magnitude", ",", "respectively", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "abscissa", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "ordinate", "start": 17, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "denote", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}], "id": 3928}, {"sent": "the concept of the matching is used in various fields such as computational biology .", "tokens": ["the", "concept", "of", "the", "matching", "is", "used", "in", "various", "fields", "such", "as", "computational", "biology", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the concept of the matching", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "is used", "start": 28, "end": 35, "i_start": 5, "i_end": 6}}], "id": 3929}, {"sent": "to this end , we extract a 4096-dimensional feature vector from each image using the caffe .", "tokens": ["to", "this", "end", ",", "we", "extract", "a", "4096", "-", "dimensional", "feature", "vector", "from", "each", "image", "using", "the", "caffe", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "verb": {"text": "extract", "start": 17, "end": 24, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "extract", "start": 17, "end": 24, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "using", "start": 75, "end": 80, "i_start": 15, "i_end": 15}}], "id": 3930}, {"sent": "the thick solid line includes in addition the absorption corrections evaluated in the double-scattering approximation .", "tokens": ["the", "thick", "solid", "line", "includes", "in", "addition", "the", "absorption", "corrections", "evaluated", "in", "the", "double", "-", "scattering", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the thick solid line", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "includes", "start": 21, "end": 29, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the absorption corrections", "start": 42, "end": 68, "i_start": 7, "i_end": 9}, "verb": {"text": "evaluated", "start": 69, "end": 78, "i_start": 10, "i_end": 10}}], "id": 3931}, {"sent": "this cancellation is the essence of the jpe .", "tokens": ["this", "cancellation", "is", "the", "essence", "of", "the", "jpe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this cancellation", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}], "id": 3932}, {"sent": "similarly , chen et al , have adopted tdma for scheduling intra-wban transmissions and carrier sensing to deal with inter-wban interference .", "tokens": ["similarly", ",", "chen", "et", "al", ",", "have", "adopted", "tdma", "for", "scheduling", "intra", "-", "wban", "transmissions", "and", "carrier", "sensing", "to", "deal", "with", "inter", "-", "wban", "interference", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "chen et al", "start": 12, "end": 22, "i_start": 2, "i_end": 4}, "verb": {"text": "have adopted", "start": 25, "end": 37, "i_start": 6, "i_end": 7}}, {"character": {"text": "chen", "start": 12, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "adopted", "start": 30, "end": 37, "i_start": 7, "i_end": 7}}, {"character": {"text": "chen", "start": 12, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "deal", "start": 106, "end": 110, "i_start": 19, "i_end": 19}}], "id": 3933}, {"sent": "for this , we use density-based spatial clustering of applications with noise , a clustering algorithm that identifies clusters as areas of high density in the feature space , separated by areas of low density .", "tokens": ["for", "this", ",", "we", "use", "density", "-", "based", "spatial", "clustering", "of", "applications", "with", "noise", ",", "a", "clustering", "algorithm", "that", "identifies", "clusters", "as", "areas", "of", "high", "density", "in", "the", "feature", "space", ",", "separated", "by", "areas", "of", "low", "density", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 11, "end": 13, "i_start": 3, "i_end": 3}, "verb": {"text": "use", "start": 14, "end": 17, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 11, "end": 13, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 14, "end": 17, "i_start": 4, "i_end": 4}}, {"character": {"text": "algorithm", "start": 93, "end": 102, "i_start": 17, "i_end": 17}, "action": {"text": "identifies", "start": 108, "end": 118, "i_start": 19, "i_end": 19}}], "id": 3934}, {"sent": "the first documented uses of comparisons in pairs date back to the thirteenth century .", "tokens": ["the", "first", "documented", "uses", "of", "comparisons", "in", "pairs", "date", "back", "to", "the", "thirteenth", "century", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3935}, {"sent": "in particular , convolutional neural networks have been applied to recognizing images with great success .", "tokens": ["in", "particular", ",", "convolutional", "neural", "networks", "have", "been", "applied", "to", "recognizing", "images", "with", "great", "success", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "have been applied", "start": 46, "end": 63, "i_start": 6, "i_end": 8}}], "id": 3936}, {"sent": "we must therefore identify some tips and tifs .", "tokens": ["we", "must", "therefore", "identify", "some", "tips", "and", "tifs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "identify", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "must", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "identify", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}], "id": 3937}, {"sent": "the segmentation part is initialized by the weights of resnet-18 .", "tokens": ["the", "segmentation", "part", "is", "initialized", "by", "the", "weights", "of", "resnet-18", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the segmentation part", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is initialized", "start": 22, "end": 36, "i_start": 3, "i_end": 4}}, {"character": {"text": "weights", "start": 44, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "initialized", "start": 25, "end": 36, "i_start": 4, "i_end": 4}}], "id": 3938}, {"sent": "the second version of the algorithm is well-suited for time-dependent networks that have arbitrary in-degree and bounded computation time , but also arbitrary memory .", "tokens": ["the", "second", "version", "of", "the", "algorithm", "is", "well", "-", "suited", "for", "time", "-", "dependent", "networks", "that", "have", "arbitrary", "in", "-", "degree", "and", "bounded", "computation", "time", ",", "but", "also", "arbitrary", "memory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the second version of the algorithm", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 36, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 70, "end": 78, "i_start": 14, "i_end": 14}, "action": {"text": "dependent", "start": 60, "end": 69, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 70, "end": 78, "i_start": 14, "i_end": 14}, "action": {"text": "have", "start": 84, "end": 88, "i_start": 16, "i_end": 16}}], "id": 3939}, {"sent": "since 2012 , convolutional neural networks have achieved great success in many computer vision tasks , eg , image classification .", "tokens": ["since", "2012", ",", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "many", "computer", "vision", "tasks", ",", "eg", ",", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 13, "end": 42, "i_start": 3, "i_end": 5}, "verb": {"text": "have achieved", "start": 43, "end": 56, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 34, "end": 42, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 48, "end": 56, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 34, "end": 42, "i_start": 5, "i_end": 5}, "action": {"text": "success", "start": 63, "end": 70, "i_start": 9, "i_end": 9}}], "id": 3940}, {"sent": "a set of pseudorandom sequences is generated by using a shift register guided by a galois field gf that satisfies orthogonal , closure and balance properties .", "tokens": ["a", "set", "of", "pseudorandom", "sequences", "is", "generated", "by", "using", "a", "shift", "register", "guided", "by", "a", "galois", "field", "gf", "that", "satisfies", "orthogonal", ",", "closure", "and", "balance", "properties", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a set of pseudorandom sequences", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "is generated", "start": 32, "end": 44, "i_start": 5, "i_end": 6}}, {"character": {"text": "gf", "start": 96, "end": 98, "i_start": 17, "i_end": 17}, "action": {"text": "guided", "start": 71, "end": 77, "i_start": 12, "i_end": 12}}, {"character": {"text": "gf", "start": 96, "end": 98, "i_start": 17, "i_end": 17}, "action": {"text": "satisfies", "start": 104, "end": 113, "i_start": 19, "i_end": 19}}], "id": 3941}, {"sent": "millimeter wave communication has been shown to be a promising technique for next generation wireless systems due to a large expanse of available spectrum .", "tokens": ["millimeter", "wave", "communication", "has", "been", "shown", "to", "be", "a", "promising", "technique", "for", "next", "generation", "wireless", "systems", "due", "to", "a", "large", "expanse", "of", "available", "spectrum", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "millimeter wave communication", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "has been shown", "start": 30, "end": 44, "i_start": 3, "i_end": 5}}, {"character": {"text": "technique", "start": 63, "end": 72, "i_start": 10, "i_end": 10}, "action": {"text": "promising", "start": 53, "end": 62, "i_start": 9, "i_end": 9}}], "id": 3942}, {"sent": "deep neural networks , especially cnns , have been pervasive in computer vision recently and served as a foundation for many critical applications ranging from image recognition .", "tokens": ["deep", "neural", "networks", ",", "especially", "cnns", ",", "have", "been", "pervasive", "in", "computer", "vision", "recently", "and", "served", "as", "a", "foundation", "for", "many", "critical", "applications", "ranging", "from", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 41, "end": 50, "i_start": 7, "i_end": 8}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "served", "start": 93, "end": 99, "i_start": 15, "i_end": 15}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "pervasive", "start": 51, "end": 60, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "served", "start": 93, "end": 99, "i_start": 15, "i_end": 15}}], "id": 3943}, {"sent": "we subsequently leverage these results to obtain an interesting generalization of the classic oconvergence rate of the conditional gradient algorithm .", "tokens": ["we", "subsequently", "leverage", "these", "results", "to", "obtain", "an", "interesting", "generalization", "of", "the", "classic", "oconvergence", "rate", "of", "the", "conditional", "gradient", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "leverage", "start": 16, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "leverage", "start": 16, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "obtain", "start": 42, "end": 48, "i_start": 6, "i_end": 6}}, {"character": {"text": "generalization", "start": 64, "end": 78, "i_start": 9, "i_end": 9}, "action": {"text": "interesting", "start": 52, "end": 63, "i_start": 8, "i_end": 8}}], "id": 3944}, {"sent": "in this section we review subsurface projections and tight geodesics from .", "tokens": ["in", "this", "section", "we", "review", "subsurface", "projections", "and", "tight", "geodesics", "from", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "review", "start": 19, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "review", "start": 19, "end": 25, "i_start": 4, "i_end": 4}}], "id": 3945}, {"sent": "bonsma et al showed that we can decide in polynomial time if two independent sets are in the same connected component for claw-free graphs .", "tokens": ["bonsma", "et", "al", "showed", "that", "we", "can", "decide", "in", "polynomial", "time", "if", "two", "independent", "sets", "are", "in", "the", "same", "connected", "component", "for", "claw", "-", "free", "graphs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bonsma et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "verb": {"text": "decide", "start": 32, "end": 38, "i_start": 7, "i_end": 7}}, {"character": {"text": "bonsma", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "decide", "start": 32, "end": 38, "i_start": 7, "i_end": 7}}, {"character": {"text": "two independent sets", "start": 61, "end": 81, "i_start": 12, "i_end": 14}, "action": {"text": "independent sets are in the same connected component for claw-", "start": 65, "end": 127, "i_start": 13, "i_end": 23}}], "id": 3946}, {"sent": "the kuramoto model , a paradigm for all-to-all , phasecoupled oscillator models , has been extensively studied and used to shed light on many synchronization phenomena .", "tokens": ["the", "kuramoto", "model", ",", "a", "paradigm", "for", "all", "-", "to", "-", "all", ",", "phasecoupled", "oscillator", "models", ",", "has", "been", "extensively", "studied", "and", "used", "to", "shed", "light", "on", "many", "synchronization", "phenomena", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the kuramoto model", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "studied", "start": 103, "end": 110, "i_start": 20, "i_end": 20}}, {"subject": {"text": "the kuramoto model", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "has been", "start": 82, "end": 90, "i_start": 17, "i_end": 18}}, {"subject": {"text": "the kuramoto model", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 115, "end": 119, "i_start": 22, "i_end": 22}}], "id": 3947}, {"sent": "generative adversarial networks are one of the main groups of methods used to learn generative models from complicated real-world data .", "tokens": ["generative", "adversarial", "networks", "are", "one", "of", "the", "main", "groups", "of", "methods", "used", "to", "learn", "generative", "models", "from", "complicated", "real", "-", "world", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}], "id": 3948}, {"sent": "deep convolutional neural networks have made significant breakthroughs in many visual understanding tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "significant", "breakthroughs", "in", "many", "visual", "understanding", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "breakthroughs", "start": 57, "end": 70, "i_start": 7, "i_end": 7}}], "id": 3949}, {"sent": "binary and ternary matrices are used in different fields of communications and coding theory .", "tokens": ["binary", "and", "ternary", "matrices", "are", "used", "in", "different", "fields", "of", "communications", "and", "coding", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "binary and ternary matrices", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "are used", "start": 28, "end": 36, "i_start": 4, "i_end": 5}}], "id": 3950}, {"sent": "in quantum mechanics p is the derivative and m the coordinate operator .", "tokens": ["in", "quantum", "mechanics", "p", "is", "the", "derivative", "and", "m", "the", "coordinate", "operator", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3951}, {"sent": "convolutional neural network has achieved great success in image recognition and object detection .", "tokens": ["convolutional", "neural", "network", "has", "achieved", "great", "success", "in", "image", "recognition", "and", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural network", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "has achieved", "start": 29, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "network", "start": 21, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 33, "end": 41, "i_start": 4, "i_end": 4}}, {"character": {"text": "network", "start": 21, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 48, "end": 55, "i_start": 6, "i_end": 6}}, {"character": {"text": "network", "start": 21, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "recognition", "start": 65, "end": 76, "i_start": 9, "i_end": 9}}, {"character": {"text": "network", "start": 21, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "detection", "start": 88, "end": 97, "i_start": 12, "i_end": 12}}], "id": 3952}, {"sent": "recently , deterministic deep neural networks have demonstrated state-of-the-art performance on many supervised tasks , eg , speech recognition .", "tokens": ["recently", ",", "deterministic", "deep", "neural", "networks", "have", "demonstrated", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "many", "supervised", "tasks", ",", "eg", ",", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deterministic deep neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have demonstrated", "start": 46, "end": 63, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "demonstrated", "start": 51, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 81, "end": 92, "i_start": 15, "i_end": 15}}], "id": 3953}, {"sent": "the belle detector is a large-solid-angle magnetic spectrometer that consists of a silicon vertex detector , an array of aerogel threshold cherenkov counters , a barrel-like arrangement of time-of-flight scintillation counters crystals located inside a superconducting solenoid coil that provides a 1 5 t magnetic field .", "tokens": ["the", "belle", "detector", "is", "a", "large", "-", "solid", "-", "angle", "magnetic", "spectrometer", "that", "consists", "of", "a", "silicon", "vertex", "detector", ",", "an", "array", "of", "aerogel", "threshold", "cherenkov", "counters", ",", "a", "barrel", "-", "like", "arrangement", "of", "time", "-", "of", "-", "flight", "scintillation", "counters", "crystals", "located", "inside", "a", "superconducting", "solenoid", "coil", "that", "provides", "a", "1", "5", "t", "magnetic", "field", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the belle detector", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "coil", "start": 278, "end": 282, "i_start": 47, "i_end": 47}, "action": {"text": "provides", "start": 288, "end": 296, "i_start": 49, "i_end": 49}}], "id": 3954}, {"sent": "the four panels correspond to the configurations , respectively .", "tokens": ["the", "four", "panels", "correspond", "to", "the", "configurations", ",", "respectively", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the four panels", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "correspond", "start": 16, "end": 26, "i_start": 3, "i_end": 3}}], "id": 3955}, {"sent": "we train this network starting from pre-trained imagenet datasets jointly .", "tokens": ["we", "train", "this", "network", "starting", "from", "pre", "-", "trained", "imagenet", "datasets", "jointly", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3956}, {"sent": "significant progress has been made in reinforcement learning to solve a large number of tasks , such as atari games , board games and robotic control .", "tokens": ["significant", "progress", "has", "been", "made", "in", "reinforcement", "learning", "to", "solve", "a", "large", "number", "of", "tasks", ",", "such", "as", "atari", "games", ",", "board", "games", "and", "robotic", "control", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "significant progress", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "has been made", "start": 21, "end": 34, "i_start": 2, "i_end": 4}}, {"character": {"text": "learning", "start": 52, "end": 60, "i_start": 7, "i_end": 7}, "action": {"text": "solve", "start": 64, "end": 69, "i_start": 9, "i_end": 9}}], "id": 3957}, {"sent": "polar codes were introduced by arikan and provide an error correction scheme for achieving the symmetric capacity of binary memoryless channels with polynomial encoding and decoding complexity .", "tokens": ["polar", "codes", "were", "introduced", "by", "arikan", "and", "provide", "an", "error", "correction", "scheme", "for", "achieving", "the", "symmetric", "capacity", "of", "binary", "memoryless", "channels", "with", "polynomial", "encoding", "and", "decoding", "complexity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "polar codes", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "were introduced", "start": 12, "end": 27, "i_start": 2, "i_end": 3}}, {"subject": {"text": "polar codes", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "provide", "start": 42, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "arikan", "start": 31, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 17, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "codes", "start": 6, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "provide", "start": 42, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "scheme", "start": 70, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "correction", "start": 59, "end": 69, "i_start": 10, "i_end": 10}}], "id": 3958}, {"sent": "for the background on the vertex tensor categories , we refer the reader to .", "tokens": ["for", "the", "background", "on", "the", "vertex", "tensor", "categories", ",", "we", "refer", "the", "reader", "to", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 53, "end": 55, "i_start": 9, "i_end": 9}, "verb": {"text": "refer", "start": 56, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 53, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "refer", "start": 56, "end": 61, "i_start": 10, "i_end": 10}}], "id": 3959}, {"sent": "data sets not consistent on this level are indicated by open circles .", "tokens": ["data", "sets", "not", "consistent", "on", "this", "level", "are", "indicated", "by", "open", "circles", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "data sets not consistent on this level", "start": 0, "end": 38, "i_start": 0, "i_end": 6}, "verb": {"text": "are indicated", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "circles", "start": 61, "end": 68, "i_start": 11, "i_end": 11}, "action": {"text": "indicated", "start": 43, "end": 52, "i_start": 8, "i_end": 8}}], "id": 3960}, {"sent": "the considered setup allows to reveal genuine tripartite nonlocality via a violation of the svetlichny inequality on local realism .", "tokens": ["the", "considered", "setup", "allows", "to", "reveal", "genuine", "tripartite", "nonlocality", "via", "a", "violation", "of", "the", "svetlichny", "inequality", "on", "local", "realism", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the considered setup", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "allows", "start": 21, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "setup", "start": 15, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "allows", "start": 21, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "setup", "start": 15, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "reveal", "start": 31, "end": 37, "i_start": 5, "i_end": 5}}], "id": 3961}, {"sent": "in recent years , a variety of new theoretical and phenomenological approaches of the glass transition stimulated new experimental investigations especially of the high-frequency dynamics of glass-forming liquids .", "tokens": ["in", "recent", "years", ",", "a", "variety", "of", "new", "theoretical", "and", "phenomenological", "approaches", "of", "the", "glass", "transition", "stimulated", "new", "experimental", "investigations", "especially", "of", "the", "high", "-", "frequency", "dynamics", "of", "glass", "-", "forming", "liquids", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "a variety of new theoretical and phenomenological approaches of the glass transition", "start": 18, "end": 102, "i_start": 4, "i_end": 15}, "verb": {"text": "stimulated", "start": 103, "end": 113, "i_start": 16, "i_end": 16}}, {"character": {"text": "approaches", "start": 68, "end": 78, "i_start": 11, "i_end": 11}, "action": {"text": "stimulated", "start": 103, "end": 113, "i_start": 16, "i_end": 16}}, {"character": {"text": "liquids", "start": 205, "end": 212, "i_start": 31, "i_end": 31}, "action": {"text": "forming", "start": 197, "end": 204, "i_start": 30, "i_end": 30}}], "id": 3962}, {"sent": "ebert , vv khudyakov , vc zhukovsky and kg klimenko , jetp lett .", "tokens": ["ebert", ",", "vv", "khudyakov", ",", "vc", "zhukovsky", "and", "kg", "klimenko", ",", "jetp", "lett", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3963}, {"sent": "thirdly , the square root of the ratio of the local length scale to the acceleration at this scale .", "tokens": ["thirdly", ",", "the", "square", "root", "of", "the", "ratio", "of", "the", "local", "length", "scale", "to", "the", "acceleration", "at", "this", "scale", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3964}, {"sent": "coded caching is a technique -first introduced in for the single-stream bottleneck broadcast channel -that exploits receiver-side caches in order to deliver cacheable content to many users at a time .", "tokens": ["coded", "caching", "is", "a", "technique", "-first", "introduced", "in", "for", "the", "single", "-", "stream", "bottleneck", "broadcast", "channel", "-that", "exploits", "receiver", "-", "side", "caches", "in", "order", "to", "deliver", "cacheable", "content", "to", "many", "users", "at", "a", "time", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "coded caching", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "technique", "start": 19, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "exploits", "start": 107, "end": 115, "i_start": 17, "i_end": 17}}, {"character": {"text": "technique", "start": 19, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "deliver", "start": 149, "end": 156, "i_start": 25, "i_end": 25}}], "id": 3965}, {"sent": "however , bertschinger et al provided a counterexample illustrating that in the multivariate case the identity axiom is incompatible with ensuring the nonnegativity of the pid terms .", "tokens": ["however", ",", "bertschinger", "et", "al", "provided", "a", "counterexample", "illustrating", "that", "in", "the", "multivariate", "case", "the", "identity", "axiom", "is", "incompatible", "with", "ensuring", "the", "nonnegativity", "of", "the", "pid", "terms", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bertschinger et al", "start": 10, "end": 28, "i_start": 2, "i_end": 4}, "verb": {"text": "provided", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "bertschinger", "start": 10, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "provided", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "counterexample", "start": 40, "end": 54, "i_start": 7, "i_end": 7}, "action": {"text": "illustrating", "start": 55, "end": 67, "i_start": 8, "i_end": 8}}], "id": 3966}, {"sent": "convolutional neural networks have witnessed great improvement on a series of vision tasks such as object classification .", "tokens": ["convolutional", "neural", "networks", "have", "witnessed", "great", "improvement", "on", "a", "series", "of", "vision", "tasks", "such", "as", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have witnessed", "start": 30, "end": 44, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "witnessed", "start": 35, "end": 44, "i_start": 4, "i_end": 4}}], "id": 3967}, {"sent": "results on reduced daquar in order to provide performance numbers that are comparable to the proposed multiworld approach in , we also run our method on the reduced set with 37 object classes and only 25 images with 297 question-answer pairs at test time .", "tokens": ["results", "on", "reduced", "daquar", "in", "order", "to", "provide", "performance", "numbers", "that", "are", "comparable", "to", "the", "proposed", "multiworld", "approach", "in", ",", "we", "also", "run", "our", "method", "on", "the", "reduced", "set", "with", "37", "object", "classes", "and", "only", "25", "images", "with", "297", "question", "-", "answer", "pairs", "at", "test", "time", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 127, "end": 129, "i_start": 20, "i_end": 20}, "verb": {"text": "run", "start": 135, "end": 138, "i_start": 22, "i_end": 22}}, {"character": {"text": "we", "start": 127, "end": 129, "i_start": 20, "i_end": 20}, "action": {"text": "run", "start": 135, "end": 138, "i_start": 22, "i_end": 22}}], "id": 3968}, {"sent": "deep neural networks are extremely powerful machine learning models that achieve excellent performance on difficult problems such as speech recognition .", "tokens": ["deep", "neural", "networks", "are", "extremely", "powerful", "machine", "learning", "models", "that", "achieve", "excellent", "performance", "on", "difficult", "problems", "such", "as", "speech", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 61, "end": 67, "i_start": 8, "i_end": 8}, "action": {"text": "achieve", "start": 73, "end": 80, "i_start": 10, "i_end": 10}}], "id": 3969}, {"sent": "these iteration identities yield new parseval-goldstein identities and goldstein ex hange identities for these and many other integral transforms .", "tokens": ["these", "iteration", "identities", "yield", "new", "parseval", "-", "goldstein", "identities", "and", "goldstein", "ex", "hange", "identities", "for", "these", "and", "many", "other", "integral", "transforms", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "these iteration identities", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "yield", "start": 27, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "identities", "start": 16, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "yield", "start": 27, "end": 32, "i_start": 3, "i_end": 3}}], "id": 3970}, {"sent": "in both calculations , there is a clear linear correlation between the time an object spends accreting and its final mass .", "tokens": ["in", "both", "calculations", ",", "there", "is", "a", "clear", "linear", "correlation", "between", "the", "time", "an", "object", "spends", "accreting", "and", "its", "final", "mass", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 23, "end": 28, "i_start": 4, "i_end": 4}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "object", "start": 79, "end": 85, "i_start": 14, "i_end": 14}, "action": {"text": "spends", "start": 86, "end": 92, "i_start": 15, "i_end": 15}}, {"character": {"text": "object", "start": 79, "end": 85, "i_start": 14, "i_end": 14}, "action": {"text": "accreting", "start": 93, "end": 102, "i_start": 16, "i_end": 16}}], "id": 3971}, {"sent": "evolution of the azimuthally averaged surface density of the viscous ring at three different times , additionally using artificial bulk viscosity and xsph together with the physical viscosity .", "tokens": ["evolution", "of", "the", "azimuthally", "averaged", "surface", "density", "of", "the", "viscous", "ring", "at", "three", "different", "times", ",", "additionally", "using", "artificial", "bulk", "viscosity", "and", "xsph", "together", "with", "the", "physical", "viscosity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "evolution", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 114, "end": 119, "i_start": 17, "i_end": 17}}], "id": 3972}, {"sent": "the block keys , bk , is an b-element array which encodes the keys of tj in level order .", "tokens": ["the", "block", "keys", ",", "bk", ",", "is", "an", "b", "-", "element", "array", "which", "encodes", "the", "keys", "of", "tj", "in", "level", "order", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the block keys , bk", "start": 0, "end": 19, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 6, "i_end": 6}}, {"character": {"text": "array", "start": 38, "end": 43, "i_start": 11, "i_end": 11}, "action": {"text": "encodes", "start": 50, "end": 57, "i_start": 13, "i_end": 13}}], "id": 3973}, {"sent": "deep neural networks are being successful in accomplishing challenging tasks such as image classification .", "tokens": ["deep", "neural", "networks", "are", "being", "successful", "in", "accomplishing", "challenging", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are being", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 31, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "accomplishing", "start": 45, "end": 58, "i_start": 7, "i_end": 7}}], "id": 3974}, {"sent": "this requires us to use the expectation-maximisation algorithm of .", "tokens": ["this", "requires", "us", "to", "use", "the", "expectation", "-", "maximisation", "algorithm", "of", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "requires", "start": 5, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "requires", "start": 5, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "us", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 20, "end": 23, "i_start": 4, "i_end": 4}}], "id": 3975}, {"sent": "the generalized gradient approximation parameterized by perdew-burke-ernzerhof is utilized to describe exchange-correlation functional .", "tokens": ["the", "generalized", "gradient", "approximation", "parameterized", "by", "perdew", "-", "burke", "-", "ernzerhof", "is", "utilized", "to", "describe", "exchange", "-", "correlation", "functional", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation parameterized by perdew-burke-ernzerhof", "start": 0, "end": 78, "i_start": 0, "i_end": 10}, "verb": {"text": "is utilized", "start": 79, "end": 90, "i_start": 11, "i_end": 12}}, {"character": {"text": "perdew", "start": 56, "end": 62, "i_start": 6, "i_end": 6}, "action": {"text": "parameterized", "start": 39, "end": 52, "i_start": 4, "i_end": 4}}, {"character": {"text": "approximation", "start": 25, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "describe", "start": 94, "end": 102, "i_start": 14, "i_end": 14}}, {"character": {"text": "exchange", "start": 103, "end": 111, "i_start": 15, "i_end": 15}, "action": {"text": "functional", "start": 124, "end": 134, "i_start": 18, "i_end": 18}}], "id": 3976}, {"sent": "an asterisk denotes the presence of a given harmonic .", "tokens": ["an", "asterisk", "denotes", "the", "presence", "of", "a", "given", "harmonic", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "an asterisk", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "denotes", "start": 12, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "asterisk", "start": 3, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "denotes", "start": 12, "end": 19, "i_start": 2, "i_end": 2}}], "id": 3977}, {"sent": "of the thirteen entries in table 4 of for genus 7 curves , three are hyperelliptic and two are cyclic trigonal .", "tokens": ["of", "the", "thirteen", "entries", "in", "table", "4", "of", "for", "genus", "7", "curves", ",", "three", "are", "hyperelliptic", "and", "two", "are", "cyclic", "trigonal", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "three", "start": 59, "end": 64, "i_start": 13, "i_end": 13}, "verb": {"text": "are", "start": 65, "end": 68, "i_start": 14, "i_end": 14}}], "id": 3978}, {"sent": "a self-transversal curve is coherent if and only if its semichart is coherent .", "tokens": ["a", "self", "-", "transversal", "curve", "is", "coherent", "if", "and", "only", "if", "its", "semichart", "is", "coherent", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a self-transversal curve", "start": 0, "end": 24, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "curve", "start": 19, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "transversal", "start": 7, "end": 18, "i_start": 3, "i_end": 3}}], "id": 3979}, {"sent": "the uncorrelated-lepton control samples in data are used to determine starting values for the final full fit to all data samples .", "tokens": ["the", "uncorrelated", "-", "lepton", "control", "samples", "in", "data", "are", "used", "to", "determine", "starting", "values", "for", "the", "final", "full", "fit", "to", "all", "data", "samples", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the uncorrelated-lepton control samples in data", "start": 0, "end": 47, "i_start": 0, "i_end": 7}, "verb": {"text": "are used", "start": 48, "end": 56, "i_start": 8, "i_end": 9}}], "id": 3980}, {"sent": "the splitting theorem for riemannian manifolds admitting affine functions has been discussed in .", "tokens": ["the", "splitting", "theorem", "for", "riemannian", "manifolds", "admitting", "affine", "functions", "has", "been", "discussed", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "theorem", "start": 14, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "admitting", "start": 47, "end": 56, "i_start": 6, "i_end": 6}}], "id": 3981}, {"sent": "bose-einstein condensates made of ultracold trapped bosonic atoms have become a vast ground to study interacting quantum systems .", "tokens": ["bose", "-", "einstein", "condensates", "made", "of", "ultracold", "trapped", "bosonic", "atoms", "have", "become", "a", "vast", "ground", "to", "study", "interacting", "quantum", "systems", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "bose-einstein condensates made of ultracold trapped bosonic atoms", "start": 0, "end": 65, "i_start": 0, "i_end": 9}, "verb": {"text": "have become", "start": 66, "end": 77, "i_start": 10, "i_end": 11}}], "id": 3982}, {"sent": "all commutators are taken with the moyal star .", "tokens": ["all", "commutators", "are", "taken", "with", "the", "moyal", "star", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all commutators", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "are taken", "start": 16, "end": 25, "i_start": 2, "i_end": 3}}], "id": 3983}, {"sent": "this policy is a reflection of a global trend to globalization of science .", "tokens": ["this", "policy", "is", "a", "reflection", "of", "a", "global", "trend", "to", "globalization", "of", "science", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this policy", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 3984}, {"sent": "quantum chromodynamics is a prospective fundamental theory for strong 6 interactions .", "tokens": ["quantum", "chromodynamics", "is", "a", "prospective", "fundamental", "theory", "for", "strong", "6", "interactions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum chromodynamics", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 2, "i_end": 2}}], "id": 3985}, {"sent": "the pulsar is the faint source near the center of the cluster , which is indicated with a cross .", "tokens": ["the", "pulsar", "is", "the", "faint", "source", "near", "the", "center", "of", "the", "cluster", ",", "which", "is", "indicated", "with", "a", "cross", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the pulsar", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}], "id": 3986}, {"sent": "let us work out the dualizable space in each case .", "tokens": ["let", "us", "work", "out", "the", "dualizable", "space", "in", "each", "case", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "work", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "work", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}], "id": 3987}, {"sent": "observations were calibrated and imaged in a standard fashion using the common astronomy software applications .", "tokens": ["observations", "were", "calibrated", "and", "imaged", "in", "a", "standard", "fashion", "using", "the", "common", "astronomy", "software", "applications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "observations", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "were calibrated", "start": 13, "end": 28, "i_start": 1, "i_end": 2}}, {"subject": {"text": "observations", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "imaged", "start": 33, "end": 39, "i_start": 4, "i_end": 4}}], "id": 3988}, {"sent": "the interested readers can see , chartrand et al generalized the concept of rainbow path to rainbow tree .", "tokens": ["the", "interested", "readers", "can", "see", ",", "chartrand", "et", "al", "generalized", "the", "concept", "of", "rainbow", "path", "to", "rainbow", "tree", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "chartrand et al", "start": 33, "end": 48, "i_start": 6, "i_end": 8}, "verb": {"text": "generalized", "start": 49, "end": 60, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the interested readers", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "see", "start": 27, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "chartrand", "start": 33, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "generalized", "start": 49, "end": 60, "i_start": 9, "i_end": 9}}], "id": 3989}, {"sent": "the cell cycle is the a concatenation of biochemical and morphological events that lead to the reproduction of a cell .", "tokens": ["the", "cell", "cycle", "is", "the", "a", "concatenation", "of", "biochemical", "and", "morphological", "events", "that", "lead", "to", "the", "reproduction", "of", "a", "cell", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the cell cycle", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "events", "start": 71, "end": 77, "i_start": 11, "i_end": 11}, "action": {"text": "lead", "start": 83, "end": 87, "i_start": 13, "i_end": 13}}], "id": 3990}, {"sent": "an eigenvalue is a number \u03bb for which is equal to 1 .", "tokens": ["an", "eigenvalue", "is", "a", "number", "\u03bb", "for", "which", "is", "equal", "to", "1", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an eigenvalue", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 3991}, {"sent": "in section 2 we introduce the model we study and give a review of main results obtained in .", "tokens": ["in", "section", "2", "we", "introduce", "the", "model", "we", "study", "and", "give", "a", "review", "of", "main", "results", "obtained", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "introduce", "start": 16, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "introduce", "start": 16, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "study", "start": 39, "end": 44, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "review", "start": 56, "end": 62, "i_start": 12, "i_end": 12}}], "id": 3992}, {"sent": "loop quantum cosmology is the quantization of symmetry reduced models of classical general relativity using the methods of loop quantum gravity .", "tokens": ["loop", "quantum", "cosmology", "is", "the", "quantization", "of", "symmetry", "reduced", "models", "of", "classical", "general", "relativity", "using", "the", "methods", "of", "loop", "quantum", "gravity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "loop quantum cosmology", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "quantization", "start": 30, "end": 42, "i_start": 5, "i_end": 5}, "action": {"text": "reduced", "start": 55, "end": 62, "i_start": 8, "i_end": 8}}], "id": 3993}, {"sent": "mechanical properties of soft biological tissues .", "tokens": ["mechanical", "properties", "of", "soft", "biological", "tissues", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3994}, {"sent": "in this paper , we use the gated recurrent unit for learning the language modeling on the client side .", "tokens": ["in", "this", "paper", ",", "we", "use", "the", "gated", "recurrent", "unit", "for", "learning", "the", "language", "modeling", "on", "the", "client", "side", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 19, "end": 22, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 19, "end": 22, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "learning", "start": 52, "end": 60, "i_start": 11, "i_end": 11}}], "id": 3995}, {"sent": "convolutional neural networks have achieved superior performance in many visual tasks , such as object classification and detection .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "classification", "and", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 6, "i_end": 6}}], "id": 3996}, {"sent": "deep neural networks have gained popularity in recent years thanks to their achievements in many applications including computer vision , signal and image processing , speech recognition .", "tokens": ["deep", "neural", "networks", "have", "gained", "popularity", "in", "recent", "years", "thanks", "to", "their", "achievements", "in", "many", "applications", "including", "computer", "vision", ",", "signal", "and", "image", "processing", ",", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have gained", "start": 21, "end": 32, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "gained", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achievements", "start": 76, "end": 88, "i_start": 12, "i_end": 12}}], "id": 3997}, {"sent": "thus , detecting the phase of the cantilever vibrations one can measure the spin component along the effective magnetic field .", "tokens": ["thus", ",", "detecting", "the", "phase", "of", "the", "cantilever", "vibrations", "one", "can", "measure", "the", "spin", "component", "along", "the", "effective", "magnetic", "field", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 56, "end": 59, "i_start": 9, "i_end": 9}, "verb": {"text": "can measure", "start": 60, "end": 71, "i_start": 10, "i_end": 11}}, {"character": {"text": "one", "start": 56, "end": 59, "i_start": 9, "i_end": 9}, "action": {"text": "measure", "start": 64, "end": 71, "i_start": 11, "i_end": 11}}, {"character": {"text": "field", "start": 120, "end": 125, "i_start": 19, "i_end": 19}, "action": {"text": "effective", "start": 101, "end": 110, "i_start": 17, "i_end": 17}}, {"character": {"text": "one", "start": 56, "end": 59, "i_start": 9, "i_end": 9}, "action": {"text": "detecting", "start": 7, "end": 16, "i_start": 2, "i_end": 2}}], "id": 3998}, {"sent": "the exchange-correlation functional was treated using the generalized gradient approximation parametrized by perdew , burke , and ernzerhof .", "tokens": ["the", "exchange", "-", "correlation", "functional", "was", "treated", "using", "the", "generalized", "gradient", "approximation", "parametrized", "by", "perdew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange-correlation functional", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "was treated", "start": 36, "end": 47, "i_start": 5, "i_end": 6}}, {"character": {"text": "perdew", "start": 109, "end": 115, "i_start": 14, "i_end": 14}, "action": {"text": "parametrized", "start": 93, "end": 105, "i_start": 12, "i_end": 12}}, {"character": {"text": "burke", "start": 118, "end": 123, "i_start": 16, "i_end": 16}, "action": {"text": "parametrized", "start": 93, "end": 105, "i_start": 12, "i_end": 12}}, {"character": {"text": "ernzerhof", "start": 130, "end": 139, "i_start": 19, "i_end": 19}, "action": {"text": "parametrized", "start": 93, "end": 105, "i_start": 12, "i_end": 12}}], "id": 3999}, {"sent": "the seiberg -witten map technique allows us to treat the theory as a perturbative lagrangian theory .", "tokens": ["the", "seiberg", "-witten", "map", "technique", "allows", "us", "to", "treat", "the", "theory", "as", "a", "perturbative", "lagrangian", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the seiberg -witten map technique", "start": 0, "end": 33, "i_start": 0, "i_end": 4}, "verb": {"text": "allows", "start": 34, "end": 40, "i_start": 5, "i_end": 5}}, {"subject": {"text": "us", "start": 41, "end": 43, "i_start": 6, "i_end": 6}, "verb": {"text": "treat", "start": 47, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "technique", "start": 24, "end": 33, "i_start": 4, "i_end": 4}, "action": {"text": "allows", "start": 34, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "us", "start": 41, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "treat", "start": 47, "end": 52, "i_start": 8, "i_end": 8}}], "id": 4000}, {"sent": "such within-view structure preservation constraints have been extensively explored in the metric learning literature .", "tokens": ["such", "within", "-", "view", "structure", "preservation", "constraints", "have", "been", "extensively", "explored", "in", "the", "metric", "learning", "literature", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such within-view structure preservation constraints", "start": 0, "end": 51, "i_start": 0, "i_end": 6}, "verb": {"text": "explored", "start": 74, "end": 82, "i_start": 10, "i_end": 10}}, {"subject": {"text": "such within-view structure preservation constraints", "start": 0, "end": 51, "i_start": 0, "i_end": 6}, "verb": {"text": "have been", "start": 52, "end": 61, "i_start": 7, "i_end": 8}}], "id": 4001}, {"sent": "quantum mechanics is a tighter package than one might have first thought .", "tokens": ["quantum", "mechanics", "is", "a", "tighter", "package", "than", "one", "might", "have", "first", "thought", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum mechanics", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}], "id": 4002}, {"sent": "neutrosophy is a new branch of philosophy that studies the origin , nature , and scope of neutralities , as well as their interactions with different ideational spectra .", "tokens": ["neutrosophy", "is", "a", "new", "branch", "of", "philosophy", "that", "studies", "the", "origin", ",", "nature", ",", "and", "scope", "of", "neutralities", ",", "as", "well", "as", "their", "interactions", "with", "different", "ideational", "spectra", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neutrosophy", "start": 0, "end": 11, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "branch", "start": 21, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "studies", "start": 47, "end": 54, "i_start": 8, "i_end": 8}}, {"character": {"text": "neutralities", "start": 90, "end": 102, "i_start": 17, "i_end": 17}, "action": {"text": "interactions", "start": 122, "end": 134, "i_start": 23, "i_end": 23}}], "id": 4003}, {"sent": "a duality is a concept that means that one object carries a double meaning or that two objects with different meanings are identically connected .", "tokens": ["a", "duality", "is", "a", "concept", "that", "means", "that", "one", "object", "carries", "a", "double", "meaning", "or", "that", "two", "objects", "with", "different", "meanings", "are", "identically", "connected", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a duality", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "one object", "start": 39, "end": 49, "i_start": 8, "i_end": 9}, "action": {"text": "carries", "start": 50, "end": 57, "i_start": 10, "i_end": 10}}], "id": 4004}, {"sent": "in this paper we study statistical mechanics of imitative diluted systems , paying particular attention to its applications in social sciences .", "tokens": ["in", "this", "paper", "we", "study", "statistical", "mechanics", "of", "imitative", "diluted", "systems", ",", "paying", "particular", "attention", "to", "its", "applications", "in", "social", "sciences", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "study", "start": 17, "end": 22, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "study", "start": 17, "end": 22, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "attention", "start": 94, "end": 103, "i_start": 14, "i_end": 14}}], "id": 4005}, {"sent": "in this paper , we use a multiscale combinatorial grouping algorithm to generate segmented object proposals from our contour detection .", "tokens": ["in", "this", "paper", ",", "we", "use", "a", "multiscale", "combinatorial", "grouping", "algorithm", "to", "generate", "segmented", "object", "proposals", "from", "our", "contour", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 19, "end": 22, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 19, "end": 22, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "generate", "start": 72, "end": 80, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "detection", "start": 125, "end": 134, "i_start": 19, "i_end": 19}}], "id": 4006}, {"sent": "conductance quantisation in metallic point contacts .", "tokens": ["conductance", "quantisation", "in", "metallic", "point", "contacts", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4007}, {"sent": "the calculations are done for the neutron-rich oxygen isotopes .", "tokens": ["the", "calculations", "are", "done", "for", "the", "neutron", "-", "rich", "oxygen", "isotopes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the calculations", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "are done", "start": 17, "end": 25, "i_start": 2, "i_end": 3}}], "id": 4008}, {"sent": "a bijective cellular map is called an isomorphism , and a self-isomorphism of a graph is called an automorphism .", "tokens": ["a", "bijective", "cellular", "map", "is", "called", "an", "isomorphism", ",", "and", "a", "self", "-", "isomorphism", "of", "a", "graph", "is", "called", "an", "automorphism", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a bijective cellular map", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "is called", "start": 25, "end": 34, "i_start": 4, "i_end": 5}}, {"subject": {"text": "a self-isomorphism of a graph", "start": 56, "end": 85, "i_start": 10, "i_end": 16}, "verb": {"text": "called", "start": 89, "end": 95, "i_start": 18, "i_end": 18}}], "id": 4009}, {"sent": "convolutional neural networks show state-of-the-art performance on many problems in computer vision , natural language processing and other fields .", "tokens": ["convolutional", "neural", "networks", "show", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "many", "problems", "in", "computer", "vision", ",", "natural", "language", "processing", "and", "other", "fields", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "show", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 52, "end": 63, "i_start": 11, "i_end": 11}}], "id": 4010}, {"sent": "deep neural networks have recently achieved huge success in various machine learning tasks .", "tokens": ["deep", "neural", "networks", "have", "recently", "achieved", "huge", "success", "in", "various", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 49, "end": 56, "i_start": 7, "i_end": 7}}], "id": 4011}, {"sent": "belle is a general-purpose detector based on a 1 5 t superconducting solenoid magnet that surrounds the kekb beam crossing point .", "tokens": ["belle", "is", "a", "general", "-", "purpose", "detector", "based", "on", "a", "1", "5", "t", "superconducting", "solenoid", "magnet", "that", "surrounds", "the", "kekb", "beam", "crossing", "point", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "belle", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "magnet", "start": 78, "end": 84, "i_start": 15, "i_end": 15}, "action": {"text": "surrounds", "start": 90, "end": 99, "i_start": 17, "i_end": 17}}, {"character": {"text": "beam", "start": 109, "end": 113, "i_start": 20, "i_end": 20}, "action": {"text": "crossing", "start": 114, "end": 122, "i_start": 21, "i_end": 21}}], "id": 4012}, {"sent": "all parameters in this case are presented in table xvi .", "tokens": ["all", "parameters", "in", "this", "case", "are", "presented", "in", "table", "xvi", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all parameters in this case", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "are presented", "start": 28, "end": 41, "i_start": 5, "i_end": 6}}], "id": 4013}, {"sent": "the dft calculations are done based on the projected augmented wave pseudo-potentials as implemented in vienna ab initio simulation package .", "tokens": ["the", "dft", "calculations", "are", "done", "based", "on", "the", "projected", "augmented", "wave", "pseudo", "-", "potentials", "as", "implemented", "in", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dft calculations", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are done", "start": 21, "end": 29, "i_start": 3, "i_end": 4}}], "id": 4014}, {"sent": "plots of amplitude versus redshift and luminosity for uvx selected quasars .", "tokens": ["plots", "of", "amplitude", "versus", "redshift", "and", "luminosity", "for", "uvx", "selected", "quasars", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4015}, {"sent": "we evaluate our approach on semantic instance completion performance on synthetic scans of suncg scans .", "tokens": ["we", "evaluate", "our", "approach", "on", "semantic", "instance", "completion", "performance", "on", "synthetic", "scans", "of", "suncg", "scans", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "approach", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}], "id": 4016}, {"sent": "what emerges is a relation between the in and out fields which is most simply stated in terms of their annihilation operators .", "tokens": ["what", "emerges", "is", "a", "relation", "between", "the", "in", "and", "out", "fields", "which", "is", "most", "simply", "stated", "in", "terms", "of", "their", "annihilation", "operators", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "what emerges", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "relation", "start": 18, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "emerges", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}], "id": 4017}, {"sent": "isola et al proposed the pix2pix framework , which uses a conditional gan to learn a mapping from source to target images .", "tokens": ["isola", "et", "al", "proposed", "the", "pix2pix", "framework", ",", "which", "uses", "a", "conditional", "gan", "to", "learn", "a", "mapping", "from", "source", "to", "target", "images", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 6, "end": 11, "i_start": 1, "i_end": 2}, "verb": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "isola", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "framework", "start": 33, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "uses", "start": 51, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "isola", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "learn", "start": 77, "end": 82, "i_start": 14, "i_end": 14}}], "id": 4018}, {"sent": "deep convolutional neural networks have shown remarkable success for various computer vision tasks in static images , such as object detection .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "shown", "remarkable", "success", "for", "various", "computer", "vision", "tasks", "in", "static", "images", ",", "such", "as", "object", "detection", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have shown", "start": 35, "end": 45, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 57, "end": 64, "i_start": 7, "i_end": 7}}], "id": 4019}, {"sent": "we will illustrate these by suitable examples .", "tokens": ["we", "will", "illustrate", "these", "by", "suitable", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will illustrate", "start": 3, "end": 18, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "illustrate", "start": 8, "end": 18, "i_start": 2, "i_end": 2}}], "id": 4020}, {"sent": "despite their outstanding performance on several machine learning tasks , deep neural networks have been shown to be susceptible to adversarial attacks .", "tokens": ["despite", "their", "outstanding", "performance", "on", "several", "machine", "learning", "tasks", ",", "deep", "neural", "networks", "have", "been", "shown", "to", "be", "susceptible", "to", "adversarial", "attacks", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 74, "end": 94, "i_start": 10, "i_end": 12}, "verb": {"text": "have been shown", "start": 95, "end": 110, "i_start": 13, "i_end": 15}}, {"character": {"text": "adversarial", "start": 132, "end": 143, "i_start": 20, "i_end": 20}, "action": {"text": "attacks", "start": 144, "end": 151, "i_start": 21, "i_end": 21}}, {"character": {"text": "networks", "start": 86, "end": 94, "i_start": 12, "i_end": 12}, "action": {"text": "performance", "start": 26, "end": 37, "i_start": 3, "i_end": 3}}], "id": 4021}, {"sent": "laboratory astrophysics comprises both theoretical and experimental studies of the underlying physics which produce the observed astrophysical processes .", "tokens": ["laboratory", "astrophysics", "comprises", "both", "theoretical", "and", "experimental", "studies", "of", "the", "underlying", "physics", "which", "produce", "the", "observed", "astrophysical", "processes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "laboratory astrophysics", "start": 0, "end": 23, "i_start": 0, "i_end": 1}, "verb": {"text": "comprises", "start": 24, "end": 33, "i_start": 2, "i_end": 2}}, {"character": {"text": "physics", "start": 94, "end": 101, "i_start": 11, "i_end": 11}, "action": {"text": "underlying", "start": 83, "end": 93, "i_start": 10, "i_end": 10}}, {"character": {"text": "physics", "start": 94, "end": 101, "i_start": 11, "i_end": 11}, "action": {"text": "produce", "start": 108, "end": 115, "i_start": 13, "i_end": 13}}], "id": 4022}, {"sent": "a consensus has been reached that a reasonable local observer will observe the local expansion rate .", "tokens": ["a", "consensus", "has", "been", "reached", "that", "a", "reasonable", "local", "observer", "will", "observe", "the", "local", "expansion", "rate", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a consensus has been reached that a reasonable local observer will observe the local expansion rate", "start": 0, "end": 99, "i_start": 0, "i_end": 15}, "verb": {"text": "has been reached", "start": 12, "end": 28, "i_start": 2, "i_end": 4}}], "id": 4023}, {"sent": "chudnovsky and seymour recently attracted considerable interest in claw-free graphs due to their excellent series of papers in journal of combinatorial theory on this topic .", "tokens": ["chudnovsky", "and", "seymour", "recently", "attracted", "considerable", "interest", "in", "claw", "-", "free", "graphs", "due", "to", "their", "excellent", "series", "of", "papers", "in", "journal", "of", "combinatorial", "theory", "on", "this", "topic", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "chudnovsky and seymour", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "attracted", "start": 32, "end": 41, "i_start": 4, "i_end": 4}}, {"character": {"text": "chudnovsky", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "attracted", "start": 32, "end": 41, "i_start": 4, "i_end": 4}}, {"character": {"text": "seymour", "start": 15, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "attracted", "start": 32, "end": 41, "i_start": 4, "i_end": 4}}], "id": 4024}, {"sent": "further progress depends on the use of compactness of to solve the remaining field equations .", "tokens": ["further", "progress", "depends", "on", "the", "use", "of", "compactness", "of", "to", "solve", "the", "remaining", "field", "equations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "further progress", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "depends", "start": 17, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "progress", "start": 8, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "depends", "start": 17, "end": 24, "i_start": 2, "i_end": 2}}], "id": 4025}, {"sent": "the first justification logic-style system , known as the logic of proofs , was introduced by artemov .", "tokens": ["the", "first", "justification", "logic", "-", "style", "system", ",", "known", "as", "the", "logic", "of", "proofs", ",", "was", "introduced", "by", "artemov", "."], "score": [1, 0, 0, 0, 1], "labels": [{"subject": {"text": "the first justification logic-style system", "start": 0, "end": 42, "i_start": 0, "i_end": 6}, "verb": {"text": "was introduced", "start": 76, "end": 90, "i_start": 15, "i_end": 16}}, {"character": {"text": "artemov", "start": 94, "end": 101, "i_start": 18, "i_end": 18}, "action": {"text": "introduced", "start": 80, "end": 90, "i_start": 16, "i_end": 16}}], "id": 4026}, {"sent": "deep neural networks have achieved impressive accuracy in many application domains such as image classification and localization , object detection , speech recognition and video classification .", "tokens": ["deep", "neural", "networks", "have", "achieved", "impressive", "accuracy", "in", "many", "application", "domains", "such", "as", "image", "classification", "and", "localization", ",", "object", "detection", ",", "speech", "recognition", "and", "video", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "accuracy", "start": 46, "end": 54, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 35, "end": 45, "i_start": 5, "i_end": 5}}], "id": 4027}, {"sent": "all models are randomly initialized and optimized by the adam optimizer with a learning rate of 3e-4 .", "tokens": ["all", "models", "are", "randomly", "initialized", "and", "optimized", "by", "the", "adam", "optimizer", "with", "a", "learning", "rate", "of", "3e-4", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "all models", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "initialized", "start": 24, "end": 35, "i_start": 4, "i_end": 4}}, {"subject": {"text": "all models", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 11, "end": 14, "i_start": 2, "i_end": 2}}, {"subject": {"text": "all models", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "optimized", "start": 40, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "adam", "start": 57, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "initialized", "start": 24, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "adam", "start": 57, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "optimizer", "start": 62, "end": 71, "i_start": 10, "i_end": 10}}], "id": 4028}, {"sent": "we evaluate our proposed method on three challenging video datasets with human actions , namely hmdb51 .", "tokens": ["we", "evaluate", "our", "proposed", "method", "on", "three", "challenging", "video", "datasets", "with", "human", "actions", ",", "namely", "hmdb51", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "three challenging video datasets", "start": 35, "end": 67, "i_start": 6, "i_end": 9}, "action": {"text": "challenging", "start": 41, "end": 52, "i_start": 7, "i_end": 7}}], "id": 4029}, {"sent": "although certain efforts we made during the last year to investigate the phase structure of qcd , the behavior of quark matter in many regions of the mentioned above extended phase diagram is not known .", "tokens": ["although", "certain", "efforts", "we", "made", "during", "the", "last", "year", "to", "investigate", "the", "phase", "structure", "of", "qcd", ",", "the", "behavior", "of", "quark", "matter", "in", "many", "regions", "of", "the", "mentioned", "above", "extended", "phase", "diagram", "is", "not", "known", "."], "score": [1, 1, 1, 0, 1], "labels": [{"subject": {"text": "certain efforts we made during the last year to investigate the phase structure of qcd", "start": 9, "end": 95, "i_start": 1, "i_end": 15}, "verb": {"text": "is not known", "start": 189, "end": 201, "i_start": 32, "i_end": 34}}, {"character": {"text": "matter", "start": 120, "end": 126, "i_start": 21, "i_end": 21}, "action": {"text": "behavior", "start": 102, "end": 110, "i_start": 18, "i_end": 18}}], "id": 4030}, {"sent": "we conclude by providing an additional formula for the mhv amplitude which is based on bcfw recursion .", "tokens": ["we", "conclude", "by", "providing", "an", "additional", "formula", "for", "the", "mhv", "amplitude", "which", "is", "based", "on", "bcfw", "recursion", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "conclude", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "conclude", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "providing", "start": 15, "end": 24, "i_start": 3, "i_end": 3}}], "id": 4031}, {"sent": "recently , unmanned aerial vehicles have been adopted in many applications such as weather monitoring and traffic control .", "tokens": ["recently", ",", "unmanned", "aerial", "vehicles", "have", "been", "adopted", "in", "many", "applications", "such", "as", "weather", "monitoring", "and", "traffic", "control", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "unmanned aerial vehicles", "start": 11, "end": 35, "i_start": 2, "i_end": 4}, "verb": {"text": "have been adopted", "start": 36, "end": 53, "i_start": 5, "i_end": 7}}], "id": 4032}, {"sent": "we now turn to consider the dynamics of any heterogeneous perturbations to the homogeneous base state just discussed .", "tokens": ["we", "now", "turn", "to", "consider", "the", "dynamics", "of", "any", "heterogeneous", "perturbations", "to", "the", "homogeneous", "base", "state", "just", "discussed", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "turn", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "turn", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "consider", "start": 15, "end": 23, "i_start": 4, "i_end": 4}}], "id": 4033}, {"sent": "global event reconstruction is performed by the particle-flow algorithm , which aims to reconstruct and identify each individual particle in an event , with an optimized combination of information from the various elements of the cms detector .", "tokens": ["global", "event", "reconstruction", "is", "performed", "by", "the", "particle", "-", "flow", "algorithm", ",", "which", "aims", "to", "reconstruct", "and", "identify", "each", "individual", "particle", "in", "an", "event", ",", "with", "an", "optimized", "combination", "of", "information", "from", "the", "various", "elements", "of", "the", "cms", "detector", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "global event reconstruction", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "is performed", "start": 28, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "algorithm", "start": 62, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "performed", "start": 31, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "algorithm", "start": 62, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "aims", "start": 80, "end": 84, "i_start": 13, "i_end": 13}}], "id": 4034}, {"sent": "deep learning has been widely used in many areas , including speech recognition , etc .", "tokens": ["deep", "learning", "has", "been", "widely", "used", "in", "many", "areas", ",", "including", "speech", "recognition", ",", "etc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "used", "start": 30, "end": 34, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has been", "start": 14, "end": 22, "i_start": 2, "i_end": 3}}], "id": 4035}, {"sent": "first we discuss the dependence of the relevant scales for the structure formation and the amount of mirror baryonic matter .", "tokens": ["first", "we", "discuss", "the", "dependence", "of", "the", "relevant", "scales", "for", "the", "structure", "formation", "and", "the", "amount", "of", "mirror", "baryonic", "matter", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 6, "end": 8, "i_start": 1, "i_end": 1}, "verb": {"text": "discuss", "start": 9, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "discuss", "start": 9, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "scales", "start": 48, "end": 54, "i_start": 8, "i_end": 8}, "action": {"text": "dependence", "start": 21, "end": 31, "i_start": 4, "i_end": 4}}], "id": 4036}, {"sent": "we apply vgg net to extract the image features , which is the 4096-dimensional output of the second fully-connected layer .", "tokens": ["we", "apply", "vgg", "net", "to", "extract", "the", "image", "features", ",", "which", "is", "the", "4096", "-", "dimensional", "output", "of", "the", "second", "fully", "-", "connected", "layer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "apply", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "apply", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extract", "start": 20, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "layer", "start": 116, "end": 121, "i_start": 23, "i_end": 23}, "action": {"text": "output", "start": 79, "end": 85, "i_start": 16, "i_end": 16}}], "id": 4037}, {"sent": "generative adversarial networks have been relatively successful in learning underlying distribution of data , especially in application such as image generation .", "tokens": ["generative", "adversarial", "networks", "have", "been", "relatively", "successful", "in", "learning", "underlying", "distribution", "of", "data", ",", "especially", "in", "application", "such", "as", "image", "generation", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 32, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 53, "end": 63, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "learning", "start": 67, "end": 75, "i_start": 8, "i_end": 8}}, {"character": {"text": "learning", "start": 67, "end": 75, "i_start": 8, "i_end": 8}, "action": {"text": "underlying", "start": 76, "end": 86, "i_start": 9, "i_end": 9}}], "id": 4038}, {"sent": "in the present paper , we generate the sf networks by a static method explained in .", "tokens": ["in", "the", "present", "paper", ",", "we", "generate", "the", "sf", "networks", "by", "a", "static", "method", "explained", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "verb": {"text": "generate", "start": 26, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "action": {"text": "generate", "start": 26, "end": 34, "i_start": 6, "i_end": 6}}], "id": 4039}, {"sent": "multi-task learning improves learning efficiency and model generalization for the task-specific models by learning several related tasks at the same time .", "tokens": ["multi", "-", "task", "learning", "improves", "learning", "efficiency", "and", "model", "generalization", "for", "the", "task", "-", "specific", "models", "by", "learning", "several", "related", "tasks", "at", "the", "same", "time", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "multi-task learning", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "improves", "start": 20, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 29, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "improves", "start": 20, "end": 28, "i_start": 4, "i_end": 4}}], "id": 4040}, {"sent": "when the mass parameters of the puncture are set to zero , x is nilpotent , and the orbit is called a nilpotent orbit .", "tokens": ["when", "the", "mass", "parameters", "of", "the", "puncture", "are", "set", "to", "zero", ",", "x", "is", "nilpotent", ",", "and", "the", "orbit", "is", "called", "a", "nilpotent", "orbit", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the orbit", "start": 80, "end": 89, "i_start": 17, "i_end": 18}, "verb": {"text": "is", "start": 61, "end": 63, "i_start": 13, "i_end": 13}}, {"subject": {"text": "the orbit", "start": 80, "end": 89, "i_start": 17, "i_end": 18}, "verb": {"text": "called", "start": 93, "end": 99, "i_start": 20, "i_end": 20}}], "id": 4041}, {"sent": "we use the reinforce algorithm to learn a policy for the mdp .", "tokens": ["we", "use", "the", "reinforce", "algorithm", "to", "learn", "a", "policy", "for", "the", "mdp", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "algorithm", "start": 21, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "reinforce", "start": 11, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "learn", "start": 34, "end": 39, "i_start": 6, "i_end": 6}}], "id": 4042}, {"sent": "the s0 galaxy class was invented by hubble to fill a transitional gap between ellipticals and spirals in his original morphological sequence .", "tokens": ["the", "s0", "galaxy", "class", "was", "invented", "by", "hubble", "to", "fill", "a", "transitional", "gap", "between", "ellipticals", "and", "spirals", "in", "his", "original", "morphological", "sequence", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the s0 galaxy class", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "was invented", "start": 20, "end": 32, "i_start": 4, "i_end": 5}}, {"character": {"text": "hubble", "start": 36, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "invented", "start": 24, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "hubble", "start": 36, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "fill", "start": 46, "end": 50, "i_start": 9, "i_end": 9}}], "id": 4043}, {"sent": "the efficiency of the method is phenomenal and its validity has been checked by various tree level calculations .", "tokens": ["the", "efficiency", "of", "the", "method", "is", "phenomenal", "and", "its", "validity", "has", "been", "checked", "by", "various", "tree", "level", "calculations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the efficiency of the method", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 5, "i_end": 5}}, {"subject": {"text": "its validity", "start": 47, "end": 59, "i_start": 8, "i_end": 9}, "verb": {"text": "checked", "start": 69, "end": 76, "i_start": 12, "i_end": 12}}], "id": 4044}, {"sent": "in , the authors presented a reduction from euclidean approximate nearest neighbor searching to polytope membership .", "tokens": ["in", ",", "the", "authors", "presented", "a", "reduction", "from", "euclidean", "approximate", "nearest", "neighbor", "searching", "to", "polytope", "membership", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 5, "end": 16, "i_start": 2, "i_end": 3}, "verb": {"text": "presented", "start": 17, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "neighbor", "start": 74, "end": 82, "i_start": 11, "i_end": 11}, "action": {"text": "searching", "start": 83, "end": 92, "i_start": 12, "i_end": 12}}], "id": 4045}, {"sent": "asterisks denote ew s corrected for the contribution of a nearby iron line .", "tokens": ["asterisks", "denote", "ew", "s", "corrected", "for", "the", "contribution", "of", "a", "nearby", "iron", "line", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "asterisks", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "line", "start": 70, "end": 74, "i_start": 12, "i_end": 12}, "action": {"text": "contribution", "start": 40, "end": 52, "i_start": 7, "i_end": 7}}], "id": 4046}, {"sent": "in this study we use b-splines as basis functions and follow closely .", "tokens": ["in", "this", "study", "we", "use", "b", "-", "splines", "as", "basis", "functions", "and", "follow", "closely", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "use", "start": 17, "end": 20, "i_start": 4, "i_end": 4}}, {"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "follow", "start": 54, "end": 60, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 17, "end": 20, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "follow", "start": 54, "end": 60, "i_start": 12, "i_end": 12}}], "id": 4047}, {"sent": "in the framework of this paper we assume that \u03bb i are free functional parameters and we do not specify any concrete their dependencies .", "tokens": ["in", "the", "framework", "of", "this", "paper", "we", "assume", "that", "\u03bb", "i", "are", "free", "functional", "parameters", "and", "we", "do", "not", "specify", "any", "concrete", "their", "dependencies", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 31, "end": 33, "i_start": 6, "i_end": 6}, "verb": {"text": "assume", "start": 34, "end": 40, "i_start": 7, "i_end": 7}}, {"subject": {"text": "we", "start": 31, "end": 33, "i_start": 6, "i_end": 6}, "verb": {"text": "are", "start": 50, "end": 53, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 6, "i_end": 6}, "action": {"text": "assume", "start": 34, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 6, "i_end": 6}, "action": {"text": "not specify", "start": 91, "end": 102, "i_start": 18, "i_end": 19}}], "id": 4048}, {"sent": "the restriction of the classes \u03c4p to fixed points .", "tokens": ["the", "restriction", "of", "the", "classes", "\u03c4p", "to", "fixed", "points", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4049}, {"sent": "we also add batch normalization layers after every couple of convolutional layers .", "tokens": ["we", "also", "add", "batch", "normalization", "layers", "after", "every", "couple", "of", "convolutional", "layers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "add", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "add", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}], "id": 4050}, {"sent": "the cosmological constant problem is one of the most severe fine tuning problems of modern day physics .", "tokens": ["the", "cosmological", "constant", "problem", "is", "one", "of", "the", "most", "severe", "fine", "tuning", "problems", "of", "modern", "day", "physics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the cosmological constant problem", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 4, "i_end": 4}}], "id": 4051}, {"sent": "the quantum fourier transforms form the basis of nearly all the known quantum algorithms .", "tokens": ["the", "quantum", "fourier", "transforms", "form", "the", "basis", "of", "nearly", "all", "the", "known", "quantum", "algorithms", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quantum fourier", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "transforms", "start": 20, "end": 30, "i_start": 3, "i_end": 3}}], "id": 4052}, {"sent": "furthermore , the phase damping channel does not influence the game .", "tokens": ["furthermore", ",", "the", "phase", "damping", "channel", "does", "not", "influence", "the", "game", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the phase damping channel", "start": 14, "end": 39, "i_start": 2, "i_end": 5}, "verb": {"text": "does not influence", "start": 40, "end": 58, "i_start": 6, "i_end": 8}}, {"character": {"text": "channel", "start": 32, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "not influence", "start": 45, "end": 58, "i_start": 7, "i_end": 8}}, {"character": {"text": "channel", "start": 32, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "damping", "start": 24, "end": 31, "i_start": 4, "i_end": 4}}], "id": 4053}, {"sent": "recently , the benefits of attention mechanism have been shown across a range of tasks , from neural machine translation in image understanding .", "tokens": ["recently", ",", "the", "benefits", "of", "attention", "mechanism", "have", "been", "shown", "across", "a", "range", "of", "tasks", ",", "from", "neural", "machine", "translation", "in", "image", "understanding", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the benefits of attention mechanism", "start": 11, "end": 46, "i_start": 2, "i_end": 6}, "verb": {"text": "have been shown", "start": 47, "end": 62, "i_start": 7, "i_end": 9}}, {"character": {"text": "mechanism", "start": 37, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "benefits", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 4054}, {"sent": "in its original version , the kuramoto model is a simple model of globally coupled oscillators .", "tokens": ["in", "its", "original", "version", ",", "the", "kuramoto", "model", "is", "a", "simple", "model", "of", "globally", "coupled", "oscillators", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the kuramoto model", "start": 26, "end": 44, "i_start": 5, "i_end": 7}, "verb": {"text": "is", "start": 45, "end": 47, "i_start": 8, "i_end": 8}}], "id": 4055}, {"sent": "in so far as teleportation is a measure of entanglement , our results suggest that quantum entanglement is degraded in non-inertial frames .", "tokens": ["in", "so", "far", "as", "teleportation", "is", "a", "measure", "of", "entanglement", ",", "our", "results", "suggest", "that", "quantum", "entanglement", "is", "degraded", "in", "non", "-", "inertial", "frames", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "our results", "start": 58, "end": 69, "i_start": 11, "i_end": 12}, "verb": {"text": "suggest", "start": 70, "end": 77, "i_start": 13, "i_end": 13}}, {"subject": {"text": "quantum entanglement", "start": 83, "end": 103, "i_start": 15, "i_end": 16}, "verb": {"text": "degraded", "start": 107, "end": 115, "i_start": 18, "i_end": 18}}, {"character": {"text": "results", "start": 62, "end": 69, "i_start": 12, "i_end": 12}, "action": {"text": "suggest", "start": 70, "end": 77, "i_start": 13, "i_end": 13}}, {"character": {"text": "frames", "start": 132, "end": 138, "i_start": 23, "i_end": 23}, "action": {"text": "degraded", "start": 107, "end": 115, "i_start": 18, "i_end": 18}}], "id": 4056}, {"sent": "we then used the levenberg-marquardt algorithm to vary band parameters .", "tokens": ["we", "then", "used", "the", "levenberg", "-", "marquardt", "algorithm", "to", "vary", "band", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "vary", "start": 50, "end": 54, "i_start": 9, "i_end": 9}}], "id": 4057}, {"sent": "deep neural networks have demonstrated significant performance improvements in a wide range of computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "significant", "performance", "improvements", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improvements", "start": 63, "end": 75, "i_start": 7, "i_end": 7}}], "id": 4058}, {"sent": "we also report the performance on the pascal voc2012 dataset , since it is a standard benchmark for generic semantic segmentation .", "tokens": ["we", "also", "report", "the", "performance", "on", "the", "pascal", "voc2012", "dataset", ",", "since", "it", "is", "a", "standard", "benchmark", "for", "generic", "semantic", "segmentation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "report", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "report", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "dataset", "start": 53, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "performance", "start": 19, "end": 30, "i_start": 4, "i_end": 4}}], "id": 4059}, {"sent": "lenet5 consists of seven layers , two convolution layers followed by two max-pooling layers , followed by a three-layer fully-connected network which learns a function f to fit the data .", "tokens": ["lenet5", "consists", "of", "seven", "layers", ",", "two", "convolution", "layers", "followed", "by", "two", "max", "-", "pooling", "layers", ",", "followed", "by", "a", "three", "-", "layer", "fully", "-", "connected", "network", "which", "learns", "a", "function", "f", "to", "fit", "the", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "lenet5", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "consists", "start": 7, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "network", "start": 136, "end": 143, "i_start": 26, "i_end": 26}, "action": {"text": "learns", "start": 150, "end": 156, "i_start": 28, "i_end": 28}}], "id": 4060}, {"sent": "the total energies were computed using the projected augmented wave method within the pbe generalized gradient approximation .", "tokens": ["the", "total", "energies", "were", "computed", "using", "the", "projected", "augmented", "wave", "method", "within", "the", "pbe", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the total energies", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "were computed", "start": 19, "end": 32, "i_start": 3, "i_end": 4}}], "id": 4061}, {"sent": "the left panel shows the dwarfs , the right the spirals .", "tokens": ["the", "left", "panel", "shows", "the", "dwarfs", ",", "the", "right", "the", "spirals", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the left panel", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "shows", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "panel", "start": 9, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "shows", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}], "id": 4062}, {"sent": "the space-time of is a 4d de sitter hyperboloid in a 5d minkowski bulk .", "tokens": ["the", "space", "-", "time", "of", "is", "a", "4d", "de", "sitter", "hyperboloid", "in", "a", "5d", "minkowski", "bulk", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the space-time of", "start": 0, "end": 17, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 5, "i_end": 5}}], "id": 4063}, {"sent": "the vienna ab-initio simulation package was used to perform the required computations .", "tokens": ["the", "vienna", "ab", "-", "initio", "simulation", "package", "was", "used", "to", "perform", "the", "required", "computations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the vienna ab-initio simulation package", "start": 0, "end": 39, "i_start": 0, "i_end": 6}, "verb": {"text": "was used", "start": 40, "end": 48, "i_start": 7, "i_end": 8}}], "id": 4064}, {"sent": "every diagram is easily seen to be realizable .", "tokens": ["every", "diagram", "is", "easily", "seen", "to", "be", "realizable", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "every diagram", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "seen", "start": 24, "end": 28, "i_start": 4, "i_end": 4}}, {"subject": {"text": "every diagram", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 4065}, {"sent": "the muons for mice were created from the decay of pions produced when a target dipped into the circulating proton beam in the isis synchrotron at the stfc rutherford appleton laboratory .", "tokens": ["the", "muons", "for", "mice", "were", "created", "from", "the", "decay", "of", "pions", "produced", "when", "a", "target", "dipped", "into", "the", "circulating", "proton", "beam", "in", "the", "isis", "synchrotron", "at", "the", "stfc", "rutherford", "appleton", "laboratory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the muons for mice", "start": 0, "end": 18, "i_start": 0, "i_end": 3}, "verb": {"text": "were created", "start": 19, "end": 31, "i_start": 4, "i_end": 5}}], "id": 4066}, {"sent": "for example , both dncnn had been evaluated on all these three tasks .", "tokens": ["for", "example", ",", "both", "dncnn", "had", "been", "evaluated", "on", "all", "these", "three", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "both dncnn", "start": 14, "end": 24, "i_start": 3, "i_end": 4}, "verb": {"text": "had been evaluated", "start": 25, "end": 43, "i_start": 5, "i_end": 7}}], "id": 4067}, {"sent": "now we can proceed towards the erasure part of system specification .", "tokens": ["now", "we", "can", "proceed", "towards", "the", "erasure", "part", "of", "system", "specification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "can proceed", "start": 7, "end": 18, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}], "id": 4068}, {"sent": "for fitness evaluations , all networks were trained using adam for eight epochs .", "tokens": ["for", "fitness", "evaluations", ",", "all", "networks", "were", "trained", "using", "adam", "for", "eight", "epochs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all networks", "start": 26, "end": 38, "i_start": 4, "i_end": 5}, "verb": {"text": "were trained", "start": 39, "end": 51, "i_start": 6, "i_end": 7}}], "id": 4069}, {"sent": "white areas correspond to unbounded trajectories .", "tokens": ["white", "areas", "correspond", "to", "unbounded", "trajectories", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "white areas", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "correspond", "start": 12, "end": 22, "i_start": 2, "i_end": 2}}], "id": 4070}, {"sent": "in fact , most of these models predict an anomalous propagation speed for gravitational waves .", "tokens": ["in", "fact", ",", "most", "of", "these", "models", "predict", "an", "anomalous", "propagation", "speed", "for", "gravitational", "waves", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "most of these models", "start": 10, "end": 30, "i_start": 3, "i_end": 6}, "verb": {"text": "predict", "start": 31, "end": 38, "i_start": 7, "i_end": 7}}, {"character": {"text": "models", "start": 24, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "predict", "start": 31, "end": 38, "i_start": 7, "i_end": 7}}], "id": 4071}, {"sent": "recently , deep convolutional neural networks have attracted much research attention in visual recognition , largely due to their excellent performance .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "attracted", "much", "research", "attention", "in", "visual", "recognition", ",", "largely", "due", "to", "their", "excellent", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have attracted", "start": 46, "end": 60, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "attracted", "start": 51, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 140, "end": 151, "i_start": 20, "i_end": 20}}], "id": 4072}, {"sent": "following , covert communications have been studied in different scenarios .", "tokens": ["following", ",", "covert", "communications", "have", "been", "studied", "in", "different", "scenarios", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "covert communications", "start": 12, "end": 33, "i_start": 2, "i_end": 3}, "verb": {"text": "have been studied", "start": 34, "end": 51, "i_start": 4, "i_end": 6}}], "id": 4073}, {"sent": "since the attention mechanism is effective in understanding images , it has been widely used in various tasks , including machine translation .", "tokens": ["since", "the", "attention", "mechanism", "is", "effective", "in", "understanding", "images", ",", "it", "has", "been", "widely", "used", "in", "various", "tasks", ",", "including", "machine", "translation", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 69, "end": 71, "i_start": 10, "i_end": 10}, "verb": {"text": "used", "start": 88, "end": 92, "i_start": 14, "i_end": 14}}, {"subject": {"text": "it", "start": 69, "end": 71, "i_start": 10, "i_end": 10}, "verb": {"text": "has been", "start": 72, "end": 80, "i_start": 11, "i_end": 12}}, {"character": {"text": "mechanism", "start": 20, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "effective", "start": 33, "end": 42, "i_start": 5, "i_end": 5}}], "id": 4074}, {"sent": "this model of learning has been formalised in computational learning theory by valiant in 1984 with the introduction of the probably approximately correct model .", "tokens": ["this", "model", "of", "learning", "has", "been", "formalised", "in", "computational", "learning", "theory", "by", "valiant", "in", "1984", "with", "the", "introduction", "of", "the", "probably", "approximately", "correct", "model", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this model of learning", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "has been formalised", "start": 23, "end": 42, "i_start": 4, "i_end": 6}}, {"character": {"text": "valiant", "start": 79, "end": 86, "i_start": 12, "i_end": 12}, "action": {"text": "formalised", "start": 32, "end": 42, "i_start": 6, "i_end": 6}}], "id": 4075}, {"sent": "we use slot error rate , including the intent as slot , to evaluate the overall predictive performance of the nlu models .", "tokens": ["we", "use", "slot", "error", "rate", ",", "including", "the", "intent", "as", "slot", ",", "to", "evaluate", "the", "overall", "predictive", "performance", "of", "the", "nlu", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 59, "end": 67, "i_start": 13, "i_end": 13}}, {"character": {"text": "models", "start": 114, "end": 120, "i_start": 21, "i_end": 21}, "action": {"text": "performance", "start": 91, "end": 102, "i_start": 17, "i_end": 17}}], "id": 4076}, {"sent": "early data stream management systems extended database management systems to support by sensor network applications , that have similarities to iot .", "tokens": ["early", "data", "stream", "management", "systems", "extended", "database", "management", "systems", "to", "support", "by", "sensor", "network", "applications", ",", "that", "have", "similarities", "to", "iot", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "early data stream management systems", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "extended", "start": 37, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "systems", "start": 29, "end": 36, "i_start": 4, "i_end": 4}, "action": {"text": "extended", "start": 37, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "systems", "start": 29, "end": 36, "i_start": 4, "i_end": 4}, "action": {"text": "management", "start": 18, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "systems", "start": 66, "end": 73, "i_start": 8, "i_end": 8}, "action": {"text": "management", "start": 55, "end": 65, "i_start": 7, "i_end": 7}}, {"character": {"text": "applications", "start": 103, "end": 115, "i_start": 14, "i_end": 14}, "action": {"text": "support", "start": 77, "end": 84, "i_start": 10, "i_end": 10}}], "id": 4077}, {"sent": "bremsstrahlung is the dominant cooling mechanism at these very high temperatures .", "tokens": ["bremsstrahlung", "is", "the", "dominant", "cooling", "mechanism", "at", "these", "very", "high", "temperatures", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "bremsstrahlung", "start": 0, "end": 14, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 1, "i_end": 1}}, {"character": {"text": "mechanism", "start": 39, "end": 48, "i_start": 5, "i_end": 5}, "action": {"text": "cooling", "start": 31, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "mechanism", "start": 39, "end": 48, "i_start": 5, "i_end": 5}, "action": {"text": "dominant", "start": 22, "end": 30, "i_start": 3, "i_end": 3}}], "id": 4078}, {"sent": "the high-speed particles are blown upward from the holes , which are the broken layer .", "tokens": ["the", "high", "-", "speed", "particles", "are", "blown", "upward", "from", "the", "holes", ",", "which", "are", "the", "broken", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the high-speed particles", "start": 0, "end": 24, "i_start": 0, "i_end": 4}, "verb": {"text": "are blown", "start": 25, "end": 34, "i_start": 5, "i_end": 6}}], "id": 4079}, {"sent": "it has been shown that it is possible to partially solve this problem by including a correction to the unwrapped measured phase using partial kramers-kroenig relations .", "tokens": ["it", "has", "been", "shown", "that", "it", "is", "possible", "to", "partially", "solve", "this", "problem", "by", "including", "a", "correction", "to", "the", "unwrapped", "measured", "phase", "using", "partial", "kramers", "-", "kroenig", "relations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has been shown", "start": 3, "end": 17, "i_start": 1, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 6, "i_end": 6}}], "id": 4080}, {"sent": "in this work , we focus on a coded caching model where a content-providing server is connected to many users , each equipped with a cache of finite memory .", "tokens": ["in", "this", "work", ",", "we", "focus", "on", "a", "coded", "caching", "model", "where", "a", "content", "-", "providing", "server", "is", "connected", "to", "many", "users", ",", "each", "equipped", "with", "a", "cache", "of", "finite", "memory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "focus", "start": 18, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "focus", "start": 18, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "server", "start": 75, "end": 81, "i_start": 16, "i_end": 16}, "action": {"text": "providing", "start": 65, "end": 74, "i_start": 15, "i_end": 15}}], "id": 4081}, {"sent": "tompson et al used a deep architecture with a graphical model whose parameters are learned jointly with the network .", "tokens": ["tompson", "et", "al", "used", "a", "deep", "architecture", "with", "a", "graphical", "model", "whose", "parameters", "are", "learned", "jointly", "with", "the", "network", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 8, "end": 13, "i_start": 1, "i_end": 2}, "verb": {"text": "used", "start": 14, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "tompson", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 14, "end": 18, "i_start": 3, "i_end": 3}}], "id": 4082}, {"sent": "weakly-supervised object localization techniques can be used to train object detectors from image-level labels only .", "tokens": ["weakly", "-", "supervised", "object", "localization", "techniques", "can", "be", "used", "to", "train", "object", "detectors", "from", "image", "-", "level", "labels", "only", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "weakly-supervised object localization techniques", "start": 0, "end": 48, "i_start": 0, "i_end": 5}, "verb": {"text": "can be used", "start": 49, "end": 60, "i_start": 6, "i_end": 8}}], "id": 4083}, {"sent": "if the tromino covering and covers then a ris completed by the tromino covering , in which case becomes inaccessible .", "tokens": ["if", "the", "tromino", "covering", "and", "covers", "then", "a", "ris", "completed", "by", "the", "tromino", "covering", ",", "in", "which", "case", "becomes", "inaccessible", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "completed", "start": 46, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "if", "start": 0, "end": 2, "i_start": 0, "i_end": 0}}], "id": 4084}, {"sent": "the pcal response measurements put the detector sensitivities lower than the conventional coil actuator response measurements .", "tokens": ["the", "pcal", "response", "measurements", "put", "the", "detector", "sensitivities", "lower", "than", "the", "conventional", "coil", "actuator", "response", "measurements", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the pcal response measurements", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "put", "start": 31, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "measurements", "start": 18, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "put", "start": 31, "end": 34, "i_start": 4, "i_end": 4}}], "id": 4085}, {"sent": "the mapping \u03c6 is called the frobenius homomorphism of l .", "tokens": ["the", "mapping", "\u03c6", "is", "called", "the", "frobenius", "homomorphism", "of", "l", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the mapping \u03c6", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 14, "end": 23, "i_start": 3, "i_end": 4}}], "id": 4086}, {"sent": "jones , hecke algebra representations of braid groups and link polynomials .", "tokens": ["jones", ",", "hecke", "algebra", "representations", "of", "braid", "groups", "and", "link", "polynomials", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4087}, {"sent": "missing ingredient is a caustic-crossing binary detection efficiency .", "tokens": ["missing", "ingredient", "is", "a", "caustic", "-", "crossing", "binary", "detection", "efficiency", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "missing ingredient", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "detection", "start": 48, "end": 57, "i_start": 8, "i_end": 8}, "action": {"text": "crossing", "start": 32, "end": 40, "i_start": 6, "i_end": 6}}], "id": 4088}, {"sent": "evolutionary game theory provides a theoretical framework to address the subtleties of cooperation among selfish individuals .", "tokens": ["evolutionary", "game", "theory", "provides", "a", "theoretical", "framework", "to", "address", "the", "subtleties", "of", "cooperation", "among", "selfish", "individuals", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "evolutionary game theory", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "provides", "start": 25, "end": 33, "i_start": 3, "i_end": 3}}, {"character": {"text": "theory", "start": 18, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "provides", "start": 25, "end": 33, "i_start": 3, "i_end": 3}}, {"character": {"text": "framework", "start": 48, "end": 57, "i_start": 6, "i_end": 6}, "action": {"text": "address", "start": 61, "end": 68, "i_start": 8, "i_end": 8}}, {"character": {"text": "individuals", "start": 113, "end": 124, "i_start": 15, "i_end": 15}, "action": {"text": "cooperation", "start": 87, "end": 98, "i_start": 12, "i_end": 12}}], "id": 4089}, {"sent": "the reason why we use the d-particle instead of the usual particle is due to the exact solubility of our model .", "tokens": ["the", "reason", "why", "we", "use", "the", "d", "-", "particle", "instead", "of", "the", "usual", "particle", "is", "due", "to", "the", "exact", "solubility", "of", "our", "model", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the reason why we use the d-particle instead of the usual particle", "start": 0, "end": 66, "i_start": 0, "i_end": 13}, "verb": {"text": "is", "start": 67, "end": 69, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 18, "end": 21, "i_start": 4, "i_end": 4}}], "id": 4090}, {"sent": "the critical power law extracted from this plot is listed in table i .", "tokens": ["the", "critical", "power", "law", "extracted", "from", "this", "plot", "is", "listed", "in", "table", "i", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the critical power law extracted from this plot", "start": 0, "end": 47, "i_start": 0, "i_end": 7}, "verb": {"text": "is listed", "start": 48, "end": 57, "i_start": 8, "i_end": 9}}], "id": 4091}, {"sent": "it was proved in the simply-laced case and later for twisted current algebras that a local weyl module is isomorphic to a level one demazure module .", "tokens": ["it", "was", "proved", "in", "the", "simply", "-", "laced", "case", "and", "later", "for", "twisted", "current", "algebras", "that", "a", "local", "weyl", "module", "is", "isomorphic", "to", "a", "level", "one", "demazure", "module", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "was proved", "start": 3, "end": 13, "i_start": 1, "i_end": 2}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 103, "end": 105, "i_start": 20, "i_end": 20}}], "id": 4092}, {"sent": "in this case , the canonicalization method in use is the one implemented by openbabel which is based on the widely used morgan algorithm .", "tokens": ["in", "this", "case", ",", "the", "canonicalization", "method", "in", "use", "is", "the", "one", "implemented", "by", "openbabel", "which", "is", "based", "on", "the", "widely", "used", "morgan", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the canonicalization method in use", "start": 15, "end": 49, "i_start": 4, "i_end": 8}, "verb": {"text": "is", "start": 50, "end": 52, "i_start": 9, "i_end": 9}}], "id": 4093}, {"sent": "inflation is one of the leading paradigms for explaining the physical conditions that prevailed in the very early universe .", "tokens": ["inflation", "is", "one", "of", "the", "leading", "paradigms", "for", "explaining", "the", "physical", "conditions", "that", "prevailed", "in", "the", "very", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "inflation", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "paradigms", "start": 32, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "leading", "start": 24, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "conditions", "start": 70, "end": 80, "i_start": 11, "i_end": 11}, "action": {"text": "prevailed", "start": 86, "end": 95, "i_start": 13, "i_end": 13}}], "id": 4094}, {"sent": "this unsupervised machine learning algorithm , similarly to latent dirichlet allocation , accumulates co-occurring words into probabilistic topics .", "tokens": ["this", "unsupervised", "machine", "learning", "algorithm", ",", "similarly", "to", "latent", "dirichlet", "allocation", ",", "accumulates", "co", "-", "occurring", "words", "into", "probabilistic", "topics", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "this unsupervised machine learning algorithm", "start": 0, "end": 44, "i_start": 0, "i_end": 4}, "verb": {"text": "accumulates", "start": 90, "end": 101, "i_start": 12, "i_end": 12}}, {"character": {"text": "algorithm", "start": 35, "end": 44, "i_start": 4, "i_end": 4}, "action": {"text": "accumulates", "start": 90, "end": 101, "i_start": 12, "i_end": 12}}, {"character": {"text": "algorithm", "start": 35, "end": 44, "i_start": 4, "i_end": 4}, "action": {"text": "learning", "start": 26, "end": 34, "i_start": 3, "i_end": 3}}], "id": 4095}, {"sent": "graphene is a hexagonal lattice built out of two inter-penetrating triangular sub-lattices a and b .", "tokens": ["graphene", "is", "a", "hexagonal", "lattice", "built", "out", "of", "two", "inter", "-", "penetrating", "triangular", "sub", "-", "lattices", "a", "and", "b", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "graphene", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "two", "start": 45, "end": 48, "i_start": 8, "i_end": 8}, "action": {"text": "penetrating", "start": 55, "end": 66, "i_start": 11, "i_end": 11}}], "id": 4096}, {"sent": "as noted with the results of the laser-driven shock experiments , this behavior is expected because the dissipation mechanism in ppm operates on smaller and smaller scales as the resolution is increased .", "tokens": ["as", "noted", "with", "the", "results", "of", "the", "laser", "-", "driven", "shock", "experiments", ",", "this", "behavior", "is", "expected", "because", "the", "dissipation", "mechanism", "in", "ppm", "operates", "on", "smaller", "and", "smaller", "scales", "as", "the", "resolution", "is", "increased", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "this behavior", "start": 66, "end": 79, "i_start": 13, "i_end": 14}, "verb": {"text": "is expected", "start": 80, "end": 91, "i_start": 15, "i_end": 16}}, {"character": {"text": "operates", "start": 133, "end": 141, "i_start": 23, "i_end": 23}, "action": {"text": "because", "start": 92, "end": 99, "i_start": 17, "i_end": 17}}, {"character": {"text": "mechanism", "start": 116, "end": 125, "i_start": 20, "i_end": 20}, "action": {"text": "dissipation", "start": 104, "end": 115, "i_start": 19, "i_end": 19}}], "id": 4097}, {"sent": "in recent years , deep neural networks , especially convolutional neural networks , have demonstrated highly competitive results on object recognition and image classification .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", ",", "especially", "convolutional", "neural", "networks", ",", "have", "demonstrated", "highly", "competitive", "results", "on", "object", "recognition", "and", "image", "classification", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have demonstrated", "start": 84, "end": 101, "i_start": 13, "i_end": 14}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "demonstrated", "start": 89, "end": 101, "i_start": 14, "i_end": 14}}], "id": 4098}, {"sent": "the value-based methods estimate future expected total rewards through a state , such as sarsa .", "tokens": ["the", "value", "-", "based", "methods", "estimate", "future", "expected", "total", "rewards", "through", "a", "state", ",", "such", "as", "sarsa", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the value-based methods", "start": 0, "end": 23, "i_start": 0, "i_end": 4}, "verb": {"text": "estimate", "start": 24, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "methods", "start": 16, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "estimate", "start": 24, "end": 32, "i_start": 5, "i_end": 5}}], "id": 4099}, {"sent": "all convolution and fully connected layers are followed by relu non-linearity , except for the output layer .", "tokens": ["all", "convolution", "and", "fully", "connected", "layers", "are", "followed", "by", "relu", "non", "-", "linearity", ",", "except", "for", "the", "output", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all convolution and fully connected layers", "start": 0, "end": 42, "i_start": 0, "i_end": 5}, "verb": {"text": "are followed", "start": 43, "end": 55, "i_start": 6, "i_end": 7}}], "id": 4100}, {"sent": "these constraints on permissible power laws apply for any spectrally localized forcing , not just for monoscale-like forcing .", "tokens": ["these", "constraints", "on", "permissible", "power", "laws", "apply", "for", "any", "spectrally", "localized", "forcing", ",", "not", "just", "for", "monoscale", "-", "like", "forcing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these constraints on permissible power laws", "start": 0, "end": 43, "i_start": 0, "i_end": 5}, "verb": {"text": "apply", "start": 44, "end": 49, "i_start": 6, "i_end": 6}}], "id": 4101}, {"sent": "deep convolutional neural networks have recently become increasingly important for computer vision applications .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "recently", "become", "increasingly", "important", "for", "computer", "vision", "applications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "become", "start": 49, "end": 55, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}], "id": 4102}, {"sent": "in tree parallelism one mcts tree is shared among several threads that are performing simultaneous tree-traversal starting from the root .", "tokens": ["in", "tree", "parallelism", "one", "mcts", "tree", "is", "shared", "among", "several", "threads", "that", "are", "performing", "simultaneous", "tree", "-", "traversal", "starting", "from", "the", "root", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "one mcts tree", "start": 20, "end": 33, "i_start": 3, "i_end": 5}, "verb": {"text": "is shared", "start": 34, "end": 43, "i_start": 6, "i_end": 7}}, {"character": {"text": "threads", "start": 58, "end": 65, "i_start": 10, "i_end": 10}, "action": {"text": "shared", "start": 37, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "threads", "start": 58, "end": 65, "i_start": 10, "i_end": 10}, "action": {"text": "performing", "start": 75, "end": 85, "i_start": 13, "i_end": 13}}], "id": 4103}, {"sent": "gruber et al found that irregular blood flow can lead to hypoplastic left heart syndrome , where the ventricle is too small or absent during the remainder of cardiogenesis .", "tokens": ["gruber", "et", "al", "found", "that", "irregular", "blood", "flow", "can", "lead", "to", "hypoplastic", "left", "heart", "syndrome", ",", "where", "the", "ventricle", "is", "too", "small", "or", "absent", "during", "the", "remainder", "of", "cardiogenesis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "gruber et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "found", "start": 13, "end": 18, "i_start": 3, "i_end": 3}}, {"subject": {"text": "irregular blood flow", "start": 24, "end": 44, "i_start": 5, "i_end": 7}, "verb": {"text": "lead", "start": 49, "end": 53, "i_start": 9, "i_end": 9}}, {"character": {"text": "gruber", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "found", "start": 13, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "flow", "start": 40, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "lead", "start": 49, "end": 53, "i_start": 9, "i_end": 9}}], "id": 4104}, {"sent": "let us recall the following fact from the theory of semisimple lie algebras .", "tokens": ["let", "us", "recall", "the", "following", "fact", "from", "the", "theory", "of", "semisimple", "lie", "algebras", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "recall", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "recall", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}], "id": 4105}, {"sent": "the upper panels show cumulation plots of the reconstructed ip distances versus the beam spot size , for non-colliding and colliding bunches separately .", "tokens": ["the", "upper", "panels", "show", "cumulation", "plots", "of", "the", "reconstructed", "ip", "distances", "versus", "the", "beam", "spot", "size", ",", "for", "non", "-", "colliding", "and", "colliding", "bunches", "separately", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the upper panels", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "show", "start": 17, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "panels", "start": 10, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 17, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "bunches", "start": 133, "end": 140, "i_start": 23, "i_end": 23}, "action": {"text": "-colliding and colliding", "start": 108, "end": 132, "i_start": 19, "i_end": 22}}], "id": 4106}, {"sent": "the models reproduce the main trends of observed methane dwarfs in near-ir color-magnitude diagrams .", "tokens": ["the", "models", "reproduce", "the", "main", "trends", "of", "observed", "methane", "dwarfs", "in", "near", "-", "ir", "color", "-", "magnitude", "diagrams", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the models", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "reproduce", "start": 11, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "models", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "reproduce", "start": 11, "end": 20, "i_start": 2, "i_end": 2}}], "id": 4107}, {"sent": "in the last decade , convolutional neural networks have shown state of the art accuracy on a variety of visual recognition tasks such as image classification .", "tokens": ["in", "the", "last", "decade", ",", "convolutional", "neural", "networks", "have", "shown", "state", "of", "the", "art", "accuracy", "on", "a", "variety", "of", "visual", "recognition", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 21, "end": 50, "i_start": 5, "i_end": 7}, "verb": {"text": "have shown", "start": 51, "end": 61, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 42, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "shown", "start": 56, "end": 61, "i_start": 9, "i_end": 9}}], "id": 4108}, {"sent": "we also show the total number of tree-level and one-loop diagrams for each process in some general gauge .", "tokens": ["we", "also", "show", "the", "total", "number", "of", "tree", "-", "level", "and", "one", "-", "loop", "diagrams", "for", "each", "process", "in", "some", "general", "gauge", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}], "id": 4109}, {"sent": "for observers with large \u03b8obs the polarization degree increases with \u03b8j .", "tokens": ["for", "observers", "with", "large", "\u03b8obs", "the", "polarization", "degree", "increases", "with", "\u03b8j", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the polarization degree", "start": 30, "end": 53, "i_start": 5, "i_end": 7}, "verb": {"text": "increases", "start": 54, "end": 63, "i_start": 8, "i_end": 8}}], "id": 4110}, {"sent": "the lagrangian is a scalar under these transformations , the theory exhibits observer lorentz symmetry .", "tokens": ["the", "lagrangian", "is", "a", "scalar", "under", "these", "transformations", ",", "the", "theory", "exhibits", "observer", "lorentz", "symmetry", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the theory", "start": 57, "end": 67, "i_start": 9, "i_end": 10}, "verb": {"text": "exhibits", "start": 68, "end": 76, "i_start": 11, "i_end": 11}}, {"subject": {"text": "the theory", "start": 57, "end": 67, "i_start": 9, "i_end": 10}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "theory", "start": 61, "end": 67, "i_start": 10, "i_end": 10}, "action": {"text": "exhibits", "start": 68, "end": 76, "i_start": 11, "i_end": 11}}], "id": 4111}, {"sent": "another dominant noma category is code-domain multiplexing , including multiple access low-density spreading cdma , and so on .", "tokens": ["another", "dominant", "noma", "category", "is", "code", "-", "domain", "multiplexing", ",", "including", "multiple", "access", "low", "-", "density", "spreading", "cdma", ",", "and", "so", "on", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another dominant noma category", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "multiplexing", "start": 46, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "dominant", "start": 8, "end": 16, "i_start": 1, "i_end": 1}}], "id": 4112}, {"sent": "slavin , chemical composition and gas-to-dust mass ratio of the nearest interstellar matter , astrophys .", "tokens": ["slavin", ",", "chemical", "composition", "and", "gas", "-", "to", "-", "dust", "mass", "ratio", "of", "the", "nearest", "interstellar", "matter", ",", "astrophys", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4113}, {"sent": "recently , deep convolutional neural networks have achieved great successes in computer vision topics such as image classification .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "achieved", "great", "successes", "in", "computer", "vision", "topics", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "successes", "start": 66, "end": 75, "i_start": 9, "i_end": 9}}], "id": 4114}, {"sent": "cosmic strings are one-dimensional topological defects which may form dynamically at a symmetry breaking phase transition in the early universe .", "tokens": ["cosmic", "strings", "are", "one", "-", "dimensional", "topological", "defects", "which", "may", "form", "dynamically", "at", "a", "symmetry", "breaking", "phase", "transition", "in", "the", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}], "id": 4115}, {"sent": "theobald et al design specialized maxsat algorithms that efficiently solve mln programs of special forms .", "tokens": ["theobald", "et", "al", "design", "specialized", "maxsat", "algorithms", "that", "efficiently", "solve", "mln", "programs", "of", "special", "forms", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "theobald", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "design", "start": 15, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithms", "start": 41, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "solve", "start": 69, "end": 74, "i_start": 9, "i_end": 9}}], "id": 4116}, {"sent": "nonempty products are shown on the left , and empty products on the right .", "tokens": ["nonempty", "products", "are", "shown", "on", "the", "left", ",", "and", "empty", "products", "on", "the", "right", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "nonempty products", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "are shown", "start": 18, "end": 27, "i_start": 2, "i_end": 3}}], "id": 4117}, {"sent": "in such cases computational strategies are needed to be reviewed .", "tokens": ["in", "such", "cases", "computational", "strategies", "are", "needed", "to", "be", "reviewed", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "computational strategies", "start": 14, "end": 38, "i_start": 3, "i_end": 4}, "verb": {"text": "are needed", "start": 39, "end": 49, "i_start": 5, "i_end": 6}}], "id": 4118}, {"sent": "now let us turn to the spin polarization detection .", "tokens": ["now", "let", "us", "turn", "to", "the", "spin", "polarization", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "let", "start": 4, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "us", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "turn", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "let", "start": 4, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "us", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "turn", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}], "id": 4119}, {"sent": "this partition function can be obtained from the refined topological vertex formalism , reviewed here .", "tokens": ["this", "partition", "function", "can", "be", "obtained", "from", "the", "refined", "topological", "vertex", "formalism", ",", "reviewed", "here", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this partition function", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "can be obtained", "start": 24, "end": 39, "i_start": 3, "i_end": 5}}, {"subject": {"text": "this partition function", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "reviewed", "start": 88, "end": 96, "i_start": 13, "i_end": 13}}], "id": 4120}, {"sent": "the structure of the particular operators used in these calculations is discussed in the next section .", "tokens": ["the", "structure", "of", "the", "particular", "operators", "used", "in", "these", "calculations", "is", "discussed", "in", "the", "next", "section", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the structure of the particular operators used in these calculations", "start": 0, "end": 68, "i_start": 0, "i_end": 9}, "verb": {"text": "is discussed", "start": 69, "end": 81, "i_start": 10, "i_end": 11}}], "id": 4121}, {"sent": "if the scale of electric taxi fleet increases , the electric taxi average idle time will increase .", "tokens": ["if", "the", "scale", "of", "electric", "taxi", "fleet", "increases", ",", "the", "electric", "taxi", "average", "idle", "time", "will", "increase", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the scale of electric taxi fleet increases , the electric taxi average idle time", "start": 3, "end": 83, "i_start": 1, "i_end": 14}, "verb": {"text": "will increase", "start": 84, "end": 97, "i_start": 15, "i_end": 16}}], "id": 4122}, {"sent": "however , we show that it is possible to resolve the equations of motion for our system via the projection method .", "tokens": ["however", ",", "we", "show", "that", "it", "is", "possible", "to", "resolve", "the", "equations", "of", "motion", "for", "our", "system", "via", "the", "projection", "method", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "show", "start": 13, "end": 17, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 13, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "resolve", "start": 41, "end": 48, "i_start": 9, "i_end": 9}}], "id": 4123}, {"sent": "it contradicts the conjecture that this correction would vanish away from the orientifold point given in imply that there should be no contributions at higher loops .", "tokens": ["it", "contradicts", "the", "conjecture", "that", "this", "correction", "would", "vanish", "away", "from", "the", "orientifold", "point", "given", "in", "imply", "that", "there", "should", "be", "no", "contributions", "at", "higher", "loops", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "contradicts", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "contradicts", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "vanish", "start": 57, "end": 63, "i_start": 8, "i_end": 8}, "action": {"text": "imply", "start": 105, "end": 110, "i_start": 16, "i_end": 16}}], "id": 4124}, {"sent": "as another application , we also check the ooguri-vafa integrality conjecture for one-point functions in arbitrary framing .", "tokens": ["as", "another", "application", ",", "we", "also", "check", "the", "ooguri", "-", "vafa", "integrality", "conjecture", "for", "one", "-", "point", "functions", "in", "arbitrary", "framing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 25, "end": 27, "i_start": 4, "i_end": 4}, "verb": {"text": "check", "start": 33, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "check", "start": 33, "end": 38, "i_start": 6, "i_end": 6}}], "id": 4125}, {"sent": "newell et al proposed a stacked hourglass network which repeats downsampling and upsampling to exploit multi-scale information effectively .", "tokens": ["newell", "et", "al", "proposed", "a", "stacked", "hourglass", "network", "which", "repeats", "downsampling", "and", "upsampling", "to", "exploit", "multi", "-", "scale", "information", "effectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "newell et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "newell", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "network", "start": 42, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "repeats", "start": 56, "end": 63, "i_start": 9, "i_end": 9}}, {"character": {"text": "newell", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "exploit", "start": 95, "end": 102, "i_start": 14, "i_end": 14}}], "id": 4126}, {"sent": "in recent years , deep learning has significantly impacted numerous areas in machine learning , improving state-of-the-art results in tasks such as image recognition , speech recognition , and language translation .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "has", "significantly", "impacted", "numerous", "areas", "in", "machine", "learning", ",", "improving", "state", "-", "of", "-", "the", "-", "art", "results", "in", "tasks", "such", "as", "image", "recognition", ",", "speech", "recognition", ",", "and", "language", "translation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 18, "end": 31, "i_start": 4, "i_end": 5}, "verb": {"text": "impacted", "start": 50, "end": 58, "i_start": 8, "i_end": 8}}, {"subject": {"text": "deep learning", "start": 18, "end": 31, "i_start": 4, "i_end": 5}, "verb": {"text": "has", "start": 32, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "learning", "start": 23, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "impacted", "start": 50, "end": 58, "i_start": 8, "i_end": 8}}, {"character": {"text": "impacted", "start": 50, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "improving", "start": 96, "end": 105, "i_start": 15, "i_end": 15}}], "id": 4127}, {"sent": "the research of orbit codes with good parameters can then be restricted to this subclass of cyclic orbit codes .", "tokens": ["the", "research", "of", "orbit", "codes", "with", "good", "parameters", "can", "then", "be", "restricted", "to", "this", "subclass", "of", "cyclic", "orbit", "codes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the research of orbit codes with good parameters", "start": 0, "end": 48, "i_start": 0, "i_end": 7}, "verb": {"text": "be restricted", "start": 58, "end": 71, "i_start": 10, "i_end": 11}}, {"subject": {"text": "the research of orbit codes with good parameters", "start": 0, "end": 48, "i_start": 0, "i_end": 7}, "verb": {"text": "can", "start": 49, "end": 52, "i_start": 8, "i_end": 8}}], "id": 4128}, {"sent": "the two types of ends are called convex or concave respectively .", "tokens": ["the", "two", "types", "of", "ends", "are", "called", "convex", "or", "concave", "respectively", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the two types of ends", "start": 0, "end": 21, "i_start": 0, "i_end": 4}, "verb": {"text": "are called", "start": 22, "end": 32, "i_start": 5, "i_end": 6}}, {"subject": {"text": "the two types of ends", "start": 0, "end": 21, "i_start": 0, "i_end": 4}, "verb": {"text": "concave", "start": 43, "end": 50, "i_start": 9, "i_end": 9}}], "id": 4129}, {"sent": "hinton et al proposed the knowledge distillation approach to compress the knowledge of a large and computational expensive model to a single computational efficient neural network .", "tokens": ["hinton", "et", "al", "proposed", "the", "knowledge", "distillation", "approach", "to", "compress", "the", "knowledge", "of", "a", "large", "and", "computational", "expensive", "model", "to", "a", "single", "computational", "efficient", "neural", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hinton et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "hinton", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}], "id": 4130}, {"sent": "5the ellipsis denotes operators not relevant to the oblique precision observables 109 5 point 2 .", "tokens": ["5the", "ellipsis", "denotes", "operators", "not", "relevant", "to", "the", "oblique", "precision", "observables", "109", "5", "point", "2", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "5the ellipsis", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "denotes", "start": 14, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "ellipsis", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "denotes operators not relevant to the oblique precision observables 109 5", "start": 14, "end": 87, "i_start": 2, "i_end": 12}}], "id": 4131}, {"sent": "we use the c3d model , pre-trained on the sports-1m dataset , to extract the c3d features for representing the actions in a video .", "tokens": ["we", "use", "the", "c3d", "model", ",", "pre", "-", "trained", "on", "the", "sports-1", "m", "dataset", ",", "to", "extract", "the", "c3d", "features", "for", "representing", "the", "actions", "in", "a", "video", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extract", "start": 65, "end": 72, "i_start": 16, "i_end": 16}}, {"character": {"text": "model", "start": 15, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "representing", "start": 94, "end": 106, "i_start": 21, "i_end": 21}}], "id": 4132}, {"sent": "more importantly , while divergent parts of the radial and azimuthal electric field components are generated by the local charge density , the divergent part of the axial component is generated by the local dipole density .", "tokens": ["more", "importantly", ",", "while", "divergent", "parts", "of", "the", "radial", "and", "azimuthal", "electric", "field", "components", "are", "generated", "by", "the", "local", "charge", "density", ",", "the", "divergent", "part", "of", "the", "axial", "component", "is", "generated", "by", "the", "local", "dipole", "density", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "the divergent part of the axial component", "start": 139, "end": 180, "i_start": 22, "i_end": 28}, "verb": {"text": "is generated", "start": 181, "end": 193, "i_start": 29, "i_end": 30}}, {"character": {"text": "density", "start": 129, "end": 136, "i_start": 20, "i_end": 20}, "action": {"text": "generated", "start": 99, "end": 108, "i_start": 15, "i_end": 15}}, {"character": {"text": "density", "start": 129, "end": 136, "i_start": 20, "i_end": 20}, "action": {"text": "generated", "start": 184, "end": 193, "i_start": 30, "i_end": 30}}], "id": 4133}, {"sent": "according to the method of asymptotic splittings , 3 we proceed to construct series expansions which are local solutions around movable singularities .", "tokens": ["according", "to", "the", "method", "of", "asymptotic", "splittings", ",", "3", "we", "proceed", "to", "construct", "series", "expansions", "which", "are", "local", "solutions", "around", "movable", "singularities", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 53, "end": 55, "i_start": 9, "i_end": 9}, "verb": {"text": "proceed", "start": 56, "end": 63, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 53, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "3 we proceed", "start": 51, "end": 63, "i_start": 8, "i_end": 10}}, {"character": {"text": "we", "start": 53, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "construct", "start": 67, "end": 76, "i_start": 12, "i_end": 12}}], "id": 4134}, {"sent": "deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification among many others .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "already", "achieved", "tremendous", "success", "on", "a", "variety", "of", "computer", "vision", "tasks", "such", "as", "image", "classification", "among", "many", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "achieved", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 68, "end": 75, "i_start": 8, "i_end": 8}}], "id": 4135}, {"sent": "we also add batch normalization layers after every couple of convolutional layers .", "tokens": ["we", "also", "add", "batch", "normalization", "layers", "after", "every", "couple", "of", "convolutional", "layers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "add", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "add", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}], "id": 4136}, {"sent": "our achievability scheme is the secret superposition of gaussian codes .", "tokens": ["our", "achievability", "scheme", "is", "the", "secret", "superposition", "of", "gaussian", "codes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our achievability scheme", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 3, "i_end": 3}}], "id": 4137}, {"sent": "overlaid is the simple line fit discussed in the text .", "tokens": ["overlaid", "is", "the", "simple", "line", "fit", "discussed", "in", "the", "text", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4138}, {"sent": "if the diffeomorphisms \u03c8t are generated by a vector field x on m , then the soliton is called gradient soliton and f is called the potential of the soliton .", "tokens": ["if", "the", "diffeomorphisms", "\u03c8t", "are", "generated", "by", "a", "vector", "field", "x", "on", "m", ",", "then", "the", "soliton", "is", "called", "gradient", "soliton", "and", "f", "is", "called", "the", "potential", "of", "the", "soliton", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the soliton", "start": 72, "end": 83, "i_start": 15, "i_end": 16}, "verb": {"text": "is called", "start": 84, "end": 93, "i_start": 17, "i_end": 18}}, {"character": {"text": "field", "start": 52, "end": 57, "i_start": 9, "i_end": 9}, "action": {"text": "generated", "start": 30, "end": 39, "i_start": 5, "i_end": 5}}], "id": 4139}, {"sent": "the ordinate is the binary fraction for all objects with projected radius less than the value on the abscissa .", "tokens": ["the", "ordinate", "is", "the", "binary", "fraction", "for", "all", "objects", "with", "projected", "radius", "less", "than", "the", "value", "on", "the", "abscissa", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ordinate", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 4140}, {"sent": "over the past few years , deep neural networks have driven advances in many practical problems , such as image classification .", "tokens": ["over", "the", "past", "few", "years", ",", "deep", "neural", "networks", "have", "driven", "advances", "in", "many", "practical", "problems", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 26, "end": 46, "i_start": 6, "i_end": 8}, "verb": {"text": "have driven", "start": 47, "end": 58, "i_start": 9, "i_end": 10}}, {"character": {"text": "networks", "start": 38, "end": 46, "i_start": 8, "i_end": 8}, "action": {"text": "driven", "start": 52, "end": 58, "i_start": 10, "i_end": 10}}], "id": 4141}, {"sent": "the symbols indicate the rank of the microstructure at the gauss points .", "tokens": ["the", "symbols", "indicate", "the", "rank", "of", "the", "microstructure", "at", "the", "gauss", "points", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the symbols", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "indicate", "start": 12, "end": 20, "i_start": 2, "i_end": 2}}], "id": 4142}, {"sent": "the fact that moderated chat rooms can not always be made available does not mean unmoderated ones should close .", "tokens": ["the", "fact", "that", "moderated", "chat", "rooms", "can", "not", "always", "be", "made", "available", "does", "not", "mean", "unmoderated", "ones", "should", "close", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the fact that moderated chat rooms can not always be made available", "start": 0, "end": 67, "i_start": 0, "i_end": 11}, "verb": {"text": "does not mean", "start": 68, "end": 81, "i_start": 12, "i_end": 14}}, {"subject": {"text": "unmoderated ones", "start": 82, "end": 98, "i_start": 15, "i_end": 16}, "verb": {"text": "close", "start": 106, "end": 111, "i_start": 18, "i_end": 18}}], "id": 4143}, {"sent": "in small spin polarized regime , the hot-electron effect tends to enhance the sdt as the increase of the scattering rate reduces the inhomogeneous broadening .", "tokens": ["in", "small", "spin", "polarized", "regime", ",", "the", "hot", "-", "electron", "effect", "tends", "to", "enhance", "the", "sdt", "as", "the", "increase", "of", "the", "scattering", "rate", "reduces", "the", "inhomogeneous", "broadening", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the hot-electron effect", "start": 33, "end": 56, "i_start": 6, "i_end": 10}, "verb": {"text": "tends", "start": 57, "end": 62, "i_start": 11, "i_end": 11}}, {"subject": {"text": "the hot-electron effect", "start": 33, "end": 56, "i_start": 6, "i_end": 10}, "verb": {"text": "reduces", "start": 121, "end": 128, "i_start": 23, "i_end": 23}}, {"character": {"text": "electron", "start": 41, "end": 49, "i_start": 9, "i_end": 9}, "action": {"text": "effect", "start": 50, "end": 56, "i_start": 10, "i_end": 10}}, {"character": {"text": "effect", "start": 50, "end": 56, "i_start": 10, "i_end": 10}, "action": {"text": "enhance", "start": 66, "end": 73, "i_start": 13, "i_end": 13}}, {"character": {"text": "increase", "start": 89, "end": 97, "i_start": 18, "i_end": 18}, "action": {"text": "reduces", "start": 121, "end": 128, "i_start": 23, "i_end": 23}}], "id": 4144}, {"sent": "presumably , they correspond to de sitter-invariant states on the elliptically identified space .", "tokens": ["presumably", ",", "they", "correspond", "to", "de", "sitter", "-", "invariant", "states", "on", "the", "elliptically", "identified", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 13, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "correspond", "start": 18, "end": 28, "i_start": 3, "i_end": 3}}], "id": 4145}, {"sent": "let us quickly recall the definition of a vertex algebra following , .", "tokens": ["let", "us", "quickly", "recall", "the", "definition", "of", "a", "vertex", "algebra", "following", ",", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "recall", "start": 15, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "recall", "start": 15, "end": 21, "i_start": 3, "i_end": 3}}], "id": 4146}, {"sent": "in recent years , many centralized power and spectrum allocation schemes have been studied in cellular and multihop wireless networks .", "tokens": ["in", "recent", "years", ",", "many", "centralized", "power", "and", "spectrum", "allocation", "schemes", "have", "been", "studied", "in", "cellular", "and", "multihop", "wireless", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many centralized power and spectrum allocation schemes", "start": 18, "end": 72, "i_start": 4, "i_end": 10}, "verb": {"text": "have been studied", "start": 73, "end": 90, "i_start": 11, "i_end": 13}}], "id": 4147}, {"sent": "a left g-space is a manifold e equipped with an action by g .", "tokens": ["a", "left", "g", "-", "space", "is", "a", "manifold", "e", "equipped", "with", "an", "action", "by", "g", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a left g-space", "start": 0, "end": 14, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 5, "i_end": 5}}], "id": 4148}, {"sent": "with the rapid development of deep convolutional neural networks , the performance of object detection has been significantly improved .", "tokens": ["with", "the", "rapid", "development", "of", "deep", "convolutional", "neural", "networks", ",", "the", "performance", "of", "object", "detection", "has", "been", "significantly", "improved", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the performance of object detection", "start": 67, "end": 102, "i_start": 10, "i_end": 14}, "verb": {"text": "improved", "start": 126, "end": 134, "i_start": 18, "i_end": 18}}, {"subject": {"text": "the performance of object detection", "start": 67, "end": 102, "i_start": 10, "i_end": 14}, "verb": {"text": "has been", "start": 103, "end": 111, "i_start": 15, "i_end": 16}}], "id": 4149}, {"sent": "in proceedings of the rocky mountain conference on arti cial intel ligence , pp .", "tokens": ["in", "proceedings", "of", "the", "rocky", "mountain", "conference", "on", "arti", "cial", "intel", "ligence", ",", "pp", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4150}, {"sent": "training is done using the adam optimizer with a mini-batch size of 16 for 200 runs with 8192 training samples each .", "tokens": ["training", "is", "done", "using", "the", "adam", "optimizer", "with", "a", "mini", "-", "batch", "size", "of", "16", "for", "200", "runs", "with", "8192", "training", "samples", "each", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "training", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is done", "start": 9, "end": 16, "i_start": 1, "i_end": 2}}], "id": 4151}, {"sent": "we will also assume that the transition is instantaneous and that the pressure within the cocoon is uniform .", "tokens": ["we", "will", "also", "assume", "that", "the", "transition", "is", "instantaneous", "and", "that", "the", "pressure", "within", "the", "cocoon", "is", "uniform", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assume", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 40, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assume", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}], "id": 4152}, {"sent": "so , these solutions are not compatible with an ingoing condition .", "tokens": ["so", ",", "these", "solutions", "are", "not", "compatible", "with", "an", "ingoing", "condition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these solutions", "start": 5, "end": 20, "i_start": 2, "i_end": 3}, "verb": {"text": "are not", "start": 21, "end": 28, "i_start": 4, "i_end": 5}}], "id": 4153}, {"sent": "for more details concerning the theory of time scales we refer to the books .", "tokens": ["for", "more", "details", "concerning", "the", "theory", "of", "time", "scales", "we", "refer", "to", "the", "books", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 54, "end": 56, "i_start": 9, "i_end": 9}, "action": {"text": "refer", "start": 57, "end": 62, "i_start": 10, "i_end": 10}}], "id": 4154}, {"sent": "convolutional neural networks have recently achieved great success on various visual recognition tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "achieved", "great", "success", "on", "various", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 7, "i_end": 7}}], "id": 4155}, {"sent": "this result with no doubt generalizes to higher-dimensional cocompact lattices in simple lie groups of rank one .", "tokens": ["this", "result", "with", "no", "doubt", "generalizes", "to", "higher", "-", "dimensional", "cocompact", "lattices", "in", "simple", "lie", "groups", "of", "rank", "one", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this result with no doubt", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "generalizes", "start": 26, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "result", "start": 5, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "generalizes", "start": 26, "end": 37, "i_start": 5, "i_end": 5}}], "id": 4156}, {"sent": "as shown by taylor , the strict topology coincides with the so-called bounded strict topology -the strongest locally convex topology that agrees with the strict topology on norm-bounded sets .", "tokens": ["as", "shown", "by", "taylor", ",", "the", "strict", "topology", "coincides", "with", "the", "so", "-", "called", "bounded", "strict", "topology", "-the", "strongest", "locally", "convex", "topology", "that", "agrees", "with", "the", "strict", "topology", "on", "norm", "-", "bounded", "sets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the strict topology", "start": 21, "end": 40, "i_start": 5, "i_end": 7}, "verb": {"text": "coincides", "start": 41, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "topology", "start": 124, "end": 132, "i_start": 21, "i_end": 21}, "action": {"text": "agrees", "start": 138, "end": 144, "i_start": 23, "i_end": 23}}], "id": 4157}, {"sent": "one possible approach , albeit beyond the scope of our considerations here , is to use adaptive aggregations based on a posteriori error estimates on graphs as proposed in .", "tokens": ["one", "possible", "approach", ",", "albeit", "beyond", "the", "scope", "of", "our", "considerations", "here", ",", "is", "to", "use", "adaptive", "aggregations", "based", "on", "a", "posteriori", "error", "estimates", "on", "graphs", "as", "proposed", "in", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "one possible approach", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 77, "end": 79, "i_start": 13, "i_end": 13}}], "id": 4158}, {"sent": "in contrast , specialized dl accelerators such as the tpu usually favor leaner control with a decoupled access-execute architecture and offload the problem of fine-grained synchronization to software .", "tokens": ["in", "contrast", ",", "specialized", "dl", "accelerators", "such", "as", "the", "tpu", "usually", "favor", "leaner", "control", "with", "a", "decoupled", "access", "-", "execute", "architecture", "and", "offload", "the", "problem", "of", "fine", "-", "grained", "synchronization", "to", "software", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "specialized dl accelerators such as the tpu", "start": 14, "end": 57, "i_start": 3, "i_end": 9}, "verb": {"text": "favor", "start": 66, "end": 71, "i_start": 11, "i_end": 11}}], "id": 4159}, {"sent": "now we proceed onto define the sesqui linear superform .", "tokens": ["now", "we", "proceed", "onto", "define", "the", "sesqui", "linear", "superform", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 20, "end": 26, "i_start": 4, "i_end": 4}}], "id": 4160}, {"sent": "the lattice boltzmann method has now been established as a powerful kinetic scheme based computational fluid dynamics approach .", "tokens": ["the", "lattice", "boltzmann", "method", "has", "now", "been", "established", "as", "a", "powerful", "kinetic", "scheme", "based", "computational", "fluid", "dynamics", "approach", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lattice boltzmann method", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "been established", "start": 37, "end": 53, "i_start": 6, "i_end": 7}}, {"subject": {"text": "the lattice boltzmann method", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "has", "start": 29, "end": 32, "i_start": 4, "i_end": 4}}], "id": 4161}, {"sent": "the adiabatic approximation thus fails for coulomb-dominated reactions .", "tokens": ["the", "adiabatic", "approximation", "thus", "fails", "for", "coulomb", "-", "dominated", "reactions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the adiabatic approximation", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "fails", "start": 33, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "coulomb", "start": 43, "end": 50, "i_start": 6, "i_end": 6}, "action": {"text": "dominated", "start": 51, "end": 60, "i_start": 8, "i_end": 8}}], "id": 4162}, {"sent": "however , in the quantum theory , it appears explicitly in the spectra of the geometric operators .", "tokens": ["however", ",", "in", "the", "quantum", "theory", ",", "it", "appears", "explicitly", "in", "the", "spectra", "of", "the", "geometric", "operators", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 34, "end": 36, "i_start": 7, "i_end": 7}, "verb": {"text": "appears", "start": 37, "end": 44, "i_start": 8, "i_end": 8}}], "id": 4163}, {"sent": "the notation used here is exactly the same as the notation for .", "tokens": ["the", "notation", "used", "here", "is", "exactly", "the", "same", "as", "the", "notation", "for", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the notation used here", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 4, "i_end": 4}}], "id": 4164}, {"sent": "the topological dynamical system associated to x is defined analogously to tiling dynamical systems , for which see .", "tokens": ["the", "topological", "dynamical", "system", "associated", "to", "x", "is", "defined", "analogously", "to", "tiling", "dynamical", "systems", ",", "for", "which", "see", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the topological dynamical system associated to x", "start": 0, "end": 48, "i_start": 0, "i_end": 6}, "verb": {"text": "is defined", "start": 49, "end": 59, "i_start": 7, "i_end": 8}}], "id": 4165}, {"sent": "unfortunately , no exact chaotic solutions have been reported .", "tokens": ["unfortunately", ",", "no", "exact", "chaotic", "solutions", "have", "been", "reported", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "no exact chaotic solutions", "start": 16, "end": 42, "i_start": 2, "i_end": 5}, "verb": {"text": "have been reported", "start": 43, "end": 61, "i_start": 6, "i_end": 8}}], "id": 4166}, {"sent": "in the literature , numerous attempts to protect privacy have followed the traditional method of anonymous communications , which is fundamentally based on the suppositions of soft privacy .", "tokens": ["in", "the", "literature", ",", "numerous", "attempts", "to", "protect", "privacy", "have", "followed", "the", "traditional", "method", "of", "anonymous", "communications", ",", "which", "is", "fundamentally", "based", "on", "the", "suppositions", "of", "soft", "privacy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "numerous attempts to protect privacy", "start": 20, "end": 56, "i_start": 4, "i_end": 8}, "verb": {"text": "have followed", "start": 57, "end": 70, "i_start": 9, "i_end": 10}}, {"character": {"text": "attempts", "start": 29, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "followed", "start": 62, "end": 70, "i_start": 10, "i_end": 10}}], "id": 4167}, {"sent": "while many of those models achieve acceptable uncertainty estimates , they are notoriously slow to train and evaluate which makes them nonviable for real-world implementation .", "tokens": ["while", "many", "of", "those", "models", "achieve", "acceptable", "uncertainty", "estimates", ",", "they", "are", "notoriously", "slow", "to", "train", "and", "evaluate", "which", "makes", "them", "nonviable", "for", "real", "-", "world", "implementation", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "they", "start": 70, "end": 74, "i_start": 10, "i_end": 10}, "verb": {"text": "are", "start": 75, "end": 78, "i_start": 11, "i_end": 11}}, {"character": {"text": "models", "start": 20, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "achieve", "start": 27, "end": 34, "i_start": 5, "i_end": 5}}], "id": 4168}, {"sent": "the connected totally geodesic subgraphs are the complete subgraphs .", "tokens": ["the", "connected", "totally", "geodesic", "subgraphs", "are", "the", "complete", "subgraphs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the connected totally geodesic subgraphs", "start": 0, "end": 40, "i_start": 0, "i_end": 4}, "verb": {"text": "are", "start": 41, "end": 44, "i_start": 5, "i_end": 5}}], "id": 4169}, {"sent": "the wightman function is also important in consideration of the response of particle detectors at a given state of motion .", "tokens": ["the", "wightman", "function", "is", "also", "important", "in", "consideration", "of", "the", "response", "of", "particle", "detectors", "at", "a", "given", "state", "of", "motion", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the wightman function", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 4170}, {"sent": "deep convolutional neural networks have shown promising performances on various computer vision problems such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "shown", "promising", "performances", "on", "various", "computer", "vision", "problems", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have shown", "start": 35, "end": 45, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 40, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performances", "start": 56, "end": 68, "i_start": 7, "i_end": 7}}, {"character": {"text": "performances", "start": 56, "end": 68, "i_start": 7, "i_end": 7}, "action": {"text": "promising", "start": 46, "end": 55, "i_start": 6, "i_end": 6}}], "id": 4171}, {"sent": "latin indices denote nearest-neighbor sites on square lattice .", "tokens": ["latin", "indices", "denote", "nearest", "-", "neighbor", "sites", "on", "square", "lattice", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "indices", "start": 6, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 14, "end": 20, "i_start": 2, "i_end": 2}}], "id": 4172}, {"sent": "the widely accepted mechanism for the evolution of growing scale-free networks is preferential attachment .", "tokens": ["the", "widely", "accepted", "mechanism", "for", "the", "evolution", "of", "growing", "scale", "-", "free", "networks", "is", "preferential", "attachment", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the widely accepted mechanism for the evolution of growing scale-free networks", "start": 0, "end": 78, "i_start": 0, "i_end": 12}, "verb": {"text": "is", "start": 79, "end": 81, "i_start": 13, "i_end": 13}}], "id": 4173}, {"sent": "machine learning models are widely deployed in various applications such as image classification .", "tokens": ["machine", "learning", "models", "are", "widely", "deployed", "in", "various", "applications", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "machine learning models", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "deployed", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"subject": {"text": "machine learning models", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 24, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 17, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "learning", "start": 8, "end": 16, "i_start": 1, "i_end": 1}}], "id": 4174}, {"sent": "in their seminal work , barles and souganidis proved a convergence theorem for monotone numerical schemes for viscosity solutions of fully nonlinear pdes .", "tokens": ["in", "their", "seminal", "work", ",", "barles", "and", "souganidis", "proved", "a", "convergence", "theorem", "for", "monotone", "numerical", "schemes", "for", "viscosity", "solutions", "of", "fully", "nonlinear", "pdes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "barles and souganidis", "start": 24, "end": 45, "i_start": 5, "i_end": 7}, "verb": {"text": "proved", "start": 46, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "barles", "start": 24, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "proved", "start": 46, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "souganidis", "start": 35, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "proved", "start": 46, "end": 52, "i_start": 8, "i_end": 8}}], "id": 4175}, {"sent": "recurrent neural networks have received renewed interest due to their recent success in various domains , including speech recognition .", "tokens": ["recurrent", "neural", "networks", "have", "received", "renewed", "interest", "due", "to", "their", "recent", "success", "in", "various", "domains", ",", "including", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recurrent neural networks", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "have received", "start": 26, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 17, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "received", "start": 31, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 17, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 77, "end": 84, "i_start": 11, "i_end": 11}}], "id": 4176}, {"sent": "because oxygen is the most abundant member of the cno trio , even a relatively modest depletion will measurably increase the nitrogen abundance .", "tokens": ["because", "oxygen", "is", "the", "most", "abundant", "member", "of", "the", "cno", "trio", ",", "even", "a", "relatively", "modest", "depletion", "will", "measurably", "increase", "the", "nitrogen", "abundance", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "even a relatively modest depletion", "start": 61, "end": 95, "i_start": 12, "i_end": 16}, "verb": {"text": "increase", "start": 112, "end": 120, "i_start": 19, "i_end": 19}}, {"subject": {"text": "even a relatively modest depletion", "start": 61, "end": 95, "i_start": 12, "i_end": 16}, "verb": {"text": "will", "start": 96, "end": 100, "i_start": 17, "i_end": 17}}, {"character": {"text": "depletion", "start": 86, "end": 95, "i_start": 16, "i_end": 16}, "action": {"text": "increase", "start": 112, "end": 120, "i_start": 19, "i_end": 19}}], "id": 4177}, {"sent": "in recent years , deep learning techniques have achieved profound breakthroughs in many computer vision applications , including the classification of natural and medical images .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "techniques", "have", "achieved", "profound", "breakthroughs", "in", "many", "computer", "vision", "applications", ",", "including", "the", "classification", "of", "natural", "and", "medical", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning techniques", "start": 18, "end": 42, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 43, "end": 56, "i_start": 7, "i_end": 8}}, {"character": {"text": "techniques", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 48, "end": 56, "i_start": 8, "i_end": 8}}, {"character": {"text": "techniques", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "breakthroughs", "start": 66, "end": 79, "i_start": 10, "i_end": 10}}], "id": 4178}, {"sent": "the third auxiliary result we need is a refinement of the existence theorem for formal models for morphisms of derived analytic spaces proven in .", "tokens": ["the", "third", "auxiliary", "result", "we", "need", "is", "a", "refinement", "of", "the", "existence", "theorem", "for", "formal", "models", "for", "morphisms", "of", "derived", "analytic", "spaces", "proven", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the third auxiliary result we need", "start": 0, "end": 34, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 6, "i_end": 6}}], "id": 4179}, {"sent": "the median value of the variables are quoted in the frames .", "tokens": ["the", "median", "value", "of", "the", "variables", "are", "quoted", "in", "the", "frames", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the median value of the variables", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "are quoted", "start": 34, "end": 44, "i_start": 6, "i_end": 7}}], "id": 4180}, {"sent": "what emerges is a simple , unified description of the complex phenomena of radar observations .", "tokens": ["what", "emerges", "is", "a", "simple", ",", "unified", "description", "of", "the", "complex", "phenomena", "of", "radar", "observations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "what emerges", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "description", "start": 35, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "emerges", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}], "id": 4181}, {"sent": "recent advances in deep learning have revolutionized the application of machine learning in areas such as computer vision , speech recognition and natural language processing .", "tokens": ["recent", "advances", "in", "deep", "learning", "have", "revolutionized", "the", "application", "of", "machine", "learning", "in", "areas", "such", "as", "computer", "vision", ",", "speech", "recognition", "and", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent advances in deep learning", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "have revolutionized", "start": 33, "end": 52, "i_start": 5, "i_end": 6}}, {"character": {"text": "advances", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "revolutionized", "start": 38, "end": 52, "i_start": 6, "i_end": 6}}], "id": 4182}, {"sent": "deep learning has been successfully applied to many computer vision problems including segmentation .", "tokens": ["deep", "learning", "has", "been", "successfully", "applied", "to", "many", "computer", "vision", "problems", "including", "segmentation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "applied", "start": 36, "end": 43, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has been", "start": 14, "end": 22, "i_start": 2, "i_end": 3}}], "id": 4183}, {"sent": "convolutional neural networks provide state-of-the-art results for many machine learning challenges , such as image classification .", "tokens": ["convolutional", "neural", "networks", "provide", "state", "-", "of", "-", "the", "-", "art", "results", "for", "many", "machine", "learning", "challenges", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "provide", "start": 30, "end": 37, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "provide", "start": 30, "end": 37, "i_start": 3, "i_end": 3}}], "id": 4184}, {"sent": "then the einstein-maxwell horizon geometry consists of the quadruplet .", "tokens": ["then", "the", "einstein", "-", "maxwell", "horizon", "geometry", "consists", "of", "the", "quadruplet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the einstein-maxwell horizon geometry", "start": 5, "end": 42, "i_start": 1, "i_end": 6}, "verb": {"text": "consists", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}], "id": 4185}, {"sent": "more precisely , the inflaton is the volume modulus and inflation takes place at a high scale for small values 1015 , thus of obtaining tev scale susy .", "tokens": ["more", "precisely", ",", "the", "inflaton", "is", "the", "volume", "modulus", "and", "inflation", "takes", "place", "at", "a", "high", "scale", "for", "small", "values", "1015", ",", "thus", "of", "obtaining", "tev", "scale", "susy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the inflaton", "start": 17, "end": 29, "i_start": 3, "i_end": 4}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the volume modulus and inflation", "start": 33, "end": 65, "i_start": 6, "i_end": 10}, "verb": {"text": "takes", "start": 66, "end": 71, "i_start": 11, "i_end": 11}}], "id": 4186}, {"sent": "since the neutralino is a majorana particle , it will self-annihilate at a rate proportional to the square of neutralino density .", "tokens": ["since", "the", "neutralino", "is", "a", "majorana", "particle", ",", "it", "will", "self", "-", "annihilate", "at", "a", "rate", "proportional", "to", "the", "square", "of", "neutralino", "density", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "neutralino", "start": 10, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "annihilate", "start": 59, "end": 69, "i_start": 12, "i_end": 12}}], "id": 4187}, {"sent": "we also assume the reader is familiar with computational complexity , both classical .", "tokens": ["we", "also", "assume", "the", "reader", "is", "familiar", "with", "computational", "complexity", ",", "both", "classical", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assume", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assume", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}], "id": 4188}, {"sent": "in recent years , convolutional neural networks have demonstrated the state-of-the-art performance in visual recognition tasks .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "demonstrated", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have demonstrated", "start": 48, "end": 65, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "demonstrated", "start": 53, "end": 65, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 87, "end": 98, "i_start": 17, "i_end": 17}}], "id": 4189}, {"sent": "by , an even order symmetric tensor is positive semi-definite if and only if it has no negative h-eigenvalues .", "tokens": ["by", ",", "an", "even", "order", "symmetric", "tensor", "is", "positive", "semi", "-", "definite", "if", "and", "only", "if", "it", "has", "no", "negative", "h", "-", "eigenvalues", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "an even order symmetric tensor", "start": 5, "end": 35, "i_start": 2, "i_end": 6}, "verb": {"text": "is", "start": 36, "end": 38, "i_start": 7, "i_end": 7}}, {"character": {"text": "tensor", "start": 29, "end": 35, "i_start": 6, "i_end": 6}, "action": {"text": "-definite if and only if it has", "start": 52, "end": 83, "i_start": 10, "i_end": 17}}], "id": 4190}, {"sent": "then the set of equivalence classes is a modular partition .", "tokens": ["then", "the", "set", "of", "equivalence", "classes", "is", "a", "modular", "partition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the set of equivalence classes", "start": 5, "end": 35, "i_start": 1, "i_end": 5}, "verb": {"text": "is", "start": 36, "end": 38, "i_start": 6, "i_end": 6}}], "id": 4191}, {"sent": "convolution-based deep neural networks have performed exceedingly well on 2d representation learning tasks .", "tokens": ["convolution", "-", "based", "deep", "neural", "networks", "have", "performed", "exceedingly", "well", "on", "2d", "representation", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolution-based deep neural networks", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "have performed", "start": 39, "end": 53, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "performed", "start": 44, "end": 53, "i_start": 7, "i_end": 7}}], "id": 4192}, {"sent": "the millimeter wave bands -roughly corresponding to frequencies above 10 ghz -are a new frontier for cellular wireless communications .", "tokens": ["the", "millimeter", "wave", "bands", "-roughly", "corresponding", "to", "frequencies", "above", "10", "ghz", "-are", "a", "new", "frontier", "for", "cellular", "wireless", "communications", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4193}, {"sent": "cluster algebras were introduced by fomin and zelevinsky in order to construct a model for dual canonical bases in semisimple groups .", "tokens": ["cluster", "algebras", "were", "introduced", "by", "fomin", "and", "zelevinsky", "in", "order", "to", "construct", "a", "model", "for", "dual", "canonical", "bases", "in", "semisimple", "groups", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were introduced", "start": 17, "end": 32, "i_start": 2, "i_end": 3}}, {"character": {"text": "fomin", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "zelevinsky", "start": 46, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "fomin", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "construct", "start": 69, "end": 78, "i_start": 11, "i_end": 11}}, {"character": {"text": "zelevinsky", "start": 46, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "construct", "start": 69, "end": 78, "i_start": 11, "i_end": 11}}], "id": 4194}, {"sent": "as we show below , this theory has the color-flavor locked z n center symmetry , so it is called z n -qcd .", "tokens": ["as", "we", "show", "below", ",", "this", "theory", "has", "the", "color", "-", "flavor", "locked", "z", "n", "center", "symmetry", ",", "so", "it", "is", "called", "z", "n", "-qcd", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this theory", "start": 19, "end": 30, "i_start": 5, "i_end": 6}, "verb": {"text": "has", "start": 31, "end": 34, "i_start": 7, "i_end": 7}}, {"subject": {"text": "it", "start": 84, "end": 86, "i_start": 19, "i_end": 19}, "verb": {"text": "called", "start": 90, "end": 96, "i_start": 21, "i_end": 21}}, {"character": {"text": "we", "start": 3, "end": 5, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 6, "end": 10, "i_start": 2, "i_end": 2}}, {"character": {"text": "theory", "start": 24, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "has", "start": 31, "end": 34, "i_start": 7, "i_end": 7}}], "id": 4195}, {"sent": "we shall explore this feature more closely in the next section .", "tokens": ["we", "shall", "explore", "this", "feature", "more", "closely", "in", "the", "next", "section", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "shall explore", "start": 3, "end": 16, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "explore", "start": 9, "end": 16, "i_start": 2, "i_end": 2}}], "id": 4196}, {"sent": "the em algorithm is widely used to learn maximum likelihood parameter estimates for complex probabilistic models .", "tokens": ["the", "em", "algorithm", "is", "widely", "used", "to", "learn", "maximum", "likelihood", "parameter", "estimates", "for", "complex", "probabilistic", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the em algorithm", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 27, "end": 31, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the em algorithm", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 4197}, {"sent": "to account for the exchange-correlation potential we have used the generalized gradient approximation as formulated by perdew , burke and ernzerhof .", "tokens": ["to", "account", "for", "the", "exchange", "-", "correlation", "potential", "we", "have", "used", "the", "generalized", "gradient", "approximation", "as", "formulated", "by", "perdew", ",", "burke", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 50, "end": 52, "i_start": 8, "i_end": 8}, "action": {"text": "used", "start": 58, "end": 62, "i_start": 10, "i_end": 10}}, {"character": {"text": "perdew", "start": 119, "end": 125, "i_start": 18, "i_end": 18}, "action": {"text": "formulated", "start": 105, "end": 115, "i_start": 16, "i_end": 16}}, {"character": {"text": "burke", "start": 128, "end": 133, "i_start": 20, "i_end": 20}, "action": {"text": "formulated", "start": 105, "end": 115, "i_start": 16, "i_end": 16}}, {"character": {"text": "ernzerhof", "start": 138, "end": 147, "i_start": 22, "i_end": 22}, "action": {"text": "formulated", "start": 105, "end": 115, "i_start": 16, "i_end": 16}}], "id": 4198}, {"sent": "cluster algebras were introduced by fomin-zelevinsky in a series of four articles to give an algebraic framework for the study of total positivity and dual canonical bases in lie theory .", "tokens": ["cluster", "algebras", "were", "introduced", "by", "fomin", "-", "zelevinsky", "in", "a", "series", "of", "four", "articles", "to", "give", "an", "algebraic", "framework", "for", "the", "study", "of", "total", "positivity", "and", "dual", "canonical", "bases", "in", "lie", "theory", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were introduced", "start": 17, "end": 32, "i_start": 2, "i_end": 3}}, {"character": {"text": "fomin", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "fomin", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "give", "start": 85, "end": 89, "i_start": 15, "i_end": 15}}], "id": 4199}, {"sent": "so , each clockwise packing reduces the number of remaining flows to be packed by at least one .", "tokens": ["so", ",", "each", "clockwise", "packing", "reduces", "the", "number", "of", "remaining", "flows", "to", "be", "packed", "by", "at", "least", "one", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "each clockwise packing", "start": 5, "end": 27, "i_start": 2, "i_end": 4}, "verb": {"text": "reduces", "start": 28, "end": 35, "i_start": 5, "i_end": 5}}, {"character": {"text": "packed", "start": 72, "end": 78, "i_start": 13, "i_end": 13}, "action": {"text": "reduces", "start": 28, "end": 35, "i_start": 5, "i_end": 5}}], "id": 4200}, {"sent": "the inflaton is the field corresponding to the position of a probe 3-brane , which moves in the internal compact space .", "tokens": ["the", "inflaton", "is", "the", "field", "corresponding", "to", "the", "position", "of", "a", "probe", "3", "-", "brane", ",", "which", "moves", "in", "the", "internal", "compact", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the inflaton", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 4201}, {"sent": "from the analytical expression of the solution of the ladder sd equation , we identify the form of the leading mass correction to the hyperscaling relation .", "tokens": ["from", "the", "analytical", "expression", "of", "the", "solution", "of", "the", "ladder", "sd", "equation", ",", "we", "identify", "the", "form", "of", "the", "leading", "mass", "correction", "to", "the", "hyperscaling", "relation", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 75, "end": 77, "i_start": 13, "i_end": 13}, "verb": {"text": "identify", "start": 78, "end": 86, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 75, "end": 77, "i_start": 13, "i_end": 13}, "action": {"text": "identify", "start": 78, "end": 86, "i_start": 14, "i_end": 14}}, {"character": {"text": "correction", "start": 116, "end": 126, "i_start": 21, "i_end": 21}, "action": {"text": "leading", "start": 103, "end": 110, "i_start": 19, "i_end": 19}}], "id": 4202}, {"sent": "we implement our kpm hourglass network based on the resnet-50 , which is pretrained on the imagenet dataset .", "tokens": ["we", "implement", "our", "kpm", "hourglass", "network", "based", "on", "the", "resnet-50", ",", "which", "is", "pretrained", "on", "the", "imagenet", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}], "id": 4203}, {"sent": "so far we have discussed the two point correlation function of eq .", "tokens": ["so", "far", "we", "have", "discussed", "the", "two", "point", "correlation", "function", "of", "eq", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "have discussed", "start": 10, "end": 24, "i_start": 3, "i_end": 4}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "discussed", "start": 15, "end": 24, "i_start": 4, "i_end": 4}}], "id": 4204}, {"sent": "convolutional neural networks have seen tremendous success across different problems including image classification .", "tokens": ["convolutional", "neural", "networks", "have", "seen", "tremendous", "success", "across", "different", "problems", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have seen", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "seen", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 51, "end": 58, "i_start": 6, "i_end": 6}}], "id": 4205}, {"sent": "deep learning has shown great success in a variety of tasks in image classification .", "tokens": ["deep", "learning", "has", "shown", "great", "success", "in", "a", "variety", "of", "tasks", "in", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has shown", "start": 14, "end": 23, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "success", "start": 30, "end": 37, "i_start": 5, "i_end": 5}}], "id": 4206}, {"sent": "the wiretap channel , introduced by wyner , represents a channel model where a user wants to communicate a message to its legitimate receiver , without leaking information to an eavesdropper .", "tokens": ["the", "wiretap", "channel", ",", "introduced", "by", "wyner", ",", "represents", "a", "channel", "model", "where", "a", "user", "wants", "to", "communicate", "a", "message", "to", "its", "legitimate", "receiver", ",", "without", "leaking", "information", "to", "an", "eavesdropper", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the wiretap channel", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "represents", "start": 44, "end": 54, "i_start": 8, "i_end": 8}}, {"character": {"text": "channel", "start": 12, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "represents", "start": 44, "end": 54, "i_start": 8, "i_end": 8}}, {"character": {"text": "wyner", "start": 36, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 4, "i_end": 4}}], "id": 4207}, {"sent": "its value can be assumed to increase between consecutive appearances .", "tokens": ["its", "value", "can", "be", "assumed", "to", "increase", "between", "consecutive", "appearances", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "its value", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "can be assumed", "start": 10, "end": 24, "i_start": 2, "i_end": 4}}], "id": 4208}, {"sent": "mykland , tierney , and yu and rosenthal have given prescriptions that are often useful for establishing in general spaces .", "tokens": ["mykland", ",", "tierney", ",", "and", "yu", "and", "rosenthal", "have", "given", "prescriptions", "that", "are", "often", "useful", "for", "establishing", "in", "general", "spaces", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "mykland", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "have given", "start": 41, "end": 51, "i_start": 8, "i_end": 9}}, {"character": {"text": "mykland", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "prescriptions", "start": 52, "end": 65, "i_start": 10, "i_end": 10}}, {"character": {"text": "tierney", "start": 10, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "prescriptions", "start": 52, "end": 65, "i_start": 10, "i_end": 10}}, {"character": {"text": "yu", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "prescriptions", "start": 52, "end": 65, "i_start": 10, "i_end": 10}}, {"character": {"text": "rosenthal", "start": 31, "end": 40, "i_start": 7, "i_end": 7}, "action": {"text": "prescriptions", "start": 52, "end": 65, "i_start": 10, "i_end": 10}}], "id": 4209}, {"sent": "it is seen that all the calculated single-particle energies are more attractive than the experimental values .", "tokens": ["it", "is", "seen", "that", "all", "the", "calculated", "single", "-", "particle", "energies", "are", "more", "attractive", "than", "the", "experimental", "values", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is seen", "start": 3, "end": 10, "i_start": 1, "i_end": 2}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 60, "end": 63, "i_start": 11, "i_end": 11}}, {"character": {"text": "energies", "start": 51, "end": 59, "i_start": 10, "i_end": 10}, "action": {"text": "attractive", "start": 69, "end": 79, "i_start": 13, "i_end": 13}}], "id": 4210}, {"sent": "it is well-known that d-branes in constant b-field background are to be described as noncommutative gauge theories .", "tokens": ["it", "is", "well", "-", "known", "that", "d", "-", "branes", "in", "constant", "b", "-", "field", "background", "are", "to", "be", "described", "as", "noncommutative", "gauge", "theories", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 62, "end": 65, "i_start": 15, "i_end": 15}}], "id": 4211}, {"sent": "we have derived the inner and outer bounds of the deterministic and stochastic rate-equivocation regions of the rcc and have established the deterministic rate region in the case where the relay channel is reversely degraded .", "tokens": ["we", "have", "derived", "the", "inner", "and", "outer", "bounds", "of", "the", "deterministic", "and", "stochastic", "rate", "-", "equivocation", "regions", "of", "the", "rcc", "and", "have", "established", "the", "deterministic", "rate", "region", "in", "the", "case", "where", "the", "relay", "channel", "is", "reversely", "degraded", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have derived", "start": 3, "end": 15, "i_start": 1, "i_end": 2}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "established", "start": 125, "end": 136, "i_start": 22, "i_end": 22}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "derived", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}], "id": 4212}, {"sent": "deep convolutional neural networks have been successfully used in various computer vision applications such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successfully", "used", "in", "various", "computer", "vision", "applications", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "used", "start": 58, "end": 62, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}], "id": 4213}, {"sent": "eigen et al proposed a cnn with different output channels to directly predict depth map , surface normal and semantic labels .", "tokens": ["eigen", "et", "al", "proposed", "a", "cnn", "with", "different", "output", "channels", "to", "directly", "predict", "depth", "map", ",", "surface", "normal", "and", "semantic", "labels", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "eigen et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "eigen", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}], "id": 4214}, {"sent": "graphene , an atomically thin two-dimensional allotrope of carbon .", "tokens": ["graphene", ",", "an", "atomically", "thin", "two", "-", "dimensional", "allotrope", "of", "carbon", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4215}, {"sent": "vorobyev institute for nuclear research , moscow , russia yu .", "tokens": ["vorobyev", "institute", "for", "nuclear", "research", ",", "moscow", ",", "russia", "yu", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4216}, {"sent": "we used a pre-trained network trained on imagenet with a resnet-101 architecture .", "tokens": ["we", "used", "a", "pre", "-", "trained", "network", "trained", "on", "imagenet", "with", "a", "resnet-101", "architecture", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 4217}, {"sent": "in , kifer established a sufficient condition for the validity of the ldp for a family of random probability measures on a compact metric space .", "tokens": ["in", ",", "kifer", "established", "a", "sufficient", "condition", "for", "the", "validity", "of", "the", "ldp", "for", "a", "family", "of", "random", "probability", "measures", "on", "a", "compact", "metric", "space", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "kifer", "start": 5, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "established", "start": 11, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "kifer", "start": 5, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "established", "start": 11, "end": 22, "i_start": 3, "i_end": 3}}], "id": 4218}, {"sent": "shifted forms of these higher order approximations diminish the order to one , making them unusable as chen and deng observed .", "tokens": ["shifted", "forms", "of", "these", "higher", "order", "approximations", "diminish", "the", "order", "to", "one", ",", "making", "them", "unusable", "as", "chen", "and", "deng", "observed", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "shifted forms of these higher order approximations", "start": 0, "end": 50, "i_start": 0, "i_end": 6}, "verb": {"text": "diminish", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "forms", "start": 8, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "diminish", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "diminish", "start": 51, "end": 59, "i_start": 7, "i_end": 7}, "action": {"text": "making", "start": 79, "end": 85, "i_start": 13, "i_end": 13}}, {"character": {"text": "chen", "start": 103, "end": 107, "i_start": 17, "i_end": 17}, "action": {"text": "observed", "start": 117, "end": 125, "i_start": 20, "i_end": 20}}, {"character": {"text": "deng", "start": 112, "end": 116, "i_start": 19, "i_end": 19}, "action": {"text": "observed", "start": 117, "end": 125, "i_start": 20, "i_end": 20}}], "id": 4219}, {"sent": "in fact , as is explicitly shown in appendix b , gws from the q-ball formation in the zero-temperature potential may not be detectable even by the next-generation detectors .", "tokens": ["in", "fact", ",", "as", "is", "explicitly", "shown", "in", "appendix", "b", ",", "gws", "from", "the", "q", "-", "ball", "formation", "in", "the", "zero", "-", "temperature", "potential", "may", "not", "be", "detectable", "even", "by", "the", "next", "-", "generation", "detectors", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4220}, {"sent": "in particular , convolutional neural networks have achieved impressive accuracy on the challenging imagenet classification benchmark .", "tokens": ["in", "particular", ",", "convolutional", "neural", "networks", "have", "achieved", "impressive", "accuracy", "on", "the", "challenging", "imagenet", "classification", "benchmark", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "accuracy", "start": 71, "end": 79, "i_start": 9, "i_end": 9}, "action": {"text": "impressive", "start": 60, "end": 70, "i_start": 8, "i_end": 8}}, {"character": {"text": "benchmark", "start": 123, "end": 132, "i_start": 15, "i_end": 15}, "action": {"text": "challenging", "start": 87, "end": 98, "i_start": 12, "i_end": 12}}], "id": 4221}, {"sent": "zero shot learning seeks to recognize novel visual categories that are unannotated in training data .", "tokens": ["zero", "shot", "learning", "seeks", "to", "recognize", "novel", "visual", "categories", "that", "are", "unannotated", "in", "training", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zero shot learning", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "seeks", "start": 19, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "learning", "start": 10, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "seeks", "start": 19, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "learning", "start": 10, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "recognize", "start": 28, "end": 37, "i_start": 5, "i_end": 5}}], "id": 4222}, {"sent": "a smooth orbifold together with a riemannian metric is called a riemannian orbifold .", "tokens": ["a", "smooth", "orbifold", "together", "with", "a", "riemannian", "metric", "is", "called", "a", "riemannian", "orbifold", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a smooth orbifold together with a riemannian metric", "start": 0, "end": 51, "i_start": 0, "i_end": 7}, "verb": {"text": "is called", "start": 52, "end": 61, "i_start": 8, "i_end": 9}}], "id": 4223}, {"sent": "the phase space is a curved manifold because the quark density matrix is a projection operator , making this theory strongly interacting even in the large n limit .", "tokens": ["the", "phase", "space", "is", "a", "curved", "manifold", "because", "the", "quark", "density", "matrix", "is", "a", "projection", "operator", ",", "making", "this", "theory", "strongly", "interacting", "even", "in", "the", "large", "n", "limit", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the phase space", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "matrix", "start": 63, "end": 69, "i_start": 11, "i_end": 11}, "action": {"text": "because", "start": 37, "end": 44, "i_start": 7, "i_end": 7}}, {"character": {"text": "matrix", "start": 63, "end": 69, "i_start": 11, "i_end": 11}, "action": {"text": "operator", "start": 86, "end": 94, "i_start": 15, "i_end": 15}}, {"character": {"text": "because", "start": 37, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "making", "start": 97, "end": 103, "i_start": 17, "i_end": 17}}, {"character": {"text": "theory", "start": 109, "end": 115, "i_start": 19, "i_end": 19}, "action": {"text": "interacting", "start": 125, "end": 136, "i_start": 21, "i_end": 21}}], "id": 4224}, {"sent": "we verify the effectiveness of our approach with a series of experiments on the well-established kitti benchmark .", "tokens": ["we", "verify", "the", "effectiveness", "of", "our", "approach", "with", "a", "series", "of", "experiments", "on", "the", "well", "-", "established", "kitti", "benchmark", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "verify", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "verify", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "approach", "start": 35, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "effectiveness", "start": 14, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "approach", "start": 35, "end": 43, "i_start": 6, "i_end": 6}}], "id": 4225}, {"sent": "our codes 2 are written in python and the deep models are implemented with theano .", "tokens": ["our", "codes", "2", "are", "written", "in", "python", "and", "the", "deep", "models", "are", "implemented", "with", "theano", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our codes 2", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "are written", "start": 12, "end": 23, "i_start": 3, "i_end": 4}}, {"subject": {"text": "the deep models", "start": 38, "end": 53, "i_start": 8, "i_end": 10}, "verb": {"text": "implemented", "start": 58, "end": 69, "i_start": 12, "i_end": 12}}], "id": 4226}, {"sent": "to deal with this issue , partially-connected hybrid mimo architectures were considered in the literature where the output of each rf chain is connected to only a subset of the antennas .", "tokens": ["to", "deal", "with", "this", "issue", ",", "partially", "-", "connected", "hybrid", "mimo", "architectures", "were", "considered", "in", "the", "literature", "where", "the", "output", "of", "each", "rf", "chain", "is", "connected", "to", "only", "a", "subset", "of", "the", "antennas", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "partially-connected hybrid mimo architectures", "start": 26, "end": 71, "i_start": 6, "i_end": 11}, "verb": {"text": "were considered", "start": 72, "end": 87, "i_start": 12, "i_end": 13}}], "id": 4227}, {"sent": "algorithms like stochastic variance reduced gradient method mix sgd-like steps with some batch computations to control the stochastic noise .", "tokens": ["algorithms", "like", "stochastic", "variance", "reduced", "gradient", "method", "mix", "sgd", "-", "like", "steps", "with", "some", "batch", "computations", "to", "control", "the", "stochastic", "noise", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "algorithms like stochastic variance", "start": 0, "end": 35, "i_start": 0, "i_end": 3}, "verb": {"text": "reduced", "start": 36, "end": 43, "i_start": 4, "i_end": 4}}], "id": 4228}, {"sent": "following the procedure hinted to in , it can be shown that the only globally coupled variables are the face unknowns for the velocity and the mean value of the pressure inside each mesh element .", "tokens": ["following", "the", "procedure", "hinted", "to", "in", ",", "it", "can", "be", "shown", "that", "the", "only", "globally", "coupled", "variables", "are", "the", "face", "unknowns", "for", "the", "velocity", "and", "the", "mean", "value", "of", "the", "pressure", "inside", "each", "mesh", "element", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 39, "end": 41, "i_start": 7, "i_end": 7}, "verb": {"text": "can be shown", "start": 42, "end": 54, "i_start": 8, "i_end": 10}}, {"subject": {"text": "it", "start": 39, "end": 41, "i_start": 7, "i_end": 7}, "verb": {"text": "are", "start": 96, "end": 99, "i_start": 17, "i_end": 17}}], "id": 4229}, {"sent": "lately , a large body of successful deep generative models have emerged , especially generative adversarial networks .", "tokens": ["lately", ",", "a", "large", "body", "of", "successful", "deep", "generative", "models", "have", "emerged", ",", "especially", "generative", "adversarial", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a large body of successful deep generative models", "start": 9, "end": 58, "i_start": 2, "i_end": 9}, "verb": {"text": "have emerged", "start": 59, "end": 71, "i_start": 10, "i_end": 11}}, {"character": {"text": "body", "start": 17, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "emerged", "start": 64, "end": 71, "i_start": 11, "i_end": 11}}], "id": 4230}, {"sent": "he et al generalize matrix factorization and factorization machines for neural collaborative filtering .", "tokens": ["he", "et", "al", "generalize", "matrix", "factorization", "and", "factorization", "machines", "for", "neural", "collaborative", "filtering", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "he", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "generalize", "start": 9, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "he", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "generalize", "start": 9, "end": 19, "i_start": 3, "i_end": 3}}], "id": 4231}, {"sent": "we take conv4 output features from resnet-101 as the visual features of each video frame .", "tokens": ["we", "take", "conv4", "output", "features", "from", "resnet-101", "as", "the", "visual", "features", "of", "each", "video", "frame", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "take", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "take", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 4232}, {"sent": "in so far as teleportation is a measure of entanglement , our results suggest that quantum entanglement is degraded in non-inertial frames .", "tokens": ["in", "so", "far", "as", "teleportation", "is", "a", "measure", "of", "entanglement", ",", "our", "results", "suggest", "that", "quantum", "entanglement", "is", "degraded", "in", "non", "-", "inertial", "frames", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "our results", "start": 58, "end": 69, "i_start": 11, "i_end": 12}, "verb": {"text": "suggest", "start": 70, "end": 77, "i_start": 13, "i_end": 13}}, {"subject": {"text": "quantum entanglement", "start": 83, "end": 103, "i_start": 15, "i_end": 16}, "verb": {"text": "degraded", "start": 107, "end": 115, "i_start": 18, "i_end": 18}}, {"character": {"text": "results", "start": 62, "end": 69, "i_start": 12, "i_end": 12}, "action": {"text": "suggest", "start": 70, "end": 77, "i_start": 13, "i_end": 13}}, {"character": {"text": "frames", "start": 132, "end": 138, "i_start": 23, "i_end": 23}, "action": {"text": "degraded", "start": 107, "end": 115, "i_start": 18, "i_end": 18}}], "id": 4233}, {"sent": "as in the ohmic case , at low dc voltages the temperature converges towards an equilibrium value .", "tokens": ["as", "in", "the", "ohmic", "case", ",", "at", "low", "dc", "voltages", "the", "temperature", "converges", "towards", "an", "equilibrium", "value", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4234}, {"sent": "the interpretation of is that these anomalies are cancelled because the ncft automatically contains the necessary closed string axion fields which cancel the anomaly by the greenschwarz mechanism , precisely as in string theory .", "tokens": ["the", "interpretation", "of", "is", "that", "these", "anomalies", "are", "cancelled", "because", "the", "ncft", "automatically", "contains", "the", "necessary", "closed", "string", "axion", "fields", "which", "cancel", "the", "anomaly", "by", "the", "greenschwarz", "mechanism", ",", "precisely", "as", "in", "string", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the interpretation of", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}, {"subject": {"text": "these anomalies", "start": 30, "end": 45, "i_start": 5, "i_end": 6}, "verb": {"text": "cancelled", "start": 50, "end": 59, "i_start": 8, "i_end": 8}}, {"character": {"text": "contains", "start": 91, "end": 99, "i_start": 13, "i_end": 13}, "action": {"text": "because", "start": 60, "end": 67, "i_start": 9, "i_end": 9}}, {"character": {"text": "fields", "start": 134, "end": 140, "i_start": 19, "i_end": 19}, "action": {"text": "cancel", "start": 147, "end": 153, "i_start": 21, "i_end": 21}}], "id": 4235}, {"sent": "dong and lapata also proposed a sequence-to-tree model for question answering .", "tokens": ["dong", "and", "lapata", "also", "proposed", "a", "sequence", "-", "to", "-", "tree", "model", "for", "question", "answering", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "dong and lapata", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 21, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "dong", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 21, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "lapata", "start": 9, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "proposed", "start": 21, "end": 29, "i_start": 4, "i_end": 4}}], "id": 4236}, {"sent": "carma is a heterogeneous array comprised of nine 6 point 1-m antennas and six 10 point 4-m antennas .", "tokens": ["carma", "is", "a", "heterogeneous", "array", "comprised", "of", "nine", "6", "point", "1", "-", "m", "antennas", "and", "six", "10", "point", "4", "-", "m", "antennas", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "carma", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}], "id": 4237}, {"sent": "overdots denote derivatives with respect to physical time .", "tokens": ["overdots", "denote", "derivatives", "with", "respect", "to", "physical", "time", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "overdots", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 9, "end": 15, "i_start": 1, "i_end": 1}}], "id": 4238}, {"sent": "a bloom filter is a space-efficient , probabilistic data structure that answers queries about set membership .", "tokens": ["a", "bloom", "filter", "is", "a", "space", "-", "efficient", ",", "probabilistic", "data", "structure", "that", "answers", "queries", "about", "set", "membership", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a bloom filter", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "structure", "start": 57, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "answers", "start": 72, "end": 79, "i_start": 13, "i_end": 13}}], "id": 4239}, {"sent": "specifically , mud algorithms based on the algorithms of jacobi , gauss-seidel and successive over-relaxation 6 were investigated .", "tokens": ["specifically", ",", "mud", "algorithms", "based", "on", "the", "algorithms", "of", "jacobi", ",", "gauss", "-", "seidel", "and", "successive", "over", "-", "relaxation", "6", "were", "investigated", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "mud algorithms based on the algorithms of jacobi , gauss-seidel and successive over-relaxation 6", "start": 15, "end": 111, "i_start": 2, "i_end": 19}, "verb": {"text": "were investigated", "start": 112, "end": 129, "i_start": 20, "i_end": 21}}], "id": 4240}, {"sent": "evolution of a system after a global quantum quench is an example of the thermalization .", "tokens": ["evolution", "of", "a", "system", "after", "a", "global", "quantum", "quench", "is", "an", "example", "of", "the", "thermalization", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "evolution of a system after a global quantum quench", "start": 0, "end": 51, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 52, "end": 54, "i_start": 9, "i_end": 9}}], "id": 4241}, {"sent": "in this section , we describe the grid diagram formulation of link floer homology discovered in .", "tokens": ["in", "this", "section", ",", "we", "describe", "the", "grid", "diagram", "formulation", "of", "link", "floer", "homology", "discovered", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "describe", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}, {"subject": {"text": "floer homology", "start": 67, "end": 81, "i_start": 12, "i_end": 13}, "verb": {"text": "discovered", "start": 82, "end": 92, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "describe", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}], "id": 4242}, {"sent": "this contribution is negative , and is called normal saturation .", "tokens": ["this", "contribution", "is", "negative", ",", "and", "is", "called", "normal", "saturation", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this contribution", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}, {"subject": {"text": "this contribution", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "called", "start": 39, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "contribution", "start": 5, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "negative", "start": 21, "end": 29, "i_start": 3, "i_end": 3}}], "id": 4243}, {"sent": "these complexity measures take into account the multilevel structure of neural nets , as opposed to the classical relative entropy term derived from pac-bayesian bounds .", "tokens": ["these", "complexity", "measures", "take", "into", "account", "the", "multilevel", "structure", "of", "neural", "nets", ",", "as", "opposed", "to", "the", "classical", "relative", "entropy", "term", "derived", "from", "pac", "-", "bayesian", "bounds", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "these complexity measures", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "take", "start": 26, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "measures", "start": 17, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "take", "start": 26, "end": 30, "i_start": 3, "i_end": 3}}], "id": 4244}, {"sent": "the expansion is convergent under the assumption of bounded bosonic and fermionic potentials as established in section .", "tokens": ["the", "expansion", "is", "convergent", "under", "the", "assumption", "of", "bounded", "bosonic", "and", "fermionic", "potentials", "as", "established", "in", "section", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the expansion", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 4245}, {"sent": "we introduce the notion of singular parameters for bn over an arbitrary field .", "tokens": ["we", "introduce", "the", "notion", "of", "singular", "parameters", "for", "bn", "over", "an", "arbitrary", "field", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "introduce", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "introduce", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}], "id": 4246}, {"sent": "recently , deep neural networks have demonstrated impressive results in image classification .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "demonstrated", "impressive", "results", "in", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have demonstrated", "start": 32, "end": 49, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "demonstrated", "start": 37, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "results", "start": 61, "end": 68, "i_start": 8, "i_end": 8}, "action": {"text": "impressive", "start": 50, "end": 60, "i_start": 7, "i_end": 7}}], "id": 4247}, {"sent": "using an efficient implementation of the pseudoinverse by means of the lsqr algorithm , we observed a run time that was only less than half that of omp , and a performance that was only slightly poorer .", "tokens": ["using", "an", "efficient", "implementation", "of", "the", "pseudoinverse", "by", "means", "of", "the", "lsqr", "algorithm", ",", "we", "observed", "a", "run", "time", "that", "was", "only", "less", "than", "half", "that", "of", "omp", ",", "and", "a", "performance", "that", "was", "only", "slightly", "poorer", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 88, "end": 90, "i_start": 14, "i_end": 14}, "verb": {"text": "observed", "start": 91, "end": 99, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 88, "end": 90, "i_start": 14, "i_end": 14}, "action": {"text": "observed", "start": 91, "end": 99, "i_start": 15, "i_end": 15}}], "id": 4248}, {"sent": "on the other hand , the classification scheme regards each identity as a unique class and trains the network as a n -way classification problem , such as softmax .", "tokens": ["on", "the", "other", "hand", ",", "the", "classification", "scheme", "regards", "each", "identity", "as", "a", "unique", "class", "and", "trains", "the", "network", "as", "a", "n", "-way", "classification", "problem", ",", "such", "as", "softmax", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the classification scheme", "start": 20, "end": 45, "i_start": 5, "i_end": 7}, "verb": {"text": "regards", "start": 46, "end": 53, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the classification scheme", "start": 20, "end": 45, "i_start": 5, "i_end": 7}, "verb": {"text": "trains", "start": 90, "end": 96, "i_start": 16, "i_end": 16}}, {"character": {"text": "scheme", "start": 39, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "regards", "start": 46, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "scheme", "start": 39, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "classification", "start": 24, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "scheme", "start": 39, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "trains", "start": 90, "end": 96, "i_start": 16, "i_end": 16}}], "id": 4249}, {"sent": "the electronelectron exchange and correlation functional was described with the perdew-burke-ernzerhof 22 parametrization of the generalized gradient approximation .", "tokens": ["the", "electronelectron", "exchange", "and", "correlation", "functional", "was", "described", "with", "the", "perdew", "-", "burke", "-", "ernzerhof", "22", "parametrization", "of", "the", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electronelectron exchange and correlation functional", "start": 0, "end": 56, "i_start": 0, "i_end": 5}, "verb": {"text": "was described", "start": 57, "end": 70, "i_start": 6, "i_end": 7}}], "id": 4250}, {"sent": "cirac , hawking radiation from an acoustic black hole on an ion ring , phys .", "tokens": ["cirac", ",", "hawking", "radiation", "from", "an", "acoustic", "black", "hole", "on", "an", "ion", "ring", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "hole", "start": 49, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "radiation", "start": 16, "end": 25, "i_start": 3, "i_end": 3}}], "id": 4251}, {"sent": "atomic bose-einstein condensates offer an ideal testing ground for confronting theoretical models of nonlinear matter waves with experimental data .", "tokens": ["atomic", "bose", "-", "einstein", "condensates", "offer", "an", "ideal", "testing", "ground", "for", "confronting", "theoretical", "models", "of", "nonlinear", "matter", "waves", "with", "experimental", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "atomic bose-einstein condensates", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "offer", "start": 33, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "condensates", "start": 21, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "offer", "start": 33, "end": 38, "i_start": 5, "i_end": 5}}], "id": 4252}, {"sent": "the fourth axiom transcribes the third reidemeister move .", "tokens": ["the", "fourth", "axiom", "transcribes", "the", "third", "reidemeister", "move", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the fourth axiom", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "transcribes", "start": 17, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "axiom", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "transcribes", "start": 17, "end": 28, "i_start": 3, "i_end": 3}}], "id": 4253}, {"sent": "significant improvements have been obtained in various computer vision tasks by applying deep learning techniques , including image classification .", "tokens": ["significant", "improvements", "have", "been", "obtained", "in", "various", "computer", "vision", "tasks", "by", "applying", "deep", "learning", "techniques", ",", "including", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "significant improvements", "start": 0, "end": 24, "i_start": 0, "i_end": 1}, "verb": {"text": "have been obtained", "start": 25, "end": 43, "i_start": 2, "i_end": 4}}], "id": 4254}, {"sent": "logistic regression is a simple but effective method for supervised classification .", "tokens": ["logistic", "regression", "is", "a", "simple", "but", "effective", "method", "for", "supervised", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "logistic regression", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "regression", "start": 9, "end": 19, "i_start": 1, "i_end": 1}, "action": {"text": "effective", "start": 36, "end": 45, "i_start": 6, "i_end": 6}}], "id": 4255}, {"sent": "more specifically , we use the straight-through gumbel-softmax estimator .", "tokens": ["more", "specifically", ",", "we", "use", "the", "straight", "-", "through", "gumbel", "-", "softmax", "estimator", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "verb": {"text": "use", "start": 23, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 23, "end": 26, "i_start": 4, "i_end": 4}}], "id": 4256}, {"sent": "jaderberg et al successfully use a synthetic dataset for optical character recognition systems .", "tokens": ["jaderberg", "et", "al", "successfully", "use", "a", "synthetic", "dataset", "for", "optical", "character", "recognition", "systems", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 10, "end": 15, "i_start": 1, "i_end": 2}, "verb": {"text": "use", "start": 29, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "jaderberg", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 29, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "systems", "start": 87, "end": 94, "i_start": 12, "i_end": 12}, "action": {"text": "recognition", "start": 75, "end": 86, "i_start": 11, "i_end": 11}}], "id": 4257}, {"sent": "a self-organization of complex systems that reflects economic and power rules in societies .", "tokens": ["a", "self", "-", "organization", "of", "complex", "systems", "that", "reflects", "economic", "and", "power", "rules", "in", "societies", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4258}, {"sent": "still , it is important to know whether lower dimensional d-branes are contained in open string field theory as solitons .", "tokens": ["still", ",", "it", "is", "important", "to", "know", "whether", "lower", "dimensional", "d", "-", "branes", "are", "contained", "in", "open", "string", "field", "theory", "as", "solitons", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 3, "i_end": 3}}, {"character": {"text": "theory", "start": 102, "end": 108, "i_start": 19, "i_end": 19}, "action": {"text": "contained", "start": 71, "end": 80, "i_start": 14, "i_end": 14}}], "id": 4259}, {"sent": "on the positive side , all simple cubic graphs admit a normal 7-edge-coloring .", "tokens": ["on", "the", "positive", "side", ",", "all", "simple", "cubic", "graphs", "admit", "a", "normal", "7", "-", "edge", "-", "coloring", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "all simple cubic graphs", "start": 23, "end": 46, "i_start": 5, "i_end": 8}, "verb": {"text": "admit", "start": 47, "end": 52, "i_start": 9, "i_end": 9}}, {"character": {"text": "graphs", "start": 40, "end": 46, "i_start": 8, "i_end": 8}, "action": {"text": "admit", "start": 47, "end": 52, "i_start": 9, "i_end": 9}}], "id": 4260}, {"sent": "each junction consists of two small weakly coupled superconducting islands .", "tokens": ["each", "junction", "consists", "of", "two", "small", "weakly", "coupled", "superconducting", "islands", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each junction", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 14, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "two small weakly coupled superconducting islands", "start": 26, "end": 74, "i_start": 4, "i_end": 9}, "action": {"text": "superconducting", "start": 51, "end": 66, "i_start": 8, "i_end": 8}}], "id": 4261}, {"sent": "following the success of deep neural networks in several computer vision tasks , neural networks have also received considerable attention in the context of image processing .", "tokens": ["following", "the", "success", "of", "deep", "neural", "networks", "in", "several", "computer", "vision", "tasks", ",", "neural", "networks", "have", "also", "received", "considerable", "attention", "in", "the", "context", "of", "image", "processing", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "neural networks", "start": 81, "end": 96, "i_start": 13, "i_end": 14}, "verb": {"text": "received", "start": 107, "end": 115, "i_start": 17, "i_end": 17}}, {"subject": {"text": "neural networks", "start": 81, "end": 96, "i_start": 13, "i_end": 14}, "verb": {"text": "have", "start": 97, "end": 101, "i_start": 15, "i_end": 15}}, {"character": {"text": "networks", "start": 88, "end": 96, "i_start": 14, "i_end": 14}, "action": {"text": "success", "start": 14, "end": 21, "i_start": 2, "i_end": 2}}], "id": 4262}, {"sent": "a pulsar is a rapidly rotating neutron star that emits highly directional radiation .", "tokens": ["a", "pulsar", "is", "a", "rapidly", "rotating", "neutron", "star", "that", "emits", "highly", "directional", "radiation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a pulsar", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "star", "start": 39, "end": 43, "i_start": 7, "i_end": 7}, "action": {"text": "emits", "start": 49, "end": 54, "i_start": 9, "i_end": 9}}], "id": 4263}, {"sent": "li et al considerably improve the performance of siamfc by relying on a region proposal network , which allows to estimate the target location with a bounding box of variable aspect ratio .", "tokens": ["li", "et", "al", "considerably", "improve", "the", "performance", "of", "siamfc", "by", "relying", "on", "a", "region", "proposal", "network", ",", "which", "allows", "to", "estimate", "the", "target", "location", "with", "a", "bounding", "box", "of", "variable", "aspect", "ratio", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "li et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "improve", "start": 22, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "li", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "improve", "start": 22, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "li", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "relying", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "network", "start": 88, "end": 95, "i_start": 15, "i_end": 15}, "action": {"text": "allows", "start": 104, "end": 110, "i_start": 18, "i_end": 18}}], "id": 4264}, {"sent": "see for the definition of standard and good determinantal schemes .", "tokens": ["see", "for", "the", "definition", "of", "standard", "and", "good", "determinantal", "schemes", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4265}, {"sent": "in the perpendicular direction of the cell interface , a standard 5th-order weno-js method is used to determine the value of the variables on both sides of the interface .", "tokens": ["in", "the", "perpendicular", "direction", "of", "the", "cell", "interface", ",", "a", "standard", "5th", "-", "order", "weno", "-", "js", "method", "is", "used", "to", "determine", "the", "value", "of", "the", "variables", "on", "both", "sides", "of", "the", "interface", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "a standard 5th-order weno-js method", "start": 55, "end": 90, "i_start": 9, "i_end": 17}, "verb": {"text": "is used", "start": 91, "end": 98, "i_start": 18, "i_end": 19}}, {"character": {"text": "method", "start": 84, "end": 90, "i_start": 17, "i_end": 17}, "action": {"text": "determine", "start": 102, "end": 111, "i_start": 21, "i_end": 21}}], "id": 4266}, {"sent": "the generalized gradient approximation of perdew , burke and ernzerhof was used to describe the exchangecorrelation potential .", "tokens": ["the", "generalized", "gradient", "approximation", "of", "perdew", ",", "burke", "and", "ernzerhof", "was", "used", "to", "describe", "the", "exchangecorrelation", "potential", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation of perdew", "start": 0, "end": 48, "i_start": 0, "i_end": 5}, "verb": {"text": "was used", "start": 71, "end": 79, "i_start": 10, "i_end": 11}}, {"character": {"text": "approximation", "start": 25, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "describe", "start": 83, "end": 91, "i_start": 13, "i_end": 13}}], "id": 4267}, {"sent": "in , a dynamic bandwidth algorithm based on local storage vod delivery in pons was proposed , and the achievable throughput levels have been improved when a local storage is used to assist vod delivery .", "tokens": ["in", ",", "a", "dynamic", "bandwidth", "algorithm", "based", "on", "local", "storage", "vod", "delivery", "in", "pons", "was", "proposed", ",", "and", "the", "achievable", "throughput", "levels", "have", "been", "improved", "when", "a", "local", "storage", "is", "used", "to", "assist", "vod", "delivery", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a dynamic bandwidth algorithm based on local storage vod delivery in pons", "start": 5, "end": 78, "i_start": 2, "i_end": 13}, "verb": {"text": "was proposed", "start": 79, "end": 91, "i_start": 14, "i_end": 15}}, {"subject": {"text": "the achievable throughput levels", "start": 98, "end": 130, "i_start": 18, "i_end": 21}, "verb": {"text": "improved", "start": 141, "end": 149, "i_start": 24, "i_end": 24}}], "id": 4268}, {"sent": "ellipses denote spin-neutral bound states .", "tokens": ["ellipses", "denote", "spin", "-", "neutral", "bound", "states", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "ellipses", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 9, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "states", "start": 35, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "neutral", "start": 21, "end": 28, "i_start": 4, "i_end": 4}}], "id": 4269}, {"sent": "success of convolutional neural networks over the past several years has lead to their extensive deployment in a wide range of computer vision tasks .", "tokens": ["success", "of", "convolutional", "neural", "networks", "over", "the", "past", "several", "years", "has", "lead", "to", "their", "extensive", "deployment", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "success of convolutional neural networks over the past several years", "start": 0, "end": 68, "i_start": 0, "i_end": 9}, "verb": {"text": "has lead", "start": 69, "end": 77, "i_start": 10, "i_end": 11}}, {"character": {"text": "success", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "lead", "start": 73, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "success", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}], "id": 4270}, {"sent": "the theoretical calculations are performed within the projector augmented wave method and the density functional theory framework as implemented in the vienna ab-initio simulation package .", "tokens": ["the", "theoretical", "calculations", "are", "performed", "within", "the", "projector", "augmented", "wave", "method", "and", "the", "density", "functional", "theory", "framework", "as", "implemented", "in", "the", "vienna", "ab", "-", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the theoretical calculations", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "are performed", "start": 29, "end": 42, "i_start": 3, "i_end": 4}}], "id": 4271}, {"sent": "calculations were performed within density-functional theory , as implemented in the vienna ab initio simulation package 39 , 40 .", "tokens": ["calculations", "were", "performed", "within", "density", "-", "functional", "theory", ",", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "39", ",", "40", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "calculations", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "were performed", "start": 13, "end": 27, "i_start": 1, "i_end": 2}}], "id": 4272}, {"sent": "the link prediction problem for social networks .", "tokens": ["the", "link", "prediction", "problem", "for", "social", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4273}, {"sent": "an n-best em variant is then employed to jointly reestimate the model parameters such that the ppl on training data is decreased -the likelihood of the training data under our model is increased .", "tokens": ["an", "n", "-", "best", "em", "variant", "is", "then", "employed", "to", "jointly", "reestimate", "the", "model", "parameters", "such", "that", "the", "ppl", "on", "training", "data", "is", "decreased", "-the", "likelihood", "of", "the", "training", "data", "under", "our", "model", "is", "increased", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "an n-best em variant", "start": 0, "end": 20, "i_start": 0, "i_end": 5}, "verb": {"text": "employed", "start": 29, "end": 37, "i_start": 8, "i_end": 8}}, {"subject": {"text": "an n-best em variant", "start": 0, "end": 20, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 6, "i_end": 6}}, {"subject": {"text": "an n-best em variant", "start": 0, "end": 20, "i_start": 0, "i_end": 5}, "verb": {"text": "increased", "start": 185, "end": 194, "i_start": 34, "i_end": 34}}, {"character": {"text": "variant", "start": 13, "end": 20, "i_start": 5, "i_end": 5}, "action": {"text": "reestimate", "start": 49, "end": 59, "i_start": 11, "i_end": 11}}], "id": 4274}, {"sent": "we use stochastic gradient descent with an adaptive learning rate .", "tokens": ["we", "use", "stochastic", "gradient", "descent", "with", "an", "adaptive", "learning", "rate", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 4275}, {"sent": "the original dynamo was one of pioneers in the eventual consistency movement and served as the basis for voldemort key-value store .", "tokens": ["the", "original", "dynamo", "was", "one", "of", "pioneers", "in", "the", "eventual", "consistency", "movement", "and", "served", "as", "the", "basis", "for", "voldemort", "key", "-", "value", "store", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the original dynamo", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "was", "start": 20, "end": 23, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the original dynamo", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "served", "start": 81, "end": 87, "i_start": 13, "i_end": 13}}], "id": 4276}, {"sent": "we use a modified version of the cosmomc code to perform markov-chain monte-carlo explorations of the model likelihoods .", "tokens": ["we", "use", "a", "modified", "version", "of", "the", "cosmomc", "code", "to", "perform", "markov", "-", "chain", "monte", "-", "carlo", "explorations", "of", "the", "model", "likelihoods", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "perform", "start": 49, "end": 56, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "explorations", "start": 82, "end": 94, "i_start": 17, "i_end": 17}}], "id": 4277}, {"sent": "are listed as sequence a006252 in the on-line encyclopedia of integer sequences .", "tokens": ["are", "listed", "as", "sequence", "a006252", "in", "the", "on", "-", "line", "encyclopedia", "of", "integer", "sequences", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4278}, {"sent": "last column lists the measured velocity dispersion and its error .", "tokens": ["last", "column", "lists", "the", "measured", "velocity", "dispersion", "and", "its", "error", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "last column", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "lists", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "column", "start": 5, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "lists", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}], "id": 4279}, {"sent": "massive mu-mimo is widely believed to be a key technology for next-generation wireless systems .", "tokens": ["massive", "mu", "-", "mimo", "is", "widely", "believed", "to", "be", "a", "key", "technology", "for", "next", "-", "generation", "wireless", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "massive mu-mimo", "start": 0, "end": 15, "i_start": 0, "i_end": 3}, "verb": {"text": "believed", "start": 26, "end": 34, "i_start": 6, "i_end": 6}}, {"subject": {"text": "massive mu-mimo", "start": 0, "end": 15, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 4, "i_end": 4}}], "id": 4280}, {"sent": "deep neural networks have achieved recordbreaking accuracy in many image classification tasks .", "tokens": ["deep", "neural", "networks", "have", "achieved", "recordbreaking", "accuracy", "in", "many", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}], "id": 4281}, {"sent": "the cascade simulations were done using the newly implemented 2t-md method in lammps code .", "tokens": ["the", "cascade", "simulations", "were", "done", "using", "the", "newly", "implemented", "2t", "-", "md", "method", "in", "lammps", "code", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the cascade simulations", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "were done", "start": 24, "end": 33, "i_start": 3, "i_end": 4}}], "id": 4282}, {"sent": "in recent years , deep learning technology has attracted considerable interest in the computer vision and machine learning community .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "technology", "has", "attracted", "considerable", "interest", "in", "the", "computer", "vision", "and", "machine", "learning", "community", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning technology", "start": 18, "end": 42, "i_start": 4, "i_end": 6}, "verb": {"text": "has attracted", "start": 43, "end": 56, "i_start": 7, "i_end": 8}}, {"character": {"text": "technology", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "attracted", "start": 47, "end": 56, "i_start": 8, "i_end": 8}}], "id": 4283}, {"sent": "as shown recently , quantum field theories in noncommutative spacetime naturally arise as a decoupling limit of the worldvolume dynamics of d-branes in a constant ns-ns two-form background .", "tokens": ["as", "shown", "recently", ",", "quantum", "field", "theories", "in", "noncommutative", "spacetime", "naturally", "arise", "as", "a", "decoupling", "limit", "of", "the", "worldvolume", "dynamics", "of", "d", "-", "branes", "in", "a", "constant", "ns", "-", "ns", "two", "-", "form", "background", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum field theories in noncommutative spacetime", "start": 20, "end": 70, "i_start": 4, "i_end": 9}, "verb": {"text": "arise", "start": 81, "end": 86, "i_start": 11, "i_end": 11}}], "id": 4284}, {"sent": "we will only illustrate this situation by some examples .", "tokens": ["we", "will", "only", "illustrate", "this", "situation", "by", "some", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "illustrate", "start": 13, "end": 23, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "illustrate", "start": 13, "end": 23, "i_start": 3, "i_end": 3}}], "id": 4285}, {"sent": "at this critical point it has been suggested that the neutral nambu-goldstone boson , being odd under cp , develops a vev spontaneously breaking cp .", "tokens": ["at", "this", "critical", "point", "it", "has", "been", "suggested", "that", "the", "neutral", "nambu", "-", "goldstone", "boson", ",", "being", "odd", "under", "cp", ",", "develops", "a", "vev", "spontaneously", "breaking", "cp", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "verb": {"text": "has been suggested", "start": 26, "end": 44, "i_start": 5, "i_end": 7}}, {"subject": {"text": "the neutral nambu-goldstone boson", "start": 50, "end": 83, "i_start": 9, "i_end": 14}, "verb": {"text": "develops", "start": 107, "end": 115, "i_start": 21, "i_end": 21}}, {"character": {"text": "boson", "start": 78, "end": 83, "i_start": 14, "i_end": 14}, "action": {"text": "develops", "start": 107, "end": 115, "i_start": 21, "i_end": 21}}, {"character": {"text": "boson", "start": 78, "end": 83, "i_start": 14, "i_end": 14}, "action": {"text": "neutral", "start": 54, "end": 61, "i_start": 10, "i_end": 10}}], "id": 4286}, {"sent": "the bound applies immediately to the scheme with normal hierarchy .", "tokens": ["the", "bound", "applies", "immediately", "to", "the", "scheme", "with", "normal", "hierarchy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the bound", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "applies", "start": 10, "end": 17, "i_start": 2, "i_end": 2}}], "id": 4287}, {"sent": "giacconi r , murray s , gursky h , kellogg e , schreier e , tananbaum h .", "tokens": ["giacconi", "r", ",", "murray", "s", ",", "gursky", "h", ",", "kellogg", "e", ",", "schreier", "e", ",", "tananbaum", "h", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4288}, {"sent": "facebook , google , baidu , microsoft , ibm , pushing towards deploying services based on braininspired machine learning to their customers within a production environment .", "tokens": ["facebook", ",", "google", ",", "baidu", ",", "microsoft", ",", "ibm", ",", "pushing", "towards", "deploying", "services", "based", "on", "braininspired", "machine", "learning", "to", "their", "customers", "within", "a", "production", "environment", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "facebook", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "pushing", "start": 46, "end": 53, "i_start": 10, "i_end": 10}}, {"character": {"text": "google", "start": 11, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "pushing", "start": 46, "end": 53, "i_start": 10, "i_end": 10}}, {"character": {"text": "baidu", "start": 20, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "pushing", "start": 46, "end": 53, "i_start": 10, "i_end": 10}}, {"character": {"text": "microsoft", "start": 28, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "pushing", "start": 46, "end": 53, "i_start": 10, "i_end": 10}}, {"character": {"text": "ibm", "start": 40, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "pushing", "start": 46, "end": 53, "i_start": 10, "i_end": 10}}], "id": 4289}, {"sent": "this feature was identified from the first reports of this gradient up to the most recent study .", "tokens": ["this", "feature", "was", "identified", "from", "the", "first", "reports", "of", "this", "gradient", "up", "to", "the", "most", "recent", "study", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this feature", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "was identified", "start": 13, "end": 27, "i_start": 2, "i_end": 3}}, {"subject": {"text": "this feature", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "up", "start": 68, "end": 70, "i_start": 11, "i_end": 11}}], "id": 4290}, {"sent": "a smaller number of disorder realizations has been considered for smaller lattices .", "tokens": ["a", "smaller", "number", "of", "disorder", "realizations", "has", "been", "considered", "for", "smaller", "lattices", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a smaller number of disorder realizations", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "has been considered", "start": 42, "end": 61, "i_start": 6, "i_end": 8}}], "id": 4291}, {"sent": "we also show the validity of the perturbative lagrangian approximations by consulting difference between the first-order and the second-order approximations .", "tokens": ["we", "also", "show", "the", "validity", "of", "the", "perturbative", "lagrangian", "approximations", "by", "consulting", "difference", "between", "the", "first", "-", "order", "and", "the", "second", "-", "order", "approximations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "consulting", "start": 75, "end": 85, "i_start": 11, "i_end": 11}}], "id": 4292}, {"sent": "the work in attacks this problem and formulates the outlier detection as a lasso problem based on sparse approximations of cyclic ranking projection of paired comparison data in hodge decomposition .", "tokens": ["the", "work", "in", "attacks", "this", "problem", "and", "formulates", "the", "outlier", "detection", "as", "a", "lasso", "problem", "based", "on", "sparse", "approximations", "of", "cyclic", "ranking", "projection", "of", "paired", "comparison", "data", "in", "hodge", "decomposition", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4293}, {"sent": "convolutional neural networks show state-of-the-art performance on many problems in computer vision , natural language processing and other fields .", "tokens": ["convolutional", "neural", "networks", "show", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "many", "problems", "in", "computer", "vision", ",", "natural", "language", "processing", "and", "other", "fields", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "show", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 52, "end": 63, "i_start": 11, "i_end": 11}}], "id": 4294}, {"sent": "zurada describes a method called rule extraction from function approximating neural networks for extracting rules from trained anns for nonlinear regression .", "tokens": ["zurada", "describes", "a", "method", "called", "rule", "extraction", "from", "function", "approximating", "neural", "networks", "for", "extracting", "rules", "from", "trained", "anns", "for", "nonlinear", "regression", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zurada", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "describes", "start": 7, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "zurada", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "describes", "start": 7, "end": 16, "i_start": 1, "i_end": 1}}], "id": 4295}, {"sent": "deep neural networks are powerful machine learning systems , which have been demonstrated in a variety of tasks including image classification among others .", "tokens": ["deep", "neural", "networks", "are", "powerful", "machine", "learning", "systems", ",", "which", "have", "been", "demonstrated", "in", "a", "variety", "of", "tasks", "including", "image", "classification", "among", "others", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "systems", "start": 51, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "learning", "start": 42, "end": 50, "i_start": 6, "i_end": 6}}], "id": 4296}, {"sent": "let us consider the movement of soliton through inhomogeneous region of the chain .", "tokens": ["let", "us", "consider", "the", "movement", "of", "soliton", "through", "inhomogeneous", "region", "of", "the", "chain", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "consider", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "consider", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}], "id": 4297}, {"sent": "we say that a foliation is a flat foliation if its leaves are flat submanifolds , and we say that a foliation is a totally geodesic foliation if its leaves are totally geodesic submanifolds .", "tokens": ["we", "say", "that", "a", "foliation", "is", "a", "flat", "foliation", "if", "its", "leaves", "are", "flat", "submanifolds", ",", "and", "we", "say", "that", "a", "foliation", "is", "a", "totally", "geodesic", "foliation", "if", "its", "leaves", "are", "totally", "geodesic", "submanifolds", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "say", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 86, "end": 88, "i_start": 17, "i_end": 17}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "say", "start": 89, "end": 92, "i_start": 18, "i_end": 18}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "say", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 4298}, {"sent": "tsuji , p-adic etale cohomology and srystalline cohomology in the semistable reduction case , invent .", "tokens": ["tsuji", ",", "p", "-", "adic", "etale", "cohomology", "and", "srystalline", "cohomology", "in", "the", "semistable", "reduction", "case", ",", "invent", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "tsuji", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "invent", "start": 94, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "cohomology", "start": 21, "end": 31, "i_start": 6, "i_end": 6}, "action": {"text": "invent", "start": 94, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "cohomology", "start": 48, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "invent", "start": 94, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "etale", "start": 15, "end": 20, "i_start": 5, "i_end": 5}, "action": {"text": "invent", "start": 94, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "srystalline", "start": 36, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "invent", "start": 94, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "case", "start": 87, "end": 91, "i_start": 14, "i_end": 14}, "action": {"text": "invent", "start": 94, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "reduction", "start": 77, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "invent", "start": 94, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "semistable", "start": 66, "end": 76, "i_start": 12, "i_end": 12}, "action": {"text": "invent", "start": 94, "end": 100, "i_start": 16, "i_end": 16}}], "id": 4299}, {"sent": "wendl proved that any filling of t 3 is symplectic deformation equivalent to one of the elements in this family .", "tokens": ["wendl", "proved", "that", "any", "filling", "of", "t", "3", "is", "symplectic", "deformation", "equivalent", "to", "one", "of", "the", "elements", "in", "this", "family", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "wendl", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "proved", "start": 6, "end": 12, "i_start": 1, "i_end": 1}}, {"subject": {"text": "wendl", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 37, "end": 39, "i_start": 8, "i_end": 8}}, {"character": {"text": "wendl", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proved", "start": 6, "end": 12, "i_start": 1, "i_end": 1}}], "id": 4300}, {"sent": "in the recent years , complex network structures and their dynamics have been studied intensively .", "tokens": ["in", "the", "recent", "years", ",", "complex", "network", "structures", "and", "their", "dynamics", "have", "been", "studied", "intensively", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "complex network structures and their dynamics", "start": 22, "end": 67, "i_start": 5, "i_end": 10}, "verb": {"text": "have been studied", "start": 68, "end": 85, "i_start": 11, "i_end": 13}}], "id": 4301}, {"sent": "the introduction of the residual learning framework by he et al allows for training substantially deeper networks than it was previously possible .", "tokens": ["the", "introduction", "of", "the", "residual", "learning", "framework", "by", "he", "et", "al", "allows", "for", "training", "substantially", "deeper", "networks", "than", "it", "was", "previously", "possible", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the introduction of the residual learning framework by he et al", "start": 0, "end": 63, "i_start": 0, "i_end": 10}, "verb": {"text": "allows", "start": 64, "end": 70, "i_start": 11, "i_end": 11}}, {"character": {"text": "introduction", "start": 4, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "allows", "start": 64, "end": 70, "i_start": 11, "i_end": 11}}, {"character": {"text": "he", "start": 55, "end": 57, "i_start": 8, "i_end": 8}, "action": {"text": "introduction", "start": 4, "end": 16, "i_start": 1, "i_end": 1}}], "id": 4302}, {"sent": "single photon sources are a fundamental component of the toolbox for quantum information technologies that promise transformational advances in the communication and processing of information .", "tokens": ["single", "photon", "sources", "are", "a", "fundamental", "component", "of", "the", "toolbox", "for", "quantum", "information", "technologies", "that", "promise", "transformational", "advances", "in", "the", "communication", "and", "processing", "of", "information", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "single photon sources", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 22, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "technologies", "start": 89, "end": 101, "i_start": 13, "i_end": 13}, "action": {"text": "promise", "start": 107, "end": 114, "i_start": 15, "i_end": 15}}, {"character": {"text": "advances", "start": 132, "end": 140, "i_start": 17, "i_end": 17}, "action": {"text": "transformational", "start": 115, "end": 131, "i_start": 16, "i_end": 16}}], "id": 4303}, {"sent": "deep convolutional neural networks achieve impressive performance on many computer vision tasks , including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "achieve", "impressive", "performance", "on", "many", "computer", "vision", "tasks", ",", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "achieve", "start": 35, "end": 42, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieve", "start": 35, "end": 42, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 54, "end": 65, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 54, "end": 65, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 43, "end": 53, "i_start": 5, "i_end": 5}}], "id": 4304}, {"sent": "electronic exchange-correlation energy was treated with generalized gradient approximation parametrized by perdew-burke-ernzerhof .", "tokens": ["electronic", "exchange", "-", "correlation", "energy", "was", "treated", "with", "generalized", "gradient", "approximation", "parametrized", "by", "perdew", "-", "burke", "-", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "electronic exchange-correlation energy", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "was treated", "start": 39, "end": 50, "i_start": 5, "i_end": 6}}], "id": 4305}, {"sent": "we use a multi-layer bidirectional transformer encoder to encode contextual information for input representation .", "tokens": ["we", "use", "a", "multi", "-", "layer", "bidirectional", "transformer", "encoder", "to", "encode", "contextual", "information", "for", "input", "representation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "encoder", "start": 47, "end": 54, "i_start": 8, "i_end": 8}, "action": {"text": "transformer", "start": 35, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "encode", "start": 58, "end": 64, "i_start": 10, "i_end": 10}}], "id": 4306}, {"sent": "deep neural networks have achieved state-of-the-art performance on a wide variety of machine learning tasks .", "tokens": ["deep", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "a", "wide", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 52, "end": 63, "i_start": 12, "i_end": 12}}], "id": 4307}, {"sent": "noncommutative field theories have been studied for some time in the search for a new class of field thories .", "tokens": ["noncommutative", "field", "theories", "have", "been", "studied", "for", "some", "time", "in", "the", "search", "for", "a", "new", "class", "of", "field", "thories", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "noncommutative field theories", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been studied", "start": 30, "end": 47, "i_start": 3, "i_end": 5}}], "id": 4308}, {"sent": "we use the projector augmented wave pseudopotentials and the exchange and correlation functionals parametrized by the generalized gradient approximation proposed by perdew-burke-ernzerhof .", "tokens": ["we", "use", "the", "projector", "augmented", "wave", "pseudopotentials", "and", "the", "exchange", "and", "correlation", "functionals", "parametrized", "by", "the", "generalized", "gradient", "approximation", "proposed", "by", "perdew", "-", "burke", "-", "ernzerhof", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "approximation", "start": 139, "end": 152, "i_start": 18, "i_end": 18}, "action": {"text": "parametrized", "start": 98, "end": 110, "i_start": 13, "i_end": 13}}, {"character": {"text": "perdew", "start": 165, "end": 171, "i_start": 21, "i_end": 21}, "action": {"text": "proposed", "start": 153, "end": 161, "i_start": 19, "i_end": 19}}], "id": 4309}, {"sent": "machine learning models , especially deep neural networks , have been deployed prominently in many real-world applications , such as image classification .", "tokens": ["machine", "learning", "models", ",", "especially", "deep", "neural", "networks", ",", "have", "been", "deployed", "prominently", "in", "many", "real", "-", "world", "applications", ",", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "machine learning models", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "have been deployed", "start": 60, "end": 78, "i_start": 9, "i_end": 11}}], "id": 4310}, {"sent": "convolutional neural networks have achieved the state-of-the-art performance in many applications such as computer vision .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "many", "applications", "such", "as", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 65, "end": 76, "i_start": 13, "i_end": 13}}], "id": 4311}, {"sent": "however , in it was observed that , in typical indoor scenarios the majority of the collected energy at the photodetector comes from the los component .", "tokens": ["however", ",", "in", "it", "was", "observed", "that", ",", "in", "typical", "indoor", "scenarios", "the", "majority", "of", "the", "collected", "energy", "at", "the", "photodetector", "comes", "from", "the", "los", "component", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "was observed", "start": 16, "end": 28, "i_start": 4, "i_end": 5}}, {"subject": {"text": "the majority of the collected energy at the photodetector", "start": 64, "end": 121, "i_start": 12, "i_end": 20}, "verb": {"text": "comes", "start": 122, "end": 127, "i_start": 21, "i_end": 21}}], "id": 4312}, {"sent": "clearly , these two categories of operads are isomorphic .", "tokens": ["clearly", ",", "these", "two", "categories", "of", "operads", "are", "isomorphic", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these two categories of operads", "start": 10, "end": 41, "i_start": 2, "i_end": 6}, "verb": {"text": "are", "start": 42, "end": 45, "i_start": 7, "i_end": 7}}], "id": 4313}, {"sent": "deep neural networks have launched a profound reformation in a wide variety of fields such as image classification , detection , and segmentation .", "tokens": ["deep", "neural", "networks", "have", "launched", "a", "profound", "reformation", "in", "a", "wide", "variety", "of", "fields", "such", "as", "image", "classification", ",", "detection", ",", "and", "segmentation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have launched", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "launched", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}], "id": 4314}, {"sent": "adversarial training has recently been shown to be one of the most successful methods for increasing the robustness to adversarial perturbations of deep neural networks .", "tokens": ["adversarial", "training", "has", "recently", "been", "shown", "to", "be", "one", "of", "the", "most", "successful", "methods", "for", "increasing", "the", "robustness", "to", "adversarial", "perturbations", "of", "deep", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "adversarial training", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "been shown", "start": 34, "end": 44, "i_start": 4, "i_end": 5}}, {"subject": {"text": "adversarial training", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "has", "start": 21, "end": 24, "i_start": 2, "i_end": 2}}], "id": 4315}, {"sent": "the parameters of the potential were obtained by matching the forces with the ones obtained by dft calculations using the pbe exchange-correlation functional .", "tokens": ["the", "parameters", "of", "the", "potential", "were", "obtained", "by", "matching", "the", "forces", "with", "the", "ones", "obtained", "by", "dft", "calculations", "using", "the", "pbe", "exchange", "-", "correlation", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the parameters of the potential", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "were obtained", "start": 32, "end": 45, "i_start": 5, "i_end": 6}}, {"character": {"text": "calculations", "start": 99, "end": 111, "i_start": 17, "i_end": 17}, "action": {"text": "obtained", "start": 83, "end": 91, "i_start": 14, "i_end": 14}}, {"character": {"text": "calculations", "start": 99, "end": 111, "i_start": 17, "i_end": 17}, "action": {"text": "using", "start": 112, "end": 117, "i_start": 18, "i_end": 18}}], "id": 4316}, {"sent": "for the version with power functions , the best corresponding clairvoyant result is a -speed o-competitive algorithm .", "tokens": ["for", "the", "version", "with", "power", "functions", ",", "the", "best", "corresponding", "clairvoyant", "result", "is", "a", "-speed", "o", "-", "competitive", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the best corresponding clairvoyant result", "start": 39, "end": 80, "i_start": 7, "i_end": 11}, "verb": {"text": "is", "start": 81, "end": 83, "i_start": 12, "i_end": 12}}], "id": 4317}, {"sent": "we find a two parameter family of pp-wave backgrounds that includes as special cases the bmn pp-wave background .", "tokens": ["we", "find", "a", "two", "parameter", "family", "of", "pp", "-", "wave", "backgrounds", "that", "includes", "as", "special", "cases", "the", "bmn", "pp", "-", "wave", "background", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 4318}, {"sent": "generalized gradient approximation was used for the exchangecorrelation energy , within the perdew-burke-ernzerhof functional form .", "tokens": ["generalized", "gradient", "approximation", "was", "used", "for", "the", "exchangecorrelation", "energy", ",", "within", "the", "perdew", "-", "burke", "-", "ernzerhof", "functional", "form", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generalized gradient approximation", "start": 0, "end": 34, "i_start": 0, "i_end": 2}, "verb": {"text": "was used", "start": 35, "end": 43, "i_start": 3, "i_end": 4}}], "id": 4319}, {"sent": "recently , deep convolutional neural networks have attracted a lot of attention in visual recognition due to its good performance .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "attracted", "a", "lot", "of", "attention", "in", "visual", "recognition", "due", "to", "its", "good", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have attracted", "start": 46, "end": 60, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "attracted", "start": 51, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 118, "end": 129, "i_start": 19, "i_end": 19}}], "id": 4320}, {"sent": "demanding correct relic abundance we constrain the parameter space of the scalar mixing angle and heavy scalar boson mass .", "tokens": ["demanding", "correct", "relic", "abundance", "we", "constrain", "the", "parameter", "space", "of", "the", "scalar", "mixing", "angle", "and", "heavy", "scalar", "boson", "mass", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 34, "end": 36, "i_start": 4, "i_end": 4}, "verb": {"text": "demanding", "start": 0, "end": 9, "i_start": 0, "i_end": 0}}, {"subject": {"text": "we", "start": 34, "end": 36, "i_start": 4, "i_end": 4}, "verb": {"text": "constrain", "start": 37, "end": 46, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 4, "i_end": 4}, "action": {"text": "constrain", "start": 37, "end": 46, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 4, "i_end": 4}, "action": {"text": "demanding", "start": 0, "end": 9, "i_start": 0, "i_end": 0}}], "id": 4321}, {"sent": "note that the code of st-cgan are not publicly available , we can not evaluate them on the usr testing data .", "tokens": ["note", "that", "the", "code", "of", "st", "-", "cgan", "are", "not", "publicly", "available", ",", "we", "can", "not", "evaluate", "them", "on", "the", "usr", "testing", "data", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 59, "end": 61, "i_start": 13, "i_end": 13}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "we", "start": 59, "end": 61, "i_start": 13, "i_end": 13}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 8, "i_end": 8}}, {"subject": {"text": "we", "start": 59, "end": 61, "i_start": 13, "i_end": 13}, "verb": {"text": "evaluate", "start": 70, "end": 78, "i_start": 16, "i_end": 16}}, {"character": {"text": "we", "start": 59, "end": 61, "i_start": 13, "i_end": 13}, "action": {"text": "evaluate", "start": 70, "end": 78, "i_start": 16, "i_end": 16}}], "id": 4322}, {"sent": "the suffix tree is a data storage and fast search technique which is commonly used in fields such as computational biology for applications such as string matching applied to dna sequences .", "tokens": ["the", "suffix", "tree", "is", "a", "data", "storage", "and", "fast", "search", "technique", "which", "is", "commonly", "used", "in", "fields", "such", "as", "computational", "biology", "for", "applications", "such", "as", "string", "matching", "applied", "to", "dna", "sequences", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the suffix tree", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 4323}, {"sent": "deep convolutional neural networks have recently shown immense success for various image recognition tasks , such as object recognition .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "recently", "shown", "immense", "success", "for", "various", "image", "recognition", "tasks", ",", "such", "as", "object", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "shown", "start": 49, "end": 54, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 63, "end": 70, "i_start": 8, "i_end": 8}}], "id": 4324}, {"sent": "although there are studies striving to indirectly infer the underlying anatomical connectivity from the functional network , it has been shown that strong functional correlations may exist with no direct physical connection .", "tokens": ["although", "there", "are", "studies", "striving", "to", "indirectly", "infer", "the", "underlying", "anatomical", "connectivity", "from", "the", "functional", "network", ",", "it", "has", "been", "shown", "that", "strong", "functional", "correlations", "may", "exist", "with", "no", "direct", "physical", "connection", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 125, "end": 127, "i_start": 17, "i_end": 17}, "verb": {"text": "has been shown", "start": 128, "end": 142, "i_start": 18, "i_end": 20}}, {"subject": {"text": "strong functional correlations", "start": 148, "end": 178, "i_start": 22, "i_end": 24}, "verb": {"text": "exist", "start": 183, "end": 188, "i_start": 26, "i_end": 26}}], "id": 4325}, {"sent": "besides , their gainbased pruning is based on the greedy algorithm presented in with a bound looser than our online bound .", "tokens": ["besides", ",", "their", "gainbased", "pruning", "is", "based", "on", "the", "greedy", "algorithm", "presented", "in", "with", "a", "bound", "looser", "than", "our", "online", "bound", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "their gainbased pruning", "start": 10, "end": 33, "i_start": 2, "i_end": 4}, "verb": {"text": "is based", "start": 34, "end": 42, "i_start": 5, "i_end": 6}}], "id": 4326}, {"sent": "however the experimental bounds on the flavor changing processes can provide stronger bounds on mrad if the fermion mass hierarchy stems from the wavefunction localization .", "tokens": ["however", "the", "experimental", "bounds", "on", "the", "flavor", "changing", "processes", "can", "provide", "stronger", "bounds", "on", "mrad", "if", "the", "fermion", "mass", "hierarchy", "stems", "from", "the", "wavefunction", "localization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the experimental bounds on the flavor changing processes", "start": 8, "end": 64, "i_start": 1, "i_end": 8}, "verb": {"text": "can provide", "start": 65, "end": 76, "i_start": 9, "i_end": 10}}], "id": 4327}, {"sent": "cluster algebras were introduced by fomin and zelevinsky in order to give a combinatorial framework for understanding total positivity in algebraic groups and dual canonical bases in quantum groups .", "tokens": ["cluster", "algebras", "were", "introduced", "by", "fomin", "and", "zelevinsky", "in", "order", "to", "give", "a", "combinatorial", "framework", "for", "understanding", "total", "positivity", "in", "algebraic", "groups", "and", "dual", "canonical", "bases", "in", "quantum", "groups", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were introduced", "start": 17, "end": 32, "i_start": 2, "i_end": 3}}, {"character": {"text": "fomin", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "zelevinsky", "start": 46, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "fomin", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "give", "start": 69, "end": 73, "i_start": 11, "i_end": 11}}, {"character": {"text": "zelevinsky", "start": 46, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "give", "start": 69, "end": 73, "i_start": 11, "i_end": 11}}], "id": 4328}, {"sent": "we use standard tools from computational algebraic geometry , following the notation from .", "tokens": ["we", "use", "standard", "tools", "from", "computational", "algebraic", "geometry", ",", "following", "the", "notation", "from", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 4329}, {"sent": "deep neural networks have achieved impressive performance on tasks across a variety of domains , including vision .", "tokens": ["deep", "neural", "networks", "have", "achieved", "impressive", "performance", "on", "tasks", "across", "a", "variety", "of", "domains", ",", "including", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 46, "end": 57, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 46, "end": 57, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 35, "end": 45, "i_start": 5, "i_end": 5}}], "id": 4330}, {"sent": "this effect is called dynamic heterogeneity .", "tokens": ["this", "effect", "is", "called", "dynamic", "heterogeneity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this effect", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is called", "start": 12, "end": 21, "i_start": 2, "i_end": 3}}], "id": 4331}, {"sent": "in recent years , deep convolutional neural networks have demonstrated dramatic improvements in performance for computer vision tasks such as object classification , detection , and segmentation .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "demonstrated", "dramatic", "improvements", "in", "performance", "for", "computer", "vision", "tasks", "such", "as", "object", "classification", ",", "detection", ",", "and", "segmentation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have demonstrated", "start": 53, "end": 70, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "demonstrated", "start": 58, "end": 70, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "improvements", "start": 80, "end": 92, "i_start": 11, "i_end": 11}}], "id": 4332}, {"sent": "in , quadratic systems of size larger than 15 equations are very difficult .", "tokens": ["in", ",", "quadratic", "systems", "of", "size", "larger", "than", "15", "equations", "are", "very", "difficult", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quadratic systems of size larger than 15 equations", "start": 5, "end": 55, "i_start": 2, "i_end": 9}, "verb": {"text": "are", "start": 56, "end": 59, "i_start": 10, "i_end": 10}}], "id": 4333}, {"sent": "deep neural networks have demonstrated dramatically accurate results for challenging tasks .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "dramatically", "accurate", "results", "for", "challenging", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}], "id": 4334}, {"sent": "face-on view of the late stage of the shock passage in the model sswb .", "tokens": ["face", "-", "on", "view", "of", "the", "late", "stage", "of", "the", "shock", "passage", "in", "the", "model", "sswb", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4335}, {"sent": "understanding the growth and development of social networks is a task of great importance in many disciplines , such as sociology , biology , and computer science , where systems are often represented as graphs .", "tokens": ["understanding", "the", "growth", "and", "development", "of", "social", "networks", "is", "a", "task", "of", "great", "importance", "in", "many", "disciplines", ",", "such", "as", "sociology", ",", "biology", ",", "and", "computer", "science", ",", "where", "systems", "are", "often", "represented", "as", "graphs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "understanding the growth and development of social networks", "start": 0, "end": 59, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 60, "end": 62, "i_start": 8, "i_end": 8}}], "id": 4336}, {"sent": "xu et al uses graph neural networks to find binary similarity between different execution platforms .", "tokens": ["xu", "et", "al", "uses", "graph", "neural", "networks", "to", "find", "binary", "similarity", "between", "different", "execution", "platforms", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "xu et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "uses", "start": 9, "end": 13, "i_start": 3, "i_end": 3}}, {"character": {"text": "xu", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "uses", "start": 9, "end": 13, "i_start": 3, "i_end": 3}}, {"character": {"text": "xu", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 39, "end": 43, "i_start": 8, "i_end": 8}}], "id": 4337}, {"sent": "convolutional neural network has achieved great success in image recognition and object detection .", "tokens": ["convolutional", "neural", "network", "has", "achieved", "great", "success", "in", "image", "recognition", "and", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural network", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "has achieved", "start": 29, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "network", "start": 21, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 33, "end": 41, "i_start": 4, "i_end": 4}}, {"character": {"text": "network", "start": 21, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 48, "end": 55, "i_start": 6, "i_end": 6}}, {"character": {"text": "network", "start": 21, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "recognition", "start": 65, "end": 76, "i_start": 9, "i_end": 9}}, {"character": {"text": "network", "start": 21, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "detection", "start": 88, "end": 97, "i_start": 12, "i_end": 12}}], "id": 4338}, {"sent": "proximal gradient methods generalize gradient descent , but typically require the nonsmooth term to be separable over the optimization variable .", "tokens": ["proximal", "gradient", "methods", "generalize", "gradient", "descent", ",", "but", "typically", "require", "the", "nonsmooth", "term", "to", "be", "separable", "over", "the", "optimization", "variable", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "proximal gradient methods", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "generalize", "start": 26, "end": 36, "i_start": 3, "i_end": 3}}, {"subject": {"text": "proximal gradient methods", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "require", "start": 70, "end": 77, "i_start": 9, "i_end": 9}}, {"character": {"text": "methods", "start": 18, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "generalize", "start": 26, "end": 36, "i_start": 3, "i_end": 3}}, {"character": {"text": "methods", "start": 18, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "require", "start": 70, "end": 77, "i_start": 9, "i_end": 9}}], "id": 4339}, {"sent": "in , a cox regression-based model was used to develop a sepsis shock severity score that can handle data streams that are censored due to interventions .", "tokens": ["in", ",", "a", "cox", "regression", "-", "based", "model", "was", "used", "to", "develop", "a", "sepsis", "shock", "severity", "score", "that", "can", "handle", "data", "streams", "that", "are", "censored", "due", "to", "interventions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a cox regression-based model", "start": 5, "end": 33, "i_start": 2, "i_end": 7}, "verb": {"text": "was used", "start": 34, "end": 42, "i_start": 8, "i_end": 9}}, {"character": {"text": "sepsis", "start": 56, "end": 62, "i_start": 13, "i_end": 13}, "action": {"text": "shock", "start": 63, "end": 68, "i_start": 14, "i_end": 14}}, {"character": {"text": "score", "start": 78, "end": 83, "i_start": 16, "i_end": 16}, "action": {"text": "handle", "start": 93, "end": 99, "i_start": 19, "i_end": 19}}], "id": 4340}, {"sent": "although the tlb invalidation itself is fast , the process of context switches , transferring ipis across all possible cores , and waiting for all acknowledgements may be time consuming .", "tokens": ["although", "the", "tlb", "invalidation", "itself", "is", "fast", ",", "the", "process", "of", "context", "switches", ",", "transferring", "ipis", "across", "all", "possible", "cores", ",", "and", "waiting", "for", "all", "acknowledgements", "may", "be", "time", "consuming", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "the process of context switches", "start": 47, "end": 78, "i_start": 8, "i_end": 12}, "verb": {"text": "may be", "start": 164, "end": 170, "i_start": 26, "i_end": 27}}, {"character": {"text": "process", "start": 51, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "consuming", "start": 176, "end": 185, "i_start": 29, "i_end": 29}}], "id": 4341}, {"sent": "using deep learning to generate new objects has been studied in different data types , such as music .", "tokens": ["using", "deep", "learning", "to", "generate", "new", "objects", "has", "been", "studied", "in", "different", "data", "types", ",", "such", "as", "music", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4342}, {"sent": "we have also presented our preliminary results of shear-band structures in wormlike micellar solutions under the condition of fixed stress .", "tokens": ["we", "have", "also", "presented", "our", "preliminary", "results", "of", "shear", "-", "band", "structures", "in", "wormlike", "micellar", "solutions", "under", "the", "condition", "of", "fixed", "stress", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "presented", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "presented", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}], "id": 4343}, {"sent": "this case is also known as multiantenna broadcast channel precoding and the precoder design is dependant on the channels of the individual users .", "tokens": ["this", "case", "is", "also", "known", "as", "multiantenna", "broadcast", "channel", "precoding", "and", "the", "precoder", "design", "is", "dependant", "on", "the", "channels", "of", "the", "individual", "users", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this case", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "known", "start": 18, "end": 23, "i_start": 4, "i_end": 4}}, {"subject": {"text": "this case", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}, {"subject": {"text": "this case", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 92, "end": 94, "i_start": 14, "i_end": 14}}, {"character": {"text": "design", "start": 85, "end": 91, "i_start": 13, "i_end": 13}, "action": {"text": "dependant", "start": 95, "end": 104, "i_start": 15, "i_end": 15}}], "id": 4344}, {"sent": "in this section we evaluate mapc on a large scale multiclass detection setup constructed from imagenet data .", "tokens": ["in", "this", "section", "we", "evaluate", "mapc", "on", "a", "large", "scale", "multiclass", "detection", "setup", "constructed", "from", "imagenet", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "evaluate", "start": 19, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "evaluate", "start": 19, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "setup", "start": 71, "end": 76, "i_start": 12, "i_end": 12}, "action": {"text": "detection", "start": 61, "end": 70, "i_start": 11, "i_end": 11}}], "id": 4345}, {"sent": "likewise , the convolution layer in artificial neural networks has achieved great success .", "tokens": ["likewise", ",", "the", "convolution", "layer", "in", "artificial", "neural", "networks", "has", "achieved", "great", "success", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the convolution layer in artificial neural networks", "start": 11, "end": 62, "i_start": 2, "i_end": 8}, "verb": {"text": "has achieved", "start": 63, "end": 75, "i_start": 9, "i_end": 10}}, {"character": {"text": "layer", "start": 27, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 67, "end": 75, "i_start": 10, "i_end": 10}}], "id": 4346}, {"sent": "nevertheless , algorithms exist that can compute the nearest lattice point in reasonable time if the dimension is small .", "tokens": ["nevertheless", ",", "algorithms", "exist", "that", "can", "compute", "the", "nearest", "lattice", "point", "in", "reasonable", "time", "if", "the", "dimension", "is", "small", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "algorithms exist that can compute the nearest lattice point in reasonable time if the dimension is small", "start": 15, "end": 119, "i_start": 2, "i_end": 18}, "verb": {"text": "exist", "start": 26, "end": 31, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithms", "start": 15, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "compute", "start": 41, "end": 48, "i_start": 6, "i_end": 6}}], "id": 4347}, {"sent": "rtkdsm enhances vm security by monitoring many kernel objects from outside .", "tokens": ["rtkdsm", "enhances", "vm", "security", "by", "monitoring", "many", "kernel", "objects", "from", "outside", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "rtkdsm", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "enhances", "start": 7, "end": 15, "i_start": 1, "i_end": 1}}], "id": 4348}, {"sent": "dropout is a regularization technique for neural network models where randomly selected neurons are ignored during training .", "tokens": ["dropout", "is", "a", "regularization", "technique", "for", "neural", "network", "models", "where", "randomly", "selected", "neurons", "are", "ignored", "during", "training", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dropout", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}], "id": 4349}, {"sent": "differential privacy is a strong notion of algorithmic stability that was originally introduced to ensure data privacy .", "tokens": ["differential", "privacy", "is", "a", "strong", "notion", "of", "algorithmic", "stability", "that", "was", "originally", "introduced", "to", "ensure", "data", "privacy", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "differential privacy", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "privacy", "start": 13, "end": 20, "i_start": 1, "i_end": 1}, "action": {"text": "ensure", "start": 99, "end": 105, "i_start": 14, "i_end": 14}}], "id": 4350}, {"sent": "recently , many studies have revealed the true structure of real-world networks .", "tokens": ["recently", ",", "many", "studies", "have", "revealed", "the", "true", "structure", "of", "real", "-", "world", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "many studies", "start": 11, "end": 23, "i_start": 2, "i_end": 3}, "verb": {"text": "have revealed", "start": 24, "end": 37, "i_start": 4, "i_end": 5}}, {"character": {"text": "studies", "start": 16, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "revealed", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}], "id": 4351}, {"sent": "note that this subspace does not consist of the same algebra elements as in the hecke algebra .", "tokens": ["note", "that", "this", "subspace", "does", "not", "consist", "of", "the", "same", "algebra", "elements", "as", "in", "the", "hecke", "algebra", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this subspace", "start": 10, "end": 23, "i_start": 2, "i_end": 3}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "this subspace", "start": 10, "end": 23, "i_start": 2, "i_end": 3}, "verb": {"text": "consist", "start": 33, "end": 40, "i_start": 6, "i_end": 6}}], "id": 4352}, {"sent": "the idea of a strong power graph was introduced by singh and manilal as a generalization of power graphs of a finite group .", "tokens": ["the", "idea", "of", "a", "strong", "power", "graph", "was", "introduced", "by", "singh", "and", "manilal", "as", "a", "generalization", "of", "power", "graphs", "of", "a", "finite", "group", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the idea of a strong power graph", "start": 0, "end": 32, "i_start": 0, "i_end": 6}, "verb": {"text": "was introduced", "start": 33, "end": 47, "i_start": 7, "i_end": 8}}, {"character": {"text": "singh", "start": 51, "end": 56, "i_start": 10, "i_end": 10}, "action": {"text": "introduced", "start": 37, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "manilal", "start": 61, "end": 68, "i_start": 12, "i_end": 12}, "action": {"text": "introduced", "start": 37, "end": 47, "i_start": 8, "i_end": 8}}], "id": 4353}, {"sent": "to circumvent these issues , compound memristive synapse with multiple bistable devices in parallel was recently proposed to emulate analog weights .", "tokens": ["to", "circumvent", "these", "issues", ",", "compound", "memristive", "synapse", "with", "multiple", "bistable", "devices", "in", "parallel", "was", "recently", "proposed", "to", "emulate", "analog", "weights", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "compound memristive synapse with multiple bistable devices in parallel", "start": 29, "end": 99, "i_start": 5, "i_end": 13}, "verb": {"text": "proposed", "start": 113, "end": 121, "i_start": 16, "i_end": 16}}, {"subject": {"text": "compound memristive synapse with multiple bistable devices in parallel", "start": 29, "end": 99, "i_start": 5, "i_end": 13}, "verb": {"text": "was", "start": 100, "end": 103, "i_start": 14, "i_end": 14}}], "id": 4354}, {"sent": "generative adversarial networks have provided very powerful and efficient solutions for learning the generative model .", "tokens": ["generative", "adversarial", "networks", "have", "provided", "very", "powerful", "and", "efficient", "solutions", "for", "learning", "the", "generative", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "have provided", "start": 32, "end": 45, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "provided", "start": 37, "end": 45, "i_start": 4, "i_end": 4}}], "id": 4355}, {"sent": "impressive results have been demonstrated in several areas such as image inpainting .", "tokens": ["impressive", "results", "have", "been", "demonstrated", "in", "several", "areas", "such", "as", "image", "inpainting", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "impressive results", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "have been demonstrated", "start": 19, "end": 41, "i_start": 2, "i_end": 4}}, {"character": {"text": "results", "start": 11, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "impressive", "start": 0, "end": 10, "i_start": 0, "i_end": 0}}], "id": 4356}, {"sent": "the poisson regression model is a special case of generalized linear model .", "tokens": ["the", "poisson", "regression", "model", "is", "a", "special", "case", "of", "generalized", "linear", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the poisson regression model", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 4, "i_end": 4}}], "id": 4357}, {"sent": "this work implements a flexible ecc accelerator which supports arbitrary primes up to 256 bits , in contrast with only supports binary field modular multiplication in hardware .", "tokens": ["this", "work", "implements", "a", "flexible", "ecc", "accelerator", "which", "supports", "arbitrary", "primes", "up", "to", "256", "bits", ",", "in", "contrast", "with", "only", "supports", "binary", "field", "modular", "multiplication", "in", "hardware", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this work", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "implements", "start": 10, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "work", "start": 5, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "implements", "start": 10, "end": 20, "i_start": 2, "i_end": 2}}], "id": 4358}, {"sent": "specially , neural networks with deep hierarchical layers have achieved many breakthroughs in machine learning , which leads to the great research interests in deep learning .", "tokens": ["specially", ",", "neural", "networks", "with", "deep", "hierarchical", "layers", "have", "achieved", "many", "breakthroughs", "in", "machine", "learning", ",", "which", "leads", "to", "the", "great", "research", "interests", "in", "deep", "learning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural networks with deep hierarchical layers", "start": 12, "end": 57, "i_start": 2, "i_end": 7}, "verb": {"text": "have achieved", "start": 58, "end": 71, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 19, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 63, "end": 71, "i_start": 9, "i_end": 9}}, {"character": {"text": "breakthroughs", "start": 77, "end": 90, "i_start": 11, "i_end": 11}, "action": {"text": "leads", "start": 119, "end": 124, "i_start": 17, "i_end": 17}}], "id": 4359}, {"sent": "convolutional neural networks have recently achieved the state-of-the-art performance in many image analysis tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "achieved", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "many", "image", "analysis", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 74, "end": 85, "i_start": 14, "i_end": 14}}], "id": 4360}, {"sent": "for this purpose we consider the vector and axialvector current correlators in the hls .", "tokens": ["for", "this", "purpose", "we", "consider", "the", "vector", "and", "axialvector", "current", "correlators", "in", "the", "hls", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 17, "end": 19, "i_start": 3, "i_end": 3}, "verb": {"text": "consider", "start": 20, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 17, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "consider", "start": 20, "end": 28, "i_start": 4, "i_end": 4}}], "id": 4361}, {"sent": "the main aim here would be to highlight the physical processes which are crucial in understanding reionization and comparing with observations .", "tokens": ["the", "main", "aim", "here", "would", "be", "to", "highlight", "the", "physical", "processes", "which", "are", "crucial", "in", "understanding", "reionization", "and", "comparing", "with", "observations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the main aim here", "start": 0, "end": 17, "i_start": 0, "i_end": 3}, "verb": {"text": "would be", "start": 18, "end": 26, "i_start": 4, "i_end": 5}}], "id": 4362}, {"sent": "the bulge is a region of the galaxy which is of tremendous interest for understanding galaxy formation .", "tokens": ["the", "bulge", "is", "a", "region", "of", "the", "galaxy", "which", "is", "of", "tremendous", "interest", "for", "understanding", "galaxy", "formation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the bulge", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}], "id": 4363}, {"sent": "generative adversarial networks are technique for training generative models to produce realistic examples from an unknown distribution .", "tokens": ["generative", "adversarial", "networks", "are", "technique", "for", "training", "generative", "models", "to", "produce", "realistic", "examples", "from", "an", "unknown", "distribution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 70, "end": 76, "i_start": 8, "i_end": 8}, "action": {"text": "produce", "start": 80, "end": 87, "i_start": 10, "i_end": 10}}], "id": 4364}, {"sent": "the em algorithm is widely used to learn maximum likelihood parameter estimates for complex probabilistic models .", "tokens": ["the", "em", "algorithm", "is", "widely", "used", "to", "learn", "maximum", "likelihood", "parameter", "estimates", "for", "complex", "probabilistic", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the em algorithm", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 27, "end": 31, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the em algorithm", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 4365}, {"sent": "the grey shaded area indicates the error margin , which is estimated as described in the supplement .", "tokens": ["the", "grey", "shaded", "area", "indicates", "the", "error", "margin", ",", "which", "is", "estimated", "as", "described", "in", "the", "supplement", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the grey shaded area", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "indicates", "start": 21, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "area", "start": 16, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "indicates", "start": 21, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "supplement", "start": 89, "end": 99, "i_start": 16, "i_end": 16}, "action": {"text": "described", "start": 72, "end": 81, "i_start": 13, "i_end": 13}}], "id": 4366}, {"sent": "according to , there exists a unique kt-connection on any hermitian manifold .", "tokens": ["according", "to", ",", "there", "exists", "a", "unique", "kt", "-", "connection", "on", "any", "hermitian", "manifold", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 15, "end": 20, "i_start": 3, "i_end": 3}, "verb": {"text": "exists", "start": 21, "end": 27, "i_start": 4, "i_end": 4}}], "id": 4367}, {"sent": "recently , supervised deep learning approaches such as large-scale deep convolutional neural networks have been immensely successful in many high-level computer vision tasks such as image recognition .", "tokens": ["recently", ",", "supervised", "deep", "learning", "approaches", "such", "as", "large", "-", "scale", "deep", "convolutional", "neural", "networks", "have", "been", "immensely", "successful", "in", "many", "high", "-", "level", "computer", "vision", "tasks", "such", "as", "image", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "approaches", "start": 36, "end": 46, "i_start": 5, "i_end": 5}, "action": {"text": "successful", "start": 122, "end": 132, "i_start": 18, "i_end": 18}}], "id": 4368}, {"sent": "in recent years , deep convolutional neural networks have been widely used in a variety of computer vision tasks and have achieved unprecedented progress .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "been", "widely", "used", "in", "a", "variety", "of", "computer", "vision", "tasks", "and", "have", "achieved", "unprecedented", "progress", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "used", "start": 70, "end": 74, "i_start": 11, "i_end": 11}}, {"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have been", "start": 53, "end": 62, "i_start": 8, "i_end": 9}}, {"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "achieved", "start": 122, "end": 130, "i_start": 21, "i_end": 21}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 122, "end": 130, "i_start": 21, "i_end": 21}}], "id": 4369}, {"sent": "more recently , studies are focused on characterizing the dependence between estimation performance and the communication constraint .", "tokens": ["more", "recently", ",", "studies", "are", "focused", "on", "characterizing", "the", "dependence", "between", "estimation", "performance", "and", "the", "communication", "constraint", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "studies", "start": 16, "end": 23, "i_start": 3, "i_end": 3}, "verb": {"text": "are focused", "start": 24, "end": 35, "i_start": 4, "i_end": 5}}, {"character": {"text": "performance", "start": 88, "end": 99, "i_start": 12, "i_end": 12}, "action": {"text": "dependence", "start": 58, "end": 68, "i_start": 9, "i_end": 9}}], "id": 4370}, {"sent": "existing multitask deep models are not suitable to solve our problem because they assume similar learning difficulties and convergence rates across all tasks .", "tokens": ["existing", "multitask", "deep", "models", "are", "not", "suitable", "to", "solve", "our", "problem", "because", "they", "assume", "similar", "learning", "difficulties", "and", "convergence", "rates", "across", "all", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "existing multitask deep models", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "are not", "start": 31, "end": 38, "i_start": 4, "i_end": 5}}, {"character": {"text": "models", "start": 24, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "solve", "start": 51, "end": 56, "i_start": 8, "i_end": 8}}, {"character": {"text": "assume", "start": 82, "end": 88, "i_start": 13, "i_end": 13}, "action": {"text": "because", "start": 69, "end": 76, "i_start": 11, "i_end": 11}}, {"character": {"text": "models", "start": 24, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "assume", "start": 82, "end": 88, "i_start": 13, "i_end": 13}}], "id": 4371}, {"sent": "indeed , as was already said , nucleon is a soliton of an effective meson lagrangian at large nc .", "tokens": ["indeed", ",", "as", "was", "already", "said", ",", "nucleon", "is", "a", "soliton", "of", "an", "effective", "meson", "lagrangian", "at", "large", "nc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "nucleon", "start": 31, "end": 38, "i_start": 7, "i_end": 7}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 8, "i_end": 8}}, {"character": {"text": "lagrangian", "start": 74, "end": 84, "i_start": 15, "i_end": 15}, "action": {"text": "effective", "start": 58, "end": 67, "i_start": 13, "i_end": 13}}], "id": 4372}, {"sent": "millimeter-wave communications has been recognized as one of the important technologies in the evolving 5g new radio .", "tokens": ["millimeter", "-", "wave", "communications", "has", "been", "recognized", "as", "one", "of", "the", "important", "technologies", "in", "the", "evolving", "5", "g", "new", "radio", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "millimeter-wave communications", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "has been recognized", "start": 31, "end": 50, "i_start": 4, "i_end": 6}}], "id": 4373}, {"sent": "the largest eigenvalue is the fivefold degenerate state at the r point , with eigenvalue 14 point 461 .", "tokens": ["the", "largest", "eigenvalue", "is", "the", "fivefold", "degenerate", "state", "at", "the", "r", "point", ",", "with", "eigenvalue", "14", "point", "461", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the largest eigenvalue", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}], "id": 4374}, {"sent": "characterize those commutative groupoid rings which do not have n-capacitor .", "tokens": ["characterize", "those", "commutative", "groupoid", "rings", "which", "do", "not", "have", "n", "-", "capacitor", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "rings", "start": 40, "end": 45, "i_start": 4, "i_end": 4}, "action": {"text": "not have", "start": 55, "end": 63, "i_start": 7, "i_end": 8}}], "id": 4375}, {"sent": "approximation in sobolev spaces by kernel expansions .", "tokens": ["approximation", "in", "sobolev", "spaces", "by", "kernel", "expansions", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4376}, {"sent": "the obtained neff values are summarized in table x .", "tokens": ["the", "obtained", "neff", "values", "are", "summarized", "in", "table", "x", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the obtained neff values", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "are summarized", "start": 25, "end": 39, "i_start": 4, "i_end": 5}}], "id": 4377}, {"sent": "some of these graph generators mechanistically model network growth .", "tokens": ["some", "of", "these", "graph", "generators", "mechanistically", "model", "network", "growth", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "some of these graph generators", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "model", "start": 47, "end": 52, "i_start": 6, "i_end": 6}}, {"character": {"text": "some", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "model", "start": 47, "end": 52, "i_start": 6, "i_end": 6}}], "id": 4378}, {"sent": "this asymmetry is a direct manifestation of the broken time-reversal symmetry characteristic of a complex superconducting order parameter .", "tokens": ["this", "asymmetry", "is", "a", "direct", "manifestation", "of", "the", "broken", "time", "-", "reversal", "symmetry", "characteristic", "of", "a", "complex", "superconducting", "order", "parameter", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this asymmetry", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "symmetry", "start": 69, "end": 77, "i_start": 12, "i_end": 12}, "action": {"text": "manifestation", "start": 27, "end": 40, "i_start": 5, "i_end": 5}}], "id": 4379}, {"sent": "for the past several years , deep neural networks have increased in popularity thanks to their ability to attain high accuracy and performance in a multitude of machine learning tasks -eg , image and speech recognition .", "tokens": ["for", "the", "past", "several", "years", ",", "deep", "neural", "networks", "have", "increased", "in", "popularity", "thanks", "to", "their", "ability", "to", "attain", "high", "accuracy", "and", "performance", "in", "a", "multitude", "of", "machine", "learning", "tasks", "-eg", ",", "image", "and", "speech", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 29, "end": 49, "i_start": 6, "i_end": 8}, "verb": {"text": "have increased", "start": 50, "end": 64, "i_start": 9, "i_end": 10}}, {"character": {"text": "networks", "start": 41, "end": 49, "i_start": 8, "i_end": 8}, "action": {"text": "attain", "start": 106, "end": 112, "i_start": 18, "i_end": 18}}, {"character": {"text": "networks", "start": 41, "end": 49, "i_start": 8, "i_end": 8}, "action": {"text": "performance", "start": 131, "end": 142, "i_start": 22, "i_end": 22}}], "id": 4380}, {"sent": "the coefficient 2kf is a decent approximation to the true adjoint is applicable only for string tension .", "tokens": ["the", "coefficient", "2kf", "is", "a", "decent", "approximation", "to", "the", "true", "adjoint", "is", "applicable", "only", "for", "string", "tension", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the coefficient 2kf", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 4381}, {"sent": "we will use this ability to extend the classical turing machines to the internal turing machines .", "tokens": ["we", "will", "use", "this", "ability", "to", "extend", "the", "classical", "turing", "machines", "to", "the", "internal", "turing", "machines", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will use", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extend", "start": 28, "end": 34, "i_start": 6, "i_end": 6}}], "id": 4382}, {"sent": "micrornas are small non-coding rna molecules that can control the function of their target messenger rnas by down-regulating the expression of the targets .", "tokens": ["micrornas", "are", "small", "non", "-", "coding", "rna", "molecules", "that", "can", "control", "the", "function", "of", "their", "target", "messenger", "rnas", "by", "down", "-", "regulating", "the", "expression", "of", "the", "targets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "micrornas", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 10, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "molecules", "start": 35, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "-", "start": 23, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "molecules", "start": 35, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "control", "start": 54, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "messenger", "start": 91, "end": 100, "i_start": 16, "i_end": 16}, "action": {"text": "function", "start": 66, "end": 74, "i_start": 12, "i_end": 12}}, {"character": {"text": "molecules", "start": 35, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "target", "start": 84, "end": 90, "i_start": 15, "i_end": 15}}, {"character": {"text": "molecules", "start": 35, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "down", "start": 109, "end": 113, "i_start": 19, "i_end": 19}}], "id": 4383}, {"sent": "we obtain samples from the posterior distribution of the dp mixture model using the blocked gibbs sampler .", "tokens": ["we", "obtain", "samples", "from", "the", "posterior", "distribution", "of", "the", "dp", "mixture", "model", "using", "the", "blocked", "gibbs", "sampler", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "obtain", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "obtain", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 74, "end": 79, "i_start": 12, "i_end": 12}}], "id": 4384}, {"sent": "zehnder , finite energy foliations of tight three-spheres and hamiltonian dynamics .", "tokens": ["zehnder", ",", "finite", "energy", "foliations", "of", "tight", "three", "-", "spheres", "and", "hamiltonian", "dynamics", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4385}, {"sent": "deep neural networks have achieved great success in cognitive applications such as image classification .", "tokens": ["deep", "neural", "networks", "have", "achieved", "great", "success", "in", "cognitive", "applications", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 41, "end": 48, "i_start": 6, "i_end": 6}}], "id": 4386}, {"sent": "fuel management programs have been extensively implemented in the usa and australia in an effort to lessen the risk posed by wildfire .", "tokens": ["fuel", "management", "programs", "have", "been", "extensively", "implemented", "in", "the", "usa", "and", "australia", "in", "an", "effort", "to", "lessen", "the", "risk", "posed", "by", "wildfire", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "fuel management programs", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "implemented", "start": 47, "end": 58, "i_start": 6, "i_end": 6}}, {"subject": {"text": "fuel management programs", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 25, "end": 34, "i_start": 3, "i_end": 4}}], "id": 4387}, {"sent": "recurrent neural nets , especially the long short-term memory have brought about breakthroughs in solving complex sequence modelling tasks in various domains such video understanding , speech recognition and natural language processing .", "tokens": ["recurrent", "neural", "nets", ",", "especially", "the", "long", "short", "-", "term", "memory", "have", "brought", "about", "breakthroughs", "in", "solving", "complex", "sequence", "modelling", "tasks", "in", "various", "domains", "such", "video", "understanding", ",", "speech", "recognition", "and", "natural", "language", "processing", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "recurrent neural nets", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "have brought about", "start": 62, "end": 80, "i_start": 11, "i_end": 13}}, {"character": {"text": "nets", "start": 17, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "breakthroughs", "start": 81, "end": 94, "i_start": 14, "i_end": 14}}], "id": 4388}, {"sent": "relativistic spin networks and quantum gravity .", "tokens": ["relativistic", "spin", "networks", "and", "quantum", "gravity", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4389}, {"sent": "kipf and welling applied a similar localized spectral filter , which is further simplified using the first-order approximation .", "tokens": ["kipf", "and", "welling", "applied", "a", "similar", "localized", "spectral", "filter", ",", "which", "is", "further", "simplified", "using", "the", "first", "-", "order", "approximation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "welling", "start": 9, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "kipf", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "welling", "start": 9, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "applied", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "kipf", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "applied", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "welling", "start": 9, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "applied", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}], "id": 4390}, {"sent": "rage uses atomic opacities compiled from the oplib database 7 and can evolve multimaterial flows with several options of eos .", "tokens": ["rage", "uses", "atomic", "opacities", "compiled", "from", "the", "oplib", "database", "7", "and", "can", "evolve", "multimaterial", "flows", "with", "several", "options", "of", "eos", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "rage", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "uses", "start": 5, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "rage", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "evolve", "start": 70, "end": 76, "i_start": 12, "i_end": 12}}, {"character": {"text": "rage", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "uses", "start": 5, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "rage", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "evolve", "start": 70, "end": 76, "i_start": 12, "i_end": 12}}], "id": 4391}, {"sent": "moreover , the dual symmetry also combines with supersymmetry into dual superconformal symmetry .", "tokens": ["moreover", ",", "the", "dual", "symmetry", "also", "combines", "with", "supersymmetry", "into", "dual", "superconformal", "symmetry", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dual symmetry", "start": 11, "end": 28, "i_start": 2, "i_end": 4}, "verb": {"text": "combines", "start": 34, "end": 42, "i_start": 6, "i_end": 6}}], "id": 4392}, {"sent": "a deterministic energy harvesting model for the gaussian rs channel was considered in where delay and nodelay constrained traffic were studied .", "tokens": ["a", "deterministic", "energy", "harvesting", "model", "for", "the", "gaussian", "rs", "channel", "was", "considered", "in", "where", "delay", "and", "nodelay", "constrained", "traffic", "were", "studied", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a deterministic energy harvesting model for the gaussian rs channel", "start": 0, "end": 67, "i_start": 0, "i_end": 9}, "verb": {"text": "was considered", "start": 68, "end": 82, "i_start": 10, "i_end": 11}}], "id": 4393}, {"sent": "the simple images contain mostly centered and clutter-free objects , unlike the challenging pas-cal voc 2012 .", "tokens": ["the", "simple", "images", "contain", "mostly", "centered", "and", "clutter", "-", "free", "objects", ",", "unlike", "the", "challenging", "pas", "-", "cal", "voc", "2012", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the simple images", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "contain", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "images", "start": 11, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "contain", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}], "id": 4394}, {"sent": "the power spectrum is the legendre transform of the two-point correlation function , and is more commonly encountered for individually for the each wmap frequency band , theoretical predictions .", "tokens": ["the", "power", "spectrum", "is", "the", "legendre", "transform", "of", "the", "two", "-", "point", "correlation", "function", ",", "and", "is", "more", "commonly", "encountered", "for", "individually", "for", "the", "each", "wmap", "frequency", "band", ",", "theoretical", "predictions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the power spectrum", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the power spectrum", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "encountered", "start": 106, "end": 117, "i_start": 19, "i_end": 19}}], "id": 4395}, {"sent": "the flux of hard x-ray emission measured by the ginga telescope for the central galactic radian .", "tokens": ["the", "flux", "of", "hard", "x", "-", "ray", "emission", "measured", "by", "the", "ginga", "telescope", "for", "the", "central", "galactic", "radian", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "telescope", "start": 54, "end": 63, "i_start": 12, "i_end": 12}, "action": {"text": "measured", "start": 32, "end": 40, "i_start": 8, "i_end": 8}}], "id": 4396}, {"sent": "these are known as higgs family symmetries , or hf symmetries .", "tokens": ["these", "are", "known", "as", "higgs", "family", "symmetries", ",", "or", "hf", "symmetries", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "are known", "start": 6, "end": 15, "i_start": 1, "i_end": 2}}], "id": 4397}, {"sent": "in , for a markov eh process , and a static channel , a discrete power allocation problem is studied to maximize the throughput .", "tokens": ["in", ",", "for", "a", "markov", "eh", "process", ",", "and", "a", "static", "channel", ",", "a", "discrete", "power", "allocation", "problem", "is", "studied", "to", "maximize", "the", "throughput", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "a discrete power allocation problem", "start": 54, "end": 89, "i_start": 13, "i_end": 17}, "verb": {"text": "is studied", "start": 90, "end": 100, "i_start": 18, "i_end": 19}}], "id": 4398}, {"sent": "convolutional neural networks have achieved great success in many fields , such as object classification , face recognition .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "many", "fields", ",", "such", "as", "object", "classification", ",", "face", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "face", "start": 107, "end": 111, "i_start": 16, "i_end": 16}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}], "id": 4399}, {"sent": "after each convolution layer , we use the scaled exponential linear unit as the activation .", "tokens": ["after", "each", "convolution", "layer", ",", "we", "use", "the", "scaled", "exponential", "linear", "unit", "as", "the", "activation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}], "id": 4400}, {"sent": "we now proceed onto give examples of square interval .", "tokens": ["we", "now", "proceed", "onto", "give", "examples", "of", "square", "interval", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "give", "start": 20, "end": 24, "i_start": 4, "i_end": 4}}], "id": 4401}, {"sent": "bolme et al firstly introduce correlation filter into visual tracking with grayscale samples , keeping the object scale fixed in tracking .", "tokens": ["bolme", "et", "al", "firstly", "introduce", "correlation", "filter", "into", "visual", "tracking", "with", "grayscale", "samples", ",", "keeping", "the", "object", "scale", "fixed", "in", "tracking", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bolme et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "introduce", "start": 20, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "bolme", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "introduce", "start": 20, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "introduce", "start": 20, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "keeping", "start": 95, "end": 102, "i_start": 14, "i_end": 14}}], "id": 4402}, {"sent": "knot floer homology and the four-ball genus .", "tokens": ["knot", "floer", "homology", "and", "the", "four", "-", "ball", "genus", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4403}, {"sent": "generally , an adm charge corresponding to an asymptotic symmetry of a spacetime is defined via hamiltonian perturbation theory .", "tokens": ["generally", ",", "an", "adm", "charge", "corresponding", "to", "an", "asymptotic", "symmetry", "of", "a", "spacetime", "is", "defined", "via", "hamiltonian", "perturbation", "theory", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "an adm charge", "start": 12, "end": 25, "i_start": 2, "i_end": 4}, "verb": {"text": "corresponding", "start": 26, "end": 39, "i_start": 5, "i_end": 5}}, {"subject": {"text": "an adm charge", "start": 12, "end": 25, "i_start": 2, "i_end": 4}, "verb": {"text": "defined", "start": 84, "end": 91, "i_start": 14, "i_end": 14}}, {"character": {"text": "theory", "start": 121, "end": 127, "i_start": 18, "i_end": 18}, "action": {"text": "defined", "start": 84, "end": 91, "i_start": 14, "i_end": 14}}], "id": 4404}, {"sent": "can bessels inequality of super vector spaces with super inner .", "tokens": ["can", "bessels", "inequality", "of", "super", "vector", "spaces", "with", "super", "inner", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4405}, {"sent": "currently , generative adversarial networks are among the most successful approaches in building such models .", "tokens": ["currently", ",", "generative", "adversarial", "networks", "are", "among", "the", "most", "successful", "approaches", "in", "building", "such", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 12, "end": 43, "i_start": 2, "i_end": 4}, "verb": {"text": "are", "start": 44, "end": 47, "i_start": 5, "i_end": 5}}], "id": 4406}, {"sent": "we first use the microsoft coco dataset , where the object segmentation masks are provided for each image .", "tokens": ["we", "first", "use", "the", "microsoft", "coco", "dataset", ",", "where", "the", "object", "segmentation", "masks", "are", "provided", "for", "each", "image", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 9, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 9, "end": 12, "i_start": 2, "i_end": 2}}], "id": 4407}, {"sent": "the laser system is standard to calibrate timing and energy response for particle detectors .", "tokens": ["the", "laser", "system", "is", "standard", "to", "calibrate", "timing", "and", "energy", "response", "for", "particle", "detectors", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the laser system", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "system", "start": 10, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "calibrate", "start": 32, "end": 41, "i_start": 6, "i_end": 6}}], "id": 4408}, {"sent": "the generalized gradient approximation parametrized by perdew-burke-ernzerhof was employed for the evaluation of the exchange-correlation functional .", "tokens": ["the", "generalized", "gradient", "approximation", "parametrized", "by", "perdew", "-", "burke", "-", "ernzerhof", "was", "employed", "for", "the", "evaluation", "of", "the", "exchange", "-", "correlation", "functional", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation parametrized by perdew-burke-ernzerhof", "start": 0, "end": 77, "i_start": 0, "i_end": 10}, "verb": {"text": "was employed", "start": 78, "end": 90, "i_start": 11, "i_end": 12}}, {"character": {"text": "perdew", "start": 55, "end": 61, "i_start": 6, "i_end": 6}, "action": {"text": "parametrized", "start": 39, "end": 51, "i_start": 4, "i_end": 4}}], "id": 4409}, {"sent": "in , the static solutions of screw and edge dislocations were given .", "tokens": ["in", ",", "the", "static", "solutions", "of", "screw", "and", "edge", "dislocations", "were", "given", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the static solutions of screw and edge dislocations", "start": 5, "end": 56, "i_start": 2, "i_end": 9}, "verb": {"text": "were given", "start": 57, "end": 67, "i_start": 10, "i_end": 11}}], "id": 4410}, {"sent": "a feature shared by many real systems modeled as complex networks is the presence of community structure .", "tokens": ["a", "feature", "shared", "by", "many", "real", "systems", "modeled", "as", "complex", "networks", "is", "the", "presence", "of", "community", "structure", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "a feature shared by many real systems modeled as complex networks", "start": 0, "end": 65, "i_start": 0, "i_end": 10}, "verb": {"text": "is", "start": 66, "end": 68, "i_start": 11, "i_end": 11}}, {"character": {"text": "systems", "start": 30, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "shared", "start": 10, "end": 16, "i_start": 2, "i_end": 2}}], "id": 4411}, {"sent": "however , previous studies have shown that fa can be solved by using several lgs to sense the whole cylinder turbulence path .", "tokens": ["however", ",", "previous", "studies", "have", "shown", "that", "fa", "can", "be", "solved", "by", "using", "several", "lgs", "to", "sense", "the", "whole", "cylinder", "turbulence", "path", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "previous studies", "start": 10, "end": 26, "i_start": 2, "i_end": 3}, "verb": {"text": "have shown", "start": 27, "end": 37, "i_start": 4, "i_end": 5}}, {"subject": {"text": "fa", "start": 43, "end": 45, "i_start": 7, "i_end": 7}, "verb": {"text": "solved", "start": 53, "end": 59, "i_start": 10, "i_end": 10}}, {"character": {"text": "studies", "start": 19, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 32, "end": 37, "i_start": 5, "i_end": 5}}], "id": 4412}, {"sent": "by dx , we denote the distance function induced on mx by .", "tokens": ["by", "dx", ",", "we", "denote", "the", "distance", "function", "induced", "on", "mx", "by", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 8, "end": 10, "i_start": 3, "i_end": 3}, "verb": {"text": "denote", "start": 11, "end": 17, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 3, "i_end": 3}, "action": {"text": "denote", "start": 11, "end": 17, "i_start": 4, "i_end": 4}}], "id": 4413}, {"sent": "in recent years , deep learning based algorithms have shown great power in object detection and classification tasks .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "based", "algorithms", "have", "shown", "great", "power", "in", "object", "detection", "and", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning based algorithms", "start": 18, "end": 48, "i_start": 4, "i_end": 7}, "verb": {"text": "have shown", "start": 49, "end": 59, "i_start": 8, "i_end": 9}}, {"character": {"text": "algorithms", "start": 38, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "shown", "start": 54, "end": 59, "i_start": 9, "i_end": 9}}], "id": 4414}, {"sent": "for the image encoder , we use a resnet-18 architecture , pretrained on imagenet .", "tokens": ["for", "the", "image", "encoder", ",", "we", "use", "a", "resnet-18", "architecture", ",", "pretrained", "on", "imagenet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 27, "end": 30, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 27, "end": 30, "i_start": 6, "i_end": 6}}], "id": 4415}, {"sent": "in recent years , deep neural networks have demonstrated outstanding performance in natural language processing , speech recognition , visual object recognition , object detection , and many other domains .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "demonstrated", "outstanding", "performance", "in", "natural", "language", "processing", ",", "speech", "recognition", ",", "visual", "object", "recognition", ",", "object", "detection", ",", "and", "many", "other", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have demonstrated", "start": 39, "end": 56, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "demonstrated", "start": 44, "end": 56, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 69, "end": 80, "i_start": 10, "i_end": 10}}], "id": 4416}, {"sent": "convolutional neural networks , as one of the widely used deep learning methods , have been proven to be very successful for object recognition in images .", "tokens": ["convolutional", "neural", "networks", ",", "as", "one", "of", "the", "widely", "used", "deep", "learning", "methods", ",", "have", "been", "proven", "to", "be", "very", "successful", "for", "object", "recognition", "in", "images", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been proven", "start": 82, "end": 98, "i_start": 14, "i_end": 16}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 110, "end": 120, "i_start": 20, "i_end": 20}}], "id": 4417}, {"sent": "besides l p regularizer , there are some other popular nonconvex regularizers for producing a sparse solution of a system or a vector optimization problem .", "tokens": ["besides", "l", "p", "regularizer", ",", "there", "are", "some", "other", "popular", "nonconvex", "regularizers", "for", "producing", "a", "sparse", "solution", "of", "a", "system", "or", "a", "vector", "optimization", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 26, "end": 31, "i_start": 5, "i_end": 5}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "producing", "start": 82, "end": 91, "i_start": 13, "i_end": 13}, "action": {"text": "regularizer", "start": 12, "end": 23, "i_start": 3, "i_end": 3}}], "id": 4418}, {"sent": "correlations between width and pulse peak time within bursts .", "tokens": ["correlations", "between", "width", "and", "pulse", "peak", "time", "within", "bursts", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4419}, {"sent": "deep neural networks recently have shown successful results on image-based recognition tasks .", "tokens": ["deep", "neural", "networks", "recently", "have", "shown", "successful", "results", "on", "image", "-", "based", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 35, "end": 40, "i_start": 5, "i_end": 5}}], "id": 4420}, {"sent": "for more details and applications we refer to and references therein .", "tokens": ["for", "more", "details", "and", "applications", "we", "refer", "to", "and", "references", "therein", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 34, "end": 36, "i_start": 5, "i_end": 5}, "verb": {"text": "refer", "start": 37, "end": 42, "i_start": 6, "i_end": 6}}, {"subject": {"text": "we", "start": 34, "end": 36, "i_start": 5, "i_end": 5}, "verb": {"text": "references", "start": 50, "end": 60, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 5, "i_end": 5}, "action": {"text": "refer", "start": 37, "end": 42, "i_start": 6, "i_end": 6}}], "id": 4421}, {"sent": "convolutional neural networks have been extensively used in different image and video processing applications .", "tokens": ["convolutional", "neural", "networks", "have", "been", "extensively", "used", "in", "different", "image", "and", "video", "processing", "applications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 52, "end": 56, "i_start": 6, "i_end": 6}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}], "id": 4422}, {"sent": "hydrogen itself is the main opacity source for earlier spectral types .", "tokens": ["hydrogen", "itself", "is", "the", "main", "opacity", "source", "for", "earlier", "spectral", "types", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "hydrogen itself", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "hydrogen", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "source", "start": 36, "end": 42, "i_start": 6, "i_end": 6}}], "id": 4423}, {"sent": "we use resnet-101 as the backbone network for extracting image feature .", "tokens": ["we", "use", "resnet-101", "as", "the", "backbone", "network", "for", "extracting", "image", "feature", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extracting", "start": 46, "end": 56, "i_start": 8, "i_end": 8}}], "id": 4424}, {"sent": "the gravitational field is a power-law function of the extra coordinate , y .", "tokens": ["the", "gravitational", "field", "is", "a", "power", "-", "law", "function", "of", "the", "extra", "coordinate", ",", "y", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the gravitational field", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "coordinate", "start": 61, "end": 71, "i_start": 12, "i_end": 12}, "action": {"text": "function", "start": 39, "end": 47, "i_start": 8, "i_end": 8}}], "id": 4425}, {"sent": "randomization has to be employed to achieve feasible beamforming vectors .", "tokens": ["randomization", "has", "to", "be", "employed", "to", "achieve", "feasible", "beamforming", "vectors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "randomization", "start": 0, "end": 13, "i_start": 0, "i_end": 0}, "verb": {"text": "has", "start": 14, "end": 17, "i_start": 1, "i_end": 1}}], "id": 4426}, {"sent": "more recently , there has been serious effort to have alternative ways of applying cnns in 3d data such as octnet .", "tokens": ["more", "recently", ",", "there", "has", "been", "serious", "effort", "to", "have", "alternative", "ways", "of", "applying", "cnns", "in", "3d", "data", "such", "as", "octnet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 16, "end": 21, "i_start": 3, "i_end": 3}, "verb": {"text": "has been", "start": 22, "end": 30, "i_start": 4, "i_end": 5}}], "id": 4427}, {"sent": "convolutional neural networks have recently been very successful on a variety of recognition and classification tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "been", "very", "successful", "on", "a", "variety", "of", "recognition", "and", "classification", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "been", "start": 44, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 54, "end": 64, "i_start": 7, "i_end": 7}}], "id": 4428}, {"sent": "the only significant difference is a fanning-out of the bar close to the binary components , right at the end of the simulation .", "tokens": ["the", "only", "significant", "difference", "is", "a", "fanning", "-", "out", "of", "the", "bar", "close", "to", "the", "binary", "components", ",", "right", "at", "the", "end", "of", "the", "simulation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the only significant difference", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 4, "i_end": 4}}], "id": 4429}, {"sent": "using this technique in , the information rate performance in frequency-flat rayleigh fading channel has also been studied .", "tokens": ["using", "this", "technique", "in", ",", "the", "information", "rate", "performance", "in", "frequency", "-", "flat", "rayleigh", "fading", "channel", "has", "also", "been", "studied", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the information rate performance in frequency-flat rayleigh fading channel", "start": 26, "end": 100, "i_start": 5, "i_end": 15}, "verb": {"text": "been studied", "start": 110, "end": 122, "i_start": 18, "i_end": 19}}, {"subject": {"text": "the information rate performance in frequency-flat rayleigh fading channel", "start": 26, "end": 100, "i_start": 5, "i_end": 15}, "verb": {"text": "has", "start": 101, "end": 104, "i_start": 16, "i_end": 16}}, {"character": {"text": "channel", "start": 93, "end": 100, "i_start": 15, "i_end": 15}, "action": {"text": "performance", "start": 47, "end": 58, "i_start": 8, "i_end": 8}}, {"character": {"text": "channel", "start": 93, "end": 100, "i_start": 15, "i_end": 15}, "action": {"text": "fading", "start": 86, "end": 92, "i_start": 14, "i_end": 14}}], "id": 4430}, {"sent": "convolutional neural networks has demonstrated overwhelming performance on image recognition , classification .", "tokens": ["convolutional", "neural", "networks", "has", "demonstrated", "overwhelming", "performance", "on", "image", "recognition", ",", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "has demonstrated", "start": 30, "end": 46, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 34, "end": 46, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 60, "end": 71, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 60, "end": 71, "i_start": 6, "i_end": 6}, "action": {"text": "overwhelming", "start": 47, "end": 59, "i_start": 5, "i_end": 5}}], "id": 4431}, {"sent": "there the condensate is a constant but in fact in our paper we propose the method which allow us to calculate the condensate varying in the space .", "tokens": ["there", "the", "condensate", "is", "a", "constant", "but", "in", "fact", "in", "our", "paper", "we", "propose", "the", "method", "which", "allow", "us", "to", "calculate", "the", "condensate", "varying", "in", "the", "space", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the condensate", "start": 6, "end": 20, "i_start": 1, "i_end": 2}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 60, "end": 62, "i_start": 12, "i_end": 12}, "verb": {"text": "propose", "start": 63, "end": 70, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 60, "end": 62, "i_start": 12, "i_end": 12}, "action": {"text": "propose", "start": 63, "end": 70, "i_start": 13, "i_end": 13}}, {"character": {"text": "method", "start": 75, "end": 81, "i_start": 15, "i_end": 15}, "action": {"text": "allow", "start": 88, "end": 93, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 60, "end": 62, "i_start": 12, "i_end": 12}, "action": {"text": "calculate", "start": 100, "end": 109, "i_start": 20, "i_end": 20}}], "id": 4432}, {"sent": "since alexnet , deep convolutional neural networks have led to rapid innovation in computer vision .", "tokens": ["since", "alexnet", ",", "deep", "convolutional", "neural", "networks", "have", "led", "to", "rapid", "innovation", "in", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 16, "end": 50, "i_start": 3, "i_end": 6}, "verb": {"text": "have led", "start": 51, "end": 59, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 42, "end": 50, "i_start": 6, "i_end": 6}, "action": {"text": "led", "start": 56, "end": 59, "i_start": 8, "i_end": 8}}], "id": 4433}, {"sent": "in recent years , deep convolutional neural networks have been shown to be exceptionally effective for image classification .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "been", "shown", "to", "be", "exceptionally", "effective", "for", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have been shown", "start": 53, "end": 68, "i_start": 8, "i_end": 10}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "effective", "start": 89, "end": 98, "i_start": 14, "i_end": 14}}], "id": 4434}, {"sent": "in recent years , convolutional neural networks has achieved remarkable results in a wide range of computer vision applications .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "has", "achieved", "remarkable", "results", "in", "a", "wide", "range", "of", "computer", "vision", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "has achieved", "start": 48, "end": 60, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 52, "end": 60, "i_start": 8, "i_end": 8}}], "id": 4435}, {"sent": "finally , we use the memory function approach to derive mct expressions for the tagged particle friction tensor and an effective temperature .", "tokens": ["finally", ",", "we", "use", "the", "memory", "function", "approach", "to", "derive", "mct", "expressions", "for", "the", "tagged", "particle", "friction", "tensor", "and", "an", "effective", "temperature", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "use", "start": 13, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 13, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "derive", "start": 49, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "temperature", "start": 129, "end": 140, "i_start": 21, "i_end": 21}, "action": {"text": "effective", "start": 119, "end": 128, "i_start": 20, "i_end": 20}}], "id": 4436}, {"sent": "naturally this shortcoming is reflected in the loop quantum cosmology .", "tokens": ["naturally", "this", "shortcoming", "is", "reflected", "in", "the", "loop", "quantum", "cosmology", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this shortcoming", "start": 10, "end": 26, "i_start": 1, "i_end": 2}, "verb": {"text": "is reflected", "start": 27, "end": 39, "i_start": 3, "i_end": 4}}], "id": 4437}, {"sent": "however , machine learning systems are vulnerable themselves , and can be targeted by attackers .", "tokens": ["however", ",", "machine", "learning", "systems", "are", "vulnerable", "themselves", ",", "and", "can", "be", "targeted", "by", "attackers", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "machine learning systems", "start": 10, "end": 34, "i_start": 2, "i_end": 4}, "verb": {"text": "are", "start": 35, "end": 38, "i_start": 5, "i_end": 5}}, {"subject": {"text": "machine learning systems", "start": 10, "end": 34, "i_start": 2, "i_end": 4}, "verb": {"text": "targeted", "start": 74, "end": 82, "i_start": 12, "i_end": 12}}, {"character": {"text": "systems", "start": 27, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "learning", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}], "id": 4438}, {"sent": "organizations and information systems development .", "tokens": ["organizations", "and", "information", "systems", "development", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4439}, {"sent": "freeanchor is implemented upon a state-of-the-art one-stage detector , retinanet as the backbone networks .", "tokens": ["freeanchor", "is", "implemented", "upon", "a", "state", "-", "of", "-", "the", "-", "art", "one", "-", "stage", "detector", ",", "retinanet", "as", "the", "backbone", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "freeanchor", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "verb": {"text": "is implemented", "start": 11, "end": 25, "i_start": 1, "i_end": 2}}], "id": 4440}, {"sent": "we performed the dft calculations using the vienna ab initio simulation package .", "tokens": ["we", "performed", "the", "dft", "calculations", "using", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "performed", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "performed", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 34, "end": 39, "i_start": 5, "i_end": 5}}], "id": 4441}, {"sent": "recently , the biologically inspired deep learning network has resulted in significant advances in many computer vision tasks .", "tokens": ["recently", ",", "the", "biologically", "inspired", "deep", "learning", "network", "has", "resulted", "in", "significant", "advances", "in", "many", "computer", "vision", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the biologically inspired deep learning network", "start": 11, "end": 58, "i_start": 2, "i_end": 7}, "verb": {"text": "has resulted", "start": 59, "end": 71, "i_start": 8, "i_end": 9}}, {"character": {"text": "network", "start": 51, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "learning", "start": 42, "end": 50, "i_start": 6, "i_end": 6}}, {"character": {"text": "biologically", "start": 15, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "inspired", "start": 28, "end": 36, "i_start": 4, "i_end": 4}}], "id": 4442}, {"sent": "the generalized gradient approximation according to perdewburke-ernzerhof was employed for both the generation of the pseudopotentials and the exchange-correlation functional .", "tokens": ["the", "generalized", "gradient", "approximation", "according", "to", "perdewburke", "-", "ernzerhof", "was", "employed", "for", "both", "the", "generation", "of", "the", "pseudopotentials", "and", "the", "exchange", "-", "correlation", "functional", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation according to perdewburke-ernzerhof", "start": 0, "end": 73, "i_start": 0, "i_end": 8}, "verb": {"text": "was employed", "start": 74, "end": 86, "i_start": 9, "i_end": 10}}], "id": 4443}, {"sent": "specifically , we use the adam stochastic gradient optimizer .", "tokens": ["specifically", ",", "we", "use", "the", "adam", "stochastic", "gradient", "optimizer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "use", "start": 18, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 18, "end": 21, "i_start": 3, "i_end": 3}}], "id": 4444}, {"sent": "deep neural networks have demonstrated success in many machine learning tasks , including image recognition , speech recognition , and even modelling mathematical learning , among many other domains .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "success", "in", "many", "machine", "learning", "tasks", ",", "including", "image", "recognition", ",", "speech", "recognition", ",", "and", "even", "modelling", "mathematical", "learning", ",", "among", "many", "other", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 39, "end": 46, "i_start": 5, "i_end": 5}}], "id": 4445}, {"sent": "a central extension and an extension by a derivation of a polynomial loop algebra over finite-dimensional simple lie algebra give a lie algebra which is isomorphic with a non-twisted affine kac-moody algebra .", "tokens": ["a", "central", "extension", "and", "an", "extension", "by", "a", "derivation", "of", "a", "polynomial", "loop", "algebra", "over", "finite", "-", "dimensional", "simple", "lie", "algebra", "give", "a", "lie", "algebra", "which", "is", "isomorphic", "with", "a", "non", "-", "twisted", "affine", "kac", "-", "moody", "algebra", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "a central extension and an extension by a derivation of a polynomial loop algebra over finite-dimensional simple lie algebra", "start": 0, "end": 124, "i_start": 0, "i_end": 20}, "verb": {"text": "give", "start": 125, "end": 129, "i_start": 21, "i_end": 21}}, {"character": {"text": "extension", "start": 10, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "give", "start": 125, "end": 129, "i_start": 21, "i_end": 21}}, {"character": {"text": "central", "start": 2, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "give", "start": 125, "end": 129, "i_start": 21, "i_end": 21}}, {"character": {"text": "extension", "start": 27, "end": 36, "i_start": 5, "i_end": 5}, "action": {"text": "give", "start": 125, "end": 129, "i_start": 21, "i_end": 21}}, {"character": {"text": "derivation", "start": 42, "end": 52, "i_start": 8, "i_end": 8}, "action": {"text": "give", "start": 125, "end": 129, "i_start": 21, "i_end": 21}}, {"character": {"text": "loop", "start": 69, "end": 73, "i_start": 12, "i_end": 12}, "action": {"text": "give", "start": 125, "end": 129, "i_start": 21, "i_end": 21}}, {"character": {"text": "polynomial", "start": 58, "end": 68, "i_start": 11, "i_end": 11}, "action": {"text": "give", "start": 125, "end": 129, "i_start": 21, "i_end": 21}}, {"character": {"text": "lie", "start": 113, "end": 116, "i_start": 19, "i_end": 19}, "action": {"text": "give", "start": 125, "end": 129, "i_start": 21, "i_end": 21}}, {"character": {"text": "dimensional", "start": 94, "end": 105, "i_start": 17, "i_end": 17}, "action": {"text": "give", "start": 125, "end": 129, "i_start": 21, "i_end": 21}}, {"character": {"text": "finite", "start": 87, "end": 93, "i_start": 15, "i_end": 15}, "action": {"text": "give", "start": 125, "end": 129, "i_start": 21, "i_end": 21}}], "id": 4446}, {"sent": "for demonstrating the effectiveness of our loss function , we train our model using a subset of the places365 data-set zhou et al .", "tokens": ["for", "demonstrating", "the", "effectiveness", "of", "our", "loss", "function", ",", "we", "train", "our", "model", "using", "a", "subset", "of", "the", "places365", "data", "-", "set", "zhou", "et", "al", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 59, "end": 61, "i_start": 9, "i_end": 9}, "verb": {"text": "train", "start": 62, "end": 67, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 59, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "train", "start": 62, "end": 67, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 59, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "using", "start": 78, "end": 83, "i_start": 13, "i_end": 13}}], "id": 4447}, {"sent": "we further show that such networks can distribute arbitrary entangled states between two distant parties , and can , by using such systems in parallel , transmit the higher dimensional systems states across the network .", "tokens": ["we", "further", "show", "that", "such", "networks", "can", "distribute", "arbitrary", "entangled", "states", "between", "two", "distant", "parties", ",", "and", "can", ",", "by", "using", "such", "systems", "in", "parallel", ",", "transmit", "the", "higher", "dimensional", "systems", "states", "across", "the", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 11, "end": 15, "i_start": 2, "i_end": 2}}, {"subject": {"text": "such networks", "start": 21, "end": 34, "i_start": 4, "i_end": 5}, "verb": {"text": "distribute", "start": 39, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 11, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "distribute", "start": 39, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "transmit", "start": 153, "end": 161, "i_start": 26, "i_end": 26}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "using", "start": 120, "end": 125, "i_start": 20, "i_end": 20}}], "id": 4448}, {"sent": "deep learning based approaches have shown great performance on many speech-related tasks .", "tokens": ["deep", "learning", "based", "approaches", "have", "shown", "great", "performance", "on", "many", "speech", "-", "related", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning based approaches", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "have shown", "start": 31, "end": 41, "i_start": 4, "i_end": 5}}, {"character": {"text": "approaches", "start": 20, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 36, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "approaches", "start": 20, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 48, "end": 59, "i_start": 7, "i_end": 7}}], "id": 4449}, {"sent": "in , resource allocation algorithms for multicast transmissions and tcp protocol performance were analysed in a long term evolution -based geo system , providing valuable solutions .", "tokens": ["in", ",", "resource", "allocation", "algorithms", "for", "multicast", "transmissions", "and", "tcp", "protocol", "performance", "were", "analysed", "in", "a", "long", "term", "evolution", "-based", "geo", "system", ",", "providing", "valuable", "solutions", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "resource allocation algorithms for multicast transmissions and tcp protocol performance", "start": 5, "end": 92, "i_start": 2, "i_end": 11}, "verb": {"text": "were analysed", "start": 93, "end": 106, "i_start": 12, "i_end": 13}}, {"character": {"text": "algorithms", "start": 25, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "allocation", "start": 14, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "protocol", "start": 72, "end": 80, "i_start": 10, "i_end": 10}, "action": {"text": "performance", "start": 81, "end": 92, "i_start": 11, "i_end": 11}}], "id": 4450}, {"sent": "it is well known that the classical low energy effective theory of d-branes can be described by the dbi action in curved spacetime .", "tokens": ["it", "is", "well", "known", "that", "the", "classical", "low", "energy", "effective", "theory", "of", "d", "-", "branes", "can", "be", "described", "by", "the", "dbi", "action", "in", "curved", "spacetime", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the classical low energy effective theory of d-branes", "start": 22, "end": 75, "i_start": 5, "i_end": 14}, "verb": {"text": "described", "start": 83, "end": 92, "i_start": 17, "i_end": 17}}, {"character": {"text": "theory", "start": 57, "end": 63, "i_start": 10, "i_end": 10}, "action": {"text": "effective", "start": 47, "end": 56, "i_start": 9, "i_end": 9}}], "id": 4451}, {"sent": "linear network coding and random linear network coding are essential for efficient utilization of network resources .", "tokens": ["linear", "network", "coding", "and", "random", "linear", "network", "coding", "are", "essential", "for", "efficient", "utilization", "of", "network", "resources", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "linear network coding and random linear network coding", "start": 0, "end": 54, "i_start": 0, "i_end": 7}, "verb": {"text": "are", "start": 55, "end": 58, "i_start": 8, "i_end": 8}}], "id": 4452}, {"sent": "we train two architectures for object detection , faster r-cnn with resnet101 , using the kittibox implementation .", "tokens": ["we", "train", "two", "architectures", "for", "object", "detection", ",", "faster", "r", "-", "cnn", "with", "resnet101", ",", "using", "the", "kittibox", "implementation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 80, "end": 85, "i_start": 15, "i_end": 15}}], "id": 4453}, {"sent": "yang et al ranked the similarity of image regions with foreground or background cues via graph-based manifold ranking .", "tokens": ["yang", "et", "al", "ranked", "the", "similarity", "of", "image", "regions", "with", "foreground", "or", "background", "cues", "via", "graph", "-", "based", "manifold", "ranking", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "yang et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "ranked", "start": 11, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "yang", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "ranked", "start": 11, "end": 17, "i_start": 3, "i_end": 3}}], "id": 4454}, {"sent": "the symbol tr denotes the trace over the flavor indices .", "tokens": ["the", "symbol", "tr", "denotes", "the", "trace", "over", "the", "flavor", "indices", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the symbol tr", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "denotes", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "tr", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "denotes", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}], "id": 4455}, {"sent": "karpathy et al presented a multimodal recurrent neural network architecture to generate concise descriptions of image regions .", "tokens": ["karpathy", "et", "al", "presented", "a", "multimodal", "recurrent", "neural", "network", "architecture", "to", "generate", "concise", "descriptions", "of", "image", "regions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "karpathy et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "presented", "start": 15, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "karpathy", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "presented", "start": 15, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "karpathy", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "generate", "start": 79, "end": 87, "i_start": 11, "i_end": 11}}], "id": 4456}, {"sent": "in fact , the iterative algorithm in can significantly improve the secrecy rate by directly optimizing the precoder matrix .", "tokens": ["in", "fact", ",", "the", "iterative", "algorithm", "in", "can", "significantly", "improve", "the", "secrecy", "rate", "by", "directly", "optimizing", "the", "precoder", "matrix", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the iterative algorithm in", "start": 10, "end": 36, "i_start": 3, "i_end": 6}, "verb": {"text": "improve", "start": 55, "end": 62, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the iterative algorithm in", "start": 10, "end": 36, "i_start": 3, "i_end": 6}, "verb": {"text": "can", "start": 37, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "algorithm", "start": 24, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "improve", "start": 55, "end": 62, "i_start": 9, "i_end": 9}}, {"character": {"text": "algorithm", "start": 24, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "optimizing", "start": 92, "end": 102, "i_start": 15, "i_end": 15}}], "id": 4457}, {"sent": "this discrepancy is a sign that another phenomenon , not included in the theoretical description happens .", "tokens": ["this", "discrepancy", "is", "a", "sign", "that", "another", "phenomenon", ",", "not", "included", "in", "the", "theoretical", "description", "happens", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this discrepancy", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "discrepancy", "start": 5, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "sign", "start": 22, "end": 26, "i_start": 4, "i_end": 4}}], "id": 4458}, {"sent": "in recent years , the deep convolutional neural networks have made great breakthroughs in computer vision .", "tokens": ["in", "recent", "years", ",", "the", "deep", "convolutional", "neural", "networks", "have", "made", "great", "breakthroughs", "in", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the deep convolutional neural networks", "start": 18, "end": 56, "i_start": 4, "i_end": 8}, "verb": {"text": "have made", "start": 57, "end": 66, "i_start": 9, "i_end": 10}}, {"character": {"text": "networks", "start": 48, "end": 56, "i_start": 8, "i_end": 8}, "action": {"text": "breakthroughs", "start": 73, "end": 86, "i_start": 12, "i_end": 12}}], "id": 4459}, {"sent": "the global sensitivity-based method is an efficient and widely used method to achieve differential privacy .", "tokens": ["the", "global", "sensitivity", "-", "based", "method", "is", "an", "efficient", "and", "widely", "used", "method", "to", "achieve", "differential", "privacy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the global sensitivity-based method", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 36, "end": 38, "i_start": 6, "i_end": 6}}], "id": 4460}, {"sent": "fast gradient sign method goodfellow et al propose the fast gradient sign method for generating adversarial examples .", "tokens": ["fast", "gradient", "sign", "method", "goodfellow", "et", "al", "propose", "the", "fast", "gradient", "sign", "method", "for", "generating", "adversarial", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "fast gradient sign method goodfellow et al", "start": 0, "end": 42, "i_start": 0, "i_end": 6}, "verb": {"text": "propose", "start": 43, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "goodfellow", "start": 26, "end": 36, "i_start": 4, "i_end": 4}, "action": {"text": "propose", "start": 43, "end": 50, "i_start": 7, "i_end": 7}}], "id": 4461}, {"sent": "the quiver consists of an interconnected stack of n copies of the e6 quiver .", "tokens": ["the", "quiver", "consists", "of", "an", "interconnected", "stack", "of", "n", "copies", "of", "the", "e6", "quiver", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quiver", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}], "id": 4462}, {"sent": "convolutional neural networks have successfully tackled classic computer vision problems such as image classification , where the input image has a grid-like structure .", "tokens": ["convolutional", "neural", "networks", "have", "successfully", "tackled", "classic", "computer", "vision", "problems", "such", "as", "image", "classification", ",", "where", "the", "input", "image", "has", "a", "grid", "-", "like", "structure", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "tackled", "start": 48, "end": 55, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "tackled", "start": 48, "end": 55, "i_start": 5, "i_end": 5}}], "id": 4463}, {"sent": "iac scripts are susceptible to human errors , bad coding practices , and can experience frequent churn , making scripts susceptible to defects .", "tokens": ["iac", "scripts", "are", "susceptible", "to", "human", "errors", ",", "bad", "coding", "practices", ",", "and", "can", "experience", "frequent", "churn", ",", "making", "scripts", "susceptible", "to", "defects", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "iac scripts", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 12, "end": 15, "i_start": 2, "i_end": 2}}, {"subject": {"text": "iac scripts", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "experience", "start": 77, "end": 87, "i_start": 14, "i_end": 14}}], "id": 4464}, {"sent": "recently , deep convolutional neural networks have led to substantial improvements for numerous computer vision tasks like object detection , often achieving human-level performance .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "led", "to", "substantial", "improvements", "for", "numerous", "computer", "vision", "tasks", "like", "object", "detection", ",", "often", "achieving", "human", "-", "level", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have led", "start": 46, "end": 54, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "led", "start": 51, "end": 54, "i_start": 7, "i_end": 7}}, {"character": {"text": "improvements", "start": 70, "end": 82, "i_start": 10, "i_end": 10}, "action": {"text": "achieving", "start": 148, "end": 157, "i_start": 21, "i_end": 21}}], "id": 4465}, {"sent": "the quadratic term is antisymmetric in gauge fields .", "tokens": ["the", "quadratic", "term", "is", "antisymmetric", "in", "gauge", "fields", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quadratic term", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 4466}, {"sent": "ohtsuka , supersymmetric gauge theories on noncommutative superspace , phys .", "tokens": ["ohtsuka", ",", "supersymmetric", "gauge", "theories", "on", "noncommutative", "superspace", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4467}, {"sent": "classical correlation functions are given by moments of the joint distribution of successive measurements and are therefore directly observable .", "tokens": ["classical", "correlation", "functions", "are", "given", "by", "moments", "of", "the", "joint", "distribution", "of", "successive", "measurements", "and", "are", "therefore", "directly", "observable", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "classical correlation functions", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are given", "start": 32, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "moments", "start": 45, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "given", "start": 36, "end": 41, "i_start": 4, "i_end": 4}}], "id": 4468}, {"sent": "ijb-a is a face verif ication and identif ication dataset , containing images captured from unconstrained environments with wide variation in pose and imaging conditions .", "tokens": ["ijb", "-", "a", "is", "a", "face", "verif", "ication", "and", "identif", "ication", "dataset", ",", "containing", "images", "captured", "from", "unconstrained", "environments", "with", "wide", "variation", "in", "pose", "and", "imaging", "conditions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "ijb-a", "start": 0, "end": 5, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 3, "i_end": 3}}, {"character": {"text": "dataset", "start": 50, "end": 57, "i_start": 11, "i_end": 11}, "action": {"text": "containing", "start": 60, "end": 70, "i_start": 13, "i_end": 13}}], "id": 4469}, {"sent": "we give an informal introduction to the most basic techniques used to evaluate moments on the critical line of the riemann zeta-function and to find asymptotics for sums of arithmetic functions .", "tokens": ["we", "give", "an", "informal", "introduction", "to", "the", "most", "basic", "techniques", "used", "to", "evaluate", "moments", "on", "the", "critical", "line", "of", "the", "riemann", "zeta", "-", "function", "and", "to", "find", "asymptotics", "for", "sums", "of", "arithmetic", "functions", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "give", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "introduction", "start": 20, "end": 32, "i_start": 4, "i_end": 4}}], "id": 4470}, {"sent": "avalanche analysis of positive lfp peaks in the awake cat .", "tokens": ["avalanche", "analysis", "of", "positive", "lfp", "peaks", "in", "the", "awake", "cat", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "cat", "start": 54, "end": 57, "i_start": 9, "i_end": 9}, "action": {"text": "awake", "start": 48, "end": 53, "i_start": 8, "i_end": 8}}], "id": 4471}, {"sent": "large neural networks with millions of parameters achieve strong performance on image classification , machine translation , language modeling , and speech recognition .", "tokens": ["large", "neural", "networks", "with", "millions", "of", "parameters", "achieve", "strong", "performance", "on", "image", "classification", ",", "machine", "translation", ",", "language", "modeling", ",", "and", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "large neural networks with millions of parameters", "start": 0, "end": 49, "i_start": 0, "i_end": 6}, "verb": {"text": "achieve", "start": 50, "end": 57, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 13, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 50, "end": 57, "i_start": 7, "i_end": 7}}], "id": 4472}, {"sent": "the second order symmetry operators for the laplacian on r n were determined by boyer , kalnins , and miller .", "tokens": ["the", "second", "order", "symmetry", "operators", "for", "the", "laplacian", "on", "r", "n", "were", "determined", "by", "boyer", ",", "kalnins", ",", "and", "miller", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "the second order symmetry operators for the laplacian on r n", "start": 0, "end": 60, "i_start": 0, "i_end": 10}, "verb": {"text": "were determined", "start": 61, "end": 76, "i_start": 11, "i_end": 12}}, {"character": {"text": "boyer", "start": 80, "end": 85, "i_start": 14, "i_end": 14}, "action": {"text": "determined", "start": 66, "end": 76, "i_start": 12, "i_end": 12}}, {"character": {"text": "kalnins", "start": 88, "end": 95, "i_start": 16, "i_end": 16}, "action": {"text": "determined", "start": 66, "end": 76, "i_start": 12, "i_end": 12}}, {"character": {"text": "miller", "start": 102, "end": 108, "i_start": 19, "i_end": 19}, "action": {"text": "determined", "start": 66, "end": 76, "i_start": 12, "i_end": 12}}], "id": 4473}, {"sent": "recently deep neural networks have attained impressive performance in many fields such as image classification .", "tokens": ["recently", "deep", "neural", "networks", "have", "attained", "impressive", "performance", "in", "many", "fields", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 9, "end": 29, "i_start": 1, "i_end": 3}, "verb": {"text": "have attained", "start": 30, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "attained", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 55, "end": 66, "i_start": 7, "i_end": 7}}, {"character": {"text": "performance", "start": 55, "end": 66, "i_start": 7, "i_end": 7}, "action": {"text": "impressive", "start": 44, "end": 54, "i_start": 6, "i_end": 6}}], "id": 4474}, {"sent": "finfet is one of the proposed candidates which shows excellent subthreshold slope and hence scalability due to its nonplanar multi-gate structure .", "tokens": ["finfet", "is", "one", "of", "the", "proposed", "candidates", "which", "shows", "excellent", "subthreshold", "slope", "and", "hence", "scalability", "due", "to", "its", "nonplanar", "multi", "-", "gate", "structure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "finfet", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 7, "end": 9, "i_start": 1, "i_end": 1}}], "id": 4475}, {"sent": "deep convolutional neural networks have proved to solve a growing number of problems .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "proved", "to", "solve", "a", "growing", "number", "of", "problems", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have proved", "start": 35, "end": 46, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "solve", "start": 50, "end": 55, "i_start": 7, "i_end": 7}}], "id": 4476}, {"sent": "this coupling of spacetime curvature to fields has been well studied on the microscopic level in the context of particle creation .", "tokens": ["this", "coupling", "of", "spacetime", "curvature", "to", "fields", "has", "been", "well", "studied", "on", "the", "microscopic", "level", "in", "the", "context", "of", "particle", "creation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this coupling of spacetime curvature to fields", "start": 0, "end": 46, "i_start": 0, "i_end": 6}, "verb": {"text": "studied", "start": 61, "end": 68, "i_start": 10, "i_end": 10}}, {"subject": {"text": "this coupling of spacetime curvature to fields", "start": 0, "end": 46, "i_start": 0, "i_end": 6}, "verb": {"text": "has been", "start": 47, "end": 55, "i_start": 7, "i_end": 8}}], "id": 4477}, {"sent": "isola et al introduced generative adversarial networks and l 1 loss to address the issue of paired image translation .", "tokens": ["isola", "et", "al", "introduced", "generative", "adversarial", "networks", "and", "l", "1", "loss", "to", "address", "the", "issue", "of", "paired", "image", "translation", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 6, "end": 11, "i_start": 1, "i_end": 2}, "verb": {"text": "introduced", "start": 12, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "isola", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 12, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "isola", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "address", "start": 71, "end": 78, "i_start": 12, "i_end": 12}}, {"character": {"text": "translation", "start": 105, "end": 116, "i_start": 18, "i_end": 18}, "action": {"text": "issue", "start": 83, "end": 88, "i_start": 14, "i_end": 14}}], "id": 4478}, {"sent": "the generalized gradient approximation parameterized by perdew-burke-ernzerhof is utilized to describe exchange-correlation functional .", "tokens": ["the", "generalized", "gradient", "approximation", "parameterized", "by", "perdew", "-", "burke", "-", "ernzerhof", "is", "utilized", "to", "describe", "exchange", "-", "correlation", "functional", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation parameterized by perdew-burke-ernzerhof", "start": 0, "end": 78, "i_start": 0, "i_end": 10}, "verb": {"text": "is utilized", "start": 79, "end": 90, "i_start": 11, "i_end": 12}}, {"character": {"text": "perdew", "start": 56, "end": 62, "i_start": 6, "i_end": 6}, "action": {"text": "parameterized", "start": 39, "end": 52, "i_start": 4, "i_end": 4}}, {"character": {"text": "approximation", "start": 25, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "describe", "start": 94, "end": 102, "i_start": 14, "i_end": 14}}, {"character": {"text": "exchange", "start": 103, "end": 111, "i_start": 15, "i_end": 15}, "action": {"text": "functional", "start": 124, "end": 134, "i_start": 18, "i_end": 18}}], "id": 4479}, {"sent": "moreover , loading of rydberg atoms into an optical lattice and the observation of emerging ordered structures have been achieved experimentally , although so far only in the frozen-limit of a deep lattice potential .", "tokens": ["moreover", ",", "loading", "of", "rydberg", "atoms", "into", "an", "optical", "lattice", "and", "the", "observation", "of", "emerging", "ordered", "structures", "have", "been", "achieved", "experimentally", ",", "although", "so", "far", "only", "in", "the", "frozen", "-", "limit", "of", "a", "deep", "lattice", "potential", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "loading of rydberg", "start": 11, "end": 29, "i_start": 2, "i_end": 4}, "verb": {"text": "atoms", "start": 30, "end": 35, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the observation of emerging ordered structures", "start": 64, "end": 110, "i_start": 11, "i_end": 16}, "verb": {"text": "achieved", "start": 121, "end": 129, "i_start": 19, "i_end": 19}}, {"character": {"text": "structures", "start": 100, "end": 110, "i_start": 16, "i_end": 16}, "action": {"text": "emerging", "start": 83, "end": 91, "i_start": 14, "i_end": 14}}], "id": 4480}, {"sent": "the following result appears in , but we include the proof for completeness .", "tokens": ["the", "following", "result", "appears", "in", ",", "but", "we", "include", "the", "proof", "for", "completeness", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the following result", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "appears", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 38, "end": 40, "i_start": 7, "i_end": 7}, "verb": {"text": "include", "start": 41, "end": 48, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 38, "end": 40, "i_start": 7, "i_end": 7}, "action": {"text": "include", "start": 41, "end": 48, "i_start": 8, "i_end": 8}}], "id": 4481}, {"sent": "in addition , we believe that our model change detection formulation can be applied in transfer learning .", "tokens": ["in", "addition", ",", "we", "believe", "that", "our", "model", "change", "detection", "formulation", "can", "be", "applied", "in", "transfer", "learning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "believe", "start": 17, "end": 24, "i_start": 4, "i_end": 4}}, {"subject": {"text": "our model change detection formulation", "start": 30, "end": 68, "i_start": 6, "i_end": 10}, "verb": {"text": "applied", "start": 76, "end": 83, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "believe", "start": 17, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "formulation", "start": 57, "end": 68, "i_start": 10, "i_end": 10}}], "id": 4482}, {"sent": "for superconductors , this is a mixed state with the normal phase residing at the point where the vortex vanishes .", "tokens": ["for", "superconductors", ",", "this", "is", "a", "mixed", "state", "with", "the", "normal", "phase", "residing", "at", "the", "point", "where", "the", "vortex", "vanishes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 22, "end": 26, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "phase", "start": 60, "end": 65, "i_start": 11, "i_end": 11}, "action": {"text": "residing", "start": 66, "end": 74, "i_start": 12, "i_end": 12}}], "id": 4483}, {"sent": "cosmic strings are one dimensional topological defects which may have been left behind by phase transitions in the early universe .", "tokens": ["cosmic", "strings", "are", "one", "dimensional", "topological", "defects", "which", "may", "have", "been", "left", "behind", "by", "phase", "transitions", "in", "the", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "transitions", "start": 96, "end": 107, "i_start": 15, "i_end": 15}, "action": {"text": "left", "start": 75, "end": 79, "i_start": 11, "i_end": 11}}], "id": 4484}, {"sent": "therefore , we also evaluate the transfer learning ability of our models to the object detection task in the pascal voc 2007 dataset .", "tokens": ["therefore", ",", "we", "also", "evaluate", "the", "transfer", "learning", "ability", "of", "our", "models", "to", "the", "object", "detection", "task", "in", "the", "pascal", "voc", "2007", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "evaluate", "start": 20, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "evaluate", "start": 20, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "models", "start": 66, "end": 72, "i_start": 11, "i_end": 11}}], "id": 4485}, {"sent": "the agreement with the avail able data is quite good .", "tokens": ["the", "agreement", "with", "the", "avail", "able", "data", "is", "quite", "good", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the agreement with the avail able data", "start": 0, "end": 38, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 7, "i_end": 7}}], "id": 4486}, {"sent": "among others , the two-dimensional case arises in pat with so called integrating line detectors .", "tokens": ["among", "others", ",", "the", "two", "-", "dimensional", "case", "arises", "in", "pat", "with", "so", "called", "integrating", "line", "detectors", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the two-dimensional case", "start": 15, "end": 39, "i_start": 3, "i_end": 7}, "verb": {"text": "arises", "start": 40, "end": 46, "i_start": 8, "i_end": 8}}, {"character": {"text": "integrating", "start": 69, "end": 80, "i_start": 14, "i_end": 14}, "action": {"text": "arises", "start": 40, "end": 46, "i_start": 8, "i_end": 8}}], "id": 4487}, {"sent": "the cms detector , definitions of angular and spatial coordinates , and its performance can be found in ref .", "tokens": ["the", "cms", "detector", ",", "definitions", "of", "angular", "and", "spatial", "coordinates", ",", "and", "its", "performance", "can", "be", "found", "in", "ref", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the cms detector , definitions of angular and spatial coordinates , and its performance", "start": 0, "end": 87, "i_start": 0, "i_end": 13}, "verb": {"text": "can be found", "start": 88, "end": 100, "i_start": 14, "i_end": 16}}], "id": 4488}, {"sent": "but the orbit through is a torus-knot which is not taut .", "tokens": ["but", "the", "orbit", "through", "is", "a", "torus", "-", "knot", "which", "is", "not", "taut", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the orbit through", "start": 4, "end": 21, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}], "id": 4489}, {"sent": "the grayscale is the same as that in the previous figures .", "tokens": ["the", "grayscale", "is", "the", "same", "as", "that", "in", "the", "previous", "figures", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the grayscale", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 4490}, {"sent": "recent developments showed that neural networks can be applied successfully in many technical applications like computer vision .", "tokens": ["recent", "developments", "showed", "that", "neural", "networks", "can", "be", "applied", "successfully", "in", "many", "technical", "applications", "like", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent developments", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "showed", "start": 20, "end": 26, "i_start": 2, "i_end": 2}}, {"subject": {"text": "neural networks", "start": 32, "end": 47, "i_start": 4, "i_end": 5}, "verb": {"text": "applied", "start": 55, "end": 62, "i_start": 8, "i_end": 8}}, {"character": {"text": "developments", "start": 7, "end": 19, "i_start": 1, "i_end": 1}, "action": {"text": "showed", "start": 20, "end": 26, "i_start": 2, "i_end": 2}}], "id": 4491}, {"sent": "for the large-scale experiments we trained a resnet-50 , network on the imagenet .", "tokens": ["for", "the", "large", "-", "scale", "experiments", "we", "trained", "a", "resnet-50", ",", "network", "on", "the", "imagenet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 32, "end": 34, "i_start": 6, "i_end": 6}, "action": {"text": "trained", "start": 35, "end": 42, "i_start": 7, "i_end": 7}}], "id": 4492}, {"sent": "inverse force and motion control of constrained elastic robots .", "tokens": ["inverse", "force", "and", "motion", "control", "of", "constrained", "elastic", "robots", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "robots", "start": 56, "end": 62, "i_start": 8, "i_end": 8}, "action": {"text": "control", "start": 25, "end": 32, "i_start": 4, "i_end": 4}}], "id": 4493}, {"sent": "consequently , stochastic gradient descent has been a typical alternative .", "tokens": ["consequently", ",", "stochastic", "gradient", "descent", "has", "been", "a", "typical", "alternative", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "stochastic gradient descent", "start": 15, "end": 42, "i_start": 2, "i_end": 4}, "verb": {"text": "has been", "start": 43, "end": 51, "i_start": 5, "i_end": 6}}], "id": 4494}, {"sent": "recently , deep convolutional neural networks have led to substantial improvements for numerous computer vision tasks like object detection , often achieving human-level performance .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "led", "to", "substantial", "improvements", "for", "numerous", "computer", "vision", "tasks", "like", "object", "detection", ",", "often", "achieving", "human", "-", "level", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have led", "start": 46, "end": 54, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "led", "start": 51, "end": 54, "i_start": 7, "i_end": 7}}, {"character": {"text": "improvements", "start": 70, "end": 82, "i_start": 10, "i_end": 10}, "action": {"text": "achieving", "start": 148, "end": 157, "i_start": 21, "i_end": 21}}], "id": 4495}, {"sent": "the proof follows from standard level set techniques .", "tokens": ["the", "proof", "follows", "from", "standard", "level", "set", "techniques", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the proof", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "follows", "start": 10, "end": 17, "i_start": 2, "i_end": 2}}], "id": 4496}, {"sent": "luong et al use recursive neural networks and neural language models to better represent rare words via morphemes .", "tokens": ["luong", "et", "al", "use", "recursive", "neural", "networks", "and", "neural", "language", "models", "to", "better", "represent", "rare", "words", "via", "morphemes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "luong", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 12, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "luong", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "represent", "start": 79, "end": 88, "i_start": 13, "i_end": 13}}], "id": 4497}, {"sent": "therefore , there always exist g-invariant infinitesimal causal structures on g .", "tokens": ["therefore", ",", "there", "always", "exist", "g", "-", "invariant", "infinitesimal", "causal", "structures", "on", "g", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 12, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "exist", "start": 25, "end": 30, "i_start": 4, "i_end": 4}}], "id": 4498}, {"sent": "the works of gave algorithms to solve various approximate numerical linear algebra problems given small memory and a only one or few passes over the matrix .", "tokens": ["the", "works", "of", "gave", "algorithms", "to", "solve", "various", "approximate", "numerical", "linear", "algebra", "problems", "given", "small", "memory", "and", "a", "only", "one", "or", "few", "passes", "over", "the", "matrix", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the works of", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "gave", "start": 13, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithms", "start": 18, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "solve", "start": 32, "end": 37, "i_start": 6, "i_end": 6}}], "id": 4499}, {"sent": "to improve convergence speed during training , we add batch normalization after every convolution .", "tokens": ["to", "improve", "convergence", "speed", "during", "training", ",", "we", "add", "batch", "normalization", "after", "every", "convolution", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 47, "end": 49, "i_start": 7, "i_end": 7}, "verb": {"text": "add", "start": 50, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 47, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "add", "start": 50, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 47, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "improve", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 4500}, {"sent": "cloaking , using transformation optics , was introduced by pendry , schurig , and smith in the geometric optics setting .", "tokens": ["cloaking", ",", "using", "transformation", "optics", ",", "was", "introduced", "by", "pendry", ",", "schurig", ",", "and", "smith", "in", "the", "geometric", "optics", "setting", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cloaking", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "was introduced", "start": 41, "end": 55, "i_start": 6, "i_end": 7}}, {"character": {"text": "pendry", "start": 59, "end": 65, "i_start": 9, "i_end": 9}, "action": {"text": "introduced", "start": 45, "end": 55, "i_start": 7, "i_end": 7}}, {"character": {"text": "schurig", "start": 68, "end": 75, "i_start": 11, "i_end": 11}, "action": {"text": "introduced", "start": 45, "end": 55, "i_start": 7, "i_end": 7}}, {"character": {"text": "smith", "start": 82, "end": 87, "i_start": 14, "i_end": 14}, "action": {"text": "introduced", "start": 45, "end": 55, "i_start": 7, "i_end": 7}}], "id": 4501}, {"sent": "the tilde again denotes the splitting function without the plus-prescription .", "tokens": ["the", "tilde", "again", "denotes", "the", "splitting", "function", "without", "the", "plus", "-", "prescription", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the tilde", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "denotes", "start": 16, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "tilde", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "denotes", "start": 16, "end": 23, "i_start": 3, "i_end": 3}}], "id": 4502}, {"sent": "similar to , by 1 n i -dehn surgery on these curves , s can be isotoped across curves inb without affecting the isotopy class of s in n .", "tokens": ["similar", "to", ",", "by", "1", "n", "i", "-dehn", "surgery", "on", "these", "curves", ",", "s", "can", "be", "isotoped", "across", "curves", "inb", "without", "affecting", "the", "isotopy", "class", "of", "s", "in", "n", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "s", "start": 54, "end": 55, "i_start": 13, "i_end": 13}, "verb": {"text": "can be isotoped", "start": 56, "end": 71, "i_start": 14, "i_end": 16}}, {"character": {"text": "isotoped", "start": 63, "end": 71, "i_start": 16, "i_end": 16}, "action": {"text": "affecting", "start": 98, "end": 107, "i_start": 21, "i_end": 21}}], "id": 4503}, {"sent": "the correlation output is called the complex visibility .", "tokens": ["the", "correlation", "output", "is", "called", "the", "complex", "visibility", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the correlation output", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 23, "end": 32, "i_start": 3, "i_end": 4}}], "id": 4504}, {"sent": "along this direction , convolutional neural networks have been very successful in various computer vision and natural language processing tasks in recent years .", "tokens": ["along", "this", "direction", ",", "convolutional", "neural", "networks", "have", "been", "very", "successful", "in", "various", "computer", "vision", "and", "natural", "language", "processing", "tasks", "in", "recent", "years", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 23, "end": 52, "i_start": 4, "i_end": 6}, "verb": {"text": "have been", "start": 53, "end": 62, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "successful", "start": 68, "end": 78, "i_start": 10, "i_end": 10}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "processing", "start": 127, "end": 137, "i_start": 18, "i_end": 18}}], "id": 4505}, {"sent": "micro-algae growth in a photobioreactor is often modeled through one of two models , the monod model .", "tokens": ["micro", "-", "algae", "growth", "in", "a", "photobioreactor", "is", "often", "modeled", "through", "one", "of", "two", "models", ",", "the", "monod", "model", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "micro-algae growth in a photobioreactor is often modeled through one of two models , the monod model", "start": 0, "end": 100, "i_start": 0, "i_end": 18}, "verb": {"text": "modeled", "start": 49, "end": 56, "i_start": 9, "i_end": 9}}, {"subject": {"text": "micro-algae growth in a photobioreactor is often modeled through one of two models , the monod model", "start": 0, "end": 100, "i_start": 0, "i_end": 18}, "verb": {"text": "is", "start": 40, "end": 42, "i_start": 7, "i_end": 7}}], "id": 4506}, {"sent": "many materials exhibiting both nontrivial band topology and superconductivity have been experimentally discovered and synthesized .", "tokens": ["many", "materials", "exhibiting", "both", "nontrivial", "band", "topology", "and", "superconductivity", "have", "been", "experimentally", "discovered", "and", "synthesized", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "many materials exhibiting both nontrivial band topology and superconductivity", "start": 0, "end": 77, "i_start": 0, "i_end": 8}, "verb": {"text": "discovered", "start": 103, "end": 113, "i_start": 12, "i_end": 12}}, {"subject": {"text": "many materials exhibiting both nontrivial band topology and superconductivity", "start": 0, "end": 77, "i_start": 0, "i_end": 8}, "verb": {"text": "have been", "start": 78, "end": 87, "i_start": 9, "i_end": 10}}, {"subject": {"text": "many materials exhibiting both nontrivial band topology and superconductivity", "start": 0, "end": 77, "i_start": 0, "i_end": 8}, "verb": {"text": "synthesized", "start": 118, "end": 129, "i_start": 14, "i_end": 14}}, {"character": {"text": "materials", "start": 5, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "exhibiting", "start": 15, "end": 25, "i_start": 2, "i_end": 2}}], "id": 4507}, {"sent": "printout the most suitable printer is a laser or an inkjet printer .", "tokens": ["printout", "the", "most", "suitable", "printer", "is", "a", "laser", "or", "an", "inkjet", "printer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "printout the most suitable printer", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 5, "i_end": 5}}], "id": 4508}, {"sent": "for more information on the blow-up criteria of compressible navier-stokes equations , we refer to and references therein .", "tokens": ["for", "more", "information", "on", "the", "blow", "-", "up", "criteria", "of", "compressible", "navier", "-", "stokes", "equations", ",", "we", "refer", "to", "and", "references", "therein", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 87, "end": 89, "i_start": 16, "i_end": 16}, "verb": {"text": "refer", "start": 90, "end": 95, "i_start": 17, "i_end": 17}}, {"subject": {"text": "we", "start": 87, "end": 89, "i_start": 16, "i_end": 16}, "verb": {"text": "references", "start": 103, "end": 113, "i_start": 20, "i_end": 20}}, {"character": {"text": "we", "start": 87, "end": 89, "i_start": 16, "i_end": 16}, "action": {"text": "refer", "start": 90, "end": 95, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 87, "end": 89, "i_start": 16, "i_end": 16}, "action": {"text": "references", "start": 103, "end": 113, "i_start": 20, "i_end": 20}}], "id": 4509}, {"sent": "here intx is the complement of the union of toric divisors .", "tokens": ["here", "intx", "is", "the", "complement", "of", "the", "union", "of", "toric", "divisors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "here intx", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}], "id": 4510}, {"sent": "recently , goodfellow et al introduced the generative adversarial networks framework .", "tokens": ["recently", ",", "goodfellow", "et", "al", "introduced", "the", "generative", "adversarial", "networks", "framework", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 11, "end": 27, "i_start": 2, "i_end": 4}, "verb": {"text": "introduced", "start": 28, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "goodfellow", "start": 11, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 28, "end": 38, "i_start": 5, "i_end": 5}}], "id": 4511}, {"sent": "we establish lower bounds on the benefit of network coding , defined as the maximum of the ratio of the minimum energy required by routing and network coding solutions , where the maximum is over all configurations .", "tokens": ["we", "establish", "lower", "bounds", "on", "the", "benefit", "of", "network", "coding", ",", "defined", "as", "the", "maximum", "of", "the", "ratio", "of", "the", "minimum", "energy", "required", "by", "routing", "and", "network", "coding", "solutions", ",", "where", "the", "maximum", "is", "over", "all", "configurations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "establish", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "establish", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "coding", "start": 151, "end": 157, "i_start": 27, "i_end": 27}, "action": {"text": "benefit", "start": 33, "end": 40, "i_start": 6, "i_end": 6}}], "id": 4512}, {"sent": "our method allows for straightforward inference using expectation-maximisation , which is implemented in 50 lines of code .", "tokens": ["our", "method", "allows", "for", "straightforward", "inference", "using", "expectation", "-", "maximisation", ",", "which", "is", "implemented", "in", "50", "lines", "of", "code", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our method", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "allows", "start": 11, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "method", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "allows", "start": 11, "end": 17, "i_start": 2, "i_end": 2}}], "id": 4513}, {"sent": "here , we calculate the baryon binding energy in sakai-sugimoto model .", "tokens": ["here", ",", "we", "calculate", "the", "baryon", "binding", "energy", "in", "sakai", "-", "sugimoto", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "calculate", "start": 10, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "calculate", "start": 10, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "energy", "start": 39, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "binding", "start": 31, "end": 38, "i_start": 6, "i_end": 6}}], "id": 4514}, {"sent": "the first shell consists of 142 new metabolites and the second shell of 171 new metabolites .", "tokens": ["the", "first", "shell", "consists", "of", "142", "new", "metabolites", "and", "the", "second", "shell", "of", "171", "new", "metabolites", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the first shell", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}], "id": 4515}, {"sent": "deep neural networks have been shown useful for many computer vision tasks , but they are still limited by requiring large-scale well-annotated datasets for network training .", "tokens": ["deep", "neural", "networks", "have", "been", "shown", "useful", "for", "many", "computer", "vision", "tasks", ",", "but", "they", "are", "still", "limited", "by", "requiring", "large", "-", "scale", "well", "-", "annotated", "datasets", "for", "network", "training", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been shown", "start": 21, "end": 36, "i_start": 3, "i_end": 5}}, {"subject": {"text": "they", "start": 81, "end": 85, "i_start": 14, "i_end": 14}, "verb": {"text": "limited", "start": 96, "end": 103, "i_start": 17, "i_end": 17}}], "id": 4516}, {"sent": "there has been a huge amount of research on graph partitioning and we refer the reader to the surveys given in for most of the material .", "tokens": ["there", "has", "been", "a", "huge", "amount", "of", "research", "on", "graph", "partitioning", "and", "we", "refer", "the", "reader", "to", "the", "surveys", "given", "in", "for", "most", "of", "the", "material", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "has been", "start": 6, "end": 14, "i_start": 1, "i_end": 2}}, {"subject": {"text": "we", "start": 67, "end": 69, "i_start": 12, "i_end": 12}, "verb": {"text": "refer", "start": 70, "end": 75, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 67, "end": 69, "i_start": 12, "i_end": 12}, "action": {"text": "refer", "start": 70, "end": 75, "i_start": 13, "i_end": 13}}], "id": 4517}, {"sent": "we also estimated the energy release rates based on the magnetic reconnection model at each radiation source .", "tokens": ["we", "also", "estimated", "the", "energy", "release", "rates", "based", "on", "the", "magnetic", "reconnection", "model", "at", "each", "radiation", "source", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "estimated", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "estimated", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "source", "start": 102, "end": 108, "i_start": 16, "i_end": 16}, "action": {"text": "radiation", "start": 92, "end": 101, "i_start": 15, "i_end": 15}}], "id": 4518}, {"sent": "precisely , the markov blanket of a target variable t is defined as the minimal set of variables , conditioned on which all other variables are independent of the target .", "tokens": ["precisely", ",", "the", "markov", "blanket", "of", "a", "target", "variable", "t", "is", "defined", "as", "the", "minimal", "set", "of", "variables", ",", "conditioned", "on", "which", "all", "other", "variables", "are", "independent", "of", "the", "target", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the markov blanket of a target variable t", "start": 12, "end": 53, "i_start": 2, "i_end": 9}, "verb": {"text": "is defined", "start": 54, "end": 64, "i_start": 10, "i_end": 11}}], "id": 4519}, {"sent": "the lightest neutralino is the lightest eigenvalue of this , and may be the lsp .", "tokens": ["the", "lightest", "neutralino", "is", "the", "lightest", "eigenvalue", "of", "this", ",", "and", "may", "be", "the", "lsp", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lightest neutralino", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}], "id": 4520}, {"sent": "these applications range from statistics on the optimal trajectories in the context of traveling salesman problem on a random set of cities , to partial self-avoiding deterministic walks .", "tokens": ["these", "applications", "range", "from", "statistics", "on", "the", "optimal", "trajectories", "in", "the", "context", "of", "traveling", "salesman", "problem", "on", "a", "random", "set", "of", "cities", ",", "to", "partial", "self", "-", "avoiding", "deterministic", "walks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these applications", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "range", "start": 19, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "walks", "start": 181, "end": 186, "i_start": 29, "i_end": 29}, "action": {"text": "avoiding", "start": 158, "end": 166, "i_start": 27, "i_end": 27}}], "id": 4521}, {"sent": "the fact that this wrapping rule works for the non-standard solitons as well can not be explained by the presence of the standard kk monopole alone .", "tokens": ["the", "fact", "that", "this", "wrapping", "rule", "works", "for", "the", "non", "-", "standard", "solitons", "as", "well", "can", "not", "be", "explained", "by", "the", "presence", "of", "the", "standard", "kk", "monopole", "alone", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "presence", "start": 105, "end": 113, "i_start": 21, "i_end": 21}, "action": {"text": "explained", "start": 88, "end": 97, "i_start": 18, "i_end": 18}}], "id": 4522}, {"sent": "deep convolutional neural networks have recently become increasingly important for computer vision applications .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "recently", "become", "increasingly", "important", "for", "computer", "vision", "applications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "become", "start": 49, "end": 55, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}], "id": 4523}, {"sent": "therefore , we will understand the equivalence between the commutative field theory and the supermatrix model including non-planar diagrams .", "tokens": ["therefore", ",", "we", "will", "understand", "the", "equivalence", "between", "the", "commutative", "field", "theory", "and", "the", "supermatrix", "model", "including", "non", "-", "planar", "diagrams", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "will understand", "start": 15, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "we", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "understand", "start": 20, "end": 30, "i_start": 4, "i_end": 4}}], "id": 4524}, {"sent": "the discriminator utilizes the vgg network with ten convolutional layers .", "tokens": ["the", "discriminator", "utilizes", "the", "vgg", "network", "with", "ten", "convolutional", "layers", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the discriminator", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "utilizes", "start": 18, "end": 26, "i_start": 2, "i_end": 2}}], "id": 4525}, {"sent": "nichols algebras play an essential role in the classification of pointed hopf algebras by the method of andruskiewitsch and schneider .", "tokens": ["nichols", "algebras", "play", "an", "essential", "role", "in", "the", "classification", "of", "pointed", "hopf", "algebras", "by", "the", "method", "of", "andruskiewitsch", "and", "schneider", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "nichols algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "play", "start": 17, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "algebras", "start": 8, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "play", "start": 17, "end": 21, "i_start": 2, "i_end": 2}}], "id": 4526}, {"sent": "the motivic triangulated category dmb is continuous .", "tokens": ["the", "motivic", "triangulated", "category", "dmb", "is", "continuous", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the motivic triangulated category dmb", "start": 0, "end": 37, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 5, "i_end": 5}}], "id": 4527}, {"sent": "from an applied point of view , entanglement is a key resource in quantum technologies and quantum information processing .", "tokens": ["from", "an", "applied", "point", "of", "view", ",", "entanglement", "is", "a", "key", "resource", "in", "quantum", "technologies", "and", "quantum", "information", "processing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "entanglement", "start": 32, "end": 44, "i_start": 7, "i_end": 7}, "verb": {"text": "is", "start": 45, "end": 47, "i_start": 8, "i_end": 8}}], "id": 4528}, {"sent": "with rgb or intensity images viola and jones face detector is often exploited , eg .", "tokens": ["with", "rgb", "or", "intensity", "images", "viola", "and", "jones", "face", "detector", "is", "often", "exploited", ",", "eg", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "jones face detector", "start": 39, "end": 58, "i_start": 7, "i_end": 9}, "verb": {"text": "exploited", "start": 68, "end": 77, "i_start": 12, "i_end": 12}}, {"subject": {"text": "jones face detector", "start": 39, "end": 58, "i_start": 7, "i_end": 9}, "verb": {"text": "is", "start": 59, "end": 61, "i_start": 10, "i_end": 10}}], "id": 4529}, {"sent": "goodfellow et al proposed an easy and effective framework of generative models based on an adversarial process .", "tokens": ["goodfellow", "et", "al", "proposed", "an", "easy", "and", "effective", "framework", "of", "generative", "models", "based", "on", "an", "adversarial", "process", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "goodfellow", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "framework", "start": 48, "end": 57, "i_start": 8, "i_end": 8}, "action": {"text": "effective", "start": 38, "end": 47, "i_start": 7, "i_end": 7}}], "id": 4530}, {"sent": "asynchronous circuits are generally categorized as strongly indicating .", "tokens": ["asynchronous", "circuits", "are", "generally", "categorized", "as", "strongly", "indicating", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "asynchronous circuits", "start": 0, "end": 21, "i_start": 0, "i_end": 1}, "verb": {"text": "categorized", "start": 36, "end": 47, "i_start": 4, "i_end": 4}}, {"subject": {"text": "asynchronous circuits", "start": 0, "end": 21, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 22, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "circuits", "start": 13, "end": 21, "i_start": 1, "i_end": 1}, "action": {"text": "indicating", "start": 60, "end": 70, "i_start": 7, "i_end": 7}}], "id": 4531}, {"sent": "nonetheless , it is possible to go beyond standard pimc by employing the recently introduced permutation blocking pimc approach .", "tokens": ["nonetheless", ",", "it", "is", "possible", "to", "go", "beyond", "standard", "pimc", "by", "employing", "the", "recently", "introduced", "permutation", "blocking", "pimc", "approach", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 4532}, {"sent": "in \u03b3\u03b3 interactions both photons are resolved .", "tokens": ["in", "\u03b3\u03b3", "interactions", "both", "photons", "are", "resolved", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "both photons", "start": 19, "end": 31, "i_start": 3, "i_end": 4}, "verb": {"text": "are resolved", "start": 32, "end": 44, "i_start": 5, "i_end": 6}}], "id": 4533}, {"sent": "we point out that the invariant disk always stays in the upper half plane .", "tokens": ["we", "point", "out", "that", "the", "invariant", "disk", "always", "stays", "in", "the", "upper", "half", "plane", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "point out", "start": 3, "end": 12, "i_start": 1, "i_end": 2}}, {"subject": {"text": "the invariant disk", "start": 18, "end": 36, "i_start": 4, "i_end": 6}, "verb": {"text": "stays", "start": 44, "end": 49, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "point", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 4534}, {"sent": "this conjecture also holds for particular classes of graphs , including powers of cycles .", "tokens": ["this", "conjecture", "also", "holds", "for", "particular", "classes", "of", "graphs", ",", "including", "powers", "of", "cycles", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this conjecture", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "holds", "start": 21, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "conjecture", "start": 5, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "holds", "start": 21, "end": 26, "i_start": 3, "i_end": 3}}], "id": 4535}, {"sent": "cluster complexes are combinatorial objects that arose in the theory of cluster algebras initiated by fomin and zelevinsky .", "tokens": ["cluster", "complexes", "are", "combinatorial", "objects", "that", "arose", "in", "the", "theory", "of", "cluster", "algebras", "initiated", "by", "fomin", "and", "zelevinsky", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cluster complexes", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 18, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "fomin", "start": 102, "end": 107, "i_start": 15, "i_end": 15}, "action": {"text": "initiated", "start": 89, "end": 98, "i_start": 13, "i_end": 13}}, {"character": {"text": "zelevinsky", "start": 112, "end": 122, "i_start": 17, "i_end": 17}, "action": {"text": "initiated", "start": 89, "end": 98, "i_start": 13, "i_end": 13}}], "id": 4536}, {"sent": "the fluxes of the various parts of the line profiles are well correlated with each other and also with the continuum flux .", "tokens": ["the", "fluxes", "of", "the", "various", "parts", "of", "the", "line", "profiles", "are", "well", "correlated", "with", "each", "other", "and", "also", "with", "the", "continuum", "flux", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the fluxes of the various parts of the line profiles", "start": 0, "end": 52, "i_start": 0, "i_end": 9}, "verb": {"text": "correlated", "start": 62, "end": 72, "i_start": 12, "i_end": 12}}, {"subject": {"text": "the fluxes of the various parts of the line profiles", "start": 0, "end": 52, "i_start": 0, "i_end": 9}, "verb": {"text": "are", "start": 53, "end": 56, "i_start": 10, "i_end": 10}}], "id": 4537}, {"sent": "deep neural networks have achieved outstanding performances on many computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "achieved", "outstanding", "performances", "on", "many", "computer", "vision", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performances", "start": 47, "end": 59, "i_start": 6, "i_end": 6}}], "id": 4538}, {"sent": "deep neural networks are powerful models that achieve extraordinary performance in various speech and vision tasks , including speech recognition .", "tokens": ["deep", "neural", "networks", "are", "powerful", "models", "that", "achieve", "extraordinary", "performance", "in", "various", "speech", "and", "vision", "tasks", ",", "including", "speech", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 34, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "achieve", "start": 46, "end": 53, "i_start": 7, "i_end": 7}}, {"character": {"text": "models", "start": 34, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 68, "end": 79, "i_start": 9, "i_end": 9}}], "id": 4539}, {"sent": "fomin and zelevinsky have defined a certain subring aof f associated to the seed , known as a cluster algebra .", "tokens": ["fomin", "and", "zelevinsky", "have", "defined", "a", "certain", "subring", "aof", "f", "associated", "to", "the", "seed", ",", "known", "as", "a", "cluster", "algebra", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "fomin and zelevinsky", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have defined", "start": 21, "end": 33, "i_start": 3, "i_end": 4}}, {"character": {"text": "fomin", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "defined", "start": 26, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "zelevinsky", "start": 10, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "defined", "start": 26, "end": 33, "i_start": 4, "i_end": 4}}], "id": 4540}, {"sent": "agrawal and srikant proposed the first data perturbation technique to build a decision-tree classifier .", "tokens": ["agrawal", "and", "srikant", "proposed", "the", "first", "data", "perturbation", "technique", "to", "build", "a", "decision", "-", "tree", "classifier", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "agrawal and srikant", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 20, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "agrawal", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 20, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "srikant", "start": 12, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "proposed", "start": 20, "end": 28, "i_start": 3, "i_end": 3}}], "id": 4541}, {"sent": "we refer the papers for more details about \u03b3-convergence , mosco convergence and their applications .", "tokens": ["we", "refer", "the", "papers", "for", "more", "details", "about", "\u03b3", "-", "convergence", ",", "mosco", "convergence", "and", "their", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 4542}, {"sent": "part weight spaces of every verma module are finite dimensional .", "tokens": ["part", "weight", "spaces", "of", "every", "verma", "module", "are", "finite", "dimensional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "part weight spaces of every verma module", "start": 0, "end": 40, "i_start": 0, "i_end": 6}, "verb": {"text": "are", "start": 41, "end": 44, "i_start": 7, "i_end": 7}}], "id": 4543}, {"sent": "virtual knot theory was introduced by kauffman and it is an extension of classical diagrammatic knot theory .", "tokens": ["virtual", "knot", "theory", "was", "introduced", "by", "kauffman", "and", "it", "is", "an", "extension", "of", "classical", "diagrammatic", "knot", "theory", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "virtual knot theory", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "was introduced", "start": 20, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "kauffman", "start": 38, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "introduced", "start": 24, "end": 34, "i_start": 4, "i_end": 4}}], "id": 4544}, {"sent": "our coding scheme is based on , but we further send a common message to both relaying nodes .", "tokens": ["our", "coding", "scheme", "is", "based", "on", ",", "but", "we", "further", "send", "a", "common", "message", "to", "both", "relaying", "nodes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our coding scheme", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is based", "start": 18, "end": 26, "i_start": 3, "i_end": 4}}, {"subject": {"text": "we", "start": 36, "end": 38, "i_start": 8, "i_end": 8}, "verb": {"text": "send", "start": 47, "end": 51, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 36, "end": 38, "i_start": 8, "i_end": 8}, "action": {"text": "send", "start": 47, "end": 51, "i_start": 10, "i_end": 10}}, {"character": {"text": "nodes", "start": 86, "end": 91, "i_start": 17, "i_end": 17}, "action": {"text": "relaying", "start": 77, "end": 85, "i_start": 16, "i_end": 16}}], "id": 4545}, {"sent": "the nucleon is a satisfactory laboratory to check the relation between fragmenta tion and distribution functions , since we have data both on the quark distributions of the nucleon from deep inelastic scattering .", "tokens": ["the", "nucleon", "is", "a", "satisfactory", "laboratory", "to", "check", "the", "relation", "between", "fragmenta", "tion", "and", "distribution", "functions", ",", "since", "we", "have", "data", "both", "on", "the", "quark", "distributions", "of", "the", "nucleon", "from", "deep", "inelastic", "scattering", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the nucleon", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "laboratory", "start": 30, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "satisfactory", "start": 17, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 121, "end": 123, "i_start": 18, "i_end": 18}, "action": {"text": "have", "start": 124, "end": 128, "i_start": 19, "i_end": 19}}], "id": 4546}, {"sent": "recently , the use of deep convolutional neural networks has shown promising results for many vision-based tasks including image classification .", "tokens": ["recently", ",", "the", "use", "of", "deep", "convolutional", "neural", "networks", "has", "shown", "promising", "results", "for", "many", "vision", "-", "based", "tasks", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the use of deep convolutional neural networks", "start": 11, "end": 56, "i_start": 2, "i_end": 8}, "verb": {"text": "has shown", "start": 57, "end": 66, "i_start": 9, "i_end": 10}}, {"character": {"text": "use", "start": 15, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 61, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "results", "start": 77, "end": 84, "i_start": 12, "i_end": 12}, "action": {"text": "promising", "start": 67, "end": 76, "i_start": 11, "i_end": 11}}], "id": 4547}, {"sent": "the intensity of incident light was controlled with filters placed on the collimator .", "tokens": ["the", "intensity", "of", "incident", "light", "was", "controlled", "with", "filters", "placed", "on", "the", "collimator", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the intensity of incident light", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "was controlled", "start": 32, "end": 46, "i_start": 5, "i_end": 6}}], "id": 4548}, {"sent": "we would also like to extend gratitude to marta sarzynska for revisions and illustrations , to dustin padilla for his mathematical revisions , and to dr baojun song for his pearls of wisdom .", "tokens": ["we", "would", "also", "like", "to", "extend", "gratitude", "to", "marta", "sarzynska", "for", "revisions", "and", "illustrations", ",", "to", "dustin", "padilla", "for", "his", "mathematical", "revisions", ",", "and", "to", "dr", "baojun", "song", "for", "his", "pearls", "of", "wisdom", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "like", "start": 14, "end": 18, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "would", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "like", "start": 14, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extend", "start": 22, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "marta sarzynska", "start": 42, "end": 57, "i_start": 8, "i_end": 9}, "action": {"text": "revisions", "start": 62, "end": 71, "i_start": 11, "i_end": 11}}, {"character": {"text": "revisions", "start": 62, "end": 71, "i_start": 11, "i_end": 11}, "action": {"text": "revisions", "start": 62, "end": 71, "i_start": 11, "i_end": 11}}, {"character": {"text": "illustrations", "start": 76, "end": 89, "i_start": 13, "i_end": 13}, "action": {"text": "revisions", "start": 62, "end": 71, "i_start": 11, "i_end": 11}}, {"character": {"text": "marta sarzynska", "start": 42, "end": 57, "i_start": 8, "i_end": 9}, "action": {"text": "illustrations", "start": 76, "end": 89, "i_start": 13, "i_end": 13}}, {"character": {"text": "revisions", "start": 62, "end": 71, "i_start": 11, "i_end": 11}, "action": {"text": "illustrations", "start": 76, "end": 89, "i_start": 13, "i_end": 13}}, {"character": {"text": "illustrations", "start": 76, "end": 89, "i_start": 13, "i_end": 13}, "action": {"text": "illustrations", "start": 76, "end": 89, "i_start": 13, "i_end": 13}}, {"character": {"text": "dustin padilla", "start": 95, "end": 109, "i_start": 16, "i_end": 17}, "action": {"text": "revisions", "start": 131, "end": 140, "i_start": 21, "i_end": 21}}], "id": 4549}, {"sent": "the closely related property of compositionality was a main motivation for hierarchical models of visual cortex such as hmax which can be regarded as a pyramid of and and or layers , that is a sequence of conjunctions and disjunctions .", "tokens": ["the", "closely", "related", "property", "of", "compositionality", "was", "a", "main", "motivation", "for", "hierarchical", "models", "of", "visual", "cortex", "such", "as", "hmax", "which", "can", "be", "regarded", "as", "a", "pyramid", "of", "and", "and", "or", "layers", ",", "that", "is", "a", "sequence", "of", "conjunctions", "and", "disjunctions", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "that", "start": 183, "end": 187, "i_start": 32, "i_end": 32}, "verb": {"text": "is", "start": 188, "end": 190, "i_start": 33, "i_end": 33}}, {"subject": {"text": "that", "start": 183, "end": 187, "i_start": 32, "i_end": 32}, "verb": {"text": "was", "start": 49, "end": 52, "i_start": 6, "i_end": 6}}, {"character": {"text": "property", "start": 20, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "motivation", "start": 60, "end": 70, "i_start": 9, "i_end": 9}}], "id": 4550}, {"sent": "by compactness there is a subsequence converge .", "tokens": ["by", "compactness", "there", "is", "a", "subsequence", "converge", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 15, "end": 20, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 3, "i_end": 3}}], "id": 4551}, {"sent": "an improved approximation ratio for the minimum latency problem .", "tokens": ["an", "improved", "approximation", "ratio", "for", "the", "minimum", "latency", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4552}, {"sent": "represents the deterministic evolution and dij is called kinetic coefficient .", "tokens": ["represents", "the", "deterministic", "evolution", "and", "dij", "is", "called", "kinetic", "coefficient", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the deterministic evolution and dij", "start": 11, "end": 46, "i_start": 1, "i_end": 5}, "verb": {"text": "represents", "start": 0, "end": 10, "i_start": 0, "i_end": 0}}, {"subject": {"text": "the deterministic evolution and dij", "start": 11, "end": 46, "i_start": 1, "i_end": 5}, "verb": {"text": "called", "start": 50, "end": 56, "i_start": 7, "i_end": 7}}, {"character": {"text": "coefficient", "start": 65, "end": 76, "i_start": 9, "i_end": 9}, "action": {"text": "represents", "start": 0, "end": 10, "i_start": 0, "i_end": 0}}], "id": 4553}, {"sent": "however , backpressure based algorithms may not have good delay performance , especially under light loads .", "tokens": ["however", ",", "backpressure", "based", "algorithms", "may", "not", "have", "good", "delay", "performance", ",", "especially", "under", "light", "loads", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "backpressure based algorithms", "start": 10, "end": 39, "i_start": 2, "i_end": 4}, "verb": {"text": "may not have", "start": 40, "end": 52, "i_start": 5, "i_end": 7}}, {"character": {"text": "algorithms", "start": 29, "end": 39, "i_start": 4, "i_end": 4}, "action": {"text": "not have good delay performance", "start": 44, "end": 75, "i_start": 6, "i_end": 10}}], "id": 4554}, {"sent": "most plausible among these is the theory that the rotation is due to an incommensuration between the shapes of the potentials created by the adjacent shells .", "tokens": ["most", "plausible", "among", "these", "is", "the", "theory", "that", "the", "rotation", "is", "due", "to", "an", "incommensuration", "between", "the", "shapes", "of", "the", "potentials", "created", "by", "the", "adjacent", "shells", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "shells", "start": 150, "end": 156, "i_start": 25, "i_end": 25}, "action": {"text": "created", "start": 126, "end": 133, "i_start": 21, "i_end": 21}}], "id": 4555}, {"sent": "we will be more explicit in the following .", "tokens": ["we", "will", "be", "more", "explicit", "in", "the", "following", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will be", "start": 3, "end": 10, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "explicit", "start": 16, "end": 24, "i_start": 4, "i_end": 4}}], "id": 4556}, {"sent": "deep neural networks have demonstrated significant performance improvements in a wide range of computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "significant", "performance", "improvements", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improvements", "start": 63, "end": 75, "i_start": 7, "i_end": 7}}], "id": 4557}, {"sent": "on abscissa , the logarithm of the star mass over the sun mass is shown .", "tokens": ["on", "abscissa", ",", "the", "logarithm", "of", "the", "star", "mass", "over", "the", "sun", "mass", "is", "shown", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the logarithm of the star mass over the sun mass", "start": 14, "end": 62, "i_start": 3, "i_end": 12}, "verb": {"text": "is shown", "start": 63, "end": 71, "i_start": 13, "i_end": 14}}], "id": 4558}, {"sent": "in particular , we investigate band-gap formation and mode localization properties in aperiodic photonic structures based on the accurate calculation of their local density of states .", "tokens": ["in", "particular", ",", "we", "investigate", "band", "-", "gap", "formation", "and", "mode", "localization", "properties", "in", "aperiodic", "photonic", "structures", "based", "on", "the", "accurate", "calculation", "of", "their", "local", "density", "of", "states", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "investigate", "start": 19, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "investigate", "start": 19, "end": 30, "i_start": 4, "i_end": 4}}], "id": 4559}, {"sent": "in recent years , deep neural networks have demonstrated impressive performance improvements on a wide range of challenging machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "demonstrated", "impressive", "performance", "improvements", "on", "a", "wide", "range", "of", "challenging", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have demonstrated", "start": 39, "end": 56, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "demonstrated", "start": 44, "end": 56, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "improvements", "start": 80, "end": 92, "i_start": 11, "i_end": 11}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 68, "end": 79, "i_start": 10, "i_end": 10}}, {"character": {"text": "tasks", "start": 141, "end": 146, "i_start": 20, "i_end": 20}, "action": {"text": "challenging", "start": 112, "end": 123, "i_start": 17, "i_end": 17}}, {"character": {"text": "improvements", "start": 80, "end": 92, "i_start": 11, "i_end": 11}, "action": {"text": "impressive", "start": 57, "end": 67, "i_start": 9, "i_end": 9}}], "id": 4560}, {"sent": "let us also insist that spacetime is a manifold .", "tokens": ["let", "us", "also", "insist", "that", "spacetime", "is", "a", "manifold", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "insist", "start": 12, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "insist", "start": 12, "end": 18, "i_start": 3, "i_end": 3}}], "id": 4561}, {"sent": "we employ the glp model proposed in to generate a scale-free graph with power law degree distribution and high clustering coefficient .", "tokens": ["we", "employ", "the", "glp", "model", "proposed", "in", "to", "generate", "a", "scale", "-", "free", "graph", "with", "power", "law", "degree", "distribution", "and", "high", "clustering", "coefficient", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the glp model", "start": 10, "end": 23, "i_start": 2, "i_end": 4}, "verb": {"text": "proposed", "start": 24, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "generate", "start": 39, "end": 47, "i_start": 8, "i_end": 8}}], "id": 4562}, {"sent": "we compare our proposed salient object detector with 16 recent state-of-the-art saliency models , including drfi .", "tokens": ["we", "compare", "our", "proposed", "salient", "object", "detector", "with", "16", "recent", "state", "-", "of", "-", "the", "-", "art", "saliency", "models", ",", "including", "drfi", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 4563}, {"sent": "following lebret et al , we build kneser-ney smoothed 5-gram language models using the kenlm toolkit .", "tokens": ["following", "lebret", "et", "al", ",", "we", "build", "kneser", "-", "ney", "smoothed", "5", "-", "gram", "language", "models", "using", "the", "kenlm", "toolkit", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "verb": {"text": "build", "start": 28, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "build", "start": 28, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "kneser", "start": 34, "end": 40, "i_start": 7, "i_end": 7}, "action": {"text": "smoothed", "start": 45, "end": 53, "i_start": 10, "i_end": 10}}], "id": 4564}, {"sent": "the surjectivity of a is a nondegeneracy condition .", "tokens": ["the", "surjectivity", "of", "a", "is", "a", "nondegeneracy", "condition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the surjectivity of a", "start": 0, "end": 21, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}], "id": 4565}, {"sent": "the relative riemann-roch theorem from hochschild homology .", "tokens": ["the", "relative", "riemann", "-", "roch", "theorem", "from", "hochschild", "homology", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4566}, {"sent": "the calorimeter consists of 1940 plastic scintillator blocks with photomultiplier readout .", "tokens": ["the", "calorimeter", "consists", "of", "1940", "plastic", "scintillator", "blocks", "with", "photomultiplier", "readout", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the calorimeter", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 16, "end": 24, "i_start": 2, "i_end": 2}}], "id": 4567}, {"sent": "among many approaches , quantum computation can be implemented by local measurement on suitably entangled resource states , which is known as measurement-based quantum computation .", "tokens": ["among", "many", "approaches", ",", "quantum", "computation", "can", "be", "implemented", "by", "local", "measurement", "on", "suitably", "entangled", "resource", "states", ",", "which", "is", "known", "as", "measurement", "-", "based", "quantum", "computation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum computation", "start": 24, "end": 43, "i_start": 4, "i_end": 5}, "verb": {"text": "can be implemented", "start": 44, "end": 62, "i_start": 6, "i_end": 8}}], "id": 4568}, {"sent": "large scale annotated visual datasets have boosted performance of deep learning methods on many challenging computer vision problems .", "tokens": ["large", "scale", "annotated", "visual", "datasets", "have", "boosted", "performance", "of", "deep", "learning", "methods", "on", "many", "challenging", "computer", "vision", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "large scale annotated visual datasets", "start": 0, "end": 37, "i_start": 0, "i_end": 4}, "verb": {"text": "have boosted", "start": 38, "end": 50, "i_start": 5, "i_end": 6}}, {"character": {"text": "datasets", "start": 29, "end": 37, "i_start": 4, "i_end": 4}, "action": {"text": "boosted", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}, {"character": {"text": "methods", "start": 80, "end": 87, "i_start": 11, "i_end": 11}, "action": {"text": "performance", "start": 51, "end": 62, "i_start": 7, "i_end": 7}}, {"character": {"text": "problems", "start": 124, "end": 132, "i_start": 17, "i_end": 17}, "action": {"text": "challenging", "start": 96, "end": 107, "i_start": 14, "i_end": 14}}], "id": 4569}, {"sent": "the appearance of central charges in these algebras is familiar from similar constructions involving edge modes at asymptotic infinity or black hole horizons .", "tokens": ["the", "appearance", "of", "central", "charges", "in", "these", "algebras", "is", "familiar", "from", "similar", "constructions", "involving", "edge", "modes", "at", "asymptotic", "infinity", "or", "black", "hole", "horizons", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the appearance of central charges in these algebras", "start": 0, "end": 51, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 52, "end": 54, "i_start": 8, "i_end": 8}}], "id": 4570}, {"sent": "however , for most of the molecular species in the network , little knowledge , if any , could be deduced about their regulatory rules , for instance in the gene transcription networks in yeast and e .", "tokens": ["however", ",", "for", "most", "of", "the", "molecular", "species", "in", "the", "network", ",", "little", "knowledge", ",", "if", "any", ",", "could", "be", "deduced", "about", "their", "regulatory", "rules", ",", "for", "instance", "in", "the", "gene", "transcription", "networks", "in", "yeast", "and", "e", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "little knowledge , if any", "start": 61, "end": 86, "i_start": 12, "i_end": 16}, "verb": {"text": "could be deduced", "start": 89, "end": 105, "i_start": 18, "i_end": 20}}, {"character": {"text": "species", "start": 36, "end": 43, "i_start": 7, "i_end": 7}, "action": {"text": "knowledge", "start": 68, "end": 77, "i_start": 13, "i_end": 13}}, {"character": {"text": "rules", "start": 129, "end": 134, "i_start": 24, "i_end": 24}, "action": {"text": "regulatory", "start": 118, "end": 128, "i_start": 23, "i_end": 23}}], "id": 4571}, {"sent": "in order to automatically learn the alignments between speech frames and label sequences , the ctc objective was adopted .", "tokens": ["in", "order", "to", "automatically", "learn", "the", "alignments", "between", "speech", "frames", "and", "label", "sequences", ",", "the", "ctc", "objective", "was", "adopted", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the ctc objective", "start": 91, "end": 108, "i_start": 14, "i_end": 16}, "verb": {"text": "was adopted", "start": 109, "end": 120, "i_start": 17, "i_end": 18}}], "id": 4572}, {"sent": "the instrumented detector volume is a cubic kilometer .", "tokens": ["the", "instrumented", "detector", "volume", "is", "a", "cubic", "kilometer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the instrumented detector volume", "start": 0, "end": 32, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 4, "i_end": 4}}], "id": 4573}, {"sent": "polar codes are the first family of explicit error-correcting codes to provably achieve the capacity of binary symmetric channels , with a low-complexity encoding and successive cancellation decoding .", "tokens": ["polar", "codes", "are", "the", "first", "family", "of", "explicit", "error", "-", "correcting", "codes", "to", "provably", "achieve", "the", "capacity", "of", "binary", "symmetric", "channels", ",", "with", "a", "low", "-", "complexity", "encoding", "and", "successive", "cancellation", "decoding", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "polar codes", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 12, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "codes", "start": 62, "end": 67, "i_start": 11, "i_end": 11}, "action": {"text": "correcting", "start": 51, "end": 61, "i_start": 10, "i_end": 10}}], "id": 4574}, {"sent": "more information regarding the function of natural dcs can be found in .", "tokens": ["more", "information", "regarding", "the", "function", "of", "natural", "dcs", "can", "be", "found", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "more information regarding the function of natural dcs", "start": 0, "end": 54, "i_start": 0, "i_end": 7}, "verb": {"text": "can be found", "start": 55, "end": 67, "i_start": 8, "i_end": 10}}], "id": 4575}, {"sent": "however , the neoplasm develops diverse strategies to circumvent the anti-tumor action of the immune system .", "tokens": ["however", ",", "the", "neoplasm", "develops", "diverse", "strategies", "to", "circumvent", "the", "anti", "-", "tumor", "action", "of", "the", "immune", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the neoplasm", "start": 10, "end": 22, "i_start": 2, "i_end": 3}, "verb": {"text": "develops", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "neoplasm", "start": 14, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "develops", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "neoplasm", "start": 14, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "circumvent", "start": 54, "end": 64, "i_start": 8, "i_end": 8}}, {"character": {"text": "system", "start": 101, "end": 107, "i_start": 17, "i_end": 17}, "action": {"text": "immune", "start": 94, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "system", "start": 101, "end": 107, "i_start": 17, "i_end": 17}, "action": {"text": "anti", "start": 69, "end": 73, "i_start": 10, "i_end": 10}}], "id": 4576}, {"sent": "generalized gradient approximation was used for the exchangecorrelation energy , within the perdew-burke-ernzerhof functional form .", "tokens": ["generalized", "gradient", "approximation", "was", "used", "for", "the", "exchangecorrelation", "energy", ",", "within", "the", "perdew", "-", "burke", "-", "ernzerhof", "functional", "form", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generalized gradient approximation", "start": 0, "end": 34, "i_start": 0, "i_end": 2}, "verb": {"text": "was used", "start": 35, "end": 43, "i_start": 3, "i_end": 4}}], "id": 4577}, {"sent": "as a potential photocatalytic material , go has been used in the decolorization of methylene blue .", "tokens": ["as", "a", "potential", "photocatalytic", "material", ",", "go", "has", "been", "used", "in", "the", "decolorization", "of", "methylene", "blue", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "go", "start": 41, "end": 43, "i_start": 6, "i_end": 6}, "verb": {"text": "has been used", "start": 44, "end": 57, "i_start": 7, "i_end": 9}}], "id": 4578}, {"sent": "the invariance under this transformation is called modular invariance .", "tokens": ["the", "invariance", "under", "this", "transformation", "is", "called", "modular", "invariance", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the invariance under this transformation", "start": 0, "end": 40, "i_start": 0, "i_end": 4}, "verb": {"text": "is called", "start": 41, "end": 50, "i_start": 5, "i_end": 6}}], "id": 4579}, {"sent": "the lagrangian is a function of fields which are themselves not smooth functions .", "tokens": ["the", "lagrangian", "is", "a", "function", "of", "fields", "which", "are", "themselves", "not", "smooth", "functions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lagrangian", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "fields", "start": 32, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "function", "start": 20, "end": 28, "i_start": 4, "i_end": 4}}], "id": 4580}, {"sent": "firstly , we are going to prove the closure of our algorithm .", "tokens": ["firstly", ",", "we", "are", "going", "to", "prove", "the", "closure", "of", "our", "algorithm", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "are going", "start": 13, "end": 22, "i_start": 3, "i_end": 4}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "prove", "start": 26, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "closure", "start": 36, "end": 43, "i_start": 8, "i_end": 8}}], "id": 4581}, {"sent": "the appearance module is a linear layer on top of a resnet18 network .", "tokens": ["the", "appearance", "module", "is", "a", "linear", "layer", "on", "top", "of", "a", "resnet18", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the appearance module", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 4582}, {"sent": "vehicle trajectories with gps data have also been widely used for driver behavior pattern analysis and prediction , etc .", "tokens": ["vehicle", "trajectories", "with", "gps", "data", "have", "also", "been", "widely", "used", "for", "driver", "behavior", "pattern", "analysis", "and", "prediction", ",", "etc", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "vehicle trajectories with gps data", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "used", "start": 57, "end": 61, "i_start": 9, "i_end": 9}}, {"subject": {"text": "vehicle trajectories with gps data", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 5, "i_end": 5}}, {"subject": {"text": "vehicle trajectories with gps data", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "been", "start": 45, "end": 49, "i_start": 7, "i_end": 7}}], "id": 4583}, {"sent": "it is an isomorphism if it consists of isomorphism of modules only .", "tokens": ["it", "is", "an", "isomorphism", "if", "it", "consists", "of", "isomorphism", "of", "modules", "only", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}], "id": 4584}, {"sent": "elliptic transformations without fixed points .", "tokens": ["elliptic", "transformations", "without", "fixed", "points", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4585}, {"sent": "for e v , we use the 50-layer resnet to encode image to domain attribute-specific features of 2048 dimensions .", "tokens": ["for", "e", "v", ",", "we", "use", "the", "50", "-", "layer", "resnet", "to", "encode", "image", "to", "domain", "attribute", "-", "specific", "features", "of", "2048", "dimensions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 13, "end": 16, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 13, "end": 16, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 4, "i_end": 4}, "action": {"text": "encode", "start": 40, "end": 46, "i_start": 12, "i_end": 12}}], "id": 4586}, {"sent": "nevertheless , we believe that the package will be adequate for some feasibility studies on the high pt physics at lhc and offer option also for lc .", "tokens": ["nevertheless", ",", "we", "believe", "that", "the", "package", "will", "be", "adequate", "for", "some", "feasibility", "studies", "on", "the", "high", "pt", "physics", "at", "lhc", "and", "offer", "option", "also", "for", "lc", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "believe", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "be", "start": 48, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "believe", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "offer", "start": 123, "end": 128, "i_start": 22, "i_end": 22}}], "id": 4587}, {"sent": "combining the previous three results yields the following theorem .", "tokens": ["combining", "the", "previous", "three", "results", "yields", "the", "following", "theorem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "combining the previous three results", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "yields", "start": 37, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "combining", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "yields", "start": 37, "end": 43, "i_start": 5, "i_end": 5}}], "id": 4588}, {"sent": "then we quantise the spacetime following the strategy of deformation quantisation the algebra of functions in the pseudo-euclidean space to the moyal algebra .", "tokens": ["then", "we", "quantise", "the", "spacetime", "following", "the", "strategy", "of", "deformation", "quantisation", "the", "algebra", "of", "functions", "in", "the", "pseudo", "-", "euclidean", "space", "to", "the", "moyal", "algebra", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "quantise", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "quantise", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "quantisation", "start": 69, "end": 81, "i_start": 10, "i_end": 10}}], "id": 4589}, {"sent": "topological defects have formed during symmetry breaking phase transitions in the early universe .", "tokens": ["topological", "defects", "have", "formed", "during", "symmetry", "breaking", "phase", "transitions", "in", "the", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "topological defects", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "have formed", "start": 20, "end": 31, "i_start": 2, "i_end": 3}}, {"character": {"text": "transitions", "start": 63, "end": 74, "i_start": 8, "i_end": 8}, "action": {"text": "breaking", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}], "id": 4590}, {"sent": "charcteristic polynomials of random matrices at edge singularities .", "tokens": ["charcteristic", "polynomials", "of", "random", "matrices", "at", "edge", "singularities", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4591}, {"sent": "later , levine and pandharipande found a simpler presentation of the cobordism groups .", "tokens": ["later", ",", "levine", "and", "pandharipande", "found", "a", "simpler", "presentation", "of", "the", "cobordism", "groups", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "levine and pandharipande", "start": 8, "end": 32, "i_start": 2, "i_end": 4}, "verb": {"text": "found", "start": 33, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "pandharipande", "start": 19, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "found", "start": 33, "end": 38, "i_start": 5, "i_end": 5}}], "id": 4592}, {"sent": "in the case of two-sided ideals , we prove that all the above concepts coincide .", "tokens": ["in", "the", "case", "of", "two", "-", "sided", "ideals", ",", "we", "prove", "that", "all", "the", "above", "concepts", "coincide", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 34, "end": 36, "i_start": 9, "i_end": 9}, "verb": {"text": "prove", "start": 37, "end": 42, "i_start": 10, "i_end": 10}}, {"subject": {"text": "all the above concepts", "start": 48, "end": 70, "i_start": 12, "i_end": 15}, "verb": {"text": "coincide", "start": 71, "end": 79, "i_start": 16, "i_end": 16}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 9, "i_end": 9}, "action": {"text": "prove", "start": 37, "end": 42, "i_start": 10, "i_end": 10}}], "id": 4593}, {"sent": "recently , there has been significant progress in deep reinforcement learning .", "tokens": ["recently", ",", "there", "has", "been", "significant", "progress", "in", "deep", "reinforcement", "learning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "has been", "start": 17, "end": 25, "i_start": 3, "i_end": 4}}], "id": 4594}, {"sent": "it is a stratified symplectic space and can be viewed in a natural way as a semialgebraic set .", "tokens": ["it", "is", "a", "stratified", "symplectic", "space", "and", "can", "be", "viewed", "in", "a", "natural", "way", "as", "a", "semialgebraic", "set", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "viewed", "start": 47, "end": 53, "i_start": 9, "i_end": 9}}], "id": 4595}, {"sent": "gao et al conducted a broad analysis on spam campaigns that occurred in facebook network .", "tokens": ["gao", "et", "al", "conducted", "a", "broad", "analysis", "on", "spam", "campaigns", "that", "occurred", "in", "facebook", "network", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "gao et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "conducted", "start": 10, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "gao", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "analysis", "start": 28, "end": 36, "i_start": 6, "i_end": 6}}], "id": 4596}, {"sent": "the string tension is a rapidly decreasing zz as fitting parameters .", "tokens": ["the", "string", "tension", "is", "a", "rapidly", "decreasing", "zz", "as", "fitting", "parameters", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the string tension", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 4597}, {"sent": "for the plane wave based calculations , we used projector augmented wave potentials .", "tokens": ["for", "the", "plane", "wave", "based", "calculations", ",", "we", "used", "projector", "augmented", "wave", "potentials", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 40, "end": 42, "i_start": 7, "i_end": 7}, "verb": {"text": "used", "start": 43, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 40, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "used", "start": 43, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "projector", "start": 48, "end": 57, "i_start": 9, "i_end": 9}, "action": {"text": "augmented", "start": 58, "end": 67, "i_start": 10, "i_end": 10}}], "id": 4598}, {"sent": "despite the fact that deep neural networks demonstrate outstanding performance for many machine learning tasks , researchers have found that they are susceptible to attacks by adversarial examples .", "tokens": ["despite", "the", "fact", "that", "deep", "neural", "networks", "demonstrate", "outstanding", "performance", "for", "many", "machine", "learning", "tasks", ",", "researchers", "have", "found", "that", "they", "are", "susceptible", "to", "attacks", "by", "adversarial", "examples", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "researchers", "start": 113, "end": 124, "i_start": 16, "i_end": 16}, "verb": {"text": "have found", "start": 125, "end": 135, "i_start": 17, "i_end": 18}}, {"subject": {"text": "researchers", "start": 113, "end": 124, "i_start": 16, "i_end": 16}, "verb": {"text": "are", "start": 146, "end": 149, "i_start": 21, "i_end": 21}}, {"character": {"text": "examples", "start": 188, "end": 196, "i_start": 27, "i_end": 27}, "action": {"text": "attacks", "start": 165, "end": 172, "i_start": 24, "i_end": 24}}], "id": 4599}, {"sent": "thus , one can achieve the same photocurrent densities with a much sparser lattice of nanoparticles than previously reported .", "tokens": ["thus", ",", "one", "can", "achieve", "the", "same", "photocurrent", "densities", "with", "a", "much", "sparser", "lattice", "of", "nanoparticles", "than", "previously", "reported", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 7, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "can achieve", "start": 11, "end": 22, "i_start": 3, "i_end": 4}}, {"character": {"text": "one", "start": 7, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 15, "end": 22, "i_start": 4, "i_end": 4}}], "id": 4600}, {"sent": "visual context can be obtained in a very local manner such as pixel context or in a global manner by image descriptors like the gist .", "tokens": ["visual", "context", "can", "be", "obtained", "in", "a", "very", "local", "manner", "such", "as", "pixel", "context", "or", "in", "a", "global", "manner", "by", "image", "descriptors", "like", "the", "gist", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "visual context", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "can be obtained", "start": 15, "end": 30, "i_start": 2, "i_end": 4}}], "id": 4601}, {"sent": "the weak phases and the decay amplitudes can then be solved by comparing the resultant parametrization with experimental data .", "tokens": ["the", "weak", "phases", "and", "the", "decay", "amplitudes", "can", "then", "be", "solved", "by", "comparing", "the", "resultant", "parametrization", "with", "experimental", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the weak phases and the decay amplitudes", "start": 0, "end": 40, "i_start": 0, "i_end": 6}, "verb": {"text": "be solved", "start": 50, "end": 59, "i_start": 9, "i_end": 10}}, {"subject": {"text": "the weak phases and the decay amplitudes", "start": 0, "end": 40, "i_start": 0, "i_end": 6}, "verb": {"text": "can", "start": 41, "end": 44, "i_start": 7, "i_end": 7}}], "id": 4602}, {"sent": "the neutrinoless double beta decay is a second order process , forbidden in the standard model due to lepton number violation .", "tokens": ["the", "neutrinoless", "double", "beta", "decay", "is", "a", "second", "order", "process", ",", "forbidden", "in", "the", "standard", "model", "due", "to", "lepton", "number", "violation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the neutrinoless double beta decay", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "model", "start": 89, "end": 94, "i_start": 15, "i_end": 15}, "action": {"text": "forbidden", "start": 63, "end": 72, "i_start": 11, "i_end": 11}}], "id": 4603}, {"sent": "this search with multiple conditions based objective statement comparison proves that the required effort needed to search some multi conditional information is very little in prototype .", "tokens": ["this", "search", "with", "multiple", "conditions", "based", "objective", "statement", "comparison", "proves", "that", "the", "required", "effort", "needed", "to", "search", "some", "multi", "conditional", "information", "is", "very", "little", "in", "prototype", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "this search with multiple conditions based objective statement comparison", "start": 0, "end": 73, "i_start": 0, "i_end": 8}, "verb": {"text": "proves", "start": 74, "end": 80, "i_start": 9, "i_end": 9}}, {"subject": {"text": "this search with multiple conditions based objective statement comparison", "start": 0, "end": 73, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 158, "end": 160, "i_start": 21, "i_end": 21}}, {"character": {"text": "search", "start": 5, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "proves", "start": 74, "end": 80, "i_start": 9, "i_end": 9}}], "id": 4604}, {"sent": "these probabilities can be approximated with high accuracy by monte carlo integration algorithm , .", "tokens": ["these", "probabilities", "can", "be", "approximated", "with", "high", "accuracy", "by", "monte", "carlo", "integration", "algorithm", ",", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these probabilities", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "can be approximated", "start": 20, "end": 39, "i_start": 2, "i_end": 4}}], "id": 4605}, {"sent": "in the authors used 50k , 12k and 95k word lexicons for the iam , rimes and openhart dataset respectively , but none of these lexicons are fully covering the evaluation set .", "tokens": ["in", "the", "authors", "used", "50k", ",", "12k", "and", "95k", "word", "lexicons", "for", "the", "iam", ",", "rimes", "and", "openhart", "dataset", "respectively", ",", "but", "none", "of", "these", "lexicons", "are", "fully", "covering", "the", "evaluation", "set", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "none of these lexicons", "start": 112, "end": 134, "i_start": 22, "i_end": 25}, "verb": {"text": "used", "start": 15, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "none of these lexicons", "start": 112, "end": 134, "i_start": 22, "i_end": 25}, "verb": {"text": "covering", "start": 145, "end": 153, "i_start": 28, "i_end": 28}}], "id": 4606}, {"sent": "recent advancements in deep convolutional neural network have led to promising results in large-scale video classification .", "tokens": ["recent", "advancements", "in", "deep", "convolutional", "neural", "network", "have", "led", "to", "promising", "results", "in", "large", "-", "scale", "video", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent advancements in deep convolutional neural network", "start": 0, "end": 56, "i_start": 0, "i_end": 6}, "verb": {"text": "have led", "start": 57, "end": 65, "i_start": 7, "i_end": 8}}, {"character": {"text": "advancements", "start": 7, "end": 19, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 62, "end": 65, "i_start": 8, "i_end": 8}}, {"character": {"text": "results", "start": 79, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "promising", "start": 69, "end": 78, "i_start": 10, "i_end": 10}}], "id": 4607}, {"sent": "the moment method has been applied to random matrices since the work of wigner .", "tokens": ["the", "moment", "method", "has", "been", "applied", "to", "random", "matrices", "since", "the", "work", "of", "wigner", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the moment method", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "has been applied", "start": 18, "end": 34, "i_start": 3, "i_end": 5}}, {"character": {"text": "wigner", "start": 72, "end": 78, "i_start": 13, "i_end": 13}, "action": {"text": "work", "start": 64, "end": 68, "i_start": 11, "i_end": 11}}], "id": 4608}, {"sent": "the client is the connection generator enabled with multiple network interfaces .", "tokens": ["the", "client", "is", "the", "connection", "generator", "enabled", "with", "multiple", "network", "interfaces", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the client", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "interfaces", "start": 69, "end": 79, "i_start": 10, "i_end": 10}, "action": {"text": "enabled", "start": 39, "end": 46, "i_start": 6, "i_end": 6}}], "id": 4609}, {"sent": "the antennas of the graph are drawn in gray .", "tokens": ["the", "antennas", "of", "the", "graph", "are", "drawn", "in", "gray", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the antennas of the graph", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "are drawn", "start": 26, "end": 35, "i_start": 5, "i_end": 6}}], "id": 4610}, {"sent": "for example , alexnet contain 61 and 128 million parameters , respectively .", "tokens": ["for", "example", ",", "alexnet", "contain", "61", "and", "128", "million", "parameters", ",", "respectively", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "alexnet", "start": 14, "end": 21, "i_start": 3, "i_end": 3}, "verb": {"text": "contain", "start": 22, "end": 29, "i_start": 4, "i_end": 4}}], "id": 4611}, {"sent": "one mc step consists of one modification of each type 1 , 2 , and 3 , where the choice of residue is random for .", "tokens": ["one", "mc", "step", "consists", "of", "one", "modification", "of", "each", "type", "1", ",", "2", ",", "and", "3", ",", "where", "the", "choice", "of", "residue", "is", "random", "for", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one mc step", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}], "id": 4612}, {"sent": "quasi-universal bandwidth selection for kernel density estimators .", "tokens": ["quasi", "-", "universal", "bandwidth", "selection", "for", "kernel", "density", "estimators", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4613}, {"sent": "deep convolutional neural networks have seen great success in a range of computer vision tasks , including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "seen", "great", "success", "in", "a", "range", "of", "computer", "vision", "tasks", ",", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have seen", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "seen", "start": 40, "end": 44, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 51, "end": 58, "i_start": 7, "i_end": 7}}], "id": 4614}, {"sent": "h igh dimensional data analysis is a widespread problem in many applications of machine learning , computer vision , and bioinformatics .", "tokens": ["h", "igh", "dimensional", "data", "analysis", "is", "a", "widespread", "problem", "in", "many", "applications", "of", "machine", "learning", ",", "computer", "vision", ",", "and", "bioinformatics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "h igh dimensional data analysis", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 5, "i_end": 5}}], "id": 4615}, {"sent": "this is reflected in the computed data points in the region of these inner cuts .", "tokens": ["this", "is", "reflected", "in", "the", "computed", "data", "points", "in", "the", "region", "of", "these", "inner", "cuts", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is reflected", "start": 5, "end": 17, "i_start": 1, "i_end": 2}}], "id": 4616}, {"sent": "let gh be the radial component and let ge be the transverse component of g .", "tokens": ["let", "gh", "be", "the", "radial", "component", "and", "let", "ge", "be", "the", "transverse", "component", "of", "g", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4617}, {"sent": "it is a concave lower semicontinuous function on the set staking values in , .", "tokens": ["it", "is", "a", "concave", "lower", "semicontinuous", "function", "on", "the", "set", "staking", "values", "in", ",", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"character": {"text": "set", "start": 53, "end": 56, "i_start": 9, "i_end": 9}, "action": {"text": "function", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}], "id": 4618}, {"sent": "as metallicity is a function of stellar mass difference in other properties of the stellar population , such as age .", "tokens": ["as", "metallicity", "is", "a", "function", "of", "stellar", "mass", "difference", "in", "other", "properties", "of", "the", "stellar", "population", ",", "such", "as", "age", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "difference", "start": 45, "end": 55, "i_start": 8, "i_end": 8}, "action": {"text": "function", "start": 20, "end": 28, "i_start": 4, "i_end": 4}}], "id": 4619}, {"sent": "in it was proposed to mimic the gl instability with the rayleigh-plateau instability , based on the suggestive appearance of the second law of black hole mechanics which endows the horizon with an effective surface tension .", "tokens": ["in", "it", "was", "proposed", "to", "mimic", "the", "gl", "instability", "with", "the", "rayleigh", "-", "plateau", "instability", ",", "based", "on", "the", "suggestive", "appearance", "of", "the", "second", "law", "of", "black", "hole", "mechanics", "which", "endows", "the", "horizon", "with", "an", "effective", "surface", "tension", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 3, "end": 5, "i_start": 1, "i_end": 1}, "verb": {"text": "was proposed", "start": 6, "end": 18, "i_start": 2, "i_end": 3}}, {"character": {"text": "law", "start": 136, "end": 139, "i_start": 24, "i_end": 24}, "action": {"text": "endows", "start": 170, "end": 176, "i_start": 30, "i_end": 30}}, {"character": {"text": "tension", "start": 215, "end": 222, "i_start": 37, "i_end": 37}, "action": {"text": "effective", "start": 197, "end": 206, "i_start": 35, "i_end": 35}}, {"character": {"text": "appearance", "start": 111, "end": 121, "i_start": 20, "i_end": 20}, "action": {"text": "suggestive", "start": 100, "end": 110, "i_start": 19, "i_end": 19}}], "id": 4620}, {"sent": "convolutional neural networks have become quintessential for solving a variety of computer vision tasks such as classification .", "tokens": ["convolutional", "neural", "networks", "have", "become", "quintessential", "for", "solving", "a", "variety", "of", "computer", "vision", "tasks", "such", "as", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have become", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "solving", "start": 61, "end": 68, "i_start": 7, "i_end": 7}}], "id": 4621}, {"sent": "the lagrangian is a lagrangian of dynamical noncommutativity of the space co ordinates .", "tokens": ["the", "lagrangian", "is", "a", "lagrangian", "of", "dynamical", "noncommutativity", "of", "the", "space", "co", "ordinates", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lagrangian", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 4622}, {"sent": "recently , graph convolutional networks have been widely studied for graph data representation and learning .", "tokens": ["recently", ",", "graph", "convolutional", "networks", "have", "been", "widely", "studied", "for", "graph", "data", "representation", "and", "learning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "graph convolutional networks", "start": 11, "end": 39, "i_start": 2, "i_end": 4}, "verb": {"text": "studied", "start": 57, "end": 64, "i_start": 8, "i_end": 8}}, {"subject": {"text": "graph convolutional networks", "start": 11, "end": 39, "i_start": 2, "i_end": 4}, "verb": {"text": "have been", "start": 40, "end": 49, "i_start": 5, "i_end": 6}}], "id": 4623}, {"sent": "deep neural networks have been very successful in large-scale recognition and classification tasks , some even surpassing human-level accuracy .", "tokens": ["deep", "neural", "networks", "have", "been", "very", "successful", "in", "large", "-", "scale", "recognition", "and", "classification", "tasks", ",", "some", "even", "surpassing", "human", "-", "level", "accuracy", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 36, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "surpassing", "start": 111, "end": 121, "i_start": 18, "i_end": 18}}], "id": 4624}, {"sent": "the state of polarization is described by stokes parameters .", "tokens": ["the", "state", "of", "polarization", "is", "described", "by", "stokes", "parameters", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the state of polarization", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "is described", "start": 26, "end": 38, "i_start": 4, "i_end": 5}}, {"character": {"text": "parameters", "start": 49, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "described", "start": 29, "end": 38, "i_start": 5, "i_end": 5}}], "id": 4625}, {"sent": "the ordinate is the time dependent conductance g is the time dependent current , and v the bias .", "tokens": ["the", "ordinate", "is", "the", "time", "dependent", "conductance", "g", "is", "the", "time", "dependent", "current", ",", "and", "v", "the", "bias", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ordinate", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "conductance", "start": 35, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "dependent", "start": 25, "end": 34, "i_start": 5, "i_end": 5}}, {"character": {"text": "current", "start": 71, "end": 78, "i_start": 12, "i_end": 12}, "action": {"text": "dependent", "start": 25, "end": 34, "i_start": 5, "i_end": 5}}], "id": 4626}, {"sent": "particles are reconstructed and identified using a particle-flow algorithm , which utilizes an optimized combination of information from the various elements of the cms detector .", "tokens": ["particles", "are", "reconstructed", "and", "identified", "using", "a", "particle", "-", "flow", "algorithm", ",", "which", "utilizes", "an", "optimized", "combination", "of", "information", "from", "the", "various", "elements", "of", "the", "cms", "detector", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "particles", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "are reconstructed", "start": 10, "end": 27, "i_start": 1, "i_end": 2}}, {"subject": {"text": "particles", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "identified", "start": 32, "end": 42, "i_start": 4, "i_end": 4}}, {"character": {"text": "algorithm", "start": 65, "end": 74, "i_start": 10, "i_end": 10}, "action": {"text": "utilizes", "start": 83, "end": 91, "i_start": 13, "i_end": 13}}], "id": 4627}, {"sent": "there are a number of papers in the physics literature that study this model .", "tokens": ["there", "are", "a", "number", "of", "papers", "in", "the", "physics", "literature", "that", "study", "this", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 6, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "papers", "start": 22, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "study", "start": 60, "end": 65, "i_start": 11, "i_end": 11}}], "id": 4628}, {"sent": "dft calculations were performed using the plane-wave pseudopotential code vasp .", "tokens": ["dft", "calculations", "were", "performed", "using", "the", "plane", "-", "wave", "pseudopotential", "code", "vasp", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dft calculations", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were performed", "start": 17, "end": 31, "i_start": 2, "i_end": 3}}], "id": 4629}, {"sent": "it is well known that network throughput can be significantly increased by network coding .", "tokens": ["it", "is", "well", "known", "that", "network", "throughput", "can", "be", "significantly", "increased", "by", "network", "coding", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "network throughput", "start": 22, "end": 40, "i_start": 5, "i_end": 6}, "verb": {"text": "increased", "start": 62, "end": 71, "i_start": 10, "i_end": 10}}], "id": 4630}, {"sent": "several methods exploit the self-similarity property in natural images and construct lr-hr patch pairs based on the scale-space pyramid of the lr input image .", "tokens": ["several", "methods", "exploit", "the", "self", "-", "similarity", "property", "in", "natural", "images", "and", "construct", "lr", "-", "hr", "patch", "pairs", "based", "on", "the", "scale", "-", "space", "pyramid", "of", "the", "lr", "input", "image", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "several methods", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "exploit", "start": 16, "end": 23, "i_start": 2, "i_end": 2}}, {"subject": {"text": "several methods", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "construct", "start": 75, "end": 84, "i_start": 12, "i_end": 12}}, {"character": {"text": "methods", "start": 8, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "exploit", "start": 16, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "methods", "start": 8, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "construct", "start": 75, "end": 84, "i_start": 12, "i_end": 12}}], "id": 4631}, {"sent": "garg et al proposed the first unsupervised network for single-view depth estimation , in which per-pixel disparity is learned driven by an image reconstruction loss in a calibrated stereo environment .", "tokens": ["garg", "et", "al", "proposed", "the", "first", "unsupervised", "network", "for", "single", "-", "view", "depth", "estimation", ",", "in", "which", "per", "-", "pixel", "disparity", "is", "learned", "driven", "by", "an", "image", "reconstruction", "loss", "in", "a", "calibrated", "stereo", "environment", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 5, "end": 10, "i_start": 1, "i_end": 2}, "verb": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "garg", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}], "id": 4632}, {"sent": "convolutional neural networks have successfully tackled classic computer vision problems such as image classification , where the input image has a grid-like structure .", "tokens": ["convolutional", "neural", "networks", "have", "successfully", "tackled", "classic", "computer", "vision", "problems", "such", "as", "image", "classification", ",", "where", "the", "input", "image", "has", "a", "grid", "-", "like", "structure", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "tackled", "start": 48, "end": 55, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "tackled", "start": 48, "end": 55, "i_start": 5, "i_end": 5}}], "id": 4633}, {"sent": "recently , deep cnn-based methods have achieved considerable progress on some low level vision tasks .", "tokens": ["recently", ",", "deep", "cnn", "-", "based", "methods", "have", "achieved", "considerable", "progress", "on", "some", "low", "level", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep cnn-based methods", "start": 11, "end": 33, "i_start": 2, "i_end": 6}, "verb": {"text": "have achieved", "start": 34, "end": 47, "i_start": 7, "i_end": 8}}, {"character": {"text": "methods", "start": 26, "end": 33, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 39, "end": 47, "i_start": 8, "i_end": 8}}], "id": 4634}, {"sent": "batch normalization and rectified linear unit activation layer are used after every convolution layer .", "tokens": ["batch", "normalization", "and", "rectified", "linear", "unit", "activation", "layer", "are", "used", "after", "every", "convolution", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "batch normalization and rectified linear unit activation layer", "start": 0, "end": 62, "i_start": 0, "i_end": 7}, "verb": {"text": "are used", "start": 63, "end": 71, "i_start": 8, "i_end": 9}}], "id": 4635}, {"sent": "roughgarden showed that , whenever player types are independent , the poa bounds for complete information games extend to bayesian-nash equilibria of the incomplete information game .", "tokens": ["roughgarden", "showed", "that", ",", "whenever", "player", "types", "are", "independent", ",", "the", "poa", "bounds", "for", "complete", "information", "games", "extend", "to", "bayesian", "-", "nash", "equilibria", "of", "the", "incomplete", "information", "game", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "roughgarden", "start": 0, "end": 11, "i_start": 0, "i_end": 0}, "verb": {"text": "showed", "start": 12, "end": 18, "i_start": 1, "i_end": 1}}, {"subject": {"text": "roughgarden", "start": 0, "end": 11, "i_start": 0, "i_end": 0}, "verb": {"text": "extend", "start": 112, "end": 118, "i_start": 17, "i_end": 17}}, {"character": {"text": "roughgarden", "start": 0, "end": 11, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 12, "end": 18, "i_start": 1, "i_end": 1}}, {"character": {"text": "types", "start": 42, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "independent , the poa bounds for complete information games extend to bayesian-", "start": 52, "end": 131, "i_start": 8, "i_end": 20}}], "id": 4636}, {"sent": "this cohomology is the lie algebroid cohomology with trivial coefficients .", "tokens": ["this", "cohomology", "is", "the", "lie", "algebroid", "cohomology", "with", "trivial", "coefficients", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this cohomology", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 4637}, {"sent": "an increasing number of providers have started to supply commercial cloud services with different terminologies , definitions , and goals .", "tokens": ["an", "increasing", "number", "of", "providers", "have", "started", "to", "supply", "commercial", "cloud", "services", "with", "different", "terminologies", ",", "definitions", ",", "and", "goals", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an increasing number of providers", "start": 0, "end": 33, "i_start": 0, "i_end": 4}, "verb": {"text": "have started", "start": 34, "end": 46, "i_start": 5, "i_end": 6}}], "id": 4638}, {"sent": "in recent years , deep neural networks have achieved great success in a variety of machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "achieved", "great", "success", "in", "a", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}], "id": 4639}, {"sent": "it also shows these coefficients are certain intersection numbers , essentially the same interpretation found by kirillov and maeno and theorem c of .", "tokens": ["it", "also", "shows", "these", "coefficients", "are", "certain", "intersection", "numbers", ",", "essentially", "the", "same", "interpretation", "found", "by", "kirillov", "and", "maeno", "and", "theorem", "c", "of", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "shows", "start": 8, "end": 13, "i_start": 2, "i_end": 2}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 33, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "shows", "start": 8, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "kirillov", "start": 113, "end": 121, "i_start": 16, "i_end": 16}, "action": {"text": "found", "start": 104, "end": 109, "i_start": 14, "i_end": 14}}, {"character": {"text": "maeno", "start": 126, "end": 131, "i_start": 18, "i_end": 18}, "action": {"text": "found", "start": 104, "end": 109, "i_start": 14, "i_end": 14}}], "id": 4640}, {"sent": "in recent deep learning works , there are two types of popular generative models , which are variational auto-encoder and generative adversarial network .", "tokens": ["in", "recent", "deep", "learning", "works", ",", "there", "are", "two", "types", "of", "popular", "generative", "models", ",", "which", "are", "variational", "auto", "-", "encoder", "and", "generative", "adversarial", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 32, "end": 37, "i_start": 6, "i_end": 6}, "verb": {"text": "are", "start": 38, "end": 41, "i_start": 7, "i_end": 7}}], "id": 4641}, {"sent": "banerjee et al extended the formulation to general exponential family forms for p via bregman divergences .", "tokens": ["banerjee", "et", "al", "extended", "the", "formulation", "to", "general", "exponential", "family", "forms", "for", "p", "via", "bregman", "divergences", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "banerjee et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "extended", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "banerjee", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "extended", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 4642}, {"sent": "the superpotential is where s is a coupling constant and n invariant under an su ns .", "tokens": ["the", "superpotential", "is", "where", "s", "is", "a", "coupling", "constant", "and", "n", "invariant", "under", "an", "su", "ns", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the superpotential", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the superpotential", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 5, "i_end": 5}}], "id": 4643}, {"sent": "we now consider amplitudes with fewer than four points .", "tokens": ["we", "now", "consider", "amplitudes", "with", "fewer", "than", "four", "points", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "consider", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "consider", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}], "id": 4644}, {"sent": "the cdos method can be easily transformed into an effective global optima search .", "tokens": ["the", "cdos", "method", "can", "be", "easily", "transformed", "into", "an", "effective", "global", "optima", "search", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the cdos method", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "transformed", "start": 30, "end": 41, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the cdos method", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "can be", "start": 16, "end": 22, "i_start": 3, "i_end": 4}}], "id": 4645}, {"sent": "more specifically , we choose the pretrained vgg-19 network and finetune it with the facescrub dataset .", "tokens": ["more", "specifically", ",", "we", "choose", "the", "pretrained", "vgg-19", "network", "and", "finetune", "it", "with", "the", "facescrub", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "verb": {"text": "choose", "start": 23, "end": 29, "i_start": 4, "i_end": 4}}, {"subject": {"text": "we", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "verb": {"text": "finetune", "start": 64, "end": 72, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "choose", "start": 23, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "finetune", "start": 64, "end": 72, "i_start": 10, "i_end": 10}}], "id": 4646}, {"sent": "the lead nanoparticles contain high atom density facets .", "tokens": ["the", "lead", "nanoparticles", "contain", "high", "atom", "density", "facets", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the lead nanoparticles", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "contain", "start": 23, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "nanoparticles", "start": 9, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "contain", "start": 23, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "nanoparticles", "start": 9, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "lead", "start": 4, "end": 8, "i_start": 1, "i_end": 1}}], "id": 4647}, {"sent": "meanwhile , the vertices connected to in qare , and , and the variable attached to them are equal tox 1 , x 1 , andx 3 , respectively .", "tokens": ["meanwhile", ",", "the", "vertices", "connected", "to", "in", "qare", ",", "and", ",", "and", "the", "variable", "attached", "to", "them", "are", "equal", "tox", "1", ",", "x", "1", ",", "andx", "3", ",", "respectively", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the vertices connected to in qare , and , and the variable attached to them", "start": 12, "end": 87, "i_start": 2, "i_end": 16}, "verb": {"text": "are", "start": 88, "end": 91, "i_start": 17, "i_end": 17}}], "id": 4648}, {"sent": "such approximate methods originated in cdma multiuser detection problems in .", "tokens": ["such", "approximate", "methods", "originated", "in", "cdma", "multiuser", "detection", "problems", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such approximate methods", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "originated", "start": 25, "end": 35, "i_start": 3, "i_end": 3}}], "id": 4649}, {"sent": "on forbidden subdivision characterization of graph classes .", "tokens": ["on", "forbidden", "subdivision", "characterization", "of", "graph", "classes", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4650}, {"sent": "following each convolutional layer is a batch normalization layer and a rectified linear unit .", "tokens": ["following", "each", "convolutional", "layer", "is", "a", "batch", "normalization", "layer", "and", "a", "rectified", "linear", "unit", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "following each convolutional layer", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "layer", "start": 29, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "normalization", "start": 46, "end": 59, "i_start": 7, "i_end": 7}}], "id": 4651}, {"sent": "by modifying or perturbing the characteristics of the transmitted signal , the power consumption can be minimized , using -- -the non-linear vector perturbation scheme .", "tokens": ["by", "modifying", "or", "perturbing", "the", "characteristics", "of", "the", "transmitted", "signal", ",", "the", "power", "consumption", "can", "be", "minimized", ",", "using", "--", "-the", "non", "-", "linear", "vector", "perturbation", "scheme", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the power consumption", "start": 75, "end": 96, "i_start": 11, "i_end": 13}, "verb": {"text": "can be minimized", "start": 97, "end": 113, "i_start": 14, "i_end": 16}}], "id": 4652}, {"sent": "for an a-module , m , we denote by m the corresponding complex in kb , concentrated in degree zero .", "tokens": ["for", "an", "a", "-", "module", ",", "m", ",", "we", "denote", "by", "m", "the", "corresponding", "complex", "in", "kb", ",", "concentrated", "in", "degree", "zero", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 22, "end": 24, "i_start": 8, "i_end": 8}, "verb": {"text": "denote", "start": 25, "end": 31, "i_start": 9, "i_end": 9}}, {"subject": {"text": "we", "start": 22, "end": 24, "i_start": 8, "i_end": 8}, "verb": {"text": "concentrated", "start": 71, "end": 83, "i_start": 18, "i_end": 18}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 8, "i_end": 8}, "action": {"text": "denote", "start": 25, "end": 31, "i_start": 9, "i_end": 9}}], "id": 4653}, {"sent": "but , their technique suffered from low f-measure when filler size is small .", "tokens": ["but", ",", "their", "technique", "suffered", "from", "low", "f", "-", "measure", "when", "filler", "size", "is", "small", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "their technique", "start": 6, "end": 21, "i_start": 2, "i_end": 3}, "verb": {"text": "suffered", "start": 22, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "technique", "start": 12, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "suffered", "start": 22, "end": 30, "i_start": 4, "i_end": 4}}], "id": 4654}, {"sent": "the physical layer security was first investigated by wyner in his landmark paper on the degraded wiretap channel .", "tokens": ["the", "physical", "layer", "security", "was", "first", "investigated", "by", "wyner", "in", "his", "landmark", "paper", "on", "the", "degraded", "wiretap", "channel", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the physical layer security", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "investigated", "start": 38, "end": 50, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the physical layer security", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "was", "start": 28, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "wyner", "start": 54, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "investigated", "start": 38, "end": 50, "i_start": 6, "i_end": 6}}], "id": 4655}, {"sent": "the opposite process also takes place occasionally .", "tokens": ["the", "opposite", "process", "also", "takes", "place", "occasionally", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the opposite process", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "takes", "start": 26, "end": 31, "i_start": 4, "i_end": 4}}], "id": 4656}, {"sent": "superscripts denote the variables at the entrance .", "tokens": ["superscripts", "denote", "the", "variables", "at", "the", "entrance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "superscripts", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "denote", "start": 13, "end": 19, "i_start": 1, "i_end": 1}}, {"character": {"text": "superscripts", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 13, "end": 19, "i_start": 1, "i_end": 1}}], "id": 4657}, {"sent": "information theory has been considered as one of the most important theories in the fields of data storage and communications .", "tokens": ["information", "theory", "has", "been", "considered", "as", "one", "of", "the", "most", "important", "theories", "in", "the", "fields", "of", "data", "storage", "and", "communications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "information theory", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "has been considered", "start": 19, "end": 38, "i_start": 2, "i_end": 4}}], "id": 4658}, {"sent": "the conjugate gradient method is one of the most powerful algorithms for solving self-adjoint , positive definite linear equations .", "tokens": ["the", "conjugate", "gradient", "method", "is", "one", "of", "the", "most", "powerful", "algorithms", "for", "solving", "self", "-", "adjoint", ",", "positive", "definite", "linear", "equations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the conjugate gradient method", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 4, "i_end": 4}}], "id": 4659}, {"sent": "this situation is very important because it links our results to the 1-matrix model studied in .", "tokens": ["this", "situation", "is", "very", "important", "because", "it", "links", "our", "results", "to", "the", "1", "-", "matrix", "model", "studied", "in", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this situation", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "links", "start": 44, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "because", "start": 33, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "situation", "start": 5, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "links", "start": 44, "end": 49, "i_start": 7, "i_end": 7}}], "id": 4660}, {"sent": "the numerator is the same in both terms in eq .", "tokens": ["the", "numerator", "is", "the", "same", "in", "both", "terms", "in", "eq", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the numerator", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 4661}, {"sent": "in recent years , deep neural networks have shown great power on image classification tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "shown", "great", "power", "on", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have shown", "start": 39, "end": 49, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "shown", "start": 44, "end": 49, "i_start": 8, "i_end": 8}}], "id": 4662}, {"sent": "this is why the temperature and inner structure coincide with the monopole case .", "tokens": ["this", "is", "why", "the", "temperature", "and", "inner", "structure", "coincide", "with", "the", "monopole", "case", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 4663}, {"sent": "a tracker is a central servers managing peer lists for individual swarms .", "tokens": ["a", "tracker", "is", "a", "central", "servers", "managing", "peer", "lists", "for", "individual", "swarms", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a tracker", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "servers", "start": 23, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "managing", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}], "id": 4664}, {"sent": "proof of this theorem will be given in section v .", "tokens": ["proof", "of", "this", "theorem", "will", "be", "given", "in", "section", "v", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "proof of this theorem", "start": 0, "end": 21, "i_start": 0, "i_end": 3}, "verb": {"text": "will be given", "start": 22, "end": 35, "i_start": 4, "i_end": 6}}], "id": 4665}, {"sent": "another extension is to abstract gradient flows in general metric spaces .", "tokens": ["another", "extension", "is", "to", "abstract", "gradient", "flows", "in", "general", "metric", "spaces", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another extension", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}], "id": 4666}, {"sent": "convolutional networks have recently demonstrated impressive progress in a variety of image classification and recognition tasks .", "tokens": ["convolutional", "networks", "have", "recently", "demonstrated", "impressive", "progress", "in", "a", "variety", "of", "image", "classification", "and", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional networks", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "demonstrated", "start": 37, "end": 49, "i_start": 4, "i_end": 4}}, {"subject": {"text": "convolutional networks", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "have", "start": 23, "end": 27, "i_start": 2, "i_end": 2}}, {"character": {"text": "networks", "start": 14, "end": 22, "i_start": 1, "i_end": 1}, "action": {"text": "demonstrated", "start": 37, "end": 49, "i_start": 4, "i_end": 4}}, {"character": {"text": "progress", "start": 61, "end": 69, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 50, "end": 60, "i_start": 5, "i_end": 5}}], "id": 4667}, {"sent": "this closed subspace is the lub of m a and mb .", "tokens": ["this", "closed", "subspace", "is", "the", "lub", "of", "m", "a", "and", "mb", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this closed subspace", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 3, "i_end": 3}}], "id": 4668}, {"sent": "all networks are implemented in tensorflow and trained with the adam optimizer .", "tokens": ["all", "networks", "are", "implemented", "in", "tensorflow", "and", "trained", "with", "the", "adam", "optimizer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all networks", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "are implemented", "start": 13, "end": 28, "i_start": 2, "i_end": 3}}, {"subject": {"text": "all networks", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "trained", "start": 47, "end": 54, "i_start": 7, "i_end": 7}}], "id": 4669}, {"sent": "the mixture correntropy was thus proposed in a recent work to improve the learning performance , in which the kernel function is implemented by a linear combination of several zero-mean gaussian kernels with different widths .", "tokens": ["the", "mixture", "correntropy", "was", "thus", "proposed", "in", "a", "recent", "work", "to", "improve", "the", "learning", "performance", ",", "in", "which", "the", "kernel", "function", "is", "implemented", "by", "a", "linear", "combination", "of", "several", "zero", "-", "mean", "gaussian", "kernels", "with", "different", "widths", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the mixture correntropy", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 33, "end": 41, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the mixture correntropy", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "was", "start": 24, "end": 27, "i_start": 3, "i_end": 3}}], "id": 4670}, {"sent": "thank you for teaching me the important things .", "tokens": ["thank", "you", "for", "teaching", "me", "the", "important", "things", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "you", "start": 6, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "teaching", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}], "id": 4671}, {"sent": "goodfellow et al present a fast method for generating adversarial perturbations to fool an image classifier .", "tokens": ["goodfellow", "et", "al", "present", "a", "fast", "method", "for", "generating", "adversarial", "perturbations", "to", "fool", "an", "image", "classifier", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "present", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "goodfellow", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "present", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}], "id": 4672}, {"sent": "convolutional neural networks have recently provided state of the art results for several recognition tasks including object recognition .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "provided", "state", "of", "the", "art", "results", "for", "several", "recognition", "tasks", "including", "object", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "provided", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "provided", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}], "id": 4673}, {"sent": "in both panels , there is a suggestion of emission near apastron .", "tokens": ["in", "both", "panels", ",", "there", "is", "a", "suggestion", "of", "emission", "near", "apastron", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 17, "end": 22, "i_start": 4, "i_end": 4}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 5, "i_end": 5}}], "id": 4674}, {"sent": "we further consider a gene clustering example using a gene expression dataset from a small round blue-cell tumors microarray experiment .", "tokens": ["we", "further", "consider", "a", "gene", "clustering", "example", "using", "a", "gene", "expression", "dataset", "from", "a", "small", "round", "blue", "-", "cell", "tumors", "microarray", "experiment", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "consider", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}, {"subject": {"text": "a gene", "start": 20, "end": 26, "i_start": 3, "i_end": 4}, "verb": {"text": "clustering", "start": 27, "end": 37, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "microarray", "start": 114, "end": 124, "i_start": 20, "i_end": 20}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "consider", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 46, "end": 51, "i_start": 7, "i_end": 7}}], "id": 4675}, {"sent": "this should improve the short-term stability of the individual resonators by about two orders of magnitude would represent an unambiguous evidence for the type of random vacuum we have been considering .", "tokens": ["this", "should", "improve", "the", "short", "-", "term", "stability", "of", "the", "individual", "resonators", "by", "about", "two", "orders", "of", "magnitude", "would", "represent", "an", "unambiguous", "evidence", "for", "the", "type", "of", "random", "vacuum", "we", "have", "been", "considering", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "should improve", "start": 5, "end": 19, "i_start": 1, "i_end": 2}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "represent", "start": 113, "end": 122, "i_start": 19, "i_end": 19}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "improve", "start": 12, "end": 19, "i_start": 2, "i_end": 2}}], "id": 4676}, {"sent": "the similarities are both in terms of infinite series formulas and in terms of formulas via iterated path integrals .", "tokens": ["the", "similarities", "are", "both", "in", "terms", "of", "infinite", "series", "formulas", "and", "in", "terms", "of", "formulas", "via", "iterated", "path", "integrals", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the similarities", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 17, "end": 20, "i_start": 2, "i_end": 2}}], "id": 4677}, {"sent": "by 2 6 it suffices to show that there is a functorial cylinder object for comonoids .", "tokens": ["by", "2", "6", "it", "suffices", "to", "show", "that", "there", "is", "a", "functorial", "cylinder", "object", "for", "comonoids", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 7, "end": 9, "i_start": 3, "i_end": 3}, "verb": {"text": "suffices", "start": 10, "end": 18, "i_start": 4, "i_end": 4}}, {"character": {"text": "show", "start": 22, "end": 26, "i_start": 6, "i_end": 6}, "action": {"text": "suffices", "start": 10, "end": 18, "i_start": 4, "i_end": 4}}], "id": 4678}, {"sent": "the condensate is a function of temperature for various values of b .", "tokens": ["the", "condensate", "is", "a", "function", "of", "temperature", "for", "various", "values", "of", "b", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the condensate", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "temperature", "start": 32, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "function", "start": 20, "end": 28, "i_start": 4, "i_end": 4}}], "id": 4679}, {"sent": "deep convolutional neural networks have been proven very useful in various tasks in computer vision including classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "proven", "very", "useful", "in", "various", "tasks", "in", "computer", "vision", "including", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been proven", "start": 35, "end": 51, "i_start": 4, "i_end": 6}}], "id": 4680}, {"sent": "most experiments have used monodisperse spheres in single component plasmas to examine coulomb crystals .", "tokens": ["most", "experiments", "have", "used", "monodisperse", "spheres", "in", "single", "component", "plasmas", "to", "examine", "coulomb", "crystals", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "most experiments", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "have used", "start": 17, "end": 26, "i_start": 2, "i_end": 3}}, {"character": {"text": "experiments", "start": 5, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "used", "start": 22, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "experiments", "start": 5, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "examine", "start": 79, "end": 86, "i_start": 11, "i_end": 11}}], "id": 4681}, {"sent": "we shall refer to the decomposition of the configuration space as the analytic .", "tokens": ["we", "shall", "refer", "to", "the", "decomposition", "of", "the", "configuration", "space", "as", "the", "analytic", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "shall refer", "start": 3, "end": 14, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 9, "end": 14, "i_start": 2, "i_end": 2}}], "id": 4682}, {"sent": "show that every unipotent subgroup of sl is nilpotent .", "tokens": ["show", "that", "every", "unipotent", "subgroup", "of", "sl", "is", "nilpotent", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4683}, {"sent": "our postulate is a straight generalization of this principle .", "tokens": ["our", "postulate", "is", "a", "straight", "generalization", "of", "this", "principle", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our postulate", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 4684}, {"sent": "despite face being a promising trait due to its convenience for users , universality and acceptability , traditional face recognition systems can be easily fooled with common printed facial photographs .", "tokens": ["despite", "face", "being", "a", "promising", "trait", "due", "to", "its", "convenience", "for", "users", ",", "universality", "and", "acceptability", ",", "traditional", "face", "recognition", "systems", "can", "be", "easily", "fooled", "with", "common", "printed", "facial", "photographs", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "traditional face recognition systems", "start": 105, "end": 141, "i_start": 17, "i_end": 20}, "verb": {"text": "fooled", "start": 156, "end": 162, "i_start": 24, "i_end": 24}}, {"subject": {"text": "traditional face recognition systems", "start": 105, "end": 141, "i_start": 17, "i_end": 20}, "verb": {"text": "can be", "start": 142, "end": 148, "i_start": 21, "i_end": 22}}, {"character": {"text": "systems", "start": 134, "end": 141, "i_start": 20, "i_end": 20}, "action": {"text": "recognition", "start": 122, "end": 133, "i_start": 19, "i_end": 19}}, {"character": {"text": "trait", "start": 31, "end": 36, "i_start": 5, "i_end": 5}, "action": {"text": "promising", "start": 21, "end": 30, "i_start": 4, "i_end": 4}}], "id": 4685}, {"sent": "to improve both contrast and resolution of mri , we adapt the state-of-the-art transfer learning method refinenet for 3d , super-resolution segmentation of plant root mri images as root vs non-root .", "tokens": ["to", "improve", "both", "contrast", "and", "resolution", "of", "mri", ",", "we", "adapt", "the", "state", "-", "of", "-", "the", "-", "art", "transfer", "learning", "method", "refinenet", "for", "3d", ",", "super", "-", "resolution", "segmentation", "of", "plant", "root", "mri", "images", "as", "root", "vs", "non", "-", "root", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "verb": {"text": "adapt", "start": 52, "end": 57, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "action": {"text": "adapt", "start": 52, "end": 57, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "action": {"text": "improve", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 4686}, {"sent": "central extensions of the differential operator algebra .", "tokens": ["central", "extensions", "of", "the", "differential", "operator", "algebra", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4687}, {"sent": "values are marked for each of the diffraction peaks .", "tokens": ["values", "are", "marked", "for", "each", "of", "the", "diffraction", "peaks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "values", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "are marked", "start": 7, "end": 17, "i_start": 1, "i_end": 2}}], "id": 4688}, {"sent": "we compare the gpis algorithm using a proximal operator , with the famous ista and fista algorithm .", "tokens": ["we", "compare", "the", "gpis", "algorithm", "using", "a", "proximal", "operator", ",", "with", "the", "famous", "ista", "and", "fista", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 30, "end": 35, "i_start": 5, "i_end": 5}}], "id": 4689}, {"sent": "we have previously classified all such codes of length up to 12 , by classifying lc orbits of simple undirected graphs .", "tokens": ["we", "have", "previously", "classified", "all", "such", "codes", "of", "length", "up", "to", "12", ",", "by", "classifying", "lc", "orbits", "of", "simple", "undirected", "graphs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "classified", "start": 19, "end": 29, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "classified", "start": 19, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "classifying", "start": 69, "end": 80, "i_start": 14, "i_end": 14}}], "id": 4690}, {"sent": "but , if the neutrino is a dirac in this context , the particle , all fermions appear in doublets of dirac particles .", "tokens": ["but", ",", "if", "the", "neutrino", "is", "a", "dirac", "in", "this", "context", ",", "the", "particle", ",", "all", "fermions", "appear", "in", "doublets", "of", "dirac", "particles", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "all fermions", "start": 66, "end": 78, "i_start": 15, "i_end": 16}, "verb": {"text": "appear", "start": 79, "end": 85, "i_start": 17, "i_end": 17}}], "id": 4691}, {"sent": "radio core luminosity of the nuclei for the three samples of local agn .", "tokens": ["radio", "core", "luminosity", "of", "the", "nuclei", "for", "the", "three", "samples", "of", "local", "agn", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4692}, {"sent": "the network coding approach introduced in generalizes routing by allowing intermediate nodes to forward packets that are coded combinations of all received data packets .", "tokens": ["the", "network", "coding", "approach", "introduced", "in", "generalizes", "routing", "by", "allowing", "intermediate", "nodes", "to", "forward", "packets", "that", "are", "coded", "combinations", "of", "all", "received", "data", "packets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "approach", "start": 19, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "generalizes", "start": 42, "end": 53, "i_start": 6, "i_end": 6}}, {"character": {"text": "approach", "start": 19, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "allowing", "start": 65, "end": 73, "i_start": 9, "i_end": 9}}, {"character": {"text": "nodes", "start": 87, "end": 92, "i_start": 11, "i_end": 11}, "action": {"text": "forward", "start": 96, "end": 103, "i_start": 13, "i_end": 13}}], "id": 4693}, {"sent": "some researchers have proposed indigenously mobility models such as random walk , random waypoint , etc .", "tokens": ["some", "researchers", "have", "proposed", "indigenously", "mobility", "models", "such", "as", "random", "walk", ",", "random", "waypoint", ",", "etc", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "some researchers", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "have proposed", "start": 17, "end": 30, "i_start": 2, "i_end": 3}}, {"character": {"text": "some", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 22, "end": 30, "i_start": 3, "i_end": 3}}], "id": 4694}, {"sent": "feedback is a useful element in higher-order tuning applications .", "tokens": ["feedback", "is", "a", "useful", "element", "in", "higher", "-", "order", "tuning", "applications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "feedback", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}], "id": 4695}, {"sent": "among direct detection experiments , the best upper bounds on the cross section of elastic , spin-independent dark matter-nucleon scattering in the 10 gev -1 tev mass range come from the xenon100 experiment .", "tokens": ["among", "direct", "detection", "experiments", ",", "the", "best", "upper", "bounds", "on", "the", "cross", "section", "of", "elastic", ",", "spin", "-", "independent", "dark", "matter", "-", "nucleon", "scattering", "in", "the", "10", "gev", "-1", "tev", "mass", "range", "come", "from", "the", "xenon100", "experiment", "."], "score": [1, 1, 1, 0, 1], "labels": [{"subject": {"text": "the best upper bounds on the cross section of elastic", "start": 37, "end": 90, "i_start": 5, "i_end": 14}, "verb": {"text": "come", "start": 173, "end": 177, "i_start": 32, "i_end": 32}}, {"character": {"text": "spin", "start": 93, "end": 97, "i_start": 16, "i_end": 16}, "action": {"text": "-independent", "start": 97, "end": 109, "i_start": 17, "i_end": 18}}], "id": 4696}, {"sent": "large-scale deep neural networks or dnns have made breakthroughs in many fields , such as image recognition .", "tokens": ["large", "-", "scale", "deep", "neural", "networks", "or", "dnns", "have", "made", "breakthroughs", "in", "many", "fields", ",", "such", "as", "image", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "large-scale deep neural networks or dnns", "start": 0, "end": 40, "i_start": 0, "i_end": 7}, "verb": {"text": "have made", "start": 41, "end": 50, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 24, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "breakthroughs", "start": 51, "end": 64, "i_start": 10, "i_end": 10}}], "id": 4697}, {"sent": "the exchange-correlation functional was treated using the generalized gradient approximation parametrized by perdew , burke , and ernzerhof .", "tokens": ["the", "exchange", "-", "correlation", "functional", "was", "treated", "using", "the", "generalized", "gradient", "approximation", "parametrized", "by", "perdew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange-correlation functional", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "was treated", "start": 36, "end": 47, "i_start": 5, "i_end": 6}}, {"character": {"text": "perdew", "start": 109, "end": 115, "i_start": 14, "i_end": 14}, "action": {"text": "parametrized", "start": 93, "end": 105, "i_start": 12, "i_end": 12}}, {"character": {"text": "burke", "start": 118, "end": 123, "i_start": 16, "i_end": 16}, "action": {"text": "parametrized", "start": 93, "end": 105, "i_start": 12, "i_end": 12}}, {"character": {"text": "ernzerhof", "start": 130, "end": 139, "i_start": 19, "i_end": 19}, "action": {"text": "parametrized", "start": 93, "end": 105, "i_start": 12, "i_end": 12}}], "id": 4698}, {"sent": "massive multiple input multiple output technology is one of the promising means for achieving very high energy and spectrum efficiency requirements of the future 5g networks .", "tokens": ["massive", "multiple", "input", "multiple", "output", "technology", "is", "one", "of", "the", "promising", "means", "for", "achieving", "very", "high", "energy", "and", "spectrum", "efficiency", "requirements", "of", "the", "future", "5", "g", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "massive multiple input multiple output technology", "start": 0, "end": 49, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 50, "end": 52, "i_start": 6, "i_end": 6}}, {"character": {"text": "means", "start": 74, "end": 79, "i_start": 11, "i_end": 11}, "action": {"text": "promising", "start": 64, "end": 73, "i_start": 10, "i_end": 10}}, {"character": {"text": "networks", "start": 165, "end": 173, "i_start": 26, "i_end": 26}, "action": {"text": "requirements", "start": 135, "end": 147, "i_start": 20, "i_end": 20}}], "id": 4699}, {"sent": "the event calculus is a temporal logic for reasoning about events and their effects .", "tokens": ["the", "event", "calculus", "is", "a", "temporal", "logic", "for", "reasoning", "about", "events", "and", "their", "effects", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the event calculus", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 4700}, {"sent": "recently , deep neural networks have achieved impressive results for many image classification tasks .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "achieved", "impressive", "results", "for", "many", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have achieved", "start": 32, "end": 45, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "results", "start": 57, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "impressive", "start": 46, "end": 56, "i_start": 7, "i_end": 7}}], "id": 4701}, {"sent": "we use the definition in of the superalgebra of killing vector fields on a riemannian supermanifold .", "tokens": ["we", "use", "the", "definition", "in", "of", "the", "superalgebra", "of", "killing", "vector", "fields", "on", "a", "riemannian", "supermanifold", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 4702}, {"sent": "since these both are isomorphisms , so is the composition .", "tokens": ["since", "these", "both", "are", "isomorphisms", ",", "so", "is", "the", "composition", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4703}, {"sent": "the chandrasekhar limit is a nearly-universal quantity , so it is not a surprise that the resulting explosions are of nearly-constant luminosity .", "tokens": ["the", "chandrasekhar", "limit", "is", "a", "nearly", "-", "universal", "quantity", ",", "so", "it", "is", "not", "a", "surprise", "that", "the", "resulting", "explosions", "are", "of", "nearly", "-", "constant", "luminosity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the chandrasekhar limit", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "explosions", "start": 100, "end": 110, "i_start": 19, "i_end": 19}, "action": {"text": "-universal quantity , so it is not a surprise", "start": 35, "end": 80, "i_start": 6, "i_end": 15}}], "id": 4704}, {"sent": "the long-dashed line is the upper bound from b-term ad leptogenesis .", "tokens": ["the", "long", "-", "dashed", "line", "is", "the", "upper", "bound", "from", "b", "-", "term", "ad", "leptogenesis", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the long-dashed line", "start": 0, "end": 20, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 5, "i_end": 5}}], "id": 4705}, {"sent": "typically parameters in a mixture model are estimated using the classical em algorithm .", "tokens": ["typically", "parameters", "in", "a", "mixture", "model", "are", "estimated", "using", "the", "classical", "em", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "parameters in a mixture model", "start": 10, "end": 39, "i_start": 1, "i_end": 5}, "verb": {"text": "are estimated", "start": 40, "end": 53, "i_start": 6, "i_end": 7}}], "id": 4706}, {"sent": "each junction is a dynamical system on its own , and there are only short-ranged correlations between spatially separated junctions .", "tokens": ["each", "junction", "is", "a", "dynamical", "system", "on", "its", "own", ",", "and", "there", "are", "only", "short", "-", "ranged", "correlations", "between", "spatially", "separated", "junctions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each junction", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"subject": {"text": "there", "start": 53, "end": 58, "i_start": 11, "i_end": 11}, "verb": {"text": "are", "start": 59, "end": 62, "i_start": 12, "i_end": 12}}], "id": 4707}, {"sent": "in particular , convolutional neural networks have achieved an unprecedented success through alexnet .", "tokens": ["in", "particular", ",", "convolutional", "neural", "networks", "have", "achieved", "an", "unprecedented", "success", "through", "alexnet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}], "id": 4708}, {"sent": "we also apply variational dropout on the output of word embedding layer .", "tokens": ["we", "also", "apply", "variational", "dropout", "on", "the", "output", "of", "word", "embedding", "layer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "apply", "start": 8, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "apply", "start": 8, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "layer", "start": 66, "end": 71, "i_start": 11, "i_end": 11}, "action": {"text": "embedding", "start": 56, "end": 65, "i_start": 10, "i_end": 10}}], "id": 4709}, {"sent": "for further results , we refer the reader to , and references therein .", "tokens": ["for", "further", "results", ",", "we", "refer", "the", "reader", "to", ",", "and", "references", "therein", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 22, "end": 24, "i_start": 4, "i_end": 4}, "verb": {"text": "refer", "start": 25, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "refer", "start": 25, "end": 30, "i_start": 5, "i_end": 5}}], "id": 4710}, {"sent": "the authors in study the performance limits of mimo broadcast channel , in which the base station is responsible for both information and power transmission .", "tokens": ["the", "authors", "in", "study", "the", "performance", "limits", "of", "mimo", "broadcast", "channel", ",", "in", "which", "the", "base", "station", "is", "responsible", "for", "both", "information", "and", "power", "transmission", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "channel", "start": 62, "end": 69, "i_start": 10, "i_end": 10}, "action": {"text": "performance", "start": 25, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "station", "start": 90, "end": 97, "i_start": 16, "i_end": 16}, "action": {"text": "responsible", "start": 101, "end": 112, "i_start": 18, "i_end": 18}}], "id": 4711}, {"sent": "success of convolutional neural networks over the past several years has lead to their extensive deployment in a wide range of computer vision tasks .", "tokens": ["success", "of", "convolutional", "neural", "networks", "over", "the", "past", "several", "years", "has", "lead", "to", "their", "extensive", "deployment", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "success of convolutional neural networks over the past several years", "start": 0, "end": 68, "i_start": 0, "i_end": 9}, "verb": {"text": "has lead", "start": 69, "end": 77, "i_start": 10, "i_end": 11}}, {"character": {"text": "success", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "lead", "start": 73, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "success", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}], "id": 4712}, {"sent": "in both figures the arrow denotes the physical point .", "tokens": ["in", "both", "figures", "the", "arrow", "denotes", "the", "physical", "point", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the arrow denotes the physical point", "start": 16, "end": 52, "i_start": 3, "i_end": 8}, "verb": {"text": "denotes", "start": 26, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "arrow", "start": 20, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "denotes", "start": 26, "end": 33, "i_start": 5, "i_end": 5}}], "id": 4713}, {"sent": "the phase boundary , which is a function of the network connectivity p and the error probability q , is described quantitatively by the crowd-anticrowd theory .", "tokens": ["the", "phase", "boundary", ",", "which", "is", "a", "function", "of", "the", "network", "connectivity", "p", "and", "the", "error", "probability", "q", ",", "is", "described", "quantitatively", "by", "the", "crowd", "-", "anticrowd", "theory", "."], "score": [1, 0, 0, 0, 1], "labels": [{"subject": {"text": "the phase boundary", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is described", "start": 101, "end": 113, "i_start": 19, "i_end": 20}}, {"character": {"text": "theory", "start": 152, "end": 158, "i_start": 27, "i_end": 27}, "action": {"text": "described", "start": 104, "end": 113, "i_start": 20, "i_end": 20}}, {"character": {"text": "connectivity", "start": 56, "end": 68, "i_start": 11, "i_end": 11}, "action": {"text": "function", "start": 32, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "probability", "start": 85, "end": 96, "i_start": 16, "i_end": 16}, "action": {"text": "function", "start": 32, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "error", "start": 79, "end": 84, "i_start": 15, "i_end": 15}, "action": {"text": "function", "start": 32, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "quantitatively", "start": 114, "end": 128, "i_start": 21, "i_end": 21}, "action": {"text": "function", "start": 32, "end": 40, "i_start": 7, "i_end": 7}}], "id": 4714}, {"sent": "according to the general theory of singular systems , the variables with ambiguous dynamics do not represent the observable quantities .", "tokens": ["according", "to", "the", "general", "theory", "of", "singular", "systems", ",", "the", "variables", "with", "ambiguous", "dynamics", "do", "not", "represent", "the", "observable", "quantities", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the variables with ambiguous dynamics", "start": 54, "end": 91, "i_start": 9, "i_end": 13}, "verb": {"text": "do not represent", "start": 92, "end": 108, "i_start": 14, "i_end": 16}}, {"character": {"text": "variables", "start": 58, "end": 67, "i_start": 10, "i_end": 10}, "action": {"text": "not represent", "start": 95, "end": 108, "i_start": 15, "i_end": 16}}], "id": 4715}, {"sent": "we train our baseline models using stochastic gradient descent along with the adam update rules .", "tokens": ["we", "train", "our", "baseline", "models", "using", "stochastic", "gradient", "descent", "along", "with", "the", "adam", "update", "rules", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 29, "end": 34, "i_start": 5, "i_end": 5}}], "id": 4716}, {"sent": "the exchange correlation energy was described by the generalized gradient approximation using the perdew-burke-ernzerhof functional .", "tokens": ["the", "exchange", "correlation", "energy", "was", "described", "by", "the", "generalized", "gradient", "approximation", "using", "the", "perdew", "-", "burke", "-", "ernzerhof", "functional", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the exchange correlation energy", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "was described", "start": 32, "end": 45, "i_start": 4, "i_end": 5}}, {"character": {"text": "approximation", "start": 74, "end": 87, "i_start": 10, "i_end": 10}, "action": {"text": "described", "start": 36, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "approximation", "start": 74, "end": 87, "i_start": 10, "i_end": 10}, "action": {"text": "using", "start": 88, "end": 93, "i_start": 11, "i_end": 11}}], "id": 4717}, {"sent": "moreover , the elliptic degeneracy and geometry of the problem makes it difficult to apply the hodograph transform approach in chen-feldman to a partially modified equation .", "tokens": ["moreover", ",", "the", "elliptic", "degeneracy", "and", "geometry", "of", "the", "problem", "makes", "it", "difficult", "to", "apply", "the", "hodograph", "transform", "approach", "in", "chen", "-", "feldman", "to", "a", "partially", "modified", "equation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the elliptic degeneracy and geometry of the problem", "start": 11, "end": 62, "i_start": 2, "i_end": 9}, "verb": {"text": "makes", "start": 63, "end": 68, "i_start": 10, "i_end": 10}}, {"subject": {"text": "the elliptic degeneracy and geometry of the problem", "start": 11, "end": 62, "i_start": 2, "i_end": 9}, "verb": {"text": "difficult", "start": 72, "end": 81, "i_start": 12, "i_end": 12}}, {"character": {"text": "degeneracy", "start": 24, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "makes", "start": 63, "end": 68, "i_start": 10, "i_end": 10}}, {"character": {"text": "elliptic", "start": 15, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "makes", "start": 63, "end": 68, "i_start": 10, "i_end": 10}}, {"character": {"text": "geometry", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "makes", "start": 63, "end": 68, "i_start": 10, "i_end": 10}}, {"character": {"text": "problem", "start": 55, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "makes", "start": 63, "end": 68, "i_start": 10, "i_end": 10}}, {"character": {"text": "chen", "start": 127, "end": 131, "i_start": 20, "i_end": 20}, "action": {"text": "approach", "start": 115, "end": 123, "i_start": 18, "i_end": 18}}], "id": 4718}, {"sent": "millimeter wave communication is a promising technology for future outdoor cellular systems .", "tokens": ["millimeter", "wave", "communication", "is", "a", "promising", "technology", "for", "future", "outdoor", "cellular", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "millimeter wave communication", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "technology", "start": 45, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "promising", "start": 35, "end": 44, "i_start": 5, "i_end": 5}}], "id": 4719}, {"sent": "a field \u03c6 , g on y is called a virtual history .", "tokens": ["a", "field", "\u03c6", ",", "g", "on", "y", "is", "called", "a", "virtual", "history", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a field \u03c6 , g on y", "start": 0, "end": 18, "i_start": 0, "i_end": 6}, "verb": {"text": "is called", "start": 19, "end": 28, "i_start": 7, "i_end": 8}}], "id": 4720}, {"sent": "to determine the mass parameter for the heavy charm quark we use the fermilab method , where the average link u 0 is determined from the plaquette .", "tokens": ["to", "determine", "the", "mass", "parameter", "for", "the", "heavy", "charm", "quark", "we", "use", "the", "fermilab", "method", ",", "where", "the", "average", "link", "u", "0", "is", "determined", "from", "the", "plaquette", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 58, "end": 60, "i_start": 10, "i_end": 10}, "verb": {"text": "use", "start": 61, "end": 64, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 58, "end": 60, "i_start": 10, "i_end": 10}, "action": {"text": "use", "start": 61, "end": 64, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 58, "end": 60, "i_start": 10, "i_end": 10}, "action": {"text": "determined", "start": 117, "end": 127, "i_start": 23, "i_end": 23}}], "id": 4721}, {"sent": "a classification of the projective lines over small rings ii .", "tokens": ["a", "classification", "of", "the", "projective", "lines", "over", "small", "rings", "ii", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4722}, {"sent": "recently , deep convolutional neural networks have achieved great successes in computer vision topics such as image classification .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "achieved", "great", "successes", "in", "computer", "vision", "topics", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "successes", "start": 66, "end": 75, "i_start": 9, "i_end": 9}}], "id": 4723}, {"sent": "in this scenario a lepton asymmetry arises from the out of equilibrium and cp-violating decay of heavy , majorana neutrinos , and it is processed into a baryon asymmetry by the electroweak sphaleron .", "tokens": ["in", "this", "scenario", "a", "lepton", "asymmetry", "arises", "from", "the", "out", "of", "equilibrium", "and", "cp", "-", "violating", "decay", "of", "heavy", ",", "majorana", "neutrinos", ",", "and", "it", "is", "processed", "into", "a", "baryon", "asymmetry", "by", "the", "electroweak", "sphaleron", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a lepton asymmetry", "start": 17, "end": 35, "i_start": 3, "i_end": 5}, "verb": {"text": "arises", "start": 36, "end": 42, "i_start": 6, "i_end": 6}}, {"subject": {"text": "it", "start": 130, "end": 132, "i_start": 24, "i_end": 24}, "verb": {"text": "processed", "start": 136, "end": 145, "i_start": 26, "i_end": 26}}, {"character": {"text": "decay", "start": 88, "end": 93, "i_start": 16, "i_end": 16}, "action": {"text": "violating", "start": 78, "end": 87, "i_start": 15, "i_end": 15}}, {"character": {"text": "neutrinos", "start": 114, "end": 123, "i_start": 21, "i_end": 21}, "action": {"text": "decay", "start": 88, "end": 93, "i_start": 16, "i_end": 16}}], "id": 4724}, {"sent": "thomas , tl watts university of tennessee , knoxville , usa g .", "tokens": ["thomas", ",", "tl", "watts", "university", "of", "tennessee", ",", "knoxville", ",", "usa", "g", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4725}, {"sent": "thereby we show the suitability of the scheme for simulations of compressible turbulence .", "tokens": ["thereby", "we", "show", "the", "suitability", "of", "the", "scheme", "for", "simulations", "of", "compressible", "turbulence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "show", "start": 11, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 11, "end": 15, "i_start": 2, "i_end": 2}}], "id": 4726}, {"sent": "in , a singular value decomposition -based analog combiner was implemented by using an alternating projection method .", "tokens": ["in", ",", "a", "singular", "value", "decomposition", "-based", "analog", "combiner", "was", "implemented", "by", "using", "an", "alternating", "projection", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a singular value decomposition -based analog combiner", "start": 5, "end": 58, "i_start": 2, "i_end": 8}, "verb": {"text": "was implemented", "start": 59, "end": 74, "i_start": 9, "i_end": 10}}], "id": 4727}, {"sent": "then , hou et al introduce dense short connections to the skip-layers within the holistically-nested edge detection architecture to get rich multi-scale features for sod .", "tokens": ["then", ",", "hou", "et", "al", "introduce", "dense", "short", "connections", "to", "the", "skip", "-", "layers", "within", "the", "holistically", "-", "nested", "edge", "detection", "architecture", "to", "get", "rich", "multi", "-", "scale", "features", "for", "sod", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hou et al", "start": 7, "end": 16, "i_start": 2, "i_end": 4}, "verb": {"text": "introduce", "start": 17, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "hou", "start": 7, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "introduce", "start": 17, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "architecture", "start": 116, "end": 128, "i_start": 21, "i_end": 21}, "action": {"text": "detection", "start": 106, "end": 115, "i_start": 20, "i_end": 20}}, {"character": {"text": "hou", "start": 7, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "get", "start": 132, "end": 135, "i_start": 23, "i_end": 23}}], "id": 4728}, {"sent": "this is an essence of the no-go theorem for the leibniz rule on lattice proved in our previous work .", "tokens": ["this", "is", "an", "essence", "of", "the", "no", "-", "go", "theorem", "for", "the", "leibniz", "rule", "on", "lattice", "proved", "in", "our", "previous", "work", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "leibniz", "start": 48, "end": 55, "i_start": 12, "i_end": 12}, "action": {"text": "rule", "start": 56, "end": 60, "i_start": 13, "i_end": 13}}], "id": 4729}, {"sent": "the generalized gradient approximation corrected functional by perdew et al is used for the exchange-correlation potential .", "tokens": ["the", "generalized", "gradient", "approximation", "corrected", "functional", "by", "perdew", "et", "al", "is", "used", "for", "the", "exchange", "-", "correlation", "potential", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation corrected functional by perdew et al", "start": 0, "end": 75, "i_start": 0, "i_end": 9}, "verb": {"text": "is used", "start": 76, "end": 83, "i_start": 10, "i_end": 11}}, {"character": {"text": "perdew", "start": 63, "end": 69, "i_start": 7, "i_end": 7}, "action": {"text": "used", "start": 79, "end": 83, "i_start": 11, "i_end": 11}}], "id": 4730}, {"sent": "for this dataset , we use deep learning features by training a googlenet style convnet .", "tokens": ["for", "this", "dataset", ",", "we", "use", "deep", "learning", "features", "by", "training", "a", "googlenet", "style", "convnet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 22, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 22, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "training", "start": 52, "end": 60, "i_start": 10, "i_end": 10}}], "id": 4731}, {"sent": "we show that there does not exist the fuzzy sphere solution .", "tokens": ["we", "show", "that", "there", "does", "not", "exist", "the", "fuzzy", "sphere", "solution", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "there", "start": 13, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "exist", "start": 28, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 4732}, {"sent": "onvolutional neural networks have achieved remarkable performance on vision problems such as image classification .", "tokens": ["onvolutional", "neural", "networks", "have", "achieved", "remarkable", "performance", "on", "vision", "problems", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "onvolutional neural networks", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 29, "end": 42, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 20, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 34, "end": 42, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 20, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 54, "end": 65, "i_start": 6, "i_end": 6}}], "id": 4733}, {"sent": "in this section we describe three dimensional spin foam models in general , where the turaev-viro model is included .", "tokens": ["in", "this", "section", "we", "describe", "three", "dimensional", "spin", "foam", "models", "in", "general", ",", "where", "the", "turaev", "-", "viro", "model", "is", "included", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "describe", "start": 19, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "describe", "start": 19, "end": 27, "i_start": 4, "i_end": 4}}], "id": 4734}, {"sent": "the model is trained using the adam gradient descent algorithm , for 100 epochs with a mini-batch size of 32 .", "tokens": ["the", "model", "is", "trained", "using", "the", "adam", "gradient", "descent", "algorithm", ",", "for", "100", "epochs", "with", "a", "mini", "-", "batch", "size", "of", "32", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is trained", "start": 10, "end": 20, "i_start": 2, "i_end": 3}}], "id": 4735}, {"sent": "here , the physics objects are the jets clustered using the jet finding algorithm with the tracks assigned to the vertex as inputs , and the associated missing transverse momentum , taken as the negative vector p t sum of those jets .", "tokens": ["here", ",", "the", "physics", "objects", "are", "the", "jets", "clustered", "using", "the", "jet", "finding", "algorithm", "with", "the", "tracks", "assigned", "to", "the", "vertex", "as", "inputs", ",", "and", "the", "associated", "missing", "transverse", "momentum", ",", "taken", "as", "the", "negative", "vector", "p", "t", "sum", "of", "those", "jets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the physics objects", "start": 7, "end": 26, "i_start": 2, "i_end": 4}, "verb": {"text": "are", "start": 27, "end": 30, "i_start": 5, "i_end": 5}}], "id": 4736}, {"sent": "polar codes are the first structured codes that provably achieve the symmetric capacity of binary-input memoryless channels .", "tokens": ["polar", "codes", "are", "the", "first", "structured", "codes", "that", "provably", "achieve", "the", "symmetric", "capacity", "of", "binary", "-", "input", "memoryless", "channels", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "polar codes", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 12, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "codes", "start": 6, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "achieve", "start": 57, "end": 64, "i_start": 9, "i_end": 9}}], "id": 4737}, {"sent": "each of these algebras is the algebra of sections of the field a\u03c3 of finite dimensional matrix algebras over b\u03c3 .", "tokens": ["each", "of", "these", "algebras", "is", "the", "algebra", "of", "sections", "of", "the", "field", "a\u03c3", "of", "finite", "dimensional", "matrix", "algebras", "over", "b\u03c3", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each of these algebras", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 4, "i_end": 4}}], "id": 4738}, {"sent": "one profile is a flat background reflecting the time-dependent charged particle background .", "tokens": ["one", "profile", "is", "a", "flat", "background", "reflecting", "the", "time", "-", "dependent", "charged", "particle", "background", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one profile", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "background", "start": 80, "end": 90, "i_start": 13, "i_end": 13}, "action": {"text": "dependent", "start": 53, "end": 62, "i_start": 10, "i_end": 10}}], "id": 4739}, {"sent": "in contrast , a stochastic homogeneous hyperelastic model is defined by a stochastic strain-energy function , for which the model parameters are random variables that satisfy standard probability laws .", "tokens": ["in", "contrast", ",", "a", "stochastic", "homogeneous", "hyperelastic", "model", "is", "defined", "by", "a", "stochastic", "strain", "-", "energy", "function", ",", "for", "which", "the", "model", "parameters", "are", "random", "variables", "that", "satisfy", "standard", "probability", "laws", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "a stochastic homogeneous hyperelastic model", "start": 14, "end": 57, "i_start": 3, "i_end": 7}, "verb": {"text": "is defined", "start": 58, "end": 68, "i_start": 8, "i_end": 9}}, {"character": {"text": "function", "start": 99, "end": 107, "i_start": 16, "i_end": 16}, "action": {"text": "defined", "start": 61, "end": 68, "i_start": 9, "i_end": 9}}, {"character": {"text": "function", "start": 99, "end": 107, "i_start": 16, "i_end": 16}, "action": {"text": "satisfy", "start": 167, "end": 174, "i_start": 27, "i_end": 27}}], "id": 4740}, {"sent": "this geometry is the one for which the permeation mode is expected .", "tokens": ["this", "geometry", "is", "the", "one", "for", "which", "the", "permeation", "mode", "is", "expected", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this geometry", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 4741}, {"sent": "all the calculations were performed using vienna ab initio simulation package , which is based on the density functional theory .", "tokens": ["all", "the", "calculations", "were", "performed", "using", "vienna", "ab", "initio", "simulation", "package", ",", "which", "is", "based", "on", "the", "density", "functional", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all the calculations", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "were performed", "start": 21, "end": 35, "i_start": 3, "i_end": 4}}], "id": 4742}, {"sent": "in particular , in this work we inflate the 18-layer resnet network into an i3d one .", "tokens": ["in", "particular", ",", "in", "this", "work", "we", "inflate", "the", "18", "-", "layer", "resnet", "network", "into", "an", "i3d", "one", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 29, "end": 31, "i_start": 6, "i_end": 6}, "verb": {"text": "inflate", "start": 32, "end": 39, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 6, "i_end": 6}, "action": {"text": "inflate", "start": 32, "end": 39, "i_start": 7, "i_end": 7}}], "id": 4743}, {"sent": "another modification is the reduction of the compton cross section in the klein-nishina regime .", "tokens": ["another", "modification", "is", "the", "reduction", "of", "the", "compton", "cross", "section", "in", "the", "klein", "-", "nishina", "regime", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another modification", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 2, "i_end": 2}}], "id": 4744}, {"sent": "we will do this term by term to work out the contributing parts .", "tokens": ["we", "will", "do", "this", "term", "by", "term", "to", "work", "out", "the", "contributing", "parts", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will do", "start": 3, "end": 10, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "work", "start": 32, "end": 36, "i_start": 8, "i_end": 8}}, {"character": {"text": "parts", "start": 58, "end": 63, "i_start": 12, "i_end": 12}, "action": {"text": "contributing", "start": 45, "end": 57, "i_start": 11, "i_end": 11}}], "id": 4745}, {"sent": "the vertical thickness of the star forming region also depends on the mass and gas fraction of the galaxy .", "tokens": ["the", "vertical", "thickness", "of", "the", "star", "forming", "region", "also", "depends", "on", "the", "mass", "and", "gas", "fraction", "of", "the", "galaxy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the vertical thickness of the star forming region", "start": 0, "end": 49, "i_start": 0, "i_end": 7}, "verb": {"text": "depends", "start": 55, "end": 62, "i_start": 9, "i_end": 9}}, {"character": {"text": "thickness", "start": 13, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "depends", "start": 55, "end": 62, "i_start": 9, "i_end": 9}}, {"character": {"text": "region", "start": 43, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "forming", "start": 35, "end": 42, "i_start": 6, "i_end": 6}}], "id": 4746}, {"sent": "the result can be easily understood by counting the total number of all possible microstates of the system .", "tokens": ["the", "result", "can", "be", "easily", "understood", "by", "counting", "the", "total", "number", "of", "all", "possible", "microstates", "of", "the", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the result", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "understood", "start": 25, "end": 35, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the result", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "can be", "start": 11, "end": 17, "i_start": 2, "i_end": 3}}], "id": 4747}, {"sent": "deep neural networks have gained lots of success after enabling several breakthroughs in notably challenging problems such as image classification .", "tokens": ["deep", "neural", "networks", "have", "gained", "lots", "of", "success", "after", "enabling", "several", "breakthroughs", "in", "notably", "challenging", "problems", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have gained", "start": 21, "end": 32, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "gained", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 41, "end": 48, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "enabling", "start": 55, "end": 63, "i_start": 9, "i_end": 9}}], "id": 4748}, {"sent": "the electron exchange-correlation functional was described by the generalized gradient approximation in the form proposed by perdew , burke , and ernzerhof .", "tokens": ["the", "electron", "exchange", "-", "correlation", "functional", "was", "described", "by", "the", "generalized", "gradient", "approximation", "in", "the", "form", "proposed", "by", "perdew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the electron exchange-correlation functional", "start": 0, "end": 44, "i_start": 0, "i_end": 5}, "verb": {"text": "was described", "start": 45, "end": 58, "i_start": 6, "i_end": 7}}, {"character": {"text": "approximation", "start": 87, "end": 100, "i_start": 12, "i_end": 12}, "action": {"text": "described", "start": 49, "end": 58, "i_start": 7, "i_end": 7}}, {"character": {"text": "perdew", "start": 125, "end": 131, "i_start": 18, "i_end": 18}, "action": {"text": "proposed", "start": 113, "end": 121, "i_start": 16, "i_end": 16}}, {"character": {"text": "burke", "start": 134, "end": 139, "i_start": 20, "i_end": 20}, "action": {"text": "proposed", "start": 113, "end": 121, "i_start": 16, "i_end": 16}}, {"character": {"text": "ernzerhof", "start": 146, "end": 155, "i_start": 23, "i_end": 23}, "action": {"text": "proposed", "start": 113, "end": 121, "i_start": 16, "i_end": 16}}], "id": 4749}, {"sent": "in recent years , deep convolution neural networks have achieved promising performance on many artificial intelligence tasks , including image recognition .", "tokens": ["in", "recent", "years", ",", "deep", "convolution", "neural", "networks", "have", "achieved", "promising", "performance", "on", "many", "artificial", "intelligence", "tasks", ",", "including", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolution neural networks", "start": 18, "end": 50, "i_start": 4, "i_end": 7}, "verb": {"text": "have achieved", "start": 51, "end": 64, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 42, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 56, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 42, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "performance", "start": 75, "end": 86, "i_start": 11, "i_end": 11}}, {"character": {"text": "performance", "start": 75, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "promising", "start": 65, "end": 74, "i_start": 10, "i_end": 10}}], "id": 4750}, {"sent": "although great effort has been devoted to the study of that problem , it has been shown to be polynomial-time solvable only for a couple of interesting classes of phylogenetic networks , namely , normal networks and tree-child networks .", "tokens": ["although", "great", "effort", "has", "been", "devoted", "to", "the", "study", "of", "that", "problem", ",", "it", "has", "been", "shown", "to", "be", "polynomial", "-", "time", "solvable", "only", "for", "a", "couple", "of", "interesting", "classes", "of", "phylogenetic", "networks", ",", "namely", ",", "normal", "networks", "and", "tree", "-", "child", "networks", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 70, "end": 72, "i_start": 13, "i_end": 13}, "verb": {"text": "has been shown", "start": 73, "end": 87, "i_start": 14, "i_end": 16}}, {"character": {"text": "classes", "start": 152, "end": 159, "i_start": 29, "i_end": 29}, "action": {"text": "solvable", "start": 110, "end": 118, "i_start": 22, "i_end": 22}}], "id": 4751}, {"sent": "calculations are carried out within the density functional theory .", "tokens": ["calculations", "are", "carried", "out", "within", "the", "density", "functional", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "calculations", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "are carried out", "start": 13, "end": 28, "i_start": 1, "i_end": 3}}], "id": 4752}, {"sent": "basic material on distance-regular graphs may be found in chapters 20 and 21 of .", "tokens": ["basic", "material", "on", "distance", "-", "regular", "graphs", "may", "be", "found", "in", "chapters", "20", "and", "21", "of", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "basic material on distance-regular graphs", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "may be found", "start": 42, "end": 54, "i_start": 7, "i_end": 9}}], "id": 4753}, {"sent": "we train the n -style network with stochastic gradient descent using the adam optimizer .", "tokens": ["we", "train", "the", "n", "-style", "network", "with", "stochastic", "gradient", "descent", "using", "the", "adam", "optimizer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 63, "end": 68, "i_start": 10, "i_end": 10}}], "id": 4754}, {"sent": "convolutional neural networks , as one of the widely used deep learning methods , have been proven to be very successful for object recognition in images .", "tokens": ["convolutional", "neural", "networks", ",", "as", "one", "of", "the", "widely", "used", "deep", "learning", "methods", ",", "have", "been", "proven", "to", "be", "very", "successful", "for", "object", "recognition", "in", "images", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been proven", "start": 82, "end": 98, "i_start": 14, "i_end": 16}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 110, "end": 120, "i_start": 20, "i_end": 20}}], "id": 4755}, {"sent": "to fix these limitations , several recent works have been proposed to generate person , bird or face images based on object keypoints .", "tokens": ["to", "fix", "these", "limitations", ",", "several", "recent", "works", "have", "been", "proposed", "to", "generate", "person", ",", "bird", "or", "face", "images", "based", "on", "object", "keypoints", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "several recent works", "start": 27, "end": 47, "i_start": 5, "i_end": 7}, "verb": {"text": "have been proposed", "start": 48, "end": 66, "i_start": 8, "i_end": 10}}], "id": 4756}, {"sent": "the first one is eigenoscillations of the poles in the giant cusp .", "tokens": ["the", "first", "one", "is", "eigenoscillations", "of", "the", "poles", "in", "the", "giant", "cusp", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the first one", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 3, "i_end": 3}}], "id": 4757}, {"sent": "le and mikolov proposed an unsupervised framework that learns continuous distributed vector representations for variable-length pieces of texts , such as sentences or paragraphs .", "tokens": ["le", "and", "mikolov", "proposed", "an", "unsupervised", "framework", "that", "learns", "continuous", "distributed", "vector", "representations", "for", "variable", "-", "length", "pieces", "of", "texts", ",", "such", "as", "sentences", "or", "paragraphs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "le and mikolov", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "le", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "mikolov", "start": 7, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "framework", "start": 40, "end": 49, "i_start": 6, "i_end": 6}, "action": {"text": "learns", "start": 55, "end": 61, "i_start": 8, "i_end": 8}}], "id": 4758}, {"sent": "this duality is a powerful mathematical result that establishes a relation , via an isomorphism , between two noncommutative algebras .", "tokens": ["this", "duality", "is", "a", "powerful", "mathematical", "result", "that", "establishes", "a", "relation", ",", "via", "an", "isomorphism", ",", "between", "two", "noncommutative", "algebras", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this duality", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "result", "start": 40, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "establishes", "start": 52, "end": 63, "i_start": 8, "i_end": 8}}], "id": 4759}, {"sent": "deep convolutional neural networks have been prevailed in various computer vision tasks , such as objection classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "prevailed", "in", "various", "computer", "vision", "tasks", ",", "such", "as", "objection", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been prevailed", "start": 35, "end": 54, "i_start": 4, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "prevailed", "start": 45, "end": 54, "i_start": 6, "i_end": 6}}], "id": 4760}, {"sent": "the single and double wavy lines represent the propagators of the bare and renormalized fluctuating cooper pairs , respectively .", "tokens": ["the", "single", "and", "double", "wavy", "lines", "represent", "the", "propagators", "of", "the", "bare", "and", "renormalized", "fluctuating", "cooper", "pairs", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the single and double wavy lines", "start": 0, "end": 32, "i_start": 0, "i_end": 5}, "verb": {"text": "represent", "start": 33, "end": 42, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the single and double wavy lines", "start": 0, "end": 32, "i_start": 0, "i_end": 5}, "verb": {"text": "renormalized", "start": 75, "end": 87, "i_start": 13, "i_end": 13}}, {"character": {"text": "lines", "start": 27, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "represent", "start": 33, "end": 42, "i_start": 6, "i_end": 6}}], "id": 4761}, {"sent": "the spectral analysis was carried out using the xspec software .", "tokens": ["the", "spectral", "analysis", "was", "carried", "out", "using", "the", "xspec", "software", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the spectral analysis", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "was carried out", "start": 22, "end": 37, "i_start": 3, "i_end": 5}}], "id": 4762}, {"sent": "we have shown that the self-similar solutions can be applied to check the accuracy of the relativistic mhd codes .", "tokens": ["we", "have", "shown", "that", "the", "self", "-", "similar", "solutions", "can", "be", "applied", "to", "check", "the", "accuracy", "of", "the", "relativistic", "mhd", "codes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have shown", "start": 3, "end": 13, "i_start": 1, "i_end": 2}}, {"subject": {"text": "the self-similar solutions", "start": 19, "end": 45, "i_start": 4, "i_end": 8}, "verb": {"text": "applied", "start": 53, "end": 60, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "shown", "start": 8, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "solutions", "start": 36, "end": 45, "i_start": 8, "i_end": 8}, "action": {"text": "check", "start": 64, "end": 69, "i_start": 13, "i_end": 13}}], "id": 4763}, {"sent": "this foliation is the well-known horosphere foliation .", "tokens": ["this", "foliation", "is", "the", "well", "-", "known", "horosphere", "foliation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this foliation", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 4764}, {"sent": "deep convolutional networks have witnessed great successes in image classification and many powerful network architectures have been developed , such as alexnet .", "tokens": ["deep", "convolutional", "networks", "have", "witnessed", "great", "successes", "in", "image", "classification", "and", "many", "powerful", "network", "architectures", "have", "been", "developed", ",", "such", "as", "alexnet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional networks", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "have witnessed", "start": 28, "end": 42, "i_start": 3, "i_end": 4}}, {"subject": {"text": "deep convolutional networks", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "developed", "start": 133, "end": 142, "i_start": 17, "i_end": 17}}, {"character": {"text": "networks", "start": 19, "end": 27, "i_start": 2, "i_end": 2}, "action": {"text": "witnessed", "start": 33, "end": 42, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 19, "end": 27, "i_start": 2, "i_end": 2}, "action": {"text": "successes", "start": 49, "end": 58, "i_start": 6, "i_end": 6}}], "id": 4765}, {"sent": "among them , convolutional neural networks have been demonstrated to be extremely successful in computer vision .", "tokens": ["among", "them", ",", "convolutional", "neural", "networks", "have", "been", "demonstrated", "to", "be", "extremely", "successful", "in", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 13, "end": 42, "i_start": 3, "i_end": 5}, "verb": {"text": "have been demonstrated", "start": 43, "end": 65, "i_start": 6, "i_end": 8}}, {"character": {"text": "networks", "start": 34, "end": 42, "i_start": 5, "i_end": 5}, "action": {"text": "successful", "start": 82, "end": 92, "i_start": 12, "i_end": 12}}], "id": 4766}, {"sent": "the complete prolog translation of the iocaste problem .", "tokens": ["the", "complete", "prolog", "translation", "of", "the", "iocaste", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4767}, {"sent": "the same argument shows the following result .", "tokens": ["the", "same", "argument", "shows", "the", "following", "result", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the same argument", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "shows", "start": 18, "end": 23, "i_start": 3, "i_end": 3}}], "id": 4768}, {"sent": "lately , a large body of successful deep generative models have emerged , especially generative adversarial networks .", "tokens": ["lately", ",", "a", "large", "body", "of", "successful", "deep", "generative", "models", "have", "emerged", ",", "especially", "generative", "adversarial", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a large body of successful deep generative models", "start": 9, "end": 58, "i_start": 2, "i_end": 9}, "verb": {"text": "have emerged", "start": 59, "end": 71, "i_start": 10, "i_end": 11}}, {"character": {"text": "body", "start": 17, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "emerged", "start": 64, "end": 71, "i_start": 11, "i_end": 11}}], "id": 4769}, {"sent": "the ellipses denote operators that are suppressed by powers of \u00b5 .", "tokens": ["the", "ellipses", "denote", "operators", "that", "are", "suppressed", "by", "powers", "of", "\u00b5", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "ellipses", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 13, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "powers", "start": 53, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "suppressed", "start": 39, "end": 49, "i_start": 6, "i_end": 6}}], "id": 4770}, {"sent": "convolutional neural networks have recently been shown to perform well on large scale visual recognition tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "been", "shown", "to", "perform", "well", "on", "large", "scale", "visual", "recognition", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "been shown", "start": 44, "end": 54, "i_start": 5, "i_end": 6}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "perform", "start": 58, "end": 65, "i_start": 8, "i_end": 8}}], "id": 4771}, {"sent": "in most cases in this category the combination with the far detector solves the degeneracy .", "tokens": ["in", "most", "cases", "in", "this", "category", "the", "combination", "with", "the", "far", "detector", "solves", "the", "degeneracy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the combination with the far detector", "start": 31, "end": 68, "i_start": 6, "i_end": 11}, "verb": {"text": "solves", "start": 69, "end": 75, "i_start": 12, "i_end": 12}}, {"character": {"text": "combination", "start": 35, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "solves", "start": 69, "end": 75, "i_start": 12, "i_end": 12}}], "id": 4772}, {"sent": "in the experiments , we used scikit-learn to perform clustering .", "tokens": ["in", "the", "experiments", ",", "we", "used", "scikit", "-", "learn", "to", "perform", "clustering", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "used", "start": 24, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "used", "start": 24, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "perform", "start": 45, "end": 52, "i_start": 10, "i_end": 10}}], "id": 4773}, {"sent": "thus we have introduced na-quad seminearrings .", "tokens": ["thus", "we", "have", "introduced", "na", "-", "quad", "seminearrings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "have introduced", "start": 8, "end": 23, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "introduced", "start": 13, "end": 23, "i_start": 3, "i_end": 3}}], "id": 4774}, {"sent": "each location of the grid is then encoded via the 2048-dimensional features extracted from a resnet-152 .", "tokens": ["each", "location", "of", "the", "grid", "is", "then", "encoded", "via", "the", "2048", "-", "dimensional", "features", "extracted", "from", "a", "resnet-152", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each location of the grid", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "encoded", "start": 34, "end": 41, "i_start": 7, "i_end": 7}}, {"subject": {"text": "each location of the grid", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 5, "i_end": 5}}], "id": 4775}, {"sent": "an alternative is the dataset of , but it only consists of 54 images and even fewer objects .", "tokens": ["an", "alternative", "is", "the", "dataset", "of", ",", "but", "it", "only", "consists", "of", "54", "images", "and", "even", "fewer", "objects", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an alternative", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "it", "start": 39, "end": 41, "i_start": 8, "i_end": 8}, "verb": {"text": "consists", "start": 47, "end": 55, "i_start": 10, "i_end": 10}}], "id": 4776}, {"sent": "all the parameters of the decoder network are initialized with xavier .", "tokens": ["all", "the", "parameters", "of", "the", "decoder", "network", "are", "initialized", "with", "xavier", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "all the parameters of the decoder network", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "are initialized", "start": 42, "end": 57, "i_start": 7, "i_end": 8}}, {"character": {"text": "network", "start": 34, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "decoder", "start": 26, "end": 33, "i_start": 5, "i_end": 5}}], "id": 4777}, {"sent": "this exposure bias results in error accumulation during the output generation at test time , since the model has never been exclusively exposed to its own predictions during training .", "tokens": ["this", "exposure", "bias", "results", "in", "error", "accumulation", "during", "the", "output", "generation", "at", "test", "time", ",", "since", "the", "model", "has", "never", "been", "exclusively", "exposed", "to", "its", "own", "predictions", "during", "training", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "model", "start": 103, "end": 108, "i_start": 17, "i_end": 17}, "action": {"text": "predictions", "start": 155, "end": 166, "i_start": 26, "i_end": 26}}], "id": 4778}, {"sent": "for many real networks the stochasticity is an inherent property .", "tokens": ["for", "many", "real", "networks", "the", "stochasticity", "is", "an", "inherent", "property", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the stochasticity", "start": 23, "end": 40, "i_start": 4, "i_end": 5}, "verb": {"text": "is", "start": 41, "end": 43, "i_start": 6, "i_end": 6}}], "id": 4779}, {"sent": "an lstm model that uses cnn features for action recognition is presented in .", "tokens": ["an", "lstm", "model", "that", "uses", "cnn", "features", "for", "action", "recognition", "is", "presented", "in", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "an lstm model that uses cnn features for action recognition", "start": 0, "end": 59, "i_start": 0, "i_end": 9}, "verb": {"text": "is presented", "start": 60, "end": 72, "i_start": 10, "i_end": 11}}, {"character": {"text": "model", "start": 8, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "uses", "start": 19, "end": 23, "i_start": 4, "i_end": 4}}], "id": 4780}, {"sent": "hinton et al proposed deep belief networks , which is a generative model that can extract high-level visual features of images .", "tokens": ["hinton", "et", "al", "proposed", "deep", "belief", "networks", ",", "which", "is", "a", "generative", "model", "that", "can", "extract", "high", "-", "level", "visual", "features", "of", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hinton et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "hinton", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "model", "start": 67, "end": 72, "i_start": 12, "i_end": 12}, "action": {"text": "extract", "start": 82, "end": 89, "i_start": 15, "i_end": 15}}], "id": 4781}, {"sent": "as in , our bounds do not coincide , which is not surprising , since we address is a special case of the berger-tung problem .", "tokens": ["as", "in", ",", "our", "bounds", "do", "not", "coincide", ",", "which", "is", "not", "surprising", ",", "since", "we", "address", "is", "a", "special", "case", "of", "the", "berger", "-", "tung", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 69, "end": 71, "i_start": 15, "i_end": 15}, "action": {"text": "bounds", "start": 12, "end": 18, "i_start": 4, "i_end": 4}}, {"character": {"text": "not coincide", "start": 22, "end": 34, "i_start": 6, "i_end": 7}, "action": {"text": "not surprising", "start": 46, "end": 60, "i_start": 11, "i_end": 12}}, {"character": {"text": "we", "start": 69, "end": 71, "i_start": 15, "i_end": 15}, "action": {"text": "address", "start": 72, "end": 79, "i_start": 16, "i_end": 16}}], "id": 4782}, {"sent": "solid lines refer to the upper stable branches of the splay state .", "tokens": ["solid", "lines", "refer", "to", "the", "upper", "stable", "branches", "of", "the", "splay", "state", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "solid lines", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "refer", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "lines", "start": 6, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "refer", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}], "id": 4783}, {"sent": "we will consider the dynamics both with and without an external magnetic field .", "tokens": ["we", "will", "consider", "the", "dynamics", "both", "with", "and", "without", "an", "external", "magnetic", "field", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will consider", "start": 3, "end": 16, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "consider", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}], "id": 4784}, {"sent": "in this context , the current standard notion of privacy is differential privacy .", "tokens": ["in", "this", "context", ",", "the", "current", "standard", "notion", "of", "privacy", "is", "differential", "privacy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the current standard notion of privacy", "start": 18, "end": 56, "i_start": 4, "i_end": 9}, "verb": {"text": "is", "start": 57, "end": 59, "i_start": 10, "i_end": 10}}], "id": 4785}, {"sent": "the recent success of deep neural networks has dramatically boosted the applications of machine learning .", "tokens": ["the", "recent", "success", "of", "deep", "neural", "networks", "has", "dramatically", "boosted", "the", "applications", "of", "machine", "learning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the recent success of deep neural networks", "start": 0, "end": 42, "i_start": 0, "i_end": 6}, "verb": {"text": "boosted", "start": 60, "end": 67, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the recent success of deep neural networks", "start": 0, "end": 42, "i_start": 0, "i_end": 6}, "verb": {"text": "has", "start": 43, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "success", "start": 11, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "boosted", "start": 60, "end": 67, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 34, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}], "id": 4786}, {"sent": "in mean field variational inference , the update to the approximating family of a latent variable depends on the distribution of that latent variable conditional on everything else .", "tokens": ["in", "mean", "field", "variational", "inference", ",", "the", "update", "to", "the", "approximating", "family", "of", "a", "latent", "variable", "depends", "on", "the", "distribution", "of", "that", "latent", "variable", "conditional", "on", "everything", "else", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the update to the approximating family of a latent variable", "start": 38, "end": 97, "i_start": 6, "i_end": 15}, "verb": {"text": "depends", "start": 98, "end": 105, "i_start": 16, "i_end": 16}}, {"character": {"text": "update", "start": 42, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "depends", "start": 98, "end": 105, "i_start": 16, "i_end": 16}}, {"character": {"text": "family", "start": 70, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "approximating", "start": 56, "end": 69, "i_start": 10, "i_end": 10}}], "id": 4787}, {"sent": "van dam and haemers conjectured that almost all graphs are dqs or dls .", "tokens": ["van", "dam", "and", "haemers", "conjectured", "that", "almost", "all", "graphs", "are", "dqs", "or", "dls", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "van dam and haemers", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "conjectured", "start": 20, "end": 31, "i_start": 4, "i_end": 4}}, {"subject": {"text": "van dam and haemers", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 55, "end": 58, "i_start": 9, "i_end": 9}}, {"character": {"text": "van dam", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "action": {"text": "conjectured", "start": 20, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "haemers", "start": 12, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "conjectured", "start": 20, "end": 31, "i_start": 4, "i_end": 4}}], "id": 4788}, {"sent": "the acquisition of this training data is a painstakingly process that requires long hours of manual labor and there is thus a strong interest in developing methods that require less groundtruth data .", "tokens": ["the", "acquisition", "of", "this", "training", "data", "is", "a", "painstakingly", "process", "that", "requires", "long", "hours", "of", "manual", "labor", "and", "there", "is", "thus", "a", "strong", "interest", "in", "developing", "methods", "that", "require", "less", "groundtruth", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the acquisition of this training data", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "process", "start": 57, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "requires", "start": 70, "end": 78, "i_start": 11, "i_end": 11}}, {"character": {"text": "methods", "start": 156, "end": 163, "i_start": 26, "i_end": 26}, "action": {"text": "require", "start": 169, "end": 176, "i_start": 28, "i_end": 28}}], "id": 4789}, {"sent": "gelberg , jh hamilton , av ramayya , jk hwang , sj zhu , pm gore , d .", "tokens": ["gelberg", ",", "jh", "hamilton", ",", "av", "ramayya", ",", "jk", "hwang", ",", "sj", "zhu", ",", "pm", "gore", ",", "d", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4790}, {"sent": "furthermore , in this work , we train the neural networks using an adam optimizer .", "tokens": ["furthermore", ",", "in", "this", "work", ",", "we", "train", "the", "neural", "networks", "using", "an", "adam", "optimizer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 29, "end": 31, "i_start": 6, "i_end": 6}, "verb": {"text": "train", "start": 32, "end": 37, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 6, "i_end": 6}, "action": {"text": "train", "start": 32, "end": 37, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 6, "i_end": 6}, "action": {"text": "using", "start": 58, "end": 63, "i_start": 11, "i_end": 11}}], "id": 4791}, {"sent": "electronic exchange-correlation energy was treated with generalized gradient approximation parametrized by perdew-burke-ernzerhof .", "tokens": ["electronic", "exchange", "-", "correlation", "energy", "was", "treated", "with", "generalized", "gradient", "approximation", "parametrized", "by", "perdew", "-", "burke", "-", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "electronic exchange-correlation energy", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "was treated", "start": 39, "end": 50, "i_start": 5, "i_end": 6}}], "id": 4792}, {"sent": "profiles of the magnetization , particle and energy density were studied in various systems , including the xx spin chain .", "tokens": ["profiles", "of", "the", "magnetization", ",", "particle", "and", "energy", "density", "were", "studied", "in", "various", "systems", ",", "including", "the", "xx", "spin", "chain", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "profiles of the magnetization", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "were studied", "start": 60, "end": 72, "i_start": 9, "i_end": 10}}], "id": 4793}, {"sent": "deep neural networks have been showing impressive performance in a variety of applications in multiple domains .", "tokens": ["deep", "neural", "networks", "have", "been", "showing", "impressive", "performance", "in", "a", "variety", "of", "applications", "in", "multiple", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been showing", "start": 21, "end": 38, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "showing", "start": 31, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 50, "end": 61, "i_start": 7, "i_end": 7}}, {"character": {"text": "performance", "start": 50, "end": 61, "i_start": 7, "i_end": 7}, "action": {"text": "impressive", "start": 39, "end": 49, "i_start": 6, "i_end": 6}}], "id": 4794}, {"sent": "since bennett and brassard proposed the first protocol of unconditionally secure quantum key distribution , several aspects of secure quantum communication have been explored .", "tokens": ["since", "bennett", "and", "brassard", "proposed", "the", "first", "protocol", "of", "unconditionally", "secure", "quantum", "key", "distribution", ",", "several", "aspects", "of", "secure", "quantum", "communication", "have", "been", "explored", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "several aspects of secure quantum communication", "start": 108, "end": 155, "i_start": 15, "i_end": 20}, "verb": {"text": "have been explored", "start": 156, "end": 174, "i_start": 21, "i_end": 23}}, {"character": {"text": "bennett", "start": 6, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "proposed", "start": 27, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "brassard", "start": 18, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "proposed", "start": 27, "end": 35, "i_start": 4, "i_end": 4}}], "id": 4795}, {"sent": "our model is based on the state-of-the-art cnn architecture resnet-101 .", "tokens": ["our", "model", "is", "based", "on", "the", "state", "-", "of", "-", "the", "-", "art", "cnn", "architecture", "resnet-101", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is based", "start": 10, "end": 18, "i_start": 2, "i_end": 3}}], "id": 4796}, {"sent": "the unitary fermi gas made of fermionic alkali-metal atoms has been largely investigated both experimentally and theoretically .", "tokens": ["the", "unitary", "fermi", "gas", "made", "of", "fermionic", "alkali", "-", "metal", "atoms", "has", "been", "largely", "investigated", "both", "experimentally", "and", "theoretically", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the unitary fermi gas made of fermionic alkali-metal atoms", "start": 0, "end": 58, "i_start": 0, "i_end": 10}, "verb": {"text": "investigated", "start": 76, "end": 88, "i_start": 14, "i_end": 14}}, {"subject": {"text": "the unitary fermi gas made of fermionic alkali-metal atoms", "start": 0, "end": 58, "i_start": 0, "i_end": 10}, "verb": {"text": "has been", "start": 59, "end": 67, "i_start": 11, "i_end": 12}}], "id": 4797}, {"sent": "we illustrate this by the following example .", "tokens": ["we", "illustrate", "this", "by", "the", "following", "example", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "illustrate", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "illustrate", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}], "id": 4798}, {"sent": "in recent years there has been an increasing interest in grassmannian codes as a result of their application to error-correction in random network coding which was demonstrated in the seminal work by koetter and kschischang .", "tokens": ["in", "recent", "years", "there", "has", "been", "an", "increasing", "interest", "in", "grassmannian", "codes", "as", "a", "result", "of", "their", "application", "to", "error", "-", "correction", "in", "random", "network", "coding", "which", "was", "demonstrated", "in", "the", "seminal", "work", "by", "koetter", "and", "kschischang", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 16, "end": 21, "i_start": 3, "i_end": 3}, "verb": {"text": "has been", "start": 22, "end": 30, "i_start": 4, "i_end": 5}}, {"character": {"text": "work", "start": 192, "end": 196, "i_start": 32, "i_end": 32}, "action": {"text": "demonstrated", "start": 164, "end": 176, "i_start": 28, "i_end": 28}}, {"character": {"text": "koetter", "start": 200, "end": 207, "i_start": 34, "i_end": 34}, "action": {"text": "work", "start": 192, "end": 196, "i_start": 32, "i_end": 32}}], "id": 4799}, {"sent": "the world-sheet is the unit disc and the target space is 26-dimensional euclidean space .", "tokens": ["the", "world", "-", "sheet", "is", "the", "unit", "disc", "and", "the", "target", "space", "is", "26", "-", "dimensional", "euclidean", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the world-sheet", "start": 0, "end": 15, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 4, "i_end": 4}}], "id": 4800}, {"sent": "for the first , we need permanent magnetic materials .", "tokens": ["for", "the", "first", ",", "we", "need", "permanent", "magnetic", "materials", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "need", "start": 19, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "need", "start": 19, "end": 23, "i_start": 5, "i_end": 5}}], "id": 4801}, {"sent": "goodfellow et al proposed the fast gradient sign method based on linearization of the network as a simple alternative to l-bfgs .", "tokens": ["goodfellow", "et", "al", "proposed", "the", "fast", "gradient", "sign", "method", "based", "on", "linearization", "of", "the", "network", "as", "a", "simple", "alternative", "to", "l", "-", "bfgs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "goodfellow", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}], "id": 4802}, {"sent": "in recent years , deep neural networks have been applied to many areas and have achieved huge success in different domains such as image classification .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "been", "applied", "to", "many", "areas", "and", "have", "achieved", "huge", "success", "in", "different", "domains", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have been applied", "start": 39, "end": 56, "i_start": 7, "i_end": 9}}, {"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "achieved", "start": 80, "end": 88, "i_start": 15, "i_end": 15}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 80, "end": 88, "i_start": 15, "i_end": 15}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 94, "end": 101, "i_start": 17, "i_end": 17}}], "id": 4803}, {"sent": "before introducing the proposed model , in this section , we briefly review the recent development of subspace clustering methods .", "tokens": ["before", "introducing", "the", "proposed", "model", ",", "in", "this", "section", ",", "we", "briefly", "review", "the", "recent", "development", "of", "subspace", "clustering", "methods", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 58, "end": 60, "i_start": 10, "i_end": 10}, "verb": {"text": "review", "start": 69, "end": 75, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 58, "end": 60, "i_start": 10, "i_end": 10}, "action": {"text": "review", "start": 69, "end": 75, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 58, "end": 60, "i_start": 10, "i_end": 10}, "action": {"text": "introducing", "start": 7, "end": 18, "i_start": 1, "i_end": 1}}], "id": 4804}, {"sent": "it is known that once the module structure and banach space structure are given the a-valued inner product is uniquely defined .", "tokens": ["it", "is", "known", "that", "once", "the", "module", "structure", "and", "banach", "space", "structure", "are", "given", "the", "a", "-", "valued", "inner", "product", "is", "uniquely", "defined", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is known", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"subject": {"text": "the a-valued inner product", "start": 80, "end": 106, "i_start": 14, "i_end": 19}, "verb": {"text": "defined", "start": 119, "end": 126, "i_start": 22, "i_end": 22}}], "id": 4805}, {"sent": "for the totally geodesic 2 is the sectional curvature of the hyperbolic vertical fibres of space sp .", "tokens": ["for", "the", "totally", "geodesic", "2", "is", "the", "sectional", "curvature", "of", "the", "hyperbolic", "vertical", "fibres", "of", "space", "sp", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4806}, {"sent": "in other words , the effects of coordinate noncommutativity should be restricted to distances comparable to the noncommutative length scale .", "tokens": ["in", "other", "words", ",", "the", "effects", "of", "coordinate", "noncommutativity", "should", "be", "restricted", "to", "distances", "comparable", "to", "the", "noncommutative", "length", "scale", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the effects of coordinate noncommutativity", "start": 17, "end": 59, "i_start": 4, "i_end": 8}, "verb": {"text": "should be restricted", "start": 60, "end": 80, "i_start": 9, "i_end": 11}}], "id": 4807}, {"sent": "for a geometric treatment of these concepts , we refer the reader to the excellent book of eisenbud .", "tokens": ["for", "a", "geometric", "treatment", "of", "these", "concepts", ",", "we", "refer", "the", "reader", "to", "the", "excellent", "book", "of", "eisenbud", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 46, "end": 48, "i_start": 8, "i_end": 8}, "verb": {"text": "refer", "start": 49, "end": 54, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 46, "end": 48, "i_start": 8, "i_end": 8}, "action": {"text": "refer", "start": 49, "end": 54, "i_start": 9, "i_end": 9}}], "id": 4808}, {"sent": "the genus of s is the genus of the heegaard splitting .", "tokens": ["the", "genus", "of", "s", "is", "the", "genus", "of", "the", "heegaard", "splitting", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the genus of s", "start": 0, "end": 14, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 4, "i_end": 4}}], "id": 4809}, {"sent": "deep neural networks have shown great success in computer vision and natural language processing tasks .", "tokens": ["deep", "neural", "networks", "have", "shown", "great", "success", "in", "computer", "vision", "and", "natural", "language", "processing", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 38, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "processing", "start": 86, "end": 96, "i_start": 13, "i_end": 13}}], "id": 4810}, {"sent": "all calculations are performed within a realm of density functional theory as implemented in the vienna ab initio simulation package .", "tokens": ["all", "calculations", "are", "performed", "within", "a", "realm", "of", "density", "functional", "theory", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all calculations", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "are performed", "start": 17, "end": 30, "i_start": 2, "i_end": 3}}], "id": 4811}, {"sent": "the optimiser we use is adam with an initial learning rate set to 5e-4 .", "tokens": ["the", "optimiser", "we", "use", "is", "adam", "with", "an", "initial", "learning", "rate", "set", "to", "5e-4", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the optimiser we use", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 17, "end": 20, "i_start": 3, "i_end": 3}}], "id": 4812}, {"sent": "in fact , the authors of have applied commutator theory to give a compactness characterization of hankel operators on holomorphic hardy spacesh 2 , where d is a bounded , strictly pseudoconvex domain in c n .", "tokens": ["in", "fact", ",", "the", "authors", "of", "have", "applied", "commutator", "theory", "to", "give", "a", "compactness", "characterization", "of", "hankel", "operators", "on", "holomorphic", "hardy", "spacesh", "2", ",", "where", "d", "is", "a", "bounded", ",", "strictly", "pseudoconvex", "domain", "in", "c", "n", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the authors of", "start": 10, "end": 24, "i_start": 3, "i_end": 5}, "verb": {"text": "have applied", "start": 25, "end": 37, "i_start": 6, "i_end": 7}}, {"character": {"text": "c n", "start": 203, "end": 206, "i_start": 34, "i_end": 35}, "action": {"text": "applied", "start": 30, "end": 37, "i_start": 7, "i_end": 7}}, {"character": {"text": "c n", "start": 203, "end": 206, "i_start": 34, "i_end": 35}, "action": {"text": "characterization", "start": 78, "end": 94, "i_start": 14, "i_end": 14}}], "id": 4813}, {"sent": "in a groundbreaking paper , hammons et al showed that certain non-linear codes which have more codewords than any linear code are images of linear codes over z 4 under the non-linear gray map .", "tokens": ["in", "a", "groundbreaking", "paper", ",", "hammons", "et", "al", "showed", "that", "certain", "non", "-", "linear", "codes", "which", "have", "more", "codewords", "than", "any", "linear", "code", "are", "images", "of", "linear", "codes", "over", "z", "4", "under", "the", "non", "-", "linear", "gray", "map", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hammons et al", "start": 28, "end": 41, "i_start": 5, "i_end": 7}, "verb": {"text": "showed", "start": 42, "end": 48, "i_start": 8, "i_end": 8}}, {"subject": {"text": "hammons et al", "start": 28, "end": 41, "i_start": 5, "i_end": 7}, "verb": {"text": "are", "start": 126, "end": 129, "i_start": 23, "i_end": 23}}, {"character": {"text": "hammons", "start": 28, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "showed", "start": 42, "end": 48, "i_start": 8, "i_end": 8}}, {"character": {"text": "code", "start": 121, "end": 125, "i_start": 22, "i_end": 22}, "action": {"text": "have", "start": 85, "end": 89, "i_start": 16, "i_end": 16}}], "id": 4814}, {"sent": "in , the authors showed that hybrid processing can realize any fully digital processing if the number of rf chains is twice the number of data streams .", "tokens": ["in", ",", "the", "authors", "showed", "that", "hybrid", "processing", "can", "realize", "any", "fully", "digital", "processing", "if", "the", "number", "of", "rf", "chains", "is", "twice", "the", "number", "of", "data", "streams", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 5, "end": 16, "i_start": 2, "i_end": 3}, "verb": {"text": "showed", "start": 17, "end": 23, "i_start": 4, "i_end": 4}}, {"subject": {"text": "hybrid processing", "start": 29, "end": 46, "i_start": 6, "i_end": 7}, "verb": {"text": "realize", "start": 51, "end": 58, "i_start": 9, "i_end": 9}}, {"character": {"text": "processing", "start": 36, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "realize", "start": 51, "end": 58, "i_start": 9, "i_end": 9}}], "id": 4815}, {"sent": "pathak et al developed a context encoder in an unsupervised learning algorithm for image inpainting .", "tokens": ["pathak", "et", "al", "developed", "a", "context", "encoder", "in", "an", "unsupervised", "learning", "algorithm", "for", "image", "inpainting", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "pathak et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "developed", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "pathak", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "developed", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}], "id": 4816}, {"sent": "polar codes are proposed by arikan as a type of error-correction coding method that provably achieves the capacity of symmetric binary-input discrete memoryless channels .", "tokens": ["polar", "codes", "are", "proposed", "by", "arikan", "as", "a", "type", "of", "error", "-", "correction", "coding", "method", "that", "provably", "achieves", "the", "capacity", "of", "symmetric", "binary", "-", "input", "discrete", "memoryless", "channels", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "polar codes", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "are proposed", "start": 12, "end": 24, "i_start": 2, "i_end": 3}}, {"character": {"text": "arikan", "start": 28, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "proposed", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "method", "start": 72, "end": 78, "i_start": 14, "i_end": 14}, "action": {"text": "correction", "start": 54, "end": 64, "i_start": 12, "i_end": 12}}, {"character": {"text": "method", "start": 72, "end": 78, "i_start": 14, "i_end": 14}, "action": {"text": "achieves", "start": 93, "end": 101, "i_start": 17, "i_end": 17}}], "id": 4817}, {"sent": "mishura , stochastic calculus for fractional brownian motion and related processes .", "tokens": ["mishura", ",", "stochastic", "calculus", "for", "fractional", "brownian", "motion", "and", "related", "processes", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4818}, {"sent": "convolutional neural networks have recently been applied to various computer vision tasks such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "been", "applied", "to", "various", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "been applied", "start": 44, "end": 56, "i_start": 5, "i_end": 6}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}], "id": 4819}, {"sent": "the word2vec is one of the most common methods for producing word embeddings .", "tokens": ["the", "word2vec", "is", "one", "of", "the", "most", "common", "methods", "for", "producing", "word", "embeddings", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the word2vec", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 4820}, {"sent": "jerrum and sinclair provided a fully-polynomial randomized approximation scheme for approximating permanents of nonnegative matrices .", "tokens": ["jerrum", "and", "sinclair", "provided", "a", "fully", "-", "polynomial", "randomized", "approximation", "scheme", "for", "approximating", "permanents", "of", "nonnegative", "matrices", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "jerrum and sinclair", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "provided", "start": 20, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "jerrum", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "provided", "start": 20, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "sinclair", "start": 11, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "provided", "start": 20, "end": 28, "i_start": 3, "i_end": 3}}], "id": 4821}, {"sent": "however , showed , using numerical experiments , that this statement is not true in general .", "tokens": ["however", ",", "showed", ",", "using", "numerical", "experiments", ",", "that", "this", "statement", "is", "not", "true", "in", "general", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4822}, {"sent": "unless otherwise stated , we follow the standard evaluation protocol by and ignore all words that contain alphanumeric characters and are not at least three characters long .", "tokens": ["unless", "otherwise", "stated", ",", "we", "follow", "the", "standard", "evaluation", "protocol", "by", "and", "ignore", "all", "words", "that", "contain", "alphanumeric", "characters", "and", "are", "not", "at", "least", "three", "characters", "long", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 26, "end": 28, "i_start": 4, "i_end": 4}, "verb": {"text": "follow", "start": 29, "end": 35, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 26, "end": 28, "i_start": 4, "i_end": 4}, "verb": {"text": "ignore", "start": 76, "end": 82, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 26, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "follow", "start": 29, "end": 35, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 26, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "ignore", "start": 76, "end": 82, "i_start": 12, "i_end": 12}}, {"character": {"text": "words", "start": 87, "end": 92, "i_start": 14, "i_end": 14}, "action": {"text": "contain", "start": 98, "end": 105, "i_start": 16, "i_end": 16}}], "id": 4823}, {"sent": "the dual matroid is also called the orthogonal matroid .", "tokens": ["the", "dual", "matroid", "is", "also", "called", "the", "orthogonal", "matroid", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dual matroid", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "called", "start": 25, "end": 31, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the dual matroid", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 4824}, {"sent": "in this section , we focus on the following theorem .", "tokens": ["in", "this", "section", ",", "we", "focus", "on", "the", "following", "theorem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "focus", "start": 21, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "focus", "start": 21, "end": 26, "i_start": 5, "i_end": 5}}], "id": 4825}, {"sent": "deep neural networks have recently achieved huge success in various machine learning tasks .", "tokens": ["deep", "neural", "networks", "have", "recently", "achieved", "huge", "success", "in", "various", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 49, "end": 56, "i_start": 7, "i_end": 7}}], "id": 4826}, {"sent": "saturation is the phenomenon of ground state factorization that occurs trivially when the value of the external field grows unboundedly compared to all other hamiltonian parameters .", "tokens": ["saturation", "is", "the", "phenomenon", "of", "ground", "state", "factorization", "that", "occurs", "trivially", "when", "the", "value", "of", "the", "external", "field", "grows", "unboundedly", "compared", "to", "all", "other", "hamiltonian", "parameters", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "saturation", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 1, "i_end": 1}}], "id": 4827}, {"sent": "some of these cold condensations allow to reconstruct the sky maps very accurately , in spite of the large amount of self-correlated noise present in the timelines .", "tokens": ["some", "of", "these", "cold", "condensations", "allow", "to", "reconstruct", "the", "sky", "maps", "very", "accurately", ",", "in", "spite", "of", "the", "large", "amount", "of", "self", "-", "correlated", "noise", "present", "in", "the", "timelines", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "some of these cold condensations", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "allow", "start": 33, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "some", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "allow", "start": 33, "end": 38, "i_start": 5, "i_end": 5}}], "id": 4828}, {"sent": "the exchangecorrelation effects were treated within generalized gradient approximation within the perdew-burke-ernzerhof functional .", "tokens": ["the", "exchangecorrelation", "effects", "were", "treated", "within", "generalized", "gradient", "approximation", "within", "the", "perdew", "-", "burke", "-", "ernzerhof", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchangecorrelation effects", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "were treated", "start": 32, "end": 44, "i_start": 3, "i_end": 4}}], "id": 4829}, {"sent": "convolutional neural networks have achieved superior performance in many visual tasks , such as object detection and segmentation .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "detection", "and", "segmentation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 6, "i_end": 6}}], "id": 4830}, {"sent": "the field fp consists of p elements and represents the simplest possible galois field .", "tokens": ["the", "field", "fp", "consists", "of", "p", "elements", "and", "represents", "the", "simplest", "possible", "galois", "field", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the field fp", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the field fp", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "represents", "start": 40, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "field", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "represents", "start": 40, "end": 50, "i_start": 8, "i_end": 8}}], "id": 4831}, {"sent": "although a photon is a spin-1 particle , it has only two spin degrees of freedom because it is massless .", "tokens": ["although", "a", "photon", "is", "a", "spin-1", "particle", ",", "it", "has", "only", "two", "spin", "degrees", "of", "freedom", "because", "it", "is", "massless", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 41, "end": 43, "i_start": 8, "i_end": 8}, "verb": {"text": "has", "start": 44, "end": 47, "i_start": 9, "i_end": 9}}, {"character": {"text": "massless", "start": 95, "end": 103, "i_start": 19, "i_end": 19}, "action": {"text": "because", "start": 81, "end": 88, "i_start": 16, "i_end": 16}}], "id": 4832}, {"sent": "we let s be the category of symmetric k-spectra with the stable model structure as defined in .", "tokens": ["we", "let", "s", "be", "the", "category", "of", "symmetric", "k", "-", "spectra", "with", "the", "stable", "model", "structure", "as", "defined", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "let", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "be", "start": 9, "end": 11, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "let", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 4833}, {"sent": "the one-dimensional spectra were extracted using standard iraf 15 routines .", "tokens": ["the", "one", "-", "dimensional", "spectra", "were", "extracted", "using", "standard", "iraf", "15", "routines", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the one-dimensional spectra", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "were extracted", "start": 28, "end": 42, "i_start": 5, "i_end": 6}}], "id": 4834}, {"sent": "we have computed an estimate of the rate of energy released by the magnetic field advected by each cme using two different methods .", "tokens": ["we", "have", "computed", "an", "estimate", "of", "the", "rate", "of", "energy", "released", "by", "the", "magnetic", "field", "advected", "by", "each", "cme", "using", "two", "different", "methods", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have computed", "start": 3, "end": 16, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "computed", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "field", "start": 76, "end": 81, "i_start": 14, "i_end": 14}, "action": {"text": "released", "start": 51, "end": 59, "i_start": 10, "i_end": 10}}], "id": 4835}, {"sent": "we will illustrate each of the situation by some examples .", "tokens": ["we", "will", "illustrate", "each", "of", "the", "situation", "by", "some", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will illustrate", "start": 3, "end": 18, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "illustrate", "start": 8, "end": 18, "i_start": 2, "i_end": 2}}], "id": 4836}, {"sent": "in recent years , deep neural networks have achieved great success in a variety of machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "achieved", "great", "success", "in", "a", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}], "id": 4837}, {"sent": "mackenzie , lie groupoids and lie algebroids in differential geometry , london math .", "tokens": ["mackenzie", ",", "lie", "groupoids", "and", "lie", "algebroids", "in", "differential", "geometry", ",", "london", "math", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4838}, {"sent": "once the features are extracted from each patch , we use the bag of words representation to describe each brain region , which calculates the histogram of representative patterns over all patches in this region .", "tokens": ["once", "the", "features", "are", "extracted", "from", "each", "patch", ",", "we", "use", "the", "bag", "of", "words", "representation", "to", "describe", "each", "brain", "region", ",", "which", "calculates", "the", "histogram", "of", "representative", "patterns", "over", "all", "patches", "in", "this", "region", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 50, "end": 52, "i_start": 9, "i_end": 9}, "verb": {"text": "use", "start": 53, "end": 56, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 50, "end": 52, "i_start": 9, "i_end": 9}, "action": {"text": "use", "start": 53, "end": 56, "i_start": 10, "i_end": 10}}, {"character": {"text": "bag", "start": 61, "end": 64, "i_start": 12, "i_end": 12}, "action": {"text": "representation", "start": 74, "end": 88, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 50, "end": 52, "i_start": 9, "i_end": 9}, "action": {"text": "describe", "start": 92, "end": 100, "i_start": 17, "i_end": 17}}, {"character": {"text": "region", "start": 112, "end": 118, "i_start": 20, "i_end": 20}, "action": {"text": "calculates", "start": 127, "end": 137, "i_start": 23, "i_end": 23}}, {"character": {"text": "patterns", "start": 170, "end": 178, "i_start": 28, "i_end": 28}, "action": {"text": "representative", "start": 155, "end": 169, "i_start": 27, "i_end": 27}}], "id": 4839}, {"sent": "significant improvements have been obtained in various computer vision tasks by applying deep learning techniques , including image classification .", "tokens": ["significant", "improvements", "have", "been", "obtained", "in", "various", "computer", "vision", "tasks", "by", "applying", "deep", "learning", "techniques", ",", "including", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "significant improvements", "start": 0, "end": 24, "i_start": 0, "i_end": 1}, "verb": {"text": "have been obtained", "start": 25, "end": 43, "i_start": 2, "i_end": 4}}], "id": 4840}, {"sent": "in this section , we prove the existence of universal perturbation data for which the moduli spaces of mushrooms are smooth manifolds .", "tokens": ["in", "this", "section", ",", "we", "prove", "the", "existence", "of", "universal", "perturbation", "data", "for", "which", "the", "moduli", "spaces", "of", "mushrooms", "are", "smooth", "manifolds", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "prove", "start": 21, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "prove", "start": 21, "end": 26, "i_start": 5, "i_end": 5}}], "id": 4841}, {"sent": "the optimal approach for reducing interference in manets is called interference alignment , which achieves the number of degrees of freedom equal to half of the number of interference links .", "tokens": ["the", "optimal", "approach", "for", "reducing", "interference", "in", "manets", "is", "called", "interference", "alignment", ",", "which", "achieves", "the", "number", "of", "degrees", "of", "freedom", "equal", "to", "half", "of", "the", "number", "of", "interference", "links", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the optimal approach for reducing interference in manets", "start": 0, "end": 56, "i_start": 0, "i_end": 7}, "verb": {"text": "is called", "start": 57, "end": 66, "i_start": 8, "i_end": 9}}, {"character": {"text": "alignment", "start": 80, "end": 89, "i_start": 11, "i_end": 11}, "action": {"text": "achieves", "start": 98, "end": 106, "i_start": 14, "i_end": 14}}, {"character": {"text": "links", "start": 184, "end": 189, "i_start": 29, "i_end": 29}, "action": {"text": "interference", "start": 67, "end": 79, "i_start": 10, "i_end": 10}}], "id": 4842}, {"sent": "most popular cryptosystems such as rsa are public-key cryptosystems .", "tokens": ["most", "popular", "cryptosystems", "such", "as", "rsa", "are", "public", "-", "key", "cryptosystems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "most popular cryptosystems such as rsa", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 39, "end": 42, "i_start": 6, "i_end": 6}}], "id": 4843}, {"sent": "the polytope 314353 is the vertex cut of the cube i 3 and hence rigid by theorem 6 point 4 .", "tokens": ["the", "polytope", "314353", "is", "the", "vertex", "cut", "of", "the", "cube", "i", "3", "and", "hence", "rigid", "by", "theorem", "6", "point", "4", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the polytope 314353", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 4844}, {"sent": "the hidden sector is the minimal requirement from the supertrace theorem and we need more severe 1 conditions to the susy breaking from the experiment .", "tokens": ["the", "hidden", "sector", "is", "the", "minimal", "requirement", "from", "the", "supertrace", "theorem", "and", "we", "need", "more", "severe", "1", "conditions", "to", "the", "susy", "breaking", "from", "the", "experiment", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the hidden sector", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 77, "end": 79, "i_start": 12, "i_end": 12}, "verb": {"text": "need", "start": 80, "end": 84, "i_start": 13, "i_end": 13}}, {"character": {"text": "theorem", "start": 65, "end": 72, "i_start": 10, "i_end": 10}, "action": {"text": "requirement", "start": 33, "end": 44, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 77, "end": 79, "i_start": 12, "i_end": 12}, "action": {"text": "need", "start": 80, "end": 84, "i_start": 13, "i_end": 13}}], "id": 4845}, {"sent": "both networks share the feature extraction layers which are based on vgg architecture .", "tokens": ["both", "networks", "share", "the", "feature", "extraction", "layers", "which", "are", "based", "on", "vgg", "architecture", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "both networks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "share", "start": 14, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "networks", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "share", "start": 14, "end": 19, "i_start": 2, "i_end": 2}}], "id": 4846}, {"sent": "the next two terms depend on the spectrum at zero frequency and the spectrum at twice the frequency being considered .", "tokens": ["the", "next", "two", "terms", "depend", "on", "the", "spectrum", "at", "zero", "frequency", "and", "the", "spectrum", "at", "twice", "the", "frequency", "being", "considered", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the next two terms", "start": 0, "end": 18, "i_start": 0, "i_end": 3}, "verb": {"text": "depend", "start": 19, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "two terms", "start": 9, "end": 18, "i_start": 2, "i_end": 3}, "action": {"text": "depend", "start": 19, "end": 25, "i_start": 4, "i_end": 4}}], "id": 4847}, {"sent": "the prototype example is that of d3-branes at a conifold singularity .", "tokens": ["the", "prototype", "example", "is", "that", "of", "d3", "-", "branes", "at", "a", "conifold", "singularity", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the prototype example is that of d3-branes", "start": 0, "end": 42, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 4848}, {"sent": "in section 6 , we look at the canonical coordinates of the 1st kind of .", "tokens": ["in", "section", "6", ",", "we", "look", "at", "the", "canonical", "coordinates", "of", "the", "1st", "kind", "of", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "look", "start": 18, "end": 22, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "look", "start": 18, "end": 22, "i_start": 5, "i_end": 5}}], "id": 4849}, {"sent": "we now illustrate this definition by the following examples .", "tokens": ["we", "now", "illustrate", "this", "definition", "by", "the", "following", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "illustrate", "start": 7, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "illustrate", "start": 7, "end": 17, "i_start": 2, "i_end": 2}}], "id": 4850}, {"sent": "in the authors compared the minimum size of advice required to solve two information dissemination problems , using a linear number of messages .", "tokens": ["in", "the", "authors", "compared", "the", "minimum", "size", "of", "advice", "required", "to", "solve", "two", "information", "dissemination", "problems", ",", "using", "a", "linear", "number", "of", "messages", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "solve", "start": 63, "end": 68, "i_start": 11, "i_end": 11}, "action": {"text": "required", "start": 51, "end": 59, "i_start": 9, "i_end": 9}}], "id": 4851}, {"sent": "furthermore , the riemannian sectional curvature of the wp metric is also negative .", "tokens": ["furthermore", ",", "the", "riemannian", "sectional", "curvature", "of", "the", "wp", "metric", "is", "also", "negative", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the riemannian sectional curvature of the wp metric", "start": 14, "end": 65, "i_start": 2, "i_end": 9}, "verb": {"text": "is", "start": 66, "end": 68, "i_start": 10, "i_end": 10}}], "id": 4852}, {"sent": "the videos are divided into validation set and test set , but only videos in the test set have spatial annotations provided by .", "tokens": ["the", "videos", "are", "divided", "into", "validation", "set", "and", "test", "set", ",", "but", "only", "videos", "in", "the", "test", "set", "have", "spatial", "annotations", "provided", "by", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the videos", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "are divided", "start": 11, "end": 22, "i_start": 2, "i_end": 3}}, {"subject": {"text": "only videos in the test set", "start": 62, "end": 89, "i_start": 12, "i_end": 17}, "verb": {"text": "have", "start": 90, "end": 94, "i_start": 18, "i_end": 18}}], "id": 4853}, {"sent": "a quantum computer is a computer , and as such it suffers from limited accuracy .", "tokens": ["a", "quantum", "computer", "is", "a", "computer", ",", "and", "as", "such", "it", "suffers", "from", "limited", "accuracy", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "a quantum computer", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 47, "end": 49, "i_start": 10, "i_end": 10}, "verb": {"text": "suffers", "start": 50, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "computer", "start": 24, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "suffers", "start": 50, "end": 57, "i_start": 11, "i_end": 11}}], "id": 4854}, {"sent": "multi-reference detection is the most popular framework for multi-scale object detection .", "tokens": ["multi", "-", "reference", "detection", "is", "the", "most", "popular", "framework", "for", "multi", "-", "scale", "object", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "multi-reference detection", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 4, "i_end": 4}}], "id": 4855}, {"sent": "although there are some upper bounds on a q and analysis of subspace packings in the topic was hardly considered in the literature so far .", "tokens": ["although", "there", "are", "some", "upper", "bounds", "on", "a", "q", "and", "analysis", "of", "subspace", "packings", "in", "the", "topic", "was", "hardly", "considered", "in", "the", "literature", "so", "far", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4856}, {"sent": "the structure of the vacuum is completely different from the massive case to the massless one in the thirring model .", "tokens": ["the", "structure", "of", "the", "vacuum", "is", "completely", "different", "from", "the", "massive", "case", "to", "the", "massless", "one", "in", "the", "thirring", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the structure of the vacuum", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 5, "i_end": 5}}], "id": 4857}, {"sent": "convolutional neural networks have recently exhibited great performance in various fields such as computer vision .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "exhibited", "great", "performance", "in", "various", "fields", "such", "as", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "exhibited", "start": 44, "end": 53, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "exhibited", "start": 44, "end": 53, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 60, "end": 71, "i_start": 7, "i_end": 7}}], "id": 4858}, {"sent": "novel schemes for measurement-based quantum computation .", "tokens": ["novel", "schemes", "for", "measurement", "-", "based", "quantum", "computation", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4859}, {"sent": "we use the resnet-101 architecture to add corresponding decoder layers so that the network can output full-resolution image .", "tokens": ["we", "use", "the", "resnet-101", "architecture", "to", "add", "corresponding", "decoder", "layers", "so", "that", "the", "network", "can", "output", "full", "-", "resolution", "image", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "add", "start": 38, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "layers", "start": 64, "end": 70, "i_start": 9, "i_end": 9}, "action": {"text": "decoder", "start": 56, "end": 63, "i_start": 8, "i_end": 8}}, {"character": {"text": "network", "start": 83, "end": 90, "i_start": 13, "i_end": 13}, "action": {"text": "output", "start": 95, "end": 101, "i_start": 15, "i_end": 15}}], "id": 4860}, {"sent": "we evaluate the performance of our proposed prpca method by comparing to the recent rpca methods on corrupted static camera videos .", "tokens": ["we", "evaluate", "the", "performance", "of", "our", "proposed", "prpca", "method", "by", "comparing", "to", "the", "recent", "rpca", "methods", "on", "corrupted", "static", "camera", "videos", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "method", "start": 50, "end": 56, "i_start": 8, "i_end": 8}, "action": {"text": "performance", "start": 16, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 35, "end": 43, "i_start": 6, "i_end": 6}}], "id": 4861}, {"sent": "the backstepping method has proved itself to be an ubiquitous method for pde control , with many other applications including , among others , flow control .", "tokens": ["the", "backstepping", "method", "has", "proved", "itself", "to", "be", "an", "ubiquitous", "method", "for", "pde", "control", ",", "with", "many", "other", "applications", "including", ",", "among", "others", ",", "flow", "control", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the backstepping method", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "has proved", "start": 24, "end": 34, "i_start": 3, "i_end": 4}}, {"subject": {"text": "the backstepping method", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "be", "start": 45, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "method", "start": 17, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "proved", "start": 28, "end": 34, "i_start": 4, "i_end": 4}}], "id": 4862}, {"sent": "scattering theory for automorphic functions .", "tokens": ["scattering", "theory", "for", "automorphic", "functions", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4863}, {"sent": "a sparse sampling algorithm for near-optimal planning in large markov decision processes .", "tokens": ["a", "sparse", "sampling", "algorithm", "for", "near", "-", "optimal", "planning", "in", "large", "markov", "decision", "processes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "algorithm", "start": 18, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "sampling", "start": 9, "end": 17, "i_start": 2, "i_end": 2}}], "id": 4864}, {"sent": "we use resnet-20 with cifar-10 as a base configuration to understand different properties of local sgd .", "tokens": ["we", "use", "resnet-20", "with", "cifar-10", "as", "a", "base", "configuration", "to", "understand", "different", "properties", "of", "local", "sgd", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "understand", "start": 58, "end": 68, "i_start": 10, "i_end": 10}}], "id": 4865}, {"sent": "recently , deep learning architectures have led to remarkable progress in problems like speech recognition and many others .", "tokens": ["recently", ",", "deep", "learning", "architectures", "have", "led", "to", "remarkable", "progress", "in", "problems", "like", "speech", "recognition", "and", "many", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning architectures", "start": 11, "end": 38, "i_start": 2, "i_end": 4}, "verb": {"text": "have led", "start": 39, "end": 47, "i_start": 5, "i_end": 6}}, {"character": {"text": "architectures", "start": 25, "end": 38, "i_start": 4, "i_end": 4}, "action": {"text": "led", "start": 44, "end": 47, "i_start": 6, "i_end": 6}}], "id": 4866}, {"sent": "this free energy consists of nearest neighbor repulsion energies of z-ions and the attraction energy of z-ions to the charge surface .", "tokens": ["this", "free", "energy", "consists", "of", "nearest", "neighbor", "repulsion", "energies", "of", "z", "-", "ions", "and", "the", "attraction", "energy", "of", "z", "-", "ions", "to", "the", "charge", "surface", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this free energy", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "energies", "start": 56, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "repulsion", "start": 46, "end": 55, "i_start": 7, "i_end": 7}}, {"character": {"text": "energy", "start": 94, "end": 100, "i_start": 16, "i_end": 16}, "action": {"text": "attraction", "start": 83, "end": 93, "i_start": 15, "i_end": 15}}], "id": 4867}, {"sent": "the higgs boson is the only elementary scalar field entering the sm .", "tokens": ["the", "higgs", "boson", "is", "the", "only", "elementary", "scalar", "field", "entering", "the", "sm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the higgs boson", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "field", "start": 46, "end": 51, "i_start": 8, "i_end": 8}, "action": {"text": "entering", "start": 52, "end": 60, "i_start": 9, "i_end": 9}}], "id": 4868}, {"sent": "a recent approach for computing complexity in continuous quantum many-body systems that exploited gaussian states to derive the timedependent complexity in the cft for a free scalar field theory , and this likewise led to similar results .", "tokens": ["a", "recent", "approach", "for", "computing", "complexity", "in", "continuous", "quantum", "many", "-", "body", "systems", "that", "exploited", "gaussian", "states", "to", "derive", "the", "timedependent", "complexity", "in", "the", "cft", "for", "a", "free", "scalar", "field", "theory", ",", "and", "this", "likewise", "led", "to", "similar", "results", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "approach", "start": 9, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "exploited", "start": 88, "end": 97, "i_start": 14, "i_end": 14}}, {"character": {"text": "computing", "start": 22, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "derive", "start": 117, "end": 123, "i_start": 18, "i_end": 18}}], "id": 4869}, {"sent": "the syntax of curry is close to haskell , only it is extended by allowing free variables in conditions and in right-hand sides of rules .", "tokens": ["the", "syntax", "of", "curry", "is", "close", "to", "haskell", ",", "only", "it", "is", "extended", "by", "allowing", "free", "variables", "in", "conditions", "and", "in", "right", "-", "hand", "sides", "of", "rules", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 47, "end": 49, "i_start": 10, "i_end": 10}, "verb": {"text": "is extended", "start": 50, "end": 61, "i_start": 11, "i_end": 12}}, {"subject": {"text": "it", "start": 47, "end": 49, "i_start": 10, "i_end": 10}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 4, "i_end": 4}}], "id": 4870}, {"sent": "mrk 291 mrk 291 is a sy2 galaxy , it has a bar and two spiral arms started at the end of the bar .", "tokens": ["mrk", "291", "mrk", "291", "is", "a", "sy2", "galaxy", ",", "it", "has", "a", "bar", "and", "two", "spiral", "arms", "started", "at", "the", "end", "of", "the", "bar", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "two spiral arms", "start": 51, "end": 66, "i_start": 14, "i_end": 16}, "verb": {"text": "has", "start": 37, "end": 40, "i_start": 10, "i_end": 10}}, {"subject": {"text": "it", "start": 34, "end": 36, "i_start": 9, "i_end": 9}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 4, "i_end": 4}}, {"subject": {"text": "it", "start": 34, "end": 36, "i_start": 9, "i_end": 9}, "verb": {"text": "started", "start": 67, "end": 74, "i_start": 17, "i_end": 17}}, {"character": {"text": "galaxy", "start": 25, "end": 31, "i_start": 7, "i_end": 7}, "action": {"text": "has", "start": 37, "end": 40, "i_start": 10, "i_end": 10}}], "id": 4871}, {"sent": "moreover , the synthesis results of were reported in 90 nm technology , but they were carried out in 65 nm technology .", "tokens": ["moreover", ",", "the", "synthesis", "results", "of", "were", "reported", "in", "90", "nm", "technology", ",", "but", "they", "were", "carried", "out", "in", "65", "nm", "technology", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the synthesis results of", "start": 11, "end": 35, "i_start": 2, "i_end": 5}, "verb": {"text": "were reported", "start": 36, "end": 49, "i_start": 6, "i_end": 7}}, {"subject": {"text": "they", "start": 76, "end": 80, "i_start": 14, "i_end": 14}, "verb": {"text": "carried", "start": 86, "end": 93, "i_start": 16, "i_end": 16}}], "id": 4872}, {"sent": "deep convolutional neural networks are useful in solving selected groups of computer vision problems , such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "are", "useful", "in", "solving", "selected", "groups", "of", "computer", "vision", "problems", ",", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 35, "end": 38, "i_start": 4, "i_end": 4}}], "id": 4873}, {"sent": "at the same time , the obtained energy-momentum tensor is .", "tokens": ["at", "the", "same", "time", ",", "the", "obtained", "energy", "-", "momentum", "tensor", "is", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the obtained energy-momentum tensor", "start": 19, "end": 54, "i_start": 5, "i_end": 10}, "verb": {"text": "is", "start": 55, "end": 57, "i_start": 11, "i_end": 11}}], "id": 4874}, {"sent": "the perdew , burke and ernzerhof parametrisation of the generalised gradient approximation was employed to describe the exchange correlation function .", "tokens": ["the", "perdew", ",", "burke", "and", "ernzerhof", "parametrisation", "of", "the", "generalised", "gradient", "approximation", "was", "employed", "to", "describe", "the", "exchange", "correlation", "function", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "the perdew", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "was employed", "start": 91, "end": 103, "i_start": 12, "i_end": 13}}, {"character": {"text": "parametrisation", "start": 33, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "describe", "start": 107, "end": 115, "i_start": 15, "i_end": 15}}, {"character": {"text": "perdew", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "describe", "start": 107, "end": 115, "i_start": 15, "i_end": 15}}, {"character": {"text": "burke", "start": 13, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "describe", "start": 107, "end": 115, "i_start": 15, "i_end": 15}}, {"character": {"text": "ernzerhof", "start": 23, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "describe", "start": 107, "end": 115, "i_start": 15, "i_end": 15}}, {"character": {"text": "generalised", "start": 56, "end": 67, "i_start": 9, "i_end": 9}, "action": {"text": "describe", "start": 107, "end": 115, "i_start": 15, "i_end": 15}}, {"character": {"text": "gradient", "start": 68, "end": 76, "i_start": 10, "i_end": 10}, "action": {"text": "describe", "start": 107, "end": 115, "i_start": 15, "i_end": 15}}], "id": 4875}, {"sent": "here the superscripts denote p2 and p4 eigenvalues .", "tokens": ["here", "the", "superscripts", "denote", "p2", "and", "p4", "eigenvalues", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "superscripts", "start": 9, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "denote", "start": 22, "end": 28, "i_start": 3, "i_end": 3}}], "id": 4876}, {"sent": "in extended networks , our upper bound is based on the characteristics of power-limited regimes shown in .", "tokens": ["in", "extended", "networks", ",", "our", "upper", "bound", "is", "based", "on", "the", "characteristics", "of", "power", "-", "limited", "regimes", "shown", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our upper bound", "start": 23, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "is based", "start": 39, "end": 47, "i_start": 7, "i_end": 8}}, {"character": {"text": "power", "start": 74, "end": 79, "i_start": 13, "i_end": 13}, "action": {"text": "limited", "start": 80, "end": 87, "i_start": 15, "i_end": 15}}], "id": 4877}, {"sent": "if the source position is closer to the caustic , then the images are located closer to the critical curve .", "tokens": ["if", "the", "source", "position", "is", "closer", "to", "the", "caustic", ",", "then", "the", "images", "are", "located", "closer", "to", "the", "critical", "curve", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the images", "start": 55, "end": 65, "i_start": 11, "i_end": 12}, "verb": {"text": "are located", "start": 66, "end": 77, "i_start": 13, "i_end": 14}}], "id": 4878}, {"sent": "recently , deep learning has been successfully adopted in various areas such as computer vision , automatic speech recognition , natural language processing , audio recognition and bioinformatics .", "tokens": ["recently", ",", "deep", "learning", "has", "been", "successfully", "adopted", "in", "various", "areas", "such", "as", "computer", "vision", ",", "automatic", "speech", "recognition", ",", "natural", "language", "processing", ",", "audio", "recognition", "and", "bioinformatics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 11, "end": 24, "i_start": 2, "i_end": 3}, "verb": {"text": "adopted", "start": 47, "end": 54, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep learning", "start": 11, "end": 24, "i_start": 2, "i_end": 3}, "verb": {"text": "has been", "start": 25, "end": 33, "i_start": 4, "i_end": 5}}], "id": 4879}, {"sent": "a computer-generated hologram is displayed on slm 1 to generate the desired field at the first diffraction order .", "tokens": ["a", "computer", "-", "generated", "hologram", "is", "displayed", "on", "slm", "1", "to", "generate", "the", "desired", "field", "at", "the", "first", "diffraction", "order", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a computer-generated hologram", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "is displayed", "start": 30, "end": 42, "i_start": 5, "i_end": 6}}, {"character": {"text": "computer", "start": 2, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "generated", "start": 11, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "hologram", "start": 21, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "generate", "start": 55, "end": 63, "i_start": 11, "i_end": 11}}], "id": 4880}, {"sent": "image features are prepared by extracting hidden representations at the final layer of resnet-101 .", "tokens": ["image", "features", "are", "prepared", "by", "extracting", "hidden", "representations", "at", "the", "final", "layer", "of", "resnet-101", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "image features", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are prepared", "start": 15, "end": 27, "i_start": 2, "i_end": 3}}], "id": 4881}, {"sent": "we used the function linearsvc from scikit-learn for training a one-vsall svm .", "tokens": ["we", "used", "the", "function", "linearsvc", "from", "scikit", "-", "learn", "for", "training", "a", "one", "-", "vsall", "svm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "training", "start": 53, "end": 61, "i_start": 10, "i_end": 10}}], "id": 4882}, {"sent": "the wide applications of the synchrotron radiation motivate the importance of investigations for various mechanisms of control of the radiation parameters .", "tokens": ["the", "wide", "applications", "of", "the", "synchrotron", "radiation", "motivate", "the", "importance", "of", "investigations", "for", "various", "mechanisms", "of", "control", "of", "the", "radiation", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the wide applications of the synchrotron radiation", "start": 0, "end": 50, "i_start": 0, "i_end": 6}, "verb": {"text": "motivate", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "applications", "start": 9, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "motivate", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "synchrotron", "start": 29, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "radiation", "start": 41, "end": 50, "i_start": 6, "i_end": 6}}], "id": 4883}, {"sent": "a monoid is a set with some extra structure .", "tokens": ["a", "monoid", "is", "a", "set", "with", "some", "extra", "structure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a monoid", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 2, "i_end": 2}}], "id": 4884}, {"sent": "all the molecular dynamics simulations were performed on the isothermal-isobaric ensemble , using the stochastic velocity rescaling thermostat at 300 k .", "tokens": ["all", "the", "molecular", "dynamics", "simulations", "were", "performed", "on", "the", "isothermal", "-", "isobaric", "ensemble", ",", "using", "the", "stochastic", "velocity", "rescaling", "thermostat", "at", "300", "k", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all the molecular dynamics simulations", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "were performed", "start": 39, "end": 53, "i_start": 5, "i_end": 6}}, {"character": {"text": "velocity", "start": 113, "end": 121, "i_start": 17, "i_end": 17}, "action": {"text": "rescaling", "start": 122, "end": 131, "i_start": 18, "i_end": 18}}], "id": 4885}, {"sent": "in this case \u03c6 is called an isomorphism of g onto h .", "tokens": ["in", "this", "case", "\u03c6", "is", "called", "an", "isomorphism", "of", "g", "onto", "h", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "\u03c6", "start": 13, "end": 14, "i_start": 3, "i_end": 3}, "verb": {"text": "is called", "start": 15, "end": 24, "i_start": 4, "i_end": 5}}], "id": 4886}, {"sent": "the reader is referred to the book by baier and katoen for further details .", "tokens": ["the", "reader", "is", "referred", "to", "the", "book", "by", "baier", "and", "katoen", "for", "further", "details", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the reader", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is referred", "start": 11, "end": 22, "i_start": 2, "i_end": 3}}, {"character": {"text": "baier", "start": 38, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "referred", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "katoen", "start": 48, "end": 54, "i_start": 10, "i_end": 10}, "action": {"text": "referred", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}], "id": 4887}, {"sent": "since silicon is a homopolar semiconductor that all atoms are neutral , the long range coulomb interaction is not necessary .", "tokens": ["since", "silicon", "is", "a", "homopolar", "semiconductor", "that", "all", "atoms", "are", "neutral", ",", "the", "long", "range", "coulomb", "interaction", "is", "not", "necessary", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the long range coulomb interaction", "start": 72, "end": 106, "i_start": 12, "i_end": 16}, "verb": {"text": "is not", "start": 107, "end": 113, "i_start": 17, "i_end": 18}}, {"character": {"text": "semiconductor", "start": 29, "end": 42, "i_start": 5, "i_end": 5}, "action": {"text": "neutral", "start": 62, "end": 69, "i_start": 10, "i_end": 10}}], "id": 4888}, {"sent": "despite the advantages , the iif approach is labour intensive and time consuming .", "tokens": ["despite", "the", "advantages", ",", "the", "iif", "approach", "is", "labour", "intensive", "and", "time", "consuming", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the iif approach", "start": 25, "end": 41, "i_start": 4, "i_end": 6}, "verb": {"text": "is", "start": 42, "end": 44, "i_start": 7, "i_end": 7}}, {"character": {"text": "approach", "start": 33, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "consuming", "start": 71, "end": 80, "i_start": 12, "i_end": 12}}], "id": 4889}, {"sent": "however , zhao et al introduced a pyramid pooling module to exploit global information from different subregions .", "tokens": ["however", ",", "zhao", "et", "al", "introduced", "a", "pyramid", "pooling", "module", "to", "exploit", "global", "information", "from", "different", "subregions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhao et al", "start": 10, "end": 20, "i_start": 2, "i_end": 4}, "verb": {"text": "introduced", "start": 21, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "zhao", "start": 10, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 21, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "zhao", "start": 10, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "exploit", "start": 60, "end": 67, "i_start": 11, "i_end": 11}}], "id": 4890}, {"sent": "she is currently working as assistant professor in the dept .", "tokens": ["she", "is", "currently", "working", "as", "assistant", "professor", "in", "the", "dept", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "she", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "working", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}, {"subject": {"text": "she", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 4, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "she", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "working", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}], "id": 4891}, {"sent": "specifically , it has been established that ssc is guaranteed to yield subspacepreserving solutions when subspaces are independent .", "tokens": ["specifically", ",", "it", "has", "been", "established", "that", "ssc", "is", "guaranteed", "to", "yield", "subspacepreserving", "solutions", "when", "subspaces", "are", "independent", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "has been established", "start": 18, "end": 38, "i_start": 3, "i_end": 5}}, {"subject": {"text": "ssc", "start": 44, "end": 47, "i_start": 7, "i_end": 7}, "verb": {"text": "guaranteed", "start": 51, "end": 61, "i_start": 9, "i_end": 9}}], "id": 4892}, {"sent": "the red and blue lines in the band structures represent nfe-ribbon and nfe-vaccum states , respectively .", "tokens": ["the", "red", "and", "blue", "lines", "in", "the", "band", "structures", "represent", "nfe", "-", "ribbon", "and", "nfe", "-", "vaccum", "states", ",", "respectively", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the red and blue lines in the band structures", "start": 0, "end": 45, "i_start": 0, "i_end": 8}, "verb": {"text": "represent", "start": 46, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "lines", "start": 17, "end": 22, "i_start": 4, "i_end": 4}, "action": {"text": "represent", "start": 46, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "structures", "start": 35, "end": 45, "i_start": 8, "i_end": 8}, "action": {"text": "represent", "start": 46, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "band", "start": 30, "end": 34, "i_start": 7, "i_end": 7}, "action": {"text": "represent", "start": 46, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "blue", "start": 12, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "represent", "start": 46, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "structures", "start": 35, "end": 45, "i_start": 8, "i_end": 8}, "action": {"text": "represent", "start": 46, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "band", "start": 30, "end": 34, "i_start": 7, "i_end": 7}, "action": {"text": "represent", "start": 46, "end": 55, "i_start": 9, "i_end": 9}}], "id": 4893}, {"sent": "the most well-known goodness measure is undoubtedly the restricted isometry constant .", "tokens": ["the", "most", "well", "-", "known", "goodness", "measure", "is", "undoubtedly", "the", "restricted", "isometry", "constant", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most well-known goodness measure", "start": 0, "end": 36, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 37, "end": 39, "i_start": 7, "i_end": 7}}], "id": 4894}, {"sent": "recently , deep learning provides a way to automatically learn discriminative features from raw data .", "tokens": ["recently", ",", "deep", "learning", "provides", "a", "way", "to", "automatically", "learn", "discriminative", "features", "from", "raw", "data", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 11, "end": 24, "i_start": 2, "i_end": 3}, "verb": {"text": "provides", "start": 25, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "learn", "start": 57, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "provides", "start": 25, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "features", "start": 78, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "discriminative", "start": 63, "end": 77, "i_start": 10, "i_end": 10}}], "id": 4895}, {"sent": "now we see that this v-duality can also be derived from that for om theory .", "tokens": ["now", "we", "see", "that", "this", "v", "-", "duality", "can", "also", "be", "derived", "from", "that", "for", "om", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "see", "start": 7, "end": 10, "i_start": 2, "i_end": 2}}, {"subject": {"text": "this v-duality", "start": 16, "end": 30, "i_start": 4, "i_end": 7}, "verb": {"text": "derived", "start": 43, "end": 50, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "see", "start": 7, "end": 10, "i_start": 2, "i_end": 2}}], "id": 4896}, {"sent": "in our implementation we utilized a variant of stochastic gradient descent , specifically we used the adam optimizer .", "tokens": ["in", "our", "implementation", "we", "utilized", "a", "variant", "of", "stochastic", "gradient", "descent", ",", "specifically", "we", "used", "the", "adam", "optimizer", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 90, "end": 92, "i_start": 13, "i_end": 13}, "verb": {"text": "used", "start": 93, "end": 97, "i_start": 14, "i_end": 14}}, {"subject": {"text": "we", "start": 22, "end": 24, "i_start": 3, "i_end": 3}, "verb": {"text": "utilized", "start": 25, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "utilized", "start": 25, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "implementation", "start": 7, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "used", "start": 93, "end": 97, "i_start": 14, "i_end": 14}}], "id": 4897}, {"sent": "hence , we may solved it , for example , via the interior-point method .", "tokens": ["hence", ",", "we", "may", "solved", "it", ",", "for", "example", ",", "via", "the", "interior", "-", "point", "method", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "may solved", "start": 11, "end": 21, "i_start": 3, "i_end": 4}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "solved", "start": 15, "end": 21, "i_start": 4, "i_end": 4}}], "id": 4898}, {"sent": "we will prove that these metrics are equivalent to those classical complete metrics .", "tokens": ["we", "will", "prove", "that", "these", "metrics", "are", "equivalent", "to", "those", "classical", "complete", "metrics", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will prove", "start": 3, "end": 13, "i_start": 1, "i_end": 2}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 33, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "prove", "start": 8, "end": 13, "i_start": 2, "i_end": 2}}], "id": 4899}, {"sent": "in the holographic dual wilson loops are described by string worldsheets that terminate on the boundary of the ads space .", "tokens": ["in", "the", "holographic", "dual", "wilson", "loops", "are", "described", "by", "string", "worldsheets", "that", "terminate", "on", "the", "boundary", "of", "the", "ads", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "worldsheets", "start": 61, "end": 72, "i_start": 10, "i_end": 10}, "action": {"text": "described", "start": 41, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "worldsheets", "start": 61, "end": 72, "i_start": 10, "i_end": 10}, "action": {"text": "terminate", "start": 78, "end": 87, "i_start": 12, "i_end": 12}}], "id": 4900}, {"sent": "new reconfigurable optical add-drop multiplexer based node architectures for cost-effectively supporting flexible sdn networks have been presented in .", "tokens": ["new", "reconfigurable", "optical", "add", "-", "drop", "multiplexer", "based", "node", "architectures", "for", "cost", "-", "effectively", "supporting", "flexible", "sdn", "networks", "have", "been", "presented", "in", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "new reconfigurable optical add-drop multiplexer based node architectures for cost-effectively supporting flexible sdn networks", "start": 0, "end": 126, "i_start": 0, "i_end": 17}, "verb": {"text": "have been presented", "start": 127, "end": 146, "i_start": 18, "i_end": 20}}, {"character": {"text": "architectures", "start": 59, "end": 72, "i_start": 9, "i_end": 9}, "action": {"text": "supporting", "start": 94, "end": 104, "i_start": 14, "i_end": 14}}, {"character": {"text": "cost", "start": 77, "end": 81, "i_start": 11, "i_end": 11}, "action": {"text": "effectively", "start": 82, "end": 93, "i_start": 13, "i_end": 13}}], "id": 4901}, {"sent": "in parentheses is the number of genes with n occurrences of ggctaag in the upstream region .", "tokens": ["in", "parentheses", "is", "the", "number", "of", "genes", "with", "n", "occurrences", "of", "ggctaag", "in", "the", "upstream", "region", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the number of genes with n occurrences of ggctaag in the upstream region", "start": 18, "end": 90, "i_start": 3, "i_end": 15}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 4902}, {"sent": "moreover , we have observed that the infrared monopoles are correlated mostly with the percolating cluster of p-vortices .", "tokens": ["moreover", ",", "we", "have", "observed", "that", "the", "infrared", "monopoles", "are", "correlated", "mostly", "with", "the", "percolating", "cluster", "of", "p", "-", "vortices", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "verb": {"text": "have observed", "start": 14, "end": 27, "i_start": 3, "i_end": 4}}, {"subject": {"text": "the infrared monopoles", "start": 33, "end": 55, "i_start": 6, "i_end": 8}, "verb": {"text": "correlated", "start": 60, "end": 70, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "observed", "start": 19, "end": 27, "i_start": 4, "i_end": 4}}], "id": 4903}, {"sent": "this is qualitatively different from the proto-magnetar model .", "tokens": ["this", "is", "qualitatively", "different", "from", "the", "proto", "-", "magnetar", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 4904}, {"sent": "deep convolutional neural networks have made great advances at numerous classification tasks in computer vision and speech applications over the past few years .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "great", "advances", "at", "numerous", "classification", "tasks", "in", "computer", "vision", "and", "speech", "applications", "over", "the", "past", "few", "years", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}], "id": 4905}, {"sent": "the expectation-maximization algorithm is commonly used for parameter estimation in model-based clustering .", "tokens": ["the", "expectation", "-", "maximization", "algorithm", "is", "commonly", "used", "for", "parameter", "estimation", "in", "model", "-", "based", "clustering", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the expectation-maximization algorithm", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "used", "start": 51, "end": 55, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the expectation-maximization algorithm", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 5, "i_end": 5}}], "id": 4906}, {"sent": "convolutional neural networks have recently been very successful on a variety of recognition and classification tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "been", "very", "successful", "on", "a", "variety", "of", "recognition", "and", "classification", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "been", "start": 44, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 54, "end": 64, "i_start": 7, "i_end": 7}}], "id": 4907}, {"sent": "blood flow in the coronary artery may be affected by multiple coronary artery stenoses and arterial plaques .", "tokens": ["blood", "flow", "in", "the", "coronary", "artery", "may", "be", "affected", "by", "multiple", "coronary", "artery", "stenoses", "and", "arterial", "plaques", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "blood flow in the coronary artery", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "may be affected", "start": 34, "end": 49, "i_start": 6, "i_end": 8}}, {"character": {"text": "stenoses", "start": 78, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "affected", "start": 41, "end": 49, "i_start": 8, "i_end": 8}}, {"character": {"text": "multiple", "start": 53, "end": 61, "i_start": 10, "i_end": 10}, "action": {"text": "affected", "start": 41, "end": 49, "i_start": 8, "i_end": 8}}, {"character": {"text": "artery", "start": 27, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "affected", "start": 41, "end": 49, "i_start": 8, "i_end": 8}}, {"character": {"text": "coronary", "start": 18, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "affected", "start": 41, "end": 49, "i_start": 8, "i_end": 8}}, {"character": {"text": "plaques", "start": 100, "end": 107, "i_start": 16, "i_end": 16}, "action": {"text": "affected", "start": 41, "end": 49, "i_start": 8, "i_end": 8}}, {"character": {"text": "artery", "start": 27, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "affected", "start": 41, "end": 49, "i_start": 8, "i_end": 8}}, {"character": {"text": "coronary", "start": 18, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "affected", "start": 41, "end": 49, "i_start": 8, "i_end": 8}}], "id": 4908}, {"sent": "assumption grammars for processing natural language .", "tokens": ["assumption", "grammars", "for", "processing", "natural", "language", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4909}, {"sent": "we use mini-batch stochastic gradient descent with adam algorithm to optimize the neural network .", "tokens": ["we", "use", "mini", "-", "batch", "stochastic", "gradient", "descent", "with", "adam", "algorithm", "to", "optimize", "the", "neural", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimize", "start": 69, "end": 77, "i_start": 12, "i_end": 12}}], "id": 4910}, {"sent": "we thus develop a modified max-flow algorithm based on edmonds-karp to sequentially find k paths and their maximum flow without excessive overheads .", "tokens": ["we", "thus", "develop", "a", "modified", "max", "-", "flow", "algorithm", "based", "on", "edmonds", "-", "karp", "to", "sequentially", "find", "k", "paths", "and", "their", "maximum", "flow", "without", "excessive", "overheads", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "develop", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "develop", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 84, "end": 88, "i_start": 16, "i_end": 16}}], "id": 4911}, {"sent": "fivechannel boxcar smoothing has been applied and baseline polynomial fits to the data are over-plotted .", "tokens": ["fivechannel", "boxcar", "smoothing", "has", "been", "applied", "and", "baseline", "polynomial", "fits", "to", "the", "data", "are", "over", "-", "plotted", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "fivechannel boxcar smoothing", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "has been applied", "start": 29, "end": 45, "i_start": 3, "i_end": 5}}, {"subject": {"text": "baseline polynomial", "start": 50, "end": 69, "i_start": 7, "i_end": 8}, "verb": {"text": "fits", "start": 70, "end": 74, "i_start": 9, "i_end": 9}}], "id": 4912}, {"sent": "the calibration and deconvolution of the data was carried out using the data analysis software package miriad .", "tokens": ["the", "calibration", "and", "deconvolution", "of", "the", "data", "was", "carried", "out", "using", "the", "data", "analysis", "software", "package", "miriad", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the calibration and deconvolution of the data", "start": 0, "end": 45, "i_start": 0, "i_end": 6}, "verb": {"text": "was carried out", "start": 46, "end": 61, "i_start": 7, "i_end": 9}}, {"character": {"text": "software", "start": 86, "end": 94, "i_start": 14, "i_end": 14}, "action": {"text": "analysis", "start": 77, "end": 85, "i_start": 13, "i_end": 13}}], "id": 4913}, {"sent": "this effect has been partly mentioned in real-world experiments in daamen and hoogendoorn , 2012 .", "tokens": ["this", "effect", "has", "been", "partly", "mentioned", "in", "real", "-", "world", "experiments", "in", "daamen", "and", "hoogendoorn", ",", "2012", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this effect", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "mentioned", "start": 28, "end": 37, "i_start": 5, "i_end": 5}}, {"subject": {"text": "this effect", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "has been", "start": 12, "end": 20, "i_start": 2, "i_end": 3}}], "id": 4914}, {"sent": "neural networks have enjoyed great success in many practical applications .", "tokens": ["neural", "networks", "have", "enjoyed", "great", "success", "in", "many", "practical", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have enjoyed", "start": 16, "end": 28, "i_start": 2, "i_end": 3}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "enjoyed", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "success", "start": 35, "end": 42, "i_start": 5, "i_end": 5}}], "id": 4915}, {"sent": "complex models such as deep neural networks have shown remarkable success in applications such as computer vision , speech and time series analysis .", "tokens": ["complex", "models", "such", "as", "deep", "neural", "networks", "have", "shown", "remarkable", "success", "in", "applications", "such", "as", "computer", "vision", ",", "speech", "and", "time", "series", "analysis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "complex models such as deep neural networks", "start": 0, "end": 43, "i_start": 0, "i_end": 6}, "verb": {"text": "have shown", "start": 44, "end": 54, "i_start": 7, "i_end": 8}}, {"character": {"text": "models", "start": 8, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "shown", "start": 49, "end": 54, "i_start": 8, "i_end": 8}}, {"character": {"text": "models", "start": 8, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "success", "start": 66, "end": 73, "i_start": 10, "i_end": 10}}], "id": 4916}, {"sent": "this class includes those with singly generated cohomology , and this case was classified in kapovitch and ziller .", "tokens": ["this", "class", "includes", "those", "with", "singly", "generated", "cohomology", ",", "and", "this", "case", "was", "classified", "in", "kapovitch", "and", "ziller", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this class", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "includes", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}, {"subject": {"text": "this case", "start": 65, "end": 74, "i_start": 10, "i_end": 11}, "verb": {"text": "classified", "start": 79, "end": 89, "i_start": 13, "i_end": 13}}], "id": 4917}, {"sent": "for recnet , we adopt the u-net architecture which has the same structure with flownet .", "tokens": ["for", "recnet", ",", "we", "adopt", "the", "u", "-", "net", "architecture", "which", "has", "the", "same", "structure", "with", "flownet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "adopt", "start": 16, "end": 21, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "adopt", "start": 16, "end": 21, "i_start": 4, "i_end": 4}}, {"character": {"text": "architecture", "start": 32, "end": 44, "i_start": 9, "i_end": 9}, "action": {"text": "has", "start": 51, "end": 54, "i_start": 11, "i_end": 11}}], "id": 4918}, {"sent": "the nucleus is the most prominent feature , this appears surrounded by diffraction rings and atmospheric speckles .", "tokens": ["the", "nucleus", "is", "the", "most", "prominent", "feature", ",", "this", "appears", "surrounded", "by", "diffraction", "rings", "and", "atmospheric", "speckles", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 44, "end": 48, "i_start": 8, "i_end": 8}, "verb": {"text": "appears", "start": 49, "end": 56, "i_start": 9, "i_end": 9}}, {"subject": {"text": "this", "start": 44, "end": 48, "i_start": 8, "i_end": 8}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 4919}, {"sent": "following their success in several computer vision tasks , neural networks have received considerable attention in the context of image processing .", "tokens": ["following", "their", "success", "in", "several", "computer", "vision", "tasks", ",", "neural", "networks", "have", "received", "considerable", "attention", "in", "the", "context", "of", "image", "processing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 59, "end": 74, "i_start": 9, "i_end": 10}, "verb": {"text": "have received", "start": 75, "end": 88, "i_start": 11, "i_end": 12}}, {"character": {"text": "networks", "start": 66, "end": 74, "i_start": 10, "i_end": 10}, "action": {"text": "success", "start": 16, "end": 23, "i_start": 2, "i_end": 2}}], "id": 4920}, {"sent": "all models were implemented using scikit-learn .", "tokens": ["all", "models", "were", "implemented", "using", "scikit", "-", "learn", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all models", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "were implemented", "start": 11, "end": 27, "i_start": 2, "i_end": 3}}], "id": 4921}, {"sent": "deep neural networks are used in many recent applications such as image recognition .", "tokens": ["deep", "neural", "networks", "are", "used", "in", "many", "recent", "applications", "such", "as", "image", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are used", "start": 21, "end": 29, "i_start": 3, "i_end": 4}}], "id": 4922}, {"sent": "gravity is a property of the geometry of a spacetime that is not merely a stage of all events , but also a participating actor .", "tokens": ["gravity", "is", "a", "property", "of", "the", "geometry", "of", "a", "spacetime", "that", "is", "not", "merely", "a", "stage", "of", "all", "events", ",", "but", "also", "a", "participating", "actor", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "gravity", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "geometry", "start": 29, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "stage", "start": 74, "end": 79, "i_start": 15, "i_end": 15}}], "id": 4923}, {"sent": "deep neural networks have achieved outstanding performances on many computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "achieved", "outstanding", "performances", "on", "many", "computer", "vision", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performances", "start": 47, "end": 59, "i_start": 6, "i_end": 6}}], "id": 4924}, {"sent": "in the upper band of model a , the power spectra are dominated by the adiabatic inflaton contribution .", "tokens": ["in", "the", "upper", "band", "of", "model", "a", ",", "the", "power", "spectra", "are", "dominated", "by", "the", "adiabatic", "inflaton", "contribution", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the power spectra", "start": 31, "end": 48, "i_start": 8, "i_end": 10}, "verb": {"text": "are dominated", "start": 49, "end": 62, "i_start": 11, "i_end": 12}}, {"character": {"text": "contribution", "start": 89, "end": 101, "i_start": 17, "i_end": 17}, "action": {"text": "dominated", "start": 53, "end": 62, "i_start": 12, "i_end": 12}}], "id": 4925}, {"sent": "in , lopez , sanz and sobottka introduced an extended concept of duality and gave general results about ergodicity .", "tokens": ["in", ",", "lopez", ",", "sanz", "and", "sobottka", "introduced", "an", "extended", "concept", "of", "duality", "and", "gave", "general", "results", "about", "ergodicity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "lopez", "start": 5, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "introduced", "start": 31, "end": 41, "i_start": 7, "i_end": 7}}, {"subject": {"text": "lopez", "start": 5, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "gave", "start": 77, "end": 81, "i_start": 14, "i_end": 14}}, {"character": {"text": "lopez", "start": 5, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 31, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "sanz", "start": 13, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "introduced", "start": 31, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "sobottka", "start": 22, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "introduced", "start": 31, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "lopez", "start": 5, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "gave", "start": 77, "end": 81, "i_start": 14, "i_end": 14}}, {"character": {"text": "sanz", "start": 13, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "gave", "start": 77, "end": 81, "i_start": 14, "i_end": 14}}, {"character": {"text": "sobottka", "start": 22, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "gave", "start": 77, "end": 81, "i_start": 14, "i_end": 14}}], "id": 4926}, {"sent": "we conclude from the perron-frobenius theorem that every primitive left-stochastic matrix a has a unique eigenvalue at one while all other eigenvalues are strictly less than one in magnitude .", "tokens": ["we", "conclude", "from", "the", "perron", "-", "frobenius", "theorem", "that", "every", "primitive", "left", "-", "stochastic", "matrix", "a", "has", "a", "unique", "eigenvalue", "at", "one", "while", "all", "other", "eigenvalues", "are", "strictly", "less", "than", "one", "in", "magnitude", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "conclude", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "conclude", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 4927}, {"sent": "deep convolutional neural networks have seen great success in a range of computer vision tasks , including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "seen", "great", "success", "in", "a", "range", "of", "computer", "vision", "tasks", ",", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have seen", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "seen", "start": 40, "end": 44, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 51, "end": 58, "i_start": 7, "i_end": 7}}], "id": 4928}, {"sent": "this field theory is known as noncommutative gauge theory .", "tokens": ["this", "field", "theory", "is", "known", "as", "noncommutative", "gauge", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this field theory", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is known", "start": 18, "end": 26, "i_start": 3, "i_end": 4}}], "id": 4929}, {"sent": "thus it can be emphasized that the electron transmission is strongly influenced by the moleculeto-electrode interface structure .", "tokens": ["thus", "it", "can", "be", "emphasized", "that", "the", "electron", "transmission", "is", "strongly", "influenced", "by", "the", "moleculeto", "-", "electrode", "interface", "structure", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "can be emphasized", "start": 8, "end": 25, "i_start": 2, "i_end": 4}}, {"subject": {"text": "the electron transmission", "start": 31, "end": 56, "i_start": 6, "i_end": 8}, "verb": {"text": "influenced", "start": 69, "end": 79, "i_start": 11, "i_end": 11}}, {"character": {"text": "structure", "start": 118, "end": 127, "i_start": 18, "i_end": 18}, "action": {"text": "influenced", "start": 69, "end": 79, "i_start": 11, "i_end": 11}}, {"character": {"text": "moleculeto", "start": 87, "end": 97, "i_start": 14, "i_end": 14}, "action": {"text": "interface", "start": 108, "end": 117, "i_start": 17, "i_end": 17}}], "id": 4930}, {"sent": "if f is a multiplicative system , the set of ideals of r containing some ideal of f is still a multiplicative system , which is called the saturation of f and is denoted by sat .", "tokens": ["if", "f", "is", "a", "multiplicative", "system", ",", "the", "set", "of", "ideals", "of", "r", "containing", "some", "ideal", "of", "f", "is", "still", "a", "multiplicative", "system", ",", "which", "is", "called", "the", "saturation", "of", "f", "and", "is", "denoted", "by", "sat", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the set of ideals of r containing some ideal of f", "start": 34, "end": 83, "i_start": 7, "i_end": 17}, "verb": {"text": "is", "start": 84, "end": 86, "i_start": 18, "i_end": 18}}, {"character": {"text": "ideals", "start": 45, "end": 51, "i_start": 10, "i_end": 10}, "action": {"text": "containing", "start": 57, "end": 67, "i_start": 13, "i_end": 13}}], "id": 4931}, {"sent": "on the other hand , the converse for the joint secrecy region follows using the standard techniques and procedures used in for less noisy channels .", "tokens": ["on", "the", "other", "hand", ",", "the", "converse", "for", "the", "joint", "secrecy", "region", "follows", "using", "the", "standard", "techniques", "and", "procedures", "used", "in", "for", "less", "noisy", "channels", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the converse for the joint secrecy region", "start": 20, "end": 61, "i_start": 5, "i_end": 11}, "verb": {"text": "follows", "start": 62, "end": 69, "i_start": 12, "i_end": 12}}, {"character": {"text": "region", "start": 55, "end": 61, "i_start": 11, "i_end": 11}, "action": {"text": "converse", "start": 24, "end": 32, "i_start": 6, "i_end": 6}}], "id": 4932}, {"sent": "to create this video dataset , we selected video scenes from movies chosen either by using movies selected by similar studies , or by choosing recent popular movies .", "tokens": ["to", "create", "this", "video", "dataset", ",", "we", "selected", "video", "scenes", "from", "movies", "chosen", "either", "by", "using", "movies", "selected", "by", "similar", "studies", ",", "or", "by", "choosing", "recent", "popular", "movies", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 31, "end": 33, "i_start": 6, "i_end": 6}, "verb": {"text": "selected", "start": 34, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 6, "i_end": 6}, "action": {"text": "selected", "start": 34, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 6, "i_end": 6}, "action": {"text": "using", "start": 85, "end": 90, "i_start": 15, "i_end": 15}}, {"character": {"text": "studies", "start": 118, "end": 125, "i_start": 20, "i_end": 20}, "action": {"text": "selected", "start": 98, "end": 106, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 6, "i_end": 6}, "action": {"text": "choosing", "start": 134, "end": 142, "i_start": 24, "i_end": 24}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 6, "i_end": 6}, "action": {"text": "create", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 4933}, {"sent": "deep learning models have accomplished superior performance in several machine learning problems , which use either visual or audio sources .", "tokens": ["deep", "learning", "models", "have", "accomplished", "superior", "performance", "in", "several", "machine", "learning", "problems", ",", "which", "use", "either", "visual", "or", "audio", "sources", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning models", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have accomplished", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "models", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "accomplished", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "models", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "models", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 48, "end": 59, "i_start": 6, "i_end": 6}}, {"character": {"text": "problems", "start": 88, "end": 96, "i_start": 11, "i_end": 11}, "action": {"text": "use", "start": 105, "end": 108, "i_start": 14, "i_end": 14}}], "id": 4934}, {"sent": "networks corresponding to realistic systems can be highly non-trivial , characterized by a low average distance combined with a high average clustering coefficient .", "tokens": ["networks", "corresponding", "to", "realistic", "systems", "can", "be", "highly", "non", "-", "trivial", ",", "characterized", "by", "a", "low", "average", "distance", "combined", "with", "a", "high", "average", "clustering", "coefficient", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "networks corresponding to realistic systems", "start": 0, "end": 43, "i_start": 0, "i_end": 4}, "verb": {"text": "can be", "start": 44, "end": 50, "i_start": 5, "i_end": 6}}], "id": 4935}, {"sent": "zhu et al propose a fully connected deep lstm network with regularization terms to learn co-occurrence features of joints .", "tokens": ["zhu", "et", "al", "propose", "a", "fully", "connected", "deep", "lstm", "network", "with", "regularization", "terms", "to", "learn", "co", "-", "occurrence", "features", "of", "joints", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhu et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 10, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhu", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 10, "end": 17, "i_start": 3, "i_end": 3}}], "id": 4936}, {"sent": "the em algorithm is the most popular approach for calculating the maximum likelihood estimator of latent variable models .", "tokens": ["the", "em", "algorithm", "is", "the", "most", "popular", "approach", "for", "calculating", "the", "maximum", "likelihood", "estimator", "of", "latent", "variable", "models", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the em algorithm", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithm", "start": 7, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "approach", "start": 37, "end": 45, "i_start": 7, "i_end": 7}}], "id": 4937}, {"sent": "a g -isomorphism class of open immersions is called an open rigid subspace of g .", "tokens": ["a", "g", "-isomorphism", "class", "of", "open", "immersions", "is", "called", "an", "open", "rigid", "subspace", "of", "g", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a g -isomorphism class of open immersions", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "is called", "start": 42, "end": 51, "i_start": 7, "i_end": 8}}], "id": 4938}, {"sent": "for the features-based system we used the gradientboostingclassifier from the scikit-learn library .", "tokens": ["for", "the", "features", "-", "based", "system", "we", "used", "the", "gradientboostingclassifier", "from", "the", "scikit", "-", "learn", "library", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 30, "end": 32, "i_start": 6, "i_end": 6}, "verb": {"text": "used", "start": 33, "end": 37, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 30, "end": 32, "i_start": 6, "i_end": 6}, "action": {"text": "used", "start": 33, "end": 37, "i_start": 7, "i_end": 7}}], "id": 4939}, {"sent": "deep learning or deep neural networks have achieved extraordinary performance in many application domains such as image classification .", "tokens": ["deep", "learning", "or", "deep", "neural", "networks", "have", "achieved", "extraordinary", "performance", "in", "many", "application", "domains", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning or deep neural networks", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "have achieved", "start": 38, "end": 51, "i_start": 6, "i_end": 7}}, {"character": {"text": "or", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}], "id": 4940}, {"sent": "for the rgb branch we use the convolutional layers of a pre-trained resnet-18 network .", "tokens": ["for", "the", "rgb", "branch", "we", "use", "the", "convolutional", "layers", "of", "a", "pre", "-", "trained", "resnet-18", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 22, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 22, "end": 25, "i_start": 5, "i_end": 5}}], "id": 4941}, {"sent": "a large soft proton flare occurred near the end of the rgs observation .", "tokens": ["a", "large", "soft", "proton", "flare", "occurred", "near", "the", "end", "of", "the", "rgs", "observation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a large soft proton flare", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "occurred", "start": 26, "end": 34, "i_start": 5, "i_end": 5}}], "id": 4942}, {"sent": "the group and matter content of the resulting models are obtained from the ade singularities of the k3 fibers and the non-trivial geometry describing the base space of the internal manifolds resepectively .", "tokens": ["the", "group", "and", "matter", "content", "of", "the", "resulting", "models", "are", "obtained", "from", "the", "ade", "singularities", "of", "the", "k3", "fibers", "and", "the", "non", "-", "trivial", "geometry", "describing", "the", "base", "space", "of", "the", "internal", "manifolds", "resepectively", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the group and matter content of the resulting models", "start": 0, "end": 52, "i_start": 0, "i_end": 8}, "verb": {"text": "are obtained", "start": 53, "end": 65, "i_start": 9, "i_end": 10}}, {"character": {"text": "models", "start": 46, "end": 52, "i_start": 8, "i_end": 8}, "action": {"text": "content", "start": 21, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "geometry", "start": 130, "end": 138, "i_start": 24, "i_end": 24}, "action": {"text": "describing", "start": 139, "end": 149, "i_start": 25, "i_end": 25}}], "id": 4943}, {"sent": "the analysis of mean field games in the lq setting has attracted substantial interest due to their appealing analytical structure .", "tokens": ["the", "analysis", "of", "mean", "field", "games", "in", "the", "lq", "setting", "has", "attracted", "substantial", "interest", "due", "to", "their", "appealing", "analytical", "structure", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the analysis of mean field games in the lq setting", "start": 0, "end": 50, "i_start": 0, "i_end": 9}, "verb": {"text": "has attracted", "start": 51, "end": 64, "i_start": 10, "i_end": 11}}, {"character": {"text": "analysis", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "attracted", "start": 55, "end": 64, "i_start": 11, "i_end": 11}}, {"character": {"text": "structure", "start": 120, "end": 129, "i_start": 19, "i_end": 19}, "action": {"text": "appealing", "start": 99, "end": 108, "i_start": 17, "i_end": 17}}], "id": 4944}, {"sent": "recently , deep neural networks have achieved remarkable progress in computer vision .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "achieved", "remarkable", "progress", "in", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have achieved", "start": 32, "end": 45, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}], "id": 4945}, {"sent": "deep convolutional neural networks have demonstrated significant improvements over traditional approaches in many pattern recognition tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "demonstrated", "significant", "improvements", "over", "traditional", "approaches", "in", "many", "pattern", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have demonstrated", "start": 35, "end": 52, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "demonstrated", "start": 40, "end": 52, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "improvements", "start": 65, "end": 77, "i_start": 7, "i_end": 7}}], "id": 4946}, {"sent": "such invariance is a key part of the york construction .", "tokens": ["such", "invariance", "is", "a", "key", "part", "of", "the", "york", "construction", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such invariance", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 4947}, {"sent": "convolutional neural networks provide state-of-the-art results for many machine learning challenges , such as image classification .", "tokens": ["convolutional", "neural", "networks", "provide", "state", "-", "of", "-", "the", "-", "art", "results", "for", "many", "machine", "learning", "challenges", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "provide", "start": 30, "end": 37, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "provide", "start": 30, "end": 37, "i_start": 3, "i_end": 3}}], "id": 4948}, {"sent": "we refer to for a detail discussion about hamiltonian vector fields on weakly symplectic spaces .", "tokens": ["we", "refer", "to", "for", "a", "detail", "discussion", "about", "hamiltonian", "vector", "fields", "on", "weakly", "symplectic", "spaces", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 4949}, {"sent": "since a collapse is a highly local effect , it is crucial that we allow for strong inhomogeneities during the simulation .", "tokens": ["since", "a", "collapse", "is", "a", "highly", "local", "effect", ",", "it", "is", "crucial", "that", "we", "allow", "for", "strong", "inhomogeneities", "during", "the", "simulation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 44, "end": 46, "i_start": 9, "i_end": 9}, "verb": {"text": "is", "start": 47, "end": 49, "i_start": 10, "i_end": 10}}, {"subject": {"text": "we", "start": 63, "end": 65, "i_start": 13, "i_end": 13}, "verb": {"text": "allow", "start": 66, "end": 71, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 63, "end": 65, "i_start": 13, "i_end": 13}, "action": {"text": "allow", "start": 66, "end": 71, "i_start": 14, "i_end": 14}}, {"character": {"text": "collapse", "start": 8, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "effect", "start": 35, "end": 41, "i_start": 7, "i_end": 7}}], "id": 4950}, {"sent": "here , we have used the average per-image peak signal-to-noise ratio and the structural similarity index .", "tokens": ["here", ",", "we", "have", "used", "the", "average", "per", "-", "image", "peak", "signal", "-", "to", "-", "noise", "ratio", "and", "the", "structural", "similarity", "index", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "have used", "start": 10, "end": 19, "i_start": 3, "i_end": 4}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "used", "start": 15, "end": 19, "i_start": 4, "i_end": 4}}], "id": 4951}, {"sent": "the ordinate is the corresponding characteristic angle .", "tokens": ["the", "ordinate", "is", "the", "corresponding", "characteristic", "angle", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ordinate", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 4952}, {"sent": "recently , convolutional neural networks have been proved to be capable of dramatically boosting the performance of many mainstream computer vision problems .", "tokens": ["recently", ",", "convolutional", "neural", "networks", "have", "been", "proved", "to", "be", "capable", "of", "dramatically", "boosting", "the", "performance", "of", "many", "mainstream", "computer", "vision", "problems", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 11, "end": 40, "i_start": 2, "i_end": 4}, "verb": {"text": "have been proved", "start": 41, "end": 57, "i_start": 5, "i_end": 7}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "boosting", "start": 88, "end": 96, "i_start": 13, "i_end": 13}}, {"character": {"text": "problems", "start": 148, "end": 156, "i_start": 21, "i_end": 21}, "action": {"text": "performance", "start": 101, "end": 112, "i_start": 15, "i_end": 15}}], "id": 4953}, {"sent": "to analyze the data and obtain the phase diagram , we use the bruce-wilding finite-size scaling techniques , to compile the phase diagram of this system .", "tokens": ["to", "analyze", "the", "data", "and", "obtain", "the", "phase", "diagram", ",", "we", "use", "the", "bruce", "-", "wilding", "finite", "-", "size", "scaling", "techniques", ",", "to", "compile", "the", "phase", "diagram", "of", "this", "system", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "verb": {"text": "use", "start": 54, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "use", "start": 54, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "compile", "start": 112, "end": 119, "i_start": 23, "i_end": 23}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "analyze", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "obtain", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}], "id": 4954}, {"sent": "elliptic curve cryptography has been proposed by miller in the mid 1980s .", "tokens": ["elliptic", "curve", "cryptography", "has", "been", "proposed", "by", "miller", "in", "the", "mid", "1980s", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "elliptic curve cryptography", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "has been proposed", "start": 28, "end": 45, "i_start": 3, "i_end": 5}}, {"character": {"text": "miller", "start": 49, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "proposed", "start": 37, "end": 45, "i_start": 5, "i_end": 5}}], "id": 4955}, {"sent": "the full distribution over the bb classes is not shown , but in each histogram bar the high-density bb cluster classes are in green .", "tokens": ["the", "full", "distribution", "over", "the", "bb", "classes", "is", "not", "shown", ",", "but", "in", "each", "histogram", "bar", "the", "high", "-", "density", "bb", "cluster", "classes", "are", "in", "green", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the full distribution over the bb classes", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "is not shown", "start": 42, "end": 54, "i_start": 7, "i_end": 9}}], "id": 4956}, {"sent": "batch normalization is used in the convolutional layers .", "tokens": ["batch", "normalization", "is", "used", "in", "the", "convolutional", "layers", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "batch normalization", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is used", "start": 20, "end": 27, "i_start": 2, "i_end": 3}}], "id": 4957}, {"sent": "the average abandonment probability ratio over periods .", "tokens": ["the", "average", "abandonment", "probability", "ratio", "over", "periods", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4958}, {"sent": "for non-radial solutions , duyckaerts , holmer , and roudenko proved the solutions in the above blow-up region blow up in finite time or grow up in infinite time .", "tokens": ["for", "non", "-", "radial", "solutions", ",", "duyckaerts", ",", "holmer", ",", "and", "roudenko", "proved", "the", "solutions", "in", "the", "above", "blow", "-", "up", "region", "blow", "up", "in", "finite", "time", "or", "grow", "up", "in", "infinite", "time", "."], "score": [1, 0, 1, 1, 0], "labels": [{"subject": {"text": "the solutions in the above blow-up region", "start": 69, "end": 110, "i_start": 13, "i_end": 21}, "verb": {"text": "proved", "start": 62, "end": 68, "i_start": 12, "i_end": 12}}, {"subject": {"text": "the solutions in the above blow-up region", "start": 69, "end": 110, "i_start": 13, "i_end": 21}, "verb": {"text": "blow", "start": 111, "end": 115, "i_start": 22, "i_end": 22}}, {"character": {"text": "duyckaerts", "start": 27, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "proved", "start": 62, "end": 68, "i_start": 12, "i_end": 12}}, {"character": {"text": "holmer", "start": 40, "end": 46, "i_start": 8, "i_end": 8}, "action": {"text": "proved", "start": 62, "end": 68, "i_start": 12, "i_end": 12}}, {"character": {"text": "roudenko", "start": 53, "end": 61, "i_start": 11, "i_end": 11}, "action": {"text": "proved", "start": 62, "end": 68, "i_start": 12, "i_end": 12}}], "id": 4959}, {"sent": "here , in obtaining the analytic expressions for potentials we also take the measure of expanding the corresponding functions in parameter \u03bb and keeping only the leading term .", "tokens": ["here", ",", "in", "obtaining", "the", "analytic", "expressions", "for", "potentials", "we", "also", "take", "the", "measure", "of", "expanding", "the", "corresponding", "functions", "in", "parameter", "\u03bb", "and", "keeping", "only", "the", "leading", "term", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 60, "end": 62, "i_start": 9, "i_end": 9}, "verb": {"text": "take", "start": 68, "end": 72, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 60, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "measure", "start": 77, "end": 84, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 60, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "expanding", "start": 88, "end": 97, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 60, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "keeping", "start": 145, "end": 152, "i_start": 23, "i_end": 23}}, {"character": {"text": "term", "start": 170, "end": 174, "i_start": 27, "i_end": 27}, "action": {"text": "leading", "start": 162, "end": 169, "i_start": 26, "i_end": 26}}, {"character": {"text": "we", "start": 60, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "obtaining", "start": 10, "end": 19, "i_start": 3, "i_end": 3}}], "id": 4960}, {"sent": "the convolutional neural network based approaches have been widely applied in object detection and recognition with promising performance .", "tokens": ["the", "convolutional", "neural", "network", "based", "approaches", "have", "been", "widely", "applied", "in", "object", "detection", "and", "recognition", "with", "promising", "performance", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the convolutional neural network based approaches", "start": 0, "end": 49, "i_start": 0, "i_end": 5}, "verb": {"text": "applied", "start": 67, "end": 74, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the convolutional neural network based approaches", "start": 0, "end": 49, "i_start": 0, "i_end": 5}, "verb": {"text": "have been", "start": 50, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "approaches", "start": 39, "end": 49, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 126, "end": 137, "i_start": 17, "i_end": 17}}, {"character": {"text": "performance", "start": 126, "end": 137, "i_start": 17, "i_end": 17}, "action": {"text": "promising", "start": 116, "end": 125, "i_start": 16, "i_end": 16}}], "id": 4961}, {"sent": "deep learning or deep neural networks have achieved extraordinary performance in many application domains such as image classification .", "tokens": ["deep", "learning", "or", "deep", "neural", "networks", "have", "achieved", "extraordinary", "performance", "in", "many", "application", "domains", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning or deep neural networks", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "have achieved", "start": 38, "end": 51, "i_start": 6, "i_end": 7}}, {"character": {"text": "or", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}], "id": 4962}, {"sent": "convolutional neural networks have recently provided state of the art results for several recognition tasks including object recognition .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "provided", "state", "of", "the", "art", "results", "for", "several", "recognition", "tasks", "including", "object", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "provided", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "provided", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}], "id": 4963}, {"sent": "the superpotential is a function of v , so one should check that the obstruction does not vanish because of special properties of the dilaton superfield .", "tokens": ["the", "superpotential", "is", "a", "function", "of", "v", ",", "so", "one", "should", "check", "that", "the", "obstruction", "does", "not", "vanish", "because", "of", "special", "properties", "of", "the", "dilaton", "superfield", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the superpotential", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}, {"subject": {"text": "one", "start": 43, "end": 46, "i_start": 9, "i_end": 9}, "verb": {"text": "check", "start": 54, "end": 59, "i_start": 11, "i_end": 11}}, {"character": {"text": "function", "start": 24, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "because", "start": 97, "end": 104, "i_start": 18, "i_end": 18}}, {"character": {"text": "one", "start": 43, "end": 46, "i_start": 9, "i_end": 9}, "action": {"text": "check", "start": 54, "end": 59, "i_start": 11, "i_end": 11}}], "id": 4964}, {"sent": "analycity breaking and anderson localization in incom mensurate lattices .", "tokens": ["analycity", "breaking", "and", "anderson", "localization", "in", "incom", "mensurate", "lattices", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4965}, {"sent": "however , since the results are very close to the ones given in as well as those obtained through the mechanism presented in the above theorem .", "tokens": ["however", ",", "since", "the", "results", "are", "very", "close", "to", "the", "ones", "given", "in", "as", "well", "as", "those", "obtained", "through", "the", "mechanism", "presented", "in", "the", "above", "theorem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the results", "start": 16, "end": 27, "i_start": 3, "i_end": 4}, "verb": {"text": "are", "start": 28, "end": 31, "i_start": 5, "i_end": 5}}], "id": 4966}, {"sent": "convolutional neural networks have achieved great success in many fields , such as object classification , face recognition .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "many", "fields", ",", "such", "as", "object", "classification", ",", "face", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "face", "start": 107, "end": 111, "i_start": 16, "i_end": 16}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}], "id": 4967}, {"sent": "approximate sr have been introduced in the control community as a generalization of sr in order to enlarge the class of systems which admit discrete abstractions .", "tokens": ["approximate", "sr", "have", "been", "introduced", "in", "the", "control", "community", "as", "a", "generalization", "of", "sr", "in", "order", "to", "enlarge", "the", "class", "of", "systems", "which", "admit", "discrete", "abstractions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "approximate sr", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "have been introduced", "start": 15, "end": 35, "i_start": 2, "i_end": 4}}, {"character": {"text": "community", "start": 51, "end": 60, "i_start": 8, "i_end": 8}, "action": {"text": "control", "start": 43, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "systems", "start": 120, "end": 127, "i_start": 21, "i_end": 21}, "action": {"text": "admit", "start": 134, "end": 139, "i_start": 23, "i_end": 23}}], "id": 4968}, {"sent": "batch normalization is added after each convolution layer to accelerate convergence .", "tokens": ["batch", "normalization", "is", "added", "after", "each", "convolution", "layer", "to", "accelerate", "convergence", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "batch normalization", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is added", "start": 20, "end": 28, "i_start": 2, "i_end": 3}}, {"character": {"text": "normalization", "start": 6, "end": 19, "i_start": 1, "i_end": 1}, "action": {"text": "accelerate", "start": 61, "end": 71, "i_start": 9, "i_end": 9}}], "id": 4969}, {"sent": "we leverage object detection module with pretrained resnet-101 to produce the region-level representation .", "tokens": ["we", "leverage", "object", "detection", "module", "with", "pretrained", "resnet-101", "to", "produce", "the", "region", "-", "level", "representation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "leverage", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "leverage", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "module", "start": 29, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "detection", "start": 19, "end": 28, "i_start": 3, "i_end": 3}}], "id": 4970}, {"sent": "the purpose of this paper is to investigate if the results regarding the equivalence between ymcs theory and non-abelian sd model can be extended to the nc case .", "tokens": ["the", "purpose", "of", "this", "paper", "is", "to", "investigate", "if", "the", "results", "regarding", "the", "equivalence", "between", "ymcs", "theory", "and", "non", "-", "abelian", "sd", "model", "can", "be", "extended", "to", "the", "nc", "case", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the purpose of this paper", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "paper", "start": 20, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "investigate", "start": 32, "end": 43, "i_start": 7, "i_end": 7}}], "id": 4971}, {"sent": "the von neumann entropy and this is the maximal value of e .", "tokens": ["the", "von", "neumann", "entropy", "and", "this", "is", "the", "maximal", "value", "of", "e", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4972}, {"sent": "deep learning approaches have exhibited impressive performance in medical imaging applications in recent years .", "tokens": ["deep", "learning", "approaches", "have", "exhibited", "impressive", "performance", "in", "medical", "imaging", "applications", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning approaches", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "have exhibited", "start": 25, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "approaches", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "exhibited", "start": 30, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "approaches", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 51, "end": 62, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 51, "end": 62, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 40, "end": 50, "i_start": 5, "i_end": 5}}], "id": 4973}, {"sent": "reinforcement learning is the problem of learning from interaction with the environment to achieve a goal .", "tokens": ["reinforcement", "learning", "is", "the", "problem", "of", "learning", "from", "interaction", "with", "the", "environment", "to", "achieve", "a", "goal", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 2, "i_end": 2}}], "id": 4974}, {"sent": "to perform object detection , we consider the state of the art faster r-cnn method .", "tokens": ["to", "perform", "object", "detection", ",", "we", "consider", "the", "state", "of", "the", "art", "faster", "r", "-", "cnn", "method", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "verb": {"text": "consider", "start": 33, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "consider", "start": 33, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "perform", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 4975}, {"sent": "we used adam optimizer to minimize the mse using stochastic gradient descent .", "tokens": ["we", "used", "adam", "optimizer", "to", "minimize", "the", "mse", "using", "stochastic", "gradient", "descent", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "minimize", "start": 26, "end": 34, "i_start": 5, "i_end": 5}}], "id": 4976}, {"sent": "iii , we perform constraints on the holographic ricci dark energy model by using the up-to-date observational data sets .", "tokens": ["iii", ",", "we", "perform", "constraints", "on", "the", "holographic", "ricci", "dark", "energy", "model", "by", "using", "the", "up", "-", "to", "-", "date", "observational", "data", "sets", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "verb": {"text": "perform", "start": 9, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "iii , we perform constraints", "start": 0, "end": 28, "i_start": 0, "i_end": 4}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "using", "start": 75, "end": 80, "i_start": 13, "i_end": 13}}], "id": 4977}, {"sent": "chen et al proposed an attention mechanism that learns to weight the multi-scale features at each pixel location .", "tokens": ["chen", "et", "al", "proposed", "an", "attention", "mechanism", "that", "learns", "to", "weight", "the", "multi", "-", "scale", "features", "at", "each", "pixel", "location", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "chen et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "chen", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "mechanism", "start": 33, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "attention", "start": 23, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "mechanism", "start": 33, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "learns", "start": 48, "end": 54, "i_start": 8, "i_end": 8}}, {"character": {"text": "mechanism", "start": 33, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "weight", "start": 58, "end": 64, "i_start": 10, "i_end": 10}}], "id": 4978}, {"sent": "virtual links are in one-to-one correspondence to abstract links on oriented surfaces .", "tokens": ["virtual", "links", "are", "in", "one", "-", "to", "-", "one", "correspondence", "to", "abstract", "links", "on", "oriented", "surfaces", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "virtual links", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 14, "end": 17, "i_start": 2, "i_end": 2}}], "id": 4979}, {"sent": "for the convolutional layers , we use the vgg16 model pre-trained on imagenet data .", "tokens": ["for", "the", "convolutional", "layers", ",", "we", "use", "the", "vgg16", "model", "pre", "-", "trained", "on", "imagenet", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}], "id": 4980}, {"sent": "construction of the minimal representation proof .", "tokens": ["construction", "of", "the", "minimal", "representation", "proof", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4981}, {"sent": "dispersion of recovered properties of artificial clusters , comparing various wide and medium-band hst filters , as indicated in the legend .", "tokens": ["dispersion", "of", "recovered", "properties", "of", "artificial", "clusters", ",", "comparing", "various", "wide", "and", "medium", "-", "band", "hst", "filters", ",", "as", "indicated", "in", "the", "legend", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "legend", "start": 133, "end": 139, "i_start": 22, "i_end": 22}, "action": {"text": "indicated", "start": 116, "end": 125, "i_start": 19, "i_end": 19}}], "id": 4982}, {"sent": "machine learning methods , such as convolutional neural networks , have been used in many classification , detection and recognition tasks .", "tokens": ["machine", "learning", "methods", ",", "such", "as", "convolutional", "neural", "networks", ",", "have", "been", "used", "in", "many", "classification", ",", "detection", "and", "recognition", "tasks", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "machine learning methods", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "have been used", "start": 67, "end": 81, "i_start": 10, "i_end": 12}}], "id": 4983}, {"sent": "deep convolutional neural networks have made great advances at numerous classification tasks in computer vision and speech applications over the past few years .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "great", "advances", "at", "numerous", "classification", "tasks", "in", "computer", "vision", "and", "speech", "applications", "over", "the", "past", "few", "years", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}], "id": 4984}, {"sent": "in 1981 , guth introduced an inflationary phase to explain the horizon , flatness , and monopole problems .", "tokens": ["in", "1981", ",", "guth", "introduced", "an", "inflationary", "phase", "to", "explain", "the", "horizon", ",", "flatness", ",", "and", "monopole", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "guth", "start": 10, "end": 14, "i_start": 3, "i_end": 3}, "verb": {"text": "introduced", "start": 15, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "guth", "start": 10, "end": 14, "i_start": 3, "i_end": 3}, "action": {"text": "introduced", "start": 15, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "guth", "start": 10, "end": 14, "i_start": 3, "i_end": 3}, "action": {"text": "explain", "start": 51, "end": 58, "i_start": 9, "i_end": 9}}], "id": 4985}, {"sent": "real networks are extremely inhomogeneous , and often display certain characteristic features , such as a power-law decay in the tail of the degree distribution .", "tokens": ["real", "networks", "are", "extremely", "inhomogeneous", ",", "and", "often", "display", "certain", "characteristic", "features", ",", "such", "as", "a", "power", "-", "law", "decay", "in", "the", "tail", "of", "the", "degree", "distribution", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "real networks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 14, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "real networks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "display", "start": 54, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "display", "start": 54, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "law", "start": 112, "end": 115, "i_start": 18, "i_end": 18}, "action": {"text": "decay", "start": 116, "end": 121, "i_start": 19, "i_end": 19}}], "id": 4986}, {"sent": "like the matrix case , copositive tensors also have wide applications , eg , in complementary problems .", "tokens": ["like", "the", "matrix", "case", ",", "copositive", "tensors", "also", "have", "wide", "applications", ",", "eg", ",", "in", "complementary", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "copositive tensors", "start": 23, "end": 41, "i_start": 5, "i_end": 6}, "verb": {"text": "have", "start": 47, "end": 51, "i_start": 8, "i_end": 8}}], "id": 4987}, {"sent": "explicit hilbert spaces for certain unipotent represen tations .", "tokens": ["explicit", "hilbert", "spaces", "for", "certain", "unipotent", "represen", "tations", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4988}, {"sent": "from this point of view , gr is no more and no less than the unique lorentz covariant theory of an interacting massless spin-2 particle .", "tokens": ["from", "this", "point", "of", "view", ",", "gr", "is", "no", "more", "and", "no", "less", "than", "the", "unique", "lorentz", "covariant", "theory", "of", "an", "interacting", "massless", "spin-2", "particle", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "gr", "start": 26, "end": 28, "i_start": 6, "i_end": 6}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 7, "i_end": 7}}, {"character": {"text": "particle", "start": 127, "end": 135, "i_start": 24, "i_end": 24}, "action": {"text": "interacting", "start": 99, "end": 110, "i_start": 21, "i_end": 21}}], "id": 4989}, {"sent": "the algebra of such operators is known as the algebra of local observables .", "tokens": ["the", "algebra", "of", "such", "operators", "is", "known", "as", "the", "algebra", "of", "local", "observables", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the algebra of such operators", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "is known", "start": 30, "end": 38, "i_start": 5, "i_end": 6}}], "id": 4990}, {"sent": "in , the authors show that , at high snr , the feedback rate required per user must grow linearly with the snr in order to obtain the full mimo bc multiplexing gain .", "tokens": ["in", ",", "the", "authors", "show", "that", ",", "at", "high", "snr", ",", "the", "feedback", "rate", "required", "per", "user", "must", "grow", "linearly", "with", "the", "snr", "in", "order", "to", "obtain", "the", "full", "mimo", "bc", "multiplexing", "gain", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 5, "end": 16, "i_start": 2, "i_end": 3}, "verb": {"text": "show", "start": 17, "end": 21, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the feedback rate required per user", "start": 43, "end": 78, "i_start": 11, "i_end": 16}, "verb": {"text": "grow", "start": 84, "end": 88, "i_start": 18, "i_end": 18}}], "id": 4991}, {"sent": "merlin is a national facility operated by the university of manchester on behalf of pparc in the uk .", "tokens": ["merlin", "is", "a", "national", "facility", "operated", "by", "the", "university", "of", "manchester", "on", "behalf", "of", "pparc", "in", "the", "uk", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "merlin", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 7, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "university", "start": 46, "end": 56, "i_start": 8, "i_end": 8}, "action": {"text": "operated", "start": 30, "end": 38, "i_start": 5, "i_end": 5}}], "id": 4992}, {"sent": "in the present study , the generalized gradient approximation is used for the exchange and correlation energy functionals with the perdew-burke-ernzerhof functional .", "tokens": ["in", "the", "present", "study", ",", "the", "generalized", "gradient", "approximation", "is", "used", "for", "the", "exchange", "and", "correlation", "energy", "functionals", "with", "the", "perdew", "-", "burke", "-", "ernzerhof", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation", "start": 23, "end": 61, "i_start": 5, "i_end": 8}, "verb": {"text": "is used", "start": 62, "end": 69, "i_start": 9, "i_end": 10}}], "id": 4993}, {"sent": "since string theory is the only consistent theory of quantum gravity we should look for such an explanation in string theory .", "tokens": ["since", "string", "theory", "is", "the", "only", "consistent", "theory", "of", "quantum", "gravity", "we", "should", "look", "for", "such", "an", "explanation", "in", "string", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "string theory", "start": 6, "end": 19, "i_start": 1, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 4994}, {"sent": "the notion of a stability condition on a triangulated category was introduced by bridgeland to formalize ideas about d-branes in topological string theory .", "tokens": ["the", "notion", "of", "a", "stability", "condition", "on", "a", "triangulated", "category", "was", "introduced", "by", "bridgeland", "to", "formalize", "ideas", "about", "d", "-", "branes", "in", "topological", "string", "theory", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "the notion of a stability condition on a triangulated category", "start": 0, "end": 62, "i_start": 0, "i_end": 9}, "verb": {"text": "was introduced", "start": 63, "end": 77, "i_start": 10, "i_end": 11}}, {"character": {"text": "bridgeland", "start": 81, "end": 91, "i_start": 13, "i_end": 13}, "action": {"text": "introduced", "start": 67, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "bridgeland", "start": 81, "end": 91, "i_start": 13, "i_end": 13}, "action": {"text": "formalize", "start": 95, "end": 104, "i_start": 15, "i_end": 15}}], "id": 4995}, {"sent": "since the free energy is a contunuous function 9 6 and is bounded from below , there exists a minimum at q equivalently m2 8 is negative .", "tokens": ["since", "the", "free", "energy", "is", "a", "contunuous", "function", "9", "6", "and", "is", "bounded", "from", "below", ",", "there", "exists", "a", "minimum", "at", "q", "equivalently", "m2", "8", "is", "negative", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "equivalently m2 8", "start": 107, "end": 124, "i_start": 22, "i_end": 24}, "verb": {"text": "is", "start": 125, "end": 127, "i_start": 25, "i_end": 25}}, {"subject": {"text": "there", "start": 79, "end": 84, "i_start": 16, "i_end": 16}, "verb": {"text": "exists", "start": 85, "end": 91, "i_start": 17, "i_end": 17}}], "id": 4996}, {"sent": "the groundbreaking observations of binary black hole collisions by advanced ligo have ushered in a new era of gravitational wave astronomy .", "tokens": ["the", "groundbreaking", "observations", "of", "binary", "black", "hole", "collisions", "by", "advanced", "ligo", "have", "ushered", "in", "a", "new", "era", "of", "gravitational", "wave", "astronomy", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the groundbreaking observations of binary black hole collisions by advanced ligo", "start": 0, "end": 80, "i_start": 0, "i_end": 10}, "verb": {"text": "have ushered in", "start": 81, "end": 96, "i_start": 11, "i_end": 13}}, {"character": {"text": "observations", "start": 19, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "ushered", "start": 86, "end": 93, "i_start": 12, "i_end": 12}}], "id": 4997}, {"sent": "recently , deep learning methods have made remarkable progress in computer vision and machine learning .", "tokens": ["recently", ",", "deep", "learning", "methods", "have", "made", "remarkable", "progress", "in", "computer", "vision", "and", "machine", "learning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning methods", "start": 11, "end": 32, "i_start": 2, "i_end": 4}, "verb": {"text": "have made", "start": 33, "end": 42, "i_start": 5, "i_end": 6}}], "id": 4998}, {"sent": "generative adversarial network has become a dominant approach for learning generative models .", "tokens": ["generative", "adversarial", "network", "has", "become", "a", "dominant", "approach", "for", "learning", "generative", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial network", "start": 0, "end": 30, "i_start": 0, "i_end": 2}, "verb": {"text": "has become", "start": 31, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "approach", "start": 53, "end": 61, "i_start": 7, "i_end": 7}, "action": {"text": "dominant", "start": 44, "end": 52, "i_start": 6, "i_end": 6}}], "id": 4999}]