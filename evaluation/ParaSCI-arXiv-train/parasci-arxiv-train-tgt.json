[{"sent": "we find the optimal alignment of the clean and noisy embeddings via procrustes analysis and apply the resulting translational , rotational , and scaling components on the oose points .", "tokens": ["we", "find", "the", "optimal", "alignment", "of", "the", "clean", "and", "noisy", "embeddings", "via", "procrustes", "analysis", "and", "apply", "the", "resulting", "translational", ",", "rotational", ",", "and", "scaling", "components", "on", "the", "oose", "points", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "apply", "start": 92, "end": 97, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "apply", "start": 92, "end": 97, "i_start": 15, "i_end": 15}}], "id": 0}, {"sent": "end-to-end neural machine translation has gained increasing popularity in the machine translation community .", "tokens": ["end", "-", "to", "-", "end", "neural", "machine", "translation", "has", "gained", "increasing", "popularity", "in", "the", "machine", "translation", "community", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "end-to-end neural machine translation", "start": 0, "end": 37, "i_start": 0, "i_end": 7}, "verb": {"text": "has gained", "start": 38, "end": 48, "i_start": 8, "i_end": 9}}, {"character": {"text": "translation", "start": 26, "end": 37, "i_start": 7, "i_end": 7}, "action": {"text": "gained", "start": 42, "end": 48, "i_start": 9, "i_end": 9}}, {"character": {"text": "community", "start": 98, "end": 107, "i_start": 16, "i_end": 16}, "action": {"text": "translation", "start": 86, "end": 97, "i_start": 15, "i_end": 15}}], "id": 1}, {"sent": "moreover , asymptotically for large k , the sorting operation can be performed with a complexity on the order of o , according to the van emde boas tree .", "tokens": ["moreover", ",", "asymptotically", "for", "large", "k", ",", "the", "sorting", "operation", "can", "be", "performed", "with", "a", "complexity", "on", "the", "order", "of", "o", ",", "according", "to", "the", "van", "emde", "boas", "tree", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the sorting operation", "start": 40, "end": 61, "i_start": 7, "i_end": 9}, "verb": {"text": "can be performed", "start": 62, "end": 78, "i_start": 10, "i_end": 12}}], "id": 2}, {"sent": "we build on the recent success of deep learning and use a convolutional neural network to encode image information .", "tokens": ["we", "build", "on", "the", "recent", "success", "of", "deep", "learning", "and", "use", "a", "convolutional", "neural", "network", "to", "encode", "image", "information", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "build", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 52, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "build", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "learning", "start": 39, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "success", "start": 23, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 52, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "network", "start": 79, "end": 86, "i_start": 14, "i_end": 14}, "action": {"text": "encode", "start": 90, "end": 96, "i_start": 16, "i_end": 16}}], "id": 3}, {"sent": "the trainable parameters are initialized using the glorot algorithm .", "tokens": ["the", "trainable", "parameters", "are", "initialized", "using", "the", "glorot", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the trainable parameters", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "are initialized", "start": 25, "end": 40, "i_start": 3, "i_end": 4}}], "id": 4}, {"sent": "transductive learning we utilize three standard citation network benchmark datasets-cora , citeseer and pubmed -and closely follow the transductive experimental setup of yang et al .", "tokens": ["transductive", "learning", "we", "utilize", "three", "standard", "citation", "network", "benchmark", "datasets", "-", "cora", ",", "citeseer", "and", "pubmed", "-and", "closely", "follow", "the", "transductive", "experimental", "setup", "of", "yang", "et", "al", "."], "score": [0, 1, 1, 0, 1], "labels": [{"subject": {"text": "transductive learning we utilize three standard citation network benchmark datasets-cora", "start": 0, "end": 88, "i_start": 0, "i_end": 11}, "verb": {"text": "follow", "start": 124, "end": 130, "i_start": 18, "i_end": 18}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "utilize", "start": 25, "end": 32, "i_start": 3, "i_end": 3}}], "id": 5}, {"sent": "convolutional neural networks have recently been very successful on a variety of recognition and classification tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "been", "very", "successful", "on", "a", "variety", "of", "recognition", "and", "classification", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "been", "start": 44, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 54, "end": 64, "i_start": 7, "i_end": 7}}], "id": 6}, {"sent": "the camera consists of an array of ccds with associated electronics , thermal control and radiation , stray light and contamination shielding .", "tokens": ["the", "camera", "consists", "of", "an", "array", "of", "ccds", "with", "associated", "electronics", ",", "thermal", "control", "and", "radiation", ",", "stray", "light", "and", "contamination", "shielding", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the camera", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the camera", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "stray", "start": 102, "end": 107, "i_start": 17, "i_end": 17}}], "id": 7}, {"sent": "in recent years deep convolutional networks have become an integral part of state-of-the-art systems for a diverse set of computer vision problems such as object detection .", "tokens": ["in", "recent", "years", "deep", "convolutional", "networks", "have", "become", "an", "integral", "part", "of", "state", "-", "of", "-", "the", "-", "art", "systems", "for", "a", "diverse", "set", "of", "computer", "vision", "problems", "such", "as", "object", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional networks", "start": 21, "end": 43, "i_start": 4, "i_end": 5}, "verb": {"text": "have become", "start": 44, "end": 55, "i_start": 6, "i_end": 7}}], "id": 8}, {"sent": "convolutional neural networks have surpassed many traditional machine learning approaches in solving several computer vision tasks such as classification and others .", "tokens": ["convolutional", "neural", "networks", "have", "surpassed", "many", "traditional", "machine", "learning", "approaches", "in", "solving", "several", "computer", "vision", "tasks", "such", "as", "classification", "and", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have surpassed", "start": 30, "end": 44, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "surpassed", "start": 35, "end": 44, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "solving", "start": 93, "end": 100, "i_start": 11, "i_end": 11}}], "id": 9}, {"sent": "however , manual segmentation is tedious , time consuming and prone to intra-and inter-observer variability .", "tokens": ["however", ",", "manual", "segmentation", "is", "tedious", ",", "time", "consuming", "and", "prone", "to", "intra", "-", "and", "inter", "-", "observer", "variability", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "manual segmentation", "start": 10, "end": 29, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "segmentation", "start": 17, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "consuming", "start": 48, "end": 57, "i_start": 8, "i_end": 8}}], "id": 10}, {"sent": "recent rapid advances in deep learning are allowing for the learning of complex functions through convolutional neural networks , which have achieved stateof-the-art performances in a plethora of computer vision tasks .", "tokens": ["recent", "rapid", "advances", "in", "deep", "learning", "are", "allowing", "for", "the", "learning", "of", "complex", "functions", "through", "convolutional", "neural", "networks", ",", "which", "have", "achieved", "stateof", "-", "the", "-", "art", "performances", "in", "a", "plethora", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent rapid advances in deep learning", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "are allowing", "start": 39, "end": 51, "i_start": 6, "i_end": 7}}, {"character": {"text": "advances", "start": 13, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "allowing", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 119, "end": 127, "i_start": 17, "i_end": 17}, "action": {"text": "achieved", "start": 141, "end": 149, "i_start": 21, "i_end": 21}}], "id": 11}, {"sent": "this figure shows how to compute ana followed by copy transformations .", "tokens": ["this", "figure", "shows", "how", "to", "compute", "ana", "followed", "by", "copy", "transformations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this figure", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "shows", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "how to compute ana", "start": 18, "end": 36, "i_start": 3, "i_end": 6}, "verb": {"text": "followed", "start": 37, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "figure", "start": 5, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "shows", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}], "id": 12}, {"sent": "it also arises in string theory , which is the leading candidate to unify gauge and gravitational forces .", "tokens": ["it", "also", "arises", "in", "string", "theory", ",", "which", "is", "the", "leading", "candidate", "to", "unify", "gauge", "and", "gravitational", "forces", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "arises", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "theory", "start": 25, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "candidate", "start": 55, "end": 64, "i_start": 11, "i_end": 11}}, {"character": {"text": "candidate", "start": 55, "end": 64, "i_start": 11, "i_end": 11}, "action": {"text": "leading", "start": 47, "end": 54, "i_start": 10, "i_end": 10}}], "id": 13}, {"sent": "in a remarkable work , spielman and srivastava analyzed a spectral sparsification algorithm based on a simple sampling procedure .", "tokens": ["in", "a", "remarkable", "work", ",", "spielman", "and", "srivastava", "analyzed", "a", "spectral", "sparsification", "algorithm", "based", "on", "a", "simple", "sampling", "procedure", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "spielman and srivastava", "start": 23, "end": 46, "i_start": 5, "i_end": 7}, "verb": {"text": "analyzed", "start": 47, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "spielman", "start": 23, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "analyzed", "start": 47, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "srivastava", "start": 36, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "analyzed", "start": 47, "end": 55, "i_start": 8, "i_end": 8}}], "id": 14}, {"sent": "note that agarwal et al also analyzed this model using m-estimators .", "tokens": ["note", "that", "agarwal", "et", "al", "also", "analyzed", "this", "model", "using", "m", "-", "estimators", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "agarwal et al", "start": 10, "end": 23, "i_start": 2, "i_end": 4}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "agarwal et al", "start": 10, "end": 23, "i_start": 2, "i_end": 4}, "verb": {"text": "analyzed", "start": 29, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "agarwal", "start": 10, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "analyzed", "start": 29, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "agarwal", "start": 10, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "using", "start": 49, "end": 54, "i_start": 9, "i_end": 9}}], "id": 15}, {"sent": "we train using the adam optimiser along with an early stopping criterion .", "tokens": ["we", "train", "using", "the", "adam", "optimiser", "along", "with", "an", "early", "stopping", "criterion", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 9, "end": 14, "i_start": 2, "i_end": 2}}], "id": 16}, {"sent": "the classifier was trained using mini-batch sgd , with the learning rate controlled by adam and the mini-batch size set to 32 .", "tokens": ["the", "classifier", "was", "trained", "using", "mini", "-", "batch", "sgd", ",", "with", "the", "learning", "rate", "controlled", "by", "adam", "and", "the", "mini", "-", "batch", "size", "set", "to", "32", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the classifier", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "was trained", "start": 15, "end": 26, "i_start": 2, "i_end": 3}}, {"character": {"text": "adam", "start": 87, "end": 91, "i_start": 16, "i_end": 16}, "action": {"text": "controlled", "start": 73, "end": 83, "i_start": 14, "i_end": 14}}], "id": 17}, {"sent": "the calculation was performed within the framework of dft 35 , as implemented in the vienna ab-initio simulation package 36 , 37 .", "tokens": ["the", "calculation", "was", "performed", "within", "the", "framework", "of", "dft", "35", ",", "as", "implemented", "in", "the", "vienna", "ab", "-", "initio", "simulation", "package", "36", ",", "37", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the calculation", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "was performed", "start": 16, "end": 29, "i_start": 2, "i_end": 3}}], "id": 18}, {"sent": "unlike prior work with sparsity-aware algorithms , the proposed sils algorithm exploits the possible sparsity of the emse associated with each of the links in an opposite way .", "tokens": ["unlike", "prior", "work", "with", "sparsity", "-", "aware", "algorithms", ",", "the", "proposed", "sils", "algorithm", "exploits", "the", "possible", "sparsity", "of", "the", "emse", "associated", "with", "each", "of", "the", "links", "in", "an", "opposite", "way", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the proposed sils algorithm", "start": 51, "end": 78, "i_start": 9, "i_end": 12}, "verb": {"text": "exploits", "start": 79, "end": 87, "i_start": 13, "i_end": 13}}, {"character": {"text": "algorithms", "start": 38, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "exploits", "start": 79, "end": 87, "i_start": 13, "i_end": 13}}], "id": 19}, {"sent": "a qubit is a unit vector in the hilbert space c2 .", "tokens": ["a", "qubit", "is", "a", "unit", "vector", "in", "the", "hilbert", "space", "c2", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a qubit", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 2, "i_end": 2}}], "id": 20}, {"sent": "for example , one might respond to edges of a particular orientation , or a sweet taste , or something that does not exactly match an established term .", "tokens": ["for", "example", ",", "one", "might", "respond", "to", "edges", "of", "a", "particular", "orientation", ",", "or", "a", "sweet", "taste", ",", "or", "something", "that", "does", "not", "exactly", "match", "an", "established", "term", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 14, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "might respond", "start": 18, "end": 31, "i_start": 4, "i_end": 5}}, {"character": {"text": "one", "start": 14, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "respond", "start": 24, "end": 31, "i_start": 5, "i_end": 5}}], "id": 21}, {"sent": "we use the adam optimizer , with gradients clipped with norm value 1 .", "tokens": ["we", "use", "the", "adam", "optimizer", ",", "with", "gradients", "clipped", "with", "norm", "value", "1", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 22}, {"sent": "in recent years , neural networks have been effectively applied in various problems such as voice recognition .", "tokens": ["in", "recent", "years", ",", "neural", "networks", "have", "been", "effectively", "applied", "in", "various", "problems", "such", "as", "voice", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 18, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "applied", "start": 56, "end": 63, "i_start": 9, "i_end": 9}}, {"subject": {"text": "neural networks", "start": 18, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "have been", "start": 34, "end": 43, "i_start": 6, "i_end": 7}}], "id": 23}, {"sent": "similarly , topic features have been used with either maximum entropy models .", "tokens": ["similarly", ",", "topic", "features", "have", "been", "used", "with", "either", "maximum", "entropy", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "topic features", "start": 12, "end": 26, "i_start": 2, "i_end": 3}, "verb": {"text": "have been used", "start": 27, "end": 41, "i_start": 4, "i_end": 6}}], "id": 24}, {"sent": "compressed sensing is a recent signal detection framework which has received considerable attention in the signal processing community .", "tokens": ["compressed", "sensing", "is", "a", "recent", "signal", "detection", "framework", "which", "has", "received", "considerable", "attention", "in", "the", "signal", "processing", "community", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "compressed sensing", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "framework", "start": 48, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "detection", "start": 38, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "framework", "start": 48, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "received", "start": 68, "end": 76, "i_start": 10, "i_end": 10}}, {"character": {"text": "community", "start": 125, "end": 134, "i_start": 17, "i_end": 17}, "action": {"text": "attention", "start": 90, "end": 99, "i_start": 12, "i_end": 12}}, {"character": {"text": "community", "start": 125, "end": 134, "i_start": 17, "i_end": 17}, "action": {"text": "processing", "start": 114, "end": 124, "i_start": 16, "i_end": 16}}], "id": 25}, {"sent": "finally , we perform binarization operation on each attention map with an adaptive threshold , which is obtained by otsu algorithm , and take the bounding box that covers the largest connected area as the discriminative region .", "tokens": ["finally", ",", "we", "perform", "binarization", "operation", "on", "each", "attention", "map", "with", "an", "adaptive", "threshold", ",", "which", "is", "obtained", "by", "otsu", "algorithm", ",", "and", "take", "the", "bounding", "box", "that", "covers", "the", "largest", "connected", "area", "as", "the", "discriminative", "region", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "perform", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "take", "start": 137, "end": 141, "i_start": 23, "i_end": 23}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "perform", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithm", "start": 121, "end": 130, "i_start": 20, "i_end": 20}, "action": {"text": "obtained", "start": 104, "end": 112, "i_start": 17, "i_end": 17}}], "id": 26}, {"sent": "parenti , multi-lepton production at hera , these proceedings .", "tokens": ["parenti", ",", "multi", "-", "lepton", "production", "at", "hera", ",", "these", "proceedings", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 27}, {"sent": "while models following this paradigm have been found very useful in a number of natural language processing tasks , they do not scale up to the level of phrases or sentences .", "tokens": ["while", "models", "following", "this", "paradigm", "have", "been", "found", "very", "useful", "in", "a", "number", "of", "natural", "language", "processing", "tasks", ",", "they", "do", "not", "scale", "up", "to", "the", "level", "of", "phrases", "or", "sentences", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "they", "start": 116, "end": 120, "i_start": 19, "i_end": 19}, "verb": {"text": "do not scale up", "start": 121, "end": 136, "i_start": 20, "i_end": 23}}, {"character": {"text": "models", "start": 6, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "not scale", "start": 124, "end": 133, "i_start": 21, "i_end": 22}}], "id": 28}, {"sent": "free energy is the fundamental object in statistical mechanics .", "tokens": ["free", "energy", "is", "the", "fundamental", "object", "in", "statistical", "mechanics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "free energy", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 29}, {"sent": "this holds in particular , for the local broadcast algorithm of which crucially relies on a very unnatural reversal step to guarantee correctness .", "tokens": ["this", "holds", "in", "particular", ",", "for", "the", "local", "broadcast", "algorithm", "of", "which", "crucially", "relies", "on", "a", "very", "unnatural", "reversal", "step", "to", "guarantee", "correctness", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "holds", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "holds", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "algorithm", "start": 51, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "broadcast", "start": 41, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "algorithm", "start": 51, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "relies", "start": 80, "end": 86, "i_start": 13, "i_end": 13}}, {"character": {"text": "step", "start": 116, "end": 120, "i_start": 19, "i_end": 19}, "action": {"text": "guarantee", "start": 124, "end": 133, "i_start": 21, "i_end": 21}}], "id": 30}, {"sent": "the youtube faces dataset exemplify both unconstrained and controlled video settings .", "tokens": ["the", "youtube", "faces", "dataset", "exemplify", "both", "unconstrained", "and", "controlled", "video", "settings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the youtube", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "faces", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "dataset", "start": 18, "end": 25, "i_start": 3, "i_end": 3}, "verb": {"text": "exemplify", "start": 26, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "dataset", "start": 18, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "exemplify", "start": 26, "end": 35, "i_start": 4, "i_end": 4}}], "id": 31}, {"sent": "to carry out our program , we generalize the toric mori theory for non-complete and non-q-factorial varieties .", "tokens": ["to", "carry", "out", "our", "program", ",", "we", "generalize", "the", "toric", "mori", "theory", "for", "non", "-", "complete", "and", "non", "-", "q", "-", "factorial", "varieties", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 27, "end": 29, "i_start": 6, "i_end": 6}, "verb": {"text": "generalize", "start": 30, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 27, "end": 29, "i_start": 6, "i_end": 6}, "action": {"text": "generalize", "start": 30, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 27, "end": 29, "i_start": 6, "i_end": 6}, "action": {"text": "carry", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 32}, {"sent": "later , defferrard et al and levie et al proposed spectrum filtering based methods that utilize chebyshev polynomials and cayley polynomials , respectively .", "tokens": ["later", ",", "defferrard", "et", "al", "and", "levie", "et", "al", "proposed", "spectrum", "filtering", "based", "methods", "that", "utilize", "chebyshev", "polynomials", "and", "cayley", "polynomials", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "defferrard et al and levie et al", "start": 8, "end": 40, "i_start": 2, "i_end": 8}, "verb": {"text": "proposed", "start": 41, "end": 49, "i_start": 9, "i_end": 9}}, {"character": {"text": "defferrard et al", "start": 8, "end": 24, "i_start": 2, "i_end": 4}, "action": {"text": "proposed", "start": 41, "end": 49, "i_start": 9, "i_end": 9}}, {"character": {"text": "levie et al", "start": 29, "end": 40, "i_start": 6, "i_end": 8}, "action": {"text": "proposed", "start": 41, "end": 49, "i_start": 9, "i_end": 9}}, {"character": {"text": "methods", "start": 75, "end": 82, "i_start": 13, "i_end": 13}, "action": {"text": "utilize", "start": 88, "end": 95, "i_start": 15, "i_end": 15}}], "id": 33}, {"sent": "this posterior is analytically intractable and we resort to variational inference .", "tokens": ["this", "posterior", "is", "analytically", "intractable", "and", "we", "resort", "to", "variational", "inference", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this posterior", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 47, "end": 49, "i_start": 6, "i_end": 6}, "verb": {"text": "resort", "start": 50, "end": 56, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 47, "end": 49, "i_start": 6, "i_end": 6}, "action": {"text": "resort", "start": 50, "end": 56, "i_start": 7, "i_end": 7}}], "id": 34}, {"sent": "the generalized gradient approximation of perdew , burke and ernzerhof was used to describe the exchangecorrelation potential .", "tokens": ["the", "generalized", "gradient", "approximation", "of", "perdew", ",", "burke", "and", "ernzerhof", "was", "used", "to", "describe", "the", "exchangecorrelation", "potential", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation of perdew", "start": 0, "end": 48, "i_start": 0, "i_end": 5}, "verb": {"text": "was used", "start": 71, "end": 79, "i_start": 10, "i_end": 11}}, {"character": {"text": "approximation", "start": 25, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "describe", "start": 83, "end": 91, "i_start": 13, "i_end": 13}}], "id": 35}, {"sent": "the time component may designate an entire year , a year and a month , or a full date .", "tokens": ["the", "time", "component", "may", "designate", "an", "entire", "year", ",", "a", "year", "and", "a", "month", ",", "or", "a", "full", "date", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the time component", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "may designate", "start": 19, "end": 32, "i_start": 3, "i_end": 4}}, {"character": {"text": "component", "start": 9, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "designate", "start": 23, "end": 32, "i_start": 4, "i_end": 4}}], "id": 36}, {"sent": "deep convolutional neural networks have made significant breakthroughs in many visual understanding tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "significant", "breakthroughs", "in", "many", "visual", "understanding", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "breakthroughs", "start": 57, "end": 70, "i_start": 7, "i_end": 7}}], "id": 37}, {"sent": "in recent years , deep neural networks have achieved great success in a variety of machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "achieved", "great", "success", "in", "a", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}], "id": 38}, {"sent": "distance of povms from observables in the preceding subsection , we have defined the rootmean-square noise of measurement using the associated indirect measurement model .", "tokens": ["distance", "of", "povms", "from", "observables", "in", "the", "preceding", "subsection", ",", "we", "have", "defined", "the", "rootmean", "-", "square", "noise", "of", "measurement", "using", "the", "associated", "indirect", "measurement", "model", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 65, "end": 67, "i_start": 10, "i_end": 10}, "verb": {"text": "have defined", "start": 68, "end": 80, "i_start": 11, "i_end": 12}}, {"character": {"text": "we", "start": 65, "end": 67, "i_start": 10, "i_end": 10}, "action": {"text": "defined", "start": 73, "end": 80, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 65, "end": 67, "i_start": 10, "i_end": 10}, "action": {"text": "using", "start": 122, "end": 127, "i_start": 20, "i_end": 20}}], "id": 39}, {"sent": "filled squares represent the g-sample , open circles the h-sample and crosses nondetections .", "tokens": ["filled", "squares", "represent", "the", "g", "-", "sample", ",", "open", "circles", "the", "h", "-", "sample", "and", "crosses", "nondetections", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "filled squares", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "represent", "start": 15, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "squares", "start": 7, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "represent", "start": 15, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "sample", "start": 31, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "crosses", "start": 70, "end": 77, "i_start": 15, "i_end": 15}}], "id": 40}, {"sent": "firstly , hydrogen is the prime fuel for galaxies , when it condenses from the hot ionized halo onto the galactic disks .", "tokens": ["firstly", ",", "hydrogen", "is", "the", "prime", "fuel", "for", "galaxies", ",", "when", "it", "condenses", "from", "the", "hot", "ionized", "halo", "onto", "the", "galactic", "disks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "hydrogen", "start": 10, "end": 18, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 41}, {"sent": "we evaluate the searched model on cifar-10 and then transfer to imagenet .", "tokens": ["we", "evaluate", "the", "searched", "model", "on", "cifar-10", "and", "then", "transfer", "to", "imagenet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "transfer", "start": 52, "end": 60, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "transfer", "start": 52, "end": 60, "i_start": 9, "i_end": 9}}], "id": 42}, {"sent": "to reduce the dependency on weight initialization and to accelerate the training process , we add batch normalization layer after each convolution and fully-connected layer .", "tokens": ["to", "reduce", "the", "dependency", "on", "weight", "initialization", "and", "to", "accelerate", "the", "training", "process", ",", "we", "add", "batch", "normalization", "layer", "after", "each", "convolution", "and", "fully", "-", "connected", "layer", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 91, "end": 93, "i_start": 14, "i_end": 14}, "verb": {"text": "add", "start": 94, "end": 97, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 91, "end": 93, "i_start": 14, "i_end": 14}, "action": {"text": "add", "start": 94, "end": 97, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 91, "end": 93, "i_start": 14, "i_end": 14}, "action": {"text": "reduce", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "initialization", "start": 35, "end": 49, "i_start": 6, "i_end": 6}, "action": {"text": "dependency", "start": 14, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 91, "end": 93, "i_start": 14, "i_end": 14}, "action": {"text": "accelerate", "start": 57, "end": 67, "i_start": 9, "i_end": 9}}], "id": 43}, {"sent": "we now proceed onto give the following interesting corollary .", "tokens": ["we", "now", "proceed", "onto", "give", "the", "following", "interesting", "corollary", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "give", "start": 20, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "corollary", "start": 51, "end": 60, "i_start": 8, "i_end": 8}, "action": {"text": "interesting", "start": 39, "end": 50, "i_start": 7, "i_end": 7}}], "id": 44}, {"sent": "the meta-meta-model layer defines the language for specifying meta-models .", "tokens": ["the", "meta", "-", "meta", "-", "model", "layer", "defines", "the", "language", "for", "specifying", "meta", "-", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the meta-meta-model layer", "start": 0, "end": 25, "i_start": 0, "i_end": 6}, "verb": {"text": "defines", "start": 26, "end": 33, "i_start": 7, "i_end": 7}}, {"character": {"text": "layer", "start": 20, "end": 25, "i_start": 6, "i_end": 6}, "action": {"text": "defines", "start": 26, "end": 33, "i_start": 7, "i_end": 7}}], "id": 45}, {"sent": "this sub-space consists of the simultaneous eigenstates of the cashmir operators for each i .", "tokens": ["this", "sub", "-", "space", "consists", "of", "the", "simultaneous", "eigenstates", "of", "the", "cashmir", "operators", "for", "each", "i", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 46}, {"sent": "the exchange-correlation potential was calculated using the generalized gradient approximation as proposed by pedrew , burke , and ernzerhof .", "tokens": ["the", "exchange", "-", "correlation", "potential", "was", "calculated", "using", "the", "generalized", "gradient", "approximation", "as", "proposed", "by", "pedrew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange-correlation potential", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "was calculated", "start": 35, "end": 49, "i_start": 5, "i_end": 6}}, {"character": {"text": "pedrew", "start": 110, "end": 116, "i_start": 15, "i_end": 15}, "action": {"text": "proposed", "start": 98, "end": 106, "i_start": 13, "i_end": 13}}, {"character": {"text": "burke", "start": 119, "end": 124, "i_start": 17, "i_end": 17}, "action": {"text": "proposed", "start": 98, "end": 106, "i_start": 13, "i_end": 13}}, {"character": {"text": "ernzerhof", "start": 131, "end": 140, "i_start": 20, "i_end": 20}, "action": {"text": "proposed", "start": 98, "end": 106, "i_start": 13, "i_end": 13}}], "id": 47}, {"sent": "an automatic binarization method for colour text area in video based on convolutional network is proposed by saidane and garcia .", "tokens": ["an", "automatic", "binarization", "method", "for", "colour", "text", "area", "in", "video", "based", "on", "convolutional", "network", "is", "proposed", "by", "saidane", "and", "garcia", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "an automatic binarization method for colour text area in video based on convolutional network", "start": 0, "end": 93, "i_start": 0, "i_end": 13}, "verb": {"text": "is proposed", "start": 94, "end": 105, "i_start": 14, "i_end": 15}}, {"character": {"text": "saidane", "start": 109, "end": 116, "i_start": 17, "i_end": 17}, "action": {"text": "proposed", "start": 97, "end": 105, "i_start": 15, "i_end": 15}}, {"character": {"text": "garcia", "start": 121, "end": 127, "i_start": 19, "i_end": 19}, "action": {"text": "proposed", "start": 97, "end": 105, "i_start": 15, "i_end": 15}}], "id": 48}, {"sent": "the zb are the zeros of zn ) and are known as the apparent singularities .", "tokens": ["the", "zb", "are", "the", "zeros", "of", "zn", ")", "and", "are", "known", "as", "the", "apparent", "singularities", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the zb", "start": 0, "end": 6, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 7, "end": 10, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the zb", "start": 0, "end": 6, "i_start": 0, "i_end": 1}, "verb": {"text": "known", "start": 37, "end": 42, "i_start": 10, "i_end": 10}}], "id": 49}, {"sent": "recently , deep neural networks have achieved impressive results for many image classification tasks .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "achieved", "impressive", "results", "for", "many", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have achieved", "start": 32, "end": 45, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "results", "start": 57, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "impressive", "start": 46, "end": 56, "i_start": 7, "i_end": 7}}], "id": 50}, {"sent": "in , a dynamic channel-selection for autonomous wireless users is proposed , where each user has a set of actions and strategies .", "tokens": ["in", ",", "a", "dynamic", "channel", "-", "selection", "for", "autonomous", "wireless", "users", "is", "proposed", ",", "where", "each", "user", "has", "a", "set", "of", "actions", "and", "strategies", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a dynamic channel-selection for autonomous wireless users", "start": 5, "end": 62, "i_start": 2, "i_end": 10}, "verb": {"text": "is proposed", "start": 63, "end": 74, "i_start": 11, "i_end": 12}}, {"character": {"text": "each", "start": 83, "end": 87, "i_start": 15, "i_end": 15}, "action": {"text": "has", "start": 93, "end": 96, "i_start": 17, "i_end": 17}}], "id": 51}, {"sent": "a singleton letter is a letter whose image , in the remaining three quadrants , is never another letter that appears in the upper left quadrant .", "tokens": ["a", "singleton", "letter", "is", "a", "letter", "whose", "image", ",", "in", "the", "remaining", "three", "quadrants", ",", "is", "never", "another", "letter", "that", "appears", "in", "the", "upper", "left", "quadrant", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a singleton letter", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 52}, {"sent": "each lattice site consists of a double well potential .", "tokens": ["each", "lattice", "site", "consists", "of", "a", "double", "well", "potential", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each lattice site", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}], "id": 53}, {"sent": "however , the computational complexity of this detection method is very high , and large number of samples are required to exploit the cyclostationarity nature of the received samples .", "tokens": ["however", ",", "the", "computational", "complexity", "of", "this", "detection", "method", "is", "very", "high", ",", "and", "large", "number", "of", "samples", "are", "required", "to", "exploit", "the", "cyclostationarity", "nature", "of", "the", "received", "samples", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the computational complexity of this detection method", "start": 10, "end": 63, "i_start": 2, "i_end": 8}, "verb": {"text": "is", "start": 64, "end": 66, "i_start": 9, "i_end": 9}}, {"subject": {"text": "large number of samples", "start": 83, "end": 106, "i_start": 14, "i_end": 17}, "verb": {"text": "required", "start": 111, "end": 119, "i_start": 19, "i_end": 19}}], "id": 54}, {"sent": "we also find that the spin current is a nonlocal function of the spin motive force and can be effectively expressed in terms of nonlocal gilbert damping tensor .", "tokens": ["we", "also", "find", "that", "the", "spin", "current", "is", "a", "nonlocal", "function", "of", "the", "spin", "motive", "force", "and", "can", "be", "effectively", "expressed", "in", "terms", "of", "nonlocal", "gilbert", "damping", "tensor", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "force", "start": 77, "end": 82, "i_start": 15, "i_end": 15}, "action": {"text": "function", "start": 49, "end": 57, "i_start": 10, "i_end": 10}}, {"character": {"text": "motive", "start": 70, "end": 76, "i_start": 14, "i_end": 14}, "action": {"text": "force", "start": 77, "end": 82, "i_start": 15, "i_end": 15}}], "id": 55}, {"sent": "for the reweighted techniques , the h-method estimator provides better energy values than the t-method estimator .", "tokens": ["for", "the", "reweighted", "techniques", ",", "the", "h", "-", "method", "estimator", "provides", "better", "energy", "values", "than", "the", "t", "-", "method", "estimator", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the h-method estimator", "start": 32, "end": 54, "i_start": 5, "i_end": 9}, "verb": {"text": "provides", "start": 55, "end": 63, "i_start": 10, "i_end": 10}}], "id": 56}, {"sent": "for a more detailed introduction to fractional sobolev spaces and related results , we refer the readers to .", "tokens": ["for", "a", "more", "detailed", "introduction", "to", "fractional", "sobolev", "spaces", "and", "related", "results", ",", "we", "refer", "the", "readers", "to", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 84, "end": 86, "i_start": 13, "i_end": 13}, "verb": {"text": "refer", "start": 87, "end": 92, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 84, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "refer", "start": 87, "end": 92, "i_start": 14, "i_end": 14}}], "id": 57}, {"sent": "son et al show that intentional resonant sounds can disrupt the mems gyroscopes and cause drones to crash .", "tokens": ["son", "et", "al", "show", "that", "intentional", "resonant", "sounds", "can", "disrupt", "the", "mems", "gyroscopes", "and", "cause", "drones", "to", "crash", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "son et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "show", "start": 10, "end": 14, "i_start": 3, "i_end": 3}}, {"subject": {"text": "intentional resonant sounds", "start": 20, "end": 47, "i_start": 5, "i_end": 7}, "verb": {"text": "disrupt", "start": 52, "end": 59, "i_start": 9, "i_end": 9}}, {"character": {"text": "sounds", "start": 41, "end": 47, "i_start": 7, "i_end": 7}, "action": {"text": "disrupt", "start": 52, "end": 59, "i_start": 9, "i_end": 9}}, {"character": {"text": "sounds", "start": 41, "end": 47, "i_start": 7, "i_end": 7}, "action": {"text": "cause", "start": 84, "end": 89, "i_start": 14, "i_end": 14}}, {"character": {"text": "sounds", "start": 41, "end": 47, "i_start": 7, "i_end": 7}, "action": {"text": "crash", "start": 100, "end": 105, "i_start": 17, "i_end": 17}}], "id": 58}, {"sent": "the set of the proteins used for the parameter refinement is called the training set .", "tokens": ["the", "set", "of", "the", "proteins", "used", "for", "the", "parameter", "refinement", "is", "called", "the", "training", "set", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the set of the proteins used for the parameter refinement", "start": 0, "end": 57, "i_start": 0, "i_end": 9}, "verb": {"text": "is called", "start": 58, "end": 67, "i_start": 10, "i_end": 11}}], "id": 59}, {"sent": "the average square amplitude of the island deviations is equal to that of the harmonically oscillating island .", "tokens": ["the", "average", "square", "amplitude", "of", "the", "island", "deviations", "is", "equal", "to", "that", "of", "the", "harmonically", "oscillating", "island", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the average square amplitude of the island deviations", "start": 0, "end": 53, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 54, "end": 56, "i_start": 8, "i_end": 8}}, {"character": {"text": "island", "start": 103, "end": 109, "i_start": 16, "i_end": 16}, "action": {"text": "oscillating", "start": 91, "end": 102, "i_start": 15, "i_end": 15}}], "id": 60}, {"sent": "deep neural networks have demonstrated extraordinary success in a variety of fields such as computer vision .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "extraordinary", "success", "in", "a", "variety", "of", "fields", "such", "as", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 53, "end": 60, "i_start": 6, "i_end": 6}}], "id": 61}, {"sent": "density functional theory calculations were performed using the vienna ab initio simulation package along with the perdew-burke-ernzerhof generalized gradient approximation exchange-correlation functional .", "tokens": ["density", "functional", "theory", "calculations", "were", "performed", "using", "the", "vienna", "ab", "initio", "simulation", "package", "along", "with", "the", "perdew", "-", "burke", "-", "ernzerhof", "generalized", "gradient", "approximation", "exchange", "-", "correlation", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "density functional theory calculations", "start": 0, "end": 38, "i_start": 0, "i_end": 3}, "verb": {"text": "were performed", "start": 39, "end": 53, "i_start": 4, "i_end": 5}}], "id": 62}, {"sent": "improved upper bounds , breaking this barrier slightly , were given in developed a new approach for constructing ldcs , called mv codes , that have much shorter codeword length than polynomial codes .", "tokens": ["improved", "upper", "bounds", ",", "breaking", "this", "barrier", "slightly", ",", "were", "given", "in", "developed", "a", "new", "approach", "for", "constructing", "ldcs", ",", "called", "mv", "codes", ",", "that", "have", "much", "shorter", "codeword", "length", "than", "polynomial", "codes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "bounds", "start": 15, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "breaking", "start": 24, "end": 32, "i_start": 4, "i_end": 4}}], "id": 63}, {"sent": "kim et al propose a 20-layer cnn model known as vdsr , which adopts residual learning and adaptive gradient clipping to ease training difficulty .", "tokens": ["kim", "et", "al", "propose", "a", "20", "-", "layer", "cnn", "model", "known", "as", "vdsr", ",", "which", "adopts", "residual", "learning", "and", "adaptive", "gradient", "clipping", "to", "ease", "training", "difficulty", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "kim et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 10, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "kim", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 10, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "model", "start": 33, "end": 38, "i_start": 9, "i_end": 9}, "action": {"text": "adopts", "start": 61, "end": 67, "i_start": 15, "i_end": 15}}, {"character": {"text": "learning", "start": 77, "end": 85, "i_start": 17, "i_end": 17}, "action": {"text": "ease", "start": 120, "end": 124, "i_start": 23, "i_end": 23}}, {"character": {"text": "residual", "start": 68, "end": 76, "i_start": 16, "i_end": 16}, "action": {"text": "ease", "start": 120, "end": 124, "i_start": 23, "i_end": 23}}, {"character": {"text": "clipping", "start": 108, "end": 116, "i_start": 21, "i_end": 21}, "action": {"text": "ease", "start": 120, "end": 124, "i_start": 23, "i_end": 23}}, {"character": {"text": "gradient", "start": 99, "end": 107, "i_start": 20, "i_end": 20}, "action": {"text": "ease", "start": 120, "end": 124, "i_start": 23, "i_end": 23}}], "id": 64}, {"sent": "because the method does not involve the movement of any mechanical or optical components during the measurement process , it can be readily applied to fragile fibers .", "tokens": ["because", "the", "method", "does", "not", "involve", "the", "movement", "of", "any", "mechanical", "or", "optical", "components", "during", "the", "measurement", "process", ",", "it", "can", "be", "readily", "applied", "to", "fragile", "fibers", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 122, "end": 124, "i_start": 19, "i_end": 19}, "verb": {"text": "applied", "start": 140, "end": 147, "i_start": 23, "i_end": 23}}, {"subject": {"text": "it", "start": 122, "end": 124, "i_start": 19, "i_end": 19}, "verb": {"text": "can be", "start": 125, "end": 131, "i_start": 20, "i_end": 21}}, {"character": {"text": "not involve", "start": 24, "end": 35, "i_start": 4, "i_end": 5}, "action": {"text": "because", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}], "id": 65}, {"sent": "we prove this theorem using a reduction from minimum feedback arc set , a wellknown np-complete problem .", "tokens": ["we", "prove", "this", "theorem", "using", "a", "reduction", "from", "minimum", "feedback", "arc", "set", ",", "a", "wellknown", "np", "-", "complete", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "prove", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "prove", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 66}, {"sent": "this bulging of the combined prior starts to resemble the 2 ball , and is in conflict with the geometrical structures known in the community to be necessary to favor sparse solutions .", "tokens": ["this", "bulging", "of", "the", "combined", "prior", "starts", "to", "resemble", "the", "2", "ball", ",", "and", "is", "in", "conflict", "with", "the", "geometrical", "structures", "known", "in", "the", "community", "to", "be", "necessary", "to", "favor", "sparse", "solutions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "bulging", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "starts", "start": 35, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "bulging", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "conflict", "start": 77, "end": 85, "i_start": 16, "i_end": 16}}, {"character": {"text": "bulging", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "favor", "start": 160, "end": 165, "i_start": 29, "i_end": 29}}, {"character": {"text": "community", "start": 131, "end": 140, "i_start": 24, "i_end": 24}, "action": {"text": "known", "start": 118, "end": 123, "i_start": 21, "i_end": 21}}], "id": 67}, {"sent": "it means that the approximation ignoring the turbulent fluctuations employed by traditional tran sition theories could overestimate the range where hysteresis is observed and statistical analyses are inevitably needed .", "tokens": ["it", "means", "that", "the", "approximation", "ignoring", "the", "turbulent", "fluctuations", "employed", "by", "traditional", "tran", "sition", "theories", "could", "overestimate", "the", "range", "where", "hysteresis", "is", "observed", "and", "statistical", "analyses", "are", "inevitably", "needed", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "means", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the approximation ignoring the turbulent fluctuations employed by traditional tran sition theories", "start": 14, "end": 112, "i_start": 3, "i_end": 14}, "verb": {"text": "overestimate", "start": 119, "end": 131, "i_start": 16, "i_end": 16}}, {"subject": {"text": "analyses", "start": 187, "end": 195, "i_start": 25, "i_end": 25}, "verb": {"text": "needed", "start": 211, "end": 217, "i_start": 28, "i_end": 28}}, {"character": {"text": "approximation", "start": 18, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "overestimate", "start": 119, "end": 131, "i_start": 16, "i_end": 16}}, {"character": {"text": "approximation", "start": 18, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "ignoring", "start": 32, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "theories", "start": 104, "end": 112, "i_start": 14, "i_end": 14}, "action": {"text": "employed", "start": 68, "end": 76, "i_start": 9, "i_end": 9}}], "id": 68}, {"sent": "solubilization of rat brain mitochondrial hexokinase by three .", "tokens": ["solubilization", "of", "rat", "brain", "mitochondrial", "hexokinase", "by", "three", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 69}, {"sent": "the shower selection criterion is the triggering of any four adjacent detectors in the course of time gate less than 3 2 ns .", "tokens": ["the", "shower", "selection", "criterion", "is", "the", "triggering", "of", "any", "four", "adjacent", "detectors", "in", "the", "course", "of", "time", "gate", "less", "than", "3", "2", "ns", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the shower selection criterion", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "four", "start": 56, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "detectors", "start": 70, "end": 79, "i_start": 11, "i_end": 11}}], "id": 70}, {"sent": "the simplex programs take as base region the standard simplex of eq .", "tokens": ["the", "simplex", "programs", "take", "as", "base", "region", "the", "standard", "simplex", "of", "eq", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the simplex programs", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "take", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "programs", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "take", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}], "id": 71}, {"sent": "convolutional neural networks have demonstrated impressive performance on computer vision tasks .", "tokens": ["convolutional", "neural", "networks", "have", "demonstrated", "impressive", "performance", "on", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 30, "end": 47, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 35, "end": 47, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 59, "end": 70, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 59, "end": 70, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 48, "end": 58, "i_start": 5, "i_end": 5}}], "id": 72}, {"sent": "perplexity is the exponential of the cross entropy , which we will define next .", "tokens": ["perplexity", "is", "the", "exponential", "of", "the", "cross", "entropy", ",", "which", "we", "will", "define", "next", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "perplexity", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 59, "end": 61, "i_start": 10, "i_end": 10}, "action": {"text": "define", "start": 67, "end": 73, "i_start": 12, "i_end": 12}}], "id": 73}, {"sent": "jie et al proposed a self-taught learning approach in which alternates between classifier training and online supportive sample harvesting .", "tokens": ["jie", "et", "al", "proposed", "a", "self", "-", "taught", "learning", "approach", "in", "which", "alternates", "between", "classifier", "training", "and", "online", "supportive", "sample", "harvesting", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "jie et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "jie", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "jie", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "taught", "start": 26, "end": 32, "i_start": 7, "i_end": 7}}, {"character": {"text": "approach", "start": 42, "end": 50, "i_start": 9, "i_end": 9}, "action": {"text": "alternates", "start": 60, "end": 70, "i_start": 12, "i_end": 12}}, {"character": {"text": "harvesting", "start": 128, "end": 138, "i_start": 20, "i_end": 20}, "action": {"text": "supportive", "start": 110, "end": 120, "i_start": 18, "i_end": 18}}], "id": 74}, {"sent": "other approaches in bipartite graphs include frequent closed itemset mining .", "tokens": ["other", "approaches", "in", "bipartite", "graphs", "include", "frequent", "closed", "itemset", "mining", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "other approaches in bipartite graphs", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "include", "start": 37, "end": 44, "i_start": 5, "i_end": 5}}], "id": 75}, {"sent": "a closely related area to our subproblem of choosing coordination leaders is leader election , where a group of agents has to jointly determine a leader .", "tokens": ["a", "closely", "related", "area", "to", "our", "subproblem", "of", "choosing", "coordination", "leaders", "is", "leader", "election", ",", "where", "a", "group", "of", "agents", "has", "to", "jointly", "determine", "a", "leader", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a closely related area to our subproblem of choosing coordination leaders", "start": 0, "end": 73, "i_start": 0, "i_end": 10}, "verb": {"text": "is", "start": 74, "end": 76, "i_start": 11, "i_end": 11}}, {"character": {"text": "group", "start": 103, "end": 108, "i_start": 17, "i_end": 17}, "action": {"text": "determine", "start": 134, "end": 143, "i_start": 23, "i_end": 23}}], "id": 76}, {"sent": "massive mimo and small cell are recognized as two key technologies for 5g wireless systems due to their great potential to enhance network capacity .", "tokens": ["massive", "mimo", "and", "small", "cell", "are", "recognized", "as", "two", "key", "technologies", "for", "5", "g", "wireless", "systems", "due", "to", "their", "great", "potential", "to", "enhance", "network", "capacity", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "massive mimo and small cell", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "are recognized", "start": 28, "end": 42, "i_start": 5, "i_end": 6}}, {"character": {"text": "cell", "start": 23, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "enhance", "start": 123, "end": 130, "i_start": 22, "i_end": 22}}, {"character": {"text": "massive", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "enhance", "start": 123, "end": 130, "i_start": 22, "i_end": 22}}, {"character": {"text": "small", "start": 17, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "enhance", "start": 123, "end": 130, "i_start": 22, "i_end": 22}}], "id": 77}, {"sent": "consistently with our bayesian methodology , rather than performing model selection we can account for uncertainty over models by combining them using bayesian model averaging .", "tokens": ["consistently", "with", "our", "bayesian", "methodology", ",", "rather", "than", "performing", "model", "selection", "we", "can", "account", "for", "uncertainty", "over", "models", "by", "combining", "them", "using", "bayesian", "model", "averaging", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 84, "end": 86, "i_start": 11, "i_end": 11}, "verb": {"text": "can account", "start": 87, "end": 98, "i_start": 12, "i_end": 13}}, {"character": {"text": "we", "start": 84, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "account", "start": 91, "end": 98, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 84, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "combining", "start": 130, "end": 139, "i_start": 19, "i_end": 19}}, {"character": {"text": "we", "start": 84, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "using", "start": 145, "end": 150, "i_start": 21, "i_end": 21}}, {"character": {"text": "we", "start": 84, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "performing", "start": 57, "end": 67, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 84, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "selection", "start": 74, "end": 83, "i_start": 10, "i_end": 10}}], "id": 78}, {"sent": "convolutional neural networks have achieved great success in grid structure data such as image and video .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "grid", "structure", "data", "such", "as", "image", "and", "video", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}], "id": 79}, {"sent": "complex networks are loosely defined as networks with non-trivial structure and dynamics , appearing in many real-world systems .", "tokens": ["complex", "networks", "are", "loosely", "defined", "as", "networks", "with", "non", "-", "trivial", "structure", "and", "dynamics", ",", "appearing", "in", "many", "real", "-", "world", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "complex networks", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "defined", "start": 29, "end": 36, "i_start": 4, "i_end": 4}}, {"subject": {"text": "complex networks", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 17, "end": 20, "i_start": 2, "i_end": 2}}], "id": 80}, {"sent": "rea , published by the investment company institute .", "tokens": ["rea", ",", "published", "by", "the", "investment", "company", "institute", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "company", "start": 34, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "investment", "start": 23, "end": 33, "i_start": 5, "i_end": 5}}], "id": 81}, {"sent": "community detection in large-scale social networks .", "tokens": ["community", "detection", "in", "large", "-", "scale", "social", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 82}, {"sent": "the olympic sports dataset was collected from youtube sequences and contains 16 different sports categories with 50 sequences per class .", "tokens": ["the", "olympic", "sports", "dataset", "was", "collected", "from", "youtube", "sequences", "and", "contains", "16", "different", "sports", "categories", "with", "50", "sequences", "per", "class", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the olympic sports dataset", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "was collected", "start": 27, "end": 40, "i_start": 4, "i_end": 5}}, {"subject": {"text": "the olympic sports dataset", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "contains", "start": 68, "end": 76, "i_start": 10, "i_end": 10}}, {"character": {"text": "collected", "start": 31, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "contains", "start": 68, "end": 76, "i_start": 10, "i_end": 10}}], "id": 83}, {"sent": "we optimize using a gradient descent approach starting from a randomly sampled code z .", "tokens": ["we", "optimize", "using", "a", "gradient", "descent", "approach", "starting", "from", "a", "randomly", "sampled", "code", "z", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "optimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 84}, {"sent": "we use batch normalization for regularization of fully connected layers .", "tokens": ["we", "use", "batch", "normalization", "for", "regularization", "of", "fully", "connected", "layers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 85}, {"sent": "a batch normalization layer are performed after each convolution layer consecutively .", "tokens": ["a", "batch", "normalization", "layer", "are", "performed", "after", "each", "convolution", "layer", "consecutively", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a batch normalization layer", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "are performed", "start": 28, "end": 41, "i_start": 4, "i_end": 5}}], "id": 86}, {"sent": "the modules are bonded to an aluminum strong-back that is mounted on the external support .", "tokens": ["the", "modules", "are", "bonded", "to", "an", "aluminum", "strong", "-", "back", "that", "is", "mounted", "on", "the", "external", "support", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the modules", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "are bonded", "start": 12, "end": 22, "i_start": 2, "i_end": 3}}], "id": 87}, {"sent": "farabet et al trained a multiscale convolutional network from raw pixels to extract dense features for assigning the label to each pixel .", "tokens": ["farabet", "et", "al", "trained", "a", "multiscale", "convolutional", "network", "from", "raw", "pixels", "to", "extract", "dense", "features", "for", "assigning", "the", "label", "to", "each", "pixel", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "farabet et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "trained", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "farabet", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "trained", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "network", "start": 49, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "extract", "start": 76, "end": 83, "i_start": 12, "i_end": 12}}, {"character": {"text": "network", "start": 49, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "assigning", "start": 103, "end": 112, "i_start": 16, "i_end": 16}}], "id": 88}, {"sent": "this non-locality is a reflection of the fact that at leading power in \u03bb the total momentum in such interactions is not conserved .", "tokens": ["this", "non", "-", "locality", "is", "a", "reflection", "of", "the", "fact", "that", "at", "leading", "power", "in", "\u03bb", "the", "total", "momentum", "in", "such", "interactions", "is", "not", "conserved", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this non-locality", "start": 0, "end": 17, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 4, "i_end": 4}}, {"character": {"text": "power", "start": 62, "end": 67, "i_start": 13, "i_end": 13}, "action": {"text": "leading", "start": 54, "end": 61, "i_start": 12, "i_end": 12}}], "id": 89}, {"sent": "for exchange and correlation we applied the gradient corrected approach using the generalized gradient approximation functional following the approach suggested by perdew-burke-ernzerhof .", "tokens": ["for", "exchange", "and", "correlation", "we", "applied", "the", "gradient", "corrected", "approach", "using", "the", "generalized", "gradient", "approximation", "functional", "following", "the", "approach", "suggested", "by", "perdew", "-", "burke", "-", "ernzerhof", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 29, "end": 31, "i_start": 4, "i_end": 4}, "verb": {"text": "applied", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "applied", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "using", "start": 72, "end": 77, "i_start": 10, "i_end": 10}}, {"character": {"text": "perdew", "start": 164, "end": 170, "i_start": 21, "i_end": 21}, "action": {"text": "suggested", "start": 151, "end": 160, "i_start": 19, "i_end": 19}}], "id": 90}, {"sent": "this geometry is a trumpet with curvature singularity at the origin of the coordinate system , and it is dual to the semi-infinite cigar .", "tokens": ["this", "geometry", "is", "a", "trumpet", "with", "curvature", "singularity", "at", "the", "origin", "of", "the", "coordinate", "system", ",", "and", "it", "is", "dual", "to", "the", "semi", "-", "infinite", "cigar", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this geometry", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 91}, {"sent": "the interplay between the lhc and lc could be qualitatively rather different in different regions of the mssm parameter space .", "tokens": ["the", "interplay", "between", "the", "lhc", "and", "lc", "could", "be", "qualitatively", "rather", "different", "in", "different", "regions", "of", "the", "mssm", "parameter", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the interplay between the lhc and lc", "start": 0, "end": 36, "i_start": 0, "i_end": 6}, "verb": {"text": "could be", "start": 37, "end": 45, "i_start": 7, "i_end": 8}}], "id": 92}, {"sent": "the masslessness of the dirac fermion is protected by the quantum order and the associated psg .", "tokens": ["the", "masslessness", "of", "the", "dirac", "fermion", "is", "protected", "by", "the", "quantum", "order", "and", "the", "associated", "psg", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the masslessness of the dirac fermion", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "is protected", "start": 38, "end": 50, "i_start": 6, "i_end": 7}}, {"character": {"text": "order", "start": 66, "end": 71, "i_start": 11, "i_end": 11}, "action": {"text": "protected", "start": 41, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "quantum", "start": 58, "end": 65, "i_start": 10, "i_end": 10}, "action": {"text": "protected", "start": 41, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "psg", "start": 91, "end": 94, "i_start": 15, "i_end": 15}, "action": {"text": "protected", "start": 41, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "quantum", "start": 58, "end": 65, "i_start": 10, "i_end": 10}, "action": {"text": "protected", "start": 41, "end": 50, "i_start": 7, "i_end": 7}}], "id": 93}, {"sent": "the clump consists of a mixture of red helium burning stars and rgb stars of different ages .", "tokens": ["the", "clump", "consists", "of", "a", "mixture", "of", "red", "helium", "burning", "stars", "and", "rgb", "stars", "of", "different", "ages", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the clump", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 10, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "stars", "start": 54, "end": 59, "i_start": 10, "i_end": 10}, "action": {"text": "burning", "start": 46, "end": 53, "i_start": 9, "i_end": 9}}], "id": 94}, {"sent": "deep convolutional neural networks have been successful in many computer vision tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successful", "in", "many", "computer", "vision", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "successful", "start": 45, "end": 55, "i_start": 6, "i_end": 6}}], "id": 95}, {"sent": "the ellipsis denotes higher order contributions to vortex interactions .", "tokens": ["the", "ellipsis", "denotes", "higher", "order", "contributions", "to", "vortex", "interactions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ellipsis", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "denotes", "start": 13, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "ellipsis", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denotes", "start": 13, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "vortex", "start": 51, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "interactions", "start": 58, "end": 70, "i_start": 8, "i_end": 8}}], "id": 96}, {"sent": "deep neural networks achieve state-of-the-art performance in a variety of domains including image classification , machine translation , and text-to-speech .", "tokens": ["deep", "neural", "networks", "achieve", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "a", "variety", "of", "domains", "including", "image", "classification", ",", "machine", "translation", ",", "and", "text", "-", "to", "-", "speech", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "achieve", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 46, "end": 57, "i_start": 11, "i_end": 11}}], "id": 97}, {"sent": "moreover , residual learning is a powerful technique proposed to train very deep convolutional neural network .", "tokens": ["moreover", ",", "residual", "learning", "is", "a", "powerful", "technique", "proposed", "to", "train", "very", "deep", "convolutional", "neural", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "residual learning", "start": 11, "end": 28, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 4, "i_end": 4}}], "id": 98}, {"sent": "these nanoblocks combine dna grafted particles with more complicated purely dna based constructs .", "tokens": ["these", "nanoblocks", "combine", "dna", "grafted", "particles", "with", "more", "complicated", "purely", "dna", "based", "constructs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "these nanoblocks", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "combine", "start": 17, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "nanoblocks", "start": 6, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "combine", "start": 17, "end": 24, "i_start": 2, "i_end": 2}}], "id": 99}, {"sent": "when the target space is a twistor space these deformations are mapped to fluctuations of the metric , ie perturbative states of gravity .", "tokens": ["when", "the", "target", "space", "is", "a", "twistor", "space", "these", "deformations", "are", "mapped", "to", "fluctuations", "of", "the", "metric", ",", "ie", "perturbative", "states", "of", "gravity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the target space", "start": 5, "end": 21, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}], "id": 100}, {"sent": "deep neural networks have demonstrated significant performance improvements in a wide range of computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "significant", "performance", "improvements", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improvements", "start": 63, "end": 75, "i_start": 7, "i_end": 7}}], "id": 101}, {"sent": "it as been proved that this approach is the only one that preserves altitudes of the passes between regions of the segmentation .", "tokens": ["it", "as", "been", "proved", "that", "this", "approach", "is", "the", "only", "one", "that", "preserves", "altitudes", "of", "the", "passes", "between", "regions", "of", "the", "segmentation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "been proved", "start": 6, "end": 17, "i_start": 2, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 37, "end": 39, "i_start": 7, "i_end": 7}}, {"character": {"text": "approach", "start": 28, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "preserves", "start": 58, "end": 67, "i_start": 12, "i_end": 12}}], "id": 102}, {"sent": "by sharing features between proposal generation and classification , r-c3d reduces computational cost significantly .", "tokens": ["by", "sharing", "features", "between", "proposal", "generation", "and", "classification", ",", "r", "-", "c3d", "reduces", "computational", "cost", "significantly", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "r-c3d", "start": 69, "end": 74, "i_start": 9, "i_end": 11}, "verb": {"text": "reduces", "start": 75, "end": 82, "i_start": 12, "i_end": 12}}], "id": 103}, {"sent": "to the extent that these are valid assumptions , we obtain the correct two-photon amplitudes and can obtain the corrected form factors .", "tokens": ["to", "the", "extent", "that", "these", "are", "valid", "assumptions", ",", "we", "obtain", "the", "correct", "two", "-", "photon", "amplitudes", "and", "can", "obtain", "the", "corrected", "form", "factors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "verb": {"text": "obtain", "start": 52, "end": 58, "i_start": 10, "i_end": 10}}, {"subject": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "verb": {"text": "obtain", "start": 101, "end": 107, "i_start": 19, "i_end": 19}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "action": {"text": "obtain", "start": 52, "end": 58, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "action": {"text": "obtain", "start": 101, "end": 107, "i_start": 19, "i_end": 19}}], "id": 104}, {"sent": "recently , deep neural networks have substantially improved the state-of-the-art performances of various challenging classification tasks , including image based object recognition .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "substantially", "improved", "the", "state", "-", "of", "-", "the", "-", "art", "performances", "of", "various", "challenging", "classification", "tasks", ",", "including", "image", "based", "object", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "improved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have", "start": 32, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "improved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "performances", "start": 81, "end": 93, "i_start": 16, "i_end": 16}}, {"character": {"text": "tasks", "start": 132, "end": 137, "i_start": 21, "i_end": 21}, "action": {"text": "classification", "start": 117, "end": 131, "i_start": 20, "i_end": 20}}], "id": 105}, {"sent": "the parafermion and paraboson fock spaces are characterized by a parameter p , and their explicit construction was given recently in and in .", "tokens": ["the", "parafermion", "and", "paraboson", "fock", "spaces", "are", "characterized", "by", "a", "parameter", "p", ",", "and", "their", "explicit", "construction", "was", "given", "recently", "in", "and", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the parafermion and paraboson fock spaces", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "are characterized", "start": 42, "end": 59, "i_start": 6, "i_end": 7}}, {"subject": {"text": "their explicit construction", "start": 83, "end": 110, "i_start": 14, "i_end": 16}, "verb": {"text": "given", "start": 115, "end": 120, "i_start": 18, "i_end": 18}}], "id": 106}, {"sent": "two of the most commonly used and efficient approaches are vae and generative adversarial networks .", "tokens": ["two", "of", "the", "most", "commonly", "used", "and", "efficient", "approaches", "are", "vae", "and", "generative", "adversarial", "networks", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "two of the most commonly used and efficient approaches", "start": 0, "end": 54, "i_start": 0, "i_end": 8}, "verb": {"text": "are", "start": 55, "end": 58, "i_start": 9, "i_end": 9}}], "id": 107}, {"sent": "recently , convolutional neural networks are driving advances in computer vision , such as for image classification .", "tokens": ["recently", ",", "convolutional", "neural", "networks", "are", "driving", "advances", "in", "computer", "vision", ",", "such", "as", "for", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 11, "end": 40, "i_start": 2, "i_end": 4}, "verb": {"text": "are driving", "start": 41, "end": 52, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "driving", "start": 45, "end": 52, "i_start": 6, "i_end": 6}}], "id": 108}, {"sent": "artificial neural networks are a powerful tool in machine learning and have been successfully applied to many problems in fields such as computer vision .", "tokens": ["artificial", "neural", "networks", "are", "a", "powerful", "tool", "in", "machine", "learning", "and", "have", "been", "successfully", "applied", "to", "many", "problems", "in", "fields", "such", "as", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "artificial neural networks", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 27, "end": 30, "i_start": 3, "i_end": 3}}, {"subject": {"text": "artificial neural networks", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "applied", "start": 94, "end": 101, "i_start": 14, "i_end": 14}}], "id": 109}, {"sent": "the exact quantum effective superpotential for the glueball field was proposed by dijkgraaf and vafa using a zero-dimensional matrix model .", "tokens": ["the", "exact", "quantum", "effective", "superpotential", "for", "the", "glueball", "field", "was", "proposed", "by", "dijkgraaf", "and", "vafa", "using", "a", "zero", "-", "dimensional", "matrix", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "dijkgraaf", "start": 82, "end": 91, "i_start": 12, "i_end": 12}, "action": {"text": "proposed", "start": 70, "end": 78, "i_start": 10, "i_end": 10}}, {"character": {"text": "vafa", "start": 96, "end": 100, "i_start": 14, "i_end": 14}, "action": {"text": "proposed", "start": 70, "end": 78, "i_start": 10, "i_end": 10}}], "id": 110}, {"sent": "information geometry and statistical pattern recognition .", "tokens": ["information", "geometry", "and", "statistical", "pattern", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 111}, {"sent": "zou et al designed an intensity-difference measuring function to find the optimal threshold for pavement crack segmentation .", "tokens": ["zou", "et", "al", "designed", "an", "intensity", "-", "difference", "measuring", "function", "to", "find", "the", "optimal", "threshold", "for", "pavement", "crack", "segmentation", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 4, "end": 9, "i_start": 1, "i_end": 2}, "verb": {"text": "designed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "zou", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "designed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "zou", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 65, "end": 69, "i_start": 11, "i_end": 11}}], "id": 112}, {"sent": "as for the existence for general pseudoeffective line bundles , now we have the following theorem .", "tokens": ["as", "for", "the", "existence", "for", "general", "pseudoeffective", "line", "bundles", ",", "now", "we", "have", "the", "following", "theorem", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 68, "end": 70, "i_start": 11, "i_end": 11}, "verb": {"text": "have", "start": 71, "end": 75, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 68, "end": 70, "i_start": 11, "i_end": 11}, "action": {"text": "have", "start": 71, "end": 75, "i_start": 12, "i_end": 12}}], "id": 113}, {"sent": "convolutional neural networks have proven to be effective models for tackling a variety of visual tasks .", "tokens": ["convolutional", "neural", "networks", "have", "proven", "to", "be", "effective", "models", "for", "tackling", "a", "variety", "of", "visual", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have proven", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "models", "start": 58, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "effective", "start": 48, "end": 57, "i_start": 7, "i_end": 7}}], "id": 114}, {"sent": "the pioneering work is semantic hashing , which uses stacked rbm models to learn compact binary representations .", "tokens": ["the", "pioneering", "work", "is", "semantic", "hashing", ",", "which", "uses", "stacked", "rbm", "models", "to", "learn", "compact", "binary", "representations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the pioneering work", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "hashing", "start": 32, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "pioneering", "start": 4, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "hashing", "start": 32, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "uses", "start": 48, "end": 52, "i_start": 8, "i_end": 8}}], "id": 115}, {"sent": "the major mechanism of dephasing due to coupling to excitations in helium is scattering of thermal ripplons off an electron .", "tokens": ["the", "major", "mechanism", "of", "dephasing", "due", "to", "coupling", "to", "excitations", "in", "helium", "is", "scattering", "of", "thermal", "ripplons", "off", "an", "electron", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the major mechanism of dephasing due to coupling to excitations in helium", "start": 0, "end": 73, "i_start": 0, "i_end": 11}, "verb": {"text": "is scattering", "start": 74, "end": 87, "i_start": 12, "i_end": 13}}, {"character": {"text": "helium", "start": 67, "end": 73, "i_start": 11, "i_end": 11}, "action": {"text": "excitations", "start": 52, "end": 63, "i_start": 9, "i_end": 9}}], "id": 116}, {"sent": "in addition , as demonstrated in , llr clipping , when built into the tree search also allows to tune the detection algorithm in terms of performance versus complexity by adjusting the llr clipping level .", "tokens": ["in", "addition", ",", "as", "demonstrated", "in", ",", "llr", "clipping", ",", "when", "built", "into", "the", "tree", "search", "also", "allows", "to", "tune", "the", "detection", "algorithm", "in", "terms", "of", "performance", "versus", "complexity", "by", "adjusting", "the", "llr", "clipping", "level", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "tune", "start": 97, "end": 101, "i_start": 19, "i_end": 19}, "action": {"text": "allows", "start": 87, "end": 93, "i_start": 17, "i_end": 17}}, {"character": {"text": "algorithm", "start": 116, "end": 125, "i_start": 22, "i_end": 22}, "action": {"text": "detection", "start": 106, "end": 115, "i_start": 21, "i_end": 21}}, {"character": {"text": "clipping", "start": 39, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "demonstrated", "start": 17, "end": 29, "i_start": 4, "i_end": 4}}], "id": 117}, {"sent": "sparse recovery is one of the essential issues in many fields of signal processing , including compressive sampling , which is a novel sampling theory .", "tokens": ["sparse", "recovery", "is", "one", "of", "the", "essential", "issues", "in", "many", "fields", "of", "signal", "processing", ",", "including", "compressive", "sampling", ",", "which", "is", "a", "novel", "sampling", "theory", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "sparse recovery", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "recovery", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "issues", "start": 40, "end": 46, "i_start": 7, "i_end": 7}}], "id": 118}, {"sent": "physical layer security has been recently proposed as a complement to cryptography method to provide secure wireless communications .", "tokens": ["physical", "layer", "security", "has", "been", "recently", "proposed", "as", "a", "complement", "to", "cryptography", "method", "to", "provide", "secure", "wireless", "communications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "physical layer security", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 42, "end": 50, "i_start": 6, "i_end": 6}}, {"subject": {"text": "physical layer security", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "has been", "start": 24, "end": 32, "i_start": 3, "i_end": 4}}], "id": 119}, {"sent": "a recent survey of coordinate descent algorithms and their convergence can be found in .", "tokens": ["a", "recent", "survey", "of", "coordinate", "descent", "algorithms", "and", "their", "convergence", "can", "be", "found", "in", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "a recent survey of coordinate descent algorithms and their convergence", "start": 0, "end": 70, "i_start": 0, "i_end": 9}, "verb": {"text": "can be found", "start": 71, "end": 83, "i_start": 10, "i_end": 12}}, {"character": {"text": "algorithms", "start": 38, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "convergence", "start": 59, "end": 70, "i_start": 9, "i_end": 9}}], "id": 120}, {"sent": "closure is a well-defined operation on semialgebraic chains .", "tokens": ["closure", "is", "a", "well", "-", "defined", "operation", "on", "semialgebraic", "chains", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "closure", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}], "id": 121}, {"sent": "convolutional neural networks have shown remarkable performance in domains like vision and nlp .", "tokens": ["convolutional", "neural", "networks", "have", "shown", "remarkable", "performance", "in", "domains", "like", "vision", "and", "nlp", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 35, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 52, "end": 63, "i_start": 6, "i_end": 6}}], "id": 122}, {"sent": "papernot et al introduced distillation as a defense to adversarial examples .", "tokens": ["papernot", "et", "al", "introduced", "distillation", "as", "a", "defense", "to", "adversarial", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "papernot et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "introduced", "start": 15, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "papernot", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 15, "end": 25, "i_start": 3, "i_end": 3}}], "id": 123}, {"sent": "a qubit is a physical entity described by the laws of quantum mechanics .", "tokens": ["a", "qubit", "is", "a", "physical", "entity", "described", "by", "the", "laws", "of", "quantum", "mechanics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a qubit", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 2, "i_end": 2}}, {"character": {"text": "laws", "start": 46, "end": 50, "i_start": 9, "i_end": 9}, "action": {"text": "described", "start": 29, "end": 38, "i_start": 6, "i_end": 6}}], "id": 124}, {"sent": "deep neural networks have demonstrated success in many machine learning tasks , including image recognition , speech recognition , and even modelling mathematical learning , among many other domains .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "success", "in", "many", "machine", "learning", "tasks", ",", "including", "image", "recognition", ",", "speech", "recognition", ",", "and", "even", "modelling", "mathematical", "learning", ",", "among", "many", "other", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 39, "end": 46, "i_start": 5, "i_end": 5}}], "id": 125}, {"sent": "we used the large scale visual recognition challenge 2012 dataset , which is widely employed and easily accessible .", "tokens": ["we", "used", "the", "large", "scale", "visual", "recognition", "challenge", "2012", "dataset", ",", "which", "is", "widely", "employed", "and", "easily", "accessible", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 126}, {"sent": "the generalized gradient approximation parameterized by perdew-burkeernzerhof for the exchange-correlation functional was used .", "tokens": ["the", "generalized", "gradient", "approximation", "parameterized", "by", "perdew", "-", "burkeernzerhof", "for", "the", "exchange", "-", "correlation", "functional", "was", "used", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation parameterized by perdew-burkeernzerhof for the exchange-correlation functional", "start": 0, "end": 117, "i_start": 0, "i_end": 14}, "verb": {"text": "was used", "start": 118, "end": 126, "i_start": 15, "i_end": 16}}, {"character": {"text": "perdew", "start": 56, "end": 62, "i_start": 6, "i_end": 6}, "action": {"text": "parameterized", "start": 39, "end": 52, "i_start": 4, "i_end": 4}}], "id": 127}, {"sent": "the result particularly helps us to prove the equivalence of the two functions in the previous example , as we can show that they are trace equivalent .", "tokens": ["the", "result", "particularly", "helps", "us", "to", "prove", "the", "equivalence", "of", "the", "two", "functions", "in", "the", "previous", "example", ",", "as", "we", "can", "show", "that", "they", "are", "trace", "equivalent", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the result", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "helps", "start": 24, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 30, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "prove", "start": 36, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "us", "start": 30, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "show", "start": 115, "end": 119, "i_start": 21, "i_end": 21}}], "id": 128}, {"sent": "the dft calculations were carried out by using the projector augmented wave method implemented in the vienna ab initio simulation package .", "tokens": ["the", "dft", "calculations", "were", "carried", "out", "by", "using", "the", "projector", "augmented", "wave", "method", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dft calculations", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "were carried out", "start": 21, "end": 37, "i_start": 3, "i_end": 5}}, {"character": {"text": "projector", "start": 51, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "augmented", "start": 61, "end": 70, "i_start": 10, "i_end": 10}}], "id": 129}, {"sent": "conway-gordon showed that k 6 is intrinsically linked , where k n denotes the complete graph on n vertices .", "tokens": ["conway", "-", "gordon", "showed", "that", "k", "6", "is", "intrinsically", "linked", ",", "where", "k", "n", "denotes", "the", "complete", "graph", "on", "n", "vertices", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "conway-gordon", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 14, "end": 20, "i_start": 3, "i_end": 3}}, {"subject": {"text": "k 6", "start": 26, "end": 29, "i_start": 5, "i_end": 6}, "verb": {"text": "linked", "start": 47, "end": 53, "i_start": 9, "i_end": 9}}, {"character": {"text": "conway", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 14, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "graph", "start": 87, "end": 92, "i_start": 17, "i_end": 17}, "action": {"text": "denotes", "start": 66, "end": 73, "i_start": 14, "i_end": 14}}], "id": 130}, {"sent": "the networks were trained through stochastic gradient descent , using the adam optimizer .", "tokens": ["the", "networks", "were", "trained", "through", "stochastic", "gradient", "descent", ",", "using", "the", "adam", "optimizer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the networks", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "were trained", "start": 13, "end": 25, "i_start": 2, "i_end": 3}}], "id": 131}, {"sent": "in this way it seems that the type of temporal description of physical processes we have at the classical level can not be seen as emerging from the quantum level of description .", "tokens": ["in", "this", "way", "it", "seems", "that", "the", "type", "of", "temporal", "description", "of", "physical", "processes", "we", "have", "at", "the", "classical", "level", "can", "not", "be", "seen", "as", "emerging", "from", "the", "quantum", "level", "of", "description", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 12, "end": 14, "i_start": 3, "i_end": 3}, "verb": {"text": "seems", "start": 15, "end": 20, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the type of temporal description of physical processes we have at the classical level", "start": 26, "end": 111, "i_start": 6, "i_end": 19}, "verb": {"text": "seen", "start": 123, "end": 127, "i_start": 23, "i_end": 23}}, {"character": {"text": "description", "start": 47, "end": 58, "i_start": 10, "i_end": 10}, "action": {"text": "emerging", "start": 131, "end": 139, "i_start": 25, "i_end": 25}}, {"character": {"text": "we", "start": 81, "end": 83, "i_start": 14, "i_end": 14}, "action": {"text": "have", "start": 84, "end": 88, "i_start": 15, "i_end": 15}}], "id": 132}, {"sent": "in hermitian systems , the winding number has been directly measured by the mean chiral displacement in photonic quantum walks .", "tokens": ["in", "hermitian", "systems", ",", "the", "winding", "number", "has", "been", "directly", "measured", "by", "the", "mean", "chiral", "displacement", "in", "photonic", "quantum", "walks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the winding number", "start": 23, "end": 41, "i_start": 4, "i_end": 6}, "verb": {"text": "measured", "start": 60, "end": 68, "i_start": 10, "i_end": 10}}, {"subject": {"text": "the winding number", "start": 23, "end": 41, "i_start": 4, "i_end": 6}, "verb": {"text": "has been", "start": 42, "end": 50, "i_start": 7, "i_end": 8}}], "id": 133}, {"sent": "a robust and widely used method for discovering topics is latent dirichlet allocation .", "tokens": ["a", "robust", "and", "widely", "used", "method", "for", "discovering", "topics", "is", "latent", "dirichlet", "allocation", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a robust and widely used method for discovering topics", "start": 0, "end": 54, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 55, "end": 57, "i_start": 9, "i_end": 9}}], "id": 134}, {"sent": "we also use an adversarial loss to approximate the distribution of optical flow .", "tokens": ["we", "also", "use", "an", "adversarial", "loss", "to", "approximate", "the", "distribution", "of", "optical", "flow", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "approximate", "start": 35, "end": 46, "i_start": 7, "i_end": 7}}], "id": 135}, {"sent": "deep learning has increasingly drawn attentions in many research fields , such as speech recognition .", "tokens": ["deep", "learning", "has", "increasingly", "drawn", "attentions", "in", "many", "research", "fields", ",", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "drawn", "start": 31, "end": 36, "i_start": 4, "i_end": 4}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has", "start": 14, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "drawn", "start": 31, "end": 36, "i_start": 4, "i_end": 4}}], "id": 136}, {"sent": "such an effective theory is known as chiral perturbation theory .", "tokens": ["such", "an", "effective", "theory", "is", "known", "as", "chiral", "perturbation", "theory", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "such an effective theory", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "is known", "start": 25, "end": 33, "i_start": 4, "i_end": 5}}, {"character": {"text": "theory", "start": 18, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "effective", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}], "id": 137}, {"sent": "a fictitious domain method for dirichlet problem and applications .", "tokens": ["a", "fictitious", "domain", "method", "for", "dirichlet", "problem", "and", "applications", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 138}, {"sent": "the malcev closure g of \u03b3 is a simply connected nilpotent lie group in which \u03b3 embeds as a uniform lattice .", "tokens": ["the", "malcev", "closure", "g", "of", "\u03b3", "is", "a", "simply", "connected", "nilpotent", "lie", "group", "in", "which", "\u03b3", "embeds", "as", "a", "uniform", "lattice", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the malcev closure g of \u03b3", "start": 0, "end": 25, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 6, "i_end": 6}}], "id": 139}, {"sent": "to have fair comparisons with the previous methods , we use the pre-trained vgg-16 as visual cnn , respectively .", "tokens": ["to", "have", "fair", "comparisons", "with", "the", "previous", "methods", ",", "we", "use", "the", "pre", "-", "trained", "vgg-16", "as", "visual", "cnn", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 53, "end": 55, "i_start": 9, "i_end": 9}, "verb": {"text": "use", "start": 56, "end": 59, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 53, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "use", "start": 56, "end": 59, "i_start": 10, "i_end": 10}}], "id": 140}, {"sent": "the outer error bars represent the systematic and model errors .", "tokens": ["the", "outer", "error", "bars", "represent", "the", "systematic", "and", "model", "errors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the outer error bars", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "represent", "start": 21, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "bars", "start": 16, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "represent", "start": 21, "end": 30, "i_start": 4, "i_end": 4}}], "id": 141}, {"sent": "for instance , it was shown recently in a group of subjects of different age , that the bold signal standard deviation can be a better predictor of the subject age than the average .", "tokens": ["for", "instance", ",", "it", "was", "shown", "recently", "in", "a", "group", "of", "subjects", "of", "different", "age", ",", "that", "the", "bold", "signal", "standard", "deviation", "can", "be", "a", "better", "predictor", "of", "the", "subject", "age", "than", "the", "average", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "was shown", "start": 18, "end": 27, "i_start": 4, "i_end": 5}}, {"subject": {"text": "it", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "be", "start": 123, "end": 125, "i_start": 23, "i_end": 23}}, {"character": {"text": "standard", "start": 100, "end": 108, "i_start": 20, "i_end": 20}, "action": {"text": "predictor", "start": 135, "end": 144, "i_start": 26, "i_end": 26}}], "id": 142}, {"sent": "poisson and symplectic groupoids were introduced by weinstein in in the late eighties .", "tokens": ["poisson", "and", "symplectic", "groupoids", "were", "introduced", "by", "weinstein", "in", "in", "the", "late", "eighties", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "poisson and symplectic groupoids", "start": 0, "end": 32, "i_start": 0, "i_end": 3}, "verb": {"text": "were introduced", "start": 33, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "weinstein", "start": 52, "end": 61, "i_start": 7, "i_end": 7}, "action": {"text": "introduced", "start": 38, "end": 48, "i_start": 5, "i_end": 5}}], "id": 143}, {"sent": "we shall also provide new results for the unquenched theory in the same finite-volume regime , but restricted to fixed topology .", "tokens": ["we", "shall", "also", "provide", "new", "results", "for", "the", "unquenched", "theory", "in", "the", "same", "finite", "-", "volume", "regime", ",", "but", "restricted", "to", "fixed", "topology", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "provide", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "shall", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "restricted", "start": 99, "end": 109, "i_start": 19, "i_end": 19}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "provide", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}], "id": 144}, {"sent": "images were processed using the miriad 5 software package .", "tokens": ["images", "were", "processed", "using", "the", "miriad", "5", "software", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "images", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "were processed", "start": 7, "end": 21, "i_start": 1, "i_end": 2}}], "id": 145}, {"sent": "the insets show the shape of the linear modes with highest and lowest frequency .", "tokens": ["the", "insets", "show", "the", "shape", "of", "the", "linear", "modes", "with", "highest", "and", "lowest", "frequency", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the insets", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "show", "start": 11, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "insets", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 11, "end": 15, "i_start": 2, "i_end": 2}}], "id": 146}, {"sent": "in the riemannian case we consider an electrostatic spacetime where the einstein equations in vacuum in the approximation of linear fields .", "tokens": ["in", "the", "riemannian", "case", "we", "consider", "an", "electrostatic", "spacetime", "where", "the", "einstein", "equations", "in", "vacuum", "in", "the", "approximation", "of", "linear", "fields", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "verb": {"text": "consider", "start": 26, "end": 34, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "consider", "start": 26, "end": 34, "i_start": 5, "i_end": 5}}], "id": 147}, {"sent": "tractable learning of large bayes net structures from sparse data .", "tokens": ["tractable", "learning", "of", "large", "bayes", "net", "structures", "from", "sparse", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 148}, {"sent": "a d-brane is a u gauge theory living on a subspace with scalar fields spanning the normal bundle .", "tokens": ["a", "d", "-", "brane", "is", "a", "u", "gauge", "theory", "living", "on", "a", "subspace", "with", "scalar", "fields", "spanning", "the", "normal", "bundle", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "d-brane", "start": 2, "end": 9, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 4, "i_end": 4}}, {"character": {"text": "fields", "start": 63, "end": 69, "i_start": 15, "i_end": 15}, "action": {"text": "spanning", "start": 70, "end": 78, "i_start": 16, "i_end": 16}}], "id": 149}, {"sent": "local boundedness of nonlinear , monotone operators .", "tokens": ["local", "boundedness", "of", "nonlinear", ",", "monotone", "operators", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 150}, {"sent": "it was introduced by the forth author in 2004 based on the joint research with steven seif on the celebrated perkins semigroup , which has played a central role in semigroup theory since 1960 , particularly as a source of examples and counterexamples .", "tokens": ["it", "was", "introduced", "by", "the", "forth", "author", "in", "2004", "based", "on", "the", "joint", "research", "with", "steven", "seif", "on", "the", "celebrated", "perkins", "semigroup", ",", "which", "has", "played", "a", "central", "role", "in", "semigroup", "theory", "since", "1960", ",", "particularly", "as", "a", "source", "of", "examples", "and", "counterexamples", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "was introduced", "start": 3, "end": 17, "i_start": 1, "i_end": 2}}, {"character": {"text": "steven seif", "start": 79, "end": 90, "i_start": 15, "i_end": 16}, "action": {"text": "research", "start": 65, "end": 73, "i_start": 13, "i_end": 13}}, {"character": {"text": "semigroup", "start": 117, "end": 126, "i_start": 21, "i_end": 21}, "action": {"text": "played", "start": 139, "end": 145, "i_start": 25, "i_end": 25}}, {"character": {"text": "semigroup", "start": 117, "end": 126, "i_start": 21, "i_end": 21}, "action": {"text": "source", "start": 212, "end": 218, "i_start": 38, "i_end": 38}}], "id": 151}, {"sent": "lastly , we discuss the universal behavior shown by persistence in various stochastic models belonging to the directed percolation universality class .", "tokens": ["lastly", ",", "we", "discuss", "the", "universal", "behavior", "shown", "by", "persistence", "in", "various", "stochastic", "models", "belonging", "to", "the", "directed", "percolation", "universality", "class", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "verb": {"text": "discuss", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "action": {"text": "discuss", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "persistence", "start": 52, "end": 63, "i_start": 9, "i_end": 9}, "action": {"text": "shown", "start": 43, "end": 48, "i_start": 7, "i_end": 7}}, {"character": {"text": "models", "start": 86, "end": 92, "i_start": 13, "i_end": 13}, "action": {"text": "persistence", "start": 52, "end": 63, "i_start": 9, "i_end": 9}}, {"character": {"text": "models", "start": 86, "end": 92, "i_start": 13, "i_end": 13}, "action": {"text": "belonging", "start": 93, "end": 102, "i_start": 14, "i_end": 14}}], "id": 152}, {"sent": "cluster algebras were introduced by fomin and zelevinsky in the context of canonical bases .", "tokens": ["cluster", "algebras", "were", "introduced", "by", "fomin", "and", "zelevinsky", "in", "the", "context", "of", "canonical", "bases", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were introduced", "start": 17, "end": 32, "i_start": 2, "i_end": 3}}, {"character": {"text": "fomin", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "zelevinsky", "start": 46, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}], "id": 153}, {"sent": "however , as detailed in section v , very few studies include the chip package in their simulations or measurements and , those that do it , are limited to low frequencies or lack proper justifications on the antenna type and placement .", "tokens": ["however", ",", "as", "detailed", "in", "section", "v", ",", "very", "few", "studies", "include", "the", "chip", "package", "in", "their", "simulations", "or", "measurements", "and", ",", "those", "that", "do", "it", ",", "are", "limited", "to", "low", "frequencies", "or", "lack", "proper", "justifications", "on", "the", "antenna", "type", "and", "placement", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "very few studies", "start": 37, "end": 53, "i_start": 8, "i_end": 10}, "verb": {"text": "include", "start": 54, "end": 61, "i_start": 11, "i_end": 11}}, {"subject": {"text": "those that do it", "start": 122, "end": 138, "i_start": 22, "i_end": 25}, "verb": {"text": "limited", "start": 145, "end": 152, "i_start": 28, "i_end": 28}}, {"character": {"text": "studies", "start": 46, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "include", "start": 54, "end": 61, "i_start": 11, "i_end": 11}}, {"character": {"text": "studies", "start": 46, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "simulations", "start": 88, "end": 99, "i_start": 17, "i_end": 17}}, {"character": {"text": "studies", "start": 46, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "measurements", "start": 103, "end": 115, "i_start": 19, "i_end": 19}}], "id": 154}, {"sent": "iii , we compare our results with the available experimental data and close with conclusions .", "tokens": ["iii", ",", "we", "compare", "our", "results", "with", "the", "available", "experimental", "data", "and", "close", "with", "conclusions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "verb": {"text": "compare", "start": 9, "end": 16, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "verb": {"text": "close", "start": 70, "end": 75, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "compare", "start": 9, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "close", "start": 70, "end": 75, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "conclusions", "start": 81, "end": 92, "i_start": 14, "i_end": 14}}], "id": 155}, {"sent": "we will illustrate this situation by some examples .", "tokens": ["we", "will", "illustrate", "this", "situation", "by", "some", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will illustrate", "start": 3, "end": 18, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "illustrate", "start": 8, "end": 18, "i_start": 2, "i_end": 2}}], "id": 156}, {"sent": "han et al proposed the pruning approach for removing subtle weights in pre-trained neural networks .", "tokens": ["han", "et", "al", "proposed", "the", "pruning", "approach", "for", "removing", "subtle", "weights", "in", "pre", "-", "trained", "neural", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "han et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "han", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}], "id": 157}, {"sent": "one of the most important extensions of the concept of li-yorke chaos is distributional chaos introduced in .", "tokens": ["one", "of", "the", "most", "important", "extensions", "of", "the", "concept", "of", "li", "-", "yorke", "chaos", "is", "distributional", "chaos", "introduced", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "one of the most important extensions of the concept of li-yorke chaos", "start": 0, "end": 69, "i_start": 0, "i_end": 13}, "verb": {"text": "is", "start": 70, "end": 72, "i_start": 14, "i_end": 14}}], "id": 158}, {"sent": "the spin-polarized density functional theory calculations were carried out by using the projector augmented wave method 26 , 27 as implemented in the vienna ab initio simulation package .", "tokens": ["the", "spin", "-", "polarized", "density", "functional", "theory", "calculations", "were", "carried", "out", "by", "using", "the", "projector", "augmented", "wave", "method", "26", ",", "27", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the spin-polarized density functional theory calculations", "start": 0, "end": 57, "i_start": 0, "i_end": 7}, "verb": {"text": "were carried out", "start": 58, "end": 74, "i_start": 8, "i_end": 10}}, {"character": {"text": "projector", "start": 88, "end": 97, "i_start": 14, "i_end": 14}, "action": {"text": "augmented", "start": 98, "end": 107, "i_start": 15, "i_end": 15}}], "id": 159}, {"sent": "recently , deep neural networks achieve excellent performance on difficult problems such as speech recognition .", "tokens": ["recently", ",", "deep", "neural", "networks", "achieve", "excellent", "performance", "on", "difficult", "problems", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "achieve", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "achieve", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "performance", "start": 50, "end": 61, "i_start": 7, "i_end": 7}}], "id": 160}, {"sent": "now we proceed onto define type ii polynomial groupoids .", "tokens": ["now", "we", "proceed", "onto", "define", "type", "ii", "polynomial", "groupoids", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 20, "end": 26, "i_start": 4, "i_end": 4}}], "id": 161}, {"sent": "the idea is similar to deep domain confusion and deep adaptation network except that the coral loss is used instead of mmd to minimize the discrepancy between source and target data .", "tokens": ["the", "idea", "is", "similar", "to", "deep", "domain", "confusion", "and", "deep", "adaptation", "network", "except", "that", "the", "coral", "loss", "is", "used", "instead", "of", "mmd", "to", "minimize", "the", "discrepancy", "between", "source", "and", "target", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the idea", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 2, "i_end": 2}}], "id": 162}, {"sent": "in figure , 5 and 6 , we provide a comparison of the estimated frames obtained by vsrresnet and the spmc-vsr model for scale factor of 2 and 4 .", "tokens": ["in", "figure", ",", "5", "and", "6", ",", "we", "provide", "a", "comparison", "of", "the", "estimated", "frames", "obtained", "by", "vsrresnet", "and", "the", "spmc", "-", "vsr", "model", "for", "scale", "factor", "of", "2", "and", "4", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 22, "end": 24, "i_start": 7, "i_end": 7}, "verb": {"text": "provide", "start": 25, "end": 32, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 7, "i_end": 7}, "action": {"text": "provide", "start": 25, "end": 32, "i_start": 8, "i_end": 8}}], "id": 163}, {"sent": "in particular , convolutional neural networks have reached outstanding performances in many different tasks such as object classification .", "tokens": ["in", "particular", ",", "convolutional", "neural", "networks", "have", "reached", "outstanding", "performances", "in", "many", "different", "tasks", "such", "as", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "have reached", "start": 46, "end": 58, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "reached", "start": 51, "end": 58, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performances", "start": 71, "end": 83, "i_start": 9, "i_end": 9}}], "id": 164}, {"sent": "the particle-flow algorithm deployed by the cms collaboration aims to reconstruct and identify each individual particle in an event , with an optimised combination of information from the various elements of the cms detector .", "tokens": ["the", "particle", "-", "flow", "algorithm", "deployed", "by", "the", "cms", "collaboration", "aims", "to", "reconstruct", "and", "identify", "each", "individual", "particle", "in", "an", "event", ",", "with", "an", "optimised", "combination", "of", "information", "from", "the", "various", "elements", "of", "the", "cms", "detector", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the particle-flow algorithm deployed by the cms collaboration", "start": 0, "end": 61, "i_start": 0, "i_end": 9}, "verb": {"text": "aims", "start": 62, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "algorithm", "start": 18, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "aims", "start": 62, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "collaboration", "start": 48, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "deployed", "start": 28, "end": 36, "i_start": 5, "i_end": 5}}], "id": 165}, {"sent": "symplectic geometry of frobenius structures .", "tokens": ["symplectic", "geometry", "of", "frobenius", "structures", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 166}, {"sent": "the nucleus is the most prominent feature , this appears surrounded by diffraction rings and atmospheric speckles .", "tokens": ["the", "nucleus", "is", "the", "most", "prominent", "feature", ",", "this", "appears", "surrounded", "by", "diffraction", "rings", "and", "atmospheric", "speckles", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 44, "end": 48, "i_start": 8, "i_end": 8}, "verb": {"text": "appears", "start": 49, "end": 56, "i_start": 9, "i_end": 9}}, {"subject": {"text": "this", "start": 44, "end": 48, "i_start": 8, "i_end": 8}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 167}, {"sent": "a diagrammatic theory of time correlation functions of facilitated kinetic ising models .", "tokens": ["a", "diagrammatic", "theory", "of", "time", "correlation", "functions", "of", "facilitated", "kinetic", "ising", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "models", "start": 81, "end": 87, "i_start": 11, "i_end": 11}, "action": {"text": "functions", "start": 42, "end": 51, "i_start": 6, "i_end": 6}}], "id": 168}, {"sent": "chiral symmetry is the fundamental symmetry of qcd and its spontaneous breaking governs the dynamics of low energy hadrons .", "tokens": ["chiral", "symmetry", "is", "the", "fundamental", "symmetry", "of", "qcd", "and", "its", "spontaneous", "breaking", "governs", "the", "dynamics", "of", "low", "energy", "hadrons", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "chiral symmetry", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "breaking", "start": 71, "end": 79, "i_start": 11, "i_end": 11}, "action": {"text": "governs", "start": 80, "end": 87, "i_start": 12, "i_end": 12}}], "id": 169}, {"sent": "all relevant parameters in the mssm are assumed to be real quantities .", "tokens": ["all", "relevant", "parameters", "in", "the", "mssm", "are", "assumed", "to", "be", "real", "quantities", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all relevant parameters in the mssm", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "are assumed", "start": 36, "end": 47, "i_start": 6, "i_end": 7}}], "id": 170}, {"sent": "a recent plethora of deep learning super-resolution techniques have achieved significant improvement in single image super-resolution performance .", "tokens": ["a", "recent", "plethora", "of", "deep", "learning", "super", "-", "resolution", "techniques", "have", "achieved", "significant", "improvement", "in", "single", "image", "super", "-", "resolution", "performance", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "a recent plethora of deep learning super-resolution techniques", "start": 0, "end": 62, "i_start": 0, "i_end": 9}, "verb": {"text": "have achieved", "start": 63, "end": 76, "i_start": 10, "i_end": 11}}, {"character": {"text": "techniques", "start": 52, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "achieved", "start": 68, "end": 76, "i_start": 11, "i_end": 11}}, {"character": {"text": "techniques", "start": 52, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "improvement", "start": 89, "end": 100, "i_start": 13, "i_end": 13}}], "id": 171}, {"sent": "for input features , we use embeddings from the resnet-50 deep convolutional neural network pre-trained on imagenet-1k .", "tokens": ["for", "input", "features", ",", "we", "use", "embeddings", "from", "the", "resnet-50", "deep", "convolutional", "neural", "network", "pre", "-", "trained", "on", "imagenet-1k", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 24, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 24, "end": 27, "i_start": 5, "i_end": 5}}], "id": 172}, {"sent": "the performance of object detectors has been dramatically improved thanks to the advance of deep convolutional neural networks .", "tokens": ["the", "performance", "of", "object", "detectors", "has", "been", "dramatically", "improved", "thanks", "to", "the", "advance", "of", "deep", "convolutional", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the performance of object detectors", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "improved", "start": 58, "end": 66, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the performance of object detectors", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "has been", "start": 36, "end": 44, "i_start": 5, "i_end": 6}}], "id": 173}, {"sent": "deep convolutional neural networks have been prevailed in various computer vision tasks , such as objection classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "prevailed", "in", "various", "computer", "vision", "tasks", ",", "such", "as", "objection", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been prevailed", "start": 35, "end": 54, "i_start": 4, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "prevailed", "start": 45, "end": 54, "i_start": 6, "i_end": 6}}], "id": 174}, {"sent": "deep neural networks have achieved impressive performance on tasks across a variety of domains , including vision .", "tokens": ["deep", "neural", "networks", "have", "achieved", "impressive", "performance", "on", "tasks", "across", "a", "variety", "of", "domains", ",", "including", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 46, "end": 57, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 46, "end": 57, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 35, "end": 45, "i_start": 5, "i_end": 5}}], "id": 175}, {"sent": "multiplication is the coproduct of the identity with itself .", "tokens": ["multiplication", "is", "the", "coproduct", "of", "the", "identity", "with", "itself", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "multiplication", "start": 0, "end": 14, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 1, "i_end": 1}}], "id": 176}, {"sent": "however , as shown in , the attention mechanism can further boost the performance of video captioning .", "tokens": ["however", ",", "as", "shown", "in", ",", "the", "attention", "mechanism", "can", "further", "boost", "the", "performance", "of", "video", "captioning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the attention mechanism", "start": 24, "end": 47, "i_start": 6, "i_end": 8}, "verb": {"text": "boost", "start": 60, "end": 65, "i_start": 11, "i_end": 11}}, {"subject": {"text": "the attention mechanism", "start": 24, "end": 47, "i_start": 6, "i_end": 8}, "verb": {"text": "can", "start": 48, "end": 51, "i_start": 9, "i_end": 9}}, {"character": {"text": "mechanism", "start": 38, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "boost", "start": 60, "end": 65, "i_start": 11, "i_end": 11}}, {"character": {"text": "mechanism", "start": 38, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "attention", "start": 28, "end": 37, "i_start": 7, "i_end": 7}}], "id": 177}, {"sent": "residual networks have enabled training of very deep neural networks .", "tokens": ["residual", "networks", "have", "enabled", "training", "of", "very", "deep", "neural", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "residual networks", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "have enabled", "start": 18, "end": 30, "i_start": 2, "i_end": 3}}, {"character": {"text": "networks", "start": 9, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "enabled", "start": 23, "end": 30, "i_start": 3, "i_end": 3}}], "id": 178}, {"sent": "then any minimal expression of \u03bb has the same number of blocks of size two .", "tokens": ["then", "any", "minimal", "expression", "of", "\u03bb", "has", "the", "same", "number", "of", "blocks", "of", "size", "two", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "any minimal expression of \u03bb", "start": 5, "end": 32, "i_start": 1, "i_end": 5}, "verb": {"text": "has", "start": 33, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "expression", "start": 17, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "has", "start": 33, "end": 36, "i_start": 6, "i_end": 6}}], "id": 179}, {"sent": "generative adversarial networks are one of the main groups of methods used to learn generative models from complicated real-world data .", "tokens": ["generative", "adversarial", "networks", "are", "one", "of", "the", "main", "groups", "of", "methods", "used", "to", "learn", "generative", "models", "from", "complicated", "real", "-", "world", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}], "id": 180}, {"sent": "in recent years , convolutional neural networks has achieved remarkable results in a wide range of computer vision applications .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "has", "achieved", "remarkable", "results", "in", "a", "wide", "range", "of", "computer", "vision", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "has achieved", "start": 48, "end": 60, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 52, "end": 60, "i_start": 8, "i_end": 8}}], "id": 181}, {"sent": "deep neural networks have shown tremendous success in several computer vision tasks in recent years .", "tokens": ["deep", "neural", "networks", "have", "shown", "tremendous", "success", "in", "several", "computer", "vision", "tasks", "in", "recent", "years", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}], "id": 182}, {"sent": "zhang et al design a bi-directional architecture with message passing among different feature maps .", "tokens": ["zhang", "et", "al", "design", "a", "bi", "-", "directional", "architecture", "with", "message", "passing", "among", "different", "feature", "maps", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhang et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "design", "start": 12, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "design", "start": 12, "end": 18, "i_start": 3, "i_end": 3}}], "id": 183}, {"sent": "we use a vgg16 network pre-trained on the imagenet dataset as our base network .", "tokens": ["we", "use", "a", "vgg16", "network", "pre", "-", "trained", "on", "the", "imagenet", "dataset", "as", "our", "base", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 184}, {"sent": "we study the relationships between these conditions and give some examples and counterexamples in the complex plane .", "tokens": ["we", "study", "the", "relationships", "between", "these", "conditions", "and", "give", "some", "examples", "and", "counterexamples", "in", "the", "complex", "plane", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "study", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "give", "start": 56, "end": 60, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "study", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "give", "start": 56, "end": 60, "i_start": 8, "i_end": 8}}], "id": 185}, {"sent": "such quark-quark double scattering processes also contribute to the semi-inclusive dis at twist-four .", "tokens": ["such", "quark", "-", "quark", "double", "scattering", "processes", "also", "contribute", "to", "the", "semi", "-", "inclusive", "dis", "at", "twist", "-", "four", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "such quark-quark double scattering processes", "start": 0, "end": 44, "i_start": 0, "i_end": 6}, "verb": {"text": "contribute", "start": 50, "end": 60, "i_start": 8, "i_end": 8}}, {"character": {"text": "processes", "start": 35, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "contribute", "start": 50, "end": 60, "i_start": 8, "i_end": 8}}], "id": 186}, {"sent": "the properties of the forming protostar are calculated using the stellar evolution tracks provided by the stellar code .", "tokens": ["the", "properties", "of", "the", "forming", "protostar", "are", "calculated", "using", "the", "stellar", "evolution", "tracks", "provided", "by", "the", "stellar", "code", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the properties of the forming protostar", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "are calculated", "start": 40, "end": 54, "i_start": 6, "i_end": 7}}, {"character": {"text": "code", "start": 114, "end": 118, "i_start": 17, "i_end": 17}, "action": {"text": "provided", "start": 90, "end": 98, "i_start": 13, "i_end": 13}}], "id": 187}, {"sent": "such a connection should shed light on the conjecture of goulden , jackson and vakil , which asserts that double hurwitz numbers arise as intersection numbers on certain moduli spaces of curves equipped with a line bundle .", "tokens": ["such", "a", "connection", "should", "shed", "light", "on", "the", "conjecture", "of", "goulden", ",", "jackson", "and", "vakil", ",", "which", "asserts", "that", "double", "hurwitz", "numbers", "arise", "as", "intersection", "numbers", "on", "certain", "moduli", "spaces", "of", "curves", "equipped", "with", "a", "line", "bundle", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "such a connection", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "should shed", "start": 18, "end": 29, "i_start": 3, "i_end": 4}}, {"character": {"text": "connection", "start": 7, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "shed", "start": 25, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "goulden", "start": 57, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "conjecture", "start": 43, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "jackson", "start": 67, "end": 74, "i_start": 12, "i_end": 12}, "action": {"text": "conjecture", "start": 43, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "vakil", "start": 79, "end": 84, "i_start": 14, "i_end": 14}, "action": {"text": "conjecture", "start": 43, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "conjecture", "start": 43, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "asserts", "start": 93, "end": 100, "i_start": 17, "i_end": 17}}, {"character": {"text": "numbers", "start": 151, "end": 158, "i_start": 25, "i_end": 25}, "action": {"text": "intersection", "start": 138, "end": 150, "i_start": 24, "i_end": 24}}], "id": 188}, {"sent": "recent years have seen a breakthrough of deep generative methods for image generation , using generative adversarial networks , variational autoencoder and so on .", "tokens": ["recent", "years", "have", "seen", "a", "breakthrough", "of", "deep", "generative", "methods", "for", "image", "generation", ",", "using", "generative", "adversarial", "networks", ",", "variational", "autoencoder", "and", "so", "on", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent years", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "have seen", "start": 13, "end": 22, "i_start": 2, "i_end": 3}}, {"character": {"text": "years", "start": 7, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "seen", "start": 18, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "methods", "start": 57, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "using", "start": 88, "end": 93, "i_start": 14, "i_end": 14}}], "id": 189}, {"sent": "duality of this kind is known as 3d mirror symmetry .", "tokens": ["duality", "of", "this", "kind", "is", "known", "as", "3d", "mirror", "symmetry", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "duality of this kind", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "is known", "start": 21, "end": 29, "i_start": 4, "i_end": 5}}], "id": 190}, {"sent": "this is comparable to pre-processing steps such as removing stopwords and high and low frequency words , that are typically carried out prior to applying topic models .", "tokens": ["this", "is", "comparable", "to", "pre", "-", "processing", "steps", "such", "as", "removing", "stopwords", "and", "high", "and", "low", "frequency", "words", ",", "that", "are", "typically", "carried", "out", "prior", "to", "applying", "topic", "models", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "that", "start": 105, "end": 109, "i_start": 19, "i_end": 19}, "verb": {"text": "carried out", "start": 124, "end": 135, "i_start": 22, "i_end": 23}}, {"subject": {"text": "that", "start": 105, "end": 109, "i_start": 19, "i_end": 19}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "that", "start": 105, "end": 109, "i_start": 19, "i_end": 19}, "verb": {"text": "are", "start": 110, "end": 113, "i_start": 20, "i_end": 20}}], "id": 191}, {"sent": "the parasitic overshoot generated by gear2 method can be solved via step no .", "tokens": ["the", "parasitic", "overshoot", "generated", "by", "gear2", "method", "can", "be", "solved", "via", "step", "no", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the parasitic overshoot generated by gear2 method", "start": 0, "end": 49, "i_start": 0, "i_end": 6}, "verb": {"text": "can be solved", "start": 50, "end": 63, "i_start": 7, "i_end": 9}}, {"character": {"text": "method", "start": 43, "end": 49, "i_start": 6, "i_end": 6}, "action": {"text": "generated", "start": 24, "end": 33, "i_start": 3, "i_end": 3}}], "id": 192}, {"sent": "an impressive number of graph clustering algorithms have been proposed , studied and compared over the past decades .", "tokens": ["an", "impressive", "number", "of", "graph", "clustering", "algorithms", "have", "been", "proposed", ",", "studied", "and", "compared", "over", "the", "past", "decades", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "an impressive number of graph clustering algorithms", "start": 0, "end": 51, "i_start": 0, "i_end": 6}, "verb": {"text": "have been proposed", "start": 52, "end": 70, "i_start": 7, "i_end": 9}}, {"subject": {"text": "an impressive number of graph clustering algorithms", "start": 0, "end": 51, "i_start": 0, "i_end": 6}, "verb": {"text": "studied", "start": 73, "end": 80, "i_start": 11, "i_end": 11}}, {"character": {"text": "number", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "impressive", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}], "id": 193}, {"sent": "phase transition in type-ii superconducting films .", "tokens": ["phase", "transition", "in", "type", "-", "ii", "superconducting", "films", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 194}, {"sent": "where the tilde denotes a reversed film , which corresponds to interchange of the diagonal elements of transfer matrix .", "tokens": ["where", "the", "tilde", "denotes", "a", "reversed", "film", ",", "which", "corresponds", "to", "interchange", "of", "the", "diagonal", "elements", "of", "transfer", "matrix", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the tilde", "start": 6, "end": 15, "i_start": 1, "i_end": 2}, "verb": {"text": "denotes", "start": 16, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "tilde", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "denotes", "start": 16, "end": 23, "i_start": 3, "i_end": 3}}], "id": 195}, {"sent": "many relatively simple methods are commonly used , such as measuring distance from the starting structure as a function of simulation time , and calculation of various autocorrelation functions .", "tokens": ["many", "relatively", "simple", "methods", "are", "commonly", "used", ",", "such", "as", "measuring", "distance", "from", "the", "starting", "structure", "as", "a", "function", "of", "simulation", "time", ",", "and", "calculation", "of", "various", "autocorrelation", "functions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many relatively simple methods", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "used", "start": 44, "end": 48, "i_start": 6, "i_end": 6}}, {"subject": {"text": "many relatively simple methods", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 31, "end": 34, "i_start": 4, "i_end": 4}}], "id": 196}, {"sent": "therefore , the dominant term is the first term .", "tokens": ["therefore", ",", "the", "dominant", "term", "is", "the", "first", "term", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dominant term", "start": 12, "end": 29, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "term", "start": 43, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "dominant", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}], "id": 197}, {"sent": "on poisson homogeneous spaces of poisson-lie groups .", "tokens": ["on", "poisson", "homogeneous", "spaces", "of", "poisson", "-", "lie", "groups", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 198}, {"sent": "neural networks have been applied to solving problems in several application domains such as computer vision , natural language processing , and disease diagnosis .", "tokens": ["neural", "networks", "have", "been", "applied", "to", "solving", "problems", "in", "several", "application", "domains", "such", "as", "computer", "vision", ",", "natural", "language", "processing", ",", "and", "disease", "diagnosis", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have been applied", "start": 16, "end": 33, "i_start": 2, "i_end": 4}}], "id": 199}, {"sent": "obviously , the eigenvector of d is the eigenvector of d2 .", "tokens": ["obviously", ",", "the", "eigenvector", "of", "d", "is", "the", "eigenvector", "of", "d2", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the eigenvector of d", "start": 12, "end": 32, "i_start": 2, "i_end": 5}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 6, "i_end": 6}}], "id": 200}, {"sent": "on large-sample estimation and testing in parametric models .", "tokens": ["on", "large", "-", "sample", "estimation", "and", "testing", "in", "parametric", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 201}, {"sent": "taking computer vision as an example , deep convolutional neural networks have been verified to yield much better performance than conventional methods in various applications , from high-level tasks such as image recognition .", "tokens": ["taking", "computer", "vision", "as", "an", "example", ",", "deep", "convolutional", "neural", "networks", "have", "been", "verified", "to", "yield", "much", "better", "performance", "than", "conventional", "methods", "in", "various", "applications", ",", "from", "high", "-", "level", "tasks", "such", "as", "image", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 39, "end": 73, "i_start": 7, "i_end": 10}, "verb": {"text": "have been verified", "start": 74, "end": 92, "i_start": 11, "i_end": 13}}, {"character": {"text": "networks", "start": 65, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "yield", "start": 96, "end": 101, "i_start": 15, "i_end": 15}}, {"character": {"text": "networks", "start": 65, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "performance", "start": 114, "end": 125, "i_start": 18, "i_end": 18}}], "id": 202}, {"sent": "such a clock is a standard of time and of length .", "tokens": ["such", "a", "clock", "is", "a", "standard", "of", "time", "and", "of", "length", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such a clock", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 3, "i_end": 3}}], "id": 203}, {"sent": "weighted automata provide a natural and flexible framework for expressing quantitative 1 properties .", "tokens": ["weighted", "automata", "provide", "a", "natural", "and", "flexible", "framework", "for", "expressing", "quantitative", "1", "properties", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "weighted automata", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "provide", "start": 18, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "automata", "start": 9, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "provide", "start": 18, "end": 25, "i_start": 2, "i_end": 2}}], "id": 204}, {"sent": "the apparent reason for the improved performance is namely that integration of the absolute velocity measurements emulates absolute position feedback .", "tokens": ["the", "apparent", "reason", "for", "the", "improved", "performance", "is", "namely", "that", "integration", "of", "the", "absolute", "velocity", "measurements", "emulates", "absolute", "position", "feedback", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the apparent reason for the improved performance", "start": 0, "end": 48, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 49, "end": 51, "i_start": 7, "i_end": 7}}, {"subject": {"text": "that integration of the absolute velocity measurements", "start": 59, "end": 113, "i_start": 9, "i_end": 15}, "verb": {"text": "emulates", "start": 114, "end": 122, "i_start": 16, "i_end": 16}}, {"character": {"text": "integration", "start": 64, "end": 75, "i_start": 10, "i_end": 10}, "action": {"text": "emulates", "start": 114, "end": 122, "i_start": 16, "i_end": 16}}], "id": 205}, {"sent": "we use resnet-20 and resnet-110 architectures for gtsrb and cifar10 datasets , respectively .", "tokens": ["we", "use", "resnet-20", "and", "resnet-110", "architectures", "for", "gtsrb", "and", "cifar10", "datasets", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 206}, {"sent": "in particular string theory has been successful in providing a correct microscopic description of the entropy of various classes of black holes .", "tokens": ["in", "particular", "string", "theory", "has", "been", "successful", "in", "providing", "a", "correct", "microscopic", "description", "of", "the", "entropy", "of", "various", "classes", "of", "black", "holes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "theory", "start": 21, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "successful", "start": 37, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "theory", "start": 21, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "providing", "start": 51, "end": 60, "i_start": 8, "i_end": 8}}, {"character": {"text": "theory", "start": 21, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "description", "start": 83, "end": 94, "i_start": 12, "i_end": 12}}], "id": 207}, {"sent": "in this section , we extend the incompressibility method on classical graphs in to plain algorithmically random mags .", "tokens": ["in", "this", "section", ",", "we", "extend", "the", "incompressibility", "method", "on", "classical", "graphs", "in", "to", "plain", "algorithmically", "random", "mags", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "extend", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "extend", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 208}, {"sent": "the bogoliubov fermi pockets are protected by a z 2 invariant , which we have identified as the relative sign of the pfaffian of the unitarily transformed bdg hamiltonian on the two sides of the fermi surface .", "tokens": ["the", "bogoliubov", "fermi", "pockets", "are", "protected", "by", "a", "z", "2", "invariant", ",", "which", "we", "have", "identified", "as", "the", "relative", "sign", "of", "the", "pfaffian", "of", "the", "unitarily", "transformed", "bdg", "hamiltonian", "on", "the", "two", "sides", "of", "the", "fermi", "surface", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the bogoliubov fermi pockets", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "are protected", "start": 29, "end": 42, "i_start": 4, "i_end": 5}}, {"character": {"text": "we", "start": 70, "end": 72, "i_start": 13, "i_end": 13}, "action": {"text": "identified", "start": 78, "end": 88, "i_start": 15, "i_end": 15}}, {"character": {"text": "invariant", "start": 52, "end": 61, "i_start": 10, "i_end": 10}, "action": {"text": "sign", "start": 105, "end": 109, "i_start": 19, "i_end": 19}}], "id": 209}, {"sent": "we utilize a simple encoder-decoder architecture inspired by u-net .", "tokens": ["we", "utilize", "a", "simple", "encoder", "-", "decoder", "architecture", "inspired", "by", "u", "-", "net", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "utilize", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "utilize", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 210}, {"sent": "millimeter wave communication is deemed as a promising technique for meeting the ever-increasing traffic demand in next generation wireless communication systems .", "tokens": ["millimeter", "wave", "communication", "is", "deemed", "as", "a", "promising", "technique", "for", "meeting", "the", "ever", "-", "increasing", "traffic", "demand", "in", "next", "generation", "wireless", "communication", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "millimeter wave communication", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "is deemed", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "technique", "start": 55, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "promising", "start": 45, "end": 54, "i_start": 7, "i_end": 7}}, {"character": {"text": "systems", "start": 154, "end": 161, "i_start": 22, "i_end": 22}, "action": {"text": "demand", "start": 105, "end": 111, "i_start": 16, "i_end": 16}}], "id": 211}, {"sent": "to overcome this , cyclegan uses a cycle consistency loss to avoid needing such input-output pairs .", "tokens": ["to", "overcome", "this", ",", "cyclegan", "uses", "a", "cycle", "consistency", "loss", "to", "avoid", "needing", "such", "input", "-", "output", "pairs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "cyclegan", "start": 19, "end": 27, "i_start": 4, "i_end": 4}, "verb": {"text": "uses", "start": 28, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "cyclegan", "start": 19, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "uses", "start": 28, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "cyclegan", "start": 19, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "avoid", "start": 61, "end": 66, "i_start": 11, "i_end": 11}}, {"character": {"text": "cyclegan", "start": 19, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "needing", "start": 67, "end": 74, "i_start": 12, "i_end": 12}}, {"character": {"text": "cyclegan", "start": 19, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "overcome", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 212}, {"sent": "lda takes the raw text , the number of topics , and a dictionary of words as input , and then provides as an output the most significant topics .", "tokens": ["lda", "takes", "the", "raw", "text", ",", "the", "number", "of", "topics", ",", "and", "a", "dictionary", "of", "words", "as", "input", ",", "and", "then", "provides", "as", "an", "output", "the", "most", "significant", "topics", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "lda", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "takes", "start": 4, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "lda", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "provides", "start": 94, "end": 102, "i_start": 21, "i_end": 21}}, {"character": {"text": "lda", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "takes", "start": 4, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "lda", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "provides", "start": 94, "end": 102, "i_start": 21, "i_end": 21}}], "id": 213}, {"sent": "the opo is locked by the pound-drever-hall technique with the s-polarized cavitylocking beam .", "tokens": ["the", "opo", "is", "locked", "by", "the", "pound", "-", "drever", "-", "hall", "technique", "with", "the", "s", "-", "polarized", "cavitylocking", "beam", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the opo", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "is locked", "start": 8, "end": 17, "i_start": 2, "i_end": 3}}, {"character": {"text": "technique", "start": 43, "end": 52, "i_start": 11, "i_end": 11}, "action": {"text": "locked", "start": 11, "end": 17, "i_start": 3, "i_end": 3}}], "id": 214}, {"sent": "more specifically , we focussed on the tendimensional supergravity considered in , in which the anomaly-cancelling trterm of the heterotic theory was supersymmetrised .", "tokens": ["more", "specifically", ",", "we", "focussed", "on", "the", "tendimensional", "supergravity", "considered", "in", ",", "in", "which", "the", "anomaly", "-", "cancelling", "trterm", "of", "the", "heterotic", "theory", "was", "supersymmetrised", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "verb": {"text": "focussed", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "focussed", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}], "id": 215}, {"sent": "this is accomplished in the following lemma .", "tokens": ["this", "is", "accomplished", "in", "the", "following", "lemma", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is accomplished", "start": 5, "end": 20, "i_start": 1, "i_end": 2}}], "id": 216}, {"sent": "however , most interesting distributed tasks can not be solved in a wait-free manner .", "tokens": ["however", ",", "most", "interesting", "distributed", "tasks", "can", "not", "be", "solved", "in", "a", "wait", "-", "free", "manner", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "most interesting distributed tasks", "start": 10, "end": 44, "i_start": 2, "i_end": 5}, "verb": {"text": "can not be solved", "start": 45, "end": 62, "i_start": 6, "i_end": 9}}, {"character": {"text": "tasks", "start": 39, "end": 44, "i_start": 5, "i_end": 5}, "action": {"text": "interesting", "start": 15, "end": 26, "i_start": 3, "i_end": 3}}], "id": 217}, {"sent": "the kuramoto-sakaguchi model of globally coupled phase oscillators is a widely used system to study synchronization phenomena , see reviews .", "tokens": ["the", "kuramoto", "-", "sakaguchi", "model", "of", "globally", "coupled", "phase", "oscillators", "is", "a", "widely", "used", "system", "to", "study", "synchronization", "phenomena", ",", "see", "reviews", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the kuramoto-sakaguchi model of globally coupled phase oscillators", "start": 0, "end": 66, "i_start": 0, "i_end": 9}, "verb": {"text": "is", "start": 67, "end": 69, "i_start": 10, "i_end": 10}}, {"character": {"text": "kuramoto", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "model", "start": 23, "end": 28, "i_start": 4, "i_end": 4}}], "id": 218}, {"sent": "in our experiments , all the models were implemented using dynet and were trained with adam .", "tokens": ["in", "our", "experiments", ",", "all", "the", "models", "were", "implemented", "using", "dynet", "and", "were", "trained", "with", "adam", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all the models", "start": 21, "end": 35, "i_start": 4, "i_end": 6}, "verb": {"text": "were implemented", "start": 36, "end": 52, "i_start": 7, "i_end": 8}}, {"subject": {"text": "all the models", "start": 21, "end": 35, "i_start": 4, "i_end": 6}, "verb": {"text": "trained", "start": 74, "end": 81, "i_start": 13, "i_end": 13}}], "id": 219}, {"sent": "all the parameters of the decoder network are initialized with xavier .", "tokens": ["all", "the", "parameters", "of", "the", "decoder", "network", "are", "initialized", "with", "xavier", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "all the parameters of the decoder network", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "are initialized", "start": 42, "end": 57, "i_start": 7, "i_end": 8}}, {"character": {"text": "network", "start": 34, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "decoder", "start": 26, "end": 33, "i_start": 5, "i_end": 5}}], "id": 220}, {"sent": "generative adversarial networks provide an important approach for learning a generative model which generates samples from the real-world data distribution .", "tokens": ["generative", "adversarial", "networks", "provide", "an", "important", "approach", "for", "learning", "a", "generative", "model", "which", "generates", "samples", "from", "the", "real", "-", "world", "data", "distribution", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "provide", "start": 32, "end": 39, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "provide", "start": 32, "end": 39, "i_start": 3, "i_end": 3}}, {"character": {"text": "model", "start": 88, "end": 93, "i_start": 11, "i_end": 11}, "action": {"text": "generates", "start": 100, "end": 109, "i_start": 13, "i_end": 13}}], "id": 221}, {"sent": "since this degree of freedom is the wilson line phase , the higgs does not have the mass term nor quartic coupling at the tree level .", "tokens": ["since", "this", "degree", "of", "freedom", "is", "the", "wilson", "line", "phase", ",", "the", "higgs", "does", "not", "have", "the", "mass", "term", "nor", "quartic", "coupling", "at", "the", "tree", "level", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the higgs", "start": 56, "end": 65, "i_start": 11, "i_end": 12}, "verb": {"text": "does not have", "start": 66, "end": 79, "i_start": 13, "i_end": 15}}], "id": 222}, {"sent": "the first equality is the chain rule for mutual information .", "tokens": ["the", "first", "equality", "is", "the", "chain", "rule", "for", "mutual", "information", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the first equality", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 223}, {"sent": "inflation is one of the leading paradigms describing the physical conditions that prevailed in the very early universe .", "tokens": ["inflation", "is", "one", "of", "the", "leading", "paradigms", "describing", "the", "physical", "conditions", "that", "prevailed", "in", "the", "very", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "inflation", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "paradigms", "start": 32, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "leading", "start": 24, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "paradigms", "start": 32, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "describing", "start": 42, "end": 52, "i_start": 7, "i_end": 7}}, {"character": {"text": "conditions", "start": 66, "end": 76, "i_start": 10, "i_end": 10}, "action": {"text": "prevailed", "start": 82, "end": 91, "i_start": 12, "i_end": 12}}], "id": 224}, {"sent": "parity-check codes have become one of promising error-correcting codes in these areas due to their near capacity-approaching performance .", "tokens": ["parity", "-", "check", "codes", "have", "become", "one", "of", "promising", "error", "-", "correcting", "codes", "in", "these", "areas", "due", "to", "their", "near", "capacity", "-", "approaching", "performance", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "parity-check codes", "start": 0, "end": 18, "i_start": 0, "i_end": 3}, "verb": {"text": "have become", "start": 19, "end": 30, "i_start": 4, "i_end": 5}}, {"character": {"text": "codes", "start": 13, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "check", "start": 7, "end": 12, "i_start": 2, "i_end": 2}}], "id": 225}, {"sent": "the network is similar to u-net , which was originally used for image segmentation .", "tokens": ["the", "network", "is", "similar", "to", "u", "-", "net", ",", "which", "was", "originally", "used", "for", "image", "segmentation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the network", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 226}, {"sent": "then , computing efficiently this tree given the graph has been an important challenge of the past three decades .", "tokens": ["then", ",", "computing", "efficiently", "this", "tree", "given", "the", "graph", "has", "been", "an", "important", "challenge", "of", "the", "past", "three", "decades", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "computing efficiently this tree given the graph", "start": 7, "end": 54, "i_start": 2, "i_end": 8}, "verb": {"text": "has been", "start": 55, "end": 63, "i_start": 9, "i_end": 10}}], "id": 227}, {"sent": "gessel and reutenauer first proved the stronger fact in that such sets are actually fine .", "tokens": ["gessel", "and", "reutenauer", "first", "proved", "the", "stronger", "fact", "in", "that", "such", "sets", "are", "actually", "fine", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "gessel and reutenauer", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "proved", "start": 28, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "gessel", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "proved", "start": 28, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "reutenauer", "start": 11, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "proved", "start": 28, "end": 34, "i_start": 4, "i_end": 4}}], "id": 228}, {"sent": "we train the model with cross-entropy loss function using adam optimizer .", "tokens": ["we", "train", "the", "model", "with", "cross", "-", "entropy", "loss", "function", "using", "adam", "optimizer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 229}, {"sent": "the chy formula for tree level m graviton scattering in any dimension is a remarkably compact packaging of the properties of perturbative quantum gravity .", "tokens": ["the", "chy", "formula", "for", "tree", "level", "m", "graviton", "scattering", "in", "any", "dimension", "is", "a", "remarkably", "compact", "packaging", "of", "the", "properties", "of", "perturbative", "quantum", "gravity", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the chy formula for tree level m graviton scattering in any dimension", "start": 0, "end": 69, "i_start": 0, "i_end": 11}, "verb": {"text": "is", "start": 70, "end": 72, "i_start": 12, "i_end": 12}}], "id": 230}, {"sent": "a modulation of the fermi velocity can be obtained in graphene , for instance , by placing metallic planes close to the graphene sheet , which will turn electron-electron interactions weaker and , consequently , modify the fermi velocity .", "tokens": ["a", "modulation", "of", "the", "fermi", "velocity", "can", "be", "obtained", "in", "graphene", ",", "for", "instance", ",", "by", "placing", "metallic", "planes", "close", "to", "the", "graphene", "sheet", ",", "which", "will", "turn", "electron", "-", "electron", "interactions", "weaker", "and", ",", "consequently", ",", "modify", "the", "fermi", "velocity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a modulation of the fermi velocity", "start": 0, "end": 34, "i_start": 0, "i_end": 5}, "verb": {"text": "can be obtained", "start": 35, "end": 50, "i_start": 6, "i_end": 8}}, {"character": {"text": "placing", "start": 83, "end": 90, "i_start": 16, "i_end": 16}, "action": {"text": "turn", "start": 148, "end": 152, "i_start": 27, "i_end": 27}}, {"character": {"text": "electron", "start": 153, "end": 161, "i_start": 28, "i_end": 28}, "action": {"text": "interactions", "start": 171, "end": 183, "i_start": 31, "i_end": 31}}], "id": 231}, {"sent": "arnold observed a strange duality between the 14 exceptional unimodal singularities .", "tokens": ["arnold", "observed", "a", "strange", "duality", "between", "the", "14", "exceptional", "unimodal", "singularities", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "arnold", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "observed", "start": 7, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "arnold", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "observed", "start": 7, "end": 15, "i_start": 1, "i_end": 1}}], "id": 232}, {"sent": "directed acyclic graph models , also known as bayesian networks , are widely used to model causal relationships in complex systems across various fields such as computational biology , epidemiology , sociology , and environmental management .", "tokens": ["directed", "acyclic", "graph", "models", ",", "also", "known", "as", "bayesian", "networks", ",", "are", "widely", "used", "to", "model", "causal", "relationships", "in", "complex", "systems", "across", "various", "fields", "such", "as", "computational", "biology", ",", "epidemiology", ",", "sociology", ",", "and", "environmental", "management", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "models", "start": 23, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "model", "start": 85, "end": 90, "i_start": 15, "i_end": 15}}], "id": 233}, {"sent": "deep neural networks have gained popularity in recent years thanks to their achievements in many applications including computer vision , signal and image processing , speech recognition .", "tokens": ["deep", "neural", "networks", "have", "gained", "popularity", "in", "recent", "years", "thanks", "to", "their", "achievements", "in", "many", "applications", "including", "computer", "vision", ",", "signal", "and", "image", "processing", ",", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have gained", "start": 21, "end": 32, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "gained", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achievements", "start": 76, "end": 88, "i_start": 12, "i_end": 12}}], "id": 234}, {"sent": "as an effective tool for semi-supervised and unsupervised learning , generative adversarial networksrecently receives much attention .", "tokens": ["as", "an", "effective", "tool", "for", "semi", "-", "supervised", "and", "unsupervised", "learning", ",", "generative", "adversarial", "networksrecently", "receives", "much", "attention", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "generative adversarial", "start": 69, "end": 91, "i_start": 12, "i_end": 13}, "verb": {"text": "receives", "start": 109, "end": 117, "i_start": 15, "i_end": 15}}, {"character": {"text": "tool", "start": 16, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "effective", "start": 6, "end": 15, "i_start": 2, "i_end": 2}}], "id": 235}, {"sent": "recently released video datasets mostly focus on video content understanding , such as classification and captioning , specifically sports-1m .", "tokens": ["recently", "released", "video", "datasets", "mostly", "focus", "on", "video", "content", "understanding", ",", "such", "as", "classification", "and", "captioning", ",", "specifically", "sports-1", "m", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recently released video datasets", "start": 0, "end": 32, "i_start": 0, "i_end": 3}, "verb": {"text": "focus", "start": 40, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "datasets", "start": 24, "end": 32, "i_start": 3, "i_end": 3}, "action": {"text": "focus", "start": 40, "end": 45, "i_start": 5, "i_end": 5}}], "id": 236}, {"sent": "the only modification is the increase of the current quark mass , m0 .", "tokens": ["the", "only", "modification", "is", "the", "increase", "of", "the", "current", "quark", "mass", ",", "m0", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the only modification", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 237}, {"sent": "we introduce \u03b4 v,0 and \u03b6 d factors , in such a way that this operator can represent the partition function of all blocks and types .", "tokens": ["we", "introduce", "\u03b4", "v,0", "and", "\u03b6", "d", "factors", ",", "in", "such", "a", "way", "that", "this", "operator", "can", "represent", "the", "partition", "function", "of", "all", "blocks", "and", "types", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "introduce", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "introduce", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 56, "end": 60, "i_start": 14, "i_end": 14}, "action": {"text": "represent", "start": 74, "end": 83, "i_start": 17, "i_end": 17}}, {"character": {"text": "blocks", "start": 114, "end": 120, "i_start": 23, "i_end": 23}, "action": {"text": "function", "start": 98, "end": 106, "i_start": 20, "i_end": 20}}, {"character": {"text": "all", "start": 110, "end": 113, "i_start": 22, "i_end": 22}, "action": {"text": "function", "start": 98, "end": 106, "i_start": 20, "i_end": 20}}, {"character": {"text": "types", "start": 125, "end": 130, "i_start": 25, "i_end": 25}, "action": {"text": "function", "start": 98, "end": 106, "i_start": 20, "i_end": 20}}], "id": 238}, {"sent": "specifically , we use the implementation of maxent models in the liblinear library with default parameter settings .", "tokens": ["specifically", ",", "we", "use", "the", "implementation", "of", "maxent", "models", "in", "the", "liblinear", "library", "with", "default", "parameter", "settings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "use", "start": 18, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 18, "end": 21, "i_start": 3, "i_end": 3}}], "id": 239}, {"sent": "being able to learn mid and high level features from the training data , convolutional neural networks have shown good recognition performances in many vision tasks , such as image classification and object detection .", "tokens": ["being", "able", "to", "learn", "mid", "and", "high", "level", "features", "from", "the", "training", "data", ",", "convolutional", "neural", "networks", "have", "shown", "good", "recognition", "performances", "in", "many", "vision", "tasks", ",", "such", "as", "image", "classification", "and", "object", "detection", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 73, "end": 102, "i_start": 14, "i_end": 16}, "verb": {"text": "have shown", "start": 103, "end": 113, "i_start": 17, "i_end": 18}}, {"character": {"text": "networks", "start": 94, "end": 102, "i_start": 16, "i_end": 16}, "action": {"text": "shown", "start": 108, "end": 113, "i_start": 18, "i_end": 18}}, {"character": {"text": "networks", "start": 94, "end": 102, "i_start": 16, "i_end": 16}, "action": {"text": "performances", "start": 131, "end": 143, "i_start": 21, "i_end": 21}}, {"character": {"text": "networks", "start": 94, "end": 102, "i_start": 16, "i_end": 16}, "action": {"text": "recognition", "start": 119, "end": 130, "i_start": 20, "i_end": 20}}, {"character": {"text": "networks", "start": 94, "end": 102, "i_start": 16, "i_end": 16}, "action": {"text": "learn", "start": 14, "end": 19, "i_start": 3, "i_end": 3}}], "id": 240}, {"sent": "convolutional neural networks have achieved notable successes in a variety of visual recognition tasks , such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "notable", "successes", "in", "a", "variety", "of", "visual", "recognition", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successes", "start": 52, "end": 61, "i_start": 6, "i_end": 6}}], "id": 241}, {"sent": "the schwarzschild solution is a useful model to describe the spacetime outside stars but the spacetime outside such a star may be filled with radiated energy from the star in the form of electromagnetic radiation .", "tokens": ["the", "schwarzschild", "solution", "is", "a", "useful", "model", "to", "describe", "the", "spacetime", "outside", "stars", "but", "the", "spacetime", "outside", "such", "a", "star", "may", "be", "filled", "with", "radiated", "energy", "from", "the", "star", "in", "the", "form", "of", "electromagnetic", "radiation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the schwarzschild solution", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the spacetime outside such a star", "start": 89, "end": 122, "i_start": 14, "i_end": 19}, "verb": {"text": "filled", "start": 130, "end": 136, "i_start": 22, "i_end": 22}}], "id": 242}, {"sent": "the p-spectral radius was introduced by keevash , lenz and mubayi .", "tokens": ["the", "p", "-", "spectral", "radius", "was", "introduced", "by", "keevash", ",", "lenz", "and", "mubayi", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the p-spectral radius", "start": 0, "end": 21, "i_start": 0, "i_end": 4}, "verb": {"text": "was introduced", "start": 22, "end": 36, "i_start": 5, "i_end": 6}}, {"character": {"text": "keevash", "start": 40, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "introduced", "start": 26, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "lenz", "start": 50, "end": 54, "i_start": 10, "i_end": 10}, "action": {"text": "introduced", "start": 26, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "mubayi", "start": 59, "end": 65, "i_start": 12, "i_end": 12}, "action": {"text": "introduced", "start": 26, "end": 36, "i_start": 6, "i_end": 6}}], "id": 243}, {"sent": "this leads to job colocation on the same server and consequently could lead to interference in shared system resources .", "tokens": ["this", "leads", "to", "job", "colocation", "on", "the", "same", "server", "and", "consequently", "could", "lead", "to", "interference", "in", "shared", "system", "resources", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "leads", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "lead", "start": 71, "end": 75, "i_start": 12, "i_end": 12}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "leads", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "lead", "start": 71, "end": 75, "i_start": 12, "i_end": 12}}], "id": 244}, {"sent": "brodmann eisenbud and huneke showed that equality holds , if the associated graded ringgr i is cohen-macaulay .", "tokens": ["brodmann", "eisenbud", "and", "huneke", "showed", "that", "equality", "holds", ",", "if", "the", "associated", "graded", "ring"], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "brodmann", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "eisenbud", "start": 9, "end": 17, "i_start": 1, "i_end": 1}}, {"subject": {"text": "huneke", "start": 22, "end": 28, "i_start": 3, "i_end": 3}, "verb": {"text": "showed", "start": 29, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "brodmann eisenbud", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "action": {"text": "showed", "start": 29, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "huneke", "start": 22, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "showed", "start": 29, "end": 35, "i_start": 4, "i_end": 4}}, {"subject": {"text": "i", "start": 3, "end": 4, "i_start": 1, "i_end": 1}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 2, "i_end": 2}}], "id": 245}, {"sent": "nt a dipolar condensate is a condensate possessing the dipole-dipole interactions , in addition to the usual swave contact interaction .", "tokens": ["nt", "a", "dipolar", "condensate", "is", "a", "condensate", "possessing", "the", "dipole", "-", "dipole", "interactions", ",", "in", "addition", "to", "the", "usual", "swave", "contact", "interaction", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a dipolar condensate", "start": 3, "end": 23, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "condensate", "start": 13, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "possessing", "start": 40, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "dipole", "start": 55, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "interactions", "start": 69, "end": 81, "i_start": 12, "i_end": 12}}], "id": 246}, {"sent": "the final result for the inflow waveform has been taken from work .", "tokens": ["the", "final", "result", "for", "the", "inflow", "waveform", "has", "been", "taken", "from", "work", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 247}, {"sent": "for each network we used adam algorithm as the optimizer of the gradient descent step .", "tokens": ["for", "each", "network", "we", "used", "adam", "algorithm", "as", "the", "optimizer", "of", "the", "gradient", "descent", "step", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 17, "end": 19, "i_start": 3, "i_end": 3}, "verb": {"text": "used", "start": 20, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 17, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "used", "start": 20, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "algorithm", "start": 30, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "optimizer", "start": 47, "end": 56, "i_start": 9, "i_end": 9}}], "id": 248}, {"sent": "it has long been known that two-layer networks with a variety of activation functions can approximate arbitrary continuous functions on compact sets .", "tokens": ["it", "has", "long", "been", "known", "that", "two", "-", "layer", "networks", "with", "a", "variety", "of", "activation", "functions", "can", "approximate", "arbitrary", "continuous", "functions", "on", "compact", "sets", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "two-layer networks with a variety of activation functions", "start": 28, "end": 85, "i_start": 6, "i_end": 15}, "verb": {"text": "been known", "start": 12, "end": 22, "i_start": 3, "i_end": 4}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "approximate", "start": 90, "end": 101, "i_start": 17, "i_end": 17}}, {"character": {"text": "networks", "start": 38, "end": 46, "i_start": 9, "i_end": 9}, "action": {"text": "approximate", "start": 90, "end": 101, "i_start": 17, "i_end": 17}}, {"character": {"text": "networks", "start": 38, "end": 46, "i_start": 9, "i_end": 9}, "action": {"text": "has", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 249}, {"sent": "in this section , we review the construction of a lattice voa and the structure of its automorphism group from .", "tokens": ["in", "this", "section", ",", "we", "review", "the", "construction", "of", "a", "lattice", "voa", "and", "the", "structure", "of", "its", "automorphism", "group", "from", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "review", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "review", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 250}, {"sent": "the notion of curling number of integer sequences are introduced in as follows .", "tokens": ["the", "notion", "of", "curling", "number", "of", "integer", "sequences", "are", "introduced", "in", "as", "follows", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the notion of curling number of integer sequences", "start": 0, "end": 49, "i_start": 0, "i_end": 7}, "verb": {"text": "are introduced in", "start": 50, "end": 67, "i_start": 8, "i_end": 10}}], "id": 251}, {"sent": "deep convolutional neural networks have shown promising performances on various computer vision problems such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "shown", "promising", "performances", "on", "various", "computer", "vision", "problems", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have shown", "start": 35, "end": 45, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 40, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performances", "start": 56, "end": 68, "i_start": 7, "i_end": 7}}, {"character": {"text": "performances", "start": 56, "end": 68, "i_start": 7, "i_end": 7}, "action": {"text": "promising", "start": 46, "end": 55, "i_start": 6, "i_end": 6}}], "id": 252}, {"sent": "more recent studies have fewer limitations , and introduce useful methods customised to the task .", "tokens": ["more", "recent", "studies", "have", "fewer", "limitations", ",", "and", "introduce", "useful", "methods", "customised", "to", "the", "task", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "more recent studies", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 20, "end": 24, "i_start": 3, "i_end": 3}}, {"subject": {"text": "more recent studies", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "introduce", "start": 49, "end": 58, "i_start": 8, "i_end": 8}}, {"character": {"text": "studies", "start": 12, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "limitations", "start": 31, "end": 42, "i_start": 5, "i_end": 5}}, {"character": {"text": "studies", "start": 12, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "introduce", "start": 49, "end": 58, "i_start": 8, "i_end": 8}}], "id": 253}, {"sent": "recurrent neural networks have been shown to achieve promising results on many difficult sequential learning problems .", "tokens": ["recurrent", "neural", "networks", "have", "been", "shown", "to", "achieve", "promising", "results", "on", "many", "difficult", "sequential", "learning", "problems", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "recurrent neural networks", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "have been shown", "start": 26, "end": 41, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 17, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 45, "end": 52, "i_start": 7, "i_end": 7}}, {"character": {"text": "results", "start": 63, "end": 70, "i_start": 9, "i_end": 9}, "action": {"text": "promising", "start": 53, "end": 62, "i_start": 8, "i_end": 8}}], "id": 254}, {"sent": "because the intersection points are primary , a resonance zone is bounded by a jordan curve and has exit and entry sets .", "tokens": ["because", "the", "intersection", "points", "are", "primary", ",", "a", "resonance", "zone", "is", "bounded", "by", "a", "jordan", "curve", "and", "has", "exit", "and", "entry", "sets", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a resonance zone", "start": 46, "end": 62, "i_start": 7, "i_end": 9}, "verb": {"text": "is bounded", "start": 63, "end": 73, "i_start": 10, "i_end": 11}}, {"subject": {"text": "a resonance zone", "start": 46, "end": 62, "i_start": 7, "i_end": 9}, "verb": {"text": "has", "start": 96, "end": 99, "i_start": 17, "i_end": 17}}, {"character": {"text": "primary", "start": 36, "end": 43, "i_start": 5, "i_end": 5}, "action": {"text": "because", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}, {"character": {"text": "zone", "start": 58, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "has", "start": 96, "end": 99, "i_start": 17, "i_end": 17}}], "id": 255}, {"sent": "activity recognition has been a popular research topic in computer vision .", "tokens": ["activity", "recognition", "has", "been", "a", "popular", "research", "topic", "in", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "activity recognition", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "has been", "start": 21, "end": 29, "i_start": 2, "i_end": 3}}], "id": 256}, {"sent": "recently , rydberg atoms have attracted interest as a possible implementation of quantum information processing based on neutral atoms .", "tokens": ["recently", ",", "rydberg", "atoms", "have", "attracted", "interest", "as", "a", "possible", "implementation", "of", "quantum", "information", "processing", "based", "on", "neutral", "atoms", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "rydberg atoms", "start": 11, "end": 24, "i_start": 2, "i_end": 3}, "verb": {"text": "have attracted", "start": 25, "end": 39, "i_start": 4, "i_end": 5}}, {"character": {"text": "atoms", "start": 19, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "attracted", "start": 30, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "atoms", "start": 129, "end": 134, "i_start": 18, "i_end": 18}, "action": {"text": "neutral", "start": 121, "end": 128, "i_start": 17, "i_end": 17}}], "id": 257}, {"sent": "the advances in convolutional neural networks have successfully pushed the limits and improved the stateof-the-art technologies of image and video understanding .", "tokens": ["the", "advances", "in", "convolutional", "neural", "networks", "have", "successfully", "pushed", "the", "limits", "and", "improved", "the", "stateof", "-", "the", "-", "art", "technologies", "of", "image", "and", "video", "understanding", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the advances in convolutional neural networks", "start": 0, "end": 45, "i_start": 0, "i_end": 5}, "verb": {"text": "pushed", "start": 64, "end": 70, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the advances in convolutional neural networks", "start": 0, "end": 45, "i_start": 0, "i_end": 5}, "verb": {"text": "have", "start": 46, "end": 50, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the advances in convolutional neural networks", "start": 0, "end": 45, "i_start": 0, "i_end": 5}, "verb": {"text": "improved", "start": 86, "end": 94, "i_start": 12, "i_end": 12}}, {"character": {"text": "advances", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "pushed", "start": 64, "end": 70, "i_start": 8, "i_end": 8}}, {"character": {"text": "advances", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "improved", "start": 86, "end": 94, "i_start": 12, "i_end": 12}}], "id": 258}, {"sent": "huang and wang established the uniqueness of the weak solution to zero-pressure gas dynamics equations when the initial condition is a random measure .", "tokens": ["huang", "and", "wang", "established", "the", "uniqueness", "of", "the", "weak", "solution", "to", "zero", "-", "pressure", "gas", "dynamics", "equations", "when", "the", "initial", "condition", "is", "a", "random", "measure", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "huang and wang", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "established", "start": 15, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "huang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "established", "start": 15, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "wang", "start": 10, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "established", "start": 15, "end": 26, "i_start": 3, "i_end": 3}}], "id": 259}, {"sent": "which satisfies \u03c6 is called a sequential isomorphism .", "tokens": ["which", "satisfies", "\u03c6", "is", "called", "a", "sequential", "isomorphism", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 260}, {"sent": "the orthogonal polynomials here are the stieltjes-wigert polynomials .", "tokens": ["the", "orthogonal", "polynomials", "here", "are", "the", "stieltjes", "-", "wigert", "polynomials", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the orthogonal polynomials here", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 4, "i_end": 4}}], "id": 261}, {"sent": "deep convolutional neural networks have been successfully used in various computer vision applications such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successfully", "used", "in", "various", "computer", "vision", "applications", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "used", "start": 58, "end": 62, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}], "id": 262}, {"sent": "we use the python scikit library to implement the machine learning model .", "tokens": ["we", "use", "the", "python", "scikit", "library", "to", "implement", "the", "machine", "learning", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implement", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}], "id": 263}, {"sent": "this counterterm is a global one as it treats the ir divergences of the sum of all diagrams .", "tokens": ["this", "counterterm", "is", "a", "global", "one", "as", "it", "treats", "the", "ir", "divergences", "of", "the", "sum", "of", "all", "diagrams", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this counterterm", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "counterterm", "start": 5, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "treats", "start": 39, "end": 45, "i_start": 8, "i_end": 8}}, {"character": {"text": "sum", "start": 72, "end": 75, "i_start": 14, "i_end": 14}, "action": {"text": "divergences", "start": 53, "end": 64, "i_start": 11, "i_end": 11}}], "id": 264}, {"sent": "in 1984 , bennett and brassard proposed a protocol to share secret keys by using quantum method , which is called the bb84 protocol .", "tokens": ["in", "1984", ",", "bennett", "and", "brassard", "proposed", "a", "protocol", "to", "share", "secret", "keys", "by", "using", "quantum", "method", ",", "which", "is", "called", "the", "bb84", "protocol", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bennett and brassard", "start": 10, "end": 30, "i_start": 3, "i_end": 5}, "verb": {"text": "proposed", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "bennett", "start": 10, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "proposed", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "brassard", "start": 22, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "proposed", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}], "id": 265}, {"sent": "density-functional theory calculations were performed using the vienna ab-initio simulation package with projected augmented wave potential 38 , 39 .", "tokens": ["density", "-", "functional", "theory", "calculations", "were", "performed", "using", "the", "vienna", "ab", "-", "initio", "simulation", "package", "with", "projected", "augmented", "wave", "potential", "38", ",", "39", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "density-functional theory calculations", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "were performed", "start": 39, "end": 53, "i_start": 5, "i_end": 6}}], "id": 266}, {"sent": "influence of generic scale invariance on quantum critical behavior we now turn to quantum systems .", "tokens": ["influence", "of", "generic", "scale", "invariance", "on", "quantum", "critical", "behavior", "we", "now", "turn", "to", "quantum", "systems", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 67, "end": 69, "i_start": 9, "i_end": 9}, "verb": {"text": "turn", "start": 74, "end": 78, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 67, "end": 69, "i_start": 9, "i_end": 9}, "action": {"text": "turn", "start": 74, "end": 78, "i_start": 11, "i_end": 11}}, {"character": {"text": "invariance", "start": 27, "end": 37, "i_start": 4, "i_end": 4}, "action": {"text": "influence", "start": 0, "end": 9, "i_start": 0, "i_end": 0}}], "id": 267}, {"sent": "the wigner transform is a useful tool in the analysis of the semi-classical limits of non-dissipative evolution equations as well as in the high frequency wave propagation .", "tokens": ["the", "wigner", "transform", "is", "a", "useful", "tool", "in", "the", "analysis", "of", "the", "semi", "-", "classical", "limits", "of", "non", "-", "dissipative", "evolution", "equations", "as", "well", "as", "in", "the", "high", "frequency", "wave", "propagation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the wigner transform", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 3, "i_end": 3}}], "id": 268}, {"sent": "in , it is shown that the relaxation model provides such a consistant approximation .", "tokens": ["in", ",", "it", "is", "shown", "that", "the", "relaxation", "model", "provides", "such", "a", "consistant", "approximation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "verb": {"text": "is shown", "start": 8, "end": 16, "i_start": 3, "i_end": 4}}, {"subject": {"text": "the relaxation model", "start": 22, "end": 42, "i_start": 6, "i_end": 8}, "verb": {"text": "provides", "start": 43, "end": 51, "i_start": 9, "i_end": 9}}, {"character": {"text": "model", "start": 37, "end": 42, "i_start": 8, "i_end": 8}, "action": {"text": "provides", "start": 43, "end": 51, "i_start": 9, "i_end": 9}}], "id": 269}, {"sent": "the transmitted signal vector at the bs can be expressed as .", "tokens": ["the", "transmitted", "signal", "vector", "at", "the", "bs", "can", "be", "expressed", "as", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the transmitted signal vector at the bs", "start": 0, "end": 39, "i_start": 0, "i_end": 6}, "verb": {"text": "can be expressed", "start": 40, "end": 56, "i_start": 7, "i_end": 9}}], "id": 270}, {"sent": "the generalized gradient approximation was used in conjunction with the perdew , burke , and ernzerhof density functional .", "tokens": ["the", "generalized", "gradient", "approximation", "was", "used", "in", "conjunction", "with", "the", "perdew", ",", "burke", ",", "and", "ernzerhof", "density", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation", "start": 0, "end": 38, "i_start": 0, "i_end": 3}, "verb": {"text": "was used", "start": 39, "end": 47, "i_start": 4, "i_end": 5}}], "id": 271}, {"sent": "we use the imagenet pretrained models to initialize the shared convolutional layers and the corresponding 4096-d fc layers .", "tokens": ["we", "use", "the", "imagenet", "pretrained", "models", "to", "initialize", "the", "shared", "convolutional", "layers", "and", "the", "corresponding", "4096", "-", "d", "fc", "layers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "initialize", "start": 41, "end": 51, "i_start": 7, "i_end": 7}}], "id": 272}, {"sent": "in the canted c-phase the dos is quasi one-dimensional with peaks towards the band edges .", "tokens": ["in", "the", "canted", "c", "-", "phase", "the", "dos", "is", "quasi", "one", "-", "dimensional", "with", "peaks", "towards", "the", "band", "edges", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dos", "start": 22, "end": 29, "i_start": 6, "i_end": 7}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 8, "i_end": 8}}], "id": 273}, {"sent": "differential privacy is a recent privacy definition that has quickly become the standard notion of privacy in statistical databases .", "tokens": ["differential", "privacy", "is", "a", "recent", "privacy", "definition", "that", "has", "quickly", "become", "the", "standard", "notion", "of", "privacy", "in", "statistical", "databases", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "differential privacy", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 2, "i_end": 2}}], "id": 274}, {"sent": "the qubit consists of the singlet state and one of the triplet states of two electrons or simply of an electron spin .", "tokens": ["the", "qubit", "consists", "of", "the", "singlet", "state", "and", "one", "of", "the", "triplet", "states", "of", "two", "electrons", "or", "simply", "of", "an", "electron", "spin", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the qubit", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 10, "end": 18, "i_start": 2, "i_end": 2}}], "id": 275}, {"sent": "deep symmetry networks generalize cnn and compute features over arbitrary symmetry groups .", "tokens": ["deep", "symmetry", "networks", "generalize", "cnn", "and", "compute", "features", "over", "arbitrary", "symmetry", "groups", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep symmetry networks", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "generalize", "start": 23, "end": 33, "i_start": 3, "i_end": 3}}, {"subject": {"text": "compute", "start": 42, "end": 49, "i_start": 6, "i_end": 6}, "verb": {"text": "features", "start": 50, "end": 58, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 14, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "generalize", "start": 23, "end": 33, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 14, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "compute", "start": 42, "end": 49, "i_start": 6, "i_end": 6}}], "id": 276}, {"sent": "the encoder and decoder were both implemented using the gru .", "tokens": ["the", "encoder", "and", "decoder", "were", "both", "implemented", "using", "the", "gru", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the encoder and decoder", "start": 0, "end": 23, "i_start": 0, "i_end": 3}, "verb": {"text": "implemented", "start": 34, "end": 45, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the encoder and decoder", "start": 0, "end": 23, "i_start": 0, "i_end": 3}, "verb": {"text": "were", "start": 24, "end": 28, "i_start": 4, "i_end": 4}}], "id": 277}, {"sent": "the axiom is the initial state of the system .", "tokens": ["the", "axiom", "is", "the", "initial", "state", "of", "the", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the axiom", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}], "id": 278}, {"sent": "in recent years , deep neural networks have achieved significant breakthroughs in many machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "achieved", "significant", "breakthroughs", "in", "many", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "breakthroughs", "start": 65, "end": 78, "i_start": 10, "i_end": 10}}], "id": 279}, {"sent": "see , for example , bien , taylor , and tibshirani , hao , feng , and zhang , zhao and leng and references therein .", "tokens": ["see", ",", "for", "example", ",", "bien", ",", "taylor", ",", "and", "tibshirani", ",", "hao", ",", "feng", ",", "and", "zhang", ",", "zhao", "and", "leng", "and", "references", "therein", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 280}, {"sent": "we used many auxiliary techniques , including xavier initialization for convergence .", "tokens": ["we", "used", "many", "auxiliary", "techniques", ",", "including", "xavier", "initialization", "for", "convergence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 281}, {"sent": "preprojective algebra play an important role in representation theory of algebras .", "tokens": ["preprojective", "algebra", "play", "an", "important", "role", "in", "representation", "theory", "of", "algebras", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "preprojective algebra", "start": 0, "end": 21, "i_start": 0, "i_end": 1}, "verb": {"text": "play", "start": 22, "end": 26, "i_start": 2, "i_end": 2}}, {"character": {"text": "algebra", "start": 14, "end": 21, "i_start": 1, "i_end": 1}, "action": {"text": "play", "start": 22, "end": 26, "i_start": 2, "i_end": 2}}], "id": 282}, {"sent": "the coulomb energy is the same for the two configurations , but the surface energy is higher in .", "tokens": ["the", "coulomb", "energy", "is", "the", "same", "for", "the", "two", "configurations", ",", "but", "the", "surface", "energy", "is", "higher", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the coulomb energy", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 283}, {"sent": "goodfellow et al presented a method to generate adversarial examples and also showed that retraining the network with these examples can be used for regularization .", "tokens": ["goodfellow", "et", "al", "presented", "a", "method", "to", "generate", "adversarial", "examples", "and", "also", "showed", "that", "retraining", "the", "network", "with", "these", "examples", "can", "be", "used", "for", "regularization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "presented", "start": 17, "end": 26, "i_start": 3, "i_end": 3}}, {"subject": {"text": "goodfellow et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 78, "end": 84, "i_start": 12, "i_end": 12}}, {"character": {"text": "goodfellow", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "presented", "start": 17, "end": 26, "i_start": 3, "i_end": 3}}], "id": 284}, {"sent": "deep convolutional neural networks have led to major breakthroughs in many computer vision tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "led", "to", "major", "breakthroughs", "in", "many", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have led", "start": 35, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "led", "start": 40, "end": 43, "i_start": 5, "i_end": 5}}], "id": 285}, {"sent": "large scale multiple-input multiple-output systems , also known as massive mimo systems , are considered as a promising technology in modern wireless networks .", "tokens": ["large", "scale", "multiple", "-", "input", "multiple", "-", "output", "systems", ",", "also", "known", "as", "massive", "mimo", "systems", ",", "are", "considered", "as", "a", "promising", "technology", "in", "modern", "wireless", "networks", "."], "score": [1, 1, 1, 0, 1], "labels": [{"subject": {"text": "large scale multiple-input multiple-output systems", "start": 0, "end": 50, "i_start": 0, "i_end": 8}, "verb": {"text": "are considered", "start": 90, "end": 104, "i_start": 17, "i_end": 18}}, {"character": {"text": "technology", "start": 120, "end": 130, "i_start": 22, "i_end": 22}, "action": {"text": "promising", "start": 110, "end": 119, "i_start": 21, "i_end": 21}}], "id": 286}, {"sent": "region-based approaches with convolutional neural networks have achieved great success in object detection .", "tokens": ["region", "-", "based", "approaches", "with", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "region-based approaches with convolutional neural networks", "start": 0, "end": 58, "i_start": 0, "i_end": 7}, "verb": {"text": "have achieved", "start": 59, "end": 72, "i_start": 8, "i_end": 9}}, {"character": {"text": "approaches", "start": 13, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 64, "end": 72, "i_start": 9, "i_end": 9}}, {"character": {"text": "approaches", "start": 13, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 79, "end": 86, "i_start": 11, "i_end": 11}}], "id": 287}, {"sent": "recently , there has been much interest in noncommutative field theory motivated by the string theory .", "tokens": ["recently", ",", "there", "has", "been", "much", "interest", "in", "noncommutative", "field", "theory", "motivated", "by", "the", "string", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "has been", "start": 17, "end": 25, "i_start": 3, "i_end": 4}}, {"character": {"text": "theory", "start": 95, "end": 101, "i_start": 15, "i_end": 15}, "action": {"text": "motivated", "start": 71, "end": 80, "i_start": 11, "i_end": 11}}], "id": 288}, {"sent": "the points marked on the tracks indicate the time taken in myr to reach that point from the onset of the burst .", "tokens": ["the", "points", "marked", "on", "the", "tracks", "indicate", "the", "time", "taken", "in", "myr", "to", "reach", "that", "point", "from", "the", "onset", "of", "the", "burst", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the points marked on the tracks", "start": 0, "end": 31, "i_start": 0, "i_end": 5}, "verb": {"text": "indicate", "start": 32, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "points", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "indicate", "start": 32, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "reach", "start": 66, "end": 71, "i_start": 13, "i_end": 13}, "action": {"text": "taken", "start": 50, "end": 55, "i_start": 9, "i_end": 9}}], "id": 289}, {"sent": "we make use of this dispersion relation to calculate the frequencies and the damping rates for monopole and quadrupole mode in both the regimes .", "tokens": ["we", "make", "use", "of", "this", "dispersion", "relation", "to", "calculate", "the", "frequencies", "and", "the", "damping", "rates", "for", "monopole", "and", "quadrupole", "mode", "in", "both", "the", "regimes", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "make", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "calculate", "start": 43, "end": 52, "i_start": 8, "i_end": 8}}], "id": 290}, {"sent": "the spectral resolution is the same to within measurement error through these three slits .", "tokens": ["the", "spectral", "resolution", "is", "the", "same", "to", "within", "measurement", "error", "through", "these", "three", "slits", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the spectral resolution", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}], "id": 291}, {"sent": "the dice factor for the proposed algorithm and the algorithms in for the first subject .", "tokens": ["the", "dice", "factor", "for", "the", "proposed", "algorithm", "and", "the", "algorithms", "in", "for", "the", "first", "subject", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 292}, {"sent": "the ordinate is the portion of the integrated flux of the source that was detected by the source finder .", "tokens": ["the", "ordinate", "is", "the", "portion", "of", "the", "integrated", "flux", "of", "the", "source", "that", "was", "detected", "by", "the", "source", "finder", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ordinate", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 293}, {"sent": "but we have class of s-loops which satisfies the s-lagranges criteria .", "tokens": ["but", "we", "have", "class", "of", "s", "-", "loops", "which", "satisfies", "the", "s", "-", "lagranges", "criteria", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "have", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "have", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "class", "start": 12, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "satisfies", "start": 35, "end": 44, "i_start": 9, "i_end": 9}}], "id": 294}, {"sent": "bello et al used reinforcement learning to train a deep q-network to incrementally construct solutions to graph-based np-hard problems , and showed that this approach outperforms prior learning-based techniques .", "tokens": ["bello", "et", "al", "used", "reinforcement", "learning", "to", "train", "a", "deep", "q", "-", "network", "to", "incrementally", "construct", "solutions", "to", "graph", "-", "based", "np", "-", "hard", "problems", ",", "and", "showed", "that", "this", "approach", "outperforms", "prior", "learning", "-", "based", "techniques", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bello et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 12, "end": 16, "i_start": 3, "i_end": 3}}, {"subject": {"text": "bello et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 141, "end": 147, "i_start": 27, "i_end": 27}}, {"character": {"text": "bello", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 12, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "bello", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 43, "end": 48, "i_start": 7, "i_end": 7}}, {"character": {"text": "bello", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "construct", "start": 83, "end": 92, "i_start": 15, "i_end": 15}}], "id": 295}, {"sent": "convolutional neural networks have been largely responsible for the significant progress achieved on visual recognition tasks in recent years .", "tokens": ["convolutional", "neural", "networks", "have", "been", "largely", "responsible", "for", "the", "significant", "progress", "achieved", "on", "visual", "recognition", "tasks", "in", "recent", "years", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "responsible", "start": 48, "end": 59, "i_start": 6, "i_end": 6}}], "id": 296}, {"sent": "convolutional neural networks have become a standard tool for machine learning in euclidean domains , such as images .", "tokens": ["convolutional", "neural", "networks", "have", "become", "a", "standard", "tool", "for", "machine", "learning", "in", "euclidean", "domains", ",", "such", "as", "images", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have become", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}], "id": 297}, {"sent": "the apparatus consist of davinci xyz positioning system with bridge mounted y-z slide .", "tokens": ["the", "apparatus", "consist", "of", "davinci", "xyz", "positioning", "system", "with", "bridge", "mounted", "y", "-", "z", "slide", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the apparatus consist of davinci xyz positioning system with bridge", "start": 0, "end": 67, "i_start": 0, "i_end": 9}, "verb": {"text": "mounted", "start": 68, "end": 75, "i_start": 10, "i_end": 10}}], "id": 298}, {"sent": "compressive sensing is a promising technique that recovers a high-dimensional signal represented by a few non-zero elements using far-fewer measurements than the signal dimension .", "tokens": ["compressive", "sensing", "is", "a", "promising", "technique", "that", "recovers", "a", "high", "-", "dimensional", "signal", "represented", "by", "a", "few", "non", "-", "zero", "elements", "using", "far", "-", "fewer", "measurements", "than", "the", "signal", "dimension", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "compressive sensing", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "technique", "start": 35, "end": 44, "i_start": 5, "i_end": 5}, "action": {"text": "promising", "start": 25, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "technique", "start": 35, "end": 44, "i_start": 5, "i_end": 5}, "action": {"text": "recovers", "start": 50, "end": 58, "i_start": 7, "i_end": 7}}, {"character": {"text": "elements", "start": 115, "end": 123, "i_start": 20, "i_end": 20}, "action": {"text": "represented", "start": 85, "end": 96, "i_start": 13, "i_end": 13}}], "id": 299}, {"sent": "following their success in several computer vision tasks , neural networks have received considerable attention in the context of image processing .", "tokens": ["following", "their", "success", "in", "several", "computer", "vision", "tasks", ",", "neural", "networks", "have", "received", "considerable", "attention", "in", "the", "context", "of", "image", "processing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 59, "end": 74, "i_start": 9, "i_end": 10}, "verb": {"text": "have received", "start": 75, "end": 88, "i_start": 11, "i_end": 12}}, {"character": {"text": "networks", "start": 66, "end": 74, "i_start": 10, "i_end": 10}, "action": {"text": "success", "start": 16, "end": 23, "i_start": 2, "i_end": 2}}], "id": 300}, {"sent": "the recent success of deep convolutional neural network models .", "tokens": ["the", "recent", "success", "of", "deep", "convolutional", "neural", "network", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "models", "start": 56, "end": 62, "i_start": 8, "i_end": 8}, "action": {"text": "success", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}], "id": 301}, {"sent": "stochastic geometry is a powerful mathematical tool that has recently been proposed to model and analyze the performance of wireless networks .", "tokens": ["stochastic", "geometry", "is", "a", "powerful", "mathematical", "tool", "that", "has", "recently", "been", "proposed", "to", "model", "and", "analyze", "the", "performance", "of", "wireless", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "stochastic geometry", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 2, "i_end": 2}}], "id": 302}, {"sent": "bicnet proposed the bidirectional rnns to exchange information between agents in an actor-critic setting .", "tokens": ["bicnet", "proposed", "the", "bidirectional", "rnns", "to", "exchange", "information", "between", "agents", "in", "an", "actor", "-", "critic", "setting", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "bicnet", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "proposed", "start": 7, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "agents", "start": 71, "end": 77, "i_start": 9, "i_end": 9}, "action": {"text": "exchange", "start": 42, "end": 50, "i_start": 6, "i_end": 6}}], "id": 303}, {"sent": "the batch normalization layer is also applied after each convolution layer .", "tokens": ["the", "batch", "normalization", "layer", "is", "also", "applied", "after", "each", "convolution", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the batch normalization layer", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "applied", "start": 38, "end": 45, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the batch normalization layer", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 4, "i_end": 4}}], "id": 304}, {"sent": "continuous-variable quantum key distribution provides an easily implementable solution to realize unconditional secure communication over the current telecommunication networks .", "tokens": ["continuous", "-", "variable", "quantum", "key", "distribution", "provides", "an", "easily", "implementable", "solution", "to", "realize", "unconditional", "secure", "communication", "over", "the", "current", "telecommunication", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "continuous-variable quantum key distribution", "start": 0, "end": 44, "i_start": 0, "i_end": 5}, "verb": {"text": "provides", "start": 45, "end": 53, "i_start": 6, "i_end": 6}}, {"character": {"text": "distribution", "start": 32, "end": 44, "i_start": 5, "i_end": 5}, "action": {"text": "provides", "start": 45, "end": 53, "i_start": 6, "i_end": 6}}], "id": 305}, {"sent": "the first one is flickr material dataset , which contains 10 material classes .", "tokens": ["the", "first", "one", "is", "flickr", "material", "dataset", ",", "which", "contains", "10", "material", "classes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the first one", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "dataset", "start": 33, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "contains", "start": 49, "end": 57, "i_start": 9, "i_end": 9}}], "id": 306}, {"sent": "convolutional neural networks have been instrumental to the recent breakthroughs in computer vision .", "tokens": ["convolutional", "neural", "networks", "have", "been", "instrumental", "to", "the", "recent", "breakthroughs", "in", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}], "id": 307}, {"sent": "we claim that \u03c4 satisfies the composition axiom for pseudo natural transfor mations .", "tokens": ["we", "claim", "that", "\u03c4", "satisfies", "the", "composition", "axiom", "for", "pseudo", "natural", "transfor", "mations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "claim", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "\u03c4", "start": 14, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "satisfies", "start": 16, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "claim", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 308}, {"sent": "we train the network using adam stochastic optimization to learn network parameters , with the batch size set to 40 .", "tokens": ["we", "train", "the", "network", "using", "adam", "stochastic", "optimization", "to", "learn", "network", "parameters", ",", "with", "the", "batch", "size", "set", "to", "40", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "network", "start": 13, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "learn", "start": 59, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "adam stochastic", "start": 27, "end": 42, "i_start": 5, "i_end": 6}, "action": {"text": "optimization", "start": 43, "end": 55, "i_start": 7, "i_end": 7}}], "id": 309}, {"sent": "effect of the tip-host coupling first , we consider the effect of the tip-host coupling only , where the tip-impurity coupling is neglected .", "tokens": ["effect", "of", "the", "tip", "-", "host", "coupling", "first", ",", "we", "consider", "the", "effect", "of", "the", "tip", "-", "host", "coupling", "only", ",", "where", "the", "tip", "-", "impurity", "coupling", "is", "neglected", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 40, "end": 42, "i_start": 9, "i_end": 9}, "verb": {"text": "consider", "start": 43, "end": 51, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 40, "end": 42, "i_start": 9, "i_end": 9}, "action": {"text": "consider", "start": 43, "end": 51, "i_start": 10, "i_end": 10}}], "id": 310}, {"sent": "later , goodfellow et al proposed fast gradient sign method to generate adversarial samples .", "tokens": ["later", ",", "goodfellow", "et", "al", "proposed", "fast", "gradient", "sign", "method", "to", "generate", "adversarial", "samples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 8, "end": 24, "i_start": 2, "i_end": 4}, "verb": {"text": "proposed", "start": 25, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "goodfellow", "start": 8, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "proposed", "start": 25, "end": 33, "i_start": 5, "i_end": 5}}], "id": 311}, {"sent": "dthis is the limit on absorption from the approaching side of the snr .", "tokens": ["dthis", "is", "the", "limit", "on", "absorption", "from", "the", "approaching", "side", "of", "the", "snr", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dthis", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "side", "start": 54, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "absorption", "start": 22, "end": 32, "i_start": 5, "i_end": 5}}], "id": 312}, {"sent": "for the embedding networks , we employ the widely used resnet architecture .", "tokens": ["for", "the", "embedding", "networks", ",", "we", "employ", "the", "widely", "used", "resnet", "architecture", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "verb": {"text": "employ", "start": 32, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "employ", "start": 32, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 18, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "embedding", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}], "id": 313}, {"sent": "deep learning has brought significant breakthroughs in many computer vision tasks , including object detection .", "tokens": ["deep", "learning", "has", "brought", "significant", "breakthroughs", "in", "many", "computer", "vision", "tasks", ",", "including", "object", "detection", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has brought", "start": 14, "end": 25, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "breakthroughs", "start": 38, "end": 51, "i_start": 5, "i_end": 5}}], "id": 314}, {"sent": "the fitted model is a cutoff power-law with neutral photo-electric absorption .", "tokens": ["the", "fitted", "model", "is", "a", "cutoff", "power", "-", "law", "with", "neutral", "photo", "-", "electric", "absorption", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the fitted model", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "absorption", "start": 67, "end": 77, "i_start": 14, "i_end": 14}, "action": {"text": "neutral", "start": 44, "end": 51, "i_start": 10, "i_end": 10}}], "id": 315}, {"sent": "the higgs boson , whose existence is predicted by the brout-englert-higgs mechanism , is responsible for electroweak symmetry breaking in the standard model .", "tokens": ["the", "higgs", "boson", ",", "whose", "existence", "is", "predicted", "by", "the", "brout", "-", "englert", "-", "higgs", "mechanism", ",", "is", "responsible", "for", "electroweak", "symmetry", "breaking", "in", "the", "standard", "model", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "the higgs boson", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 86, "end": 88, "i_start": 17, "i_end": 17}}, {"character": {"text": "boson", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "responsible", "start": 89, "end": 100, "i_start": 18, "i_end": 18}}, {"character": {"text": "mechanism", "start": 74, "end": 83, "i_start": 15, "i_end": 15}, "action": {"text": "predicted", "start": 37, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "boson", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "breaking", "start": 126, "end": 134, "i_start": 22, "i_end": 22}}], "id": 316}, {"sent": "we refer the reader to for the basic properties of o-minimal structures .", "tokens": ["we", "refer", "the", "reader", "to", "for", "the", "basic", "properties", "of", "o", "-", "minimal", "structures", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 317}, {"sent": "efficiency is a primary driver of cost for solar cells .", "tokens": ["efficiency", "is", "a", "primary", "driver", "of", "cost", "for", "solar", "cells", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "efficiency", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "efficiency", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "driver", "start": 24, "end": 30, "i_start": 4, "i_end": 4}}], "id": 318}, {"sent": "a choice of such isomorphism is called a complex orientation of e .", "tokens": ["a", "choice", "of", "such", "isomorphism", "is", "called", "a", "complex", "orientation", "of", "e", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a choice of such isomorphism", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "is called", "start": 29, "end": 38, "i_start": 5, "i_end": 6}}], "id": 319}, {"sent": "all networks are trained using the adam optimizer , which is based on a gradient descent .", "tokens": ["all", "networks", "are", "trained", "using", "the", "adam", "optimizer", ",", "which", "is", "based", "on", "a", "gradient", "descent", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all networks", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "are trained", "start": 13, "end": 24, "i_start": 2, "i_end": 3}}], "id": 320}, {"sent": "in recent years , deep neural networks have revolutionized machine-learning tasks such as image classification , speech recognition , and language translation .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "revolutionized", "machine", "-", "learning", "tasks", "such", "as", "image", "classification", ",", "speech", "recognition", ",", "and", "language", "translation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have revolutionized", "start": 39, "end": 58, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "revolutionized", "start": 44, "end": 58, "i_start": 8, "i_end": 8}}], "id": 321}, {"sent": "this type of hierarchy was first considered in statistical physics and is sometimes known as the bogoliubovborn-green-kirkwood-yvon hierarchy .", "tokens": ["this", "type", "of", "hierarchy", "was", "first", "considered", "in", "statistical", "physics", "and", "is", "sometimes", "known", "as", "the", "bogoliubovborn", "-", "green", "-", "kirkwood", "-", "yvon", "hierarchy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this type of hierarchy", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "considered", "start": 33, "end": 43, "i_start": 6, "i_end": 6}}, {"subject": {"text": "this type of hierarchy", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "was", "start": 23, "end": 26, "i_start": 4, "i_end": 4}}, {"subject": {"text": "this type of hierarchy", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "known", "start": 84, "end": 89, "i_start": 13, "i_end": 13}}], "id": 322}, {"sent": "also here we establish the relation between the structures of norm and innerproduct on hyperspaces .", "tokens": ["also", "here", "we", "establish", "the", "relation", "between", "the", "structures", "of", "norm", "and", "innerproduct", "on", "hyperspaces", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "establish", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "innerproduct", "start": 71, "end": 83, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "establish", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}], "id": 323}, {"sent": "in this paper , we perform graph-based clustering using the louvain method .", "tokens": ["in", "this", "paper", ",", "we", "perform", "graph", "-", "based", "clustering", "using", "the", "louvain", "method", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "perform", "start": 19, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "perform", "start": 19, "end": 26, "i_start": 5, "i_end": 5}}], "id": 324}, {"sent": "concerning the converse we will prove the following proposition .", "tokens": ["concerning", "the", "converse", "we", "will", "prove", "the", "following", "proposition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 24, "end": 26, "i_start": 3, "i_end": 3}, "verb": {"text": "will prove", "start": 27, "end": 37, "i_start": 4, "i_end": 5}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "prove", "start": 32, "end": 37, "i_start": 5, "i_end": 5}}], "id": 325}, {"sent": "in the past few years , many mil algorithms have been successfully used for weakly supervised learning , such as milboost .", "tokens": ["in", "the", "past", "few", "years", ",", "many", "mil", "algorithms", "have", "been", "successfully", "used", "for", "weakly", "supervised", "learning", ",", "such", "as", "milboost", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many mil algorithms", "start": 24, "end": 43, "i_start": 6, "i_end": 8}, "verb": {"text": "used", "start": 67, "end": 71, "i_start": 12, "i_end": 12}}, {"subject": {"text": "many mil algorithms", "start": 24, "end": 43, "i_start": 6, "i_end": 8}, "verb": {"text": "have been", "start": 44, "end": 53, "i_start": 9, "i_end": 10}}], "id": 326}, {"sent": "more specifically , the vgg16 network is a deep convolutional neural network that has been proved successful on classification tasks on imagenet .", "tokens": ["more", "specifically", ",", "the", "vgg16", "network", "is", "a", "deep", "convolutional", "neural", "network", "that", "has", "been", "proved", "successful", "on", "classification", "tasks", "on", "imagenet", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the vgg16 network", "start": 20, "end": 37, "i_start": 3, "i_end": 5}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "network", "start": 30, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "successful", "start": 98, "end": 108, "i_start": 16, "i_end": 16}}], "id": 327}, {"sent": "this geometry is the area covered by the imaging , by the set of survey tiles , and not near tycho stars .", "tokens": ["this", "geometry", "is", "the", "area", "covered", "by", "the", "imaging", ",", "by", "the", "set", "of", "survey", "tiles", ",", "and", "not", "near", "tycho", "stars", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this geometry", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "set", "start": 58, "end": 61, "i_start": 12, "i_end": 12}, "action": {"text": "covered", "start": 26, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "tiles", "start": 72, "end": 77, "i_start": 15, "i_end": 15}, "action": {"text": "covered", "start": 26, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "survey", "start": 65, "end": 71, "i_start": 14, "i_end": 14}, "action": {"text": "covered", "start": 26, "end": 33, "i_start": 5, "i_end": 5}}], "id": 328}, {"sent": "now we proceed on to define non-associative smarandache seminear-ring .", "tokens": ["now", "we", "proceed", "on", "to", "define", "non", "-", "associative", "smarandache", "seminear", "-", "ring", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed on", "start": 7, "end": 17, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 329}, {"sent": "it encodes the quality of being canonical quantizers along a guideline established by klauder .", "tokens": ["it", "encodes", "the", "quality", "of", "being", "canonical", "quantizers", "along", "a", "guideline", "established", "by", "klauder", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "encodes", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "encodes", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "klauder", "start": 86, "end": 93, "i_start": 13, "i_end": 13}, "action": {"text": "established", "start": 71, "end": 82, "i_start": 11, "i_end": 11}}], "id": 330}, {"sent": "jiang et al use easy samples first to perform re-ranking of the initial video list .", "tokens": ["jiang", "et", "al", "use", "easy", "samples", "first", "to", "perform", "re", "-", "ranking", "of", "the", "initial", "video", "list", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "jiang et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "use", "start": 12, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "jiang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 12, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "jiang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "perform", "start": 38, "end": 45, "i_start": 8, "i_end": 8}}, {"character": {"text": "jiang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "ranking", "start": 49, "end": 56, "i_start": 11, "i_end": 11}}], "id": 331}, {"sent": "it is shown in several previous works that such kind of classification task could greatly benefit the feature learning .", "tokens": ["it", "is", "shown", "in", "several", "previous", "works", "that", "such", "kind", "of", "classification", "task", "could", "greatly", "benefit", "the", "feature", "learning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is shown", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"subject": {"text": "such kind of classification task", "start": 43, "end": 75, "i_start": 8, "i_end": 12}, "verb": {"text": "benefit", "start": 90, "end": 97, "i_start": 15, "i_end": 15}}, {"character": {"text": "task", "start": 71, "end": 75, "i_start": 12, "i_end": 12}, "action": {"text": "benefit", "start": 90, "end": 97, "i_start": 15, "i_end": 15}}], "id": 332}, {"sent": "all the weight matrices and bias vectors were initialized using glorot normal initializer and zero vectors respectively .", "tokens": ["all", "the", "weight", "matrices", "and", "bias", "vectors", "were", "initialized", "using", "glorot", "normal", "initializer", "and", "zero", "vectors", "respectively", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all the weight matrices and bias vectors", "start": 0, "end": 40, "i_start": 0, "i_end": 6}, "verb": {"text": "were initialized", "start": 41, "end": 57, "i_start": 7, "i_end": 8}}], "id": 333}, {"sent": "prior work introduces various visualizations in planar scatter plots of drs , in order to improve the user experience by communicating projection errors .", "tokens": ["prior", "work", "introduces", "various", "visualizations", "in", "planar", "scatter", "plots", "of", "drs", ",", "in", "order", "to", "improve", "the", "user", "experience", "by", "communicating", "projection", "errors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "prior work", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "introduces", "start": 11, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "work", "start": 6, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "introduces", "start": 11, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "work", "start": 6, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "improve", "start": 90, "end": 97, "i_start": 15, "i_end": 15}}, {"character": {"text": "work", "start": 6, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "communicating", "start": 121, "end": 134, "i_start": 20, "i_end": 20}}], "id": 334}, {"sent": "li et al proposed a energy functional that regularizes the distance function as the level set deviates from a sdf in the vicinity of the front .", "tokens": ["li", "et", "al", "proposed", "a", "energy", "functional", "that", "regularizes", "the", "distance", "function", "as", "the", "level", "set", "deviates", "from", "a", "sdf", "in", "the", "vicinity", "of", "the", "front", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "li et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "li", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "energy", "start": 20, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "function", "start": 68, "end": 76, "i_start": 11, "i_end": 11}}, {"character": {"text": "function", "start": 68, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "regularizes", "start": 43, "end": 54, "i_start": 8, "i_end": 8}}, {"character": {"text": "set", "start": 90, "end": 93, "i_start": 15, "i_end": 15}, "action": {"text": "deviates", "start": 94, "end": 102, "i_start": 16, "i_end": 16}}], "id": 335}, {"sent": "according to the agt correspondence the nekrasov partition function coincides with the conformal block in the liouville theory .", "tokens": ["according", "to", "the", "agt", "correspondence", "the", "nekrasov", "partition", "function", "coincides", "with", "the", "conformal", "block", "in", "the", "liouville", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "nekrasov", "start": 40, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "function", "start": 59, "end": 67, "i_start": 8, "i_end": 8}}], "id": 336}, {"sent": "alternatively , the exit functions of the constituent decoders and of the mud can be properly combined and projected into a two-dimensional chart .", "tokens": ["alternatively", ",", "the", "exit", "functions", "of", "the", "constituent", "decoders", "and", "of", "the", "mud", "can", "be", "properly", "combined", "and", "projected", "into", "a", "two", "-", "dimensional", "chart", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the exit functions of the constituent decoders and of the mud", "start": 16, "end": 77, "i_start": 2, "i_end": 12}, "verb": {"text": "combined", "start": 94, "end": 102, "i_start": 16, "i_end": 16}}, {"subject": {"text": "the exit functions of the constituent decoders and of the mud", "start": 16, "end": 77, "i_start": 2, "i_end": 12}, "verb": {"text": "can be", "start": 78, "end": 84, "i_start": 13, "i_end": 14}}, {"subject": {"text": "the exit functions of the constituent decoders and of the mud", "start": 16, "end": 77, "i_start": 2, "i_end": 12}, "verb": {"text": "projected", "start": 107, "end": 116, "i_start": 18, "i_end": 18}}, {"character": {"text": "decoders", "start": 54, "end": 62, "i_start": 8, "i_end": 8}, "action": {"text": "functions", "start": 25, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "constituent", "start": 42, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "functions", "start": 25, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "mud", "start": 74, "end": 77, "i_start": 12, "i_end": 12}, "action": {"text": "functions", "start": 25, "end": 34, "i_start": 4, "i_end": 4}}], "id": 337}, {"sent": "cs is a novel theory for signal sensing and acquisition able to acquire signals in an already compressed fashion , using fewer coefficients than dictated by the classical nyquist- shannon theory .", "tokens": ["cs", "is", "a", "novel", "theory", "for", "signal", "sensing", "and", "acquisition", "able", "to", "acquire", "signals", "in", "an", "already", "compressed", "fashion", ",", "using", "fewer", "coefficients", "than", "dictated", "by", "the", "classical", "nyquist-", "shannon", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cs", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"character": {"text": "theory", "start": 14, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "compressed", "start": 94, "end": 104, "i_start": 17, "i_end": 17}}, {"character": {"text": "theory", "start": 14, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "using", "start": 115, "end": 120, "i_start": 20, "i_end": 20}}, {"character": {"text": "theory", "start": 188, "end": 194, "i_start": 30, "i_end": 30}, "action": {"text": "dictated", "start": 145, "end": 153, "i_start": 24, "i_end": 24}}], "id": 338}, {"sent": "the next example is that of the axially symmetric graded index medium .", "tokens": ["the", "next", "example", "is", "that", "of", "the", "axially", "symmetric", "graded", "index", "medium", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the next example is that of the axially symmetric graded index medium", "start": 0, "end": 69, "i_start": 0, "i_end": 11}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 339}, {"sent": "in , a multi-task decomposition model , where each component matrix is regularized by a priori information organized in a graph , is proposed for head pose classification in an uncontrolled environment .", "tokens": ["in", ",", "a", "multi", "-", "task", "decomposition", "model", ",", "where", "each", "component", "matrix", "is", "regularized", "by", "a", "priori", "information", "organized", "in", "a", "graph", ",", "is", "proposed", "for", "head", "pose", "classification", "in", "an", "uncontrolled", "environment", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "a multi-task decomposition model", "start": 5, "end": 37, "i_start": 2, "i_end": 7}, "verb": {"text": "is proposed", "start": 130, "end": 141, "i_start": 24, "i_end": 25}}, {"character": {"text": "information", "start": 95, "end": 106, "i_start": 18, "i_end": 18}, "action": {"text": "regularized", "start": 71, "end": 82, "i_start": 14, "i_end": 14}}], "id": 340}, {"sent": "then we derive homological expressions for the holomorphic linking using the yoneda pairing .", "tokens": ["then", "we", "derive", "homological", "expressions", "for", "the", "holomorphic", "linking", "using", "the", "yoneda", "pairing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "derive", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "derive", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "using", "start": 67, "end": 72, "i_start": 9, "i_end": 9}}], "id": 341}, {"sent": "it is therefore natural to consider a corresponding reduction of the blg model .", "tokens": ["it", "is", "therefore", "natural", "to", "consider", "a", "corresponding", "reduction", "of", "the", "blg", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}], "id": 342}, {"sent": "in the context of hyperbolic conservation laws , many studies are based on the seminal work of tadmor concerning entropy stability of semidiscretisations .", "tokens": ["in", "the", "context", "of", "hyperbolic", "conservation", "laws", ",", "many", "studies", "are", "based", "on", "the", "seminal", "work", "of", "tadmor", "concerning", "entropy", "stability", "of", "semidiscretisations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many studies", "start": 49, "end": 61, "i_start": 8, "i_end": 9}, "verb": {"text": "are based", "start": 62, "end": 71, "i_start": 10, "i_end": 11}}, {"character": {"text": "tadmor", "start": 95, "end": 101, "i_start": 17, "i_end": 17}, "action": {"text": "work", "start": 87, "end": 91, "i_start": 15, "i_end": 15}}], "id": 343}, {"sent": "we calculate sentence similarity by using three major vector space models , tf-idf , latent semantic analysis , and latent dirichlet allocation .", "tokens": ["we", "calculate", "sentence", "similarity", "by", "using", "three", "major", "vector", "space", "models", ",", "tf", "-", "idf", ",", "latent", "semantic", "analysis", ",", "and", "latent", "dirichlet", "allocation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "calculate", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "calculate", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 36, "end": 41, "i_start": 5, "i_end": 5}}], "id": 344}, {"sent": "this is the first sign that rw optimal routing undo correlation between traffic load and network structure .", "tokens": ["this", "is", "the", "first", "sign", "that", "rw", "optimal", "routing", "undo", "correlation", "between", "traffic", "load", "and", "network", "structure", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "sign", "start": 18, "end": 22, "i_start": 4, "i_end": 4}}, {"character": {"text": "routing", "start": 39, "end": 46, "i_start": 8, "i_end": 8}, "action": {"text": "undo", "start": 47, "end": 51, "i_start": 9, "i_end": 9}}], "id": 345}, {"sent": "tzeng et al proposed a unified framework for unsupervised domain adaptation based on adversarial learning objectives .", "tokens": ["tzeng", "et", "al", "proposed", "a", "unified", "framework", "for", "unsupervised", "domain", "adaptation", "based", "on", "adversarial", "learning", "objectives", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "tzeng et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "tzeng", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}], "id": 346}, {"sent": "solid blue squares show the hydra uniform simulation results .", "tokens": ["solid", "blue", "squares", "show", "the", "hydra", "uniform", "simulation", "results", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "solid blue squares", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "show", "start": 19, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "squares", "start": 11, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 19, "end": 23, "i_start": 3, "i_end": 3}}], "id": 347}, {"sent": "deep neural networks , in particular convolutional neural networks , have been used with great success for perceptual tasks such as image classification .", "tokens": ["deep", "neural", "networks", ",", "in", "particular", "convolutional", "neural", "networks", ",", "have", "been", "used", "with", "great", "success", "for", "perceptual", "tasks", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been used", "start": 69, "end": 83, "i_start": 10, "i_end": 12}}], "id": 348}, {"sent": "deep convolutional neural networks have recently shown immense success for various image recognition tasks , such as object recognition .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "recently", "shown", "immense", "success", "for", "various", "image", "recognition", "tasks", ",", "such", "as", "object", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "shown", "start": 49, "end": 54, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 63, "end": 70, "i_start": 8, "i_end": 8}}], "id": 349}, {"sent": "cosmic strings are topologically stable gravitational defects which may have been created in the early universe after planck time by a vacuum phase transition .", "tokens": ["cosmic", "strings", "are", "topologically", "stable", "gravitational", "defects", "which", "may", "have", "been", "created", "in", "the", "early", "universe", "after", "planck", "time", "by", "a", "vacuum", "phase", "transition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "transition", "start": 148, "end": 158, "i_start": 23, "i_end": 23}, "action": {"text": "created", "start": 82, "end": 89, "i_start": 11, "i_end": 11}}], "id": 350}, {"sent": "deep convolutional neural networks achieve impressive performance on many computer vision tasks , including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "achieve", "impressive", "performance", "on", "many", "computer", "vision", "tasks", ",", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "achieve", "start": 35, "end": 42, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieve", "start": 35, "end": 42, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 54, "end": 65, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 54, "end": 65, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 43, "end": 53, "i_start": 5, "i_end": 5}}], "id": 351}, {"sent": "deep neural networks have been shown to be vulnerable to adversarial examples .", "tokens": ["deep", "neural", "networks", "have", "been", "shown", "to", "be", "vulnerable", "to", "adversarial", "examples", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been shown", "start": 21, "end": 36, "i_start": 3, "i_end": 5}}], "id": 352}, {"sent": "one major motivation of this paper is to extend the original problem in , where the hierarchical game was formulated for the energy efficiency maximization problem in the single carrier system .", "tokens": ["one", "major", "motivation", "of", "this", "paper", "is", "to", "extend", "the", "original", "problem", "in", ",", "where", "the", "hierarchical", "game", "was", "formulated", "for", "the", "energy", "efficiency", "maximization", "problem", "in", "the", "single", "carrier", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one major motivation of this paper", "start": 0, "end": 34, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 6, "i_end": 6}}], "id": 353}, {"sent": "it was also shown that nearly all planetary detections in high magnification events will not involve caustic crossings .", "tokens": ["it", "was", "also", "shown", "that", "nearly", "all", "planetary", "detections", "in", "high", "magnification", "events", "will", "not", "involve", "caustic", "crossings", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "nearly all planetary detections in high magnification events", "start": 23, "end": 83, "i_start": 5, "i_end": 12}, "verb": {"text": "shown", "start": 12, "end": 17, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "was", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "involve", "start": 93, "end": 100, "i_start": 15, "i_end": 15}}], "id": 354}, {"sent": "we prove this theorem by a reduction from two n p-hard problems , vertex cover .", "tokens": ["we", "prove", "this", "theorem", "by", "a", "reduction", "from", "two", "n", "p", "-", "hard", "problems", ",", "vertex", "cover", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "prove", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "prove", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 355}, {"sent": "this phenomenon is well studied and known as preferential attachment .", "tokens": ["this", "phenomenon", "is", "well", "studied", "and", "known", "as", "preferential", "attachment", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this phenomenon", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "studied", "start": 24, "end": 31, "i_start": 4, "i_end": 4}}, {"subject": {"text": "this phenomenon", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"subject": {"text": "this phenomenon", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "known", "start": 36, "end": 41, "i_start": 6, "i_end": 6}}], "id": 356}, {"sent": "one approach to studying the complexity of csps is to restrict the instances by allowing a fixed set of constraint relations , which is generally referred to in the literature as a constraint language or , a fixed template .", "tokens": ["one", "approach", "to", "studying", "the", "complexity", "of", "csps", "is", "to", "restrict", "the", "instances", "by", "allowing", "a", "fixed", "set", "of", "constraint", "relations", ",", "which", "is", "generally", "referred", "to", "in", "the", "literature", "as", "a", "constraint", "language", "or", ",", "a", "fixed", "template", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one approach to studying the complexity of csps", "start": 0, "end": 47, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 48, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "literature", "start": 165, "end": 175, "i_start": 29, "i_end": 29}, "action": {"text": "referred", "start": 146, "end": 154, "i_start": 25, "i_end": 25}}], "id": 357}, {"sent": "the shaded regions indicate the range of wavenumbers used in our analysis .", "tokens": ["the", "shaded", "regions", "indicate", "the", "range", "of", "wavenumbers", "used", "in", "our", "analysis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the shaded regions", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "indicate", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "regions", "start": 11, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "indicate", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}], "id": 358}, {"sent": "generative adversarial networks have become the benchmark in image synthesis .", "tokens": ["generative", "adversarial", "networks", "have", "become", "the", "benchmark", "in", "image", "synthesis", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "have become", "start": 32, "end": 43, "i_start": 3, "i_end": 4}}], "id": 359}, {"sent": "angular variation of the d-wave gap around the fermi surface is shown in the left panel .", "tokens": ["angular", "variation", "of", "the", "d", "-", "wave", "gap", "around", "the", "fermi", "surface", "is", "shown", "in", "the", "left", "panel", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "angular variation of the d-wave gap around the fermi surface", "start": 0, "end": 60, "i_start": 0, "i_end": 11}, "verb": {"text": "is shown", "start": 61, "end": 69, "i_start": 12, "i_end": 13}}], "id": 360}, {"sent": "classify those group rings which have s-fixed support subring .", "tokens": ["classify", "those", "group", "rings", "which", "have", "s", "-", "fixed", "support", "subring", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "rings", "start": 21, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "have", "start": 33, "end": 37, "i_start": 5, "i_end": 5}}], "id": 361}, {"sent": "the canonical ensemble is the central one , which has a precursor as micro canonical and a extension to grand canonical ensemble .", "tokens": ["the", "canonical", "ensemble", "is", "the", "central", "one", ",", "which", "has", "a", "precursor", "as", "micro", "canonical", "and", "a", "extension", "to", "grand", "canonical", "ensemble", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the canonical ensemble", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "ensemble", "start": 14, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "has", "start": 50, "end": 53, "i_start": 9, "i_end": 9}}], "id": 362}, {"sent": "understanding the inner working of neural networks is currently one of the pressing questions in learning theory .", "tokens": ["understanding", "the", "inner", "working", "of", "neural", "networks", "is", "currently", "one", "of", "the", "pressing", "questions", "in", "learning", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "understanding the inner working of neural networks", "start": 0, "end": 50, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 51, "end": 53, "i_start": 7, "i_end": 7}}, {"character": {"text": "theory", "start": 106, "end": 112, "i_start": 16, "i_end": 16}, "action": {"text": "pressing", "start": 75, "end": 83, "i_start": 12, "i_end": 12}}], "id": 363}, {"sent": "deep convolutional neural networks have achieved great success on many tasks across a variety of domains , such as vision .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "on", "many", "tasks", "across", "a", "variety", "of", "domains", ",", "such", "as", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}], "id": 364}, {"sent": "analysis of concrete structures under thermal loading .", "tokens": ["analysis", "of", "concrete", "structures", "under", "thermal", "loading", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 365}, {"sent": "therefore the detection potential for relevant plasma physics processes and their characteristic scales such as turbulent energy injection and dissipation will be considerably increased .", "tokens": ["therefore", "the", "detection", "potential", "for", "relevant", "plasma", "physics", "processes", "and", "their", "characteristic", "scales", "such", "as", "turbulent", "energy", "injection", "and", "dissipation", "will", "be", "considerably", "increased", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the detection potential for relevant plasma physics processes and their characteristic scales such as turbulent energy injection and dissipation", "start": 10, "end": 154, "i_start": 1, "i_end": 19}, "verb": {"text": "increased", "start": 176, "end": 185, "i_start": 23, "i_end": 23}}, {"subject": {"text": "the detection potential for relevant plasma physics processes and their characteristic scales such as turbulent energy injection and dissipation", "start": 10, "end": 154, "i_start": 1, "i_end": 19}, "verb": {"text": "will be", "start": 155, "end": 162, "i_start": 20, "i_end": 21}}], "id": 366}, {"sent": "recently convolutional neural networks have performed very well on image classification tasks and are pervasive in machine learning and computer vision .", "tokens": ["recently", "convolutional", "neural", "networks", "have", "performed", "very", "well", "on", "image", "classification", "tasks", "and", "are", "pervasive", "in", "machine", "learning", "and", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 9, "end": 38, "i_start": 1, "i_end": 3}, "verb": {"text": "have performed", "start": 39, "end": 53, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "performed", "start": 44, "end": 53, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "pervasive", "start": 102, "end": 111, "i_start": 14, "i_end": 14}}], "id": 367}, {"sent": "on the continuum side such behavior can be modelled by anisotropic surface terms which are locally minimized for these crack geometries , see eg .", "tokens": ["on", "the", "continuum", "side", "such", "behavior", "can", "be", "modelled", "by", "anisotropic", "surface", "terms", "which", "are", "locally", "minimized", "for", "these", "crack", "geometries", ",", "see", "eg", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such behavior", "start": 22, "end": 35, "i_start": 4, "i_end": 5}, "verb": {"text": "can be modelled", "start": 36, "end": 51, "i_start": 6, "i_end": 8}}], "id": 368}, {"sent": "ahn et al proposed a language model that copies fact attributes from a topic knowledge memory .", "tokens": ["ahn", "et", "al", "proposed", "a", "language", "model", "that", "copies", "fact", "attributes", "from", "a", "topic", "knowledge", "memory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "ahn et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "ahn", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "model", "start": 30, "end": 35, "i_start": 6, "i_end": 6}, "action": {"text": "copies", "start": 41, "end": 47, "i_start": 8, "i_end": 8}}], "id": 369}, {"sent": "the gan was first introduced by goodfellow et al for the image generation .", "tokens": ["the", "gan", "was", "first", "introduced", "by", "goodfellow", "et", "al", "for", "the", "image", "generation", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the gan", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "introduced", "start": 18, "end": 28, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the gan", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "was", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "goodfellow", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "introduced", "start": 18, "end": 28, "i_start": 4, "i_end": 4}}], "id": 370}, {"sent": "recent years have seen the emergence of stochastic gradient descent as an important tool for solving large-scale optimization problems in machine learning .", "tokens": ["recent", "years", "have", "seen", "the", "emergence", "of", "stochastic", "gradient", "descent", "as", "an", "important", "tool", "for", "solving", "large", "-", "scale", "optimization", "problems", "in", "machine", "learning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent years", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "have seen", "start": 13, "end": 22, "i_start": 2, "i_end": 3}}, {"character": {"text": "years", "start": 7, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "seen", "start": 18, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "descent", "start": 60, "end": 67, "i_start": 9, "i_end": 9}, "action": {"text": "emergence", "start": 27, "end": 36, "i_start": 5, "i_end": 5}}], "id": 371}, {"sent": "using the concept of important separators as introduced by marx we prove that the number of separators which are relevant to the problem can be bounded polynomially in x .", "tokens": ["using", "the", "concept", "of", "important", "separators", "as", "introduced", "by", "marx", "we", "prove", "that", "the", "number", "of", "separators", "which", "are", "relevant", "to", "the", "problem", "can", "be", "bounded", "polynomially", "in", "x", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 64, "end": 66, "i_start": 10, "i_end": 10}, "verb": {"text": "prove", "start": 67, "end": 72, "i_start": 11, "i_end": 11}}, {"subject": {"text": "the number of separators which are relevant to the problem", "start": 78, "end": 136, "i_start": 13, "i_end": 22}, "verb": {"text": "bounded", "start": 144, "end": 151, "i_start": 25, "i_end": 25}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 10, "i_end": 10}, "action": {"text": "prove", "start": 67, "end": 72, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 10, "i_end": 10}, "action": {"text": "using", "start": 0, "end": 5, "i_start": 0, "i_end": 0}}, {"character": {"text": "marx", "start": 59, "end": 63, "i_start": 9, "i_end": 9}, "action": {"text": "introduced", "start": 45, "end": 55, "i_start": 7, "i_end": 7}}], "id": 372}, {"sent": "for a fixed number of components k , the model is usually estimated using the em algorithm .", "tokens": ["for", "a", "fixed", "number", "of", "components", "k", ",", "the", "model", "is", "usually", "estimated", "using", "the", "em", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 37, "end": 46, "i_start": 8, "i_end": 9}, "verb": {"text": "estimated", "start": 58, "end": 67, "i_start": 12, "i_end": 12}}, {"subject": {"text": "the model", "start": 37, "end": 46, "i_start": 8, "i_end": 9}, "verb": {"text": "is", "start": 47, "end": 49, "i_start": 10, "i_end": 10}}], "id": 373}, {"sent": "since the forms above are non-negative on all cohomology tables \u03b3 .", "tokens": ["since", "the", "forms", "above", "are", "non", "-", "negative", "on", "all", "cohomology", "tables", "\u03b3", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the forms above", "start": 6, "end": 21, "i_start": 1, "i_end": 3}, "verb": {"text": "are", "start": 22, "end": 25, "i_start": 4, "i_end": 4}}], "id": 374}, {"sent": "this is a special case of the latent space model .", "tokens": ["this", "is", "a", "special", "case", "of", "the", "latent", "space", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 375}, {"sent": "such a residue is a motivic number then in some modern mathematic parlance .", "tokens": ["such", "a", "residue", "is", "a", "motivic", "number", "then", "in", "some", "modern", "mathematic", "parlance", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such a residue", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "number", "start": 28, "end": 34, "i_start": 6, "i_end": 6}, "action": {"text": "motivic", "start": 20, "end": 27, "i_start": 5, "i_end": 5}}], "id": 376}, {"sent": "the authors in study a cognitive radio network with energy harvesting secondary users , wherein both the primary and secondary networks are distributed as independent homogeneous ppps .", "tokens": ["the", "authors", "in", "study", "a", "cognitive", "radio", "network", "with", "energy", "harvesting", "secondary", "users", ",", "wherein", "both", "the", "primary", "and", "secondary", "networks", "are", "distributed", "as", "independent", "homogeneous", "ppps", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 377}, {"sent": "deep neural networks have achieved great success in recent years on many applications .", "tokens": ["deep", "neural", "networks", "have", "achieved", "great", "success", "in", "recent", "years", "on", "many", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 41, "end": 48, "i_start": 6, "i_end": 6}}], "id": 378}, {"sent": "large deep neural networks trained on massive data sets have led to major advances in machine learning performance .", "tokens": ["large", "deep", "neural", "networks", "trained", "on", "massive", "data", "sets", "have", "led", "to", "major", "advances", "in", "machine", "learning", "performance", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "large deep neural networks trained on massive data sets", "start": 0, "end": 55, "i_start": 0, "i_end": 8}, "verb": {"text": "have led", "start": 56, "end": 64, "i_start": 9, "i_end": 10}}, {"character": {"text": "networks", "start": 18, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "led", "start": 61, "end": 64, "i_start": 10, "i_end": 10}}], "id": 379}, {"sent": "recent advances in the design of convolutional neural networks has led to state of the art performances in several tasks , including image classification .", "tokens": ["recent", "advances", "in", "the", "design", "of", "convolutional", "neural", "networks", "has", "led", "to", "state", "of", "the", "art", "performances", "in", "several", "tasks", ",", "including", "image", "classification", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "recent advances in the design of convolutional neural networks", "start": 0, "end": 62, "i_start": 0, "i_end": 8}, "verb": {"text": "has led", "start": 63, "end": 70, "i_start": 9, "i_end": 10}}, {"character": {"text": "advances", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 67, "end": 70, "i_start": 10, "i_end": 10}}], "id": 380}, {"sent": "if neutrino is a majorana particle then by definition it is identical to its charge conjugate .", "tokens": ["if", "neutrino", "is", "a", "majorana", "particle", "then", "by", "definition", "it", "is", "identical", "to", "its", "charge", "conjugate", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 54, "end": 56, "i_start": 9, "i_end": 9}, "verb": {"text": "is", "start": 57, "end": 59, "i_start": 10, "i_end": 10}}], "id": 381}, {"sent": "convolutional neural networks have achieved state-of-the-art performance on the object detection task .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "the", "object", "detection", "task", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 61, "end": 72, "i_start": 12, "i_end": 12}}], "id": 382}, {"sent": "accordingly e\u03bb v is called an elementary automorphism .", "tokens": ["accordingly", "e\u03bb", "v", "is", "called", "an", "elementary", "automorphism", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "accordingly e\u03bb v", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 17, "end": 26, "i_start": 3, "i_end": 4}}], "id": 383}, {"sent": "actually , this theorem has three forms , which are used by bayes , and this paper respectively .", "tokens": ["actually", ",", "this", "theorem", "has", "three", "forms", ",", "which", "are", "used", "by", "bayes", ",", "and", "this", "paper", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this theorem", "start": 11, "end": 23, "i_start": 2, "i_end": 3}, "verb": {"text": "has", "start": 24, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "theorem", "start": 16, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "has", "start": 24, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "bayes", "start": 60, "end": 65, "i_start": 12, "i_end": 12}, "action": {"text": "used", "start": 52, "end": 56, "i_start": 10, "i_end": 10}}, {"character": {"text": "paper", "start": 77, "end": 82, "i_start": 16, "i_end": 16}, "action": {"text": "used", "start": 52, "end": 56, "i_start": 10, "i_end": 10}}, {"character": {"text": "this", "start": 72, "end": 76, "i_start": 15, "i_end": 15}, "action": {"text": "used", "start": 52, "end": 56, "i_start": 10, "i_end": 10}}], "id": 384}, {"sent": "biological interference should not be confused with the intersymbol interference or co-channel interference which have been already investigated in , from the aspect of molecular communications .", "tokens": ["biological", "interference", "should", "not", "be", "confused", "with", "the", "intersymbol", "interference", "or", "co", "-", "channel", "interference", "which", "have", "been", "already", "investigated", "in", ",", "from", "the", "aspect", "of", "molecular", "communications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "biological interference", "start": 0, "end": 23, "i_start": 0, "i_end": 1}, "verb": {"text": "should not be confused", "start": 24, "end": 46, "i_start": 2, "i_end": 5}}], "id": 385}, {"sent": "most of these conditions are satisfied by the local density approximation .", "tokens": ["most", "of", "these", "conditions", "are", "satisfied", "by", "the", "local", "density", "approximation", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "most of these conditions", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "are satisfied", "start": 25, "end": 38, "i_start": 4, "i_end": 5}}, {"character": {"text": "approximation", "start": 60, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "satisfied", "start": 29, "end": 38, "i_start": 5, "i_end": 5}}], "id": 386}, {"sent": "sauerbrei and schumacher developped a bootstrap selection procedure which combined the bootstrap method with stepwise selection in cox regression .", "tokens": ["sauerbrei", "and", "schumacher", "developped", "a", "bootstrap", "selection", "procedure", "which", "combined", "the", "bootstrap", "method", "with", "stepwise", "selection", "in", "cox", "regression", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "sauerbrei", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "developped", "start": 25, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "schumacher", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "developped", "start": 25, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "procedure", "start": 58, "end": 67, "i_start": 7, "i_end": 7}, "action": {"text": "combined", "start": 74, "end": 82, "i_start": 9, "i_end": 9}}], "id": 387}, {"sent": "shows the comparison result of the asrs between the proposed mmwave-noma algorithm , the mmwave-noma approach in and mmwave-oma with varying minimum rate constraint .", "tokens": ["shows", "the", "comparison", "result", "of", "the", "asrs", "between", "the", "proposed", "mmwave", "-", "noma", "algorithm", ",", "the", "mmwave", "-", "noma", "approach", "in", "and", "mmwave", "-", "oma", "with", "varying", "minimum", "rate", "constraint", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 388}, {"sent": "the ordinate is the ratio of the core-sw component separation divided by the core-ne component separation .", "tokens": ["the", "ordinate", "is", "the", "ratio", "of", "the", "core", "-", "sw", "component", "separation", "divided", "by", "the", "core", "-", "ne", "component", "separation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ordinate", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 389}, {"sent": "in recent years , convolutional neural networks have become the dominant approach for various tasks including classification .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "become", "the", "dominant", "approach", "for", "various", "tasks", "including", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have become", "start": 48, "end": 59, "i_start": 7, "i_end": 8}}, {"character": {"text": "approach", "start": 73, "end": 81, "i_start": 11, "i_end": 11}, "action": {"text": "dominant", "start": 64, "end": 72, "i_start": 10, "i_end": 10}}], "id": 390}, {"sent": "the free energy then is a generating function for the counting numbers of connected graphs that can be embedded in a compact surface with a given genus .", "tokens": ["the", "free", "energy", "then", "is", "a", "generating", "function", "for", "the", "counting", "numbers", "of", "connected", "graphs", "that", "can", "be", "embedded", "in", "a", "compact", "surface", "with", "a", "given", "genus", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the free energy", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "numbers", "start": 63, "end": 70, "i_start": 11, "i_end": 11}, "action": {"text": "function", "start": 37, "end": 45, "i_start": 7, "i_end": 7}}], "id": 391}, {"sent": "farabet et al propose a method of learning hierarchical features based on multi-scale convolutional networks .", "tokens": ["farabet", "et", "al", "propose", "a", "method", "of", "learning", "hierarchical", "features", "based", "on", "multi", "-", "scale", "convolutional", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "farabet et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "farabet", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}], "id": 392}, {"sent": "the generalized gradient approximation was used with the perdewburke-ernzerhof functional to describe the exchange-correlation interaction .", "tokens": ["the", "generalized", "gradient", "approximation", "was", "used", "with", "the", "perdewburke", "-", "ernzerhof", "functional", "to", "describe", "the", "exchange", "-", "correlation", "interaction", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation", "start": 0, "end": 38, "i_start": 0, "i_end": 3}, "verb": {"text": "was used", "start": 39, "end": 47, "i_start": 4, "i_end": 5}}, {"character": {"text": "approximation", "start": 25, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "describe", "start": 93, "end": 101, "i_start": 13, "i_end": 13}}], "id": 393}, {"sent": "the batch normalization layers are inserted before every relu layer to accelerate the convergence .", "tokens": ["the", "batch", "normalization", "layers", "are", "inserted", "before", "every", "relu", "layer", "to", "accelerate", "the", "convergence", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the batch normalization layers", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "are inserted", "start": 31, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "layers", "start": 24, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "normalization", "start": 10, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "layers", "start": 24, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "accelerate", "start": 71, "end": 81, "i_start": 11, "i_end": 11}}], "id": 394}, {"sent": "following the tradition of the traffic signal control study , we conduct experiments in a simulation platform sumo 3 .", "tokens": ["following", "the", "tradition", "of", "the", "traffic", "signal", "control", "study", ",", "we", "conduct", "experiments", "in", "a", "simulation", "platform", "sumo", "3", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 62, "end": 64, "i_start": 10, "i_end": 10}, "verb": {"text": "conduct", "start": 65, "end": 72, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 62, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "experiments", "start": 73, "end": 84, "i_start": 12, "i_end": 12}}], "id": 395}, {"sent": "the asymmetry is a requirement since the net polarization is non-zero .", "tokens": ["the", "asymmetry", "is", "a", "requirement", "since", "the", "net", "polarization", "is", "non", "-", "zero", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the asymmetry", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 396}, {"sent": "collective behaviors of multi-agent systems are ubiquitous in the nature , like flocking of birds , synchronization of oscillators , herding of sheeps and alignment of robots , etc .", "tokens": ["collective", "behaviors", "of", "multi", "-", "agent", "systems", "are", "ubiquitous", "in", "the", "nature", ",", "like", "flocking", "of", "birds", ",", "synchronization", "of", "oscillators", ",", "herding", "of", "sheeps", "and", "alignment", "of", "robots", ",", "etc", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "collective behaviors of multi-agent systems", "start": 0, "end": 43, "i_start": 0, "i_end": 6}, "verb": {"text": "are", "start": 44, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "systems", "start": 36, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "behaviors", "start": 11, "end": 20, "i_start": 1, "i_end": 1}}], "id": 397}, {"sent": "deep networks have been applied to almost all computer vision tasks and have achieved state-of-the-art performances , such as image classification .", "tokens": ["deep", "networks", "have", "been", "applied", "to", "almost", "all", "computer", "vision", "tasks", "and", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performances", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep networks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "have been applied", "start": 14, "end": 31, "i_start": 2, "i_end": 4}}, {"subject": {"text": "deep networks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "achieved", "start": 77, "end": 85, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "achieved", "start": 77, "end": 85, "i_start": 13, "i_end": 13}}], "id": 398}, {"sent": "we use the standard flickr30k entities dataset for evaluating our proposed approach .", "tokens": ["we", "use", "the", "standard", "flickr30k", "entities", "dataset", "for", "evaluating", "our", "proposed", "approach", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluating", "start": 51, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "approach", "start": 75, "end": 83, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 66, "end": 74, "i_start": 10, "i_end": 10}}], "id": 399}, {"sent": "a feynman graph without external edges is called a vacuum bubble .", "tokens": ["a", "feynman", "graph", "without", "external", "edges", "is", "called", "a", "vacuum", "bubble", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a feynman graph without external edges", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "is called", "start": 39, "end": 48, "i_start": 6, "i_end": 7}}], "id": 400}, {"sent": "other approaches allow one to get direct solutions in a closed form .", "tokens": ["other", "approaches", "allow", "one", "to", "get", "direct", "solutions", "in", "a", "closed", "form", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "other approaches", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "allow", "start": 17, "end": 22, "i_start": 2, "i_end": 2}}, {"subject": {"text": "one", "start": 23, "end": 26, "i_start": 3, "i_end": 3}, "verb": {"text": "get", "start": 30, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "approaches", "start": 6, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "allow", "start": 17, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "one", "start": 23, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "get", "start": 30, "end": 33, "i_start": 5, "i_end": 5}}], "id": 401}, {"sent": "we use adam optimizer for optimizing the loss function on model parameters \u03b8 .", "tokens": ["we", "use", "adam", "optimizer", "for", "optimizing", "the", "loss", "function", "on", "model", "parameters", "\u03b8", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimizing", "start": 26, "end": 36, "i_start": 5, "i_end": 5}}], "id": 402}, {"sent": "now let us introduce minimal electromagnetic interaction .", "tokens": ["now", "let", "us", "introduce", "minimal", "electromagnetic", "interaction", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "let", "start": 4, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "us", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "introduce", "start": 11, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "let", "start": 4, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "us", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "introduce", "start": 11, "end": 20, "i_start": 3, "i_end": 3}}], "id": 403}, {"sent": "we considered the lbp with a circular neighbourhood of radius 2 and 16 elements , and 18 uniform and rotation invariant patterns cusano , napoletano , and schettini .", "tokens": ["we", "considered", "the", "lbp", "with", "a", "circular", "neighbourhood", "of", "radius", "2", "and", "16", "elements", ",", "and", "18", "uniform", "and", "rotation", "invariant", "patterns", "cusano", ",", "napoletano", ",", "and", "schettini", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "considered", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "considered", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}], "id": 404}, {"sent": "quantum computers have the potential to solve a number of important problems , including integer factorization asymptotically faster than the best known classical algorithms .", "tokens": ["quantum", "computers", "have", "the", "potential", "to", "solve", "a", "number", "of", "important", "problems", ",", "including", "integer", "factorization", "asymptotically", "faster", "than", "the", "best", "known", "classical", "algorithms", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum computers", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "have", "start": 18, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "computers", "start": 8, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "solve", "start": 40, "end": 45, "i_start": 6, "i_end": 6}}], "id": 405}, {"sent": "bergsma proposed a game ai architecture which use influence maps for a turn based strategy game .", "tokens": ["bergsma", "proposed", "a", "game", "ai", "architecture", "which", "use", "influence", "maps", "for", "a", "turn", "based", "strategy", "game", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bergsma", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "proposed", "start": 8, "end": 16, "i_start": 1, "i_end": 1}}, {"subject": {"text": "a game", "start": 17, "end": 23, "i_start": 2, "i_end": 3}, "verb": {"text": "ai", "start": 24, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "bergsma", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 8, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "architecture", "start": 27, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 46, "end": 49, "i_start": 7, "i_end": 7}}], "id": 406}, {"sent": "in fang , the euler equations were first studied with a uniform bernoulli constant for both strong and weak transonic shocks .", "tokens": ["in", "fang", ",", "the", "euler", "equations", "were", "first", "studied", "with", "a", "uniform", "bernoulli", "constant", "for", "both", "strong", "and", "weak", "transonic", "shocks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the euler equations", "start": 10, "end": 29, "i_start": 3, "i_end": 5}, "verb": {"text": "studied", "start": 41, "end": 48, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the euler equations", "start": 10, "end": 29, "i_start": 3, "i_end": 5}, "verb": {"text": "were", "start": 30, "end": 34, "i_start": 6, "i_end": 6}}], "id": 407}, {"sent": "while the control objectives will be reached for any nonzero gains c ij , an important control design question is how to choose these gains to optimize network performance .", "tokens": ["while", "the", "control", "objectives", "will", "be", "reached", "for", "any", "nonzero", "gains", "c", "ij", ",", "an", "important", "control", "design", "question", "is", "how", "to", "choose", "these", "gains", "to", "optimize", "network", "performance", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "an important control design question", "start": 74, "end": 110, "i_start": 14, "i_end": 18}, "verb": {"text": "is", "start": 111, "end": 113, "i_start": 19, "i_end": 19}}], "id": 408}, {"sent": "physical layer security has become a popular way to improve the secrecy performance of wireless communication systems by utilizing wireless channel characteristics .", "tokens": ["physical", "layer", "security", "has", "become", "a", "popular", "way", "to", "improve", "the", "secrecy", "performance", "of", "wireless", "communication", "systems", "by", "utilizing", "wireless", "channel", "characteristics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "physical layer security", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "has become", "start": 24, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "systems", "start": 110, "end": 117, "i_start": 16, "i_end": 16}, "action": {"text": "performance", "start": 72, "end": 83, "i_start": 12, "i_end": 12}}], "id": 409}, {"sent": "axions are hypothetical pseudoscalar particles that have been suggested as a solution of the cp-violation problem in the strong interactions .", "tokens": ["axions", "are", "hypothetical", "pseudoscalar", "particles", "that", "have", "been", "suggested", "as", "a", "solution", "of", "the", "cp", "-", "violation", "problem", "in", "the", "strong", "interactions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "axions", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 7, "end": 10, "i_start": 1, "i_end": 1}}], "id": 410}, {"sent": "in the intermediate density , the p-wave pairing state is dominant .", "tokens": ["in", "the", "intermediate", "density", ",", "the", "p", "-", "wave", "pairing", "state", "is", "dominant", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the p-wave pairing state", "start": 30, "end": 54, "i_start": 5, "i_end": 10}, "verb": {"text": "is", "start": 55, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "state", "start": 49, "end": 54, "i_start": 10, "i_end": 10}, "action": {"text": "dominant", "start": 58, "end": 66, "i_start": 12, "i_end": 12}}], "id": 411}, {"sent": "phase transitions on fractal lattices with long-range interactions .", "tokens": ["phase", "transitions", "on", "fractal", "lattices", "with", "long", "-", "range", "interactions", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 412}, {"sent": "generative adversarial networks using gan framework for generative image modeling and synthesis has gained remarkable progress recently .", "tokens": ["generative", "adversarial", "networks", "using", "gan", "framework", "for", "generative", "image", "modeling", "and", "synthesis", "has", "gained", "remarkable", "progress", "recently", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks using gan framework for generative image modeling and synthesis", "start": 0, "end": 95, "i_start": 0, "i_end": 11}, "verb": {"text": "has gained", "start": 96, "end": 106, "i_start": 12, "i_end": 13}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "gained", "start": 100, "end": 106, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "using", "start": 32, "end": 37, "i_start": 3, "i_end": 3}}], "id": 413}, {"sent": "deep neural networks have achieved great success across a broad range of domains , such as computer vision , speech processing and natural language processing .", "tokens": ["deep", "neural", "networks", "have", "achieved", "great", "success", "across", "a", "broad", "range", "of", "domains", ",", "such", "as", "computer", "vision", ",", "speech", "processing", "and", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 41, "end": 48, "i_start": 6, "i_end": 6}}], "id": 414}, {"sent": "from a more computational perspective , studying the convergence of empirical averages is an important problem for the efficiency of monte carlo markov chain methods , large deviations theory has been given many extensions .", "tokens": ["from", "a", "more", "computational", "perspective", ",", "studying", "the", "convergence", "of", "empirical", "averages", "is", "an", "important", "problem", "for", "the", "efficiency", "of", "monte", "carlo", "markov", "chain", "methods", ",", "large", "deviations", "theory", "has", "been", "given", "many", "extensions", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "large deviations theory", "start": 168, "end": 191, "i_start": 26, "i_end": 28}, "verb": {"text": "has been given", "start": 192, "end": 206, "i_start": 29, "i_end": 31}}, {"subject": {"text": "large deviations theory", "start": 168, "end": 191, "i_start": 26, "i_end": 28}, "verb": {"text": "is", "start": 87, "end": 89, "i_start": 12, "i_end": 12}}], "id": 415}, {"sent": "the generalizedgradient approximation of perdew-burke-ernzerhof is employed as the exchange-correlation functional .", "tokens": ["the", "generalizedgradient", "approximation", "of", "perdew", "-", "burke", "-", "ernzerhof", "is", "employed", "as", "the", "exchange", "-", "correlation", "functional", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalizedgradient approximation of perdew-burke-ernzerhof", "start": 0, "end": 63, "i_start": 0, "i_end": 8}, "verb": {"text": "is employed", "start": 64, "end": 75, "i_start": 9, "i_end": 10}}], "id": 416}, {"sent": "in this work we build on the model that was introduced by karloff , suri , and vassilvitski .", "tokens": ["in", "this", "work", "we", "build", "on", "the", "model", "that", "was", "introduced", "by", "karloff", ",", "suri", ",", "and", "vassilvitski", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "build", "start": 16, "end": 21, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "build", "start": 16, "end": 21, "i_start": 4, "i_end": 4}}, {"character": {"text": "karloff", "start": 58, "end": 65, "i_start": 12, "i_end": 12}, "action": {"text": "introduced", "start": 44, "end": 54, "i_start": 10, "i_end": 10}}, {"character": {"text": "suri", "start": 68, "end": 72, "i_start": 14, "i_end": 14}, "action": {"text": "introduced", "start": 44, "end": 54, "i_start": 10, "i_end": 10}}, {"character": {"text": "vassilvitski", "start": 79, "end": 91, "i_start": 17, "i_end": 17}, "action": {"text": "introduced", "start": 44, "end": 54, "i_start": 10, "i_end": 10}}], "id": 417}, {"sent": "cambridge university press , cambridge , england .", "tokens": ["cambridge", "university", "press", ",", "cambridge", ",", "england", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 418}, {"sent": "the first results were obtained by huneke and sharp who proved that if r is a regular ring containing a field of prime characteristic , then the set of associated prime ideals of h n a is finite , .", "tokens": ["the", "first", "results", "were", "obtained", "by", "huneke", "and", "sharp", "who", "proved", "that", "if", "r", "is", "a", "regular", "ring", "containing", "a", "field", "of", "prime", "characteristic", ",", "then", "the", "set", "of", "associated", "prime", "ideals", "of", "h", "n", "a", "is", "finite", ",", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the first results", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "were obtained", "start": 18, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "huneke", "start": 35, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "obtained", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "sharp", "start": 46, "end": 51, "i_start": 8, "i_end": 8}, "action": {"text": "obtained", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "set", "start": 145, "end": 148, "i_start": 27, "i_end": 27}, "action": {"text": "obtained", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "ideals", "start": 169, "end": 175, "i_start": 31, "i_end": 31}, "action": {"text": "obtained", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "prime", "start": 113, "end": 118, "i_start": 22, "i_end": 22}, "action": {"text": "obtained", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "prime", "start": 113, "end": 118, "i_start": 22, "i_end": 22}, "action": {"text": "obtained", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "ring", "start": 86, "end": 90, "i_start": 17, "i_end": 17}, "action": {"text": "obtained", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "characteristic", "start": 119, "end": 133, "i_start": 23, "i_end": 23}, "action": {"text": "obtained", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "prime", "start": 113, "end": 118, "i_start": 22, "i_end": 22}, "action": {"text": "obtained", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "r", "start": 71, "end": 72, "i_start": 13, "i_end": 13}, "action": {"text": "obtained", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "and", "start": 42, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "proved", "start": 56, "end": 62, "i_start": 10, "i_end": 10}}, {"character": {"text": "ring", "start": 86, "end": 90, "i_start": 17, "i_end": 17}, "action": {"text": "containing", "start": 91, "end": 101, "i_start": 18, "i_end": 18}}], "id": 419}, {"sent": "we used hungarian method for matching our score matrix .", "tokens": ["we", "used", "hungarian", "method", "for", "matching", "our", "score", "matrix", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "matching", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}], "id": 420}, {"sent": "recently , the methods which combine deep neural networks and reinforcement learning have achieved remarkable performance on many tasks such as atari games .", "tokens": ["recently", ",", "the", "methods", "which", "combine", "deep", "neural", "networks", "and", "reinforcement", "learning", "have", "achieved", "remarkable", "performance", "on", "many", "tasks", "such", "as", "atari", "games", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the methods which combine deep neural networks and reinforcement learning", "start": 11, "end": 84, "i_start": 2, "i_end": 11}, "verb": {"text": "have achieved", "start": 85, "end": 98, "i_start": 12, "i_end": 13}}, {"character": {"text": "methods", "start": 15, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 90, "end": 98, "i_start": 13, "i_end": 13}}, {"character": {"text": "methods", "start": 15, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "combine", "start": 29, "end": 36, "i_start": 5, "i_end": 5}}], "id": 421}, {"sent": "deep neural networks have shown considerable capabilities for handling specific complex tasks such as speech recognition .", "tokens": ["deep", "neural", "networks", "have", "shown", "considerable", "capabilities", "for", "handling", "specific", "complex", "tasks", "such", "as", "speech", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "handling", "start": 62, "end": 70, "i_start": 8, "i_end": 8}}], "id": 422}, {"sent": "recently , deep neural networks have substantially improved the state-of-the-art performances of various challenging classification tasks , including image based object recognition .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "substantially", "improved", "the", "state", "-", "of", "-", "the", "-", "art", "performances", "of", "various", "challenging", "classification", "tasks", ",", "including", "image", "based", "object", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "improved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have", "start": 32, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "improved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "performances", "start": 81, "end": 93, "i_start": 16, "i_end": 16}}, {"character": {"text": "tasks", "start": 132, "end": 137, "i_start": 21, "i_end": 21}, "action": {"text": "classification", "start": 117, "end": 131, "i_start": 20, "i_end": 20}}], "id": 423}, {"sent": "thus , we see that in these regimes , it is a good approximation to neglect the effects of radiative cooling for our canonical model parameters .", "tokens": ["thus", ",", "we", "see", "that", "in", "these", "regimes", ",", "it", "is", "a", "good", "approximation", "to", "neglect", "the", "effects", "of", "radiative", "cooling", "for", "our", "canonical", "model", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "see", "start": 10, "end": 13, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 41, "end": 43, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "see", "start": 10, "end": 13, "i_start": 3, "i_end": 3}}], "id": 424}, {"sent": "among these methods , one inspiring us is , which adopts an em learning algorithm for training the model with image-level semantic labels .", "tokens": ["among", "these", "methods", ",", "one", "inspiring", "us", "is", ",", "which", "adopts", "an", "em", "learning", "algorithm", "for", "training", "the", "model", "with", "image", "-", "level", "semantic", "labels", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "one inspiring us", "start": 22, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 7, "i_end": 7}}, {"subject": {"text": "which", "start": 44, "end": 49, "i_start": 9, "i_end": 9}, "verb": {"text": "adopts", "start": 50, "end": 56, "i_start": 10, "i_end": 10}}, {"character": {"text": "methods", "start": 12, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "adopts", "start": 50, "end": 56, "i_start": 10, "i_end": 10}}], "id": 425}, {"sent": "in contrast , a constant approximation is given in , but only when there are a constant number of different time windows .", "tokens": ["in", "contrast", ",", "a", "constant", "approximation", "is", "given", "in", ",", "but", "only", "when", "there", "are", "a", "constant", "number", "of", "different", "time", "windows", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a constant approximation", "start": 14, "end": 38, "i_start": 3, "i_end": 5}, "verb": {"text": "is given in", "start": 39, "end": 50, "i_start": 6, "i_end": 8}}, {"subject": {"text": "there", "start": 67, "end": 72, "i_start": 13, "i_end": 13}, "verb": {"text": "are", "start": 73, "end": 76, "i_start": 14, "i_end": 14}}], "id": 426}, {"sent": "the inflaton is a scalar field introduced to address the homogeneity and flatness problems through accelerated expansion in the early universe .", "tokens": ["the", "inflaton", "is", "a", "scalar", "field", "introduced", "to", "address", "the", "homogeneity", "and", "flatness", "problems", "through", "accelerated", "expansion", "in", "the", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the inflaton", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "field", "start": 25, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "address", "start": 45, "end": 52, "i_start": 8, "i_end": 8}}], "id": 427}, {"sent": "the recent advance in deep learning expands its applications on graph data .", "tokens": ["the", "recent", "advance", "in", "deep", "learning", "expands", "its", "applications", "on", "graph", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the recent advance in deep learning", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "expands", "start": 36, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "advance", "start": 11, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "expands", "start": 36, "end": 43, "i_start": 6, "i_end": 6}}], "id": 428}, {"sent": "deep convolutional neural networks have gained tremendous attention recently due to their great success in boosting the performance of image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "gained", "tremendous", "attention", "recently", "due", "to", "their", "great", "success", "in", "boosting", "the", "performance", "of", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have gained", "start": 35, "end": 46, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "gained", "start": 40, "end": 46, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 96, "end": 103, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "boosting", "start": 107, "end": 115, "i_start": 15, "i_end": 15}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 120, "end": 131, "i_start": 17, "i_end": 17}}], "id": 429}, {"sent": "a detailed description of the cms detector can be found elsewhere .", "tokens": ["a", "detailed", "description", "of", "the", "cms", "detector", "can", "be", "found", "elsewhere", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a detailed description of the cms detector", "start": 0, "end": 42, "i_start": 0, "i_end": 6}, "verb": {"text": "can be found", "start": 43, "end": 55, "i_start": 7, "i_end": 9}}], "id": 430}, {"sent": "in weng et al the instantaneous energy was used to solve the label ambiguity problem and a two-speaker joint-decoder with a speaker switching penalty was used to separate and trace speakers .", "tokens": ["in", "weng", "et", "al", "the", "instantaneous", "energy", "was", "used", "to", "solve", "the", "label", "ambiguity", "problem", "and", "a", "two", "-", "speaker", "joint", "-", "decoder", "with", "a", "speaker", "switching", "penalty", "was", "used", "to", "separate", "and", "trace", "speakers", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the instantaneous energy", "start": 14, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "was used", "start": 39, "end": 47, "i_start": 7, "i_end": 8}}, {"subject": {"text": "a two-speaker joint-decoder with a speaker switching penalty", "start": 89, "end": 149, "i_start": 16, "i_end": 27}, "verb": {"text": "used", "start": 154, "end": 158, "i_start": 29, "i_end": 29}}, {"character": {"text": "energy", "start": 32, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "solve", "start": 51, "end": 56, "i_start": 10, "i_end": 10}}], "id": 431}, {"sent": "the maximum mass for these models is strongly reduced compared to models without hyperons .", "tokens": ["the", "maximum", "mass", "for", "these", "models", "is", "strongly", "reduced", "compared", "to", "models", "without", "hyperons", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the maximum mass for these models", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "reduced", "start": 46, "end": 53, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the maximum mass for these models", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 6, "i_end": 6}}], "id": 432}, {"sent": "the uncertainty on the signal cross section due to pdf uncertainties has been determined using the pdf4lhc prescription .", "tokens": ["the", "uncertainty", "on", "the", "signal", "cross", "section", "due", "to", "pdf", "uncertainties", "has", "been", "determined", "using", "the", "pdf4lhc", "prescription", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the uncertainty on the signal cross section due to pdf uncertainties", "start": 0, "end": 68, "i_start": 0, "i_end": 10}, "verb": {"text": "has been determined", "start": 69, "end": 88, "i_start": 11, "i_end": 13}}, {"character": {"text": "section", "start": 36, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "cross", "start": 30, "end": 35, "i_start": 5, "i_end": 5}}], "id": 433}, {"sent": "improving range query estimation on histograms .", "tokens": ["improving", "range", "query", "estimation", "on", "histograms", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 434}, {"sent": "many recent works have shown the susceptibility of convolutional neural networks to adversarial samples .", "tokens": ["many", "recent", "works", "have", "shown", "the", "susceptibility", "of", "convolutional", "neural", "networks", "to", "adversarial", "samples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "many recent works", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 18, "end": 28, "i_start": 3, "i_end": 4}}, {"character": {"text": "works", "start": 12, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 23, "end": 28, "i_start": 4, "i_end": 4}}], "id": 435}, {"sent": "we employ a bidirectional gated recurrent unit to encode the input source sequence .", "tokens": ["we", "employ", "a", "bidirectional", "gated", "recurrent", "unit", "to", "encode", "the", "input", "source", "sequence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "unit", "start": 42, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "encode", "start": 50, "end": 56, "i_start": 8, "i_end": 8}}], "id": 436}, {"sent": "the calibrated visibility data were fourier-transformed and cleaned with miriad to produce images .", "tokens": ["the", "calibrated", "visibility", "data", "were", "fourier", "-", "transformed", "and", "cleaned", "with", "miriad", "to", "produce", "images", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the calibrated visibility data", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "were", "start": 31, "end": 35, "i_start": 4, "i_end": 4}}], "id": 437}, {"sent": "glauber , in high energy physics and nuclear structure , edited by s .", "tokens": ["glauber", ",", "in", "high", "energy", "physics", "and", "nuclear", "structure", ",", "edited", "by", "s", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "glauber", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "edited", "start": 57, "end": 63, "i_start": 10, "i_end": 10}}], "id": 438}, {"sent": "for this study we ignore training hyper-parameters and use the adam optimizer .", "tokens": ["for", "this", "study", "we", "ignore", "training", "hyper", "-", "parameters", "and", "use", "the", "adam", "optimizer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "ignore", "start": 18, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "ignore", "start": 18, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 55, "end": 58, "i_start": 10, "i_end": 10}}], "id": 439}, {"sent": "we use frames 601 through 1400 as training set and the rest of the frames as testing set following .", "tokens": ["we", "use", "frames", "601", "through", "1400", "as", "training", "set", "and", "the", "rest", "of", "the", "frames", "as", "testing", "set", "following", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 440}, {"sent": "exchange and correlation were treated in the generalized gradient approximation as parameterized in the perdew-burke-ernzerhof functional .", "tokens": ["exchange", "and", "correlation", "were", "treated", "in", "the", "generalized", "gradient", "approximation", "as", "parameterized", "in", "the", "perdew", "-", "burke", "-", "ernzerhof", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "exchange and correlation", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "were treated", "start": 25, "end": 37, "i_start": 3, "i_end": 4}}, {"character": {"text": "functional", "start": 127, "end": 137, "i_start": 19, "i_end": 19}, "action": {"text": "parameterized", "start": 83, "end": 96, "i_start": 11, "i_end": 11}}], "id": 441}, {"sent": "this random variable can be approximated by a wiener-hermite polynomial chaos expansion .", "tokens": ["this", "random", "variable", "can", "be", "approximated", "by", "a", "wiener", "-", "hermite", "polynomial", "chaos", "expansion", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this random variable", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "can be approximated", "start": 21, "end": 40, "i_start": 3, "i_end": 5}}], "id": 442}, {"sent": "the r 3 svd algorithm described in this paper is based on gaussian sampling .", "tokens": ["the", "r", "3", "svd", "algorithm", "described", "in", "this", "paper", "is", "based", "on", "gaussian", "sampling", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the r 3 svd algorithm described in this paper", "start": 0, "end": 45, "i_start": 0, "i_end": 8}, "verb": {"text": "is based", "start": 46, "end": 54, "i_start": 9, "i_end": 10}}], "id": 443}, {"sent": "for a class of states called homogeneously adequate states , work of futer shows that the associated state surface is a fiber if and only if a related graph , called the reduced state graph , is a tree .", "tokens": ["for", "a", "class", "of", "states", "called", "homogeneously", "adequate", "states", ",", "work", "of", "futer", "shows", "that", "the", "associated", "state", "surface", "is", "a", "fiber", "if", "and", "only", "if", "a", "related", "graph", ",", "called", "the", "reduced", "state", "graph", ",", "is", "a", "tree", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "work of futer", "start": 61, "end": 74, "i_start": 10, "i_end": 12}, "verb": {"text": "shows", "start": 75, "end": 80, "i_start": 13, "i_end": 13}}, {"subject": {"text": "if a related graph", "start": 138, "end": 156, "i_start": 25, "i_end": 28}, "verb": {"text": "is", "start": 115, "end": 117, "i_start": 19, "i_end": 19}}, {"subject": {"text": "work of futer", "start": 61, "end": 74, "i_start": 10, "i_end": 12}, "verb": {"text": "called", "start": 159, "end": 165, "i_start": 30, "i_end": 30}}, {"character": {"text": "work", "start": 61, "end": 65, "i_start": 10, "i_end": 10}, "action": {"text": "shows", "start": 75, "end": 80, "i_start": 13, "i_end": 13}}], "id": 444}, {"sent": "shou et al proposed an end-to-end segment-based 3d cnn framework , which outperformed other rnn-based methods by capturing spatio-temporal information simultaneously .", "tokens": ["shou", "et", "al", "proposed", "an", "end", "-", "to", "-", "end", "segment", "-", "based", "3d", "cnn", "framework", ",", "which", "outperformed", "other", "rnn", "-", "based", "methods", "by", "capturing", "spatio", "-", "temporal", "information", "simultaneously", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "shou et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "shou", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "other", "start": 86, "end": 91, "i_start": 19, "i_end": 19}, "action": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "framework", "start": 55, "end": 64, "i_start": 15, "i_end": 15}, "action": {"text": "outperformed", "start": 73, "end": 85, "i_start": 18, "i_end": 18}}, {"character": {"text": "framework", "start": 55, "end": 64, "i_start": 15, "i_end": 15}, "action": {"text": "capturing", "start": 113, "end": 122, "i_start": 25, "i_end": 25}}], "id": 445}, {"sent": "the electronic noise has been subtracted , but is shown explicitly .", "tokens": ["the", "electronic", "noise", "has", "been", "subtracted", ",", "but", "is", "shown", "explicitly", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electronic noise", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "has been subtracted", "start": 21, "end": 40, "i_start": 3, "i_end": 5}}, {"subject": {"text": "the electronic noise", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "shown", "start": 50, "end": 55, "i_start": 9, "i_end": 9}}], "id": 446}, {"sent": "convolutional neural networks have recently achieved great success on various visual recognition tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "achieved", "great", "success", "on", "various", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 7, "i_end": 7}}], "id": 447}, {"sent": "the lightest neutralino , if it is the lsp , is the plausible candidate for the cdm .", "tokens": ["the", "lightest", "neutralino", ",", "if", "it", "is", "the", "lsp", ",", "is", "the", "plausible", "candidate", "for", "the", "cdm", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the lightest neutralino", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 45, "end": 47, "i_start": 10, "i_end": 10}}], "id": 448}, {"sent": "ultra-wideband is a promising technology for wireless high rate and short range communications .", "tokens": ["ultra", "-", "wideband", "is", "a", "promising", "technology", "for", "wireless", "high", "rate", "and", "short", "range", "communications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "ultra-wideband", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "technology", "start": 30, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "promising", "start": 20, "end": 29, "i_start": 5, "i_end": 5}}], "id": 449}, {"sent": "by solving the evolution equations with the calculated evolution kernels , we derive the virtual photon fragmentation functions .", "tokens": ["by", "solving", "the", "evolution", "equations", "with", "the", "calculated", "evolution", "kernels", ",", "we", "derive", "the", "virtual", "photon", "fragmentation", "functions", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 75, "end": 77, "i_start": 11, "i_end": 11}, "verb": {"text": "derive", "start": 78, "end": 84, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 75, "end": 77, "i_start": 11, "i_end": 11}, "action": {"text": "derive", "start": 78, "end": 84, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 75, "end": 77, "i_start": 11, "i_end": 11}, "action": {"text": "solving", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 450}, {"sent": "however , both very strict limits are obtained with the assumption that brane effects do not change the physics in the pre-recombination era , while the sn ia limit is model independent .", "tokens": ["however", ",", "both", "very", "strict", "limits", "are", "obtained", "with", "the", "assumption", "that", "brane", "effects", "do", "not", "change", "the", "physics", "in", "the", "pre", "-", "recombination", "era", ",", "while", "the", "sn", "ia", "limit", "is", "model", "independent", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "both very strict limits", "start": 10, "end": 33, "i_start": 2, "i_end": 5}, "verb": {"text": "are obtained", "start": 34, "end": 46, "i_start": 6, "i_end": 7}}, {"character": {"text": "effects", "start": 78, "end": 85, "i_start": 13, "i_end": 13}, "action": {"text": "not change", "start": 89, "end": 99, "i_start": 15, "i_end": 16}}], "id": 451}, {"sent": "we implement the heuristic heterogeneous channel recommendation mechanism in both homogeneous and heterogenous homogeneous environments .", "tokens": ["we", "implement", "the", "heuristic", "heterogeneous", "channel", "recommendation", "mechanism", "in", "both", "homogeneous", "and", "heterogenous", "homogeneous", "environments", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}], "id": 452}, {"sent": "the residual connection makes gradient propagation more fluent , allowing training deeper networks .", "tokens": ["the", "residual", "connection", "makes", "gradient", "propagation", "more", "fluent", ",", "allowing", "training", "deeper", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the residual connection", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "makes", "start": 24, "end": 29, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the residual connection", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "fluent", "start": 56, "end": 62, "i_start": 7, "i_end": 7}}, {"character": {"text": "connection", "start": 13, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "makes", "start": 24, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "makes", "start": 24, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "allowing", "start": 65, "end": 73, "i_start": 9, "i_end": 9}}], "id": 453}, {"sent": "using this formula , we can read the ratio of shear viscosity over entropy density from the effective action of the transverse gravitons in the gravity description .", "tokens": ["using", "this", "formula", ",", "we", "can", "read", "the", "ratio", "of", "shear", "viscosity", "over", "entropy", "density", "from", "the", "effective", "action", "of", "the", "transverse", "gravitons", "in", "the", "gravity", "description", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "can read", "start": 24, "end": 32, "i_start": 5, "i_end": 6}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "read", "start": 28, "end": 32, "i_start": 6, "i_end": 6}}], "id": 454}, {"sent": "neural networks have been proven effective in several domains such as image classification .", "tokens": ["neural", "networks", "have", "been", "proven", "effective", "in", "several", "domains", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have been proven", "start": 16, "end": 32, "i_start": 2, "i_end": 4}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "effective", "start": 33, "end": 42, "i_start": 5, "i_end": 5}}], "id": 455}, {"sent": "the isomorphism is a non-abelian analogue of the blo h-kato log map .", "tokens": ["the", "isomorphism", "is", "a", "non", "-", "abelian", "analogue", "of", "the", "blo", "h", "-", "kato", "log", "map", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the isomorphism", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 456}, {"sent": "we use a resnet 101 network to learn features from the input rgb image .", "tokens": ["we", "use", "a", "resnet", "101", "network", "to", "learn", "features", "from", "the", "input", "rgb", "image", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "learn", "start": 31, "end": 36, "i_start": 7, "i_end": 7}}], "id": 457}, {"sent": "the exchange correlation functional is approximated by the generalized gradient approximation as parametrized by perdew , burke and ernzerhof .", "tokens": ["the", "exchange", "correlation", "functional", "is", "approximated", "by", "the", "generalized", "gradient", "approximation", "as", "parametrized", "by", "perdew", ",", "burke", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange correlation functional", "start": 0, "end": 35, "i_start": 0, "i_end": 3}, "verb": {"text": "is approximated", "start": 36, "end": 51, "i_start": 4, "i_end": 5}}, {"character": {"text": "perdew", "start": 113, "end": 119, "i_start": 14, "i_end": 14}, "action": {"text": "parametrized", "start": 97, "end": 109, "i_start": 12, "i_end": 12}}, {"character": {"text": "burke", "start": 122, "end": 127, "i_start": 16, "i_end": 16}, "action": {"text": "parametrized", "start": 97, "end": 109, "i_start": 12, "i_end": 12}}, {"character": {"text": "ernzerhof", "start": 132, "end": 141, "i_start": 18, "i_end": 18}, "action": {"text": "parametrized", "start": 97, "end": 109, "i_start": 12, "i_end": 12}}], "id": 458}, {"sent": "this kind of computation is predominant in machine learning .", "tokens": ["this", "kind", "of", "computation", "is", "predominant", "in", "machine", "learning", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this kind of computation", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "computation", "start": 13, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "predominant", "start": 28, "end": 39, "i_start": 5, "i_end": 5}}], "id": 459}, {"sent": "westin j , sneden c , gustafsson b , cowan j .", "tokens": ["westin", "j", ",", "sneden", "c", ",", "gustafsson", "b", ",", "cowan", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 460}, {"sent": "the celebfaces attribute dataset contains 202,599 face images with large pose variations and background clutter .", "tokens": ["the", "celebfaces", "attribute", "dataset", "contains", "202,599", "face", "images", "with", "large", "pose", "variations", "and", "background", "clutter", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the celebfaces", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "attribute", "start": 15, "end": 24, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the celebfaces", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "contains", "start": 33, "end": 41, "i_start": 4, "i_end": 4}}, {"character": {"text": "dataset", "start": 25, "end": 32, "i_start": 3, "i_end": 3}, "action": {"text": "contains", "start": 33, "end": 41, "i_start": 4, "i_end": 4}}], "id": 461}, {"sent": "however , in quantum mechanics there is a limit to the level of detail that can be achieved .", "tokens": ["however", ",", "in", "quantum", "mechanics", "there", "is", "a", "limit", "to", "the", "level", "of", "detail", "that", "can", "be", "achieved", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 31, "end": 36, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 37, "end": 39, "i_start": 6, "i_end": 6}}], "id": 462}, {"sent": "low-density parity-check codes were invented by gallager in 1963 .", "tokens": ["low", "-", "density", "parity", "-", "check", "codes", "were", "invented", "by", "gallager", "in", "1963", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "low-density parity-check codes", "start": 0, "end": 30, "i_start": 0, "i_end": 6}, "verb": {"text": "were invented", "start": 31, "end": 44, "i_start": 7, "i_end": 8}}, {"character": {"text": "gallager", "start": 48, "end": 56, "i_start": 10, "i_end": 10}, "action": {"text": "invented", "start": 36, "end": 44, "i_start": 8, "i_end": 8}}], "id": 463}, {"sent": "the lhcb detector is a single-arm forward spectrometer covering the pseudorapidity range 2-5 , designed for the study of particles containing b or c quarks .", "tokens": ["the", "lhcb", "detector", "is", "a", "single", "-", "arm", "forward", "spectrometer", "covering", "the", "pseudorapidity", "range", "2", "-", "5", ",", "designed", "for", "the", "study", "of", "particles", "containing", "b", "or", "c", "quarks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lhcb detector", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "spectrometer", "start": 42, "end": 54, "i_start": 9, "i_end": 9}, "action": {"text": "covering", "start": 55, "end": 63, "i_start": 10, "i_end": 10}}, {"character": {"text": "particles", "start": 121, "end": 130, "i_start": 23, "i_end": 23}, "action": {"text": "containing", "start": 131, "end": 141, "i_start": 24, "i_end": 24}}], "id": 464}, {"sent": "moreover , the distribution \u03be is a contact structure on m if and only if the connection a is fat at the proof .", "tokens": ["moreover", ",", "the", "distribution", "\u03be", "is", "a", "contact", "structure", "on", "m", "if", "and", "only", "if", "the", "connection", "a", "is", "fat", "at", "the", "proof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the distribution \u03be", "start": 11, "end": 29, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 5, "i_end": 5}}], "id": 465}, {"sent": "li et al showed that linear network coding with finite alphabet is sufficient for multicast .", "tokens": ["li", "et", "al", "showed", "that", "linear", "network", "coding", "with", "finite", "alphabet", "is", "sufficient", "for", "multicast", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "li et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 9, "end": 15, "i_start": 3, "i_end": 3}}, {"subject": {"text": "li et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 64, "end": 66, "i_start": 11, "i_end": 11}}, {"character": {"text": "li", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 9, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "coding", "start": 36, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "sufficient", "start": 67, "end": 77, "i_start": 12, "i_end": 12}}], "id": 466}, {"sent": "geng et al proposed an aging pattern subspace approach to construct a subspace for aging patterns as a chronological sequence of face images .", "tokens": ["geng", "et", "al", "proposed", "an", "aging", "pattern", "subspace", "approach", "to", "construct", "a", "subspace", "for", "aging", "patterns", "as", "a", "chronological", "sequence", "of", "face", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "geng et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "geng", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}], "id": 467}, {"sent": "such a spacetime is a solution without any source but with a universal curvature encapsulated in a cosmological constant .", "tokens": ["such", "a", "spacetime", "is", "a", "solution", "without", "any", "source", "but", "with", "a", "universal", "curvature", "encapsulated", "in", "a", "cosmological", "constant", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such a spacetime", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 468}, {"sent": "on the other hand , there is a non-constructive approach of banaszczyk that provides a bound of ousing convex geometry arguments .", "tokens": ["on", "the", "other", "hand", ",", "there", "is", "a", "non", "-", "constructive", "approach", "of", "banaszczyk", "that", "provides", "a", "bound", "of", "ousing", "convex", "geometry", "arguments", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 20, "end": 25, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 6, "i_end": 6}}, {"character": {"text": "banaszczyk", "start": 60, "end": 70, "i_start": 13, "i_end": 13}, "action": {"text": "approach", "start": 48, "end": 56, "i_start": 11, "i_end": 11}}, {"character": {"text": "approach", "start": 48, "end": 56, "i_start": 11, "i_end": 11}, "action": {"text": "provides", "start": 76, "end": 84, "i_start": 15, "i_end": 15}}], "id": 469}, {"sent": "in the recent years , the development of deep convolutional neural networks with advanced network structures such as vgg and resnet , have been widely used in many areas such as object detection and segmentation .", "tokens": ["in", "the", "recent", "years", ",", "the", "development", "of", "deep", "convolutional", "neural", "networks", "with", "advanced", "network", "structures", "such", "as", "vgg", "and", "resnet", ",", "have", "been", "widely", "used", "in", "many", "areas", "such", "as", "object", "detection", "and", "segmentation", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the development of deep convolutional neural networks with advanced network structures such as vgg and resnet", "start": 22, "end": 131, "i_start": 5, "i_end": 20}, "verb": {"text": "used", "start": 151, "end": 155, "i_start": 25, "i_end": 25}}, {"subject": {"text": "the development of deep convolutional neural networks with advanced network structures such as vgg and resnet", "start": 22, "end": 131, "i_start": 5, "i_end": 20}, "verb": {"text": "have been", "start": 134, "end": 143, "i_start": 22, "i_end": 23}}, {"character": {"text": "networks", "start": 67, "end": 75, "i_start": 11, "i_end": 11}, "action": {"text": "have", "start": 134, "end": 138, "i_start": 22, "i_end": 22}}], "id": 470}, {"sent": "gradual typing enables programmers to gradually evolve their programs from the flexibility of dynamic typing to the security of static typing .", "tokens": ["gradual", "typing", "enables", "programmers", "to", "gradually", "evolve", "their", "programs", "from", "the", "flexibility", "of", "dynamic", "typing", "to", "the", "security", "of", "static", "typing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "gradual typing", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "enables", "start": 15, "end": 22, "i_start": 2, "i_end": 2}}], "id": 471}, {"sent": "when the target space is a kahler manifold , the system has product metric parametrized by the radius r of the circle .", "tokens": ["when", "the", "target", "space", "is", "a", "kahler", "manifold", ",", "the", "system", "has", "product", "metric", "parametrized", "by", "the", "radius", "r", "of", "the", "circle", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "system", "start": 49, "end": 55, "i_start": 10, "i_end": 10}, "action": {"text": "has", "start": 56, "end": 59, "i_start": 11, "i_end": 11}}], "id": 472}, {"sent": "thirdly , volatility is a crucial factor in a wide range of research areas .", "tokens": ["thirdly", ",", "volatility", "is", "a", "crucial", "factor", "in", "a", "wide", "range", "of", "research", "areas", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "volatility", "start": 10, "end": 20, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 3, "i_end": 3}}], "id": 473}, {"sent": "for finite difference methods with convergence rates of order oin space , where h is the maximum meshsize , see , for example , .", "tokens": ["for", "finite", "difference", "methods", "with", "convergence", "rates", "of", "order", "oin", "space", ",", "where", "h", "is", "the", "maximum", "meshsize", ",", "see", ",", "for", "example", ",", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 474}, {"sent": "various theoretical analyses of this algorithm have been proposed .", "tokens": ["various", "theoretical", "analyses", "of", "this", "algorithm", "have", "been", "proposed", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "various theoretical analyses of this algorithm", "start": 0, "end": 46, "i_start": 0, "i_end": 5}, "verb": {"text": "have been proposed", "start": 47, "end": 65, "i_start": 6, "i_end": 8}}], "id": 475}, {"sent": "recently , many generative adversarial models have also been proposed for learning robust and reusable representations .", "tokens": ["recently", ",", "many", "generative", "adversarial", "models", "have", "also", "been", "proposed", "for", "learning", "robust", "and", "reusable", "representations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many generative adversarial models", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "been proposed", "start": 56, "end": 69, "i_start": 8, "i_end": 9}}, {"subject": {"text": "many generative adversarial models", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have", "start": 46, "end": 50, "i_start": 6, "i_end": 6}}], "id": 476}, {"sent": "for planar graphs , partial representation extension is solvable in linear time .", "tokens": ["for", "planar", "graphs", ",", "partial", "representation", "extension", "is", "solvable", "in", "linear", "time", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "partial representation extension", "start": 20, "end": 52, "i_start": 4, "i_end": 6}, "verb": {"text": "is", "start": 53, "end": 55, "i_start": 7, "i_end": 7}}], "id": 477}, {"sent": "from the exact s-matrix , one can derive exact form factors and extract correlators .", "tokens": ["from", "the", "exact", "s", "-", "matrix", ",", "one", "can", "derive", "exact", "form", "factors", "and", "extract", "correlators", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 26, "end": 29, "i_start": 7, "i_end": 7}, "verb": {"text": "can derive", "start": 30, "end": 40, "i_start": 8, "i_end": 9}}, {"subject": {"text": "one", "start": 26, "end": 29, "i_start": 7, "i_end": 7}, "verb": {"text": "extract", "start": 64, "end": 71, "i_start": 14, "i_end": 14}}, {"character": {"text": "one", "start": 26, "end": 29, "i_start": 7, "i_end": 7}, "action": {"text": "derive", "start": 34, "end": 40, "i_start": 9, "i_end": 9}}, {"character": {"text": "one", "start": 26, "end": 29, "i_start": 7, "i_end": 7}, "action": {"text": "extract", "start": 64, "end": 71, "i_start": 14, "i_end": 14}}], "id": 478}, {"sent": "we propose a multi-scale version of the crooks-chandler method that is based on parallel tempering .", "tokens": ["we", "propose", "a", "multi", "-", "scale", "version", "of", "the", "crooks", "-", "chandler", "method", "that", "is", "based", "on", "parallel", "tempering", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "propose", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 479}, {"sent": "models based on convolutional neural networks and recurrent neural networks have achieved remarkable performance in many tasks , such as image classification .", "tokens": ["models", "based", "on", "convolutional", "neural", "networks", "and", "recurrent", "neural", "networks", "have", "achieved", "remarkable", "performance", "in", "many", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "models based on convolutional neural networks and recurrent neural networks", "start": 0, "end": 75, "i_start": 0, "i_end": 9}, "verb": {"text": "have achieved", "start": 76, "end": 89, "i_start": 10, "i_end": 11}}, {"character": {"text": "models", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "achieved", "start": 81, "end": 89, "i_start": 11, "i_end": 11}}], "id": 480}, {"sent": "in this approach , the fourier-images of electric and magnetic fields are considered as quantum mechanical observables of corresponding electric and magnetic field operators .", "tokens": ["in", "this", "approach", ",", "the", "fourier", "-", "images", "of", "electric", "and", "magnetic", "fields", "are", "considered", "as", "quantum", "mechanical", "observables", "of", "corresponding", "electric", "and", "magnetic", "field", "operators", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the fourier-images of electric and magnetic fields", "start": 19, "end": 69, "i_start": 4, "i_end": 12}, "verb": {"text": "are considered", "start": 70, "end": 84, "i_start": 13, "i_end": 14}}, {"character": {"text": "fields", "start": 63, "end": 69, "i_start": 12, "i_end": 12}, "action": {"text": "observables", "start": 107, "end": 118, "i_start": 18, "i_end": 18}}, {"character": {"text": "electric", "start": 41, "end": 49, "i_start": 9, "i_end": 9}, "action": {"text": "observables", "start": 107, "end": 118, "i_start": 18, "i_end": 18}}, {"character": {"text": "field", "start": 158, "end": 163, "i_start": 24, "i_end": 24}, "action": {"text": "observables", "start": 107, "end": 118, "i_start": 18, "i_end": 18}}, {"character": {"text": "magnetic", "start": 54, "end": 62, "i_start": 11, "i_end": 11}, "action": {"text": "observables", "start": 107, "end": 118, "i_start": 18, "i_end": 18}}], "id": 481}, {"sent": "for explaining aging changes , we proposed a generalized concept of misrepair in our misrepair-accumulation theory .", "tokens": ["for", "explaining", "aging", "changes", ",", "we", "proposed", "a", "generalized", "concept", "of", "misrepair", "in", "our", "misrepair", "-", "accumulation", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "verb": {"text": "proposed", "start": 34, "end": 42, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "proposed", "start": 34, "end": 42, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "explaining", "start": 4, "end": 14, "i_start": 1, "i_end": 1}}], "id": 482}, {"sent": "for flexible , fast and effective image denoising , zhang et al proposed a discriminative learning method called ffdnet .", "tokens": ["for", "flexible", ",", "fast", "and", "effective", "image", "denoising", ",", "zhang", "et", "al", "proposed", "a", "discriminative", "learning", "method", "called", "ffdnet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhang et al", "start": 52, "end": 63, "i_start": 9, "i_end": 11}, "verb": {"text": "proposed", "start": 64, "end": 72, "i_start": 12, "i_end": 12}}, {"character": {"text": "zhang", "start": 52, "end": 57, "i_start": 9, "i_end": 9}, "action": {"text": "proposed", "start": 64, "end": 72, "i_start": 12, "i_end": 12}}, {"character": {"text": "method", "start": 99, "end": 105, "i_start": 16, "i_end": 16}, "action": {"text": "effective", "start": 24, "end": 33, "i_start": 5, "i_end": 5}}], "id": 483}, {"sent": "since hammons et al have showed certain good binary nonlinear codes are actually images of some linear codes over z 4 via the gray map , which has made a breakthrough in coding theory .", "tokens": ["since", "hammons", "et", "al", "have", "showed", "certain", "good", "binary", "nonlinear", "codes", "are", "actually", "images", "of", "some", "linear", "codes", "over", "z", "4", "via", "the", "gray", "map", ",", "which", "has", "made", "a", "breakthrough", "in", "coding", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hammons et al", "start": 6, "end": 19, "i_start": 1, "i_end": 3}, "verb": {"text": "have showed", "start": 20, "end": 31, "i_start": 4, "i_end": 5}}, {"subject": {"text": "hammons et al", "start": 6, "end": 19, "i_start": 1, "i_end": 3}, "verb": {"text": "are", "start": 68, "end": 71, "i_start": 11, "i_end": 11}}, {"character": {"text": "map", "start": 131, "end": 134, "i_start": 24, "i_end": 24}, "action": {"text": "breakthrough", "start": 154, "end": 166, "i_start": 30, "i_end": 30}}, {"character": {"text": "hammons", "start": 6, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "showed", "start": 25, "end": 31, "i_start": 5, "i_end": 5}}], "id": 484}, {"sent": "faghani and his collaborators modeled the propagation of crosssite-scripting worms in osns .", "tokens": ["faghani", "and", "his", "collaborators", "modeled", "the", "propagation", "of", "crosssite", "-", "scripting", "worms", "in", "osns", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "faghani and his collaborators", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "modeled", "start": 30, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "faghani", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "modeled", "start": 30, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "faghani", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "modeled", "start": 30, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "worms", "start": 77, "end": 82, "i_start": 11, "i_end": 11}, "action": {"text": "scripting", "start": 67, "end": 76, "i_start": 10, "i_end": 10}}], "id": 485}, {"sent": "for all the sandwich waves described above , it is straightforward to construct their corresponding impulsive limits .", "tokens": ["for", "all", "the", "sandwich", "waves", "described", "above", ",", "it", "is", "straightforward", "to", "construct", "their", "corresponding", "impulsive", "limits", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 45, "end": 47, "i_start": 8, "i_end": 8}, "verb": {"text": "is", "start": 48, "end": 50, "i_start": 9, "i_end": 9}}], "id": 486}, {"sent": "in recent years , convolutional neural networks have become the dominant approach for a variety of computer vision tasks , eg , image classification .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "become", "the", "dominant", "approach", "for", "a", "variety", "of", "computer", "vision", "tasks", ",", "eg", ",", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have become", "start": 48, "end": 59, "i_start": 7, "i_end": 8}}, {"character": {"text": "approach", "start": 73, "end": 81, "i_start": 11, "i_end": 11}, "action": {"text": "dominant", "start": 64, "end": 72, "i_start": 10, "i_end": 10}}], "id": 487}, {"sent": "reinforcement learning is a machine learning paradigm based on sequential interactions between an agent and an environment in which the agent attempts to learn a policy \u03c0 to maximize a total reward .", "tokens": ["reinforcement", "learning", "is", "a", "machine", "learning", "paradigm", "based", "on", "sequential", "interactions", "between", "an", "agent", "and", "an", "environment", "in", "which", "the", "agent", "attempts", "to", "learn", "a", "policy", "\u03c0", "to", "maximize", "a", "total", "reward", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "agent", "start": 98, "end": 103, "i_start": 13, "i_end": 13}, "action": {"text": "interactions", "start": 74, "end": 86, "i_start": 10, "i_end": 10}}, {"character": {"text": "agent", "start": 98, "end": 103, "i_start": 13, "i_end": 13}, "action": {"text": "attempts", "start": 142, "end": 150, "i_start": 21, "i_end": 21}}, {"character": {"text": "agent", "start": 98, "end": 103, "i_start": 13, "i_end": 13}, "action": {"text": "learning", "start": 14, "end": 22, "i_start": 1, "i_end": 1}}, {"character": {"text": "agent", "start": 98, "end": 103, "i_start": 13, "i_end": 13}, "action": {"text": "maximize", "start": 174, "end": 182, "i_start": 28, "i_end": 28}}], "id": 488}, {"sent": "deep convolutional neural networks have achieved dramatic accuracy improvements in many areas of computer vision .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "dramatic", "accuracy", "improvements", "in", "many", "areas", "of", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "improvements", "start": 67, "end": 79, "i_start": 8, "i_end": 8}}], "id": 489}, {"sent": "erez and zamir dealt with the issue of the power constraint using nested lattice codes , where a quantization-good lattice serves as the shaping lattice while the awgn-good lattice serves as the coding lattice .", "tokens": ["erez", "and", "zamir", "dealt", "with", "the", "issue", "of", "the", "power", "constraint", "using", "nested", "lattice", "codes", ",", "where", "a", "quantization", "-", "good", "lattice", "serves", "as", "the", "shaping", "lattice", "while", "the", "awgn", "-", "good", "lattice", "serves", "as", "the", "coding", "lattice", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "erez and zamir", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "dealt", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "erez", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "dealt", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "zamir", "start": 9, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "dealt", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "constraint", "start": 49, "end": 59, "i_start": 10, "i_end": 10}, "action": {"text": "issue", "start": 30, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "lattice", "start": 115, "end": 122, "i_start": 21, "i_end": 21}, "action": {"text": "serves", "start": 123, "end": 129, "i_start": 22, "i_end": 22}}, {"character": {"text": "lattice", "start": 115, "end": 122, "i_start": 21, "i_end": 21}, "action": {"text": "shaping", "start": 137, "end": 144, "i_start": 25, "i_end": 25}}, {"character": {"text": "lattice", "start": 173, "end": 180, "i_start": 32, "i_end": 32}, "action": {"text": "serves", "start": 181, "end": 187, "i_start": 33, "i_end": 33}}, {"character": {"text": "lattice", "start": 202, "end": 209, "i_start": 37, "i_end": 37}, "action": {"text": "coding", "start": 195, "end": 201, "i_start": 36, "i_end": 36}}], "id": 490}, {"sent": "for the training of vsrn , we use the adam optimizer to train the model with 30 epochs .", "tokens": ["for", "the", "training", "of", "vsrn", ",", "we", "use", "the", "adam", "optimizer", "to", "train", "the", "model", "with", "30", "epochs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 27, "end": 29, "i_start": 6, "i_end": 6}, "verb": {"text": "use", "start": 30, "end": 33, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 27, "end": 29, "i_start": 6, "i_end": 6}, "action": {"text": "use", "start": 30, "end": 33, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 27, "end": 29, "i_start": 6, "i_end": 6}, "action": {"text": "train", "start": 56, "end": 61, "i_start": 12, "i_end": 12}}], "id": 491}, {"sent": "the quintessence is a slowly varying scalar field with a canonical kinetic energy term .", "tokens": ["the", "quintessence", "is", "a", "slowly", "varying", "scalar", "field", "with", "a", "canonical", "kinetic", "energy", "term", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quintessence", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}], "id": 492}, {"sent": "exchangecorrelation effects were described using the perdew-burke-ernzerhof generalised gradient approximation .", "tokens": ["exchangecorrelation", "effects", "were", "described", "using", "the", "perdew", "-", "burke", "-", "ernzerhof", "generalised", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "exchangecorrelation effects", "start": 0, "end": 27, "i_start": 0, "i_end": 1}, "verb": {"text": "were described", "start": 28, "end": 42, "i_start": 2, "i_end": 3}}], "id": 493}, {"sent": "the general object proposals are generated by the selective search algorithm .", "tokens": ["the", "general", "object", "proposals", "are", "generated", "by", "the", "selective", "search", "algorithm", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the general object proposals", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "are generated", "start": 29, "end": 42, "i_start": 4, "i_end": 5}}, {"character": {"text": "algorithm", "start": 67, "end": 76, "i_start": 10, "i_end": 10}, "action": {"text": "generated", "start": 33, "end": 42, "i_start": 5, "i_end": 5}}, {"character": {"text": "algorithm", "start": 67, "end": 76, "i_start": 10, "i_end": 10}, "action": {"text": "search", "start": 60, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "algorithm", "start": 67, "end": 76, "i_start": 10, "i_end": 10}, "action": {"text": "selective", "start": 50, "end": 59, "i_start": 8, "i_end": 8}}], "id": 494}, {"sent": "to minimize the electrostatic free energy , the positions of condensed counterions on the two polyions become correlated .", "tokens": ["to", "minimize", "the", "electrostatic", "free", "energy", ",", "the", "positions", "of", "condensed", "counterions", "on", "the", "two", "polyions", "become", "correlated", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the positions of condensed counterions on the two polyions", "start": 44, "end": 102, "i_start": 7, "i_end": 15}, "verb": {"text": "become", "start": 103, "end": 109, "i_start": 16, "i_end": 16}}], "id": 495}, {"sent": "like many pervious researches , this paper compares the performance of its proposed method with other individual clustering methods and cluster ensemble methods by using standard datasets and their real classes .", "tokens": ["like", "many", "pervious", "researches", ",", "this", "paper", "compares", "the", "performance", "of", "its", "proposed", "method", "with", "other", "individual", "clustering", "methods", "and", "cluster", "ensemble", "methods", "by", "using", "standard", "datasets", "and", "their", "real", "classes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this paper", "start": 32, "end": 42, "i_start": 5, "i_end": 6}, "verb": {"text": "compares", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "paper", "start": 37, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "compares", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "method", "start": 84, "end": 90, "i_start": 13, "i_end": 13}, "action": {"text": "performance", "start": 56, "end": 67, "i_start": 9, "i_end": 9}}, {"character": {"text": "paper", "start": 37, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "proposed", "start": 75, "end": 83, "i_start": 12, "i_end": 12}}, {"character": {"text": "paper", "start": 37, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "using", "start": 164, "end": 169, "i_start": 24, "i_end": 24}}], "id": 496}, {"sent": "the entanglement of formation is a well-defined important measure of entanglement for bipartite systems .", "tokens": ["the", "entanglement", "of", "formation", "is", "a", "well", "-", "defined", "important", "measure", "of", "entanglement", "for", "bipartite", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the entanglement of formation", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 4, "i_end": 4}}], "id": 497}, {"sent": "this orbit consists of exactly nine lines .", "tokens": ["this", "orbit", "consists", "of", "exactly", "nine", "lines", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this orbit", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}], "id": 498}, {"sent": "the following crucial theorem fails for the q-model structure .", "tokens": ["the", "following", "crucial", "theorem", "fails", "for", "the", "q", "-", "model", "structure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the following crucial theorem", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "fails", "start": 30, "end": 35, "i_start": 4, "i_end": 4}}], "id": 499}, {"sent": "timusk , physical properties of high temperature superconductors iii , edited by d .", "tokens": ["timusk", ",", "physical", "properties", "of", "high", "temperature", "superconductors", "iii", ",", "edited", "by", "d", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "timusk", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "iii", "start": 65, "end": 68, "i_start": 8, "i_end": 8}}], "id": 500}, {"sent": "dawkins , the selfish gene , oxford university press , oxford .", "tokens": ["dawkins", ",", "the", "selfish", "gene", ",", "oxford", "university", "press", ",", "oxford", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 501}, {"sent": "a striking feature of this figure is the appearance of a double peak at short residence times for the lower temperatures .", "tokens": ["a", "striking", "feature", "of", "this", "figure", "is", "the", "appearance", "of", "a", "double", "peak", "at", "short", "residence", "times", "for", "the", "lower", "temperatures", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a striking feature of this figure", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "appearance", "start": 41, "end": 51, "i_start": 8, "i_end": 8}, "action": {"text": "feature", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}], "id": 502}, {"sent": "for any fixed positive integer k , gordon and ono proved that the number of partitions of n into distinct parts is divisible by 2 k for almost all n .", "tokens": ["for", "any", "fixed", "positive", "integer", "k", ",", "gordon", "and", "ono", "proved", "that", "the", "number", "of", "partitions", "of", "n", "into", "distinct", "parts", "is", "divisible", "by", "2", "k", "for", "almost", "all", "n", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "any fixed positive integer k", "start": 4, "end": 32, "i_start": 1, "i_end": 5}, "verb": {"text": "proved", "start": 50, "end": 56, "i_start": 10, "i_end": 10}}, {"subject": {"text": "any fixed positive integer k", "start": 4, "end": 32, "i_start": 1, "i_end": 5}, "verb": {"text": "is", "start": 112, "end": 114, "i_start": 21, "i_end": 21}}, {"character": {"text": "gordon", "start": 35, "end": 41, "i_start": 7, "i_end": 7}, "action": {"text": "proved", "start": 50, "end": 56, "i_start": 10, "i_end": 10}}, {"character": {"text": "ono", "start": 46, "end": 49, "i_start": 9, "i_end": 9}, "action": {"text": "proved", "start": 50, "end": 56, "i_start": 10, "i_end": 10}}], "id": 503}, {"sent": "quantum mechanics is a fundamentally probabilistic theory .", "tokens": ["quantum", "mechanics", "is", "a", "fundamentally", "probabilistic", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum mechanics", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}], "id": 504}, {"sent": "convolutional neural networks have made great progress in various fields , such as object classification , detection and character recognition .", "tokens": ["convolutional", "neural", "networks", "have", "made", "great", "progress", "in", "various", "fields", ",", "such", "as", "object", "classification", ",", "detection", "and", "character", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have made", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}], "id": 505}, {"sent": "in recent years , deep convolutional neural networks have demonstrated dramatic improvements in performance for computer vision tasks such as object classification , detection , and segmentation .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "demonstrated", "dramatic", "improvements", "in", "performance", "for", "computer", "vision", "tasks", "such", "as", "object", "classification", ",", "detection", ",", "and", "segmentation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have demonstrated", "start": 53, "end": 70, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "demonstrated", "start": 58, "end": 70, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "improvements", "start": 80, "end": 92, "i_start": 11, "i_end": 11}}], "id": 506}, {"sent": "for input features , we use embeddings from the resnet-50 deep convolutional neural network pre-trained on imagenet-1k .", "tokens": ["for", "input", "features", ",", "we", "use", "embeddings", "from", "the", "resnet-50", "deep", "convolutional", "neural", "network", "pre", "-", "trained", "on", "imagenet-1k", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 24, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 24, "end": 27, "i_start": 5, "i_end": 5}}], "id": 507}, {"sent": "note that dbrane-antidbrane annihilation plays an important role in the mechanism for generating the inflationary potential in current proposals for early universe string cosmology .", "tokens": ["note", "that", "dbrane", "-", "antidbrane", "annihilation", "plays", "an", "important", "role", "in", "the", "mechanism", "for", "generating", "the", "inflationary", "potential", "in", "current", "proposals", "for", "early", "universe", "string", "cosmology", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "dbrane-antidbrane annihilation", "start": 10, "end": 40, "i_start": 2, "i_end": 5}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "dbrane-antidbrane annihilation", "start": 10, "end": 40, "i_start": 2, "i_end": 5}, "verb": {"text": "plays", "start": 41, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "annihilation", "start": 28, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "plays", "start": 41, "end": 46, "i_start": 6, "i_end": 6}}], "id": 508}, {"sent": "we also compare our scheme with another recently proposed time-domain ba approach which focuses on estimating the instantaneous channel coefficients based on orthogonal matching pursuit technique .", "tokens": ["we", "also", "compare", "our", "scheme", "with", "another", "recently", "proposed", "time", "-", "domain", "ba", "approach", "which", "focuses", "on", "estimating", "the", "instantaneous", "channel", "coefficients", "based", "on", "orthogonal", "matching", "pursuit", "technique", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "approach", "start": 73, "end": 81, "i_start": 13, "i_end": 13}, "action": {"text": "focuses", "start": 88, "end": 95, "i_start": 15, "i_end": 15}}], "id": 509}, {"sent": "deep convolutional neural networks , in particular , have enjoyed huge success in tackling many computer vision problems over the past few years , thanks to the tremendous development of many effective architectures , alexnet to name a few .", "tokens": ["deep", "convolutional", "neural", "networks", ",", "in", "particular", ",", "have", "enjoyed", "huge", "success", "in", "tackling", "many", "computer", "vision", "problems", "over", "the", "past", "few", "years", ",", "thanks", "to", "the", "tremendous", "development", "of", "many", "effective", "architectures", ",", "alexnet", "to", "name", "a", "few", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have enjoyed", "start": 53, "end": 65, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "enjoyed", "start": 58, "end": 65, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 71, "end": 78, "i_start": 11, "i_end": 11}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "tackling", "start": 82, "end": 90, "i_start": 13, "i_end": 13}}, {"character": {"text": "architectures", "start": 202, "end": 215, "i_start": 32, "i_end": 32}, "action": {"text": "effective", "start": 192, "end": 201, "i_start": 31, "i_end": 31}}], "id": 510}, {"sent": "the security aspects are dealt in prasad , which discuss the research challenges for security in cognitive networks .", "tokens": ["the", "security", "aspects", "are", "dealt", "in", "prasad", ",", "which", "discuss", "the", "research", "challenges", "for", "security", "in", "cognitive", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the security aspects", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are dealt", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "security", "start": 85, "end": 93, "i_start": 14, "i_end": 14}, "action": {"text": "challenges", "start": 70, "end": 80, "i_start": 12, "i_end": 12}}], "id": 511}, {"sent": "the isotope is a beta emitter with an energy endpoint of 565 kev .", "tokens": ["the", "isotope", "is", "a", "beta", "emitter", "with", "an", "energy", "endpoint", "of", "565", "kev", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the isotope", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "isotope", "start": 4, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "emitter", "start": 22, "end": 29, "i_start": 5, "i_end": 5}}], "id": 512}, {"sent": "this led to the concept of frames , which was introduced by duffin and schaefer .", "tokens": ["this", "led", "to", "the", "concept", "of", "frames", ",", "which", "was", "introduced", "by", "duffin", "and", "schaefer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "led", "start": 5, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "led", "start": 5, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "duffin", "start": 60, "end": 66, "i_start": 12, "i_end": 12}, "action": {"text": "introduced", "start": 46, "end": 56, "i_start": 10, "i_end": 10}}, {"character": {"text": "schaefer", "start": 71, "end": 79, "i_start": 14, "i_end": 14}, "action": {"text": "introduced", "start": 46, "end": 56, "i_start": 10, "i_end": 10}}], "id": 513}, {"sent": "deep convolutional neural networks have led to major breakthroughs in many computer vision tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "led", "to", "major", "breakthroughs", "in", "many", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have led", "start": 35, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "led", "start": 40, "end": 43, "i_start": 5, "i_end": 5}}], "id": 514}, {"sent": "this condensate is a very important characteristics of qcd vacuum , since it is directly related to the vacuum energy density .", "tokens": ["this", "condensate", "is", "a", "very", "important", "characteristics", "of", "qcd", "vacuum", ",", "since", "it", "is", "directly", "related", "to", "the", "vacuum", "energy", "density", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this condensate", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"subject": {"text": "this condensate", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "related", "start": 89, "end": 96, "i_start": 15, "i_end": 15}}], "id": 515}, {"sent": "moreover , a finite-volume scheme for a keller-segel system with additional cross diffusion and discrete entropy dissipation property was investigated in .", "tokens": ["moreover", ",", "a", "finite", "-", "volume", "scheme", "for", "a", "keller", "-", "segel", "system", "with", "additional", "cross", "diffusion", "and", "discrete", "entropy", "dissipation", "property", "was", "investigated", "in", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "a finite-volume scheme for a keller-segel system with additional cross diffusion and discrete entropy dissipation property", "start": 11, "end": 133, "i_start": 2, "i_end": 21}, "verb": {"text": "was investigated", "start": 134, "end": 150, "i_start": 22, "i_end": 23}}, {"character": {"text": "diffusion", "start": 82, "end": 91, "i_start": 16, "i_end": 16}, "action": {"text": "cross", "start": 76, "end": 81, "i_start": 15, "i_end": 15}}], "id": 516}, {"sent": "oxygen is the most important element , and it affects both energy generation and opacity in an important way .", "tokens": ["oxygen", "is", "the", "most", "important", "element", ",", "and", "it", "affects", "both", "energy", "generation", "and", "opacity", "in", "an", "important", "way", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "oxygen", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 7, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 43, "end": 45, "i_start": 8, "i_end": 8}, "verb": {"text": "affects", "start": 46, "end": 53, "i_start": 9, "i_end": 9}}, {"character": {"text": "oxygen", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "affects", "start": 46, "end": 53, "i_start": 9, "i_end": 9}}], "id": 517}, {"sent": "in general , fine-grained uncertainty relations with unequal weights may be of interest .", "tokens": ["in", "general", ",", "fine", "-", "grained", "uncertainty", "relations", "with", "unequal", "weights", "may", "be", "of", "interest", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "general", "start": 3, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "may be", "start": 69, "end": 75, "i_start": 11, "i_end": 12}}], "id": 518}, {"sent": "ab initio calculations were performed within the density-functional theory framework as implemented in the vasp code .", "tokens": ["ab", "initio", "calculations", "were", "performed", "within", "the", "density", "-", "functional", "theory", "framework", "as", "implemented", "in", "the", "vasp", "code", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "ab initio calculations", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "were performed", "start": 23, "end": 37, "i_start": 3, "i_end": 4}}], "id": 519}, {"sent": "we implemented a peepholes connection lstm variant where its gate layers look at the cell state .", "tokens": ["we", "implemented", "a", "peepholes", "connection", "lstm", "variant", "where", "its", "gate", "layers", "look", "at", "the", "cell", "state", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implemented", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implemented", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "layers", "start": 66, "end": 72, "i_start": 10, "i_end": 10}, "action": {"text": "look", "start": 73, "end": 77, "i_start": 11, "i_end": 11}}], "id": 520}, {"sent": "in , the authors provide algorithms that permit repair of crashed servers , while implementing consistent storage .", "tokens": ["in", ",", "the", "authors", "provide", "algorithms", "that", "permit", "repair", "of", "crashed", "servers", ",", "while", "implementing", "consistent", "storage", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 5, "end": 16, "i_start": 2, "i_end": 3}, "verb": {"text": "provide", "start": 17, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "algorithms", "start": 25, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "permit", "start": 41, "end": 47, "i_start": 7, "i_end": 7}}], "id": 521}, {"sent": "since the seminal papers of gross , the relations among various types of contractivity properties of linear semigroups on the one hand and functional inequalities satisfied by their generators on the other hand , has been intensively investigated .", "tokens": ["since", "the", "seminal", "papers", "of", "gross", ",", "the", "relations", "among", "various", "types", "of", "contractivity", "properties", "of", "linear", "semigroups", "on", "the", "one", "hand", "and", "functional", "inequalities", "satisfied", "by", "their", "generators", "on", "the", "other", "hand", ",", "has", "been", "intensively", "investigated", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the relations among various types of contractivity properties of linear semigroups on the one hand and functional inequalities satisfied by their generators on the other hand", "start": 36, "end": 210, "i_start": 7, "i_end": 32}, "verb": {"text": "investigated", "start": 234, "end": 246, "i_start": 37, "i_end": 37}}, {"subject": {"text": "the relations among various types of contractivity properties of linear semigroups on the one hand and functional inequalities satisfied by their generators on the other hand", "start": 36, "end": 210, "i_start": 7, "i_end": 32}, "verb": {"text": "has been", "start": 213, "end": 221, "i_start": 34, "i_end": 35}}], "id": 522}, {"sent": "a saddle connection is a geodesic segment joining a pair of conical singularities or a conical singularity to itself without any singularities in its interior .", "tokens": ["a", "saddle", "connection", "is", "a", "geodesic", "segment", "joining", "a", "pair", "of", "conical", "singularities", "or", "a", "conical", "singularity", "to", "itself", "without", "any", "singularities", "in", "its", "interior", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a saddle connection", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 523}, {"sent": "the composite system is a superposition of these systems , the power in the sparse system is normalised to \u03b3 and in the dense code to 1 \u03b3 .", "tokens": ["the", "composite", "system", "is", "a", "superposition", "of", "these", "systems", ",", "the", "power", "in", "the", "sparse", "system", "is", "normalised", "to", "\u03b3", "and", "in", "the", "dense", "code", "to", "1", "\u03b3", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the power in the sparse system", "start": 59, "end": 89, "i_start": 10, "i_end": 15}, "verb": {"text": "is", "start": 90, "end": 92, "i_start": 16, "i_end": 16}}, {"subject": {"text": "the power in the sparse system", "start": 59, "end": 89, "i_start": 10, "i_end": 15}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 3, "i_end": 3}}], "id": 524}, {"sent": "the axion is a hypothetical light scalar particle that could explain the origin of dark matter and solve the strong cp problem at the same time .", "tokens": ["the", "axion", "is", "a", "hypothetical", "light", "scalar", "particle", "that", "could", "explain", "the", "origin", "of", "dark", "matter", "and", "solve", "the", "strong", "cp", "problem", "at", "the", "same", "time", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the axion", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "particle", "start": 41, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "explain", "start": 61, "end": 68, "i_start": 10, "i_end": 10}}, {"character": {"text": "particle", "start": 41, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "solve", "start": 99, "end": 104, "i_start": 17, "i_end": 17}}], "id": 525}, {"sent": "graphene is a 1-atom thick , pure-carbon sheet with extraordinary electronic , mechanical , and optical properties .", "tokens": ["graphene", "is", "a", "1", "-", "atom", "thick", ",", "pure", "-", "carbon", "sheet", "with", "extraordinary", "electronic", ",", "mechanical", ",", "and", "optical", "properties", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "graphene", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}], "id": 526}, {"sent": "an introduction to partial differential equations .", "tokens": ["an", "introduction", "to", "partial", "differential", "equations", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 527}, {"sent": "after this phase the shock wave has driven off the stellar mantle .", "tokens": ["after", "this", "phase", "the", "shock", "wave", "has", "driven", "off", "the", "stellar", "mantle", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the shock wave", "start": 17, "end": 31, "i_start": 3, "i_end": 5}, "verb": {"text": "has driven off", "start": 32, "end": 46, "i_start": 6, "i_end": 8}}, {"character": {"text": "wave", "start": 27, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "driven", "start": 36, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "wave", "start": 27, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "shock", "start": 21, "end": 26, "i_start": 4, "i_end": 4}}], "id": 528}, {"sent": "convolutional neural networks have made great progress in various fields , such as object classification , detection and character recognition .", "tokens": ["convolutional", "neural", "networks", "have", "made", "great", "progress", "in", "various", "fields", ",", "such", "as", "object", "classification", ",", "detection", "and", "character", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have made", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}], "id": 529}, {"sent": "leung et al have shown that applying node preference , to alter propagation strength or spread from certain nodes , can greatly improve the performance of the basic label propagation .", "tokens": ["leung", "et", "al", "have", "shown", "that", "applying", "node", "preference", ",", "to", "alter", "propagation", "strength", "or", "spread", "from", "certain", "nodes", ",", "can", "greatly", "improve", "the", "performance", "of", "the", "basic", "label", "propagation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "leung et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 12, "end": 22, "i_start": 3, "i_end": 4}}, {"subject": {"text": "applying node preference", "start": 28, "end": 52, "i_start": 6, "i_end": 8}, "verb": {"text": "improve", "start": 128, "end": 135, "i_start": 22, "i_end": 22}}, {"character": {"text": "applying", "start": 28, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "improve", "start": 128, "end": 135, "i_start": 22, "i_end": 22}}, {"character": {"text": "node", "start": 37, "end": 41, "i_start": 7, "i_end": 7}, "action": {"text": "preference", "start": 42, "end": 52, "i_start": 8, "i_end": 8}}], "id": 530}, {"sent": "the proof of this result relies substantially on a useful result from negahban et al .", "tokens": ["the", "proof", "of", "this", "result", "relies", "substantially", "on", "a", "useful", "result", "from", "negahban", "et", "al", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the proof of this result", "start": 0, "end": 24, "i_start": 0, "i_end": 4}, "verb": {"text": "relies", "start": 25, "end": 31, "i_start": 5, "i_end": 5}}], "id": 531}, {"sent": "a bounds-based reduction scheme for constraints of difference .", "tokens": ["a", "bounds", "-", "based", "reduction", "scheme", "for", "constraints", "of", "difference", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 532}, {"sent": "to detect these communities , we employ the use of the louvain algorithm , a heuristic method based on modularity optimization .", "tokens": ["to", "detect", "these", "communities", ",", "we", "employ", "the", "use", "of", "the", "louvain", "algorithm", ",", "a", "heuristic", "method", "based", "on", "modularity", "optimization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "verb": {"text": "employ", "start": 33, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "employ", "start": 33, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 44, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "detect", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 533}, {"sent": "in recent years , deep learning techniques have changed the performance of different applications such as speech recognition .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "techniques", "have", "changed", "the", "performance", "of", "different", "applications", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning techniques", "start": 18, "end": 42, "i_start": 4, "i_end": 6}, "verb": {"text": "have changed", "start": 43, "end": 55, "i_start": 7, "i_end": 8}}, {"character": {"text": "techniques", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "changed", "start": 48, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "applications", "start": 85, "end": 97, "i_start": 13, "i_end": 13}, "action": {"text": "performance", "start": 60, "end": 71, "i_start": 10, "i_end": 10}}], "id": 534}, {"sent": "recently , a multiple feedback strategy is proposed in for sic based mimo detection .", "tokens": ["recently", ",", "a", "multiple", "feedback", "strategy", "is", "proposed", "in", "for", "sic", "based", "mimo", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a multiple feedback strategy", "start": 11, "end": 39, "i_start": 2, "i_end": 5}, "verb": {"text": "is proposed", "start": 40, "end": 51, "i_start": 6, "i_end": 7}}], "id": 535}, {"sent": "their only matter content is a scalar field with an exponential potential .", "tokens": ["their", "only", "matter", "content", "is", "a", "scalar", "field", "with", "an", "exponential", "potential", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "their only matter content", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 4, "i_end": 4}}], "id": 536}, {"sent": "recently , deep neural networks have demonstrated impressive results in image classification .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "demonstrated", "impressive", "results", "in", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have demonstrated", "start": 32, "end": 49, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "demonstrated", "start": 37, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "results", "start": 61, "end": 68, "i_start": 8, "i_end": 8}, "action": {"text": "impressive", "start": 50, "end": 60, "i_start": 7, "i_end": 7}}], "id": 537}, {"sent": "studies have shown that data representations obtained from stacking up nonlinear feature extractors often yield better machine classification resultscomputer vision , 47 , 48 , 57 and natural language processing .", "tokens": ["studies", "have", "shown", "that", "data", "representations", "obtained", "from", "stacking", "up", "nonlinear", "feature", "extractors", "often", "yield", "better", "machine", "classification", "resultscomputer", "vision", ",", "47", ",", "48", ",", "57", "and", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "studies", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "have shown", "start": 8, "end": 18, "i_start": 1, "i_end": 2}}, {"subject": {"text": "data representations obtained from stacking up nonlinear feature extractors", "start": 24, "end": 99, "i_start": 4, "i_end": 12}, "verb": {"text": "yield", "start": 106, "end": 111, "i_start": 14, "i_end": 14}}, {"character": {"text": "studies", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "shown", "start": 13, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "representations", "start": 29, "end": 44, "i_start": 5, "i_end": 5}, "action": {"text": "yield", "start": 106, "end": 111, "i_start": 14, "i_end": 14}}], "id": 538}, {"sent": "this phase space is a two-dimensional continuum , which is best represented by points on the unit square .", "tokens": ["this", "phase", "space", "is", "a", "two", "-", "dimensional", "continuum", ",", "which", "is", "best", "represented", "by", "points", "on", "the", "unit", "square", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this phase space", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "points", "start": 79, "end": 85, "i_start": 15, "i_end": 15}, "action": {"text": "represented", "start": 64, "end": 75, "i_start": 13, "i_end": 13}}], "id": 539}, {"sent": "with the explosive growth of multimedia data including images and videos , hashing has received a great deal of attentions in large-scale visual retrieval for its capability in storage and computation efficiency .", "tokens": ["with", "the", "explosive", "growth", "of", "multimedia", "data", "including", "images", "and", "videos", ",", "hashing", "has", "received", "a", "great", "deal", "of", "attentions", "in", "large", "-", "scale", "visual", "retrieval", "for", "its", "capability", "in", "storage", "and", "computation", "efficiency", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "hashing", "start": 75, "end": 82, "i_start": 12, "i_end": 12}, "verb": {"text": "has received", "start": 83, "end": 95, "i_start": 13, "i_end": 14}}, {"character": {"text": "hashing", "start": 75, "end": 82, "i_start": 12, "i_end": 12}, "action": {"text": "received", "start": 87, "end": 95, "i_start": 14, "i_end": 14}}], "id": 540}, {"sent": "the continuum data were edited and calibrated using miriad .", "tokens": ["the", "continuum", "data", "were", "edited", "and", "calibrated", "using", "miriad", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the continuum data", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "were edited", "start": 19, "end": 30, "i_start": 3, "i_end": 4}}, {"subject": {"text": "the continuum data", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "calibrated", "start": 35, "end": 45, "i_start": 6, "i_end": 6}}], "id": 541}, {"sent": "this modification is the standard part of the cmb anisotropy and polarization spectrum calculations using cmbfast codes .", "tokens": ["this", "modification", "is", "the", "standard", "part", "of", "the", "cmb", "anisotropy", "and", "polarization", "spectrum", "calculations", "using", "cmbfast", "codes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this modification", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}], "id": 542}, {"sent": "here we compare certain integrals in the non-commutative hilbert modular symbol to multiple dedkeind zeta values .", "tokens": ["here", "we", "compare", "certain", "integrals", "in", "the", "non", "-", "commutative", "hilbert", "modular", "symbol", "to", "multiple", "dedkeind", "zeta", "values", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "compare", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "compare", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}], "id": 543}, {"sent": "recent progress in deep convolutional neural networks has led to substantial performance improvements in a broad range of computer vision tasks .", "tokens": ["recent", "progress", "in", "deep", "convolutional", "neural", "networks", "has", "led", "to", "substantial", "performance", "improvements", "in", "a", "broad", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent progress in deep convolutional neural networks", "start": 0, "end": 53, "i_start": 0, "i_end": 6}, "verb": {"text": "has led", "start": 54, "end": 61, "i_start": 7, "i_end": 8}}, {"character": {"text": "progress", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 58, "end": 61, "i_start": 8, "i_end": 8}}], "id": 544}, {"sent": "compressed sensing is a data acquisition strategy that exploits the sparsity or compressibility of a signal .", "tokens": ["compressed", "sensing", "is", "a", "data", "acquisition", "strategy", "that", "exploits", "the", "sparsity", "or", "compressibility", "of", "a", "signal", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "compressed sensing", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "strategy", "start": 41, "end": 49, "i_start": 6, "i_end": 6}, "action": {"text": "exploits", "start": 55, "end": 63, "i_start": 8, "i_end": 8}}], "id": 545}, {"sent": "another example is the shor algorithm , which is purely quantum-mechanical but is solving the classical factoring problem .", "tokens": ["another", "example", "is", "the", "shor", "algorithm", ",", "which", "is", "purely", "quantum", "-", "mechanical", "but", "is", "solving", "the", "classical", "factoring", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another example", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "algorithm", "start": 28, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "solving", "start": 82, "end": 89, "i_start": 15, "i_end": 15}}], "id": 546}, {"sent": "following , we treat this problem as a multi-label classification task .", "tokens": ["following", ",", "we", "treat", "this", "problem", "as", "a", "multi", "-", "label", "classification", "task", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "treat", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "treat", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}], "id": 547}, {"sent": "deep neural networks are able to achieve stateof-the-art performance in many cognitive applications , including computer vision .", "tokens": ["deep", "neural", "networks", "are", "able", "to", "achieve", "stateof", "-", "the", "-", "art", "performance", "in", "many", "cognitive", "applications", ",", "including", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 33, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 57, "end": 68, "i_start": 12, "i_end": 12}}], "id": 548}, {"sent": "the symmetric radon-nikodym property for tensor norms .", "tokens": ["the", "symmetric", "radon", "-", "nikodym", "property", "for", "tensor", "norms", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 549}, {"sent": "in recent years , remarkable progress has been made in object detection .", "tokens": ["in", "recent", "years", ",", "remarkable", "progress", "has", "been", "made", "in", "object", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "remarkable progress", "start": 18, "end": 37, "i_start": 4, "i_end": 5}, "verb": {"text": "has been made", "start": 38, "end": 51, "i_start": 6, "i_end": 8}}], "id": 550}, {"sent": "recently , deep convolutional neural networks have achieved great successes in computer vision topics such as image classification .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "achieved", "great", "successes", "in", "computer", "vision", "topics", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "successes", "start": 66, "end": 75, "i_start": 9, "i_end": 9}}], "id": 551}, {"sent": "our framework and other baseline methods are implemented based on the pytorch toolbox .", "tokens": ["our", "framework", "and", "other", "baseline", "methods", "are", "implemented", "based", "on", "the", "pytorch", "toolbox", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our framework and other baseline methods", "start": 0, "end": 40, "i_start": 0, "i_end": 5}, "verb": {"text": "are implemented", "start": 41, "end": 56, "i_start": 6, "i_end": 7}}], "id": 552}, {"sent": "the weights were initialized using the uniform initialization , .", "tokens": ["the", "weights", "were", "initialized", "using", "the", "uniform", "initialization", ",", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the weights", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "were initialized", "start": 12, "end": 28, "i_start": 2, "i_end": 3}}], "id": 553}, {"sent": "nsamp is the number of samples , nequil is the number of sweeps for equilibration and nmeas is the number of sweeps for measurements for each of the 2nt replicas for a single sample .", "tokens": ["nsamp", "is", "the", "number", "of", "samples", ",", "nequil", "is", "the", "number", "of", "sweeps", "for", "equilibration", "and", "nmeas", "is", "the", "number", "of", "sweeps", "for", "measurements", "for", "each", "of", "the", "2nt", "replicas", "for", "a", "single", "sample", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "nequil", "start": 33, "end": 39, "i_start": 7, "i_end": 7}, "verb": {"text": "is", "start": 40, "end": 42, "i_start": 8, "i_end": 8}}, {"subject": {"text": "nequil", "start": 33, "end": 39, "i_start": 7, "i_end": 7}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}], "id": 554}, {"sent": "a rectangle is a product of intervals in the standard basis .", "tokens": ["a", "rectangle", "is", "a", "product", "of", "intervals", "in", "the", "standard", "basis", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a rectangle", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "intervals", "start": 28, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "product", "start": 17, "end": 24, "i_start": 4, "i_end": 4}}], "id": 555}, {"sent": "in particular , convolutional neural networks has been popular in vision and audio recognition areas .", "tokens": ["in", "particular", ",", "convolutional", "neural", "networks", "has", "been", "popular", "in", "vision", "and", "audio", "recognition", "areas", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "has been", "start": 46, "end": 54, "i_start": 6, "i_end": 7}}], "id": 556}, {"sent": "algorithms proposed in levine et al only focus on the detection of grasps in scenes where objects are densely cluttered , rather than what the grasped objects are .", "tokens": ["algorithms", "proposed", "in", "levine", "et", "al", "only", "focus", "on", "the", "detection", "of", "grasps", "in", "scenes", "where", "objects", "are", "densely", "cluttered", ",", "rather", "than", "what", "the", "grasped", "objects", "are", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "algorithms proposed in levine et al", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "focus", "start": 41, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "algorithms", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "focus", "start": 41, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "levine", "start": 23, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "proposed", "start": 11, "end": 19, "i_start": 1, "i_end": 1}}], "id": 557}, {"sent": "deep neural networks have shown tremendous success in several computer vision tasks in recent years .", "tokens": ["deep", "neural", "networks", "have", "shown", "tremendous", "success", "in", "several", "computer", "vision", "tasks", "in", "recent", "years", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}], "id": 558}, {"sent": "for applications of variance reduction techniques to kinetic equation let us remind to the works of homolle and hadjiconstantinou .", "tokens": ["for", "applications", "of", "variance", "reduction", "techniques", "to", "kinetic", "equation", "let", "us", "remind", "to", "the", "works", "of", "homolle", "and", "hadjiconstantinou", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "us", "start": 74, "end": 76, "i_start": 10, "i_end": 10}, "verb": {"text": "let", "start": 70, "end": 73, "i_start": 9, "i_end": 9}}, {"subject": {"text": "us", "start": 74, "end": 76, "i_start": 10, "i_end": 10}, "verb": {"text": "remind", "start": 77, "end": 83, "i_start": 11, "i_end": 11}}, {"character": {"text": "us", "start": 74, "end": 76, "i_start": 10, "i_end": 10}, "action": {"text": "remind", "start": 77, "end": 83, "i_start": 11, "i_end": 11}}, {"character": {"text": "homolle", "start": 100, "end": 107, "i_start": 16, "i_end": 16}, "action": {"text": "works", "start": 91, "end": 96, "i_start": 14, "i_end": 14}}, {"character": {"text": "hadjiconstantinou", "start": 112, "end": 129, "i_start": 18, "i_end": 18}, "action": {"text": "works", "start": 91, "end": 96, "i_start": 14, "i_end": 14}}], "id": 559}, {"sent": "recently , deep neural networks has achieved great success on computer vision .", "tokens": ["recently", ",", "deep", "neural", "networks", "has", "achieved", "great", "success", "on", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "has achieved", "start": 32, "end": 44, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 36, "end": 44, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "success", "start": 51, "end": 58, "i_start": 8, "i_end": 8}}], "id": 560}, {"sent": "deep learning or deep neural networks have achieved extraordinary performance in many application domains such as image classification .", "tokens": ["deep", "learning", "or", "deep", "neural", "networks", "have", "achieved", "extraordinary", "performance", "in", "many", "application", "domains", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning or deep neural networks", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "have achieved", "start": 38, "end": 51, "i_start": 6, "i_end": 7}}, {"character": {"text": "or", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}], "id": 561}, {"sent": "convolutional neural networks have achieved state-of-the-art performance on visual tasks such as image and video recognition in the last few years .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "visual", "tasks", "such", "as", "image", "and", "video", "recognition", "in", "the", "last", "few", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 61, "end": 72, "i_start": 12, "i_end": 12}}], "id": 562}, {"sent": "we therefore need to consider convolutions of the splitting functions which appear in the perturbative expansion of \u03b3a , \u03b3b .", "tokens": ["we", "therefore", "need", "to", "consider", "convolutions", "of", "the", "splitting", "functions", "which", "appear", "in", "the", "perturbative", "expansion", "of", "\u03b3a", ",", "\u03b3b", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "need", "start": 13, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "need", "start": 13, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "consider", "start": 21, "end": 29, "i_start": 4, "i_end": 4}}], "id": 563}, {"sent": "consequently , this means that the difference discrete multisymplectic structure preserving law holds in the function space with the closed discrete euler-lagrange condition in general rather than in the solution space only .", "tokens": ["consequently", ",", "this", "means", "that", "the", "difference", "discrete", "multisymplectic", "structure", "preserving", "law", "holds", "in", "the", "function", "space", "with", "the", "closed", "discrete", "euler", "-", "lagrange", "condition", "in", "general", "rather", "than", "in", "the", "solution", "space", "only", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 15, "end": 19, "i_start": 2, "i_end": 2}, "verb": {"text": "means", "start": 20, "end": 25, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the difference discrete multisymplectic structure preserving law", "start": 31, "end": 95, "i_start": 5, "i_end": 11}, "verb": {"text": "holds", "start": 96, "end": 101, "i_start": 12, "i_end": 12}}, {"character": {"text": "law", "start": 92, "end": 95, "i_start": 11, "i_end": 11}, "action": {"text": "holds", "start": 96, "end": 101, "i_start": 12, "i_end": 12}}, {"character": {"text": "law", "start": 92, "end": 95, "i_start": 11, "i_end": 11}, "action": {"text": "preserving", "start": 81, "end": 91, "i_start": 10, "i_end": 10}}], "id": 564}, {"sent": "matsuda et al designed ionic liquids based on conductivity and viscosity targets .", "tokens": ["matsuda", "et", "al", "designed", "ionic", "liquids", "based", "on", "conductivity", "and", "viscosity", "targets", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "matsuda et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "designed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "matsuda", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "designed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}], "id": 565}, {"sent": "the data were reduced using the herschel interactive processing environment .", "tokens": ["the", "data", "were", "reduced", "using", "the", "herschel", "interactive", "processing", "environment", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "were reduced", "start": 9, "end": 21, "i_start": 2, "i_end": 3}}], "id": 566}, {"sent": "in deep learning for computer vision , object classification and other tasks have improved performance for image understanding .", "tokens": ["in", "deep", "learning", "for", "computer", "vision", ",", "object", "classification", "and", "other", "tasks", "have", "improved", "performance", "for", "image", "understanding", "."], "score": [1, 0, 0, 0, 1], "labels": [{"subject": {"text": "in deep learning for computer vision", "start": 0, "end": 36, "i_start": 0, "i_end": 5}, "verb": {"text": "have improved", "start": 77, "end": 90, "i_start": 12, "i_end": 13}}, {"character": {"text": "classification", "start": 46, "end": 60, "i_start": 8, "i_end": 8}, "action": {"text": "improved", "start": 82, "end": 90, "i_start": 13, "i_end": 13}}, {"character": {"text": "tasks", "start": 71, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "improved", "start": 82, "end": 90, "i_start": 13, "i_end": 13}}, {"character": {"text": "other", "start": 65, "end": 70, "i_start": 10, "i_end": 10}, "action": {"text": "improved", "start": 82, "end": 90, "i_start": 13, "i_end": 13}}], "id": 567}, {"sent": "zhu and ranaman proposed the tspm approach for simultaneous face detection , pose estimation and face alignment .", "tokens": ["zhu", "and", "ranaman", "proposed", "the", "tspm", "approach", "for", "simultaneous", "face", "detection", ",", "pose", "estimation", "and", "face", "alignment", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhu and ranaman", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}, {"subject": {"text": "zhu and ranaman", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "pose", "start": 77, "end": 81, "i_start": 12, "i_end": 12}}, {"character": {"text": "zhu", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "ranaman", "start": 8, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "proposed", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}], "id": 568}, {"sent": "deep convolutional neural networks have been applied successfully to a wide range of computer vision problems , including image recognition , etc .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "applied", "successfully", "to", "a", "wide", "range", "of", "computer", "vision", "problems", ",", "including", "image", "recognition", ",", "etc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been applied", "start": 35, "end": 52, "i_start": 4, "i_end": 6}}], "id": 569}, {"sent": "supervised deep learning has played a crucial role in recent developments in several computer vision tasks , eg , object recognition .", "tokens": ["supervised", "deep", "learning", "has", "played", "a", "crucial", "role", "in", "recent", "developments", "in", "several", "computer", "vision", "tasks", ",", "eg", ",", "object", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "supervised deep learning", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "has played", "start": 25, "end": 35, "i_start": 3, "i_end": 4}}, {"character": {"text": "learning", "start": 16, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "played", "start": 29, "end": 35, "i_start": 4, "i_end": 4}}], "id": 570}, {"sent": "recently , there has been an upsurge of interest in radio signal enabled simultaneous wireless information and power transfer .", "tokens": ["recently", ",", "there", "has", "been", "an", "upsurge", "of", "interest", "in", "radio", "signal", "enabled", "simultaneous", "wireless", "information", "and", "power", "transfer", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "has been", "start": 17, "end": 25, "i_start": 3, "i_end": 4}}, {"subject": {"text": "there", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "enabled", "start": 65, "end": 72, "i_start": 12, "i_end": 12}}, {"character": {"text": "signal", "start": 58, "end": 64, "i_start": 11, "i_end": 11}, "action": {"text": "enabled", "start": 65, "end": 72, "i_start": 12, "i_end": 12}}], "id": 571}, {"sent": "we follow the notations of the quantized universal enveloping algebra and the crystal base in .", "tokens": ["we", "follow", "the", "notations", "of", "the", "quantized", "universal", "enveloping", "algebra", "and", "the", "crystal", "base", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 572}, {"sent": "this step is called the residual renormalization .", "tokens": ["this", "step", "is", "called", "the", "residual", "renormalization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this step", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is called", "start": 10, "end": 19, "i_start": 2, "i_end": 3}}], "id": 573}, {"sent": "arora et al interpret over-parametrization as a means of implicit acceleration during optimization .", "tokens": ["arora", "et", "al", "interpret", "over", "-", "parametrization", "as", "a", "means", "of", "implicit", "acceleration", "during", "optimization", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 6, "end": 11, "i_start": 1, "i_end": 2}, "verb": {"text": "interpret", "start": 12, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "arora", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "interpret", "start": 12, "end": 21, "i_start": 3, "i_end": 3}}], "id": 574}, {"sent": "kurakin et al showed that printed adversarial examples can be misclassified when viewed through a smartphone camera .", "tokens": ["kurakin", "et", "al", "showed", "that", "printed", "adversarial", "examples", "can", "be", "misclassified", "when", "viewed", "through", "a", "smartphone", "camera", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "kurakin et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 14, "end": 20, "i_start": 3, "i_end": 3}}, {"subject": {"text": "printed adversarial examples", "start": 26, "end": 54, "i_start": 5, "i_end": 7}, "verb": {"text": "misclassified", "start": 62, "end": 75, "i_start": 10, "i_end": 10}}, {"character": {"text": "kurakin", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 14, "end": 20, "i_start": 3, "i_end": 3}}], "id": 575}, {"sent": "wanda employs two antennas to authenticate the devices in proximity according to the large rss variation between the two antennas .", "tokens": ["wanda", "employs", "two", "antennas", "to", "authenticate", "the", "devices", "in", "proximity", "according", "to", "the", "large", "rss", "variation", "between", "the", "two", "antennas", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "wanda", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "employs", "start": 6, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "two antennas", "start": 14, "end": 26, "i_start": 2, "i_end": 3}, "action": {"text": "authenticate", "start": 30, "end": 42, "i_start": 5, "i_end": 5}}], "id": 576}, {"sent": "ba et al extended the glimpse network for multiple object recognition with visual attention .", "tokens": ["ba", "et", "al", "extended", "the", "glimpse", "network", "for", "multiple", "object", "recognition", "with", "visual", "attention", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "ba et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "extended", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "ba", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extended", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}], "id": 577}, {"sent": "deep convolutional neural networks have achieved significant success in a wide range of studies .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "significant", "success", "in", "a", "wide", "range", "of", "studies", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}], "id": 578}, {"sent": "laudal , formal moduli of algebraic structures , lecture notes in mathematics , vol .", "tokens": ["laudal", ",", "formal", "moduli", "of", "algebraic", "structures", ",", "lecture", "notes", "in", "mathematics", ",", "vol", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 579}, {"sent": "in particular , we will show explicitly that the stable fixed point of the generic model can be identified with the stable fixed point of the lgw theory .", "tokens": ["in", "particular", ",", "we", "will", "show", "explicitly", "that", "the", "stable", "fixed", "point", "of", "the", "generic", "model", "can", "be", "identified", "with", "the", "stable", "fixed", "point", "of", "the", "lgw", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "will show", "start": 19, "end": 28, "i_start": 4, "i_end": 5}}, {"subject": {"text": "the stable fixed point of the generic model", "start": 45, "end": 88, "i_start": 8, "i_end": 15}, "verb": {"text": "identified", "start": 96, "end": 106, "i_start": 18, "i_end": 18}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "show", "start": 24, "end": 28, "i_start": 5, "i_end": 5}}], "id": 580}, {"sent": "rosenthal , brane world scenarios and the cosmological constant , nucl .", "tokens": ["rosenthal", ",", "brane", "world", "scenarios", "and", "the", "cosmological", "constant", ",", "nucl", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 581}, {"sent": "therefore he resisted all these attempts , though in 1950 he wrote a paper with ginzburg on superconductivity in which the notion of spontaneous symmetry breaking was brought into condensed matter physics and a phenomenon , which was later discovered in field theory and is called now higgs mechanism , was suggested .", "tokens": ["therefore", "he", "resisted", "all", "these", "attempts", ",", "though", "in", "1950", "he", "wrote", "a", "paper", "with", "ginzburg", "on", "superconductivity", "in", "which", "the", "notion", "of", "spontaneous", "symmetry", "breaking", "was", "brought", "into", "condensed", "matter", "physics", "and", "a", "phenomenon", ",", "which", "was", "later", "discovered", "in", "field", "theory", "and", "is", "called", "now", "higgs", "mechanism", ",", "was", "suggested", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "he", "start": 10, "end": 12, "i_start": 1, "i_end": 1}, "verb": {"text": "was suggested", "start": 303, "end": 316, "i_start": 50, "i_end": 51}}, {"subject": {"text": "he", "start": 10, "end": 12, "i_start": 1, "i_end": 1}, "verb": {"text": "resisted", "start": 13, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "he", "start": 10, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "resisted", "start": 13, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "he", "start": 10, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "wrote", "start": 61, "end": 66, "i_start": 11, "i_end": 11}}], "id": 582}, {"sent": "we use the well-known kitti vision benchmark suite to evaluate our system .", "tokens": ["we", "use", "the", "well", "-", "known", "kitti", "vision", "benchmark", "suite", "to", "evaluate", "our", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 54, "end": 62, "i_start": 11, "i_end": 11}}], "id": 583}, {"sent": "large-scale language models have been shown to dramatically improve the performance of natural language understanding systems on a broad range of tasks .", "tokens": ["large", "-", "scale", "language", "models", "have", "been", "shown", "to", "dramatically", "improve", "the", "performance", "of", "natural", "language", "understanding", "systems", "on", "a", "broad", "range", "of", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "large-scale language models", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "have been shown", "start": 28, "end": 43, "i_start": 5, "i_end": 7}}, {"character": {"text": "models", "start": 21, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "improve", "start": 60, "end": 67, "i_start": 10, "i_end": 10}}, {"character": {"text": "systems", "start": 118, "end": 125, "i_start": 17, "i_end": 17}, "action": {"text": "performance", "start": 72, "end": 83, "i_start": 12, "i_end": 12}}, {"character": {"text": "systems", "start": 118, "end": 125, "i_start": 17, "i_end": 17}, "action": {"text": "understanding", "start": 104, "end": 117, "i_start": 16, "i_end": 16}}], "id": 584}, {"sent": "asterisks denote experimental realizations .", "tokens": ["asterisks", "denote", "experimental", "realizations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "asterisks", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "denote", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "asterisks", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}], "id": 585}, {"sent": "we can use the augmented lagrange multiplier to solve this optimization problem efficiently .", "tokens": ["we", "can", "use", "the", "augmented", "lagrange", "multiplier", "to", "solve", "this", "optimization", "problem", "efficiently", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "can use", "start": 3, "end": 10, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 7, "end": 10, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "solve", "start": 48, "end": 53, "i_start": 8, "i_end": 8}}], "id": 586}, {"sent": "deep model-free reinforcement learning has had great successes in recent years , notably in playing video games .", "tokens": ["deep", "model", "-", "free", "reinforcement", "learning", "has", "had", "great", "successes", "in", "recent", "years", ",", "notably", "in", "playing", "video", "games", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep model-free reinforcement learning", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "has had", "start": 39, "end": 46, "i_start": 6, "i_end": 7}}, {"character": {"text": "learning", "start": 30, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "successes", "start": 53, "end": 62, "i_start": 9, "i_end": 9}}], "id": 587}, {"sent": "these algorithms were implemented by using the scikit-learn toolbox in python .", "tokens": ["these", "algorithms", "were", "implemented", "by", "using", "the", "scikit", "-", "learn", "toolbox", "in", "python", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these algorithms", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were implemented", "start": 17, "end": 33, "i_start": 2, "i_end": 3}}], "id": 588}, {"sent": "for example , bryant et al found that while novice editors contribute only to articles related to their expertise , expert editors contribute to improve the overall quality of wikipedia articles .", "tokens": ["for", "example", ",", "bryant", "et", "al", "found", "that", "while", "novice", "editors", "contribute", "only", "to", "articles", "related", "to", "their", "expertise", ",", "expert", "editors", "contribute", "to", "improve", "the", "overall", "quality", "of", "wikipedia", "articles", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bryant et al", "start": 14, "end": 26, "i_start": 3, "i_end": 5}, "verb": {"text": "found", "start": 27, "end": 32, "i_start": 6, "i_end": 6}}, {"subject": {"text": "expert editors", "start": 116, "end": 130, "i_start": 20, "i_end": 21}, "verb": {"text": "contribute", "start": 131, "end": 141, "i_start": 22, "i_end": 22}}, {"character": {"text": "bryant", "start": 14, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "found", "start": 27, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "novice", "start": 44, "end": 50, "i_start": 9, "i_end": 9}, "action": {"text": "contribute", "start": 131, "end": 141, "i_start": 22, "i_end": 22}}, {"character": {"text": "novice", "start": 44, "end": 50, "i_start": 9, "i_end": 9}, "action": {"text": "improve", "start": 145, "end": 152, "i_start": 24, "i_end": 24}}], "id": 589}, {"sent": "we refer to for the definitions and basic properties of functions with bounded variation .", "tokens": ["we", "refer", "to", "for", "the", "definitions", "and", "basic", "properties", "of", "functions", "with", "bounded", "variation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 590}, {"sent": "here , the ratio of cross sections is positive .", "tokens": ["here", ",", "the", "ratio", "of", "cross", "sections", "is", "positive", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ratio of cross sections", "start": 7, "end": 34, "i_start": 2, "i_end": 6}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 7, "i_end": 7}}, {"character": {"text": "sections", "start": 26, "end": 34, "i_start": 6, "i_end": 6}, "action": {"text": "cross", "start": 20, "end": 25, "i_start": 5, "i_end": 5}}], "id": 591}, {"sent": "this measurement period is also a lower yet unrealized bound for on-chip ht detection using ros .", "tokens": ["this", "measurement", "period", "is", "also", "a", "lower", "yet", "unrealized", "bound", "for", "on", "-", "chip", "ht", "detection", "using", "ros", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this measurement period", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}], "id": 592}, {"sent": "recently , end-to-end neural approaches have attracted increasing interest .", "tokens": ["recently", ",", "end", "-", "to", "-", "end", "neural", "approaches", "have", "attracted", "increasing", "interest", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "end-to-end neural approaches", "start": 11, "end": 39, "i_start": 2, "i_end": 8}, "verb": {"text": "have attracted", "start": 40, "end": 54, "i_start": 9, "i_end": 10}}, {"character": {"text": "approaches", "start": 29, "end": 39, "i_start": 8, "i_end": 8}, "action": {"text": "attracted", "start": 45, "end": 54, "i_start": 10, "i_end": 10}}], "id": 593}, {"sent": "deep neural networks have achieved tremendous success in recent years , due to the ability of these models to achieve state-of-the-art performances .", "tokens": ["deep", "neural", "networks", "have", "achieved", "tremendous", "success", "in", "recent", "years", ",", "due", "to", "the", "ability", "of", "these", "models", "to", "achieve", "state", "-", "of", "-", "the", "-", "art", "performances", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "models", "start": 100, "end": 106, "i_start": 17, "i_end": 17}, "action": {"text": "achieve", "start": 110, "end": 117, "i_start": 19, "i_end": 19}}], "id": 594}, {"sent": "the hash sort will falter , but will not degenerate as badly as the bubble sort and quick sort do in the extreme cases .", "tokens": ["the", "hash", "sort", "will", "falter", ",", "but", "will", "not", "degenerate", "as", "badly", "as", "the", "bubble", "sort", "and", "quick", "sort", "do", "in", "the", "extreme", "cases", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the hash sort", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "will falter", "start": 14, "end": 25, "i_start": 3, "i_end": 4}}, {"subject": {"text": "the hash sort", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "degenerate", "start": 41, "end": 51, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the hash sort", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "do", "start": 95, "end": 97, "i_start": 19, "i_end": 19}}], "id": 595}, {"sent": "one can collect all konishi transformations or virasoro constraints in the dijkgraaf-vafa approach .", "tokens": ["one", "can", "collect", "all", "konishi", "transformations", "or", "virasoro", "constraints", "in", "the", "dijkgraaf", "-", "vafa", "approach", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "can collect", "start": 4, "end": 15, "i_start": 1, "i_end": 2}}, {"character": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "collect", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "approach", "start": 90, "end": 98, "i_start": 14, "i_end": 14}, "action": {"text": "constraints", "start": 56, "end": 67, "i_start": 8, "i_end": 8}}], "id": 596}, {"sent": "the transversity is a crucial property of the nucleon , carrying information on its spin structure complementary to what we can deduce from helicity distributions .", "tokens": ["the", "transversity", "is", "a", "crucial", "property", "of", "the", "nucleon", ",", "carrying", "information", "on", "its", "spin", "structure", "complementary", "to", "what", "we", "can", "deduce", "from", "helicity", "distributions", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the transversity", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "transversity", "start": 4, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "carrying", "start": 56, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 121, "end": 123, "i_start": 19, "i_end": 19}, "action": {"text": "deduce", "start": 128, "end": 134, "i_start": 21, "i_end": 21}}], "id": 597}, {"sent": "if the orbit o is the williamson type of x .", "tokens": ["if", "the", "orbit", "o", "is", "the", "williamson", "type", "of", "x", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the orbit o", "start": 3, "end": 14, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 4, "i_end": 4}}], "id": 598}, {"sent": "the physics objects are the jets , clustered using the jet finding algorithm with the tracks assigned to the vertex as inputs , and the negative vector sum of the p t of those jets .", "tokens": ["the", "physics", "objects", "are", "the", "jets", ",", "clustered", "using", "the", "jet", "finding", "algorithm", "with", "the", "tracks", "assigned", "to", "the", "vertex", "as", "inputs", ",", "and", "the", "negative", "vector", "sum", "of", "the", "p", "t", "of", "those", "jets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the physics objects", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 20, "end": 23, "i_start": 3, "i_end": 3}}], "id": 599}, {"sent": "one well-studied direction is to impose a sufficiently small-norm condition on the neural network weights .", "tokens": ["one", "well", "-", "studied", "direction", "is", "to", "impose", "a", "sufficiently", "small", "-", "norm", "condition", "on", "the", "neural", "network", "weights", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one well-studied direction", "start": 0, "end": 26, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 5, "i_end": 5}}], "id": 600}, {"sent": "for all comparisons , we use dynamic time warping to match the predicted to the reference sequence length .", "tokens": ["for", "all", "comparisons", ",", "we", "use", "dynamic", "time", "warping", "to", "match", "the", "predicted", "to", "the", "reference", "sequence", "length", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 22, "end": 24, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 25, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 25, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "match", "start": 53, "end": 58, "i_start": 10, "i_end": 10}}], "id": 601}, {"sent": "this problem can be solved using principles from probabilistic model checking .", "tokens": ["this", "problem", "can", "be", "solved", "using", "principles", "from", "probabilistic", "model", "checking", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this problem", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "can be solved", "start": 13, "end": 26, "i_start": 2, "i_end": 4}}], "id": 602}, {"sent": "a striking example is the incredibly successful observation of grb080319b that was performed within the framework of the russian-italian experiment tortora .", "tokens": ["a", "striking", "example", "is", "the", "incredibly", "successful", "observation", "of", "grb080319b", "that", "was", "performed", "within", "the", "framework", "of", "the", "russian", "-", "italian", "experiment", "tortora", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a striking example", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "example", "start": 11, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "striking", "start": 2, "end": 10, "i_start": 1, "i_end": 1}}], "id": 603}, {"sent": "a basin is the set of points in phase space representing configurations having the same local minimum .", "tokens": ["a", "basin", "is", "the", "set", "of", "points", "in", "phase", "space", "representing", "configurations", "having", "the", "same", "local", "minimum", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a basin", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 2, "i_end": 2}}, {"character": {"text": "set", "start": 15, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "representing", "start": 44, "end": 56, "i_start": 10, "i_end": 10}}, {"character": {"text": "configurations", "start": 57, "end": 71, "i_start": 11, "i_end": 11}, "action": {"text": "having", "start": 72, "end": 78, "i_start": 12, "i_end": 12}}], "id": 604}, {"sent": "in proceedings of the fifth international conference on principles of know ledge representation and reasoning , pp .", "tokens": ["in", "proceedings", "of", "the", "fifth", "international", "conference", "on", "principles", "of", "know", "ledge", "representation", "and", "reasoning", ",", "pp", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 605}, {"sent": "the paper by hille and perling contains a first systematic study of full exceptional collections of line bundles on surfaces .", "tokens": ["the", "paper", "by", "hille", "and", "perling", "contains", "a", "first", "systematic", "study", "of", "full", "exceptional", "collections", "of", "line", "bundles", "on", "surfaces", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the paper by hille and perling", "start": 0, "end": 30, "i_start": 0, "i_end": 5}, "verb": {"text": "contains", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "paper", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "contains", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}], "id": 606}, {"sent": "convolutional neural networks have achieved great success on visual recognition tasks .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "great", "success", "on", "visual", "recognition", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}], "id": 607}, {"sent": "each polytope is the convex hull of three regular triangles lying in three pairwise orthogonal affine planes .", "tokens": ["each", "polytope", "is", "the", "convex", "hull", "of", "three", "regular", "triangles", "lying", "in", "three", "pairwise", "orthogonal", "affine", "planes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each polytope", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 608}, {"sent": "we use the resnet-50 model to extract features throughout all the experiments .", "tokens": ["we", "use", "the", "resnet-50", "model", "to", "extract", "features", "throughout", "all", "the", "experiments", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extract", "start": 30, "end": 37, "i_start": 6, "i_end": 6}}], "id": 609}, {"sent": "fang et al proposed a fr lfi quality assessment method that measures the gradient magnitude similarity of reference and distorted epipolar plane images .", "tokens": ["fang", "et", "al", "proposed", "a", "fr", "lfi", "quality", "assessment", "method", "that", "measures", "the", "gradient", "magnitude", "similarity", "of", "reference", "and", "distorted", "epipolar", "plane", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "fang et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "fang", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "method", "start": 48, "end": 54, "i_start": 9, "i_end": 9}, "action": {"text": "measures", "start": 60, "end": 68, "i_start": 11, "i_end": 11}}], "id": 610}, {"sent": "mountain , conserved charges and supersymmetry in principal chiral and wzw models , nucl .", "tokens": ["mountain", ",", "conserved", "charges", "and", "supersymmetry", "in", "principal", "chiral", "and", "wzw", "models", ",", "nucl", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 611}, {"sent": "the third approach generated fuzzy if-then rules by homogeneously partitioning each attribute .", "tokens": ["the", "third", "approach", "generated", "fuzzy", "if", "-", "then", "rules", "by", "homogeneously", "partitioning", "each", "attribute", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the third approach", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "generated", "start": 19, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "approach", "start": 10, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "generated", "start": 19, "end": 28, "i_start": 3, "i_end": 3}}], "id": 612}, {"sent": "data reduction was performed in a standard manner using mopex software .", "tokens": ["data", "reduction", "was", "performed", "in", "a", "standard", "manner", "using", "mopex", "software", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "data reduction", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "was performed", "start": 15, "end": 28, "i_start": 2, "i_end": 3}}], "id": 613}, {"sent": "additional details of this calculation are found in appendix a .", "tokens": ["additional", "details", "of", "this", "calculation", "are", "found", "in", "appendix", "a", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "additional details of this calculation", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "are found", "start": 39, "end": 48, "i_start": 5, "i_end": 6}}], "id": 614}, {"sent": "large amounts of training data and increased computing power have lead to recent successes of deep architectures on diverse computer vision tasks .", "tokens": ["large", "amounts", "of", "training", "data", "and", "increased", "computing", "power", "have", "lead", "to", "recent", "successes", "of", "deep", "architectures", "on", "diverse", "computer", "vision", "tasks", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "large amounts of training data and increased computing power", "start": 0, "end": 60, "i_start": 0, "i_end": 8}, "verb": {"text": "have lead", "start": 61, "end": 70, "i_start": 9, "i_end": 10}}, {"character": {"text": "data", "start": 26, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "lead", "start": 66, "end": 70, "i_start": 10, "i_end": 10}}, {"character": {"text": "training", "start": 17, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "lead", "start": 66, "end": 70, "i_start": 10, "i_end": 10}}, {"character": {"text": "amounts", "start": 6, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "lead", "start": 66, "end": 70, "i_start": 10, "i_end": 10}}, {"character": {"text": "large", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "lead", "start": 66, "end": 70, "i_start": 10, "i_end": 10}}, {"character": {"text": "power", "start": 55, "end": 60, "i_start": 8, "i_end": 8}, "action": {"text": "lead", "start": 66, "end": 70, "i_start": 10, "i_end": 10}}], "id": 615}, {"sent": "game theory is a mature field of applied mathematics .", "tokens": ["game", "theory", "is", "a", "mature", "field", "of", "applied", "mathematics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "game theory", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 616}, {"sent": "calibration and imaging were performed with the casa 1 software .", "tokens": ["calibration", "and", "imaging", "were", "performed", "with", "the", "casa", "1", "software", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "calibration and imaging", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "were performed", "start": 24, "end": 38, "i_start": 3, "i_end": 4}}], "id": 617}, {"sent": "the parameters before pool4 are initialized with the values from the 16-layer vgg model .", "tokens": ["the", "parameters", "before", "pool4", "are", "initialized", "with", "the", "values", "from", "the", "16", "-", "layer", "vgg", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the parameters", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are initialized", "start": 28, "end": 43, "i_start": 4, "i_end": 5}}], "id": 618}, {"sent": "the concept of capsules was first introduced by hinton et al as a method for learning robust unsupervised representation of images .", "tokens": ["the", "concept", "of", "capsules", "was", "first", "introduced", "by", "hinton", "et", "al", "as", "a", "method", "for", "learning", "robust", "unsupervised", "representation", "of", "images", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the concept of capsules", "start": 0, "end": 23, "i_start": 0, "i_end": 3}, "verb": {"text": "introduced", "start": 34, "end": 44, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the concept of capsules", "start": 0, "end": 23, "i_start": 0, "i_end": 3}, "verb": {"text": "was", "start": 24, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "hinton", "start": 48, "end": 54, "i_start": 8, "i_end": 8}, "action": {"text": "introduced", "start": 34, "end": 44, "i_start": 6, "i_end": 6}}], "id": 619}, {"sent": "composites of carbon black and silicone are widely used , see eg .", "tokens": ["composites", "of", "carbon", "black", "and", "silicone", "are", "widely", "used", ",", "see", "eg", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "composites of carbon black and silicone", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "used", "start": 51, "end": 55, "i_start": 8, "i_end": 8}}, {"subject": {"text": "composites of carbon black and silicone", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 40, "end": 43, "i_start": 6, "i_end": 6}}], "id": 620}, {"sent": "the features learned from deep convolutional networks have been used for many computer vision tasks such as image recognition , object detection , and image segmentation .", "tokens": ["the", "features", "learned", "from", "deep", "convolutional", "networks", "have", "been", "used", "for", "many", "computer", "vision", "tasks", "such", "as", "image", "recognition", ",", "object", "detection", ",", "and", "image", "segmentation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the features learned from deep convolutional networks", "start": 0, "end": 53, "i_start": 0, "i_end": 6}, "verb": {"text": "have been used", "start": 54, "end": 68, "i_start": 7, "i_end": 9}}], "id": 621}, {"sent": "to this aim , we use the volume of the negative part of the wigner function as a measure of the nonclassicality .", "tokens": ["to", "this", "aim", ",", "we", "use", "the", "volume", "of", "the", "negative", "part", "of", "the", "wigner", "function", "as", "a", "measure", "of", "the", "nonclassicality", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 17, "end": 20, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 17, "end": 20, "i_start": 5, "i_end": 5}}, {"character": {"text": "part", "start": 48, "end": 52, "i_start": 11, "i_end": 11}, "action": {"text": "negative", "start": 39, "end": 47, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "measure", "start": 81, "end": 88, "i_start": 18, "i_end": 18}}], "id": 622}, {"sent": "to overcome these problems , he et al proposed residual learning technique to ease the training of networks and enables them to be substantially deeper .", "tokens": ["to", "overcome", "these", "problems", ",", "he", "et", "al", "proposed", "residual", "learning", "technique", "to", "ease", "the", "training", "of", "networks", "and", "enables", "them", "to", "be", "substantially", "deeper", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "he et al", "start": 29, "end": 37, "i_start": 5, "i_end": 7}, "verb": {"text": "proposed", "start": 38, "end": 46, "i_start": 8, "i_end": 8}}, {"character": {"text": "he", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "proposed", "start": 38, "end": 46, "i_start": 8, "i_end": 8}}, {"character": {"text": "technique", "start": 65, "end": 74, "i_start": 11, "i_end": 11}, "action": {"text": "ease", "start": 78, "end": 82, "i_start": 13, "i_end": 13}}, {"character": {"text": "technique", "start": 65, "end": 74, "i_start": 11, "i_end": 11}, "action": {"text": "enables", "start": 112, "end": 119, "i_start": 19, "i_end": 19}}], "id": 623}, {"sent": "more recently , pan et al in apply an 0 norm as a sparse prior on both the intensity values and the image gradient for deblurring text .", "tokens": ["more", "recently", ",", "pan", "et", "al", "in", "apply", "an", "0", "norm", "as", "a", "sparse", "prior", "on", "both", "the", "intensity", "values", "and", "the", "image", "gradient", "for", "deblurring", "text", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "pan et al", "start": 16, "end": 25, "i_start": 3, "i_end": 5}, "verb": {"text": "apply", "start": 29, "end": 34, "i_start": 7, "i_end": 7}}, {"character": {"text": "pan", "start": 16, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "apply", "start": 29, "end": 34, "i_start": 7, "i_end": 7}}], "id": 624}, {"sent": "previous works on deep da learn domain invariant representations by exploiting different architectures , such as convolutional neural networks .", "tokens": ["previous", "works", "on", "deep", "da", "learn", "domain", "invariant", "representations", "by", "exploiting", "different", "architectures", ",", "such", "as", "convolutional", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "previous works on deep da", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "learn", "start": 26, "end": 31, "i_start": 5, "i_end": 5}}], "id": 625}, {"sent": "the study of the iterated brownian motion has been motivated by the analysis of diffusions in cracks .", "tokens": ["the", "study", "of", "the", "iterated", "brownian", "motion", "has", "been", "motivated", "by", "the", "analysis", "of", "diffusions", "in", "cracks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the study of the iterated brownian motion", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "has been motivated", "start": 42, "end": 60, "i_start": 7, "i_end": 9}}, {"character": {"text": "analysis", "start": 68, "end": 76, "i_start": 12, "i_end": 12}, "action": {"text": "motivated", "start": 51, "end": 60, "i_start": 9, "i_end": 9}}], "id": 626}, {"sent": "honeywell has faced this problem and used the pvs theorem prover to analyze the deos scheduler .", "tokens": ["honeywell", "has", "faced", "this", "problem", "and", "used", "the", "pvs", "theorem", "prover", "to", "analyze", "the", "deos", "scheduler", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "honeywell", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "has faced", "start": 10, "end": 19, "i_start": 1, "i_end": 2}}, {"subject": {"text": "honeywell", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 37, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "honeywell", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "faced", "start": 14, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "honeywell", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 37, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "honeywell", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "analyze", "start": 68, "end": 75, "i_start": 12, "i_end": 12}}], "id": 627}, {"sent": "such approach was regularly adopted by the relevant literature , and we also follow the same .", "tokens": ["such", "approach", "was", "regularly", "adopted", "by", "the", "relevant", "literature", ",", "and", "we", "also", "follow", "the", "same", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 69, "end": 71, "i_start": 11, "i_end": 11}, "verb": {"text": "adopted", "start": 28, "end": 35, "i_start": 4, "i_end": 4}}, {"subject": {"text": "such approach", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "was", "start": 14, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "such approach", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "follow", "start": 77, "end": 83, "i_start": 13, "i_end": 13}}, {"character": {"text": "literature", "start": 52, "end": 62, "i_start": 8, "i_end": 8}, "action": {"text": "adopted", "start": 28, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 69, "end": 71, "i_start": 11, "i_end": 11}, "action": {"text": "follow", "start": 77, "end": 83, "i_start": 13, "i_end": 13}}], "id": 628}, {"sent": "a powerful tool which enables to compute this maximization in such a setting is the expectation maximization algorithm .", "tokens": ["a", "powerful", "tool", "which", "enables", "to", "compute", "this", "maximization", "in", "such", "a", "setting", "is", "the", "expectation", "maximization", "algorithm", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "a powerful tool which enables to compute this maximization in such a setting", "start": 0, "end": 76, "i_start": 0, "i_end": 12}, "verb": {"text": "is", "start": 77, "end": 79, "i_start": 13, "i_end": 13}}, {"character": {"text": "tool", "start": 11, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "enables", "start": 22, "end": 29, "i_start": 4, "i_end": 4}}], "id": 629}, {"sent": "it is anticipated that this form of perturbation can effectively eliminate the irregular electrical wave propagation ( spiral waves and turbulent states ) in the cardiac tissue and convert the heart to the normal state .", "tokens": ["it", "is", "anticipated", "that", "this", "form", "of", "perturbation", "can", "effectively", "eliminate", "the", "irregular", "electrical", "wave", "propagation", "(", "spiral", "waves", "and", "turbulent", "states", ")", "in", "the", "cardiac", "tissue", "and", "convert", "the", "heart", "to", "the", "normal", "state", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is anticipated", "start": 3, "end": 17, "i_start": 1, "i_end": 2}}, {"subject": {"text": "this form of perturbation", "start": 23, "end": 48, "i_start": 4, "i_end": 7}, "verb": {"text": "eliminate", "start": 65, "end": 74, "i_start": 10, "i_end": 10}}, {"character": {"text": "perturbation", "start": 36, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "eliminate", "start": 65, "end": 74, "i_start": 10, "i_end": 10}}, {"character": {"text": "perturbation", "start": 36, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "convert", "start": 181, "end": 188, "i_start": 28, "i_end": 28}}], "id": 630}, {"sent": "we use a neural sequence-to-sequence architecture with a hard attention mechanism .", "tokens": ["we", "use", "a", "neural", "sequence", "-", "to", "-", "sequence", "architecture", "with", "a", "hard", "attention", "mechanism", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 631}, {"sent": "we use the levenbergmarquardt algorithm to minimize a huber loss function instead of squared loss to improve robustness .", "tokens": ["we", "use", "the", "levenbergmarquardt", "algorithm", "to", "minimize", "a", "huber", "loss", "function", "instead", "of", "squared", "loss", "to", "improve", "robustness", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "minimize", "start": 43, "end": 51, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "improve", "start": 101, "end": 108, "i_start": 16, "i_end": 16}}], "id": 632}, {"sent": "a large flare occurred during the last third of the rgs observations .", "tokens": ["a", "large", "flare", "occurred", "during", "the", "last", "third", "of", "the", "rgs", "observations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a large flare", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "occurred", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}], "id": 633}, {"sent": "the stability condition can be derived by applying the routh-hurwitz criterion , whose general form is too cumbersome to give here .", "tokens": ["the", "stability", "condition", "can", "be", "derived", "by", "applying", "the", "routh", "-", "hurwitz", "criterion", ",", "whose", "general", "form", "is", "too", "cumbersome", "to", "give", "here", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the stability condition", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "can be derived", "start": 24, "end": 38, "i_start": 3, "i_end": 5}}], "id": 634}, {"sent": "note that as in plain markov models we assume all probabilities are stationary .", "tokens": ["note", "that", "as", "in", "plain", "markov", "models", "we", "assume", "all", "probabilities", "are", "stationary", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 36, "end": 38, "i_start": 7, "i_end": 7}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "we", "start": 36, "end": 38, "i_start": 7, "i_end": 7}, "verb": {"text": "assume", "start": 39, "end": 45, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 36, "end": 38, "i_start": 7, "i_end": 7}, "action": {"text": "assume", "start": 39, "end": 45, "i_start": 8, "i_end": 8}}, {"character": {"text": "markov", "start": 22, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "models", "start": 29, "end": 35, "i_start": 6, "i_end": 6}}], "id": 635}, {"sent": "implementations of these methods are obtained from the scikit-learn machine learning library .", "tokens": ["implementations", "of", "these", "methods", "are", "obtained", "from", "the", "scikit", "-", "learn", "machine", "learning", "library", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "implementations of these methods", "start": 0, "end": 32, "i_start": 0, "i_end": 3}, "verb": {"text": "are obtained", "start": 33, "end": 45, "i_start": 4, "i_end": 5}}], "id": 636}, {"sent": "at the largest energies there is a small contribution from deep inelastic scattering .", "tokens": ["at", "the", "largest", "energies", "there", "is", "a", "small", "contribution", "from", "deep", "inelastic", "scattering", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 24, "end": 29, "i_start": 4, "i_end": 4}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "scattering", "start": 74, "end": 84, "i_start": 12, "i_end": 12}, "action": {"text": "contribution", "start": 41, "end": 53, "i_start": 8, "i_end": 8}}], "id": 637}, {"sent": "first let us construct the bulk lagrangian for the vector multiplet and the hypermultiplets .", "tokens": ["first", "let", "us", "construct", "the", "bulk", "lagrangian", "for", "the", "vector", "multiplet", "and", "the", "hypermultiplets", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "let", "start": 6, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "us", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "construct", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "construct", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}], "id": 638}, {"sent": "deep networks have been applied to almost all computer vision tasks and have achieved state-of-the-art performances , such as image classification .", "tokens": ["deep", "networks", "have", "been", "applied", "to", "almost", "all", "computer", "vision", "tasks", "and", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performances", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep networks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "have been applied", "start": 14, "end": 31, "i_start": 2, "i_end": 4}}, {"subject": {"text": "deep networks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "achieved", "start": 77, "end": 85, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "achieved", "start": 77, "end": 85, "i_start": 13, "i_end": 13}}], "id": 639}, {"sent": "deep learning based models have achieved great advances in object detection in recent years .", "tokens": ["deep", "learning", "based", "models", "have", "achieved", "great", "advances", "in", "object", "detection", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning based models", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 27, "end": 40, "i_start": 4, "i_end": 5}}, {"character": {"text": "models", "start": 20, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 32, "end": 40, "i_start": 5, "i_end": 5}}], "id": 640}, {"sent": "note that the spin diffusion length in the superconducting state is the same as that in the normal state .", "tokens": ["note", "that", "the", "spin", "diffusion", "length", "in", "the", "superconducting", "state", "is", "the", "same", "as", "that", "in", "the", "normal", "state", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 641}, {"sent": "orbifolds also naturally appears when there is a symmetry , such as in symplectic reductions or in the presence of group actions .", "tokens": ["orbifolds", "also", "naturally", "appears", "when", "there", "is", "a", "symmetry", ",", "such", "as", "in", "symplectic", "reductions", "or", "in", "the", "presence", "of", "group", "actions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "orbifolds", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "appears", "start": 25, "end": 32, "i_start": 3, "i_end": 3}}], "id": 642}, {"sent": "we use glorot initialization for all the free parameters of our networks .", "tokens": ["we", "use", "glorot", "initialization", "for", "all", "the", "free", "parameters", "of", "our", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 643}, {"sent": "note that we are working here with a first-order formulation , whereas the action of is presented in a second-order formulation .", "tokens": ["note", "that", "we", "are", "working", "here", "with", "a", "first", "-", "order", "formulation", ",", "whereas", "the", "action", "of", "is", "presented", "in", "a", "second", "-", "order", "formulation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "working", "start": 17, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "working", "start": 17, "end": 24, "i_start": 4, "i_end": 4}}], "id": 644}, {"sent": "the multiplication is the associative direct product of tensors .", "tokens": ["the", "multiplication", "is", "the", "associative", "direct", "product", "of", "tensors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the multiplication", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "product", "start": 45, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "associative", "start": 26, "end": 37, "i_start": 4, "i_end": 4}}], "id": 645}, {"sent": "deep convolutional neural networks have been successful in many computer vision tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successful", "in", "many", "computer", "vision", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "successful", "start": 45, "end": 55, "i_start": 6, "i_end": 6}}], "id": 646}, {"sent": "the data were reduced and analyzed using the echelle package of midas .", "tokens": ["the", "data", "were", "reduced", "and", "analyzed", "using", "the", "echelle", "package", "of", "midas", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "were reduced", "start": 9, "end": 21, "i_start": 2, "i_end": 3}}, {"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "analyzed", "start": 26, "end": 34, "i_start": 5, "i_end": 5}}], "id": 647}, {"sent": "the lightest neutralino is the wino which is a perfect cold dark matter candidate assuming the non-thermal production from the gravitino decay .", "tokens": ["the", "lightest", "neutralino", "is", "the", "wino", "which", "is", "a", "perfect", "cold", "dark", "matter", "candidate", "assuming", "the", "non", "-", "thermal", "production", "from", "the", "gravitino", "decay", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lightest neutralino", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "decay", "start": 137, "end": 142, "i_start": 23, "i_end": 23}, "action": {"text": "production", "start": 107, "end": 117, "i_start": 19, "i_end": 19}}, {"character": {"text": "gravitino", "start": 127, "end": 136, "i_start": 22, "i_end": 22}, "action": {"text": "decay", "start": 137, "end": 142, "i_start": 23, "i_end": 23}}], "id": 648}, {"sent": "indeed , we implement a soft transition between a classical dropout-free training of a network versus the dropout one .", "tokens": ["indeed", ",", "we", "implement", "a", "soft", "transition", "between", "a", "classical", "dropout", "-", "free", "training", "of", "a", "network", "versus", "the", "dropout", "one", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "verb": {"text": "implement", "start": 12, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "action": {"text": "implement", "start": 12, "end": 21, "i_start": 3, "i_end": 3}}], "id": 649}, {"sent": "this region is characterized by delocalized , band-electron-like states .", "tokens": ["this", "region", "is", "characterized", "by", "delocalized", ",", "band", "-", "electron", "-", "like", "states", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this region", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is characterized", "start": 12, "end": 28, "i_start": 2, "i_end": 3}}], "id": 650}, {"sent": "the geometry is the deformed conifold with a cons3 , formal factor .", "tokens": ["the", "geometry", "is", "the", "deformed", "conifold", "with", "a", "cons3", ",", "formal", "factor", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the geometry", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 651}, {"sent": "the higgs boson is the only sm particle that has not yet been discovered .", "tokens": ["the", "higgs", "boson", "is", "the", "only", "sm", "particle", "that", "has", "not", "yet", "been", "discovered", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the higgs boson", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 652}, {"sent": "this approach is known as dynamical compactification .", "tokens": ["this", "approach", "is", "known", "as", "dynamical", "compactification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this approach", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is known", "start": 14, "end": 22, "i_start": 2, "i_end": 3}}], "id": 653}, {"sent": "consider the sheaf wo on \u03c6 which is the extension by zero of the sheaf w on the open point o .", "tokens": ["consider", "the", "sheaf", "wo", "on", "\u03c6", "which", "is", "the", "extension", "by", "zero", "of", "the", "sheaf", "w", "on", "the", "open", "point", "o", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "zero", "start": 53, "end": 57, "i_start": 11, "i_end": 11}, "action": {"text": "extension", "start": 40, "end": 49, "i_start": 9, "i_end": 9}}], "id": 654}, {"sent": "recently , increasing attention has focused on data-driven 3d reconstruction from single images .", "tokens": ["recently", ",", "increasing", "attention", "has", "focused", "on", "data", "-", "driven", "3d", "reconstruction", "from", "single", "images", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "increasing attention", "start": 11, "end": 31, "i_start": 2, "i_end": 3}, "verb": {"text": "has focused", "start": 32, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "data", "start": 47, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "driven", "start": 52, "end": 58, "i_start": 9, "i_end": 9}}], "id": 655}, {"sent": "cluster algebras have been introduced and studied by fomin and zelevinsky in .", "tokens": ["cluster", "algebras", "have", "been", "introduced", "and", "studied", "by", "fomin", "and", "zelevinsky", "in", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "have been introduced", "start": 17, "end": 37, "i_start": 2, "i_end": 4}}, {"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "studied", "start": 42, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "fomin", "start": 53, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "introduced", "start": 27, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "zelevinsky", "start": 63, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "introduced", "start": 27, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "fomin", "start": 53, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "studied", "start": 42, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "zelevinsky", "start": 63, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "studied", "start": 42, "end": 49, "i_start": 6, "i_end": 6}}], "id": 656}, {"sent": "every sheaf is the direct sum of a torsion-free sheaf and a finite length sheaf .", "tokens": ["every", "sheaf", "is", "the", "direct", "sum", "of", "a", "torsion", "-", "free", "sheaf", "and", "a", "finite", "length", "sheaf", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "every sheaf", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 657}, {"sent": "ellis , the large scale structure of spacetime , cam bridge university press .", "tokens": ["ellis", ",", "the", "large", "scale", "structure", "of", "spacetime", ",", "cam", "bridge", "university", "press", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 658}, {"sent": "significant improvements have been made recently on various computer vision and natural language processing tasks using deep architectures .", "tokens": ["significant", "improvements", "have", "been", "made", "recently", "on", "various", "computer", "vision", "and", "natural", "language", "processing", "tasks", "using", "deep", "architectures", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "significant improvements", "start": 0, "end": 24, "i_start": 0, "i_end": 1}, "verb": {"text": "have been made", "start": 25, "end": 39, "i_start": 2, "i_end": 4}}], "id": 659}, {"sent": "the newton-hooke limit of beltrami-ds spacetime and inertial-type motion a .", "tokens": ["the", "newton", "-", "hooke", "limit", "of", "beltrami", "-", "ds", "spacetime", "and", "inertial", "-", "type", "motion", "a", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 660}, {"sent": "we turn to the fluctuation spectrum on the kink .", "tokens": ["we", "turn", "to", "the", "fluctuation", "spectrum", "on", "the", "kink", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "turn", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "turn", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "spectrum", "start": 27, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "fluctuation", "start": 15, "end": 26, "i_start": 4, "i_end": 4}}], "id": 661}, {"sent": "the study launched here is built upon the framework of an explicit model , dubbed no-scale f -su , uniting the f -lipped su grand unified theory .", "tokens": ["the", "study", "launched", "here", "is", "built", "upon", "the", "framework", "of", "an", "explicit", "model", ",", "dubbed", "no", "-", "scale", "f", "-su", ",", "uniting", "the", "f", "-lipped", "su", "grand", "unified", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the study launched here", "start": 0, "end": 23, "i_start": 0, "i_end": 3}, "verb": {"text": "is built", "start": 24, "end": 32, "i_start": 4, "i_end": 5}}, {"character": {"text": "model", "start": 67, "end": 72, "i_start": 12, "i_end": 12}, "action": {"text": "uniting", "start": 99, "end": 106, "i_start": 21, "i_end": 21}}], "id": 662}, {"sent": "we use the resnet50 architecture and its weights for initialization .", "tokens": ["we", "use", "the", "resnet50", "architecture", "and", "its", "weights", "for", "initialization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 663}, {"sent": "deep convolutional neural networks have achieved great success in various computer vision tasks , including object classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "various", "computer", "vision", "tasks", ",", "including", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}], "id": 664}, {"sent": "spectral function of discrete all-coupling polarons vi .", "tokens": ["spectral", "function", "of", "discrete", "all", "-", "coupling", "polarons", "vi", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "polarons", "start": 43, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "function", "start": 9, "end": 17, "i_start": 1, "i_end": 1}}], "id": 665}, {"sent": "recently , a novel structure called generative adversarial network has become extremely popular .", "tokens": ["recently", ",", "a", "novel", "structure", "called", "generative", "adversarial", "network", "has", "become", "extremely", "popular", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a novel structure called generative adversarial network", "start": 11, "end": 66, "i_start": 2, "i_end": 8}, "verb": {"text": "has become", "start": 67, "end": 77, "i_start": 9, "i_end": 10}}], "id": 666}, {"sent": "the effect of varying the dark matter halo profile on the positron spectrum .", "tokens": ["the", "effect", "of", "varying", "the", "dark", "matter", "halo", "profile", "on", "the", "positron", "spectrum", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 667}, {"sent": "quantum mechanics is a new tool for both code-breakers and code-makers in their eternal arms race .", "tokens": ["quantum", "mechanics", "is", "a", "new", "tool", "for", "both", "code", "-", "breakers", "and", "code", "-", "makers", "in", "their", "eternal", "arms", "race", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum mechanics", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "both", "start": 36, "end": 40, "i_start": 7, "i_end": 7}, "action": {"text": "race", "start": 93, "end": 97, "i_start": 19, "i_end": 19}}], "id": 668}, {"sent": "the two styles of algorithms for agnostic active learning are disagreement-based active learning .", "tokens": ["the", "two", "styles", "of", "algorithms", "for", "agnostic", "active", "learning", "are", "disagreement", "-", "based", "active", "learning", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the two styles of algorithms for agnostic active learning", "start": 0, "end": 57, "i_start": 0, "i_end": 8}, "verb": {"text": "are", "start": 58, "end": 61, "i_start": 9, "i_end": 9}}], "id": 669}, {"sent": "reinforcement learning , which is an online learning method , assists an agent to take a series of optimal actions to the environment , then obtains an instantaneous reward to maximize the cumulative benefit over time .", "tokens": ["reinforcement", "learning", ",", "which", "is", "an", "online", "learning", "method", ",", "assists", "an", "agent", "to", "take", "a", "series", "of", "optimal", "actions", "to", "the", "environment", ",", "then", "obtains", "an", "instantaneous", "reward", "to", "maximize", "the", "cumulative", "benefit", "over", "time", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "assists", "start": 62, "end": 69, "i_start": 10, "i_end": 10}}, {"character": {"text": "learning", "start": 14, "end": 22, "i_start": 1, "i_end": 1}, "action": {"text": "assists", "start": 62, "end": 69, "i_start": 10, "i_end": 10}}, {"character": {"text": "agent", "start": 73, "end": 78, "i_start": 12, "i_end": 12}, "action": {"text": "obtains", "start": 141, "end": 148, "i_start": 25, "i_end": 25}}, {"character": {"text": "agent", "start": 73, "end": 78, "i_start": 12, "i_end": 12}, "action": {"text": "maximize", "start": 176, "end": 184, "i_start": 30, "i_end": 30}}], "id": 670}, {"sent": "the computations of entanglement entropies for locally excited states have been worked out in in various dimensional field theories .", "tokens": ["the", "computations", "of", "entanglement", "entropies", "for", "locally", "excited", "states", "have", "been", "worked", "out", "in", "in", "various", "dimensional", "field", "theories", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the computations of entanglement entropies for locally excited states", "start": 0, "end": 69, "i_start": 0, "i_end": 8}, "verb": {"text": "have been worked out", "start": 70, "end": 90, "i_start": 9, "i_end": 12}}], "id": 671}, {"sent": "generative adversarial networks and its variants are rapidly emerging unsupervised machine learning techniques .", "tokens": ["generative", "adversarial", "networks", "and", "its", "variants", "are", "rapidly", "emerging", "unsupervised", "machine", "learning", "techniques", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "emerging", "start": 61, "end": 69, "i_start": 8, "i_end": 8}}, {"character": {"text": "adversarial", "start": 11, "end": 22, "i_start": 1, "i_end": 1}, "action": {"text": "emerging", "start": 61, "end": 69, "i_start": 8, "i_end": 8}}, {"character": {"text": "generative", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "emerging", "start": 61, "end": 69, "i_start": 8, "i_end": 8}}, {"character": {"text": "variants", "start": 40, "end": 48, "i_start": 5, "i_end": 5}, "action": {"text": "emerging", "start": 61, "end": 69, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "emerging", "start": 61, "end": 69, "i_start": 8, "i_end": 8}}, {"character": {"text": "adversarial", "start": 11, "end": 22, "i_start": 1, "i_end": 1}, "action": {"text": "emerging", "start": 61, "end": 69, "i_start": 8, "i_end": 8}}, {"character": {"text": "generative", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "emerging", "start": 61, "end": 69, "i_start": 8, "i_end": 8}}], "id": 672}, {"sent": "in this work , however , we are mainly interested in polarization measures at large angles , to test how they can improve the reconstruction of the reionization history .", "tokens": ["in", "this", "work", ",", "however", ",", "we", "are", "mainly", "interested", "in", "polarization", "measures", "at", "large", "angles", ",", "to", "test", "how", "they", "can", "improve", "the", "reconstruction", "of", "the", "reionization", "history", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 25, "end": 27, "i_start": 6, "i_end": 6}, "verb": {"text": "are", "start": 28, "end": 31, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 6, "i_end": 6}, "action": {"text": "test", "start": 96, "end": 100, "i_start": 18, "i_end": 18}}, {"character": {"text": "they", "start": 105, "end": 109, "i_start": 20, "i_end": 20}, "action": {"text": "improve", "start": 114, "end": 121, "i_start": 22, "i_end": 22}}, {"character": {"text": "they", "start": 105, "end": 109, "i_start": 20, "i_end": 20}, "action": {"text": "reconstruction", "start": 126, "end": 140, "i_start": 24, "i_end": 24}}], "id": 673}, {"sent": "deep convolutional neural networks have achieved great success in image classification and many others .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "image", "classification", "and", "many", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}], "id": 674}, {"sent": "a key technical insight of ours is to use a monadic structure for galois connections and proofs by calculus , following the example of moggi .", "tokens": ["a", "key", "technical", "insight", "of", "ours", "is", "to", "use", "a", "monadic", "structure", "for", "galois", "connections", "and", "proofs", "by", "calculus", ",", "following", "the", "example", "of", "moggi", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a key technical insight of ours", "start": 0, "end": 31, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 6, "i_end": 6}}], "id": 675}, {"sent": "the portfolio consists of the top 100 stocks by market capitalisation on the johannesburg stock exchange .", "tokens": ["the", "portfolio", "consists", "of", "the", "top", "100", "stocks", "by", "market", "capitalisation", "on", "the", "johannesburg", "stock", "exchange", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the portfolio", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 14, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "market", "start": 48, "end": 54, "i_start": 9, "i_end": 9}, "action": {"text": "capitalisation", "start": 55, "end": 69, "i_start": 10, "i_end": 10}}], "id": 676}, {"sent": "le and mikolov propose a method called paragraph vector , which adopts a word2vec model to create an unsupervised learning algorithm to provide a fixedlength feature representation from variable-length pieces of text .", "tokens": ["le", "and", "mikolov", "propose", "a", "method", "called", "paragraph", "vector", ",", "which", "adopts", "a", "word2vec", "model", "to", "create", "an", "unsupervised", "learning", "algorithm", "to", "provide", "a", "fixedlength", "feature", "representation", "from", "variable", "-", "length", "pieces", "of", "text", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "le and mikolov", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 15, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "le", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 15, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "mikolov", "start": 7, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "propose", "start": 15, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "method", "start": 25, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "adopts", "start": 64, "end": 70, "i_start": 11, "i_end": 11}}, {"character": {"text": "algorithm", "start": 123, "end": 132, "i_start": 20, "i_end": 20}, "action": {"text": "provide", "start": 136, "end": 143, "i_start": 22, "i_end": 22}}], "id": 677}, {"sent": "normal -a binary classification problem of distinguishing subjects with any syndrome from normal subjects .", "tokens": ["normal", "-a", "binary", "classification", "problem", "of", "distinguishing", "subjects", "with", "any", "syndrome", "from", "normal", "subjects", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 678}, {"sent": "starting from the work of bucila et al and knowledge distillation by hinton et al , the design of smaller yet efficient networks has gained a lot of research interest .", "tokens": ["starting", "from", "the", "work", "of", "bucila", "et", "al", "and", "knowledge", "distillation", "by", "hinton", "et", "al", ",", "the", "design", "of", "smaller", "yet", "efficient", "networks", "has", "gained", "a", "lot", "of", "research", "interest", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "the design of smaller yet efficient networks", "start": 84, "end": 128, "i_start": 16, "i_end": 22}, "verb": {"text": "has gained", "start": 129, "end": 139, "i_start": 23, "i_end": 24}}, {"character": {"text": "design", "start": 88, "end": 94, "i_start": 17, "i_end": 17}, "action": {"text": "gained", "start": 133, "end": 139, "i_start": 24, "i_end": 24}}], "id": 679}, {"sent": "we compare our proposed pifpaf method against the reproducible state-of-the-art bottom-up openpose methods .", "tokens": ["we", "compare", "our", "proposed", "pifpaf", "method", "against", "the", "reproducible", "state", "-", "of", "-", "the", "-", "art", "bottom", "-", "up", "openpose", "methods", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 680}, {"sent": "recently , convolutional neural networks -based methods achieve great success in image classification tasks .", "tokens": ["recently", ",", "convolutional", "neural", "networks", "-based", "methods", "achieve", "great", "success", "in", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks -based methods", "start": 11, "end": 55, "i_start": 2, "i_end": 6}, "verb": {"text": "achieve", "start": 56, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "methods", "start": 48, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "achieve", "start": 56, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "methods", "start": 48, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 70, "end": 77, "i_start": 9, "i_end": 9}}], "id": 681}, {"sent": "we can observe that our optimized algorithm succeeds in slightly reducing the route length .", "tokens": ["we", "can", "observe", "that", "our", "optimized", "algorithm", "succeeds", "in", "slightly", "reducing", "the", "route", "length", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "can observe", "start": 3, "end": 14, "i_start": 1, "i_end": 2}}, {"subject": {"text": "our optimized algorithm", "start": 20, "end": 43, "i_start": 4, "i_end": 6}, "verb": {"text": "succeeds", "start": 44, "end": 52, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "observe", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "algorithm", "start": 34, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "succeeds", "start": 44, "end": 52, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimized", "start": 24, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "algorithm", "start": 34, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "reducing", "start": 65, "end": 73, "i_start": 10, "i_end": 10}}], "id": 682}, {"sent": "convolutional neural networks have broken many records of computer vision tasks , such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "broken", "many", "records", "of", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have broken", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "broken", "start": 35, "end": 41, "i_start": 4, "i_end": 4}}], "id": 683}, {"sent": "deep neural networks have achieved great success in image classification , speech recognition and classic games such as go in recent years .", "tokens": ["deep", "neural", "networks", "have", "achieved", "great", "success", "in", "image", "classification", ",", "speech", "recognition", "and", "classic", "games", "such", "as", "go", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 41, "end": 48, "i_start": 6, "i_end": 6}}], "id": 684}, {"sent": "this limitation is countered by the gdof framework , which largely inherits the tractability of the dof framework while capturing the diversity in channel strengths .", "tokens": ["this", "limitation", "is", "countered", "by", "the", "gdof", "framework", ",", "which", "largely", "inherits", "the", "tractability", "of", "the", "dof", "framework", "while", "capturing", "the", "diversity", "in", "channel", "strengths", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this limitation", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is countered", "start": 16, "end": 28, "i_start": 2, "i_end": 3}}, {"character": {"text": "framework", "start": 41, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "countered", "start": 19, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "framework", "start": 41, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "inherits", "start": 67, "end": 75, "i_start": 11, "i_end": 11}}, {"character": {"text": "framework", "start": 41, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "capturing", "start": 120, "end": 129, "i_start": 19, "i_end": 19}}], "id": 685}, {"sent": "the network is trained with minibatch gradient descent using the adam optimizer .", "tokens": ["the", "network", "is", "trained", "with", "minibatch", "gradient", "descent", "using", "the", "adam", "optimizer", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the network", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is trained", "start": 12, "end": 22, "i_start": 2, "i_end": 3}}, {"character": {"text": "network", "start": 4, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "descent", "start": 47, "end": 54, "i_start": 7, "i_end": 7}}], "id": 686}, {"sent": "recently , it has been applied to medical imaging , such as image denoising and artifact reduction , using convolutional neural network or generative adversarial network .", "tokens": ["recently", ",", "it", "has", "been", "applied", "to", "medical", "imaging", ",", "such", "as", "image", "denoising", "and", "artifact", "reduction", ",", "using", "convolutional", "neural", "network", "or", "generative", "adversarial", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "verb": {"text": "has been applied", "start": 14, "end": 30, "i_start": 3, "i_end": 5}}], "id": 687}, {"sent": "the o-module scheme alt when s is the spectrum of a local artin o-algebra .", "tokens": ["the", "o", "-", "module", "scheme", "alt", "when", "s", "is", "the", "spectrum", "of", "a", "local", "artin", "o", "-", "algebra", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 688}, {"sent": "distinct is a global constraint that asserts that all its component variables are distinct integers .", "tokens": ["distinct", "is", "a", "global", "constraint", "that", "asserts", "that", "all", "its", "component", "variables", "are", "distinct", "integers", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "constraint", "start": 21, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "asserts", "start": 37, "end": 44, "i_start": 6, "i_end": 6}}], "id": 689}, {"sent": "indeed , visual feature learning with deep neural networks has swept the field of computer vision in recent years .", "tokens": ["indeed", ",", "visual", "feature", "learning", "with", "deep", "neural", "networks", "has", "swept", "the", "field", "of", "computer", "vision", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "visual feature learning with deep neural networks", "start": 9, "end": 58, "i_start": 2, "i_end": 8}, "verb": {"text": "has swept", "start": 59, "end": 68, "i_start": 9, "i_end": 10}}, {"character": {"text": "learning", "start": 24, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "swept", "start": 63, "end": 68, "i_start": 10, "i_end": 10}}], "id": 690}, {"sent": "recurrent neural networks , including their improved variant lstm , have shown their excellent capability to memorize long term contexts in time series data , eg , speech recognition .", "tokens": ["recurrent", "neural", "networks", ",", "including", "their", "improved", "variant", "lstm", ",", "have", "shown", "their", "excellent", "capability", "to", "memorize", "long", "term", "contexts", "in", "time", "series", "data", ",", "eg", ",", "speech", "recognition", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "recurrent neural networks", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 68, "end": 78, "i_start": 10, "i_end": 11}}, {"character": {"text": "networks", "start": 17, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 73, "end": 78, "i_start": 11, "i_end": 11}}, {"character": {"text": "networks", "start": 17, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "memorize", "start": 109, "end": 117, "i_start": 16, "i_end": 16}}], "id": 691}, {"sent": "we propose a learning algorithm for map estimates of the parameters based on the expectation-maximisation algorithm .", "tokens": ["we", "propose", "a", "learning", "algorithm", "for", "map", "estimates", "of", "the", "parameters", "based", "on", "the", "expectation", "-", "maximisation", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "propose", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 692}, {"sent": "cluster algebras have been introduced by fomin and zelevinsky in in the context of total positivity and canonical bases in lie theory .", "tokens": ["cluster", "algebras", "have", "been", "introduced", "by", "fomin", "and", "zelevinsky", "in", "in", "the", "context", "of", "total", "positivity", "and", "canonical", "bases", "in", "lie", "theory", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "have been introduced", "start": 17, "end": 37, "i_start": 2, "i_end": 4}}, {"character": {"text": "fomin", "start": 41, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "introduced", "start": 27, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "zelevinsky", "start": 51, "end": 61, "i_start": 8, "i_end": 8}, "action": {"text": "introduced", "start": 27, "end": 37, "i_start": 4, "i_end": 4}}], "id": 693}, {"sent": "in this respect , our approach is related to variational autoencoders , which aims at hiding a signal in a carrier image .", "tokens": ["in", "this", "respect", ",", "our", "approach", "is", "related", "to", "variational", "autoencoders", ",", "which", "aims", "at", "hiding", "a", "signal", "in", "a", "carrier", "image", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our approach", "start": 18, "end": 30, "i_start": 4, "i_end": 5}, "verb": {"text": "is related", "start": 31, "end": 41, "i_start": 6, "i_end": 7}}, {"character": {"text": "autoencoders", "start": 57, "end": 69, "i_start": 10, "i_end": 10}, "action": {"text": "aims", "start": 78, "end": 82, "i_start": 13, "i_end": 13}}], "id": 694}, {"sent": "s is built by the repetition of two blocks , each defined by a fully connected layer , a batch normalization layer , followed by a fully connected layer with tanh activation functions .", "tokens": ["s", "is", "built", "by", "the", "repetition", "of", "two", "blocks", ",", "each", "defined", "by", "a", "fully", "connected", "layer", ",", "a", "batch", "normalization", "layer", ",", "followed", "by", "a", "fully", "connected", "layer", "with", "tanh", "activation", "functions", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "s", "start": 0, "end": 1, "i_start": 0, "i_end": 0}, "verb": {"text": "is built", "start": 2, "end": 10, "i_start": 1, "i_end": 2}}, {"character": {"text": "repetition", "start": 18, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "built", "start": 5, "end": 10, "i_start": 2, "i_end": 2}}], "id": 695}, {"sent": "to find the complete set of constraints we use the general lagrangian scheme 17 which is equivalent to the dirac-bergmann procedure in hamiltonian formalism but for our purposes is simpler .", "tokens": ["to", "find", "the", "complete", "set", "of", "constraints", "we", "use", "the", "general", "lagrangian", "scheme", "17", "which", "is", "equivalent", "to", "the", "dirac", "-", "bergmann", "procedure", "in", "hamiltonian", "formalism", "but", "for", "our", "purposes", "is", "simpler", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 40, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "use", "start": 43, "end": 46, "i_start": 8, "i_end": 8}}], "id": 696}, {"sent": "the majority of our graphs comes from stanford large network dataset collection .", "tokens": ["the", "majority", "of", "our", "graphs", "comes", "from", "stanford", "large", "network", "dataset", "collection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the majority of our graphs", "start": 0, "end": 26, "i_start": 0, "i_end": 4}, "verb": {"text": "comes", "start": 27, "end": 32, "i_start": 5, "i_end": 5}}], "id": 697}, {"sent": "convolutional neural networks have achieved superior performance in various tasks .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "various", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 6, "i_end": 6}}], "id": 698}, {"sent": "in parallel , deep convolutional neural networks have proven their effectiveness in many computer vision fields such as object classification .", "tokens": ["in", "parallel", ",", "deep", "convolutional", "neural", "networks", "have", "proven", "their", "effectiveness", "in", "many", "computer", "vision", "fields", "such", "as", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 14, "end": 48, "i_start": 3, "i_end": 6}, "verb": {"text": "have proven", "start": 49, "end": 60, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 40, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "proven", "start": 54, "end": 60, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 40, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "effectiveness", "start": 67, "end": 80, "i_start": 10, "i_end": 10}}], "id": 699}, {"sent": "we use an augmented lagrangian multiplier scheme to solve the optimization problem .", "tokens": ["we", "use", "an", "augmented", "lagrangian", "multiplier", "scheme", "to", "solve", "the", "optimization", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "solve", "start": 52, "end": 57, "i_start": 8, "i_end": 8}}], "id": 700}, {"sent": "an example table of the the catalogue of high probability members of the pleiades .", "tokens": ["an", "example", "table", "of", "the", "the", "catalogue", "of", "high", "probability", "members", "of", "the", "pleiades", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 701}, {"sent": "cnns have been proven as effective tools for pattern recognition in different applications such as image classification , object detection , and sentiment analysis .", "tokens": ["cnns", "have", "been", "proven", "as", "effective", "tools", "for", "pattern", "recognition", "in", "different", "applications", "such", "as", "image", "classification", ",", "object", "detection", ",", "and", "sentiment", "analysis", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cnns", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "have been proven", "start": 5, "end": 21, "i_start": 1, "i_end": 3}}, {"character": {"text": "tools", "start": 35, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "effective", "start": 25, "end": 34, "i_start": 5, "i_end": 5}}], "id": 702}, {"sent": "the phenomenon of entanglement is one of the most fundamental and nonclassical features exhibited by quantum systems .", "tokens": ["the", "phenomenon", "of", "entanglement", "is", "one", "of", "the", "most", "fundamental", "and", "nonclassical", "features", "exhibited", "by", "quantum", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the phenomenon of entanglement", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "systems", "start": 109, "end": 116, "i_start": 16, "i_end": 16}, "action": {"text": "exhibited", "start": 88, "end": 97, "i_start": 13, "i_end": 13}}], "id": 703}, {"sent": "in recent years , deep neural network has been widely employed in the state-of-the-art works in many fields like computer vision .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "network", "has", "been", "widely", "employed", "in", "the", "state", "-", "of", "-", "the", "-", "art", "works", "in", "many", "fields", "like", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural network", "start": 18, "end": 37, "i_start": 4, "i_end": 6}, "verb": {"text": "employed", "start": 54, "end": 62, "i_start": 10, "i_end": 10}}, {"subject": {"text": "deep neural network", "start": 18, "end": 37, "i_start": 4, "i_end": 6}, "verb": {"text": "has been", "start": 38, "end": 46, "i_start": 7, "i_end": 8}}], "id": 704}, {"sent": "fault-tolerant quantum computation with very high threshold for loss errors .", "tokens": ["fault", "-", "tolerant", "quantum", "computation", "with", "very", "high", "threshold", "for", "loss", "errors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "computation", "start": 23, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "tolerant", "start": 6, "end": 14, "i_start": 2, "i_end": 2}}], "id": 705}, {"sent": "people interact with computers and intelligent systems in ways that directly mirror how they interact with people .", "tokens": ["people", "interact", "with", "computers", "and", "intelligent", "systems", "in", "ways", "that", "directly", "mirror", "how", "they", "interact", "with", "people", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "people", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "interact", "start": 7, "end": 15, "i_start": 1, "i_end": 1}}], "id": 706}, {"sent": "indeed , in the case of the a l sutherland model , the yangian symmetry was the cornerstone of the explicit construction of the eigenvectors .", "tokens": ["indeed", ",", "in", "the", "case", "of", "the", "a", "l", "sutherland", "model", ",", "the", "yangian", "symmetry", "was", "the", "cornerstone", "of", "the", "explicit", "construction", "of", "the", "eigenvectors", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the yangian symmetry", "start": 51, "end": 71, "i_start": 12, "i_end": 14}, "verb": {"text": "was", "start": 72, "end": 75, "i_start": 15, "i_end": 15}}], "id": 707}, {"sent": "moreover , a variety of degenerate behaviors have been observed-eg , mode collapse .", "tokens": ["moreover", ",", "a", "variety", "of", "degenerate", "behaviors", "have", "been", "observed", "-", "eg", ",", "mode", "collapse", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 708}, {"sent": "inflation is the leading theoretical paradigm for understanding the early universe and the origin of the primordial perturbations .", "tokens": ["inflation", "is", "the", "leading", "theoretical", "paradigm", "for", "understanding", "the", "early", "universe", "and", "the", "origin", "of", "the", "primordial", "perturbations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "inflation", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "paradigm", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "leading", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}], "id": 709}, {"sent": "in , berenstein and zelevinsky introduced quantum cluster algebras as a generalization of cluster algebras in the noncommutative setting .", "tokens": ["in", ",", "berenstein", "and", "zelevinsky", "introduced", "quantum", "cluster", "algebras", "as", "a", "generalization", "of", "cluster", "algebras", "in", "the", "noncommutative", "setting", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "berenstein and zelevinsky", "start": 5, "end": 30, "i_start": 2, "i_end": 4}, "verb": {"text": "introduced", "start": 31, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "berenstein", "start": 5, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 31, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "zelevinsky", "start": 20, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "introduced", "start": 31, "end": 41, "i_start": 5, "i_end": 5}}], "id": 710}, {"sent": "for the alignment , we used the idl-based program idp36 that was initially developed for hst imaging data .", "tokens": ["for", "the", "alignment", ",", "we", "used", "the", "idl", "-", "based", "program", "idp36", "that", "was", "initially", "developed", "for", "hst", "imaging", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 20, "end": 22, "i_start": 4, "i_end": 4}, "verb": {"text": "used", "start": 23, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 20, "end": 22, "i_start": 4, "i_end": 4}, "action": {"text": "used", "start": 23, "end": 27, "i_start": 5, "i_end": 5}}], "id": 711}, {"sent": "any two-qubit entangling quantum gate and a small number of single-qubit gates can form a universal set of quantum gates .", "tokens": ["any", "two", "-", "qubit", "entangling", "quantum", "gate", "and", "a", "small", "number", "of", "single", "-", "qubit", "gates", "can", "form", "a", "universal", "set", "of", "quantum", "gates", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "any two-qubit entangling quantum gate and a small number of single-qubit gates", "start": 0, "end": 78, "i_start": 0, "i_end": 15}, "verb": {"text": "can form", "start": 79, "end": 87, "i_start": 16, "i_end": 17}}, {"character": {"text": "gate", "start": 33, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "form", "start": 83, "end": 87, "i_start": 17, "i_end": 17}}, {"character": {"text": "quantum", "start": 25, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "form", "start": 83, "end": 87, "i_start": 17, "i_end": 17}}, {"character": {"text": "entangling", "start": 14, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "form", "start": 83, "end": 87, "i_start": 17, "i_end": 17}}, {"character": {"text": "any", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "form", "start": 83, "end": 87, "i_start": 17, "i_end": 17}}, {"character": {"text": "gates", "start": 73, "end": 78, "i_start": 15, "i_end": 15}, "action": {"text": "form", "start": 83, "end": 87, "i_start": 17, "i_end": 17}}, {"character": {"text": "number", "start": 50, "end": 56, "i_start": 10, "i_end": 10}, "action": {"text": "form", "start": 83, "end": 87, "i_start": 17, "i_end": 17}}, {"character": {"text": "small", "start": 44, "end": 49, "i_start": 9, "i_end": 9}, "action": {"text": "form", "start": 83, "end": 87, "i_start": 17, "i_end": 17}}], "id": 712}, {"sent": "deep neural networks have achieved impressive performance on tasks across a variety of domains , including vision .", "tokens": ["deep", "neural", "networks", "have", "achieved", "impressive", "performance", "on", "tasks", "across", "a", "variety", "of", "domains", ",", "including", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 46, "end": 57, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 46, "end": 57, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 35, "end": 45, "i_start": 5, "i_end": 5}}], "id": 713}, {"sent": "marra , solutions to the boltzmann equation in the boussinesq regime , j .", "tokens": ["marra", ",", "solutions", "to", "the", "boltzmann", "equation", "in", "the", "boussinesq", "regime", ",", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 714}, {"sent": "deep convolutional neural networks have enabled unparalleled breakthroughs in a variety of visual tasks , such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "enabled", "unparalleled", "breakthroughs", "in", "a", "variety", "of", "visual", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have enabled", "start": 35, "end": 47, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "enabled", "start": 40, "end": 47, "i_start": 5, "i_end": 5}}], "id": 715}, {"sent": "models based on deep convolutional neural networks have become the de facto standards in a wide variety of computer vision tasks , such as image classification .", "tokens": ["models", "based", "on", "deep", "convolutional", "neural", "networks", "have", "become", "the", "de", "facto", "standards", "in", "a", "wide", "variety", "of", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "models based on deep convolutional neural networks", "start": 0, "end": 50, "i_start": 0, "i_end": 6}, "verb": {"text": "have become", "start": 51, "end": 62, "i_start": 7, "i_end": 8}}], "id": 716}, {"sent": "in particular , in multicarrier transmission , it is shown in that nonzero mean gaussian input distributions lead to an enlarged rp region compared to circularly symmetric complex gaussian input distributions .", "tokens": ["in", "particular", ",", "in", "multicarrier", "transmission", ",", "it", "is", "shown", "in", "that", "nonzero", "mean", "gaussian", "input", "distributions", "lead", "to", "an", "enlarged", "rp", "region", "compared", "to", "circularly", "symmetric", "complex", "gaussian", "input", "distributions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 47, "end": 49, "i_start": 7, "i_end": 7}, "verb": {"text": "is shown", "start": 50, "end": 58, "i_start": 8, "i_end": 9}}, {"character": {"text": "distributions", "start": 95, "end": 108, "i_start": 16, "i_end": 16}, "action": {"text": "lead", "start": 109, "end": 113, "i_start": 17, "i_end": 17}}], "id": 717}, {"sent": "this semantics is a simple variant of ld-resolution .", "tokens": ["this", "semantics", "is", "a", "simple", "variant", "of", "ld", "-", "resolution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this semantics", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 718}, {"sent": "the generators of this language exhaust all possible local order parameters .", "tokens": ["the", "generators", "of", "this", "language", "exhaust", "all", "possible", "local", "order", "parameters", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the generators of this language", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "exhaust", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}], "id": 719}, {"sent": "in order to efficiently simulate the model equations , we present a simple operator splitting algorithm based on strang-marchuk splitting .", "tokens": ["in", "order", "to", "efficiently", "simulate", "the", "model", "equations", ",", "we", "present", "a", "simple", "operator", "splitting", "algorithm", "based", "on", "strang", "-", "marchuk", "splitting", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 55, "end": 57, "i_start": 9, "i_end": 9}, "verb": {"text": "present", "start": 58, "end": 65, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 55, "end": 57, "i_start": 9, "i_end": 9}, "action": {"text": "present", "start": 58, "end": 65, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 55, "end": 57, "i_start": 9, "i_end": 9}, "action": {"text": "simulate", "start": 24, "end": 32, "i_start": 4, "i_end": 4}}], "id": 720}, {"sent": "hence , directed graphs with directed cycles are more appropriate to model such feedback .", "tokens": ["hence", ",", "directed", "graphs", "with", "directed", "cycles", "are", "more", "appropriate", "to", "model", "such", "feedback", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "graphs", "start": 17, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "model", "start": 69, "end": 74, "i_start": 11, "i_end": 11}}], "id": 721}, {"sent": "a variety of spectral models were fitted to the data employing the software tool xspec v11 .", "tokens": ["a", "variety", "of", "spectral", "models", "were", "fitted", "to", "the", "data", "employing", "the", "software", "tool", "xspec", "v11", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a variety of spectral models", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "were fitted", "start": 29, "end": 40, "i_start": 5, "i_end": 6}}, {"character": {"text": "data", "start": 48, "end": 52, "i_start": 9, "i_end": 9}, "action": {"text": "employing", "start": 53, "end": 62, "i_start": 10, "i_end": 10}}], "id": 722}, {"sent": "in human attractiveness assessment with 5 levels from 1 to 5 , the cumulative score , which has been measured in recognition , is also used to evaluate the performance of the proposed methods .", "tokens": ["in", "human", "attractiveness", "assessment", "with", "5", "levels", "from", "1", "to", "5", ",", "the", "cumulative", "score", ",", "which", "has", "been", "measured", "in", "recognition", ",", "is", "also", "used", "to", "evaluate", "the", "performance", "of", "the", "proposed", "methods", "."], "score": [0, 1, 0, 1, 1], "labels": [{"subject": {"text": "the cumulative score", "start": 63, "end": 83, "i_start": 12, "i_end": 14}, "verb": {"text": "used", "start": 135, "end": 139, "i_start": 25, "i_end": 25}}, {"subject": {"text": "the cumulative score", "start": 63, "end": 83, "i_start": 12, "i_end": 14}, "verb": {"text": "is", "start": 127, "end": 129, "i_start": 23, "i_end": 23}}, {"character": {"text": "score", "start": 78, "end": 83, "i_start": 14, "i_end": 14}, "action": {"text": "evaluate", "start": 143, "end": 151, "i_start": 27, "i_end": 27}}, {"character": {"text": "methods", "start": 184, "end": 191, "i_start": 33, "i_end": 33}, "action": {"text": "performance", "start": 156, "end": 167, "i_start": 29, "i_end": 29}}], "id": 723}, {"sent": "neural networks based multi-task learning has been proven effective in many nlp problems .", "tokens": ["neural", "networks", "based", "multi", "-", "task", "learning", "has", "been", "proven", "effective", "in", "many", "nlp", "problems", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks based multi-task learning", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "has been proven", "start": 42, "end": 57, "i_start": 7, "i_end": 9}}, {"character": {"text": "learning", "start": 33, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "effective", "start": 58, "end": 67, "i_start": 10, "i_end": 10}}], "id": 724}, {"sent": "in recent years , methods using convolution neural network have been successful in the classification of image recognition .", "tokens": ["in", "recent", "years", ",", "methods", "using", "convolution", "neural", "network", "have", "been", "successful", "in", "the", "classification", "of", "image", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "methods using convolution neural network", "start": 18, "end": 58, "i_start": 4, "i_end": 8}, "verb": {"text": "have been", "start": 59, "end": 68, "i_start": 9, "i_end": 10}}, {"character": {"text": "methods", "start": 18, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "successful", "start": 69, "end": 79, "i_start": 11, "i_end": 11}}, {"character": {"text": "methods", "start": 18, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "using", "start": 26, "end": 31, "i_start": 5, "i_end": 5}}], "id": 725}, {"sent": "with the use of orthogonal latin squares , we have constructed the permutations with the maximum entangling power for every dimension .", "tokens": ["with", "the", "use", "of", "orthogonal", "latin", "squares", ",", "we", "have", "constructed", "the", "permutations", "with", "the", "maximum", "entangling", "power", "for", "every", "dimension", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 43, "end": 45, "i_start": 8, "i_end": 8}, "verb": {"text": "have constructed", "start": 46, "end": 62, "i_start": 9, "i_end": 10}}, {"character": {"text": "we", "start": 43, "end": 45, "i_start": 8, "i_end": 8}, "action": {"text": "constructed", "start": 51, "end": 62, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 43, "end": 45, "i_start": 8, "i_end": 8}, "action": {"text": "use", "start": 9, "end": 12, "i_start": 2, "i_end": 2}}], "id": 726}, {"sent": "to calculate such density matrices , we will also have to make use of the trace operator .", "tokens": ["to", "calculate", "such", "density", "matrices", ",", "we", "will", "also", "have", "to", "make", "use", "of", "the", "trace", "operator", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 37, "end": 39, "i_start": 6, "i_end": 6}, "verb": {"text": "have", "start": 50, "end": 54, "i_start": 9, "i_end": 9}}, {"subject": {"text": "we", "start": 37, "end": 39, "i_start": 6, "i_end": 6}, "verb": {"text": "will", "start": 40, "end": 44, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 37, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "use", "start": 63, "end": 66, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 37, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "calculate", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}], "id": 727}, {"sent": "li et al propose a model called csrnet that uses dilated convolution to enlarge receptive fields and extract deeper features for boosting performance .", "tokens": ["li", "et", "al", "propose", "a", "model", "called", "csrnet", "that", "uses", "dilated", "convolution", "to", "enlarge", "receptive", "fields", "and", "extract", "deeper", "features", "for", "boosting", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "li et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 9, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "li", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 9, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "model", "start": 19, "end": 24, "i_start": 5, "i_end": 5}, "action": {"text": "uses", "start": 44, "end": 48, "i_start": 9, "i_end": 9}}, {"character": {"text": "model", "start": 19, "end": 24, "i_start": 5, "i_end": 5}, "action": {"text": "enlarge", "start": 72, "end": 79, "i_start": 13, "i_end": 13}}, {"character": {"text": "fields", "start": 90, "end": 96, "i_start": 15, "i_end": 15}, "action": {"text": "receptive", "start": 80, "end": 89, "i_start": 14, "i_end": 14}}, {"character": {"text": "model", "start": 19, "end": 24, "i_start": 5, "i_end": 5}, "action": {"text": "extract", "start": 101, "end": 108, "i_start": 17, "i_end": 17}}, {"character": {"text": "model", "start": 19, "end": 24, "i_start": 5, "i_end": 5}, "action": {"text": "boosting", "start": 129, "end": 137, "i_start": 21, "i_end": 21}}], "id": 728}, {"sent": "in recent years , deep learning has been successfully applied in computer vision and other ai domains , such as object recognition .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "has", "been", "successfully", "applied", "in", "computer", "vision", "and", "other", "ai", "domains", ",", "such", "as", "object", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 18, "end": 31, "i_start": 4, "i_end": 5}, "verb": {"text": "applied", "start": 54, "end": 61, "i_start": 9, "i_end": 9}}, {"subject": {"text": "deep learning", "start": 18, "end": 31, "i_start": 4, "i_end": 5}, "verb": {"text": "has been", "start": 32, "end": 40, "i_start": 6, "i_end": 7}}], "id": 729}, {"sent": "wz sge is a very famous , bright variable star now known to be the closest cataclysmic variable .", "tokens": ["wz", "sge", "is", "a", "very", "famous", ",", "bright", "variable", "star", "now", "known", "to", "be", "the", "closest", "cataclysmic", "variable", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "wz sge", "start": 0, "end": 6, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 7, "end": 9, "i_start": 2, "i_end": 2}}], "id": 730}, {"sent": "we postulate that this is the connection that ought to be used in the procedure of minimal coupling .", "tokens": ["we", "postulate", "that", "this", "is", "the", "connection", "that", "ought", "to", "be", "used", "in", "the", "procedure", "of", "minimal", "coupling", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "postulate", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 4, "i_end": 4}}], "id": 731}, {"sent": "more specifically , for visual features r vis of a bounding box of an object , we use faster-rcnn .", "tokens": ["more", "specifically", ",", "for", "visual", "features", "r", "vis", "of", "a", "bounding", "box", "of", "an", "object", ",", "we", "use", "faster", "-", "rcnn", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 79, "end": 81, "i_start": 16, "i_end": 16}, "verb": {"text": "use", "start": 82, "end": 85, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 79, "end": 81, "i_start": 16, "i_end": 16}, "action": {"text": "use", "start": 82, "end": 85, "i_start": 17, "i_end": 17}}], "id": 732}, {"sent": "deep learning has recently garnered considerable interest in the research community , particularly in computer vision and natural language processing .", "tokens": ["deep", "learning", "has", "recently", "garnered", "considerable", "interest", "in", "the", "research", "community", ",", "particularly", "in", "computer", "vision", "and", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "garnered", "start": 27, "end": 35, "i_start": 4, "i_end": 4}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has", "start": 14, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "garnered", "start": 27, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "community", "start": 74, "end": 83, "i_start": 10, "i_end": 10}, "action": {"text": "research", "start": 65, "end": 73, "i_start": 9, "i_end": 9}}], "id": 733}, {"sent": "neural networks have been applied to solving problems in several application domains such as computer vision , natural language processing , and disease diagnosis .", "tokens": ["neural", "networks", "have", "been", "applied", "to", "solving", "problems", "in", "several", "application", "domains", "such", "as", "computer", "vision", ",", "natural", "language", "processing", ",", "and", "disease", "diagnosis", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have been applied", "start": 16, "end": 33, "i_start": 2, "i_end": 4}}], "id": 734}, {"sent": "this resembles the expectation maximization algorithm in nature .", "tokens": ["this", "resembles", "the", "expectation", "maximization", "algorithm", "in", "nature", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "resembles", "start": 5, "end": 14, "i_start": 1, "i_end": 1}}], "id": 735}, {"sent": "in recent years , deep convolutional neural networks have demonstrated dramatic improvements in performance for computer vision tasks such as object classification , detection , and segmentation .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "demonstrated", "dramatic", "improvements", "in", "performance", "for", "computer", "vision", "tasks", "such", "as", "object", "classification", ",", "detection", ",", "and", "segmentation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have demonstrated", "start": 53, "end": 70, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "demonstrated", "start": 58, "end": 70, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "improvements", "start": 80, "end": 92, "i_start": 11, "i_end": 11}}], "id": 736}, {"sent": "so , we expect that string theory is the best of candidates for consistent quantum gravity theory since string theory is free of the ultraviolet divergences .", "tokens": ["so", ",", "we", "expect", "that", "string", "theory", "is", "the", "best", "of", "candidates", "for", "consistent", "quantum", "gravity", "theory", "since", "string", "theory", "is", "free", "of", "the", "ultraviolet", "divergences", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "verb": {"text": "expect", "start": 8, "end": 14, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "action": {"text": "expect", "start": 8, "end": 14, "i_start": 3, "i_end": 3}}], "id": 737}, {"sent": "recently , significant progress in data-driven image generation has been achieved through generative adversarial networks .", "tokens": ["recently", ",", "significant", "progress", "in", "data", "-", "driven", "image", "generation", "has", "been", "achieved", "through", "generative", "adversarial", "networks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "significant progress in data-driven image generation", "start": 11, "end": 63, "i_start": 2, "i_end": 9}, "verb": {"text": "has been achieved", "start": 64, "end": 81, "i_start": 10, "i_end": 12}}, {"character": {"text": "data", "start": 35, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "driven", "start": 40, "end": 46, "i_start": 7, "i_end": 7}}], "id": 738}, {"sent": "in recent years , alternative solutions have been proposed to make use of the tactile modality to enhance bci efficiency .", "tokens": ["in", "recent", "years", ",", "alternative", "solutions", "have", "been", "proposed", "to", "make", "use", "of", "the", "tactile", "modality", "to", "enhance", "bci", "efficiency", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "alternative solutions", "start": 18, "end": 39, "i_start": 4, "i_end": 5}, "verb": {"text": "have been proposed", "start": 40, "end": 58, "i_start": 6, "i_end": 8}}, {"character": {"text": "modality", "start": 86, "end": 94, "i_start": 15, "i_end": 15}, "action": {"text": "enhance", "start": 98, "end": 105, "i_start": 17, "i_end": 17}}], "id": 739}, {"sent": "recently , convolutional neural networks have been proved to be capable of dramatically boosting the performance of many mainstream computer vision problems .", "tokens": ["recently", ",", "convolutional", "neural", "networks", "have", "been", "proved", "to", "be", "capable", "of", "dramatically", "boosting", "the", "performance", "of", "many", "mainstream", "computer", "vision", "problems", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 11, "end": 40, "i_start": 2, "i_end": 4}, "verb": {"text": "have been proved", "start": 41, "end": 57, "i_start": 5, "i_end": 7}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "boosting", "start": 88, "end": 96, "i_start": 13, "i_end": 13}}, {"character": {"text": "problems", "start": 148, "end": 156, "i_start": 21, "i_end": 21}, "action": {"text": "performance", "start": 101, "end": 112, "i_start": 15, "i_end": 15}}], "id": 740}, {"sent": "now we can give the estimation on the upper bound that preserves the non-degeneracy .", "tokens": ["now", "we", "can", "give", "the", "estimation", "on", "the", "upper", "bound", "that", "preserves", "the", "non", "-", "degeneracy", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "can give", "start": 7, "end": 15, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "estimation", "start": 20, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "bound", "start": 44, "end": 49, "i_start": 9, "i_end": 9}, "action": {"text": "preserves", "start": 55, "end": 64, "i_start": 11, "i_end": 11}}], "id": 741}, {"sent": "recently , generative adversarial networks have led to large improvements in image generation tasks .", "tokens": ["recently", ",", "generative", "adversarial", "networks", "have", "led", "to", "large", "improvements", "in", "image", "generation", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 11, "end": 42, "i_start": 2, "i_end": 4}, "verb": {"text": "have led", "start": 43, "end": 51, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 34, "end": 42, "i_start": 4, "i_end": 4}, "action": {"text": "led", "start": 48, "end": 51, "i_start": 6, "i_end": 6}}], "id": 742}, {"sent": "if gravitino is the lsp , r-parity conservation leads to a long lifetime of the next-to-lsp , which becomes a stable particle in collider scale .", "tokens": ["if", "gravitino", "is", "the", "lsp", ",", "r", "-", "parity", "conservation", "leads", "to", "a", "long", "lifetime", "of", "the", "next", "-", "to", "-", "lsp", ",", "which", "becomes", "a", "stable", "particle", "in", "collider", "scale", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "conservation", "start": 35, "end": 47, "i_start": 9, "i_end": 9}, "action": {"text": "leads", "start": 48, "end": 53, "i_start": 10, "i_end": 10}}], "id": 743}, {"sent": "rsm , a probabilistic undirected topic model is a generalization of the energy-based restricted boltzmann machines rbm , which can be used to model word counts .", "tokens": ["rsm", ",", "a", "probabilistic", "undirected", "topic", "model", "is", "a", "generalization", "of", "the", "energy", "-", "based", "restricted", "boltzmann", "machines", "rbm", ",", "which", "can", "be", "used", "to", "model", "word", "counts", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "rsm", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 45, "end": 47, "i_start": 7, "i_end": 7}}], "id": 744}, {"sent": "and the number of bsv blocks generated by each miner in previous 100 blocks , respectively .", "tokens": ["and", "the", "number", "of", "bsv", "blocks", "generated", "by", "each", "miner", "in", "previous", "100", "blocks", ",", "respectively", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "each", "start": 42, "end": 46, "i_start": 8, "i_end": 8}, "action": {"text": "generated", "start": 29, "end": 38, "i_start": 6, "i_end": 6}}], "id": 745}, {"sent": "in this work , we adopt the adam solver to learn the model parameters .", "tokens": ["in", "this", "work", ",", "we", "adopt", "the", "adam", "solver", "to", "learn", "the", "model", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "adopt", "start": 18, "end": 23, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the adam", "start": 24, "end": 32, "i_start": 6, "i_end": 7}, "verb": {"text": "solver", "start": 33, "end": 39, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "adopt", "start": 18, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "learn", "start": 43, "end": 48, "i_start": 10, "i_end": 10}}], "id": 746}, {"sent": "consider the assumptions and notations above .", "tokens": ["consider", "the", "assumptions", "and", "notations", "above", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 747}, {"sent": "recent deep learning methods have yielded exciting results on large-scale image recognition .", "tokens": ["recent", "deep", "learning", "methods", "have", "yielded", "exciting", "results", "on", "large", "-", "scale", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent deep learning methods", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "have yielded", "start": 29, "end": 41, "i_start": 4, "i_end": 5}}, {"character": {"text": "methods", "start": 21, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "yielded", "start": 34, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "results", "start": 51, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "exciting", "start": 42, "end": 50, "i_start": 6, "i_end": 6}}], "id": 748}, {"sent": "because of corollary 5 , in the simply laced case , any simple transitive 2-representation of s is equivalent to a cell 2-representation by .", "tokens": ["because", "of", "corollary", "5", ",", "in", "the", "simply", "laced", "case", ",", "any", "simple", "transitive", "2", "-", "representation", "of", "s", "is", "equivalent", "to", "a", "cell", "2", "-", "representation", "by", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "any simple transitive 2-representation of s", "start": 52, "end": 95, "i_start": 11, "i_end": 18}, "verb": {"text": "is", "start": 96, "end": 98, "i_start": 19, "i_end": 19}}, {"character": {"text": "transitive", "start": 63, "end": 73, "i_start": 13, "i_end": 13}, "action": {"text": "2-representation", "start": 74, "end": 90, "i_start": 14, "i_end": 16}}, {"character": {"text": "cell", "start": 115, "end": 119, "i_start": 23, "i_end": 23}, "action": {"text": "representation", "start": 122, "end": 136, "i_start": 26, "i_end": 26}}], "id": 749}, {"sent": "the code optimization techniques to auto-vectorize the loop nests , so as to generate simd instructions , require careful analysis of data dependences , memory access patterns , etc .", "tokens": ["the", "code", "optimization", "techniques", "to", "auto", "-", "vectorize", "the", "loop", "nests", ",", "so", "as", "to", "generate", "simd", "instructions", ",", "require", "careful", "analysis", "of", "data", "dependences", ",", "memory", "access", "patterns", ",", "etc", "."], "score": [0, 0, 1, 0, 1], "labels": [{"subject": {"text": "the code optimization techniques to auto-vectorize the loop nests", "start": 0, "end": 65, "i_start": 0, "i_end": 10}, "verb": {"text": "require", "start": 106, "end": 113, "i_start": 19, "i_end": 19}}, {"character": {"text": "techniques", "start": 22, "end": 32, "i_start": 3, "i_end": 3}, "action": {"text": "require", "start": 106, "end": 113, "i_start": 19, "i_end": 19}}, {"character": {"text": "data", "start": 134, "end": 138, "i_start": 23, "i_end": 23}, "action": {"text": "dependences", "start": 139, "end": 150, "i_start": 24, "i_end": 24}}], "id": 750}, {"sent": "roughly , a spacetime is the arena in which all physical events take place .", "tokens": ["roughly", ",", "a", "spacetime", "is", "the", "arena", "in", "which", "all", "physical", "events", "take", "place", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a spacetime", "start": 10, "end": 21, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}], "id": 751}, {"sent": "it is well known that the collections of images of a convex lambertian object typically lies close to a low-dimensional subspace .", "tokens": ["it", "is", "well", "known", "that", "the", "collections", "of", "images", "of", "a", "convex", "lambertian", "object", "typically", "lies", "close", "to", "a", "low", "-", "dimensional", "subspace", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the collections of images of a convex lambertian object", "start": 22, "end": 77, "i_start": 5, "i_end": 13}, "verb": {"text": "lies", "start": 88, "end": 92, "i_start": 15, "i_end": 15}}], "id": 752}, {"sent": "belyavskaya are not isotopi to prolongations obtained by the method proposed by v .", "tokens": ["belyavskaya", "are", "not", "isotopi", "to", "prolongations", "obtained", "by", "the", "method", "proposed", "by", "v", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "belyavskaya", "start": 0, "end": 11, "i_start": 0, "i_end": 0}, "verb": {"text": "are not", "start": 12, "end": 19, "i_start": 1, "i_end": 2}}, {"character": {"text": "method", "start": 61, "end": 67, "i_start": 9, "i_end": 9}, "action": {"text": "obtained", "start": 45, "end": 53, "i_start": 6, "i_end": 6}}], "id": 753}, {"sent": "the second and third convolutional layers are followed by batch normalization .", "tokens": ["the", "second", "and", "third", "convolutional", "layers", "are", "followed", "by", "batch", "normalization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the second and third convolutional layers", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "are followed", "start": 42, "end": 54, "i_start": 6, "i_end": 7}}], "id": 754}, {"sent": "in recent years , deep convolutional neural networks have demonstrated dramatic improvements in performance for computer vision tasks such as object classification , detection , and segmentation .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "demonstrated", "dramatic", "improvements", "in", "performance", "for", "computer", "vision", "tasks", "such", "as", "object", "classification", ",", "detection", ",", "and", "segmentation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have demonstrated", "start": 53, "end": 70, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "demonstrated", "start": 58, "end": 70, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "improvements", "start": 80, "end": 92, "i_start": 11, "i_end": 11}}], "id": 755}, {"sent": "deep neural networks have been found to be quite effective for solving problems in the domain of computer vision .", "tokens": ["deep", "neural", "networks", "have", "been", "found", "to", "be", "quite", "effective", "for", "solving", "problems", "in", "the", "domain", "of", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been found", "start": 21, "end": 36, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "effective", "start": 49, "end": 58, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "solving", "start": 63, "end": 70, "i_start": 11, "i_end": 11}}], "id": 756}, {"sent": "we use similar method as to stitch the two images , but we use surf instead of sift to do the feature matching since surf is more efficient than sift .", "tokens": ["we", "use", "similar", "method", "as", "to", "stitch", "the", "two", "images", ",", "but", "we", "use", "surf", "instead", "of", "sift", "to", "do", "the", "feature", "matching", "since", "surf", "is", "more", "efficient", "than", "sift", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 56, "end": 58, "i_start": 12, "i_end": 12}, "verb": {"text": "use", "start": 59, "end": 62, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "stitch", "start": 28, "end": 34, "i_start": 6, "i_end": 6}}], "id": 757}, {"sent": "we show that the sufficient conditions for our scheme , are indeed necessary conditions for the slepian-wolf coding over arbitrary aref networks and linear finitefield cooperative relay networks .", "tokens": ["we", "show", "that", "the", "sufficient", "conditions", "for", "our", "scheme", ",", "are", "indeed", "necessary", "conditions", "for", "the", "slepian", "-", "wolf", "coding", "over", "arbitrary", "aref", "networks", "and", "linear", "finitefield", "cooperative", "relay", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 56, "end": 59, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "conditions", "start": 28, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "sufficient", "start": 17, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 186, "end": 194, "i_start": 29, "i_end": 29}, "action": {"text": "relay", "start": 180, "end": 185, "i_start": 28, "i_end": 28}}], "id": 758}, {"sent": "in section 4 , we discuss inconsistency analysis in preferential multi-context systems .", "tokens": ["in", "section", "4", ",", "we", "discuss", "inconsistency", "analysis", "in", "preferential", "multi", "-", "context", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "discuss", "start": 18, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "discuss", "start": 18, "end": 25, "i_start": 5, "i_end": 5}}], "id": 759}, {"sent": "invariance of proper 4-volume is a propery of tensor calculus and coordinate transfor mation .", "tokens": ["invariance", "of", "proper", "4", "-", "volume", "is", "a", "propery", "of", "tensor", "calculus", "and", "coordinate", "transfor", "mation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "invariance of proper 4-volume", "start": 0, "end": 29, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 6, "i_end": 6}}, {"subject": {"text": "invariance of proper 4-volume", "start": 0, "end": 29, "i_start": 0, "i_end": 5}, "verb": {"text": "coordinate", "start": 66, "end": 76, "i_start": 13, "i_end": 13}}], "id": 760}, {"sent": "a way out of it , proposed by steve smale , is to assume a probability measure on the space of data and to study the condition number c at data a as a random variable .", "tokens": ["a", "way", "out", "of", "it", ",", "proposed", "by", "steve", "smale", ",", "is", "to", "assume", "a", "probability", "measure", "on", "the", "space", "of", "data", "and", "to", "study", "the", "condition", "number", "c", "at", "data", "a", "as", "a", "random", "variable", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a way out of it", "start": 0, "end": 15, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 44, "end": 46, "i_start": 11, "i_end": 11}}, {"character": {"text": "steve smale", "start": 30, "end": 41, "i_start": 8, "i_end": 9}, "action": {"text": "proposed", "start": 18, "end": 26, "i_start": 6, "i_end": 6}}], "id": 761}, {"sent": "additionally , we consider natural language inference with snli .", "tokens": ["additionally", ",", "we", "consider", "natural", "language", "inference", "with", "snli", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "consider", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "consider", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}], "id": 762}, {"sent": "the only stable solution is a stationary one .", "tokens": ["the", "only", "stable", "solution", "is", "a", "stationary", "one", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the only stable solution", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 4, "i_end": 4}}], "id": 763}, {"sent": "whittle proposed a gittins-like indexing heuristic for the restless bandit problems .", "tokens": ["whittle", "proposed", "a", "gittins", "-", "like", "indexing", "heuristic", "for", "the", "restless", "bandit", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "whittle", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 8, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "bandit", "start": 68, "end": 74, "i_start": 11, "i_end": 11}, "action": {"text": "restless", "start": 59, "end": 67, "i_start": 10, "i_end": 10}}], "id": 764}, {"sent": "pioneering contributions in that direction are hong and li , who coined the names of laplace spectrum and laplace periodogram .", "tokens": ["pioneering", "contributions", "in", "that", "direction", "are", "hong", "and", "li", ",", "who", "coined", "the", "names", "of", "laplace", "spectrum", "and", "laplace", "periodogram", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "pioneering contributions in that direction", "start": 0, "end": 42, "i_start": 0, "i_end": 4}, "verb": {"text": "are", "start": 43, "end": 46, "i_start": 5, "i_end": 5}}, {"character": {"text": "hong", "start": 47, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "contributions", "start": 11, "end": 24, "i_start": 1, "i_end": 1}}, {"character": {"text": "li", "start": 56, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "contributions", "start": 11, "end": 24, "i_start": 1, "i_end": 1}}, {"character": {"text": "spectrum", "start": 93, "end": 101, "i_start": 16, "i_end": 16}, "action": {"text": "contributions", "start": 11, "end": 24, "i_start": 1, "i_end": 1}}, {"character": {"text": "laplace", "start": 85, "end": 92, "i_start": 15, "i_end": 15}, "action": {"text": "contributions", "start": 11, "end": 24, "i_start": 1, "i_end": 1}}, {"character": {"text": "periodogram", "start": 114, "end": 125, "i_start": 19, "i_end": 19}, "action": {"text": "contributions", "start": 11, "end": 24, "i_start": 1, "i_end": 1}}, {"character": {"text": "laplace", "start": 85, "end": 92, "i_start": 15, "i_end": 15}, "action": {"text": "contributions", "start": 11, "end": 24, "i_start": 1, "i_end": 1}}, {"character": {"text": "and", "start": 52, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "coined", "start": 65, "end": 71, "i_start": 11, "i_end": 11}}], "id": 765}, {"sent": "quandle modules we now study the specialisation of rack modules to the subcategory quandle .", "tokens": ["quandle", "modules", "we", "now", "study", "the", "specialisation", "of", "rack", "modules", "to", "the", "subcategory", "quandle", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 16, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "study", "start": 23, "end": 28, "i_start": 4, "i_end": 4}}], "id": 766}, {"sent": "from early hugo , the past few years witness the flourish of additive schemes in spatial domain .", "tokens": ["from", "early", "hugo", ",", "the", "past", "few", "years", "witness", "the", "flourish", "of", "additive", "schemes", "in", "spatial", "domain", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the past few years", "start": 18, "end": 36, "i_start": 4, "i_end": 7}, "verb": {"text": "witness", "start": 37, "end": 44, "i_start": 8, "i_end": 8}}, {"character": {"text": "few", "start": 27, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "witness", "start": 37, "end": 44, "i_start": 8, "i_end": 8}}, {"character": {"text": "schemes", "start": 70, "end": 77, "i_start": 13, "i_end": 13}, "action": {"text": "flourish", "start": 49, "end": 57, "i_start": 10, "i_end": 10}}], "id": 767}, {"sent": "multitaper methods for spectral estimation use special data tapers .", "tokens": ["multitaper", "methods", "for", "spectral", "estimation", "use", "special", "data", "tapers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "multitaper methods for spectral estimation", "start": 0, "end": 42, "i_start": 0, "i_end": 4}, "verb": {"text": "use", "start": 43, "end": 46, "i_start": 5, "i_end": 5}}, {"character": {"text": "methods", "start": 11, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "use", "start": 43, "end": 46, "i_start": 5, "i_end": 5}}], "id": 768}, {"sent": "to this end , we will count the number of zero modes by using an index theorem technique .", "tokens": ["to", "this", "end", ",", "we", "will", "count", "the", "number", "of", "zero", "modes", "by", "using", "an", "index", "theorem", "technique", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "verb": {"text": "will count", "start": 17, "end": 27, "i_start": 5, "i_end": 6}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "count", "start": 22, "end": 27, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "using", "start": 56, "end": 61, "i_start": 13, "i_end": 13}}], "id": 769}, {"sent": "the ion channels are formed by specific membrane proteins which undergo a spontaneous , voltage-sensing conformational transitions between the open and the closed states .", "tokens": ["the", "ion", "channels", "are", "formed", "by", "specific", "membrane", "proteins", "which", "undergo", "a", "spontaneous", ",", "voltage", "-", "sensing", "conformational", "transitions", "between", "the", "open", "and", "the", "closed", "states", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ion channels", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "are formed", "start": 17, "end": 27, "i_start": 3, "i_end": 4}}, {"character": {"text": "proteins", "start": 49, "end": 57, "i_start": 8, "i_end": 8}, "action": {"text": "formed", "start": 21, "end": 27, "i_start": 4, "i_end": 4}}], "id": 770}, {"sent": "moreover , we determine the iso morphic classes of the generalized simple lie algebras of witt type .", "tokens": ["moreover", ",", "we", "determine", "the", "iso", "morphic", "classes", "of", "the", "generalized", "simple", "lie", "algebras", "of", "witt", "type", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "verb": {"text": "determine", "start": 14, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "determine", "start": 14, "end": 23, "i_start": 3, "i_end": 3}}], "id": 771}, {"sent": "the risk of overfitting by co-adapting units is reduced by implementing dropout between individual neural network layers .", "tokens": ["the", "risk", "of", "overfitting", "by", "co", "-", "adapting", "units", "is", "reduced", "by", "implementing", "dropout", "between", "individual", "neural", "network", "layers", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "the risk of overfitting by co-adapting units", "start": 0, "end": 44, "i_start": 0, "i_end": 8}, "verb": {"text": "is reduced", "start": 45, "end": 55, "i_start": 9, "i_end": 10}}, {"character": {"text": "implementing", "start": 59, "end": 71, "i_start": 12, "i_end": 12}, "action": {"text": "reduced", "start": 48, "end": 55, "i_start": 10, "i_end": 10}}], "id": 772}, {"sent": "the chemical potential is a function of the band-filling n , the inverse temperature \u03b2 and the electron hopping energy t .", "tokens": ["the", "chemical", "potential", "is", "a", "function", "of", "the", "band", "-", "filling", "n", ",", "the", "inverse", "temperature", "\u03b2", "and", "the", "electron", "hopping", "energy", "t", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the chemical potential", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "n", "start": 57, "end": 58, "i_start": 11, "i_end": 11}, "action": {"text": "function", "start": 28, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "temperature \u03b2", "start": 73, "end": 86, "i_start": 15, "i_end": 16}, "action": {"text": "function", "start": 28, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "energy t", "start": 112, "end": 120, "i_start": 21, "i_end": 22}, "action": {"text": "function", "start": 28, "end": 36, "i_start": 5, "i_end": 5}}], "id": 773}, {"sent": "indeed , as shown in , they can always be written as the direct sum of abelian lie 3-algebras plus multiple copies of the unique simple euclidean lie 3-algebra considered by bagger and lambert in their original construction .", "tokens": ["indeed", ",", "as", "shown", "in", ",", "they", "can", "always", "be", "written", "as", "the", "direct", "sum", "of", "abelian", "lie", "3", "-", "algebras", "plus", "multiple", "copies", "of", "the", "unique", "simple", "euclidean", "lie", "3", "-", "algebra", "considered", "by", "bagger", "and", "lambert", "in", "their", "original", "construction", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 23, "end": 27, "i_start": 6, "i_end": 6}, "verb": {"text": "be written", "start": 39, "end": 49, "i_start": 9, "i_end": 10}}, {"subject": {"text": "they", "start": 23, "end": 27, "i_start": 6, "i_end": 6}, "verb": {"text": "can", "start": 28, "end": 31, "i_start": 7, "i_end": 7}}, {"character": {"text": "bagger", "start": 174, "end": 180, "i_start": 35, "i_end": 35}, "action": {"text": "considered", "start": 160, "end": 170, "i_start": 33, "i_end": 33}}, {"character": {"text": "lambert", "start": 185, "end": 192, "i_start": 37, "i_end": 37}, "action": {"text": "considered", "start": 160, "end": 170, "i_start": 33, "i_end": 33}}], "id": 774}, {"sent": "convolutional neural networks have achieved great success in visual recognition in recent years .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "visual", "recognition", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "recognition", "start": 68, "end": 79, "i_start": 9, "i_end": 9}}], "id": 775}, {"sent": "recently , deep neural network based methods have lead to breakthroughs in several vision tasks , such as classification .", "tokens": ["recently", ",", "deep", "neural", "network", "based", "methods", "have", "lead", "to", "breakthroughs", "in", "several", "vision", "tasks", ",", "such", "as", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural network based methods", "start": 11, "end": 44, "i_start": 2, "i_end": 6}, "verb": {"text": "have lead", "start": 45, "end": 54, "i_start": 7, "i_end": 8}}, {"character": {"text": "methods", "start": 37, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "lead", "start": 50, "end": 54, "i_start": 8, "i_end": 8}}], "id": 776}, {"sent": "generative adversarial networks are one of the main groups of methods used to learn generative models from complicated real-world data .", "tokens": ["generative", "adversarial", "networks", "are", "one", "of", "the", "main", "groups", "of", "methods", "used", "to", "learn", "generative", "models", "from", "complicated", "real", "-", "world", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}], "id": 777}, {"sent": "there have been many follow-up cnn architectures to further boost image classification , including vggnet , etc .", "tokens": ["there", "have", "been", "many", "follow", "-", "up", "cnn", "architectures", "to", "further", "boost", "image", "classification", ",", "including", "vggnet", ",", "etc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "have been", "start": 6, "end": 15, "i_start": 1, "i_end": 2}}], "id": 778}, {"sent": "as fully data driven approaches , cnns have shown satisfying performance in various computer vision tasks .", "tokens": ["as", "fully", "data", "driven", "approaches", ",", "cnns", "have", "shown", "satisfying", "performance", "in", "various", "computer", "vision", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cnns", "start": 34, "end": 38, "i_start": 6, "i_end": 6}, "verb": {"text": "have shown", "start": 39, "end": 49, "i_start": 7, "i_end": 8}}, {"character": {"text": "performance", "start": 61, "end": 72, "i_start": 10, "i_end": 10}, "action": {"text": "satisfying", "start": 50, "end": 60, "i_start": 9, "i_end": 9}}, {"character": {"text": "data", "start": 9, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "driven", "start": 14, "end": 20, "i_start": 3, "i_end": 3}}], "id": 779}, {"sent": "deep neural networks have been shown to be effective for solving many computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "been", "shown", "to", "be", "effective", "for", "solving", "many", "computer", "vision", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been shown", "start": 21, "end": 36, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "effective", "start": 43, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "solving", "start": 57, "end": 64, "i_start": 10, "i_end": 10}}], "id": 780}, {"sent": "to overcome these problems , a non-parametric approach using kernel density estimation technique was proposed in , which estimates the probability density function at each pixel from many samples without any prior assumptions .", "tokens": ["to", "overcome", "these", "problems", ",", "a", "non", "-", "parametric", "approach", "using", "kernel", "density", "estimation", "technique", "was", "proposed", "in", ",", "which", "estimates", "the", "probability", "density", "function", "at", "each", "pixel", "from", "many", "samples", "without", "any", "prior", "assumptions", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "a non-parametric approach using kernel density estimation technique", "start": 29, "end": 96, "i_start": 5, "i_end": 14}, "verb": {"text": "was proposed", "start": 97, "end": 109, "i_start": 15, "i_end": 16}}, {"character": {"text": "approach", "start": 46, "end": 54, "i_start": 9, "i_end": 9}, "action": {"text": "using", "start": 55, "end": 60, "i_start": 10, "i_end": 10}}], "id": 781}, {"sent": "though the results for the shear viscosity turned out to be quite robust , all evaluations of the shear and bulk viscosities obtained in the framework of the relaxation time approximation can be considered only as rough estimations .", "tokens": ["though", "the", "results", "for", "the", "shear", "viscosity", "turned", "out", "to", "be", "quite", "robust", ",", "all", "evaluations", "of", "the", "shear", "and", "bulk", "viscosities", "obtained", "in", "the", "framework", "of", "the", "relaxation", "time", "approximation", "can", "be", "considered", "only", "as", "rough", "estimations", "."], "score": [1, 1, 1, 1, 0], "labels": [{"subject": {"text": "all evaluations of the shear and bulk viscosities obtained in the framework of the relaxation time approximation", "start": 75, "end": 187, "i_start": 14, "i_end": 30}, "verb": {"text": "can be considered", "start": 188, "end": 205, "i_start": 31, "i_end": 33}}], "id": 782}, {"sent": "we employed the perdew-burke-ernzerhof exchange correlation functional in the generalized gradient approximation .", "tokens": ["we", "employed", "the", "perdew", "-", "burke", "-", "ernzerhof", "exchange", "correlation", "functional", "in", "the", "generalized", "gradient", "approximation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employed", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employed", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 783}, {"sent": "the electronelectron exchange and correlation functional was described with the perdew-burke-ernzerhof 22 parametrization of the generalized gradient approximation .", "tokens": ["the", "electronelectron", "exchange", "and", "correlation", "functional", "was", "described", "with", "the", "perdew", "-", "burke", "-", "ernzerhof", "22", "parametrization", "of", "the", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electronelectron exchange and correlation functional", "start": 0, "end": 56, "i_start": 0, "i_end": 5}, "verb": {"text": "was described", "start": 57, "end": 70, "i_start": 6, "i_end": 7}}], "id": 784}, {"sent": "recently , a novel structure called generative adversarial network has become extremely popular .", "tokens": ["recently", ",", "a", "novel", "structure", "called", "generative", "adversarial", "network", "has", "become", "extremely", "popular", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a novel structure called generative adversarial network", "start": 11, "end": 66, "i_start": 2, "i_end": 8}, "verb": {"text": "has become", "start": 67, "end": 77, "i_start": 9, "i_end": 10}}], "id": 785}, {"sent": "deep convolutional neural networks have been successful in many computer vision tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successful", "in", "many", "computer", "vision", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "successful", "start": 45, "end": 55, "i_start": 6, "i_end": 6}}], "id": 786}, {"sent": "liu et al proposed the nonparanormal , which uses the semiparametric gaussian copula for estimating the graph .", "tokens": ["liu", "et", "al", "proposed", "the", "nonparanormal", ",", "which", "uses", "the", "semiparametric", "gaussian", "copula", "for", "estimating", "the", "graph", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "liu et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "liu", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "liu", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "estimating", "start": 89, "end": 99, "i_start": 14, "i_end": 14}}], "id": 787}, {"sent": "a case study at google shows that developers issue an average of twelve code search queries per weekday .", "tokens": ["a", "case", "study", "at", "google", "shows", "that", "developers", "issue", "an", "average", "of", "twelve", "code", "search", "queries", "per", "weekday", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a case study at google", "start": 0, "end": 22, "i_start": 0, "i_end": 4}, "verb": {"text": "shows", "start": 23, "end": 28, "i_start": 5, "i_end": 5}}, {"subject": {"text": "developers", "start": 34, "end": 44, "i_start": 7, "i_end": 7}, "verb": {"text": "issue", "start": 45, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "study", "start": 7, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "shows", "start": 23, "end": 28, "i_start": 5, "i_end": 5}}], "id": 788}, {"sent": "hansen , cummings , clements , bou-ghazale , zhou , and kaiser used susas database in which eight talking conditions are used to simulate speech produced under real stressful talking conditions and three real talking conditions .", "tokens": ["hansen", ",", "cummings", ",", "clements", ",", "bou", "-", "ghazale", ",", "zhou", ",", "and", "kaiser", "used", "susas", "database", "in", "which", "eight", "talking", "conditions", "are", "used", "to", "simulate", "speech", "produced", "under", "real", "stressful", "talking", "conditions", "and", "three", "real", "talking", "conditions", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "hansen", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 63, "end": 67, "i_start": 14, "i_end": 14}}, {"character": {"text": "hansen", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 63, "end": 67, "i_start": 14, "i_end": 14}}, {"character": {"text": "cummings", "start": 9, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "used", "start": 63, "end": 67, "i_start": 14, "i_end": 14}}, {"character": {"text": "clements", "start": 20, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "used", "start": 63, "end": 67, "i_start": 14, "i_end": 14}}, {"character": {"text": "zhou", "start": 45, "end": 49, "i_start": 10, "i_end": 10}, "action": {"text": "used", "start": 63, "end": 67, "i_start": 14, "i_end": 14}}, {"character": {"text": "kaiser", "start": 56, "end": 62, "i_start": 13, "i_end": 13}, "action": {"text": "used", "start": 63, "end": 67, "i_start": 14, "i_end": 14}}], "id": 789}, {"sent": "convolutional neural networks have shown outstanding performance in many fundamental areas in computer vision , enabled by the availability of large-scale annotated datasets .", "tokens": ["convolutional", "neural", "networks", "have", "shown", "outstanding", "performance", "in", "many", "fundamental", "areas", "in", "computer", "vision", ",", "enabled", "by", "the", "availability", "of", "large", "-", "scale", "annotated", "datasets", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 35, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 6, "i_end": 6}}, {"character": {"text": "availability", "start": 127, "end": 139, "i_start": 18, "i_end": 18}, "action": {"text": "enabled", "start": 112, "end": 119, "i_start": 15, "i_end": 15}}], "id": 790}, {"sent": "several techniques have been proposed to reduce computation in neural networks , including weights pruning .", "tokens": ["several", "techniques", "have", "been", "proposed", "to", "reduce", "computation", "in", "neural", "networks", ",", "including", "weights", "pruning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "several techniques", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "have been proposed", "start": 19, "end": 37, "i_start": 2, "i_end": 4}}], "id": 791}, {"sent": "the systematic low-energy expansion of the s-matrix generated by lef f is called chiral perturbation theory .", "tokens": ["the", "systematic", "low", "-", "energy", "expansion", "of", "the", "s", "-", "matrix", "generated", "by", "lef", "f", "is", "called", "chiral", "perturbation", "theory", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the systematic low-energy expansion of the s-matrix generated by lef f", "start": 0, "end": 70, "i_start": 0, "i_end": 14}, "verb": {"text": "is called", "start": 71, "end": 80, "i_start": 15, "i_end": 16}}], "id": 792}, {"sent": "the perdew-burke-ernzerhof 96 of the generalized gradient approximation is used for exchange-correlation potential .", "tokens": ["the", "perdew", "-", "burke", "-", "ernzerhof", "96", "of", "the", "generalized", "gradient", "approximation", "is", "used", "for", "exchange", "-", "correlation", "potential", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the perdew-burke-ernzerhof 96 of the generalized gradient approximation", "start": 0, "end": 71, "i_start": 0, "i_end": 11}, "verb": {"text": "is used", "start": 72, "end": 79, "i_start": 12, "i_end": 13}}], "id": 793}, {"sent": "the present result clearly shows that the oxygen-isotope effect observed in the argon annealed samples may not be intrinsic , and that the normal isotope exchange procedure can ensure the same oxygen content for two isotope samples and thus produce an intrinsic isotope effect .", "tokens": ["the", "present", "result", "clearly", "shows", "that", "the", "oxygen", "-", "isotope", "effect", "observed", "in", "the", "argon", "annealed", "samples", "may", "not", "be", "intrinsic", ",", "and", "that", "the", "normal", "isotope", "exchange", "procedure", "can", "ensure", "the", "same", "oxygen", "content", "for", "two", "isotope", "samples", "and", "thus", "produce", "an", "intrinsic", "isotope", "effect", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the present result", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "shows", "start": 27, "end": 32, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the present result", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "be", "start": 111, "end": 113, "i_start": 19, "i_end": 19}}, {"character": {"text": "result", "start": 12, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "shows", "start": 27, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "samples", "start": 95, "end": 102, "i_start": 16, "i_end": 16}, "action": {"text": "observed", "start": 64, "end": 72, "i_start": 11, "i_end": 11}}, {"character": {"text": "procedure", "start": 163, "end": 172, "i_start": 28, "i_end": 28}, "action": {"text": "ensure", "start": 177, "end": 183, "i_start": 30, "i_end": 30}}, {"character": {"text": "procedure", "start": 163, "end": 172, "i_start": 28, "i_end": 28}, "action": {"text": "produce", "start": 241, "end": 248, "i_start": 41, "i_end": 41}}], "id": 794}, {"sent": "dirac observed in 1931 that charge quantisation could be understood as a consequence of angular momentum conservation if a pole of magnetic charge existed .", "tokens": ["dirac", "observed", "in", "1931", "that", "charge", "quantisation", "could", "be", "understood", "as", "a", "consequence", "of", "angular", "momentum", "conservation", "if", "a", "pole", "of", "magnetic", "charge", "existed", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "dirac", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "observed", "start": 6, "end": 14, "i_start": 1, "i_end": 1}}, {"subject": {"text": "that charge quantisation", "start": 23, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "understood", "start": 57, "end": 67, "i_start": 9, "i_end": 9}}, {"character": {"text": "dirac", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "observed", "start": 6, "end": 14, "i_start": 1, "i_end": 1}}], "id": 795}, {"sent": "the right column shows four different rotation-curve decompositions .", "tokens": ["the", "right", "column", "shows", "four", "different", "rotation", "-", "curve", "decompositions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the right column", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "shows", "start": 17, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "column", "start": 10, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "shows", "start": 17, "end": 22, "i_start": 3, "i_end": 3}}], "id": 796}, {"sent": "it is quite interesting whether the present weak contact scheme can be applied to systems other than the sheared fluid .", "tokens": ["it", "is", "quite", "interesting", "whether", "the", "present", "weak", "contact", "scheme", "can", "be", "applied", "to", "systems", "other", "than", "the", "sheared", "fluid", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the present weak contact scheme", "start": 32, "end": 63, "i_start": 5, "i_end": 9}, "verb": {"text": "applied", "start": 71, "end": 78, "i_start": 12, "i_end": 12}}], "id": 797}, {"sent": "this means , that we can reduce our case to the situation with bounded plane domain d b , considered in .", "tokens": ["this", "means", ",", "that", "we", "can", "reduce", "our", "case", "to", "the", "situation", "with", "bounded", "plane", "domain", "d", "b", ",", "considered", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "means", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "reduce", "start": 25, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "reduce", "start": 25, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "case", "start": 36, "end": 40, "i_start": 8, "i_end": 8}}], "id": 798}, {"sent": "in fact , the data transmit power takes only a small share of the total power consumption when moving towards 5g networks .", "tokens": ["in", "fact", ",", "the", "data", "transmit", "power", "takes", "only", "a", "small", "share", "of", "the", "total", "power", "consumption", "when", "moving", "towards", "5", "g", "networks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the data", "start": 10, "end": 18, "i_start": 3, "i_end": 4}, "verb": {"text": "transmit", "start": 19, "end": 27, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the data", "start": 10, "end": 18, "i_start": 3, "i_end": 4}, "verb": {"text": "takes", "start": 34, "end": 39, "i_start": 7, "i_end": 7}}, {"character": {"text": "power", "start": 28, "end": 33, "i_start": 6, "i_end": 6}, "action": {"text": "takes", "start": 34, "end": 39, "i_start": 7, "i_end": 7}}, {"character": {"text": "power", "start": 28, "end": 33, "i_start": 6, "i_end": 6}, "action": {"text": "transmit", "start": 19, "end": 27, "i_start": 5, "i_end": 5}}], "id": 799}, {"sent": "gong et al presented a structure-sensitive learning to enforce the produced parsing results semantically consistent with the human joint structures .", "tokens": ["gong", "et", "al", "presented", "a", "structure", "-", "sensitive", "learning", "to", "enforce", "the", "produced", "parsing", "results", "semantically", "consistent", "with", "the", "human", "joint", "structures", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "gong et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "presented", "start": 11, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "gong", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "presented", "start": 11, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "gong", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "learning", "start": 43, "end": 51, "i_start": 8, "i_end": 8}}, {"character": {"text": "gong", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "sensitive", "start": 33, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "gong", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "enforce", "start": 55, "end": 62, "i_start": 10, "i_end": 10}}], "id": 800}, {"sent": "the effect of non-gaussian curvature perturbations on the formation of primordial black holes .", "tokens": ["the", "effect", "of", "non", "-", "gaussian", "curvature", "perturbations", "on", "the", "formation", "of", "primordial", "black", "holes", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 801}, {"sent": "the evolution equations for the spacetime and the fluid are already described in our previous paper .", "tokens": ["the", "evolution", "equations", "for", "the", "spacetime", "and", "the", "fluid", "are", "already", "described", "in", "our", "previous", "paper", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "the evolution equations for the spacetime and the fluid", "start": 0, "end": 55, "i_start": 0, "i_end": 8}, "verb": {"text": "described", "start": 68, "end": 77, "i_start": 11, "i_end": 11}}, {"subject": {"text": "the evolution equations for the spacetime and the fluid", "start": 0, "end": 55, "i_start": 0, "i_end": 8}, "verb": {"text": "are", "start": 56, "end": 59, "i_start": 9, "i_end": 9}}, {"character": {"text": "paper", "start": 94, "end": 99, "i_start": 15, "i_end": 15}, "action": {"text": "described", "start": 68, "end": 77, "i_start": 11, "i_end": 11}}], "id": 802}, {"sent": "we evaluate our method using the celeba dataset , which consists of 40 facial attribute labels and 202,599 images .", "tokens": ["we", "evaluate", "our", "method", "using", "the", "celeba", "dataset", ",", "which", "consists", "of", "40", "facial", "attribute", "labels", "and", "202,599", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 803}, {"sent": "in conclusion , we have used magnetotunneling spectroscopy to observe the spin splitting of the ground state of si donor impurities in an alas tunnel barrier .", "tokens": ["in", "conclusion", ",", "we", "have", "used", "magnetotunneling", "spectroscopy", "to", "observe", "the", "spin", "splitting", "of", "the", "ground", "state", "of", "si", "donor", "impurities", "in", "an", "alas", "tunnel", "barrier", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "have used", "start": 19, "end": 28, "i_start": 4, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "used", "start": 24, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "observe", "start": 62, "end": 69, "i_start": 9, "i_end": 9}}], "id": 804}, {"sent": "data-driven approaches , in particular , deep learning with convolutional neural networks , have recently attained great success in many computer vision tasks such as image classification .", "tokens": ["data", "-", "driven", "approaches", ",", "in", "particular", ",", "deep", "learning", "with", "convolutional", "neural", "networks", ",", "have", "recently", "attained", "great", "success", "in", "many", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "data-driven approaches", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "attained", "start": 106, "end": 114, "i_start": 17, "i_end": 17}}, {"subject": {"text": "data-driven approaches", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 92, "end": 96, "i_start": 15, "i_end": 15}}, {"character": {"text": "approaches", "start": 12, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "attained", "start": 106, "end": 114, "i_start": 17, "i_end": 17}}, {"character": {"text": "data", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "driven", "start": 5, "end": 11, "i_start": 2, "i_end": 2}}], "id": 805}, {"sent": "the concept of packing chromatic number was introduced by goddard et al under the name broadcast chromatic number .", "tokens": ["the", "concept", "of", "packing", "chromatic", "number", "was", "introduced", "by", "goddard", "et", "al", "under", "the", "name", "broadcast", "chromatic", "number", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the concept of packing chromatic number", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "was introduced", "start": 40, "end": 54, "i_start": 6, "i_end": 7}}, {"character": {"text": "goddard", "start": 58, "end": 65, "i_start": 9, "i_end": 9}, "action": {"text": "introduced", "start": 44, "end": 54, "i_start": 7, "i_end": 7}}], "id": 806}, {"sent": "deep neural networks have significantly advanced the state-of-the-art performance for various machine learning problems .", "tokens": ["deep", "neural", "networks", "have", "significantly", "advanced", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "for", "various", "machine", "learning", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "advanced", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "advanced", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}], "id": 807}, {"sent": "the markov chain is a mathematical model that is defined by initial probabilities p is necessary .", "tokens": ["the", "markov", "chain", "is", "a", "mathematical", "model", "that", "is", "defined", "by", "initial", "probabilities", "p", "is", "necessary", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the markov chain", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "probabilities", "start": 68, "end": 81, "i_start": 12, "i_end": 12}, "action": {"text": "defined", "start": 49, "end": 56, "i_start": 9, "i_end": 9}}], "id": 808}, {"sent": "colloquially , the palette is the set of colors to which an edge can be changed .", "tokens": ["colloquially", ",", "the", "palette", "is", "the", "set", "of", "colors", "to", "which", "an", "edge", "can", "be", "changed", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the palette", "start": 15, "end": 26, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 4, "i_end": 4}}], "id": 809}, {"sent": "mean freeze-out times for different hadron species at sps , rhic and lhc .", "tokens": ["mean", "freeze", "-", "out", "times", "for", "different", "hadron", "species", "at", "sps", ",", "rhic", "and", "lhc", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 810}, {"sent": "preliminaries and notation let a denote a finite-dimensional indecomposable algebra over a field k and a-mod the category of finite-dimensional left a-modules .", "tokens": ["preliminaries", "and", "notation", "let", "a", "denote", "a", "finite", "-", "dimensional", "indecomposable", "algebra", "over", "a", "field", "k", "and", "a", "-", "mod", "the", "category", "of", "finite", "-", "dimensional", "left", "a", "-", "modules", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "preliminaries and notation", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "let", "start": 27, "end": 30, "i_start": 3, "i_end": 3}}, {"subject": {"text": "a denote a finite-dimensional indecomposable algebra over a field k and a-mod the category of finite-dimensional", "start": 31, "end": 143, "i_start": 4, "i_end": 25}, "verb": {"text": "left", "start": 144, "end": 148, "i_start": 26, "i_end": 26}}, {"character": {"text": "preliminaries", "start": 0, "end": 13, "i_start": 0, "i_end": 0}, "action": {"text": "let", "start": 27, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "notation", "start": 18, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "let", "start": 27, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "preliminaries", "start": 0, "end": 13, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 33, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "notation", "start": 18, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "denote", "start": 33, "end": 39, "i_start": 5, "i_end": 5}}], "id": 811}, {"sent": "the simplest examples of particles with exotic braiding statistics are called anyons .", "tokens": ["the", "simplest", "examples", "of", "particles", "with", "exotic", "braiding", "statistics", "are", "called", "anyons", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the simplest examples of particles with exotic braiding statistics", "start": 0, "end": 66, "i_start": 0, "i_end": 8}, "verb": {"text": "are called", "start": 67, "end": 77, "i_start": 9, "i_end": 10}}], "id": 812}, {"sent": "therefore , the initially broken charge conjugation symmetry is not restored at high temperature .", "tokens": ["therefore", ",", "the", "initially", "broken", "charge", "conjugation", "symmetry", "is", "not", "restored", "at", "high", "temperature", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the initially broken charge conjugation symmetry", "start": 12, "end": 60, "i_start": 2, "i_end": 7}, "verb": {"text": "is not restored", "start": 61, "end": 76, "i_start": 8, "i_end": 10}}], "id": 813}, {"sent": "recently , deep convolutional neural networks have taken the computer vision field by storm , significantly improving the state-of-the-art performances in many visual tasks , such as face recognition .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "taken", "the", "computer", "vision", "field", "by", "storm", ",", "significantly", "improving", "the", "state", "-", "of", "-", "the", "-", "art", "performances", "in", "many", "visual", "tasks", ",", "such", "as", "face", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have taken", "start": 46, "end": 56, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "taken", "start": 51, "end": 56, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "improving", "start": 108, "end": 117, "i_start": 16, "i_end": 16}}], "id": 814}, {"sent": "for convenience this same notation will denote the denote the set of edges on the surface cardinalities of these sets .", "tokens": ["for", "convenience", "this", "same", "notation", "will", "denote", "the", "denote", "the", "set", "of", "edges", "on", "the", "surface", "cardinalities", "of", "these", "sets", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this same notation", "start": 16, "end": 34, "i_start": 2, "i_end": 4}, "verb": {"text": "will denote", "start": 35, "end": 46, "i_start": 5, "i_end": 6}}, {"character": {"text": "notation", "start": 26, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "denote", "start": 40, "end": 46, "i_start": 6, "i_end": 6}}], "id": 815}, {"sent": "for the pbf network , we replace the convolutional layers with those from either the alexnet .", "tokens": ["for", "the", "pbf", "network", ",", "we", "replace", "the", "convolutional", "layers", "with", "those", "from", "either", "the", "alexnet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 22, "end": 24, "i_start": 5, "i_end": 5}, "verb": {"text": "replace", "start": 25, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 5, "i_end": 5}, "action": {"text": "replace", "start": 25, "end": 32, "i_start": 6, "i_end": 6}}], "id": 816}, {"sent": "all phase transitions between them are of second-order .", "tokens": ["all", "phase", "transitions", "between", "them", "are", "of", "second", "-", "order", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all phase transitions between them", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "are", "start": 35, "end": 38, "i_start": 5, "i_end": 5}}], "id": 817}, {"sent": "a schematic outline of the relationship between coupled pattern and coupled climate network analysis in the spirit of the diagrams in bretherton et al .", "tokens": ["a", "schematic", "outline", "of", "the", "relationship", "between", "coupled", "pattern", "and", "coupled", "climate", "network", "analysis", "in", "the", "spirit", "of", "the", "diagrams", "in", "bretherton", "et", "al", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 818}, {"sent": "in this section , we compute the contribution of this displacement mechanism to the photoconductivity within our model .", "tokens": ["in", "this", "section", ",", "we", "compute", "the", "contribution", "of", "this", "displacement", "mechanism", "to", "the", "photoconductivity", "within", "our", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "compute", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "compute", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "mechanism", "start": 67, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "contribution", "start": 33, "end": 45, "i_start": 7, "i_end": 7}}], "id": 819}, {"sent": "for showing that positive transfer happened , we use the features from the imagenet-pretrained vgg-16 networks for the clustering method .", "tokens": ["for", "showing", "that", "positive", "transfer", "happened", ",", "we", "use", "the", "features", "from", "the", "imagenet", "-", "pretrained", "vgg-16", "networks", "for", "the", "clustering", "method", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 46, "end": 48, "i_start": 7, "i_end": 7}, "verb": {"text": "use", "start": 49, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 46, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "use", "start": 49, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 46, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "showing", "start": 4, "end": 11, "i_start": 1, "i_end": 1}}], "id": 820}, {"sent": "the 5the submillimeter array is a joint project between the smithsonian astrophysical observatory and the academia sinica institute of astronomy and astrophysics , and is funded by the smithsonian institution and the academia sinica .", "tokens": ["the", "5the", "submillimeter", "array", "is", "a", "joint", "project", "between", "the", "smithsonian", "astrophysical", "observatory", "and", "the", "academia", "sinica", "institute", "of", "astronomy", "and", "astrophysics", ",", "and", "is", "funded", "by", "the", "smithsonian", "institution", "and", "the", "academia", "sinica", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the 5the submillimeter array", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the 5the submillimeter array", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "funded", "start": 171, "end": 177, "i_start": 25, "i_end": 25}}, {"character": {"text": "institution", "start": 197, "end": 208, "i_start": 29, "i_end": 29}, "action": {"text": "funded", "start": 171, "end": 177, "i_start": 25, "i_end": 25}}, {"character": {"text": "smithsonian", "start": 60, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "funded", "start": 171, "end": 177, "i_start": 25, "i_end": 25}}, {"character": {"text": "academia sinica institute of astronomy and astrophysics", "start": 106, "end": 161, "i_start": 15, "i_end": 21}, "action": {"text": "funded", "start": 171, "end": 177, "i_start": 25, "i_end": 25}}], "id": 821}, {"sent": "his current research interests are in developing efficient dynamic routing protocols for mobile ad hoc networks , wireless networks management and security , and ad hoc networks modeling and simulation .", "tokens": ["his", "current", "research", "interests", "are", "in", "developing", "efficient", "dynamic", "routing", "protocols", "for", "mobile", "ad", "hoc", "networks", ",", "wireless", "networks", "management", "and", "security", ",", "and", "ad", "hoc", "networks", "modeling", "and", "simulation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "his current research interests", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 31, "end": 34, "i_start": 4, "i_end": 4}}], "id": 822}, {"sent": "in recent years , deep neural networks have achieved great success in a variety of machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "achieved", "great", "success", "in", "a", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}], "id": 823}, {"sent": "to adapt detector weights , tang et al gradually update the weights of webtrained detectors as they are applied to videos .", "tokens": ["to", "adapt", "detector", "weights", ",", "tang", "et", "al", "gradually", "update", "the", "weights", "of", "webtrained", "detectors", "as", "they", "are", "applied", "to", "videos", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 33, "end": 38, "i_start": 6, "i_end": 7}, "verb": {"text": "update", "start": 49, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "tang", "start": 28, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "update", "start": 49, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "tang", "start": 28, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "adapt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 824}, {"sent": "wakimoto , branching functions for winding subalgebras and tensor products , acta appl .", "tokens": ["wakimoto", ",", "branching", "functions", "for", "winding", "subalgebras", "and", "tensor", "products", ",", "acta", "appl", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "acta", "start": 77, "end": 81, "i_start": 11, "i_end": 11}, "verb": {"text": "appl", "start": 82, "end": 86, "i_start": 12, "i_end": 12}}], "id": 825}, {"sent": "in the remainder of this section we discuss the basic properties of the tetrain section two the quantum hedral chain hamiltonian .", "tokens": ["in", "the", "remainder", "of", "this", "section", "we", "discuss", "the", "basic", "properties", "of", "the", "tetrain", "section", "two", "the", "quantum", "hedral", "chain", "hamiltonian", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 33, "end": 35, "i_start": 6, "i_end": 6}, "verb": {"text": "discuss", "start": 36, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 33, "end": 35, "i_start": 6, "i_end": 6}, "action": {"text": "discuss", "start": 36, "end": 43, "i_start": 7, "i_end": 7}}], "id": 826}, {"sent": "vacuum is the state for which there is no field excitations but which still contains zeropoint field fluctuations .", "tokens": ["vacuum", "is", "the", "state", "for", "which", "there", "is", "no", "field", "excitations", "but", "which", "still", "contains", "zeropoint", "field", "fluctuations", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "vacuum", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 7, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "state", "start": 14, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "no field excitations", "start": 39, "end": 59, "i_start": 8, "i_end": 10}}, {"character": {"text": "vacuum", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "contains", "start": 76, "end": 84, "i_start": 14, "i_end": 14}}], "id": 827}, {"sent": "a major practical appeal of this approach stems from the availability of modern numerical tools which can compute various definitions of reachable sets .", "tokens": ["a", "major", "practical", "appeal", "of", "this", "approach", "stems", "from", "the", "availability", "of", "modern", "numerical", "tools", "which", "can", "compute", "various", "definitions", "of", "reachable", "sets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a major practical appeal of this approach", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "stems", "start": 42, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "tools", "start": 90, "end": 95, "i_start": 14, "i_end": 14}, "action": {"text": "compute", "start": 106, "end": 113, "i_start": 17, "i_end": 17}}], "id": 828}, {"sent": "massive multiple-input multiple-output is already considered as a core physical layer component for fifth generation , and beyond , broadband wireless networks .", "tokens": ["massive", "multiple", "-", "input", "multiple", "-", "output", "is", "already", "considered", "as", "a", "core", "physical", "layer", "component", "for", "fifth", "generation", ",", "and", "beyond", ",", "broadband", "wireless", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "massive multiple-input multiple-output", "start": 0, "end": 38, "i_start": 0, "i_end": 6}, "verb": {"text": "considered", "start": 50, "end": 60, "i_start": 9, "i_end": 9}}, {"subject": {"text": "massive multiple-input multiple-output", "start": 0, "end": 38, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 7, "i_end": 7}}], "id": 829}, {"sent": "deep learning is a subset of machine learning which refers to the use of highly multilayered neural networks to understand a complex dataset with the intention of predicting some features of that dataset .", "tokens": ["deep", "learning", "is", "a", "subset", "of", "machine", "learning", "which", "refers", "to", "the", "use", "of", "highly", "multilayered", "neural", "networks", "to", "understand", "a", "complex", "dataset", "with", "the", "intention", "of", "predicting", "some", "features", "of", "that", "dataset", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "networks", "start": 100, "end": 108, "i_start": 17, "i_end": 17}, "action": {"text": "understand", "start": 112, "end": 122, "i_start": 19, "i_end": 19}}, {"character": {"text": "networks", "start": 100, "end": 108, "i_start": 17, "i_end": 17}, "action": {"text": "predicting", "start": 163, "end": 173, "i_start": 27, "i_end": 27}}], "id": 830}, {"sent": "all convolution layers are followed by batch normalization nonlinear activation .", "tokens": ["all", "convolution", "layers", "are", "followed", "by", "batch", "normalization", "nonlinear", "activation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all convolution layers", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "are followed", "start": 23, "end": 35, "i_start": 3, "i_end": 4}}], "id": 831}, {"sent": "conjectures 3 and 4 have also been verified for outerplanar graphs , .", "tokens": ["conjectures", "3", "and", "4", "have", "also", "been", "verified", "for", "outerplanar", "graphs", ",", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "4", "start": 18, "end": 19, "i_start": 3, "i_end": 3}, "verb": {"text": "conjectures", "start": 0, "end": 11, "i_start": 0, "i_end": 0}}, {"subject": {"text": "4", "start": 18, "end": 19, "i_start": 3, "i_end": 3}, "verb": {"text": "verified", "start": 35, "end": 43, "i_start": 7, "i_end": 7}}], "id": 832}, {"sent": "consider now the case when we keep all the seven branes far away .", "tokens": ["consider", "now", "the", "case", "when", "we", "keep", "all", "the", "seven", "branes", "far", "away", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 27, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "keep", "start": 30, "end": 34, "i_start": 6, "i_end": 6}}], "id": 833}, {"sent": "deep neural networks have achieved outstanding performances on many computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "achieved", "outstanding", "performances", "on", "many", "computer", "vision", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performances", "start": 47, "end": 59, "i_start": 6, "i_end": 6}}], "id": 834}, {"sent": "the weights are optimized using the adam algorithm for stochastic gradient descent .", "tokens": ["the", "weights", "are", "optimized", "using", "the", "adam", "algorithm", "for", "stochastic", "gradient", "descent", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the weights", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "are optimized", "start": 12, "end": 25, "i_start": 2, "i_end": 3}}], "id": 835}, {"sent": "we tested our predictions by measuring the spread of messages in an organization and also by numerical experiments that take into consideration the organizational distance among individuals .", "tokens": ["we", "tested", "our", "predictions", "by", "measuring", "the", "spread", "of", "messages", "in", "an", "organization", "and", "also", "by", "numerical", "experiments", "that", "take", "into", "consideration", "the", "organizational", "distance", "among", "individuals", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "tested", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "tested", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "predictions", "start": 14, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "measuring", "start": 29, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "experiments", "start": 103, "end": 114, "i_start": 17, "i_end": 17}, "action": {"text": "take", "start": 120, "end": 124, "i_start": 19, "i_end": 19}}], "id": 836}, {"sent": "deep learning has lead to groundbreaking results in multiple fields such as natural language processing .", "tokens": ["deep", "learning", "has", "lead", "to", "groundbreaking", "results", "in", "multiple", "fields", "such", "as", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has lead", "start": 14, "end": 22, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "lead", "start": 18, "end": 22, "i_start": 3, "i_end": 3}}], "id": 837}, {"sent": "an example of a novel process that benefits from robots and cad versatility is the so-called incremental forming process of metal sheets .", "tokens": ["an", "example", "of", "a", "novel", "process", "that", "benefits", "from", "robots", "and", "cad", "versatility", "is", "the", "so", "-", "called", "incremental", "forming", "process", "of", "metal", "sheets", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "an example of a novel process that benefits from robots and cad versatility", "start": 0, "end": 75, "i_start": 0, "i_end": 12}, "verb": {"text": "is", "start": 76, "end": 78, "i_start": 13, "i_end": 13}}, {"character": {"text": "process", "start": 113, "end": 120, "i_start": 20, "i_end": 20}, "action": {"text": "benefits", "start": 35, "end": 43, "i_start": 7, "i_end": 7}}], "id": 838}, {"sent": "demonstration of threedimensional electrostatic trapping of state-selected rydberg atoms .", "tokens": ["demonstration", "of", "threedimensional", "electrostatic", "trapping", "of", "state", "-", "selected", "rydberg", "atoms", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "state", "start": 60, "end": 65, "i_start": 6, "i_end": 6}, "action": {"text": "selected", "start": 66, "end": 74, "i_start": 8, "i_end": 8}}], "id": 839}, {"sent": "this confirms the independent behaviour of narrow dws in thicker layers as discussed above .", "tokens": ["this", "confirms", "the", "independent", "behaviour", "of", "narrow", "dws", "in", "thicker", "layers", "as", "discussed", "above", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "confirms", "start": 5, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "confirms", "start": 5, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "dws", "start": 50, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "behaviour", "start": 30, "end": 39, "i_start": 4, "i_end": 4}}], "id": 840}, {"sent": "the deuteron is a weakly bound system and it is natural to assume that the deuteron polarizability is a sum of the polarizability due to relative motion of the nucleons and their internal polarizabilities .", "tokens": ["the", "deuteron", "is", "a", "weakly", "bound", "system", "and", "it", "is", "natural", "to", "assume", "that", "the", "deuteron", "polarizability", "is", "a", "sum", "of", "the", "polarizability", "due", "to", "relative", "motion", "of", "the", "nucleons", "and", "their", "internal", "polarizabilities", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the deuteron", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 841}, {"sent": "deep neural networks have shown improvement in state-of-the-art in different tasks , such as image classification .", "tokens": ["deep", "neural", "networks", "have", "shown", "improvement", "in", "state", "-", "of", "-", "the", "-", "art", "in", "different", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improvement", "start": 32, "end": 43, "i_start": 5, "i_end": 5}}], "id": 842}, {"sent": "the following theorems can be easily proved by any reader .", "tokens": ["the", "following", "theorems", "can", "be", "easily", "proved", "by", "any", "reader", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the following theorems", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "proved", "start": 37, "end": 43, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the following theorems", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "can be", "start": 23, "end": 29, "i_start": 3, "i_end": 4}}, {"character": {"text": "any", "start": 47, "end": 50, "i_start": 8, "i_end": 8}, "action": {"text": "proved", "start": 37, "end": 43, "i_start": 6, "i_end": 6}}], "id": 843}, {"sent": "in recent years , the deep learning models like the cnns have been shown to achieve superior performance in numerous visual perception tasks .", "tokens": ["in", "recent", "years", ",", "the", "deep", "learning", "models", "like", "the", "cnns", "have", "been", "shown", "to", "achieve", "superior", "performance", "in", "numerous", "visual", "perception", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the deep learning models like the cnns", "start": 18, "end": 56, "i_start": 4, "i_end": 10}, "verb": {"text": "have been shown", "start": 57, "end": 72, "i_start": 11, "i_end": 13}}, {"character": {"text": "models", "start": 36, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "achieve", "start": 76, "end": 83, "i_start": 15, "i_end": 15}}, {"character": {"text": "models", "start": 36, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "learning", "start": 27, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "models", "start": 36, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "performance", "start": 93, "end": 104, "i_start": 17, "i_end": 17}}], "id": 844}, {"sent": "in this section we focus on the system architecture and assumptions that are the same as those assumed in .", "tokens": ["in", "this", "section", "we", "focus", "on", "the", "system", "architecture", "and", "assumptions", "that", "are", "the", "same", "as", "those", "assumed", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "focus", "start": 19, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "focus", "start": 19, "end": 24, "i_start": 4, "i_end": 4}}], "id": 845}, {"sent": "deep neural networks have achieved considerable improvements in learning tasks with voluminous labeled data .", "tokens": ["deep", "neural", "networks", "have", "achieved", "considerable", "improvements", "in", "learning", "tasks", "with", "voluminous", "labeled", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improvements", "start": 48, "end": 60, "i_start": 6, "i_end": 6}}], "id": 846}, {"sent": "in recent years , deep neural networks have led to many breakthrough results in machine learning and computer vision , and are now widely deployed in industry .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "led", "to", "many", "breakthrough", "results", "in", "machine", "learning", "and", "computer", "vision", ",", "and", "are", "now", "widely", "deployed", "in", "industry", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have led", "start": 39, "end": 47, "i_start": 7, "i_end": 8}}, {"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "deployed", "start": 138, "end": 146, "i_start": 24, "i_end": 24}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "led", "start": 44, "end": 47, "i_start": 8, "i_end": 8}}], "id": 847}, {"sent": "planck is the next generation satellite , both more ambitious and riskier than wmap .", "tokens": ["planck", "is", "the", "next", "generation", "satellite", ",", "both", "more", "ambitious", "and", "riskier", "than", "wmap", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "planck", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 7, "end": 9, "i_start": 1, "i_end": 1}}], "id": 848}, {"sent": "the left panel shows the dressing functions and the right panel the propagators .", "tokens": ["the", "left", "panel", "shows", "the", "dressing", "functions", "and", "the", "right", "panel", "the", "propagators", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the left panel", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "shows", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "panel", "start": 9, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "shows", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}], "id": 849}, {"sent": "convolutional neural networks have found widespread use in computer vision .", "tokens": ["convolutional", "neural", "networks", "have", "found", "widespread", "use", "in", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have found", "start": 30, "end": 40, "i_start": 3, "i_end": 4}}], "id": 850}, {"sent": "let a be a k-algebra , we say that a is a quasi-coherent algebra .", "tokens": ["let", "a", "be", "a", "k", "-", "algebra", ",", "we", "say", "that", "a", "is", "a", "quasi", "-", "coherent", "algebra", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 23, "end": 25, "i_start": 8, "i_end": 8}, "verb": {"text": "say", "start": 26, "end": 29, "i_start": 9, "i_end": 9}}, {"subject": {"text": "we", "start": 23, "end": 25, "i_start": 8, "i_end": 8}, "verb": {"text": "is", "start": 37, "end": 39, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 8, "i_end": 8}, "action": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}], "id": 851}, {"sent": "in this paper , we want to investigate the constraints on n reh and t reh as functions of the scalar spectral index , n s , focusing on the class of the so-called string fiber inflation models .", "tokens": ["in", "this", "paper", ",", "we", "want", "to", "investigate", "the", "constraints", "on", "n", "reh", "and", "t", "reh", "as", "functions", "of", "the", "scalar", "spectral", "index", ",", "n", "s", ",", "focusing", "on", "the", "class", "of", "the", "so", "-", "called", "string", "fiber", "inflation", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "want", "start": 19, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "want", "start": 19, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "investigate", "start": 27, "end": 38, "i_start": 7, "i_end": 7}}, {"character": {"text": "index", "start": 110, "end": 115, "i_start": 22, "i_end": 22}, "action": {"text": "functions", "start": 77, "end": 86, "i_start": 17, "i_end": 17}}, {"character": {"text": "want", "start": 19, "end": 23, "i_start": 5, "i_end": 5}, "action": {"text": "focusing", "start": 124, "end": 132, "i_start": 27, "i_end": 27}}], "id": 852}, {"sent": "deep learning algorithms have yielded impressive performance across a range of tasks , including object and voice recognition .", "tokens": ["deep", "learning", "algorithms", "have", "yielded", "impressive", "performance", "across", "a", "range", "of", "tasks", ",", "including", "object", "and", "voice", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning algorithms", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "have yielded", "start": 25, "end": 37, "i_start": 3, "i_end": 4}}, {"character": {"text": "algorithms", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "yielded", "start": 30, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "algorithms", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "algorithms", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 49, "end": 60, "i_start": 6, "i_end": 6}}, {"character": {"text": "yielded", "start": 30, "end": 37, "i_start": 4, "i_end": 4}, "action": {"text": "impressive", "start": 38, "end": 48, "i_start": 5, "i_end": 5}}], "id": 853}, {"sent": "generative adversarial networks have produced high-quality results on a variety of tasks .", "tokens": ["generative", "adversarial", "networks", "have", "produced", "high", "-", "quality", "results", "on", "a", "variety", "of", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "have produced", "start": 32, "end": 45, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "produced", "start": 37, "end": 45, "i_start": 4, "i_end": 4}}], "id": 854}, {"sent": "we show that one can realize robust stationary optomechanical entanglement even in the presence of non-negligible laser phase noise .", "tokens": ["we", "show", "that", "one", "can", "realize", "robust", "stationary", "optomechanical", "entanglement", "even", "in", "the", "presence", "of", "non", "-", "negligible", "laser", "phase", "noise", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "one", "start": 13, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "realize", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "one", "start": 13, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "realize", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}], "id": 855}, {"sent": "supervised hashing with kernels is a kernel based method which learns compact binary codes by maximizing the separability between similar and dissimilar pairs in the hamming space .", "tokens": ["supervised", "hashing", "with", "kernels", "is", "a", "kernel", "based", "method", "which", "learns", "compact", "binary", "codes", "by", "maximizing", "the", "separability", "between", "similar", "and", "dissimilar", "pairs", "in", "the", "hamming", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "supervised hashing with kernels", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "method", "start": 50, "end": 56, "i_start": 8, "i_end": 8}, "action": {"text": "learns", "start": 63, "end": 69, "i_start": 10, "i_end": 10}}], "id": 856}, {"sent": "yang et al proposed a knowledge distillation paradigm for transferring useful information from a given teacher network to a portable student network .", "tokens": ["yang", "et", "al", "proposed", "a", "knowledge", "distillation", "paradigm", "for", "transferring", "useful", "information", "from", "a", "given", "teacher", "network", "to", "a", "portable", "student", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "yang et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "yang", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}], "id": 857}, {"sent": "there are many interesting phenomena when allowing p to grow with n , see , for example , but in this paper we consider the sparse case where p is fixed and does not depend on n .", "tokens": ["there", "are", "many", "interesting", "phenomena", "when", "allowing", "p", "to", "grow", "with", "n", ",", "see", ",", "for", "example", ",", "but", "in", "this", "paper", "we", "consider", "the", "sparse", "case", "where", "p", "is", "fixed", "and", "does", "not", "depend", "on", "n", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 6, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 108, "end": 110, "i_start": 22, "i_end": 22}, "verb": {"text": "consider", "start": 111, "end": 119, "i_start": 23, "i_end": 23}}], "id": 858}, {"sent": "from the above points of view , one may arrive at the conclusion that up to now there exists no single satisfactory regularization that can be applied to all purposes in qfts .", "tokens": ["from", "the", "above", "points", "of", "view", ",", "one", "may", "arrive", "at", "the", "conclusion", "that", "up", "to", "now", "there", "exists", "no", "single", "satisfactory", "regularization", "that", "can", "be", "applied", "to", "all", "purposes", "in", "qfts", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 32, "end": 35, "i_start": 7, "i_end": 7}, "verb": {"text": "may arrive", "start": 36, "end": 46, "i_start": 8, "i_end": 9}}, {"character": {"text": "one", "start": 32, "end": 35, "i_start": 7, "i_end": 7}, "action": {"text": "conclusion", "start": 54, "end": 64, "i_start": 12, "i_end": 12}}], "id": 859}, {"sent": "so this stencil is a projection of a good deformation 26 a .", "tokens": ["so", "this", "stencil", "is", "a", "projection", "of", "a", "good", "deformation", "26", "a", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this stencil", "start": 3, "end": 15, "i_start": 1, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 860}, {"sent": "another class of approaches adopts a nonlinear model to map noisy to clean speech signals .", "tokens": ["another", "class", "of", "approaches", "adopts", "a", "nonlinear", "model", "to", "map", "noisy", "to", "clean", "speech", "signals", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "another class of approaches", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "adopts", "start": 28, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "class", "start": 8, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "adopts", "start": 28, "end": 34, "i_start": 4, "i_end": 4}}], "id": 861}, {"sent": "the vacuum is a non-generic coherent state , for which this does not happen .", "tokens": ["the", "vacuum", "is", "a", "non", "-", "generic", "coherent", "state", ",", "for", "which", "this", "does", "not", "happen", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the vacuum", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}], "id": 862}, {"sent": "duality is a general concept relating physical quantities in different regions of the parameter space .", "tokens": ["duality", "is", "a", "general", "concept", "relating", "physical", "quantities", "in", "different", "regions", "of", "the", "parameter", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "duality", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "concept", "start": 21, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "relating", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}], "id": 863}, {"sent": "deep learning has had a tremendous impact in several fields , such as image processing and natural language processing .", "tokens": ["deep", "learning", "has", "had", "a", "tremendous", "impact", "in", "several", "fields", ",", "such", "as", "image", "processing", "and", "natural", "language", "processing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has had", "start": 14, "end": 21, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "impact", "start": 35, "end": 41, "i_start": 6, "i_end": 6}}], "id": 864}, {"sent": "the study of noncommutative gauge theories has been a popular subject since their relation to matrix theory has been understood .", "tokens": ["the", "study", "of", "noncommutative", "gauge", "theories", "has", "been", "a", "popular", "subject", "since", "their", "relation", "to", "matrix", "theory", "has", "been", "understood", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the study of noncommutative gauge theories", "start": 0, "end": 42, "i_start": 0, "i_end": 5}, "verb": {"text": "has been", "start": 43, "end": 51, "i_start": 6, "i_end": 7}}], "id": 865}, {"sent": "we then color x 0 x 1 from with respect to 2 and u \u03c6 , and color x 3 x 4 from with respect to 1 and u \u03c6 .", "tokens": ["we", "then", "color", "x", "0", "x", "1", "from", "with", "respect", "to", "2", "and", "u", "\u03c6", ",", "and", "color", "x", "3", "x", "4", "from", "with", "respect", "to", "1", "and", "u", "\u03c6", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "color", "start": 8, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "color", "start": 59, "end": 64, "i_start": 17, "i_end": 17}}], "id": 866}, {"sent": "cluster algebras , first defined in , are algebras with a distinguished set of generators satisfying certain combinatorial conditions .", "tokens": ["cluster", "algebras", ",", "first", "defined", "in", ",", "are", "algebras", "with", "a", "distinguished", "set", "of", "generators", "satisfying", "certain", "combinatorial", "conditions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 38, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "generators", "start": 79, "end": 89, "i_start": 14, "i_end": 14}, "action": {"text": "satisfying", "start": 90, "end": 100, "i_start": 15, "i_end": 15}}], "id": 867}, {"sent": "it assures that the physics remains independent of the observer , and it is therefore also called observer invariance .", "tokens": ["it", "assures", "that", "the", "physics", "remains", "independent", "of", "the", "observer", ",", "and", "it", "is", "therefore", "also", "called", "observer", "invariance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assures", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the physics", "start": 16, "end": 27, "i_start": 3, "i_end": 4}, "verb": {"text": "remains", "start": 28, "end": 35, "i_start": 5, "i_end": 5}}, {"subject": {"text": "it", "start": 70, "end": 72, "i_start": 12, "i_end": 12}, "verb": {"text": "called", "start": 91, "end": 97, "i_start": 16, "i_end": 16}}, {"character": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assures", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "physics", "start": 20, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "independent", "start": 36, "end": 47, "i_start": 6, "i_end": 6}}], "id": 868}, {"sent": "in supergravity there is a special problem with symmetries which does not occur in yang-mills theories , the problem of auxiliary fields .", "tokens": ["in", "supergravity", "there", "is", "a", "special", "problem", "with", "symmetries", "which", "does", "not", "occur", "in", "yang", "-", "mills", "theories", ",", "the", "problem", "of", "auxiliary", "fields", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 16, "end": 21, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 869}, {"sent": "today , the concept of antimatroid appears in many fields of mathematics such as formal language theory , choice theory , game theory and mathematical psychology among others .", "tokens": ["today", ",", "the", "concept", "of", "antimatroid", "appears", "in", "many", "fields", "of", "mathematics", "such", "as", "formal", "language", "theory", ",", "choice", "theory", ",", "game", "theory", "and", "mathematical", "psychology", "among", "others", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the concept of antimatroid", "start": 8, "end": 34, "i_start": 2, "i_end": 5}, "verb": {"text": "appears", "start": 35, "end": 42, "i_start": 6, "i_end": 6}}], "id": 870}, {"sent": "as for the phase error correction , we design a procedure similar to the idea of gottesman and lo as shown in fig .", "tokens": ["as", "for", "the", "phase", "error", "correction", ",", "we", "design", "a", "procedure", "similar", "to", "the", "idea", "of", "gottesman", "and", "lo", "as", "shown", "in", "fig", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 36, "end": 38, "i_start": 7, "i_end": 7}, "verb": {"text": "design", "start": 39, "end": 45, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 36, "end": 38, "i_start": 7, "i_end": 7}, "action": {"text": "design", "start": 39, "end": 45, "i_start": 8, "i_end": 8}}, {"character": {"text": "fig", "start": 110, "end": 113, "i_start": 22, "i_end": 22}, "action": {"text": "shown", "start": 101, "end": 106, "i_start": 20, "i_end": 20}}], "id": 871}, {"sent": "the pt antenna gain and st antenna gain are set at 6dbi as in , and the circuit power consumption is set at -35dbm .", "tokens": ["the", "pt", "antenna", "gain", "and", "st", "antenna", "gain", "are", "set", "at", "6dbi", "as", "in", ",", "and", "the", "circuit", "power", "consumption", "is", "set", "at", "-35dbm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the pt antenna gain and st antenna gain", "start": 0, "end": 39, "i_start": 0, "i_end": 7}, "verb": {"text": "are set", "start": 40, "end": 47, "i_start": 8, "i_end": 9}}, {"subject": {"text": "the circuit power consumption", "start": 68, "end": 97, "i_start": 16, "i_end": 19}, "verb": {"text": "set", "start": 101, "end": 104, "i_start": 21, "i_end": 21}}], "id": 872}, {"sent": "following the methodology in , we exploit residual learning every few stacked layers .", "tokens": ["following", "the", "methodology", "in", ",", "we", "exploit", "residual", "learning", "every", "few", "stacked", "layers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "verb": {"text": "exploit", "start": 34, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "exploit", "start": 34, "end": 41, "i_start": 6, "i_end": 6}}], "id": 873}, {"sent": "for the training , we use a policy gradient method , namely proximal policy optimization .", "tokens": ["for", "the", "training", ",", "we", "use", "a", "policy", "gradient", "method", ",", "namely", "proximal", "policy", "optimization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 22, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 22, "end": 25, "i_start": 5, "i_end": 5}}], "id": 874}, {"sent": "in recent years , deep neural networks have demonstrated outstanding performance in natural language processing , speech recognition , visual object recognition , object detection , and many other domains .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "demonstrated", "outstanding", "performance", "in", "natural", "language", "processing", ",", "speech", "recognition", ",", "visual", "object", "recognition", ",", "object", "detection", ",", "and", "many", "other", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have demonstrated", "start": 39, "end": 56, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "demonstrated", "start": 44, "end": 56, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 69, "end": 80, "i_start": 10, "i_end": 10}}], "id": 875}, {"sent": "we have also evaluated the rf-spectrum due to the current produced by dissociation of molecules at the center of the trap .", "tokens": ["we", "have", "also", "evaluated", "the", "rf", "-", "spectrum", "due", "to", "the", "current", "produced", "by", "dissociation", "of", "molecules", "at", "the", "center", "of", "the", "trap", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluated", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluated", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "dissociation", "start": 70, "end": 82, "i_start": 14, "i_end": 14}, "action": {"text": "produced", "start": 58, "end": 66, "i_start": 12, "i_end": 12}}], "id": 876}, {"sent": "danelljan et al propose the continuous convolution operator tracker to efficiently integrate multi-resolution shallow and deep feature maps .", "tokens": ["danelljan", "et", "al", "propose", "the", "continuous", "convolution", "operator", "tracker", "to", "efficiently", "integrate", "multi", "-", "resolution", "shallow", "and", "deep", "feature", "maps", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 10, "end": 15, "i_start": 1, "i_end": 2}, "verb": {"text": "propose", "start": 16, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "danelljan", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 16, "end": 23, "i_start": 3, "i_end": 3}}], "id": 877}, {"sent": "we see that classically the shell has three allowed regions .", "tokens": ["we", "see", "that", "classically", "the", "shell", "has", "three", "allowed", "regions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "see", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the shell", "start": 24, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "has", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "see", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "shell", "start": 28, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "has", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}], "id": 878}, {"sent": "is the derivative in the tan gential direction perpendicular to the vector .", "tokens": ["is", "the", "derivative", "in", "the", "tan", "gential", "direction", "perpendicular", "to", "the", "vector", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the derivative in the tan gential direction perpendicular to the vector", "start": 3, "end": 74, "i_start": 1, "i_end": 11}, "verb": {"text": "is", "start": 0, "end": 2, "i_start": 0, "i_end": 0}}], "id": 879}, {"sent": "the quantum osft on a d0-brane is a quantum mechanical system of infinitely many degrees of freedom .", "tokens": ["the", "quantum", "osft", "on", "a", "d0", "-", "brane", "is", "a", "quantum", "mechanical", "system", "of", "infinitely", "many", "degrees", "of", "freedom", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quantum osft on a d0-brane", "start": 0, "end": 30, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 8, "i_end": 8}}], "id": 880}, {"sent": "this discrepancy is a sign that another phenomenon , not included in the theoretical description happens .", "tokens": ["this", "discrepancy", "is", "a", "sign", "that", "another", "phenomenon", ",", "not", "included", "in", "the", "theoretical", "description", "happens", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this discrepancy", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "discrepancy", "start": 5, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "sign", "start": 22, "end": 26, "i_start": 4, "i_end": 4}}], "id": 881}, {"sent": "between each convolutional layer and following non-linearity we use batch normalization .", "tokens": ["between", "each", "convolutional", "layer", "and", "following", "non", "-", "linearity", "we", "use", "batch", "normalization", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 61, "end": 63, "i_start": 9, "i_end": 9}, "verb": {"text": "use", "start": 64, "end": 67, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 61, "end": 63, "i_start": 9, "i_end": 9}, "action": {"text": "use", "start": 64, "end": 67, "i_start": 10, "i_end": 10}}], "id": 882}, {"sent": "however , some slsne show broad hydrogen lines and there exist some slsne that are initially type ic but start to show hydrogen emissions about 1 year after the luminosity peak , yan et al 2015 , yan et al , 2017a .", "tokens": ["however", ",", "some", "slsne", "show", "broad", "hydrogen", "lines", "and", "there", "exist", "some", "slsne", "that", "are", "initially", "type", "ic", "but", "start", "to", "show", "hydrogen", "emissions", "about", "1", "year", "after", "the", "luminosity", "peak", ",", "yan", "et", "al", "2015", ",", "yan", "et", "al", ",", "2017a", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "some slsne", "start": 10, "end": 20, "i_start": 2, "i_end": 3}, "verb": {"text": "show", "start": 21, "end": 25, "i_start": 4, "i_end": 4}}, {"subject": {"text": "there", "start": 51, "end": 56, "i_start": 9, "i_end": 9}, "verb": {"text": "exist", "start": 57, "end": 62, "i_start": 10, "i_end": 10}}], "id": 883}, {"sent": "the performance of various computer vision problems has been significantly improved with the development of deep convolutional neural networks .", "tokens": ["the", "performance", "of", "various", "computer", "vision", "problems", "has", "been", "significantly", "improved", "with", "the", "development", "of", "deep", "convolutional", "neural", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the performance of various computer vision problems", "start": 0, "end": 51, "i_start": 0, "i_end": 6}, "verb": {"text": "improved", "start": 75, "end": 83, "i_start": 10, "i_end": 10}}, {"subject": {"text": "the performance of various computer vision problems", "start": 0, "end": 51, "i_start": 0, "i_end": 6}, "verb": {"text": "has been", "start": 52, "end": 60, "i_start": 7, "i_end": 8}}, {"character": {"text": "development", "start": 93, "end": 104, "i_start": 13, "i_end": 13}, "action": {"text": "improved", "start": 75, "end": 83, "i_start": 10, "i_end": 10}}, {"character": {"text": "problems", "start": 43, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 4, "end": 15, "i_start": 1, "i_end": 1}}], "id": 884}, {"sent": "dropout is a regularization technique for neural network models where randomly selected neurons are ignored during training .", "tokens": ["dropout", "is", "a", "regularization", "technique", "for", "neural", "network", "models", "where", "randomly", "selected", "neurons", "are", "ignored", "during", "training", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dropout", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}], "id": 885}, {"sent": "we evaluate our mv3d network on the challenging kitti object detection benchmark .", "tokens": ["we", "evaluate", "our", "mv3d", "network", "on", "the", "challenging", "kitti", "object", "detection", "benchmark", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "benchmark", "start": 71, "end": 80, "i_start": 11, "i_end": 11}, "action": {"text": "challenging", "start": 36, "end": 47, "i_start": 7, "i_end": 7}}], "id": 886}, {"sent": "in 1984 bennett and brassard suggested a quantum cryptographic protocol that relies on the use of non-orthogonal states .", "tokens": ["in", "1984", "bennett", "and", "brassard", "suggested", "a", "quantum", "cryptographic", "protocol", "that", "relies", "on", "the", "use", "of", "non", "-", "orthogonal", "states", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "brassard", "start": 20, "end": 28, "i_start": 4, "i_end": 4}, "verb": {"text": "suggested", "start": 29, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "bennett", "start": 8, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "suggested", "start": 29, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "brassard", "start": 20, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "suggested", "start": 29, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "protocol", "start": 63, "end": 71, "i_start": 9, "i_end": 9}, "action": {"text": "relies", "start": 77, "end": 83, "i_start": 11, "i_end": 11}}], "id": 887}, {"sent": "the analysis of pseudo-paradoxist events is called pseudo-paradoxist statistics .", "tokens": ["the", "analysis", "of", "pseudo", "-", "paradoxist", "events", "is", "called", "pseudo", "-", "paradoxist", "statistics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the analysis of pseudo-paradoxist events", "start": 0, "end": 40, "i_start": 0, "i_end": 6}, "verb": {"text": "is called", "start": 41, "end": 50, "i_start": 7, "i_end": 8}}], "id": 888}, {"sent": "fortunately , knill , laflamme and milburn showed that it was , in principle , possible to carry out quantum information processing using only linear optical elements , single photon sources and photo-detectors .", "tokens": ["fortunately", ",", "knill", ",", "laflamme", "and", "milburn", "showed", "that", "it", "was", ",", "in", "principle", ",", "possible", "to", "carry", "out", "quantum", "information", "processing", "using", "only", "linear", "optical", "elements", ",", "single", "photon", "sources", "and", "photo", "-", "detectors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "knill", "start": 14, "end": 19, "i_start": 2, "i_end": 2}, "verb": {"text": "showed", "start": 43, "end": 49, "i_start": 7, "i_end": 7}}, {"subject": {"text": "knill", "start": 14, "end": 19, "i_start": 2, "i_end": 2}, "verb": {"text": "was", "start": 58, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "knill", "start": 14, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "showed", "start": 43, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "laflamme", "start": 22, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "showed", "start": 43, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "milburn", "start": 35, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "showed", "start": 43, "end": 49, "i_start": 7, "i_end": 7}}], "id": 889}, {"sent": "over the past few years , deep convolutional neural networks have been very successful in a wide range of computer vision tasks such as image classification .", "tokens": ["over", "the", "past", "few", "years", ",", "deep", "convolutional", "neural", "networks", "have", "been", "very", "successful", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 26, "end": 60, "i_start": 6, "i_end": 9}, "verb": {"text": "have been", "start": 61, "end": 70, "i_start": 10, "i_end": 11}}, {"character": {"text": "networks", "start": 52, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "successful", "start": 76, "end": 86, "i_start": 13, "i_end": 13}}], "id": 890}, {"sent": "convolutional neural networks have achieved superior performance in many visual tasks , such as object classification and detection .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "classification", "and", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 6, "i_end": 6}}], "id": 891}, {"sent": "all models overestimate precipitation amount over high latitudes .", "tokens": ["all", "models", "overestimate", "precipitation", "amount", "over", "high", "latitudes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "all models", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "overestimate", "start": 11, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "models", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "overestimate", "start": 11, "end": 23, "i_start": 2, "i_end": 2}}], "id": 892}, {"sent": "based on seven years of measurements , the icecube collaboration has observed plenty of neutrino events with energies above 30 tev , including four pev scale neutrinos .", "tokens": ["based", "on", "seven", "years", "of", "measurements", ",", "the", "icecube", "collaboration", "has", "observed", "plenty", "of", "neutrino", "events", "with", "energies", "above", "30", "tev", ",", "including", "four", "pev", "scale", "neutrinos", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the icecube collaboration", "start": 39, "end": 64, "i_start": 7, "i_end": 9}, "verb": {"text": "has observed", "start": 65, "end": 77, "i_start": 10, "i_end": 11}}, {"character": {"text": "collaboration", "start": 51, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "observed", "start": 69, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "events", "start": 97, "end": 103, "i_start": 15, "i_end": 15}, "action": {"text": "has", "start": 65, "end": 68, "i_start": 10, "i_end": 10}}], "id": 893}, {"sent": "kiros et al adopted an encoder-decoder framework coupled with a contrastive loss to train a joint visual-semantic embedding .", "tokens": ["kiros", "et", "al", "adopted", "an", "encoder", "-", "decoder", "framework", "coupled", "with", "a", "contrastive", "loss", "to", "train", "a", "joint", "visual", "-", "semantic", "embedding", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "kiros et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "adopted", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "kiros", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "adopted", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}], "id": 894}, {"sent": "the log-submodularity condition and the corresponding logsupermodularity condition were referred to in karlin and rinott as the multivariate total positivity of order 2 and the multivariate reverse rule of order 2 , respectively .", "tokens": ["the", "log", "-", "submodularity", "condition", "and", "the", "corresponding", "logsupermodularity", "condition", "were", "referred", "to", "in", "karlin", "and", "rinott", "as", "the", "multivariate", "total", "positivity", "of", "order", "2", "and", "the", "multivariate", "reverse", "rule", "of", "order", "2", ",", "respectively", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the log-submodularity condition and the corresponding logsupermodularity condition", "start": 0, "end": 82, "i_start": 0, "i_end": 9}, "verb": {"text": "were referred", "start": 83, "end": 96, "i_start": 10, "i_end": 11}}, {"subject": {"text": "the log-submodularity condition and the corresponding logsupermodularity condition", "start": 0, "end": 82, "i_start": 0, "i_end": 9}, "verb": {"text": "rinott", "start": 114, "end": 120, "i_start": 16, "i_end": 16}}], "id": 895}, {"sent": "such a vortex is called a geostrophic vortex .", "tokens": ["such", "a", "vortex", "is", "called", "a", "geostrophic", "vortex", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such a vortex", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 14, "end": 23, "i_start": 3, "i_end": 4}}], "id": 896}, {"sent": "we use the powerful technique of exchangeable pairs as employed by chatterjee and dembo .", "tokens": ["we", "use", "the", "powerful", "technique", "of", "exchangeable", "pairs", "as", "employed", "by", "chatterjee", "and", "dembo", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "chatterjee", "start": 67, "end": 77, "i_start": 11, "i_end": 11}, "action": {"text": "employed", "start": 55, "end": 63, "i_start": 9, "i_end": 9}}, {"character": {"text": "dembo", "start": 82, "end": 87, "i_start": 13, "i_end": 13}, "action": {"text": "employed", "start": 55, "end": 63, "i_start": 9, "i_end": 9}}], "id": 897}, {"sent": "deep convolutional neural networks have made significant breakthroughs in many visual understanding tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "significant", "breakthroughs", "in", "many", "visual", "understanding", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "breakthroughs", "start": 57, "end": 70, "i_start": 7, "i_end": 7}}], "id": 898}, {"sent": "the proof of the theorem is left as an exercise for the reader .", "tokens": ["the", "proof", "of", "the", "theorem", "is", "left", "as", "an", "exercise", "for", "the", "reader", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the proof of the theorem", "start": 0, "end": 24, "i_start": 0, "i_end": 4}, "verb": {"text": "is left", "start": 25, "end": 32, "i_start": 5, "i_end": 6}}], "id": 899}, {"sent": "capitalizing on the results of , it can be shown that under mild transversality assumptions , the set of partly smooth functions is closed under addition and pre-composition by a linear operator .", "tokens": ["capitalizing", "on", "the", "results", "of", ",", "it", "can", "be", "shown", "that", "under", "mild", "transversality", "assumptions", ",", "the", "set", "of", "partly", "smooth", "functions", "is", "closed", "under", "addition", "and", "pre", "-", "composition", "by", "a", "linear", "operator", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 33, "end": 35, "i_start": 6, "i_end": 6}, "verb": {"text": "can be shown", "start": 36, "end": 48, "i_start": 7, "i_end": 9}}, {"subject": {"text": "the set of partly smooth functions", "start": 94, "end": 128, "i_start": 16, "i_end": 21}, "verb": {"text": "closed", "start": 132, "end": 138, "i_start": 23, "i_end": 23}}], "id": 900}, {"sent": "in the recent years , detectionbased methods engined by convolutional neural networks are the most successful .", "tokens": ["in", "the", "recent", "years", ",", "detectionbased", "methods", "engined", "by", "convolutional", "neural", "networks", "are", "the", "most", "successful", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "detectionbased methods engined by convolutional neural networks", "start": 22, "end": 85, "i_start": 5, "i_end": 11}, "verb": {"text": "are", "start": 86, "end": 89, "i_start": 12, "i_end": 12}}, {"character": {"text": "methods", "start": 37, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "successful", "start": 99, "end": 109, "i_start": 15, "i_end": 15}}], "id": 901}, {"sent": "the resnet-50 model pre-trained on imagenet is adopted to initialize our network .", "tokens": ["the", "resnet-50", "model", "pre", "-", "trained", "on", "imagenet", "is", "adopted", "to", "initialize", "our", "network", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the resnet-50 model pre-trained on imagenet", "start": 0, "end": 43, "i_start": 0, "i_end": 7}, "verb": {"text": "is adopted", "start": 44, "end": 54, "i_start": 8, "i_end": 9}}, {"character": {"text": "model", "start": 14, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "initialize", "start": 58, "end": 68, "i_start": 11, "i_end": 11}}], "id": 902}, {"sent": "convolutional neural networks have broken many records of computer vision tasks , such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "broken", "many", "records", "of", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have broken", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "broken", "start": 35, "end": 41, "i_start": 4, "i_end": 4}}], "id": 903}, {"sent": "therefore , the renormalization is the same in the infinite and finite volume cases .", "tokens": ["therefore", ",", "the", "renormalization", "is", "the", "same", "in", "the", "infinite", "and", "finite", "volume", "cases", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the renormalization", "start": 12, "end": 31, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 4, "i_end": 4}}], "id": 904}, {"sent": "in this section , following , we define regularized petersson inner product of a cusp form and a meromorphic modular form with the same weight .", "tokens": ["in", "this", "section", ",", "following", ",", "we", "define", "regularized", "petersson", "inner", "product", "of", "a", "cusp", "form", "and", "a", "meromorphic", "modular", "form", "with", "the", "same", "weight", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 30, "end": 32, "i_start": 6, "i_end": 6}, "verb": {"text": "define", "start": 33, "end": 39, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 30, "end": 32, "i_start": 6, "i_end": 6}, "action": {"text": "define", "start": 33, "end": 39, "i_start": 7, "i_end": 7}}, {"character": {"text": "form", "start": 86, "end": 90, "i_start": 15, "i_end": 15}, "action": {"text": "product", "start": 68, "end": 75, "i_start": 11, "i_end": 11}}, {"character": {"text": "cusp", "start": 81, "end": 85, "i_start": 14, "i_end": 14}, "action": {"text": "product", "start": 68, "end": 75, "i_start": 11, "i_end": 11}}, {"character": {"text": "form", "start": 117, "end": 121, "i_start": 20, "i_end": 20}, "action": {"text": "product", "start": 68, "end": 75, "i_start": 11, "i_end": 11}}, {"character": {"text": "modular", "start": 109, "end": 116, "i_start": 19, "i_end": 19}, "action": {"text": "product", "start": 68, "end": 75, "i_start": 11, "i_end": 11}}, {"character": {"text": "meromorphic", "start": 97, "end": 108, "i_start": 18, "i_end": 18}, "action": {"text": "product", "start": 68, "end": 75, "i_start": 11, "i_end": 11}}], "id": 905}, {"sent": "deep neural networks have achieved great success in cognitive applications such as image classification .", "tokens": ["deep", "neural", "networks", "have", "achieved", "great", "success", "in", "cognitive", "applications", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 41, "end": 48, "i_start": 6, "i_end": 6}}], "id": 906}, {"sent": "in the polynomial chaos , orthogonal polynomials are applied , see .", "tokens": ["in", "the", "polynomial", "chaos", ",", "orthogonal", "polynomials", "are", "applied", ",", "see", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "orthogonal polynomials", "start": 26, "end": 48, "i_start": 5, "i_end": 6}, "verb": {"text": "see", "start": 63, "end": 66, "i_start": 10, "i_end": 10}}, {"subject": {"text": "orthogonal polynomials", "start": 26, "end": 48, "i_start": 5, "i_end": 6}, "verb": {"text": "applied", "start": 53, "end": 60, "i_start": 8, "i_end": 8}}], "id": 907}, {"sent": "it is possible to use the potential between monopole and anti-monopole to find the mass spectrum of the glueballs .", "tokens": ["it", "is", "possible", "to", "use", "the", "potential", "between", "monopole", "and", "anti", "-", "monopole", "to", "find", "the", "mass", "spectrum", "of", "the", "glueballs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}], "id": 908}, {"sent": "the obtained results allow us to predict the dynamics of oscillatory systems de pending on the initial phase difference , on the type and the intensity of the interaction .", "tokens": ["the", "obtained", "results", "allow", "us", "to", "predict", "the", "dynamics", "of", "oscillatory", "systems", "de", "pending", "on", "the", "initial", "phase", "difference", ",", "on", "the", "type", "and", "the", "intensity", "of", "the", "interaction", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the obtained results", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "allow", "start": 21, "end": 26, "i_start": 3, "i_end": 3}}, {"subject": {"text": "us", "start": 27, "end": 29, "i_start": 4, "i_end": 4}, "verb": {"text": "predict", "start": 33, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "results", "start": 13, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "allow", "start": 21, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 27, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "predict", "start": 33, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "systems", "start": 69, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "oscillatory", "start": 57, "end": 68, "i_start": 10, "i_end": 10}}], "id": 909}, {"sent": "in , a u-shaped network for segmentation is designed with a contracting path to capture context and a symmetric expanding path to localize objects .", "tokens": ["in", ",", "a", "u", "-", "shaped", "network", "for", "segmentation", "is", "designed", "with", "a", "contracting", "path", "to", "capture", "context", "and", "a", "symmetric", "expanding", "path", "to", "localize", "objects", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a u-shaped network for segmentation", "start": 5, "end": 40, "i_start": 2, "i_end": 8}, "verb": {"text": "is designed", "start": 41, "end": 52, "i_start": 9, "i_end": 10}}, {"character": {"text": "path", "start": 72, "end": 76, "i_start": 14, "i_end": 14}, "action": {"text": "contracting", "start": 60, "end": 71, "i_start": 13, "i_end": 13}}], "id": 910}, {"sent": "recent rapid advances in deep learning are allowing for the learning of complex functions through convolutional neural networks , which have achieved stateof-the-art performances in a plethora of computer vision tasks .", "tokens": ["recent", "rapid", "advances", "in", "deep", "learning", "are", "allowing", "for", "the", "learning", "of", "complex", "functions", "through", "convolutional", "neural", "networks", ",", "which", "have", "achieved", "stateof", "-", "the", "-", "art", "performances", "in", "a", "plethora", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent rapid advances in deep learning", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "are allowing", "start": 39, "end": 51, "i_start": 6, "i_end": 7}}, {"character": {"text": "advances", "start": 13, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "allowing", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 119, "end": 127, "i_start": 17, "i_end": 17}, "action": {"text": "achieved", "start": 141, "end": 149, "i_start": 21, "i_end": 21}}], "id": 911}, {"sent": "convolutional neural networks have been extensively used in different image and video processing applications .", "tokens": ["convolutional", "neural", "networks", "have", "been", "extensively", "used", "in", "different", "image", "and", "video", "processing", "applications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 52, "end": 56, "i_start": 6, "i_end": 6}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}], "id": 912}, {"sent": "the encoder is a fullyconvolutional part of vgg network , pre-trained on imagenet dataset .", "tokens": ["the", "encoder", "is", "a", "fullyconvolutional", "part", "of", "vgg", "network", ",", "pre", "-", "trained", "on", "imagenet", "dataset", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the encoder", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 913}, {"sent": "for more comprehensive evaluations , we compare our lmsco with nine state-of-the-art trackers on vot-tir2016 benchmark , including mdnet .", "tokens": ["for", "more", "comprehensive", "evaluations", ",", "we", "compare", "our", "lmsco", "with", "nine", "state", "-", "of", "-", "the", "-", "art", "trackers", "on", "vot", "-", "tir2016", "benchmark", ",", "including", "mdnet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 37, "end": 39, "i_start": 5, "i_end": 5}, "verb": {"text": "compare", "start": 40, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 37, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "compare", "start": 40, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "nine", "start": 63, "end": 67, "i_start": 10, "i_end": 10}, "action": {"text": "trackers", "start": 85, "end": 93, "i_start": 18, "i_end": 18}}], "id": 914}, {"sent": "the localized spectral interpretation of defferrard et al is based on recursive feature learning with chebyshev polynomials and has linear evaluation complexity .", "tokens": ["the", "localized", "spectral", "interpretation", "of", "defferrard", "et", "al", "is", "based", "on", "recursive", "feature", "learning", "with", "chebyshev", "polynomials", "and", "has", "linear", "evaluation", "complexity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the localized spectral interpretation of defferrard et al", "start": 0, "end": 57, "i_start": 0, "i_end": 7}, "verb": {"text": "is based", "start": 58, "end": 66, "i_start": 8, "i_end": 9}}, {"subject": {"text": "the localized spectral interpretation of defferrard et al", "start": 0, "end": 57, "i_start": 0, "i_end": 7}, "verb": {"text": "has", "start": 128, "end": 131, "i_start": 18, "i_end": 18}}, {"character": {"text": "interpretation", "start": 23, "end": 37, "i_start": 3, "i_end": 3}, "action": {"text": "has", "start": 128, "end": 131, "i_start": 18, "i_end": 18}}], "id": 915}, {"sent": "deep learning techniques , especially the convolutional neural network architectures have achieved remarkable breakthroughs in learning image representation for classification .", "tokens": ["deep", "learning", "techniques", ",", "especially", "the", "convolutional", "neural", "network", "architectures", "have", "achieved", "remarkable", "breakthroughs", "in", "learning", "image", "representation", "for", "classification", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep learning techniques", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 85, "end": 98, "i_start": 10, "i_end": 11}}, {"character": {"text": "techniques", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 90, "end": 98, "i_start": 11, "i_end": 11}}], "id": 916}, {"sent": "locality sensitive hashing is a popular and fast method for candidate generation and approximate similarity computation within a large high dimensional dataset .", "tokens": ["locality", "sensitive", "hashing", "is", "a", "popular", "and", "fast", "method", "for", "candidate", "generation", "and", "approximate", "similarity", "computation", "within", "a", "large", "high", "dimensional", "dataset", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "locality sensitive hashing", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "hashing", "start": 19, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "sensitive", "start": 9, "end": 18, "i_start": 1, "i_end": 1}}], "id": 917}, {"sent": "the dashed line comes once again from equation , and separates the region on the left where the kozai resonance exists from that on the right where relativistic periastron precession destroys the resonance .", "tokens": ["the", "dashed", "line", "comes", "once", "again", "from", "equation", ",", "and", "separates", "the", "region", "on", "the", "left", "where", "the", "kozai", "resonance", "exists", "from", "that", "on", "the", "right", "where", "relativistic", "periastron", "precession", "destroys", "the", "resonance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the dashed line", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "comes", "start": 16, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the dashed line", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "separates", "start": 53, "end": 62, "i_start": 10, "i_end": 10}}, {"character": {"text": "line", "start": 11, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "separates", "start": 53, "end": 62, "i_start": 10, "i_end": 10}}, {"character": {"text": "precession", "start": 172, "end": 182, "i_start": 29, "i_end": 29}, "action": {"text": "destroys", "start": 183, "end": 191, "i_start": 30, "i_end": 30}}], "id": 918}, {"sent": "this step is called the residual renormalization .", "tokens": ["this", "step", "is", "called", "the", "residual", "renormalization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this step", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is called", "start": 10, "end": 19, "i_start": 2, "i_end": 3}}], "id": 919}, {"sent": "the double semion model is a simple example of a string-net model .", "tokens": ["the", "double", "semion", "model", "is", "a", "simple", "example", "of", "a", "string", "-", "net", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the double semion model", "start": 0, "end": 23, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 4, "i_end": 4}}], "id": 920}, {"sent": "the clear differences of the two polarizations demonstrate the anisotropy of the optical conductivity .", "tokens": ["the", "clear", "differences", "of", "the", "two", "polarizations", "demonstrate", "the", "anisotropy", "of", "the", "optical", "conductivity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the clear differences of the two polarizations", "start": 0, "end": 46, "i_start": 0, "i_end": 6}, "verb": {"text": "demonstrate", "start": 47, "end": 58, "i_start": 7, "i_end": 7}}, {"character": {"text": "differences", "start": 10, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrate", "start": 47, "end": 58, "i_start": 7, "i_end": 7}}], "id": 921}, {"sent": "borodin showed that every planar graph admits an acyclic 5-coloring .", "tokens": ["borodin", "showed", "that", "every", "planar", "graph", "admits", "an", "acyclic", "5", "-", "coloring", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "borodin", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "showed", "start": 8, "end": 14, "i_start": 1, "i_end": 1}}, {"subject": {"text": "every planar graph", "start": 20, "end": 38, "i_start": 3, "i_end": 5}, "verb": {"text": "admits", "start": 39, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "graph", "start": 33, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "admits", "start": 39, "end": 45, "i_start": 6, "i_end": 6}}], "id": 922}, {"sent": "in addition , dropout is an effective way to prevent neural networks from overfitting .", "tokens": ["in", "addition", ",", "dropout", "is", "an", "effective", "way", "to", "prevent", "neural", "networks", "from", "overfitting", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dropout", "start": 14, "end": 21, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "way", "start": 38, "end": 41, "i_start": 7, "i_end": 7}, "action": {"text": "prevent", "start": 45, "end": 52, "i_start": 9, "i_end": 9}}, {"character": {"text": "way", "start": 38, "end": 41, "i_start": 7, "i_end": 7}, "action": {"text": "effective", "start": 28, "end": 37, "i_start": 6, "i_end": 6}}], "id": 923}, {"sent": "the advantages for the policy gradient will be computed using the generalized advantage estimator gae .", "tokens": ["the", "advantages", "for", "the", "policy", "gradient", "will", "be", "computed", "using", "the", "generalized", "advantage", "estimator", "gae", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the advantages for the policy gradient", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "will be computed", "start": 39, "end": 55, "i_start": 6, "i_end": 8}}], "id": 924}, {"sent": "to examine the properties of entanglement we use the pereshorodecki criterion .", "tokens": ["to", "examine", "the", "properties", "of", "entanglement", "we", "use", "the", "pereshorodecki", "criterion", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 42, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "use", "start": 45, "end": 48, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 42, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "examine", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 925}, {"sent": "the classical field would cause the ac-stark shift that randomizes the phase of the qubit states .", "tokens": ["the", "classical", "field", "would", "cause", "the", "ac", "-", "stark", "shift", "that", "randomizes", "the", "phase", "of", "the", "qubit", "states", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the classical field", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "would cause", "start": 20, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "field", "start": 14, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "cause", "start": 26, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "shift", "start": 45, "end": 50, "i_start": 9, "i_end": 9}, "action": {"text": "randomizes", "start": 56, "end": 66, "i_start": 11, "i_end": 11}}], "id": 926}, {"sent": "the strongest model is the fully synchronized model where each phase of each cycle is performed simultaneously by all robots .", "tokens": ["the", "strongest", "model", "is", "the", "fully", "synchronized", "model", "where", "each", "phase", "of", "each", "cycle", "is", "performed", "simultaneously", "by", "all", "robots", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the strongest model", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "robots", "start": 118, "end": 124, "i_start": 19, "i_end": 19}, "action": {"text": "performed", "start": 86, "end": 95, "i_start": 15, "i_end": 15}}], "id": 927}, {"sent": "box-and-whisker plot for the results based on the solovay-strassen probabilistic primality test .", "tokens": ["box", "-", "and", "-", "whisker", "plot", "for", "the", "results", "based", "on", "the", "solovay", "-", "strassen", "probabilistic", "primality", "test", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 928}, {"sent": "in recent years , deep neural networks , especially convolutional neural networks , have demonstrated highly competitive results on object recognition and image classification .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", ",", "especially", "convolutional", "neural", "networks", ",", "have", "demonstrated", "highly", "competitive", "results", "on", "object", "recognition", "and", "image", "classification", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have demonstrated", "start": 84, "end": 101, "i_start": 13, "i_end": 14}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "demonstrated", "start": 89, "end": 101, "i_start": 14, "i_end": 14}}], "id": 929}, {"sent": "in this section , we will define analogues of oc for non-commutative smooth proper surfaces .", "tokens": ["in", "this", "section", ",", "we", "will", "define", "analogues", "of", "oc", "for", "non", "-", "commutative", "smooth", "proper", "surfaces", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "will define", "start": 21, "end": 32, "i_start": 5, "i_end": 6}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "define", "start": 26, "end": 32, "i_start": 6, "i_end": 6}}], "id": 930}, {"sent": "this , in turn , implies that m is a constant of the slow motion .", "tokens": ["this", ",", "in", "turn", ",", "implies", "that", "m", "is", "a", "constant", "of", "the", "slow", "motion", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "implies", "start": 17, "end": 24, "i_start": 5, "i_end": 5}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 8, "i_end": 8}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "implies", "start": 17, "end": 24, "i_start": 5, "i_end": 5}}], "id": 931}, {"sent": "the backbone of the network is the feature pyramid network which incorporates residual operations from resnet-50 .", "tokens": ["the", "backbone", "of", "the", "network", "is", "the", "feature", "pyramid", "network", "which", "incorporates", "residual", "operations", "from", "resnet-50", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the backbone of the network", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "network", "start": 20, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "incorporates", "start": 65, "end": 77, "i_start": 11, "i_end": 11}}], "id": 932}, {"sent": "the problem above is equivalent to a henchman problem , in which a wiretapper reconstructs a single sequence with the help of a rate-limited henchman who can access to both the source s m and the wiretapped signal z n .", "tokens": ["the", "problem", "above", "is", "equivalent", "to", "a", "henchman", "problem", ",", "in", "which", "a", "wiretapper", "reconstructs", "a", "single", "sequence", "with", "the", "help", "of", "a", "rate", "-", "limited", "henchman", "who", "can", "access", "to", "both", "the", "source", "s", "m", "and", "the", "wiretapped", "signal", "z", "n", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the problem above", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "henchman", "start": 37, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "help", "start": 118, "end": 122, "i_start": 20, "i_end": 20}}, {"character": {"text": "henchman", "start": 37, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "access", "start": 158, "end": 164, "i_start": 29, "i_end": 29}}], "id": 933}, {"sent": "zuber , final chorus and nomad results , paper presented at this conference .", "tokens": ["zuber", ",", "final", "chorus", "and", "nomad", "results", ",", "paper", "presented", "at", "this", "conference", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 934}, {"sent": "the local part of tip-surface capacitance is .", "tokens": ["the", "local", "part", "of", "tip", "-", "surface", "capacitance", "is", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the local part of tip-surface capacitance", "start": 0, "end": 41, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 42, "end": 44, "i_start": 8, "i_end": 8}}], "id": 935}, {"sent": "deep learning has been successfully applied in a wide range of areas with significant performance improvement , including computer vision , and so on .", "tokens": ["deep", "learning", "has", "been", "successfully", "applied", "in", "a", "wide", "range", "of", "areas", "with", "significant", "performance", "improvement", ",", "including", "computer", "vision", ",", "and", "so", "on", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "applied", "start": 36, "end": 43, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has been", "start": 14, "end": 22, "i_start": 2, "i_end": 3}}], "id": 936}, {"sent": "bekenstein , in second canadian conference on general relativity and relativistic astrophysics , a .", "tokens": ["bekenstein", ",", "in", "second", "canadian", "conference", "on", "general", "relativity", "and", "relativistic", "astrophysics", ",", "a", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 937}, {"sent": "a polyhedron is a topological space x which is the target of some triangulation .", "tokens": ["a", "polyhedron", "is", "a", "topological", "space", "x", "which", "is", "the", "target", "of", "some", "triangulation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a polyhedron", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "triangulation", "start": 66, "end": 79, "i_start": 13, "i_end": 13}, "action": {"text": "target", "start": 51, "end": 57, "i_start": 10, "i_end": 10}}], "id": 938}, {"sent": "recently , convolutional neural networks -based methods achieve great success in image classification tasks .", "tokens": ["recently", ",", "convolutional", "neural", "networks", "-based", "methods", "achieve", "great", "success", "in", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks -based methods", "start": 11, "end": 55, "i_start": 2, "i_end": 6}, "verb": {"text": "achieve", "start": 56, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "methods", "start": 48, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "achieve", "start": 56, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "methods", "start": 48, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 70, "end": 77, "i_start": 9, "i_end": 9}}], "id": 939}, {"sent": "deep neural networks have achieved great progress in a variety of computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "achieved", "great", "progress", "in", "a", "variety", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}], "id": 940}, {"sent": "we use the standard pck metric from which measures the percentage of keypoints that are sufficiently close to the ground truth .", "tokens": ["we", "use", "the", "standard", "pck", "metric", "from", "which", "measures", "the", "percentage", "of", "keypoints", "that", "are", "sufficiently", "close", "to", "the", "ground", "truth", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "metric", "start": 24, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "measures", "start": 42, "end": 50, "i_start": 8, "i_end": 8}}], "id": 941}, {"sent": "generalisation to massive partons in this section we present the generalisation to massive qcd .", "tokens": ["generalisation", "to", "massive", "partons", "in", "this", "section", "we", "present", "the", "generalisation", "to", "massive", "qcd", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 50, "end": 52, "i_start": 7, "i_end": 7}, "verb": {"text": "present", "start": 53, "end": 60, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 50, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "present", "start": 53, "end": 60, "i_start": 8, "i_end": 8}}], "id": 942}, {"sent": "next we recall the definition of the weighted ricci curvature on finsler manifolds introduced by ohta in .", "tokens": ["next", "we", "recall", "the", "definition", "of", "the", "weighted", "ricci", "curvature", "on", "finsler", "manifolds", "introduced", "by", "ohta", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "recall", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "recall", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "ohta", "start": 97, "end": 101, "i_start": 15, "i_end": 15}, "action": {"text": "introduced", "start": 83, "end": 93, "i_start": 13, "i_end": 13}}], "id": 943}, {"sent": "compressed sensing is a signal processing technique that compresses analog vectors by means of a linear transformation .", "tokens": ["compressed", "sensing", "is", "a", "signal", "processing", "technique", "that", "compresses", "analog", "vectors", "by", "means", "of", "a", "linear", "transformation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "compressed sensing", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "technique", "start": 42, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "processing", "start": 31, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "technique", "start": 42, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "compressed", "start": 0, "end": 10, "i_start": 0, "i_end": 0}}], "id": 944}, {"sent": "by construction , \u00b5 is a borel measure , and the sigma algebra of \u00b5-measurable sets is just the sigma algebra of borel mesurable sets , denoted by b throughout .", "tokens": ["by", "construction", ",", "\u00b5", "is", "a", "borel", "measure", ",", "and", "the", "sigma", "algebra", "of", "\u00b5-measurable", "sets", "is", "just", "the", "sigma", "algebra", "of", "borel", "mesurable", "sets", ",", "denoted", "by", "b", "throughout", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "\u00b5", "start": 18, "end": 19, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 4, "i_end": 4}}], "id": 945}, {"sent": "performance-centric task scheduling algorithms take the scheduling performance as the ultimate goal such as the shortest completion time , including max-min , min-min algorithm , genetic algorithm , ant ant colony algorithm .", "tokens": ["performance", "-", "centric", "task", "scheduling", "algorithms", "take", "the", "scheduling", "performance", "as", "the", "ultimate", "goal", "such", "as", "the", "shortest", "completion", "time", ",", "including", "max", "-", "min", ",", "min", "-", "min", "algorithm", ",", "genetic", "algorithm", ",", "ant", "ant", "colony", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "performance-centric task scheduling algorithms", "start": 0, "end": 46, "i_start": 0, "i_end": 5}, "verb": {"text": "take", "start": 47, "end": 51, "i_start": 6, "i_end": 6}}, {"character": {"text": "algorithms", "start": 36, "end": 46, "i_start": 5, "i_end": 5}, "action": {"text": "take", "start": 47, "end": 51, "i_start": 6, "i_end": 6}}], "id": 946}, {"sent": "the electron exchange and correlation are treated within the framework of generalized gradient approximation given by perdew-burke-ernzerhof functional .", "tokens": ["the", "electron", "exchange", "and", "correlation", "are", "treated", "within", "the", "framework", "of", "generalized", "gradient", "approximation", "given", "by", "perdew", "-", "burke", "-", "ernzerhof", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electron exchange and correlation", "start": 0, "end": 37, "i_start": 0, "i_end": 4}, "verb": {"text": "are treated", "start": 38, "end": 49, "i_start": 5, "i_end": 6}}, {"character": {"text": "functional", "start": 141, "end": 151, "i_start": 21, "i_end": 21}, "action": {"text": "given", "start": 109, "end": 114, "i_start": 14, "i_end": 14}}], "id": 947}, {"sent": "since the debut of alexnet , cnns have become widely adopted to solve computer vision problems .", "tokens": ["since", "the", "debut", "of", "alexnet", ",", "cnns", "have", "become", "widely", "adopted", "to", "solve", "computer", "vision", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 948}, {"sent": "we processed and imaged the data using the common astronomy software application software package .", "tokens": ["we", "processed", "and", "imaged", "the", "data", "using", "the", "common", "astronomy", "software", "application", "software", "package", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "processed", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "imaged", "start": 17, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "processed", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "imaged", "start": 17, "end": 23, "i_start": 3, "i_end": 3}}], "id": 949}, {"sent": "deeper convolutional neural networks have obtained state-of-the-art results in many image classification tasks .", "tokens": ["deeper", "convolutional", "neural", "networks", "have", "obtained", "state", "-", "of", "-", "the", "-", "art", "results", "in", "many", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deeper convolutional neural networks", "start": 0, "end": 36, "i_start": 0, "i_end": 3}, "verb": {"text": "have obtained", "start": 37, "end": 50, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 28, "end": 36, "i_start": 3, "i_end": 3}, "action": {"text": "obtained", "start": 42, "end": 50, "i_start": 5, "i_end": 5}}], "id": 950}, {"sent": "we use the switchboard corpus , which contains roughly 300 hours of conversational telephone speech , as our training set .", "tokens": ["we", "use", "the", "switchboard", "corpus", ",", "which", "contains", "roughly", "300", "hours", "of", "conversational", "telephone", "speech", ",", "as", "our", "training", "set", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "corpus", "start": 23, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "contains", "start": 38, "end": 46, "i_start": 7, "i_end": 7}}], "id": 951}, {"sent": "in , petrosyan has verified this conjecture in the case of lhf -group , under the assumption that m is also orientable and in the case when n is 1-dimensional .", "tokens": ["in", ",", "petrosyan", "has", "verified", "this", "conjecture", "in", "the", "case", "of", "lhf", "-group", ",", "under", "the", "assumption", "that", "m", "is", "also", "orientable", "and", "in", "the", "case", "when", "n", "is", "1", "-", "dimensional", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "petrosyan", "start": 5, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "has verified", "start": 15, "end": 27, "i_start": 3, "i_end": 4}}, {"character": {"text": "petrosyan", "start": 5, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "verified", "start": 19, "end": 27, "i_start": 4, "i_end": 4}}], "id": 952}, {"sent": "we choose the imagenet-pretrained vgg-a with batch normalization 2 as our base network .", "tokens": ["we", "choose", "the", "imagenet", "-", "pretrained", "vgg", "-", "a", "with", "batch", "normalization", "2", "as", "our", "base", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "choose", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "choose", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 953}, {"sent": "furthermore , the development of generative adversarial networks has led to revival of generative models .", "tokens": ["furthermore", ",", "the", "development", "of", "generative", "adversarial", "networks", "has", "led", "to", "revival", "of", "generative", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the development of generative adversarial networks", "start": 14, "end": 64, "i_start": 2, "i_end": 7}, "verb": {"text": "has led", "start": 65, "end": 72, "i_start": 8, "i_end": 9}}, {"character": {"text": "development", "start": 18, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "led", "start": 69, "end": 72, "i_start": 9, "i_end": 9}}], "id": 954}, {"sent": "asterisks denote objects with at least one component with a flat or inverted spectrum 130 5 point 3 .", "tokens": ["asterisks", "denote", "objects", "with", "at", "least", "one", "component", "with", "a", "flat", "or", "inverted", "spectrum", "130", "5", "point", "3", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "asterisks", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}], "id": 955}, {"sent": "a manifold n with a given symplectic form is called a phase space .", "tokens": ["a", "manifold", "n", "with", "a", "given", "symplectic", "form", "is", "called", "a", "phase", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a given symplectic form", "start": 18, "end": 41, "i_start": 4, "i_end": 7}, "verb": {"text": "is called", "start": 42, "end": 51, "i_start": 8, "i_end": 9}}], "id": 956}, {"sent": "more importantly , string theory is a perfectly quantum mechanical theory which does include gravity .", "tokens": ["more", "importantly", ",", "string", "theory", "is", "a", "perfectly", "quantum", "mechanical", "theory", "which", "does", "include", "gravity", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "string theory", "start": 19, "end": 32, "i_start": 3, "i_end": 4}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 5, "i_end": 5}}, {"character": {"text": "theory", "start": 26, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "include", "start": 85, "end": 92, "i_start": 13, "i_end": 13}}], "id": 957}, {"sent": "an important difference between network generation models and ergms is that network models try to explain how a network evolves whereas ergms do not explicitly explain any network generation process .", "tokens": ["an", "important", "difference", "between", "network", "generation", "models", "and", "ergms", "is", "that", "network", "models", "try", "to", "explain", "how", "a", "network", "evolves", "whereas", "ergms", "do", "not", "explicitly", "explain", "any", "network", "generation", "process", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "an important difference between network generation models and ergms", "start": 0, "end": 67, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 68, "end": 70, "i_start": 9, "i_end": 9}}, {"subject": {"text": "network models", "start": 76, "end": 90, "i_start": 11, "i_end": 12}, "verb": {"text": "try", "start": 91, "end": 94, "i_start": 13, "i_end": 13}}, {"character": {"text": "models", "start": 51, "end": 57, "i_start": 6, "i_end": 6}, "action": {"text": "try", "start": 91, "end": 94, "i_start": 13, "i_end": 13}}, {"character": {"text": "models", "start": 51, "end": 57, "i_start": 6, "i_end": 6}, "action": {"text": "explain", "start": 98, "end": 105, "i_start": 15, "i_end": 15}}, {"character": {"text": "ergms", "start": 62, "end": 67, "i_start": 8, "i_end": 8}, "action": {"text": "not explicitly explain", "start": 145, "end": 167, "i_start": 23, "i_end": 25}}], "id": 958}, {"sent": "a linear combination of complex exponential functions is known to be very expressive , and can approximate many other functions very well .", "tokens": ["a", "linear", "combination", "of", "complex", "exponential", "functions", "is", "known", "to", "be", "very", "expressive", ",", "and", "can", "approximate", "many", "other", "functions", "very", "well", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a linear combination of complex exponential functions", "start": 0, "end": 53, "i_start": 0, "i_end": 6}, "verb": {"text": "is known", "start": 54, "end": 62, "i_start": 7, "i_end": 8}}, {"subject": {"text": "a linear combination of complex exponential functions", "start": 0, "end": 53, "i_start": 0, "i_end": 6}, "verb": {"text": "approximate", "start": 95, "end": 106, "i_start": 16, "i_end": 16}}, {"character": {"text": "combination", "start": 9, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "expressive", "start": 74, "end": 84, "i_start": 12, "i_end": 12}}, {"character": {"text": "combination", "start": 9, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "approximate", "start": 95, "end": 106, "i_start": 16, "i_end": 16}}], "id": 959}, {"sent": "dark energy is the reason of expansion of the universe to accelerate .", "tokens": ["dark", "energy", "is", "the", "reason", "of", "expansion", "of", "the", "universe", "to", "accelerate", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dark energy", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 960}, {"sent": "the temperature is relatively well constrained while the source size is not .", "tokens": ["the", "temperature", "is", "relatively", "well", "constrained", "while", "the", "source", "size", "is", "not", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the temperature", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 961}, {"sent": "kamilov et al have taken the first step toward a theoretical understanding of such algorithms .", "tokens": ["kamilov", "et", "al", "have", "taken", "the", "first", "step", "toward", "a", "theoretical", "understanding", "of", "such", "algorithms", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "kamilov et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "have taken", "start": 14, "end": 24, "i_start": 3, "i_end": 4}}], "id": 962}, {"sent": "batch normalization is applied to speed up training and prevent overfitting .", "tokens": ["batch", "normalization", "is", "applied", "to", "speed", "up", "training", "and", "prevent", "overfitting", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "batch normalization", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is applied", "start": 20, "end": 30, "i_start": 2, "i_end": 3}}], "id": 963}, {"sent": "the t -duality is a symmetry of the string theory .", "tokens": ["the", "t", "-duality", "is", "a", "symmetry", "of", "the", "string", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the t -duality", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}], "id": 964}, {"sent": "the spin-polarized density functional theory calculations were carried out by using the projector augmented wave method 26 , 27 as implemented in the vienna ab initio simulation package .", "tokens": ["the", "spin", "-", "polarized", "density", "functional", "theory", "calculations", "were", "carried", "out", "by", "using", "the", "projector", "augmented", "wave", "method", "26", ",", "27", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the spin-polarized density functional theory calculations", "start": 0, "end": 57, "i_start": 0, "i_end": 7}, "verb": {"text": "were carried out", "start": 58, "end": 74, "i_start": 8, "i_end": 10}}, {"character": {"text": "projector", "start": 88, "end": 97, "i_start": 14, "i_end": 14}, "action": {"text": "augmented", "start": 98, "end": 107, "i_start": 15, "i_end": 15}}], "id": 965}, {"sent": "although the result regarding the continuous case is less tight , we show that this is the best rate function that can be defined by second order moments , and is tight for the gaussian additive channel .", "tokens": ["although", "the", "result", "regarding", "the", "continuous", "case", "is", "less", "tight", ",", "we", "show", "that", "this", "is", "the", "best", "rate", "function", "that", "can", "be", "defined", "by", "second", "order", "moments", ",", "and", "is", "tight", "for", "the", "gaussian", "additive", "channel", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 66, "end": 68, "i_start": 11, "i_end": 11}, "verb": {"text": "show", "start": 69, "end": 73, "i_start": 12, "i_end": 12}}, {"subject": {"text": "we", "start": 66, "end": 68, "i_start": 11, "i_end": 11}, "verb": {"text": "is", "start": 84, "end": 86, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 66, "end": 68, "i_start": 11, "i_end": 11}, "action": {"text": "show", "start": 69, "end": 73, "i_start": 12, "i_end": 12}}, {"character": {"text": "moments", "start": 146, "end": 153, "i_start": 27, "i_end": 27}, "action": {"text": "defined", "start": 122, "end": 129, "i_start": 23, "i_end": 23}}], "id": 966}, {"sent": "its quantum counterpart is the integration of the electrostatic interactions which give rise to 3 an atomic bound state in a two-level atom .", "tokens": ["its", "quantum", "counterpart", "is", "the", "integration", "of", "the", "electrostatic", "interactions", "which", "give", "rise", "to", "3", "an", "atomic", "bound", "state", "in", "a", "two", "-", "level", "atom", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "its quantum counterpart", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "interactions", "start": 64, "end": 76, "i_start": 9, "i_end": 9}, "action": {"text": "rise", "start": 88, "end": 92, "i_start": 12, "i_end": 12}}], "id": 967}, {"sent": "due to its edge-preserving properties a frequent choice for the regularization term is the total variation semi-norm introduced by rudin , osher and fatemi .", "tokens": ["due", "to", "its", "edge", "-", "preserving", "properties", "a", "frequent", "choice", "for", "the", "regularization", "term", "is", "the", "total", "variation", "semi", "-", "norm", "introduced", "by", "rudin", ",", "osher", "and", "fatemi", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a frequent choice for the regularization term", "start": 38, "end": 83, "i_start": 7, "i_end": 13}, "verb": {"text": "is", "start": 84, "end": 86, "i_start": 14, "i_end": 14}}, {"character": {"text": "rudin", "start": 131, "end": 136, "i_start": 23, "i_end": 23}, "action": {"text": "introduced", "start": 117, "end": 127, "i_start": 21, "i_end": 21}}, {"character": {"text": "osher", "start": 139, "end": 144, "i_start": 25, "i_end": 25}, "action": {"text": "introduced", "start": 117, "end": 127, "i_start": 21, "i_end": 21}}, {"character": {"text": "fatemi", "start": 149, "end": 155, "i_start": 27, "i_end": 27}, "action": {"text": "introduced", "start": 117, "end": 127, "i_start": 21, "i_end": 21}}], "id": 968}, {"sent": "on the global correspondence between gl and division algebras .", "tokens": ["on", "the", "global", "correspondence", "between", "gl", "and", "division", "algebras", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 969}, {"sent": "convolutional neural networks have recently brought in revolutions to the computer vision area .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "brought", "in", "revolutions", "to", "the", "computer", "vision", "area", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "brought in", "start": 44, "end": 54, "i_start": 5, "i_end": 6}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "brought", "start": 44, "end": 51, "i_start": 5, "i_end": 5}}], "id": 970}, {"sent": "convolutional neural networks have gained remarkable success on a variety of visual recognition tasks .", "tokens": ["convolutional", "neural", "networks", "have", "gained", "remarkable", "success", "on", "a", "variety", "of", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have gained", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "gained", "start": 35, "end": 41, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 53, "end": 60, "i_start": 6, "i_end": 6}}], "id": 971}, {"sent": "in this case , there is no obvious duality condition and the equations of motion must be solved directly for the perturbed instanton solutions .", "tokens": ["in", "this", "case", ",", "there", "is", "no", "obvious", "duality", "condition", "and", "the", "equations", "of", "motion", "must", "be", "solved", "directly", "for", "the", "perturbed", "instanton", "solutions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 15, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the equations of motion", "start": 57, "end": 80, "i_start": 11, "i_end": 14}, "verb": {"text": "solved", "start": 89, "end": 95, "i_start": 17, "i_end": 17}}], "id": 972}, {"sent": "neural networks have proved their efficiency in solving classification problems in areas such as computer vision .", "tokens": ["neural", "networks", "have", "proved", "their", "efficiency", "in", "solving", "classification", "problems", "in", "areas", "such", "as", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have proved", "start": 16, "end": 27, "i_start": 2, "i_end": 3}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "proved", "start": 21, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "solving", "start": 48, "end": 55, "i_start": 7, "i_end": 7}}], "id": 973}, {"sent": "it is also shown that essentially the same result is obtained in an anderson model constructed with the j-j coupling scheme .", "tokens": ["it", "is", "also", "shown", "that", "essentially", "the", "same", "result", "is", "obtained", "in", "an", "anderson", "model", "constructed", "with", "the", "j", "-", "j", "coupling", "scheme", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the same result", "start": 34, "end": 49, "i_start": 6, "i_end": 8}, "verb": {"text": "shown", "start": 11, "end": 16, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "obtained", "start": 53, "end": 61, "i_start": 10, "i_end": 10}}], "id": 974}, {"sent": "reinforcement learning is a machine learning problem that is used to train the machine to take actions in environments to maximize the reward .", "tokens": ["reinforcement", "learning", "is", "a", "machine", "learning", "problem", "that", "is", "used", "to", "train", "the", "machine", "to", "take", "actions", "in", "environments", "to", "maximize", "the", "reward", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "machine", "start": 28, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "maximize", "start": 122, "end": 130, "i_start": 20, "i_end": 20}}], "id": 975}, {"sent": "a limit theorem for the maximum of autoregressive processes with uniform marginal distribution .", "tokens": ["a", "limit", "theorem", "for", "the", "maximum", "of", "autoregressive", "processes", "with", "uniform", "marginal", "distribution", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 976}, {"sent": "we have 8 such coefficients which is the number of coefficients needed to describe a three-qubit state .", "tokens": ["we", "have", "8", "such", "coefficients", "which", "is", "the", "number", "of", "coefficients", "needed", "to", "describe", "a", "three", "-", "qubit", "state", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "have", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 977}, {"sent": "we use stochastic gradient descent with the adam solver to train our model .", "tokens": ["we", "use", "stochastic", "gradient", "descent", "with", "the", "adam", "solver", "to", "train", "our", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "solver", "start": 49, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 59, "end": 64, "i_start": 10, "i_end": 10}}], "id": 978}, {"sent": "in recent years , convolutional neural networks have shown excellent performance on classification problems when large-scale labeled datasets are available .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "shown", "excellent", "performance", "on", "classification", "problems", "when", "large", "-", "scale", "labeled", "datasets", "are", "available", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have shown", "start": 48, "end": 58, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "shown", "start": 53, "end": 58, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 69, "end": 80, "i_start": 10, "i_end": 10}}], "id": 979}, {"sent": "the rise and fall times , fwhm and area of the pulses are highly correlated with each other .", "tokens": ["the", "rise", "and", "fall", "times", ",", "fwhm", "and", "area", "of", "the", "pulses", "are", "highly", "correlated", "with", "each", "other", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 980}, {"sent": "in this paper , we consider a wireless broadcast problem where a sender wishes to broadcast a block p of k data packets to a set of n receivers using linear network coding .", "tokens": ["in", "this", "paper", ",", "we", "consider", "a", "wireless", "broadcast", "problem", "where", "a", "sender", "wishes", "to", "broadcast", "a", "block", "p", "of", "k", "data", "packets", "to", "a", "set", "of", "n", "receivers", "using", "linear", "network", "coding", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "consider", "start": 19, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "consider", "start": 19, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "set", "start": 125, "end": 128, "i_start": 25, "i_end": 25}, "action": {"text": "using", "start": 144, "end": 149, "i_start": 29, "i_end": 29}}], "id": 981}, {"sent": "convolutional neural networks have seen tremendous success across different problems including image classification .", "tokens": ["convolutional", "neural", "networks", "have", "seen", "tremendous", "success", "across", "different", "problems", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have seen", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "seen", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 51, "end": 58, "i_start": 6, "i_end": 6}}], "id": 982}, {"sent": "we now imagine computing renormalized one-loop matrix elements of these currents between the vacuum and an on-shell background supergravity state .", "tokens": ["we", "now", "imagine", "computing", "renormalized", "one", "-", "loop", "matrix", "elements", "of", "these", "currents", "between", "the", "vacuum", "and", "an", "on", "-", "shell", "background", "supergravity", "state", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "imagine", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "imagine", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}], "id": 983}, {"sent": "goodfellow et al propose an efficient single step attack called fgsm based on network linearity .", "tokens": ["goodfellow", "et", "al", "propose", "an", "efficient", "single", "step", "attack", "called", "fgsm", "based", "on", "network", "linearity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "goodfellow", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}], "id": 984}, {"sent": "hence we will use the indistinguishability notion of differential privacy .", "tokens": ["hence", "we", "will", "use", "the", "indistinguishability", "notion", "of", "differential", "privacy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 6, "end": 8, "i_start": 1, "i_end": 1}, "verb": {"text": "will use", "start": 9, "end": 17, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "use", "start": 14, "end": 17, "i_start": 3, "i_end": 3}}], "id": 985}, {"sent": "liu et al improved the quality of depth by combining a superpixel-based conditional random field to a cnn .", "tokens": ["liu", "et", "al", "improved", "the", "quality", "of", "depth", "by", "combining", "a", "superpixel", "-", "based", "conditional", "random", "field", "to", "a", "cnn", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "liu et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "improved", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "liu", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "improved", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "liu", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "combining", "start": 43, "end": 52, "i_start": 9, "i_end": 9}}], "id": 986}, {"sent": "therefore we can conclude that the spacetime is i-non-degenerate .", "tokens": ["therefore", "we", "can", "conclude", "that", "the", "spacetime", "is", "i", "-", "non", "-", "degenerate", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 1, "i_end": 1}, "verb": {"text": "can conclude", "start": 13, "end": 25, "i_start": 2, "i_end": 3}}, {"subject": {"text": "we", "start": 10, "end": 12, "i_start": 1, "i_end": 1}, "verb": {"text": "is", "start": 45, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "conclude", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}], "id": 987}, {"sent": "it was illustrated by ding et al that complete weight enumerators can be applied to the calculation of the deception probabilities of certain authentication codes .", "tokens": ["it", "was", "illustrated", "by", "ding", "et", "al", "that", "complete", "weight", "enumerators", "can", "be", "applied", "to", "the", "calculation", "of", "the", "deception", "probabilities", "of", "certain", "authentication", "codes", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "was illustrated", "start": 3, "end": 18, "i_start": 1, "i_end": 2}}, {"subject": {"text": "that complete weight enumerators", "start": 33, "end": 65, "i_start": 7, "i_end": 10}, "verb": {"text": "applied", "start": 73, "end": 80, "i_start": 13, "i_end": 13}}, {"character": {"text": "ding", "start": 22, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "illustrated", "start": 7, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "codes", "start": 157, "end": 162, "i_start": 24, "i_end": 24}, "action": {"text": "authentication", "start": 142, "end": 156, "i_start": 23, "i_end": 23}}], "id": 988}, {"sent": "deep convolutional neural networks have experienced a recent surge in computer vision research due to their immense success for visual recognition tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "experienced", "a", "recent", "surge", "in", "computer", "vision", "research", "due", "to", "their", "immense", "success", "for", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have experienced", "start": 35, "end": 51, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "experienced", "start": 40, "end": 51, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 116, "end": 123, "i_start": 17, "i_end": 17}}], "id": 989}, {"sent": "the interfaces will also show what the organization believes in and does not .", "tokens": ["the", "interfaces", "will", "also", "show", "what", "the", "organization", "believes", "in", "and", "does", "not", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the organization", "start": 35, "end": 51, "i_start": 6, "i_end": 7}, "verb": {"text": "show", "start": 25, "end": 29, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the interfaces", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "will", "start": 15, "end": 19, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the interfaces", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "believes", "start": 52, "end": 60, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the organization", "start": 35, "end": 51, "i_start": 6, "i_end": 7}, "verb": {"text": "does", "start": 68, "end": 72, "i_start": 11, "i_end": 11}}, {"character": {"text": "interfaces", "start": 4, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 25, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "organization", "start": 39, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "believes", "start": 52, "end": 60, "i_start": 8, "i_end": 8}}, {"character": {"text": "organization", "start": 39, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "not", "start": 73, "end": 76, "i_start": 12, "i_end": 12}}], "id": 990}, {"sent": "bert pretrained models like bert and elmo have shown great efficacy in many natural language processing tasks .", "tokens": ["bert", "pretrained", "models", "like", "bert", "and", "elmo", "have", "shown", "great", "efficacy", "in", "many", "natural", "language", "processing", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bert pretrained models like bert and elmo", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "have shown", "start": 42, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "models", "start": 16, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 47, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "bert", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "pretrained", "start": 5, "end": 15, "i_start": 1, "i_end": 1}}], "id": 991}, {"sent": "not all equations from this class are integrable and we derive those of them that have y-symmetries .", "tokens": ["not", "all", "equations", "from", "this", "class", "are", "integrable", "and", "we", "derive", "those", "of", "them", "that", "have", "y", "-", "symmetries", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "not all equations from this class", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}, {"subject": {"text": "we", "start": 53, "end": 55, "i_start": 9, "i_end": 9}, "verb": {"text": "derive", "start": 56, "end": 62, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 53, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "derive", "start": 56, "end": 62, "i_start": 10, "i_end": 10}}], "id": 992}, {"sent": "deep convolutional neural networks have been successfully used in various computer vision applications such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successfully", "used", "in", "various", "computer", "vision", "applications", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "used", "start": 58, "end": 62, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}], "id": 993}, {"sent": "over the past few years deep convolutional neural networks have emerged as the method of choice for the majority of computer vision tasks that require learning from data .", "tokens": ["over", "the", "past", "few", "years", "deep", "convolutional", "neural", "networks", "have", "emerged", "as", "the", "method", "of", "choice", "for", "the", "majority", "of", "computer", "vision", "tasks", "that", "require", "learning", "from", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 29, "end": 58, "i_start": 6, "i_end": 8}, "verb": {"text": "have emerged", "start": 59, "end": 71, "i_start": 9, "i_end": 10}}, {"character": {"text": "networks", "start": 50, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "emerged", "start": 64, "end": 71, "i_start": 10, "i_end": 10}}, {"character": {"text": "tasks", "start": 132, "end": 137, "i_start": 22, "i_end": 22}, "action": {"text": "require", "start": 143, "end": 150, "i_start": 24, "i_end": 24}}], "id": 994}, {"sent": "we will prove that specializations of modules preserve the exactness of an exact sequence .", "tokens": ["we", "will", "prove", "that", "specializations", "of", "modules", "preserve", "the", "exactness", "of", "an", "exact", "sequence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will prove", "start": 3, "end": 13, "i_start": 1, "i_end": 2}}, {"subject": {"text": "specializations of modules", "start": 19, "end": 45, "i_start": 4, "i_end": 6}, "verb": {"text": "preserve", "start": 46, "end": 54, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "prove", "start": 8, "end": 13, "i_start": 2, "i_end": 2}}], "id": 995}, {"sent": "quantum states are therefore usually nonlocal .", "tokens": ["quantum", "states", "are", "therefore", "usually", "nonlocal", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum states", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}], "id": 996}, {"sent": "the clustering coefficient cof node v i is defined as the ratio of the actual number of edges to the possible number of edges among neighbors of node v i .", "tokens": ["the", "clustering", "coefficient", "cof", "node", "v", "i", "is", "defined", "as", "the", "ratio", "of", "the", "actual", "number", "of", "edges", "to", "the", "possible", "number", "of", "edges", "among", "neighbors", "of", "node", "v", "i", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 997}, {"sent": "we employ a preprocessing scheme that matches the evaluation strategy later on for saliency map generation .", "tokens": ["we", "employ", "a", "preprocessing", "scheme", "that", "matches", "the", "evaluation", "strategy", "later", "on", "for", "saliency", "map", "generation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 998}, {"sent": "we assume below that the plasma only consist of one type of particles whereas the results below also hold for plasmas with several particle species .", "tokens": ["we", "assume", "below", "that", "the", "plasma", "only", "consist", "of", "one", "type", "of", "particles", "whereas", "the", "results", "below", "also", "hold", "for", "plasmas", "with", "several", "particle", "species", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the plasma", "start": 21, "end": 31, "i_start": 4, "i_end": 5}, "verb": {"text": "consist", "start": 37, "end": 44, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 999}, {"sent": "the perdew-burkeernzerhof generalized-gradient approximation is employed to describe the exchange and correlation functional .", "tokens": ["the", "perdew", "-", "burkeernzerhof", "generalized", "-", "gradient", "approximation", "is", "employed", "to", "describe", "the", "exchange", "and", "correlation", "functional", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the perdew-burkeernzerhof generalized-gradient approximation", "start": 0, "end": 60, "i_start": 0, "i_end": 7}, "verb": {"text": "is employed", "start": 61, "end": 72, "i_start": 8, "i_end": 9}}, {"character": {"text": "approximation", "start": 47, "end": 60, "i_start": 7, "i_end": 7}, "action": {"text": "describe", "start": 76, "end": 84, "i_start": 11, "i_end": 11}}], "id": 1000}, {"sent": "the notion of differential privacy provides a strong notion of individual privacy while permitting useful data analysis in machine learning tasks .", "tokens": ["the", "notion", "of", "differential", "privacy", "provides", "a", "strong", "notion", "of", "individual", "privacy", "while", "permitting", "useful", "data", "analysis", "in", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the notion of differential privacy", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "provides", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "notion", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "provides", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}], "id": 1001}, {"sent": "it is generated from 300w , in which it establishes a 3d morphable model and reconstruct the face appearance with varying head poses .", "tokens": ["it", "is", "generated", "from", "300w", ",", "in", "which", "it", "establishes", "a", "3d", "morphable", "model", "and", "reconstruct", "the", "face", "appearance", "with", "varying", "head", "poses", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is generated", "start": 3, "end": 15, "i_start": 1, "i_end": 2}}, {"character": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "establishes", "start": 40, "end": 51, "i_start": 9, "i_end": 9}}, {"character": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "reconstruct", "start": 77, "end": 88, "i_start": 15, "i_end": 15}}], "id": 1002}, {"sent": "statistical modeling techniques have been widely applied for learning multivariate time series either in the multiple linear regression setting .", "tokens": ["statistical", "modeling", "techniques", "have", "been", "widely", "applied", "for", "learning", "multivariate", "time", "series", "either", "in", "the", "multiple", "linear", "regression", "setting", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "statistical modeling techniques", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "applied", "start": 49, "end": 56, "i_start": 6, "i_end": 6}}, {"subject": {"text": "statistical modeling techniques", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 32, "end": 41, "i_start": 3, "i_end": 4}}], "id": 1003}, {"sent": "wackeroth , loop corrections in ww , these proceedings .", "tokens": ["wackeroth", ",", "loop", "corrections", "in", "ww", ",", "these", "proceedings", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1004}, {"sent": "recently , deep learning techniques have achieved great success in many ai applications such as image classification , speech recognition and generation , and natural language processing .", "tokens": ["recently", ",", "deep", "learning", "techniques", "have", "achieved", "great", "success", "in", "many", "ai", "applications", "such", "as", "image", "classification", ",", "speech", "recognition", "and", "generation", ",", "and", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning techniques", "start": 11, "end": 35, "i_start": 2, "i_end": 4}, "verb": {"text": "have achieved", "start": 36, "end": 49, "i_start": 5, "i_end": 6}}, {"character": {"text": "techniques", "start": 25, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 41, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "techniques", "start": 25, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "success", "start": 56, "end": 63, "i_start": 8, "i_end": 8}}], "id": 1005}, {"sent": "deep neural networks have significantly improved the performance of diverse data mining and computer vision applications .", "tokens": ["deep", "neural", "networks", "have", "significantly", "improved", "the", "performance", "of", "diverse", "data", "mining", "and", "computer", "vision", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "applications", "start": 108, "end": 120, "i_start": 15, "i_end": 15}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 7, "i_end": 7}}, {"character": {"text": "diverse", "start": 68, "end": 75, "i_start": 9, "i_end": 9}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 7, "i_end": 7}}], "id": 1006}, {"sent": "in this section , we explain the computation method which has been developed by ohya-masuda and accardi-sabbadini .", "tokens": ["in", "this", "section", ",", "we", "explain", "the", "computation", "method", "which", "has", "been", "developed", "by", "ohya", "-", "masuda", "and", "accardi", "-", "sabbadini", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "explain", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "explain", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "ohya", "start": 80, "end": 84, "i_start": 14, "i_end": 14}, "action": {"text": "developed", "start": 67, "end": 76, "i_start": 12, "i_end": 12}}, {"character": {"text": "accardi", "start": 96, "end": 103, "i_start": 18, "i_end": 18}, "action": {"text": "developed", "start": 67, "end": 76, "i_start": 12, "i_end": 12}}], "id": 1007}, {"sent": "recently , there have been more and more works on clustering in the deep learning literature .", "tokens": ["recently", ",", "there", "have", "been", "more", "and", "more", "works", "on", "clustering", "in", "the", "deep", "learning", "literature", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "have been", "start": 17, "end": 26, "i_start": 3, "i_end": 4}}], "id": 1008}, {"sent": "the emergence of deep convolutional neural networks has greatly contributed to advancements in solving complex tasks in computer vision with significantly improved performance .", "tokens": ["the", "emergence", "of", "deep", "convolutional", "neural", "networks", "has", "greatly", "contributed", "to", "advancements", "in", "solving", "complex", "tasks", "in", "computer", "vision", "with", "significantly", "improved", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the emergence of deep convolutional neural networks", "start": 0, "end": 51, "i_start": 0, "i_end": 6}, "verb": {"text": "contributed", "start": 64, "end": 75, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the emergence of deep convolutional neural networks", "start": 0, "end": 51, "i_start": 0, "i_end": 6}, "verb": {"text": "has", "start": 52, "end": 55, "i_start": 7, "i_end": 7}}, {"character": {"text": "emergence", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "contributed", "start": 64, "end": 75, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 43, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "emergence", "start": 4, "end": 13, "i_start": 1, "i_end": 1}}], "id": 1009}, {"sent": "deep neural networks have demonstrated to be effective models for solving a large variety of problems in several domains , including image , to name a few .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "to", "be", "effective", "models", "for", "solving", "a", "large", "variety", "of", "problems", "in", "several", "domains", ",", "including", "image", ",", "to", "name", "a", "few", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "models", "start": 55, "end": 61, "i_start": 8, "i_end": 8}, "action": {"text": "effective", "start": 45, "end": 54, "i_start": 7, "i_end": 7}}], "id": 1010}, {"sent": "obviously , gravity is a destabilizing effect since the heavy fluid is above the light one .", "tokens": ["obviously", ",", "gravity", "is", "a", "destabilizing", "effect", "since", "the", "heavy", "fluid", "is", "above", "the", "light", "one", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "gravity", "start": 12, "end": 19, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "gravity", "start": 12, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "destabilizing", "start": 25, "end": 38, "i_start": 5, "i_end": 5}}], "id": 1011}, {"sent": "as is well known , there is a maximal temperature for a gas of closed strings in thermal equilibrium , the hagedorn temperature t h .", "tokens": ["as", "is", "well", "known", ",", "there", "is", "a", "maximal", "temperature", "for", "a", "gas", "of", "closed", "strings", "in", "thermal", "equilibrium", ",", "the", "hagedorn", "temperature", "t", "h", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 19, "end": 24, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 6, "i_end": 6}}], "id": 1012}, {"sent": "however , one may still discuss the scale of fermion mass generation .", "tokens": ["however", ",", "one", "may", "still", "discuss", "the", "scale", "of", "fermion", "mass", "generation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 10, "end": 13, "i_start": 2, "i_end": 2}, "verb": {"text": "discuss", "start": 24, "end": 31, "i_start": 5, "i_end": 5}}, {"subject": {"text": "one", "start": 10, "end": 13, "i_start": 2, "i_end": 2}, "verb": {"text": "may", "start": 14, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "one", "start": 10, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "discuss", "start": 24, "end": 31, "i_start": 5, "i_end": 5}}], "id": 1013}, {"sent": "convolutional neural networks have achieved tremendous progress on many pattern recognition tasks , especially large-scale images recognition problems .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "tremendous", "progress", "on", "many", "pattern", "recognition", "tasks", ",", "especially", "large", "-", "scale", "images", "recognition", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 1014}, {"sent": "frames in hilbert spaces were introduced by duffin and schaeffer in 1952 to study some deep problems in nonharmonic fourier series .", "tokens": ["frames", "in", "hilbert", "spaces", "were", "introduced", "by", "duffin", "and", "schaeffer", "in", "1952", "to", "study", "some", "deep", "problems", "in", "nonharmonic", "fourier", "series", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "frames in hilbert spaces", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "were introduced", "start": 25, "end": 40, "i_start": 4, "i_end": 5}}, {"character": {"text": "duffin", "start": 44, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "introduced", "start": 30, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "schaeffer", "start": 55, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "introduced", "start": 30, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "duffin", "start": 44, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "study", "start": 76, "end": 81, "i_start": 13, "i_end": 13}}, {"character": {"text": "schaeffer", "start": 55, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "study", "start": 76, "end": 81, "i_start": 13, "i_end": 13}}], "id": 1015}, {"sent": "the original paper of goodfellow suggests the use of jensen-shannon divergence .", "tokens": ["the", "original", "paper", "of", "goodfellow", "suggests", "the", "use", "of", "jensen", "-", "shannon", "divergence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the original paper of goodfellow", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "suggests", "start": 33, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "paper", "start": 13, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "suggests", "start": 33, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "jensen", "start": 53, "end": 59, "i_start": 9, "i_end": 9}, "action": {"text": "divergence", "start": 68, "end": 78, "i_start": 12, "i_end": 12}}], "id": 1016}, {"sent": "townsley , in computer simulation studies in condensed matter physics x , edited by d .", "tokens": ["townsley", ",", "in", "computer", "simulation", "studies", "in", "condensed", "matter", "physics", "x", ",", "edited", "by", "d", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "townsley", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "edited", "start": 74, "end": 80, "i_start": 12, "i_end": 12}}], "id": 1017}, {"sent": "the ordinate is a strong function of \u03c4 and places a limit on the sky conditions which are usable for 450\u00b5m observations when accurate calibration is required .", "tokens": ["the", "ordinate", "is", "a", "strong", "function", "of", "\u03c4", "and", "places", "a", "limit", "on", "the", "sky", "conditions", "which", "are", "usable", "for", "450", "\u00b5m", "observations", "when", "accurate", "calibration", "is", "required", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ordinate", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the ordinate", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "places", "start": 43, "end": 49, "i_start": 9, "i_end": 9}}, {"character": {"text": "ordinate", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "limit", "start": 52, "end": 57, "i_start": 11, "i_end": 11}}], "id": 1018}, {"sent": "after every convolutional layer , batch normalization are applied to the output .", "tokens": ["after", "every", "convolutional", "layer", ",", "batch", "normalization", "are", "applied", "to", "the", "output", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "batch normalization", "start": 34, "end": 53, "i_start": 5, "i_end": 6}, "verb": {"text": "are applied", "start": 54, "end": 65, "i_start": 7, "i_end": 8}}], "id": 1019}, {"sent": "the framework of residual learning was introduced by he et al as a strategy to cope with the challenging optimization of deep models .", "tokens": ["the", "framework", "of", "residual", "learning", "was", "introduced", "by", "he", "et", "al", "as", "a", "strategy", "to", "cope", "with", "the", "challenging", "optimization", "of", "deep", "models", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the framework of residual learning", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "was introduced", "start": 35, "end": 49, "i_start": 5, "i_end": 6}}, {"character": {"text": "he", "start": 53, "end": 55, "i_start": 8, "i_end": 8}, "action": {"text": "introduced", "start": 39, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "he", "start": 53, "end": 55, "i_start": 8, "i_end": 8}, "action": {"text": "cope", "start": 79, "end": 83, "i_start": 15, "i_end": 15}}, {"character": {"text": "optimization", "start": 105, "end": 117, "i_start": 19, "i_end": 19}, "action": {"text": "challenging", "start": 93, "end": 104, "i_start": 18, "i_end": 18}}], "id": 1020}, {"sent": "seiberg , d-brane instantons and k-theory charges , j .", "tokens": ["seiberg", ",", "d", "-", "brane", "instantons", "and", "k", "-", "theory", "charges", ",", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1021}, {"sent": "we find that the trilayer spectrum is narrower than the bilayer spectrum but is wider than the monolayer spectrum .", "tokens": ["we", "find", "that", "the", "trilayer", "spectrum", "is", "narrower", "than", "the", "bilayer", "spectrum", "but", "is", "wider", "than", "the", "monolayer", "spectrum", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 1022}, {"sent": "deep learning has been used as a dramatically powerful tool in computer vision tasks such as image recognition .", "tokens": ["deep", "learning", "has", "been", "used", "as", "a", "dramatically", "powerful", "tool", "in", "computer", "vision", "tasks", "such", "as", "image", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has been used", "start": 14, "end": 27, "i_start": 2, "i_end": 4}}], "id": 1023}, {"sent": "let us consider each of these cases in turn .", "tokens": ["let", "us", "consider", "each", "of", "these", "cases", "in", "turn", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "consider", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "consider", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}], "id": 1024}, {"sent": "goodman and leveque also showed that in 2 space dimensions , any tvd scheme is generally at most first-order accurate .", "tokens": ["goodman", "and", "leveque", "also", "showed", "that", "in", "2", "space", "dimensions", ",", "any", "tvd", "scheme", "is", "generally", "at", "most", "first", "-", "order", "accurate", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodman and leveque", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 25, "end": 31, "i_start": 4, "i_end": 4}}, {"subject": {"text": "goodman and leveque", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 76, "end": 78, "i_start": 14, "i_end": 14}}, {"character": {"text": "goodman", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 25, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "leveque", "start": 12, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "showed", "start": 25, "end": 31, "i_start": 4, "i_end": 4}}], "id": 1025}, {"sent": "region-based convolutional neural networks have been recognized as one of the most effective tools for object detection .", "tokens": ["region", "-", "based", "convolutional", "neural", "networks", "have", "been", "recognized", "as", "one", "of", "the", "most", "effective", "tools", "for", "object", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "region-based convolutional neural networks", "start": 0, "end": 42, "i_start": 0, "i_end": 5}, "verb": {"text": "have been recognized", "start": 43, "end": 63, "i_start": 6, "i_end": 8}}], "id": 1026}, {"sent": "another option is to use the expectation conditional maximization algorithm proposed by .", "tokens": ["another", "option", "is", "to", "use", "the", "expectation", "conditional", "maximization", "algorithm", "proposed", "by", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another option", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 1027}, {"sent": "topological defects are believed to have formed in the numerous phase transitions in the early universe due to the kibble mechanism .", "tokens": ["topological", "defects", "are", "believed", "to", "have", "formed", "in", "the", "numerous", "phase", "transitions", "in", "the", "early", "universe", "due", "to", "the", "kibble", "mechanism", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "topological defects", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "are believed", "start": 20, "end": 32, "i_start": 2, "i_end": 3}}], "id": 1028}, {"sent": "the solid line represents the results from the integration of the gpe , while the dashed one the results obtained from the odes .", "tokens": ["the", "solid", "line", "represents", "the", "results", "from", "the", "integration", "of", "the", "gpe", ",", "while", "the", "dashed", "one", "the", "results", "obtained", "from", "the", "odes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the solid line", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "represents", "start": 15, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "line", "start": 10, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "represents", "start": 15, "end": 25, "i_start": 3, "i_end": 3}}], "id": 1029}, {"sent": "deep convolutional neural networks have enabled unparalleled breakthroughs in a variety of visual tasks , such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "enabled", "unparalleled", "breakthroughs", "in", "a", "variety", "of", "visual", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have enabled", "start": 35, "end": 47, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "enabled", "start": 40, "end": 47, "i_start": 5, "i_end": 5}}], "id": 1030}, {"sent": "the electronelectron exchange and correlation functional was described with the perdew-burke-ernzerhof 22 parametrization of the generalized gradient approximation .", "tokens": ["the", "electronelectron", "exchange", "and", "correlation", "functional", "was", "described", "with", "the", "perdew", "-", "burke", "-", "ernzerhof", "22", "parametrization", "of", "the", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electronelectron exchange and correlation functional", "start": 0, "end": 56, "i_start": 0, "i_end": 5}, "verb": {"text": "was described", "start": 57, "end": 70, "i_start": 6, "i_end": 7}}], "id": 1031}, {"sent": "deep neural networks have enabled recent breakthroughs on many tasks , such as image classification and speech recognition .", "tokens": ["deep", "neural", "networks", "have", "enabled", "recent", "breakthroughs", "on", "many", "tasks", ",", "such", "as", "image", "classification", "and", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have enabled", "start": 21, "end": 33, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "enabled", "start": 26, "end": 33, "i_start": 4, "i_end": 4}}], "id": 1032}, {"sent": "in recent years , convolutional neural networks s have emerged as the most powerful technique for image classification .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "s", "have", "emerged", "as", "the", "most", "powerful", "technique", "for", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks s", "start": 18, "end": 49, "i_start": 4, "i_end": 7}, "verb": {"text": "have emerged", "start": 50, "end": 62, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "emerged", "start": 55, "end": 62, "i_start": 9, "i_end": 9}}], "id": 1033}, {"sent": "this fractional order integration is the building bloc of the riemann-liouville and caputo calculus , the two most popular formulations of fractional calculus , as well as several other approaches to fractional calculus .", "tokens": ["this", "fractional", "order", "integration", "is", "the", "building", "bloc", "of", "the", "riemann", "-", "liouville", "and", "caputo", "calculus", ",", "the", "two", "most", "popular", "formulations", "of", "fractional", "calculus", ",", "as", "well", "as", "several", "other", "approaches", "to", "fractional", "calculus", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this fractional order integration", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 4, "i_end": 4}}, {"character": {"text": "bloc", "start": 50, "end": 54, "i_start": 7, "i_end": 7}, "action": {"text": "building", "start": 41, "end": 49, "i_start": 6, "i_end": 6}}], "id": 1034}, {"sent": "moreover , psychological evidence indicates that human similarity ratings are reflected better by the manhattan metric than by the euclidean metric if different domains are involved .", "tokens": ["moreover", ",", "psychological", "evidence", "indicates", "that", "human", "similarity", "ratings", "are", "reflected", "better", "by", "the", "manhattan", "metric", "than", "by", "the", "euclidean", "metric", "if", "different", "domains", "are", "involved", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "psychological evidence", "start": 11, "end": 33, "i_start": 2, "i_end": 3}, "verb": {"text": "indicates", "start": 34, "end": 43, "i_start": 4, "i_end": 4}}, {"subject": {"text": "human similarity ratings", "start": 49, "end": 73, "i_start": 6, "i_end": 8}, "verb": {"text": "reflected", "start": 78, "end": 87, "i_start": 10, "i_end": 10}}, {"character": {"text": "evidence", "start": 25, "end": 33, "i_start": 3, "i_end": 3}, "action": {"text": "indicates", "start": 34, "end": 43, "i_start": 4, "i_end": 4}}], "id": 1035}, {"sent": "one can then compare upper bounds at a particular confidence level with a confidence band at a particular cl to assess if they are compatible .", "tokens": ["one", "can", "then", "compare", "upper", "bounds", "at", "a", "particular", "confidence", "level", "with", "a", "confidence", "band", "at", "a", "particular", "cl", "to", "assess", "if", "they", "are", "compatible", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "can", "start": 4, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "assess", "start": 112, "end": 118, "i_start": 20, "i_end": 20}}], "id": 1036}, {"sent": "kg has no non- zero s-semi nilpotent ideals .", "tokens": ["kg", "has", "no", "non-", "zero", "s", "-", "semi", "nilpotent", "ideals", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "kg", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 1037}, {"sent": "the hyperparameters w k and \u03c3 k can be learned using the expectation maximization algorithm .", "tokens": ["the", "hyperparameters", "w", "k", "and", "\u03c3", "k", "can", "be", "learned", "using", "the", "expectation", "maximization", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the hyperparameters w k and \u03c3 k", "start": 0, "end": 31, "i_start": 0, "i_end": 6}, "verb": {"text": "can be learned", "start": 32, "end": 46, "i_start": 7, "i_end": 9}}], "id": 1038}, {"sent": "the edge spectral channels are usually discarded because they are the worst affected by aliasing .", "tokens": ["the", "edge", "spectral", "channels", "are", "usually", "discarded", "because", "they", "are", "the", "worst", "affected", "by", "aliasing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the edge spectral channels", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "discarded", "start": 39, "end": 48, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the edge spectral channels", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 27, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "affected", "start": 76, "end": 84, "i_start": 12, "i_end": 12}, "action": {"text": "because", "start": 49, "end": 56, "i_start": 7, "i_end": 7}}, {"character": {"text": "aliasing", "start": 88, "end": 96, "i_start": 14, "i_end": 14}, "action": {"text": "affected", "start": 76, "end": 84, "i_start": 12, "i_end": 12}}], "id": 1039}, {"sent": "a foliation endowed with a transverse riemannian structure is called a riemannian foliation .", "tokens": ["a", "foliation", "endowed", "with", "a", "transverse", "riemannian", "structure", "is", "called", "a", "riemannian", "foliation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a foliation endowed with a transverse riemannian structure", "start": 0, "end": 58, "i_start": 0, "i_end": 7}, "verb": {"text": "is called", "start": 59, "end": 68, "i_start": 8, "i_end": 9}}], "id": 1040}, {"sent": "the kinetic energy is the dependence of the energy on quasi-momentum for the considered band .", "tokens": ["the", "kinetic", "energy", "is", "the", "dependence", "of", "the", "energy", "on", "quasi", "-", "momentum", "for", "the", "considered", "band", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the kinetic energy", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "energy", "start": 12, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "dependence", "start": 26, "end": 36, "i_start": 5, "i_end": 5}}], "id": 1041}, {"sent": "however , if the gravitino is the lsp , the next-to-lightest supersymmetric particle decays to its standard model partner and a gravitino .", "tokens": ["however", ",", "if", "the", "gravitino", "is", "the", "lsp", ",", "the", "next", "-", "to", "-", "lightest", "supersymmetric", "particle", "decays", "to", "its", "standard", "model", "partner", "and", "a", "gravitino", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the next-to-lightest supersymmetric particle", "start": 40, "end": 84, "i_start": 9, "i_end": 16}, "verb": {"text": "decays", "start": 85, "end": 91, "i_start": 17, "i_end": 17}}, {"character": {"text": "particle", "start": 76, "end": 84, "i_start": 16, "i_end": 16}, "action": {"text": "decays", "start": 85, "end": 91, "i_start": 17, "i_end": 17}}, {"character": {"text": "gravitino", "start": 17, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "partner", "start": 114, "end": 121, "i_start": 22, "i_end": 22}}], "id": 1042}, {"sent": "an absence of adequate training can significantly compromise the clinical outcome , which has been shown in numerous studies .", "tokens": ["an", "absence", "of", "adequate", "training", "can", "significantly", "compromise", "the", "clinical", "outcome", ",", "which", "has", "been", "shown", "in", "numerous", "studies", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "an absence of adequate training", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "compromise", "start": 50, "end": 60, "i_start": 7, "i_end": 7}}, {"subject": {"text": "an absence of adequate training", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "can", "start": 32, "end": 35, "i_start": 5, "i_end": 5}}, {"character": {"text": "absence", "start": 3, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "compromise", "start": 50, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "studies", "start": 117, "end": 124, "i_start": 18, "i_end": 18}, "action": {"text": "shown", "start": 99, "end": 104, "i_start": 15, "i_end": 15}}], "id": 1043}, {"sent": "deep reinforcement learning has demonstrated remarkable progress in recent years , achieving high levels of performance across a wide array of challenging tasks , including atari games , locomotion , and 3d navigation .", "tokens": ["deep", "reinforcement", "learning", "has", "demonstrated", "remarkable", "progress", "in", "recent", "years", ",", "achieving", "high", "levels", "of", "performance", "across", "a", "wide", "array", "of", "challenging", "tasks", ",", "including", "atari", "games", ",", "locomotion", ",", "and", "3d", "navigation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep reinforcement learning", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "has demonstrated", "start": 28, "end": 44, "i_start": 3, "i_end": 4}}, {"character": {"text": "learning", "start": 19, "end": 27, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 32, "end": 44, "i_start": 4, "i_end": 4}}], "id": 1044}, {"sent": "yosinski et al verified lower layer features are more general and higher layer features have a greater specificity .", "tokens": ["yosinski", "et", "al", "verified", "lower", "layer", "features", "are", "more", "general", "and", "higher", "layer", "features", "have", "a", "greater", "specificity", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 9, "end": 14, "i_start": 1, "i_end": 2}, "verb": {"text": "verified", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"subject": {"text": "more general and higher layer features", "start": 49, "end": 87, "i_start": 8, "i_end": 13}, "verb": {"text": "are", "start": 45, "end": 48, "i_start": 7, "i_end": 7}}, {"subject": {"text": "et al", "start": 9, "end": 14, "i_start": 1, "i_end": 2}, "verb": {"text": "have", "start": 88, "end": 92, "i_start": 14, "i_end": 14}}, {"character": {"text": "yosinski", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "verified", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 1045}, {"sent": "both criteria have been previously applied to evaluate single-photon implementations of qkd .", "tokens": ["both", "criteria", "have", "been", "previously", "applied", "to", "evaluate", "single", "-", "photon", "implementations", "of", "qkd", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "both criteria", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "applied", "start": 35, "end": 42, "i_start": 5, "i_end": 5}}, {"subject": {"text": "both criteria", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "have been", "start": 14, "end": 23, "i_start": 2, "i_end": 3}}], "id": 1046}, {"sent": "the free analogue of the symmetric group s n was constructed by wang in .", "tokens": ["the", "free", "analogue", "of", "the", "symmetric", "group", "s", "n", "was", "constructed", "by", "wang", "in", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the free analogue of the symmetric group s", "start": 0, "end": 42, "i_start": 0, "i_end": 7}, "verb": {"text": "n was constructed", "start": 43, "end": 60, "i_start": 8, "i_end": 10}}, {"character": {"text": "wang in", "start": 64, "end": 71, "i_start": 12, "i_end": 13}, "action": {"text": "constructed", "start": 49, "end": 60, "i_start": 10, "i_end": 10}}], "id": 1047}, {"sent": "the widely used bleu metrics are reported in our quantitative evaluation of the performance of the proposed model and baselines in the literature .", "tokens": ["the", "widely", "used", "bleu", "metrics", "are", "reported", "in", "our", "quantitative", "evaluation", "of", "the", "performance", "of", "the", "proposed", "model", "and", "baselines", "in", "the", "literature", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the widely used bleu metrics", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "are reported", "start": 29, "end": 41, "i_start": 5, "i_end": 6}}, {"character": {"text": "model", "start": 108, "end": 113, "i_start": 17, "i_end": 17}, "action": {"text": "performance", "start": 80, "end": 91, "i_start": 13, "i_end": 13}}, {"character": {"text": "baselines", "start": 118, "end": 127, "i_start": 19, "i_end": 19}, "action": {"text": "performance", "start": 80, "end": 91, "i_start": 13, "i_end": 13}}, {"character": {"text": "literature", "start": 135, "end": 145, "i_start": 22, "i_end": 22}, "action": {"text": "performance", "start": 80, "end": 91, "i_start": 13, "i_end": 13}}], "id": 1048}, {"sent": "the pascal-s dataset is derived from the validation set of pascal voc 2010 , as it contains 100 images , each with two salient objects .", "tokens": ["the", "pascal", "-", "s", "dataset", "is", "derived", "from", "the", "validation", "set", "of", "pascal", "voc", "2010", ",", "as", "it", "contains", "100", "images", ",", "each", "with", "two", "salient", "objects", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the pascal-s dataset", "start": 0, "end": 20, "i_start": 0, "i_end": 4}, "verb": {"text": "is derived", "start": 21, "end": 31, "i_start": 5, "i_end": 6}}, {"character": {"text": "set", "start": 52, "end": 55, "i_start": 10, "i_end": 10}, "action": {"text": "validation", "start": 41, "end": 51, "i_start": 9, "i_end": 9}}, {"character": {"text": "dataset", "start": 13, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "contains", "start": 83, "end": 91, "i_start": 18, "i_end": 18}}], "id": 1049}, {"sent": "exponentiation gives , which is the expected unit expectation value of the straight line wilson loop .", "tokens": ["exponentiation", "gives", ",", "which", "is", "the", "expected", "unit", "expectation", "value", "of", "the", "straight", "line", "wilson", "loop", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "exponentiation", "start": 0, "end": 14, "i_start": 0, "i_end": 0}, "verb": {"text": "gives", "start": 15, "end": 20, "i_start": 1, "i_end": 1}}, {"character": {"text": "exponentiation", "start": 0, "end": 14, "i_start": 0, "i_end": 0}, "action": {"text": "gives", "start": 15, "end": 20, "i_start": 1, "i_end": 1}}], "id": 1050}, {"sent": "recent work has exhibited the effectiveness of visual analytics in understanding , diagnosing and presenting neural networks .", "tokens": ["recent", "work", "has", "exhibited", "the", "effectiveness", "of", "visual", "analytics", "in", "understanding", ",", "diagnosing", "and", "presenting", "neural", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent work", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "has exhibited", "start": 12, "end": 25, "i_start": 2, "i_end": 3}}, {"character": {"text": "work", "start": 7, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "exhibited", "start": 16, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "analytics", "start": 54, "end": 63, "i_start": 8, "i_end": 8}, "action": {"text": "effectiveness", "start": 30, "end": 43, "i_start": 5, "i_end": 5}}], "id": 1051}, {"sent": "similarly , mao et al use the multimodal fusion layer to fuse the image features and word representation at each time step .", "tokens": ["similarly", ",", "mao", "et", "al", "use", "the", "multimodal", "fusion", "layer", "to", "fuse", "the", "image", "features", "and", "word", "representation", "at", "each", "time", "step", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "mao et al", "start": 12, "end": 21, "i_start": 2, "i_end": 4}, "verb": {"text": "use", "start": 22, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "mao", "start": 12, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 22, "end": 25, "i_start": 5, "i_end": 5}}], "id": 1052}, {"sent": "a large number of domainspecific network programming languages have been proposed over the past few years , driven by rapidly expanding infrastructures and the emergence of software-defined networking .", "tokens": ["a", "large", "number", "of", "domainspecific", "network", "programming", "languages", "have", "been", "proposed", "over", "the", "past", "few", "years", ",", "driven", "by", "rapidly", "expanding", "infrastructures", "and", "the", "emergence", "of", "software", "-", "defined", "networking", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a large number of domainspecific network programming languages", "start": 0, "end": 62, "i_start": 0, "i_end": 7}, "verb": {"text": "have been proposed", "start": 63, "end": 81, "i_start": 8, "i_end": 10}}, {"character": {"text": "languages", "start": 53, "end": 62, "i_start": 7, "i_end": 7}, "action": {"text": "programming", "start": 41, "end": 52, "i_start": 6, "i_end": 6}}, {"character": {"text": "expanding", "start": 126, "end": 135, "i_start": 20, "i_end": 20}, "action": {"text": "driven", "start": 108, "end": 114, "i_start": 17, "i_end": 17}}, {"character": {"text": "rapidly", "start": 118, "end": 125, "i_start": 19, "i_end": 19}, "action": {"text": "driven", "start": 108, "end": 114, "i_start": 17, "i_end": 17}}, {"character": {"text": "emergence", "start": 160, "end": 169, "i_start": 24, "i_end": 24}, "action": {"text": "driven", "start": 108, "end": 114, "i_start": 17, "i_end": 17}}, {"character": {"text": "software", "start": 173, "end": 181, "i_start": 26, "i_end": 26}, "action": {"text": "defined", "start": 182, "end": 189, "i_start": 28, "i_end": 28}}], "id": 1053}, {"sent": "previous research on detection in mimo systems with a large number of transmit antennas has focused on hard decision algorithms .", "tokens": ["previous", "research", "on", "detection", "in", "mimo", "systems", "with", "a", "large", "number", "of", "transmit", "antennas", "has", "focused", "on", "hard", "decision", "algorithms", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "previous research on detection in mimo systems with a large number of transmit antennas", "start": 0, "end": 87, "i_start": 0, "i_end": 13}, "verb": {"text": "has focused", "start": 88, "end": 99, "i_start": 14, "i_end": 15}}, {"character": {"text": "systems", "start": 39, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "has", "start": 88, "end": 91, "i_start": 14, "i_end": 14}}], "id": 1054}, {"sent": "in , zhu et al studied using multiple nearby vehicles to collaboratively download data from an rsu and analyzed the average download time using the network coding techniques .", "tokens": ["in", ",", "zhu", "et", "al", "studied", "using", "multiple", "nearby", "vehicles", "to", "collaboratively", "download", "data", "from", "an", "rsu", "and", "analyzed", "the", "average", "download", "time", "using", "the", "network", "coding", "techniques", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhu et al", "start": 5, "end": 14, "i_start": 2, "i_end": 4}, "verb": {"text": "studied", "start": 15, "end": 22, "i_start": 5, "i_end": 5}}, {"character": {"text": "zhu", "start": 5, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "studied", "start": 15, "end": 22, "i_start": 5, "i_end": 5}}, {"character": {"text": "zhu", "start": 5, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "using", "start": 23, "end": 28, "i_start": 6, "i_end": 6}}, {"character": {"text": "zhu", "start": 5, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "download", "start": 73, "end": 81, "i_start": 12, "i_end": 12}}], "id": 1055}, {"sent": "mikolov et al introduced the skip-gram model , which predicts the surrounding context words given the target word to avoid many dense matrix multiplications .", "tokens": ["mikolov", "et", "al", "introduced", "the", "skip", "-", "gram", "model", ",", "which", "predicts", "the", "surrounding", "context", "words", "given", "the", "target", "word", "to", "avoid", "many", "dense", "matrix", "multiplications", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 8, "end": 13, "i_start": 1, "i_end": 2}, "verb": {"text": "introduced", "start": 14, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "mikolov", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 14, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "model", "start": 39, "end": 44, "i_start": 8, "i_end": 8}, "action": {"text": "predicts", "start": 53, "end": 61, "i_start": 11, "i_end": 11}}, {"character": {"text": "mikolov", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "avoid", "start": 117, "end": 122, "i_start": 21, "i_end": 21}}], "id": 1056}, {"sent": "the higgs is a composite of fermions interacting via strong dynamics at the 10 tev scale .", "tokens": ["the", "higgs", "is", "a", "composite", "of", "fermions", "interacting", "via", "strong", "dynamics", "at", "the", "10", "tev", "scale", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the higgs", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "fermions", "start": 28, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "interacting", "start": 37, "end": 48, "i_start": 7, "i_end": 7}}], "id": 1057}, {"sent": "in particular , a substantial amount of work has focused on the study of asymptotic computational complexity of quantile estimation algorithms .", "tokens": ["in", "particular", ",", "a", "substantial", "amount", "of", "work", "has", "focused", "on", "the", "study", "of", "asymptotic", "computational", "complexity", "of", "quantile", "estimation", "algorithms", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a substantial amount of work", "start": 16, "end": 44, "i_start": 3, "i_end": 7}, "verb": {"text": "has focused", "start": 45, "end": 56, "i_start": 8, "i_end": 9}}], "id": 1058}, {"sent": "historically , many of the se process applications were in the aerospace industry and the defense industry .", "tokens": ["historically", ",", "many", "of", "the", "se", "process", "applications", "were", "in", "the", "aerospace", "industry", "and", "the", "defense", "industry", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many of the se process applications", "start": 15, "end": 50, "i_start": 2, "i_end": 7}, "verb": {"text": "were", "start": 51, "end": 55, "i_start": 8, "i_end": 8}}], "id": 1059}, {"sent": "convolutional neural networks have been largely responsible for the significant progress achieved on visual recognition tasks in recent years .", "tokens": ["convolutional", "neural", "networks", "have", "been", "largely", "responsible", "for", "the", "significant", "progress", "achieved", "on", "visual", "recognition", "tasks", "in", "recent", "years", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "responsible", "start": 48, "end": 59, "i_start": 6, "i_end": 6}}], "id": 1060}, {"sent": "today , directed percolation is considered as the most important universality class of absorbing phase transitions .", "tokens": ["today", ",", "directed", "percolation", "is", "considered", "as", "the", "most", "important", "universality", "class", "of", "absorbing", "phase", "transitions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "class", "start": 78, "end": 83, "i_start": 11, "i_end": 11}, "action": {"text": "absorbing", "start": 87, "end": 96, "i_start": 13, "i_end": 13}}], "id": 1061}, {"sent": "the same technique and direct simulations for other nonlinearities suggest quadratic speed enhancement in the small rms regime .", "tokens": ["the", "same", "technique", "and", "direct", "simulations", "for", "other", "nonlinearities", "suggest", "quadratic", "speed", "enhancement", "in", "the", "small", "rms", "regime", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the same technique and direct simulations for other nonlinearities", "start": 0, "end": 66, "i_start": 0, "i_end": 8}, "verb": {"text": "suggest", "start": 67, "end": 74, "i_start": 9, "i_end": 9}}, {"character": {"text": "technique", "start": 9, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "suggest", "start": 67, "end": 74, "i_start": 9, "i_end": 9}}, {"character": {"text": "simulations", "start": 30, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "suggest", "start": 67, "end": 74, "i_start": 9, "i_end": 9}}, {"character": {"text": "other", "start": 46, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "suggest", "start": 67, "end": 74, "i_start": 9, "i_end": 9}}], "id": 1062}, {"sent": "in recent years , deep learning methods based on convolutional neural networks have dominated nearly all tasks involving image recognition , outperforming competing methods by a large margin on almost all existing benchmarks .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "methods", "based", "on", "convolutional", "neural", "networks", "have", "dominated", "nearly", "all", "tasks", "involving", "image", "recognition", ",", "outperforming", "competing", "methods", "by", "a", "large", "margin", "on", "almost", "all", "existing", "benchmarks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning methods based on convolutional neural networks", "start": 18, "end": 78, "i_start": 4, "i_end": 11}, "verb": {"text": "have dominated", "start": 79, "end": 93, "i_start": 12, "i_end": 13}}, {"character": {"text": "methods", "start": 32, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "dominated", "start": 84, "end": 93, "i_start": 13, "i_end": 13}}], "id": 1063}, {"sent": "this decrease is a result of an accumulation of surface roughness with each superlattice cycle and a gradual decrease in emission current of the rheed gun , which was not adjusted during deposition .", "tokens": ["this", "decrease", "is", "a", "result", "of", "an", "accumulation", "of", "surface", "roughness", "with", "each", "superlattice", "cycle", "and", "a", "gradual", "decrease", "in", "emission", "current", "of", "the", "rheed", "gun", ",", "which", "was", "not", "adjusted", "during", "deposition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this decrease", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1064}, {"sent": "then , we expressed the stochastic process that is the expected payoff for both the call and put options at the money in terms of the solution to the schroedinger equation .", "tokens": ["then", ",", "we", "expressed", "the", "stochastic", "process", "that", "is", "the", "expected", "payoff", "for", "both", "the", "call", "and", "put", "options", "at", "the", "money", "in", "terms", "of", "the", "solution", "to", "the", "schroedinger", "equation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "expressed", "start": 10, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "expressed", "start": 10, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "put", "start": 93, "end": 96, "i_start": 17, "i_end": 17}}], "id": 1065}, {"sent": "the most popular generative model used to test community detection algorithms , has been defined by newman and girvan .", "tokens": ["the", "most", "popular", "generative", "model", "used", "to", "test", "community", "detection", "algorithms", ",", "has", "been", "defined", "by", "newman", "and", "girvan", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the most popular generative model used to test community detection algorithms", "start": 0, "end": 77, "i_start": 0, "i_end": 10}, "verb": {"text": "has been defined", "start": 80, "end": 96, "i_start": 12, "i_end": 14}}, {"character": {"text": "newman", "start": 100, "end": 106, "i_start": 16, "i_end": 16}, "action": {"text": "defined", "start": 89, "end": 96, "i_start": 14, "i_end": 14}}, {"character": {"text": "girvan", "start": 111, "end": 117, "i_start": 18, "i_end": 18}, "action": {"text": "defined", "start": 89, "end": 96, "i_start": 14, "i_end": 14}}, {"character": {"text": "algorithms", "start": 67, "end": 77, "i_start": 10, "i_end": 10}, "action": {"text": "detection", "start": 57, "end": 66, "i_start": 9, "i_end": 9}}], "id": 1066}, {"sent": "deep neural networks have been shown to be very efficient in image processing tasks such as content classification .", "tokens": ["deep", "neural", "networks", "have", "been", "shown", "to", "be", "very", "efficient", "in", "image", "processing", "tasks", "such", "as", "content", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been shown", "start": 21, "end": 36, "i_start": 3, "i_end": 5}}], "id": 1067}, {"sent": "specifically , for visual feature representation , we use the resnet .", "tokens": ["specifically", ",", "for", "visual", "feature", "representation", ",", "we", "use", "the", "resnet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 51, "end": 53, "i_start": 7, "i_end": 7}, "verb": {"text": "use", "start": 54, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "use", "start": 54, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "representation", "start": 34, "end": 48, "i_start": 5, "i_end": 5}}], "id": 1068}, {"sent": "clearly sl is an infinite non associative interval semiring .", "tokens": ["clearly", "sl", "is", "an", "infinite", "non", "associative", "interval", "semiring", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "sl", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "interval", "start": 42, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "associative", "start": 30, "end": 41, "i_start": 6, "i_end": 6}}], "id": 1069}, {"sent": "in order for enterprises to counter apt attacks , recent approaches based on ubiquitous system monitoring have emerged as an important solution for monitoring , connecting , and investigating risky software behaviors across software applications .", "tokens": ["in", "order", "for", "enterprises", "to", "counter", "apt", "attacks", ",", "recent", "approaches", "based", "on", "ubiquitous", "system", "monitoring", "have", "emerged", "as", "an", "important", "solution", "for", "monitoring", ",", "connecting", ",", "and", "investigating", "risky", "software", "behaviors", "across", "software", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent approaches based on ubiquitous system monitoring", "start": 50, "end": 105, "i_start": 9, "i_end": 15}, "verb": {"text": "have emerged", "start": 106, "end": 118, "i_start": 16, "i_end": 17}}, {"character": {"text": "approaches", "start": 57, "end": 67, "i_start": 10, "i_end": 10}, "action": {"text": "emerged", "start": 111, "end": 118, "i_start": 17, "i_end": 17}}, {"character": {"text": "software", "start": 198, "end": 206, "i_start": 30, "i_end": 30}, "action": {"text": "behaviors", "start": 207, "end": 216, "i_start": 31, "i_end": 31}}, {"character": {"text": "enterprises", "start": 13, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "counter", "start": 28, "end": 35, "i_start": 5, "i_end": 5}}], "id": 1070}, {"sent": "the harmonics are spatially dispersed and refocused onto the sample by a single toroidal grating , and the 38 th harmonic is selected by a slit .", "tokens": ["the", "harmonics", "are", "spatially", "dispersed", "and", "refocused", "onto", "the", "sample", "by", "a", "single", "toroidal", "grating", ",", "and", "the", "38", "th", "harmonic", "is", "selected", "by", "a", "slit", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the harmonics", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 14, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the 38 th harmonic", "start": 103, "end": 121, "i_start": 17, "i_end": 20}, "verb": {"text": "selected", "start": 125, "end": 133, "i_start": 22, "i_end": 22}}], "id": 1071}, {"sent": "qqq qqq qqqq qqq qqqq qqq qqqq qqq qqq qqqq qqqq qqq qqq qqqq qqq qqqq qqq qqq qqqq .", "tokens": ["qqq", "qqq", "qqqq", "qqq", "qqqq", "qqq", "qqqq", "qqq", "qqq", "qqqq", "qqqq", "qqq", "qqq", "qqqq", "qqq", "qqqq", "qqq", "qqq", "qqqq", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1072}, {"sent": "multiscaling of the crack front is observed for scales below \u03be , provided that the disorder is strong enough .", "tokens": ["multiscaling", "of", "the", "crack", "front", "is", "observed", "for", "scales", "below", "\u03be", ",", "provided", "that", "the", "disorder", "is", "strong", "enough", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "multiscaling of the crack front", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "is observed", "start": 32, "end": 43, "i_start": 5, "i_end": 6}}], "id": 1073}, {"sent": "for the discriminator , we use patchgan that penalizes structure at the scale of image patches .", "tokens": ["for", "the", "discriminator", ",", "we", "use", "patchgan", "that", "penalizes", "structure", "at", "the", "scale", "of", "image", "patches", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 24, "end": 26, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 27, "end": 30, "i_start": 5, "i_end": 5}}, {"subject": {"text": "that", "start": 40, "end": 44, "i_start": 7, "i_end": 7}, "verb": {"text": "penalizes", "start": 45, "end": 54, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 27, "end": 30, "i_start": 5, "i_end": 5}}], "id": 1074}, {"sent": "the 3lp model , as its name implies faraji and ijspeert , is composed of three linear pendulums to simulate legs and torso dynamics in walking .", "tokens": ["the", "3lp", "model", ",", "as", "its", "name", "implies", "faraji", "and", "ijspeert", ",", "is", "composed", "of", "three", "linear", "pendulums", "to", "simulate", "legs", "and", "torso", "dynamics", "in", "walking", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the 3lp model", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is composed", "start": 58, "end": 69, "i_start": 12, "i_end": 13}}], "id": 1075}, {"sent": "we employ the gated recurrent units to implement the rnn model in this work .", "tokens": ["we", "employ", "the", "gated", "recurrent", "units", "to", "implement", "the", "rnn", "model", "in", "this", "work", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "units", "start": 30, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "implement", "start": 39, "end": 48, "i_start": 7, "i_end": 7}}], "id": 1076}, {"sent": "edge computing is an emerging computing paradigm that is transforming the landscape of provision and consumption of computing services for a wide range of applications and end users at the edge of the internet .", "tokens": ["edge", "computing", "is", "an", "emerging", "computing", "paradigm", "that", "is", "transforming", "the", "landscape", "of", "provision", "and", "consumption", "of", "computing", "services", "for", "a", "wide", "range", "of", "applications", "and", "end", "users", "at", "the", "edge", "of", "the", "internet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "edge computing", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "paradigm", "start": 40, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "emerging", "start": 21, "end": 29, "i_start": 4, "i_end": 4}}], "id": 1077}, {"sent": "the colorspin-colorspin interaction is introduced as the central potential and the isospin-orbit potential and colorspin-orbit potential are introduced as non-local potentials in analogy with the spin-orbit potential .", "tokens": ["the", "colorspin", "-", "colorspin", "interaction", "is", "introduced", "as", "the", "central", "potential", "and", "the", "isospin", "-", "orbit", "potential", "and", "colorspin", "-", "orbit", "potential", "are", "introduced", "as", "non", "-", "local", "potentials", "in", "analogy", "with", "the", "spin", "-", "orbit", "potential", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the colorspin-colorspin interaction", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "is introduced", "start": 36, "end": 49, "i_start": 5, "i_end": 6}}, {"subject": {"text": "the colorspin-colorspin interaction", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "introduced", "start": 141, "end": 151, "i_start": 23, "i_end": 23}}, {"character": {"text": "colorspin", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "interaction", "start": 24, "end": 35, "i_start": 4, "i_end": 4}}], "id": 1078}, {"sent": "generative adversarial networks are among the most powerful generative models that capture data distribution .", "tokens": ["generative", "adversarial", "networks", "are", "among", "the", "most", "powerful", "generative", "models", "that", "capture", "data", "distribution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 71, "end": 77, "i_start": 9, "i_end": 9}, "action": {"text": "capture", "start": 83, "end": 90, "i_start": 11, "i_end": 11}}], "id": 1079}, {"sent": "at nite temperature , there is a pseudogap phase by the vanishing of the tunneling density of states \u03c1 , are rossover lines .", "tokens": ["at", "nite", "temperature", ",", "there", "is", "a", "pseudogap", "phase", "by", "the", "vanishing", "of", "the", "tunneling", "density", "of", "states", "\u03c1", ",", "are", "rossover", "lines", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 22, "end": 27, "i_start": 4, "i_end": 4}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 5, "i_end": 5}}], "id": 1080}, {"sent": "then the einstein-maxwell horizon geometry consists of the quadruplet .", "tokens": ["then", "the", "einstein", "-", "maxwell", "horizon", "geometry", "consists", "of", "the", "quadruplet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the einstein-maxwell horizon geometry", "start": 5, "end": 42, "i_start": 1, "i_end": 6}, "verb": {"text": "consists", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}], "id": 1081}, {"sent": "following it is convenient to write a permutation by putting a vertical bar after each element of e or f according to the case .", "tokens": ["following", "it", "is", "convenient", "to", "write", "a", "permutation", "by", "putting", "a", "vertical", "bar", "after", "each", "element", "of", "e", "or", "f", "according", "to", "the", "case", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "following it", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 1082}, {"sent": "zhang et al proposed a multi-column cnn to extract multi-scale features by columns with different kernel sizes .", "tokens": ["zhang", "et", "al", "proposed", "a", "multi", "-", "column", "cnn", "to", "extract", "multi", "-", "scale", "features", "by", "columns", "with", "different", "kernel", "sizes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhang et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}], "id": 1083}, {"sent": "quantum tomography is a technique of characterizing a state of a quantum system by subjecting it to a large number of quantum measurements , each time preparing the system anew .", "tokens": ["quantum", "tomography", "is", "a", "technique", "of", "characterizing", "a", "state", "of", "a", "quantum", "system", "by", "subjecting", "it", "to", "a", "large", "number", "of", "quantum", "measurements", ",", "each", "time", "preparing", "the", "system", "anew", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum tomography", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}], "id": 1084}, {"sent": "neural networks are usually trained with the stochastic gradient descent algorithm where the gradient is computed using the back-propagation procedure .", "tokens": ["neural", "networks", "are", "usually", "trained", "with", "the", "stochastic", "gradient", "descent", "algorithm", "where", "the", "gradient", "is", "computed", "using", "the", "back", "-", "propagation", "procedure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "trained", "start": 28, "end": 35, "i_start": 4, "i_end": 4}}, {"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 16, "end": 19, "i_start": 2, "i_end": 2}}], "id": 1085}, {"sent": "takemiya t , maehara m , matsumura k , yasuda s , sugiura h , yamagata k .", "tokens": ["takemiya", "t", ",", "maehara", "m", ",", "matsumura", "k", ",", "yasuda", "s", ",", "sugiura", "h", ",", "yamagata", "k", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1086}, {"sent": "no correlation with sunspot activity is observed .", "tokens": ["no", "correlation", "with", "sunspot", "activity", "is", "observed", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "no correlation with sunspot activity", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "is observed", "start": 37, "end": 48, "i_start": 5, "i_end": 6}}, {"character": {"text": "sunspot", "start": 20, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "activity", "start": 28, "end": 36, "i_start": 4, "i_end": 4}}], "id": 1087}, {"sent": "recently , deep neural networks have led to significant improvement in several machine learning domains , from speech recognition to computer vision and machine translation .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "led", "to", "significant", "improvement", "in", "several", "machine", "learning", "domains", ",", "from", "speech", "recognition", "to", "computer", "vision", "and", "machine", "translation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have led", "start": 32, "end": 40, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "led", "start": 37, "end": 40, "i_start": 6, "i_end": 6}}], "id": 1088}, {"sent": "entanglement is one of the salient features of quantum physics , from the point of view of both foundations .", "tokens": ["entanglement", "is", "one", "of", "the", "salient", "features", "of", "quantum", "physics", ",", "from", "the", "point", "of", "view", "of", "both", "foundations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "entanglement", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "foundations", "start": 96, "end": 107, "i_start": 18, "i_end": 18}, "action": {"text": "view", "start": 83, "end": 87, "i_start": 15, "i_end": 15}}], "id": 1089}, {"sent": "in this section , we evaluate the performance of the ssimlayer on imagenet images of cifar-10 categories .", "tokens": ["in", "this", "section", ",", "we", "evaluate", "the", "performance", "of", "the", "ssimlayer", "on", "imagenet", "images", "of", "cifar-10", "categories", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "evaluate", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "evaluate", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "ssimlayer", "start": 53, "end": 62, "i_start": 10, "i_end": 10}, "action": {"text": "performance", "start": 34, "end": 45, "i_start": 7, "i_end": 7}}], "id": 1090}, {"sent": "the effectiveness of the deep convolutional neural networks has been demonstrated for various computer vision tasks such as image classification and so on .", "tokens": ["the", "effectiveness", "of", "the", "deep", "convolutional", "neural", "networks", "has", "been", "demonstrated", "for", "various", "computer", "vision", "tasks", "such", "as", "image", "classification", "and", "so", "on", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the effectiveness of the deep convolutional neural networks", "start": 0, "end": 59, "i_start": 0, "i_end": 7}, "verb": {"text": "has been demonstrated", "start": 60, "end": 81, "i_start": 8, "i_end": 10}}, {"character": {"text": "networks", "start": 51, "end": 59, "i_start": 7, "i_end": 7}, "action": {"text": "effectiveness", "start": 4, "end": 17, "i_start": 1, "i_end": 1}}], "id": 1091}, {"sent": "the i solid squares denote the results of the present calculation , and for comparison , qcdsf results are shown by the open points .", "tokens": ["the", "i", "solid", "squares", "denote", "the", "results", "of", "the", "present", "calculation", ",", "and", "for", "comparison", ",", "qcdsf", "results", "are", "shown", "by", "the", "open", "points", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the i solid squares", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "denote", "start": 20, "end": 26, "i_start": 4, "i_end": 4}}, {"subject": {"text": "qcdsf results", "start": 89, "end": 102, "i_start": 16, "i_end": 17}, "verb": {"text": "shown", "start": 107, "end": 112, "i_start": 19, "i_end": 19}}, {"character": {"text": "squares", "start": 12, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "denote", "start": 20, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "points", "start": 125, "end": 131, "i_start": 23, "i_end": 23}, "action": {"text": "shown", "start": 107, "end": 112, "i_start": 19, "i_end": 19}}], "id": 1092}, {"sent": "quantum teleportation is a protocol in which an arbitrary , unknown quantum state can be reliably transferred from a sender to a receiver .", "tokens": ["quantum", "teleportation", "is", "a", "protocol", "in", "which", "an", "arbitrary", ",", "unknown", "quantum", "state", "can", "be", "reliably", "transferred", "from", "a", "sender", "to", "a", "receiver", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum teleportation", "start": 0, "end": 21, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 2, "i_end": 2}}], "id": 1093}, {"sent": "connes gave an asymptotic trace identity that is equivalent to the riemann hypothesis .", "tokens": ["connes", "gave", "an", "asymptotic", "trace", "identity", "that", "is", "equivalent", "to", "the", "riemann", "hypothesis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "connes", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "gave", "start": 7, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "connes", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "gave", "start": 7, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "riemann", "start": 67, "end": 74, "i_start": 11, "i_end": 11}, "action": {"text": "hypothesis", "start": 75, "end": 85, "i_start": 12, "i_end": 12}}], "id": 1094}, {"sent": "in electromagnetism there is a non-local order parameter , the mass of the magnetic photons , that corresponds physically to the meissner effect and distinguishes the free phase from the superconducting one .", "tokens": ["in", "electromagnetism", "there", "is", "a", "non", "-", "local", "order", "parameter", ",", "the", "mass", "of", "the", "magnetic", "photons", ",", "that", "corresponds", "physically", "to", "the", "meissner", "effect", "and", "distinguishes", "the", "free", "phase", "from", "the", "superconducting", "one", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 20, "end": 25, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "parameter", "start": 47, "end": 56, "i_start": 9, "i_end": 9}, "action": {"text": "distinguishes", "start": 149, "end": 162, "i_start": 26, "i_end": 26}}], "id": 1095}, {"sent": "in recent years , convolutional neural networks have achieved superior performance in many visual tasks , such as object classification and detection .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "classification", "and", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 48, "end": 61, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 53, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 71, "end": 82, "i_start": 10, "i_end": 10}}], "id": 1096}, {"sent": "as is shown in , the integrals listed above do not depend on the choice of the nonnegative cutoff function for the haar system .", "tokens": ["as", "is", "shown", "in", ",", "the", "integrals", "listed", "above", "do", "not", "depend", "on", "the", "choice", "of", "the", "nonnegative", "cutoff", "function", "for", "the", "haar", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the integrals listed above", "start": 17, "end": 43, "i_start": 5, "i_end": 8}, "verb": {"text": "do not depend", "start": 44, "end": 57, "i_start": 9, "i_end": 11}}, {"character": {"text": "integrals", "start": 21, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "not depend", "start": 47, "end": 57, "i_start": 10, "i_end": 11}}], "id": 1097}, {"sent": "the so-called degenerate case is established for all rational symplectic manifolds in .", "tokens": ["the", "so", "-", "called", "degenerate", "case", "is", "established", "for", "all", "rational", "symplectic", "manifolds", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the so-called degenerate case", "start": 0, "end": 29, "i_start": 0, "i_end": 5}, "verb": {"text": "is established", "start": 30, "end": 44, "i_start": 6, "i_end": 7}}], "id": 1098}, {"sent": "he et al solved this problem using a deep residual learning framework .", "tokens": ["he", "et", "al", "solved", "this", "problem", "using", "a", "deep", "residual", "learning", "framework", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "he et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "solved", "start": 9, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "he", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "solved", "start": 9, "end": 15, "i_start": 3, "i_end": 3}}], "id": 1099}, {"sent": "recently deep neural networks have made a great success in many real-world applications , such as image classification .", "tokens": ["recently", "deep", "neural", "networks", "have", "made", "a", "great", "success", "in", "many", "real", "-", "world", "applications", ",", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 9, "end": 29, "i_start": 1, "i_end": 3}, "verb": {"text": "have made", "start": 30, "end": 39, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 48, "end": 55, "i_start": 8, "i_end": 8}}], "id": 1100}, {"sent": "it is originally proposed in the large margin nearest neighbor method .", "tokens": ["it", "is", "originally", "proposed", "in", "the", "large", "margin", "nearest", "neighbor", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}], "id": 1101}, {"sent": "cluster algebras were introduced by fomin and zelevinsky in in order to give a combinatorial framework for studying positivity in algebraic groups and canonical bases in quantum groups .", "tokens": ["cluster", "algebras", "were", "introduced", "by", "fomin", "and", "zelevinsky", "in", "in", "order", "to", "give", "a", "combinatorial", "framework", "for", "studying", "positivity", "in", "algebraic", "groups", "and", "canonical", "bases", "in", "quantum", "groups", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were introduced", "start": 17, "end": 32, "i_start": 2, "i_end": 3}}, {"character": {"text": "fomin", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "zelevinsky", "start": 46, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "fomin", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "give", "start": 72, "end": 76, "i_start": 12, "i_end": 12}}, {"character": {"text": "zelevinsky", "start": 46, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "give", "start": 72, "end": 76, "i_start": 12, "i_end": 12}}], "id": 1102}, {"sent": "the table lists the measured frequencies of the various transitions .", "tokens": ["the", "table", "lists", "the", "measured", "frequencies", "of", "the", "various", "transitions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the table", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "lists", "start": 10, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "table", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "lists", "start": 10, "end": 15, "i_start": 2, "i_end": 2}}], "id": 1103}, {"sent": "although many studies looked on editing and commenting activity on wikipedia , there are not many quantitative works focusing on the wikipedia usage by the internet users .", "tokens": ["although", "many", "studies", "looked", "on", "editing", "and", "commenting", "activity", "on", "wikipedia", ",", "there", "are", "not", "many", "quantitative", "works", "focusing", "on", "the", "wikipedia", "usage", "by", "the", "internet", "users", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "there", "start": 79, "end": 84, "i_start": 12, "i_end": 12}, "verb": {"text": "are not", "start": 85, "end": 92, "i_start": 13, "i_end": 14}}, {"character": {"text": "works", "start": 111, "end": 116, "i_start": 17, "i_end": 17}, "action": {"text": "focusing", "start": 117, "end": 125, "i_start": 18, "i_end": 18}}], "id": 1104}, {"sent": "in the privacy research community , a prevalent and strong notion of privacy is that of differential privacy .", "tokens": ["in", "the", "privacy", "research", "community", ",", "a", "prevalent", "and", "strong", "notion", "of", "privacy", "is", "that", "of", "differential", "privacy", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a prevalent and strong notion of privacy is that of differential privacy", "start": 36, "end": 108, "i_start": 6, "i_end": 17}, "verb": {"text": "is", "start": 77, "end": 79, "i_start": 13, "i_end": 13}}, {"character": {"text": "community", "start": 24, "end": 33, "i_start": 4, "i_end": 4}, "action": {"text": "research", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 1105}, {"sent": "we review various notions of v -modules and the definition of rational vertex operator algebras .", "tokens": ["we", "review", "various", "notions", "of", "v", "-modules", "and", "the", "definition", "of", "rational", "vertex", "operator", "algebras", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "review", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "review", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "algebras", "start": 87, "end": 95, "i_start": 14, "i_end": 14}, "action": {"text": "operator", "start": 78, "end": 86, "i_start": 13, "i_end": 13}}], "id": 1106}, {"sent": "generative adversarial networks have emerged as a powerful framework for learning generative models of arbitrarily complex data distributions .", "tokens": ["generative", "adversarial", "networks", "have", "emerged", "as", "a", "powerful", "framework", "for", "learning", "generative", "models", "of", "arbitrarily", "complex", "data", "distributions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "have emerged", "start": 32, "end": 44, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "emerged", "start": 37, "end": 44, "i_start": 4, "i_end": 4}}], "id": 1107}, {"sent": "this attractive force was later shown to apply also to closely spaced dielectric plates .", "tokens": ["this", "attractive", "force", "was", "later", "shown", "to", "apply", "also", "to", "closely", "spaced", "dielectric", "plates", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this attractive force", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "shown", "start": 32, "end": 37, "i_start": 5, "i_end": 5}}, {"subject": {"text": "this attractive force", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "was", "start": 22, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "force", "start": 16, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "attractive", "start": 5, "end": 15, "i_start": 1, "i_end": 1}}], "id": 1108}, {"sent": "stringlike defects are widely discussed as the possible remnants surviving the epoch of phase transitions in the early universe .", "tokens": ["stringlike", "defects", "are", "widely", "discussed", "as", "the", "possible", "remnants", "surviving", "the", "epoch", "of", "phase", "transitions", "in", "the", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "stringlike defects", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "discussed", "start": 30, "end": 39, "i_start": 4, "i_end": 4}}, {"subject": {"text": "stringlike defects", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 19, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "remnants", "start": 56, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "surviving", "start": 65, "end": 74, "i_start": 9, "i_end": 9}}], "id": 1109}, {"sent": "the properties of riemannian manifolds with semi-symmetric and non-metric connection have been studied by many authors .", "tokens": ["the", "properties", "of", "riemannian", "manifolds", "with", "semi", "-", "symmetric", "and", "non", "-", "metric", "connection", "have", "been", "studied", "by", "many", "authors", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the properties of riemannian manifolds with semi-symmetric and non-metric connection", "start": 0, "end": 84, "i_start": 0, "i_end": 13}, "verb": {"text": "have been studied", "start": 85, "end": 102, "i_start": 14, "i_end": 16}}, {"character": {"text": "many", "start": 106, "end": 110, "i_start": 18, "i_end": 18}, "action": {"text": "studied", "start": 95, "end": 102, "i_start": 16, "i_end": 16}}, {"character": {"text": "manifolds", "start": 29, "end": 38, "i_start": 4, "i_end": 4}, "action": {"text": "have", "start": 85, "end": 89, "i_start": 14, "i_end": 14}}], "id": 1110}, {"sent": "we use the em algorithm to search for maximum likelihood parameters integrating over the unobserved noise processes and envelope shapes .", "tokens": ["we", "use", "the", "em", "algorithm", "to", "search", "for", "maximum", "likelihood", "parameters", "integrating", "over", "the", "unobserved", "noise", "processes", "and", "envelope", "shapes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "search", "start": 27, "end": 33, "i_start": 6, "i_end": 6}}], "id": 1111}, {"sent": "in fact , by using contraction theory , 55 , 62 we can prove global exponential synchronization of the coupled hopf oscillators .", "tokens": ["in", "fact", ",", "by", "using", "contraction", "theory", ",", "55", ",", "62", "we", "can", "prove", "global", "exponential", "synchronization", "of", "the", "coupled", "hopf", "oscillators", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 48, "end": 50, "i_start": 11, "i_end": 11}, "verb": {"text": "can prove", "start": 51, "end": 60, "i_start": 12, "i_end": 13}}, {"character": {"text": "we", "start": 48, "end": 50, "i_start": 11, "i_end": 11}, "action": {"text": "prove", "start": 55, "end": 60, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 48, "end": 50, "i_start": 11, "i_end": 11}, "action": {"text": "using", "start": 13, "end": 18, "i_start": 4, "i_end": 4}}], "id": 1112}, {"sent": "deep neural networks have demonstrated to be effective models for solving a large variety of problems in several domains , including image , to name a few .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "to", "be", "effective", "models", "for", "solving", "a", "large", "variety", "of", "problems", "in", "several", "domains", ",", "including", "image", ",", "to", "name", "a", "few", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "models", "start": 55, "end": 61, "i_start": 8, "i_end": 8}, "action": {"text": "effective", "start": 45, "end": 54, "i_start": 7, "i_end": 7}}], "id": 1113}, {"sent": "the data were calibrated and flagged for rfi using the nrao casa pipeline .", "tokens": ["the", "data", "were", "calibrated", "and", "flagged", "for", "rfi", "using", "the", "nrao", "casa", "pipeline", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "were calibrated", "start": 9, "end": 24, "i_start": 2, "i_end": 3}}, {"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "flagged", "start": 29, "end": 36, "i_start": 5, "i_end": 5}}], "id": 1114}, {"sent": "the continuous time analogy was proved in together with a sketch of a proof for the discrete case .", "tokens": ["the", "continuous", "time", "analogy", "was", "proved", "in", "together", "with", "a", "sketch", "of", "a", "proof", "for", "the", "discrete", "case", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the continuous time analogy", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "was proved in", "start": 28, "end": 41, "i_start": 4, "i_end": 6}}], "id": 1115}, {"sent": "now , we can apply the induction hypothesis to the remaining -dimensional system and estimate the remaining states .", "tokens": ["now", ",", "we", "can", "apply", "the", "induction", "hypothesis", "to", "the", "remaining", "-dimensional", "system", "and", "estimate", "the", "remaining", "states", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "verb": {"text": "can apply", "start": 9, "end": 18, "i_start": 3, "i_end": 4}}, {"subject": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "verb": {"text": "estimate", "start": 85, "end": 93, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "apply", "start": 13, "end": 18, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "estimate", "start": 85, "end": 93, "i_start": 14, "i_end": 14}}], "id": 1116}, {"sent": "theory for the transport properties of normal metal point contacts a .", "tokens": ["theory", "for", "the", "transport", "properties", "of", "normal", "metal", "point", "contacts", "a", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1117}, {"sent": "sakamoto et al proposed a robot control interface especially for home robots .", "tokens": ["sakamoto", "et", "al", "proposed", "a", "robot", "control", "interface", "especially", "for", "home", "robots", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "sakamoto et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "sakamoto", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 1118}, {"sent": "the standard choice is a zero-torque boundary condition , which is appropriate in the following two situations .", "tokens": ["the", "standard", "choice", "is", "a", "zero", "-", "torque", "boundary", "condition", ",", "which", "is", "appropriate", "in", "the", "following", "two", "situations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the standard choice", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 1119}, {"sent": "primitive predicates for encoding the usual inequality relations over r .", "tokens": ["primitive", "predicates", "for", "encoding", "the", "usual", "inequality", "relations", "over", "r", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1120}, {"sent": "this geometry is a trumpet with curvature singularity at the origin of the coordinate system , and it is dual to the semi-infinite cigar .", "tokens": ["this", "geometry", "is", "a", "trumpet", "with", "curvature", "singularity", "at", "the", "origin", "of", "the", "coordinate", "system", ",", "and", "it", "is", "dual", "to", "the", "semi", "-", "infinite", "cigar", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this geometry", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1121}, {"sent": "depending on the coupling of the field s to matter , these fluctuations may lead to dangerous isocurvature perturbations of metric , or to non-gaussian adiabatic perturbations , as in the curvaton theory .", "tokens": ["depending", "on", "the", "coupling", "of", "the", "field", "s", "to", "matter", ",", "these", "fluctuations", "may", "lead", "to", "dangerous", "isocurvature", "perturbations", "of", "metric", ",", "or", "to", "non", "-", "gaussian", "adiabatic", "perturbations", ",", "as", "in", "the", "curvaton", "theory", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "these fluctuations", "start": 53, "end": 71, "i_start": 11, "i_end": 12}, "verb": {"text": "may lead", "start": 72, "end": 80, "i_start": 13, "i_end": 14}}, {"character": {"text": "fluctuations", "start": 59, "end": 71, "i_start": 12, "i_end": 12}, "action": {"text": "lead", "start": 76, "end": 80, "i_start": 14, "i_end": 14}}, {"character": {"text": "perturbations", "start": 162, "end": 175, "i_start": 28, "i_end": 28}, "action": {"text": "depending", "start": 0, "end": 9, "i_start": 0, "i_end": 0}}], "id": 1122}, {"sent": "by our assumption , where we follow using a most general protocol , the environment is completely under the control of the eavesdropper .", "tokens": ["by", "our", "assumption", ",", "where", "we", "follow", "using", "a", "most", "general", "protocol", ",", "the", "environment", "is", "completely", "under", "the", "control", "of", "the", "eavesdropper", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the environment", "start": 68, "end": 83, "i_start": 13, "i_end": 14}, "verb": {"text": "is", "start": 84, "end": 86, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "follow", "start": 29, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "using", "start": 36, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "assumption", "start": 7, "end": 17, "i_start": 2, "i_end": 2}}], "id": 1123}, {"sent": "the categorical approach for the smash product that we introduce here is equivalent to the ring without identity construction obtained by m .", "tokens": ["the", "categorical", "approach", "for", "the", "smash", "product", "that", "we", "introduce", "here", "is", "equivalent", "to", "the", "ring", "without", "identity", "construction", "obtained", "by", "m", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the categorical approach for the smash product that we introduce here", "start": 0, "end": 69, "i_start": 0, "i_end": 10}, "verb": {"text": "is", "start": 70, "end": 72, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 52, "end": 54, "i_start": 8, "i_end": 8}, "action": {"text": "introduce", "start": 55, "end": 64, "i_start": 9, "i_end": 9}}], "id": 1124}, {"sent": "convolution-based deep neural networks have performed exceedingly well on 2d representation learning tasks .", "tokens": ["convolution", "-", "based", "deep", "neural", "networks", "have", "performed", "exceedingly", "well", "on", "2d", "representation", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolution-based deep neural networks", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "have performed", "start": 39, "end": 53, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "performed", "start": 44, "end": 53, "i_start": 7, "i_end": 7}}], "id": 1125}, {"sent": "the ucf101 dataset contains 101 types of behavioral categories with a total of 13320 videos .", "tokens": ["the", "ucf101", "dataset", "contains", "101", "types", "of", "behavioral", "categories", "with", "a", "total", "of", "13320", "videos", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ucf101 dataset", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "contains", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "dataset", "start": 11, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "contains", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}], "id": 1126}, {"sent": "we recall the definitions of vertex operator algebras and their modules in this section .", "tokens": ["we", "recall", "the", "definitions", "of", "vertex", "operator", "algebras", "and", "their", "modules", "in", "this", "section", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "recall", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "recall", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "algebras", "start": 45, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "operator", "start": 36, "end": 44, "i_start": 6, "i_end": 6}}], "id": 1127}, {"sent": "deep neural networks have made great strides in many computer vision tasks such as image classification .", "tokens": ["deep", "neural", "networks", "have", "made", "great", "strides", "in", "many", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have made", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "strides", "start": 37, "end": 44, "i_start": 6, "i_end": 6}}], "id": 1128}, {"sent": "the electron exchange correlation potential is treated with the generalized gradient of the perdew-bruke-ernzerhof functional .", "tokens": ["the", "electron", "exchange", "correlation", "potential", "is", "treated", "with", "the", "generalized", "gradient", "of", "the", "perdew", "-", "bruke", "-", "ernzerhof", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electron exchange correlation potential", "start": 0, "end": 43, "i_start": 0, "i_end": 4}, "verb": {"text": "is treated", "start": 44, "end": 54, "i_start": 5, "i_end": 6}}], "id": 1129}, {"sent": "an alternative explicit algebraic solution to the coupled differential equations uses the quasi-steady-state approximations developed by mott and collaborators .", "tokens": ["an", "alternative", "explicit", "algebraic", "solution", "to", "the", "coupled", "differential", "equations", "uses", "the", "quasi", "-", "steady", "-", "state", "approximations", "developed", "by", "mott", "and", "collaborators", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "an alternative explicit algebraic solution to the coupled differential equations", "start": 0, "end": 80, "i_start": 0, "i_end": 9}, "verb": {"text": "uses", "start": 81, "end": 85, "i_start": 10, "i_end": 10}}, {"character": {"text": "mott", "start": 137, "end": 141, "i_start": 20, "i_end": 20}, "action": {"text": "developed", "start": 124, "end": 133, "i_start": 18, "i_end": 18}}], "id": 1130}, {"sent": "the bias dependence of the average force gradient and the domain force gradient .", "tokens": ["the", "bias", "dependence", "of", "the", "average", "force", "gradient", "and", "the", "domain", "force", "gradient", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "bias", "start": 4, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "dependence", "start": 9, "end": 19, "i_start": 2, "i_end": 2}}], "id": 1131}, {"sent": "because a monopole is a localised object , the regions far from the monopole core are unaware of the twist in the boundary conditions .", "tokens": ["because", "a", "monopole", "is", "a", "localised", "object", ",", "the", "regions", "far", "from", "the", "monopole", "core", "are", "unaware", "of", "the", "twist", "in", "the", "boundary", "conditions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the regions far from the monopole core", "start": 43, "end": 81, "i_start": 8, "i_end": 14}, "verb": {"text": "are", "start": 82, "end": 85, "i_start": 15, "i_end": 15}}, {"character": {"text": "object", "start": 34, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "because", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}], "id": 1132}, {"sent": "the string equations of motion require a ten-dimensional spacetime , at least in the formulation of what is called critical string theory .", "tokens": ["the", "string", "equations", "of", "motion", "require", "a", "ten", "-", "dimensional", "spacetime", ",", "at", "least", "in", "the", "formulation", "of", "what", "is", "called", "critical", "string", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the string equations of motion", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "require", "start": 31, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "equations", "start": 11, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "require", "start": 31, "end": 38, "i_start": 5, "i_end": 5}}], "id": 1133}, {"sent": "the algorithm exploits the relationship between the curvature and torsion of two similar space curves and extends the results of , where the problem of detecting the symmetries of rational space curves was addressed .", "tokens": ["the", "algorithm", "exploits", "the", "relationship", "between", "the", "curvature", "and", "torsion", "of", "two", "similar", "space", "curves", "and", "extends", "the", "results", "of", ",", "where", "the", "problem", "of", "detecting", "the", "symmetries", "of", "rational", "space", "curves", "was", "addressed", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the algorithm", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "exploits", "start": 14, "end": 22, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the algorithm", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "extends", "start": 106, "end": 113, "i_start": 16, "i_end": 16}}, {"character": {"text": "algorithm", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "exploits", "start": 14, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "two similar space curves", "start": 77, "end": 101, "i_start": 11, "i_end": 14}, "action": {"text": "relationship", "start": 27, "end": 39, "i_start": 4, "i_end": 4}}], "id": 1134}, {"sent": "since the matrix v is symmetric and positive definite , we can employ a conjugate gradient method to solve the linear system .", "tokens": ["since", "the", "matrix", "v", "is", "symmetric", "and", "positive", "definite", ",", "we", "can", "employ", "a", "conjugate", "gradient", "method", "to", "solve", "the", "linear", "system", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 56, "end": 58, "i_start": 10, "i_end": 10}, "verb": {"text": "can employ", "start": 59, "end": 69, "i_start": 11, "i_end": 12}}, {"character": {"text": "we", "start": 56, "end": 58, "i_start": 10, "i_end": 10}, "action": {"text": "employ", "start": 63, "end": 69, "i_start": 12, "i_end": 12}}, {"character": {"text": "method", "start": 91, "end": 97, "i_start": 16, "i_end": 16}, "action": {"text": "solve", "start": 101, "end": 106, "i_start": 18, "i_end": 18}}], "id": 1135}, {"sent": "deep neural networks have been shown to be very efficient in image processing tasks such as content classification .", "tokens": ["deep", "neural", "networks", "have", "been", "shown", "to", "be", "very", "efficient", "in", "image", "processing", "tasks", "such", "as", "content", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been shown", "start": 21, "end": 36, "i_start": 3, "i_end": 5}}], "id": 1136}, {"sent": "an xppml specification is a collection of unparsing rules associated with abstract syntax patterns .", "tokens": ["an", "xppml", "specification", "is", "a", "collection", "of", "unparsing", "rules", "associated", "with", "abstract", "syntax", "patterns", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an xppml specification", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "rules", "start": 52, "end": 57, "i_start": 8, "i_end": 8}, "action": {"text": "unparsing", "start": 42, "end": 51, "i_start": 7, "i_end": 7}}], "id": 1137}, {"sent": "the notion of differential entropy was essentially introduced by shannon .", "tokens": ["the", "notion", "of", "differential", "entropy", "was", "essentially", "introduced", "by", "shannon", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the notion of differential entropy", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "introduced", "start": 51, "end": 61, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the notion of differential entropy", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "was", "start": 35, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "shannon", "start": 65, "end": 72, "i_start": 9, "i_end": 9}, "action": {"text": "introduced", "start": 51, "end": 61, "i_start": 7, "i_end": 7}}], "id": 1138}, {"sent": "the classical morrey spaces l p , \u03bb were introduced by morrey in 1938 to study the local behavior of solutions of second order elliptic partial differential equations .", "tokens": ["the", "classical", "morrey", "spaces", "l", "p", ",", "\u03bb", "were", "introduced", "by", "morrey", "in", "1938", "to", "study", "the", "local", "behavior", "of", "solutions", "of", "second", "order", "elliptic", "partial", "differential", "equations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the classical morrey", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "spaces", "start": 21, "end": 27, "i_start": 3, "i_end": 3}}, {"subject": {"text": "\u03bb", "start": 34, "end": 35, "i_start": 7, "i_end": 7}, "verb": {"text": "introduced", "start": 41, "end": 51, "i_start": 9, "i_end": 9}}, {"character": {"text": "morrey", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 41, "end": 51, "i_start": 9, "i_end": 9}}, {"character": {"text": "morrey", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "study", "start": 73, "end": 78, "i_start": 15, "i_end": 15}}], "id": 1139}, {"sent": "asterisks denote the ratio of the normal self-energy terms n0\u03c3 e at .", "tokens": ["asterisks", "denote", "the", "ratio", "of", "the", "normal", "self", "-", "energy", "terms", "n0\u03c3", "e", "at", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "asterisks", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "denote", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "asterisks", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}], "id": 1140}, {"sent": "in particular , due to the ekc mechanism , the superhorizon mode could bring modifications at observational scales , which is expected as an approximately linear function of positions .", "tokens": ["in", "particular", ",", "due", "to", "the", "ekc", "mechanism", ",", "the", "superhorizon", "mode", "could", "bring", "modifications", "at", "observational", "scales", ",", "which", "is", "expected", "as", "an", "approximately", "linear", "function", "of", "positions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the superhorizon mode", "start": 43, "end": 64, "i_start": 9, "i_end": 11}, "verb": {"text": "could bring", "start": 65, "end": 76, "i_start": 12, "i_end": 13}}, {"character": {"text": "mode", "start": 60, "end": 64, "i_start": 11, "i_end": 11}, "action": {"text": "bring", "start": 71, "end": 76, "i_start": 13, "i_end": 13}}, {"character": {"text": "positions", "start": 174, "end": 183, "i_start": 28, "i_end": 28}, "action": {"text": "function", "start": 162, "end": 170, "i_start": 26, "i_end": 26}}], "id": 1141}, {"sent": "let o be an algebra of operators acting on an algebra a .", "tokens": ["let", "o", "be", "an", "algebra", "of", "operators", "acting", "on", "an", "algebra", "a", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1142}, {"sent": "recently there have been many attempts to understand properties of supersymmetric gauge theories using branes in string theory and m-theory .", "tokens": ["recently", "there", "have", "been", "many", "attempts", "to", "understand", "properties", "of", "supersymmetric", "gauge", "theories", "using", "branes", "in", "string", "theory", "and", "m", "-", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 9, "end": 14, "i_start": 1, "i_end": 1}, "verb": {"text": "have been", "start": 15, "end": 24, "i_start": 2, "i_end": 3}}, {"character": {"text": "theories", "start": 88, "end": 96, "i_start": 12, "i_end": 12}, "action": {"text": "using", "start": 97, "end": 102, "i_start": 13, "i_end": 13}}], "id": 1143}, {"sent": "the dft computations were performed by using the plane-wave technique implemented in the vienna ab initio simulation package .", "tokens": ["the", "dft", "computations", "were", "performed", "by", "using", "the", "plane", "-", "wave", "technique", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dft computations", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "were performed", "start": 21, "end": 35, "i_start": 3, "i_end": 4}}], "id": 1144}, {"sent": "the exchange-correlation energy was approximated by the scheme of perdew , burke , and ernzerhof .", "tokens": ["the", "exchange", "-", "correlation", "energy", "was", "approximated", "by", "the", "scheme", "of", "perdew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the exchange-correlation energy", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "was approximated", "start": 32, "end": 48, "i_start": 5, "i_end": 6}}, {"character": {"text": "scheme", "start": 56, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "approximated", "start": 36, "end": 48, "i_start": 6, "i_end": 6}}], "id": 1145}, {"sent": "the performance may be further improved by explicitly estimating camera motion .", "tokens": ["the", "performance", "may", "be", "further", "improved", "by", "explicitly", "estimating", "camera", "motion", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the performance", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "improved", "start": 31, "end": 39, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the performance", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "may be", "start": 16, "end": 22, "i_start": 2, "i_end": 3}}, {"character": {"text": "estimating", "start": 54, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "improved", "start": 31, "end": 39, "i_start": 5, "i_end": 5}}], "id": 1146}, {"sent": "deep neural networks have gained popularity in recent years thanks to their achievements in many applications including computer vision , signal and image processing , speech recognition .", "tokens": ["deep", "neural", "networks", "have", "gained", "popularity", "in", "recent", "years", "thanks", "to", "their", "achievements", "in", "many", "applications", "including", "computer", "vision", ",", "signal", "and", "image", "processing", ",", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have gained", "start": 21, "end": 32, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "gained", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achievements", "start": 76, "end": 88, "i_start": 12, "i_end": 12}}], "id": 1147}, {"sent": "recently , deep convolutional neural networks have attracted a lot of attention in visual recognition due to its good performance .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "attracted", "a", "lot", "of", "attention", "in", "visual", "recognition", "due", "to", "its", "good", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have attracted", "start": 46, "end": 60, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "attracted", "start": 51, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 118, "end": 129, "i_start": 19, "i_end": 19}}], "id": 1148}, {"sent": "with the help of powerful well-designed deep neural networks , great progresses have been made in the field of object detection .", "tokens": ["with", "the", "help", "of", "powerful", "well", "-", "designed", "deep", "neural", "networks", ",", "great", "progresses", "have", "been", "made", "in", "the", "field", "of", "object", "detection", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "great progresses", "start": 63, "end": 79, "i_start": 12, "i_end": 13}, "verb": {"text": "have been made", "start": 80, "end": 94, "i_start": 14, "i_end": 16}}, {"character": {"text": "networks", "start": 52, "end": 60, "i_start": 10, "i_end": 10}, "action": {"text": "help", "start": 9, "end": 13, "i_start": 2, "i_end": 2}}], "id": 1149}, {"sent": "an analogy can be drawn with dispersive coupling of qubits in a cavity .", "tokens": ["an", "analogy", "can", "be", "drawn", "with", "dispersive", "coupling", "of", "qubits", "in", "a", "cavity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an analogy", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "can be drawn", "start": 11, "end": 23, "i_start": 2, "i_end": 4}}, {"character": {"text": "coupling", "start": 40, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "dispersive", "start": 29, "end": 39, "i_start": 6, "i_end": 6}}], "id": 1150}, {"sent": "this class of policies is motivated by the risk of cache pollution due to ephemeral content popularity and the long tail of one-timers observed in edge networks .", "tokens": ["this", "class", "of", "policies", "is", "motivated", "by", "the", "risk", "of", "cache", "pollution", "due", "to", "ephemeral", "content", "popularity", "and", "the", "long", "tail", "of", "one", "-", "timers", "observed", "in", "edge", "networks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this class of policies", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "is motivated", "start": 23, "end": 35, "i_start": 4, "i_end": 5}}, {"character": {"text": "risk", "start": 43, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "motivated", "start": 26, "end": 35, "i_start": 5, "i_end": 5}}, {"character": {"text": "cache", "start": 51, "end": 56, "i_start": 10, "i_end": 10}, "action": {"text": "pollution", "start": 57, "end": 66, "i_start": 11, "i_end": 11}}], "id": 1151}, {"sent": "deep learning has led to significant improvements in many computer vision tasks such as image classification .", "tokens": ["deep", "learning", "has", "led", "to", "significant", "improvements", "in", "many", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has led", "start": 14, "end": 21, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 18, "end": 21, "i_start": 3, "i_end": 3}}], "id": 1152}, {"sent": "also avila proved in a very general setting that there exists a dense , but not open , set of cocycles with non zero lyapunov exponents .", "tokens": ["also", "avila", "proved", "in", "a", "very", "general", "setting", "that", "there", "exists", "a", "dense", ",", "but", "not", "open", ",", "set", "of", "cocycles", "with", "non", "zero", "lyapunov", "exponents", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "avila", "start": 5, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "proved", "start": 11, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "there", "start": 49, "end": 54, "i_start": 9, "i_end": 9}, "verb": {"text": "exists", "start": 55, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "avila", "start": 5, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "proved", "start": 11, "end": 17, "i_start": 2, "i_end": 2}}], "id": 1153}, {"sent": "more specifically , the implementation we choose is the linearsvc class based on the liblinear library .", "tokens": ["more", "specifically", ",", "the", "implementation", "we", "choose", "is", "the", "linearsvc", "class", "based", "on", "the", "liblinear", "library", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the implementation we choose", "start": 20, "end": 48, "i_start": 3, "i_end": 6}, "verb": {"text": "is", "start": 49, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 39, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "implementation", "start": 24, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 39, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "choose", "start": 42, "end": 48, "i_start": 6, "i_end": 6}}], "id": 1154}, {"sent": "at the other end of the spectrum is the sub-mm population detected by scuba , believed to be predominantly high redshift , but provide a crucial counter-balance to the optical observations .", "tokens": ["at", "the", "other", "end", "of", "the", "spectrum", "is", "the", "sub", "-", "mm", "population", "detected", "by", "scuba", ",", "believed", "to", "be", "predominantly", "high", "redshift", ",", "but", "provide", "a", "crucial", "counter", "-", "balance", "to", "the", "optical", "observations", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the sub-mm population detected by scuba", "start": 36, "end": 75, "i_start": 8, "i_end": 15}, "verb": {"text": "believed", "start": 78, "end": 86, "i_start": 17, "i_end": 17}}, {"subject": {"text": "the sub-mm population detected by scuba", "start": 36, "end": 75, "i_start": 8, "i_end": 15}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the sub-mm population detected by scuba", "start": 36, "end": 75, "i_start": 8, "i_end": 15}, "verb": {"text": "provide", "start": 127, "end": 134, "i_start": 25, "i_end": 25}}, {"character": {"text": "scuba", "start": 70, "end": 75, "i_start": 15, "i_end": 15}, "action": {"text": "detected", "start": 58, "end": 66, "i_start": 13, "i_end": 13}}], "id": 1155}, {"sent": "a filtration is a decreasing sequence of \u03c3-algebras .", "tokens": ["a", "filtration", "is", "a", "decreasing", "sequence", "of", "\u03c3", "-", "algebras", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a filtration", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "sequence", "start": 29, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "decreasing", "start": 18, "end": 28, "i_start": 4, "i_end": 4}}], "id": 1156}, {"sent": "while self-similarity is a strong restriction of a geometric nature on the spacetime , it has been successfully exploited in various physical scenarios .", "tokens": ["while", "self", "-", "similarity", "is", "a", "strong", "restriction", "of", "a", "geometric", "nature", "on", "the", "spacetime", ",", "it", "has", "been", "successfully", "exploited", "in", "various", "physical", "scenarios", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 87, "end": 89, "i_start": 16, "i_end": 16}, "verb": {"text": "exploited", "start": 112, "end": 121, "i_start": 20, "i_end": 20}}, {"subject": {"text": "it", "start": 87, "end": 89, "i_start": 16, "i_end": 16}, "verb": {"text": "has been", "start": 90, "end": 98, "i_start": 17, "i_end": 18}}], "id": 1157}, {"sent": "in , goodfelow et al introduced a generative adversarial network framework called gan .", "tokens": ["in", ",", "goodfelow", "et", "al", "introduced", "a", "generative", "adversarial", "network", "framework", "called", "gan", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfelow et al", "start": 5, "end": 20, "i_start": 2, "i_end": 4}, "verb": {"text": "introduced", "start": 21, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "goodfelow", "start": 5, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 21, "end": 31, "i_start": 5, "i_end": 5}}], "id": 1158}, {"sent": "the lightest neutralino which is the lightest susy particle is in the right mass range to become a dark matter candidate .", "tokens": ["the", "lightest", "neutralino", "which", "is", "the", "lightest", "susy", "particle", "is", "in", "the", "right", "mass", "range", "to", "become", "a", "dark", "matter", "candidate", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the lightest neutralino which is the lightest susy particle", "start": 0, "end": 59, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 60, "end": 62, "i_start": 9, "i_end": 9}}], "id": 1159}, {"sent": "however in this case the d-terms are non-vanishing and the brane configuration is not supersymmetric .", "tokens": ["however", "in", "this", "case", "the", "d", "-", "terms", "are", "non", "-", "vanishing", "and", "the", "brane", "configuration", "is", "not", "supersymmetric", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the d-terms", "start": 21, "end": 32, "i_start": 4, "i_end": 7}, "verb": {"text": "are", "start": 33, "end": 36, "i_start": 8, "i_end": 8}}], "id": 1160}, {"sent": "the polynomials d n are of particular case of the dual big j-jacobi polynomials .", "tokens": ["the", "polynomials", "d", "n", "are", "of", "particular", "case", "of", "the", "dual", "big", "j", "-", "jacobi", "polynomials", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the polynomials d n", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 20, "end": 23, "i_start": 4, "i_end": 4}}], "id": 1161}, {"sent": "in , an example of a 3-step nilpotent lie algebra g is discussed , all of whose derivations are nilpotent .", "tokens": ["in", ",", "an", "example", "of", "a", "3", "-", "step", "nilpotent", "lie", "algebra", "g", "is", "discussed", ",", "all", "of", "whose", "derivations", "are", "nilpotent", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "an example of a 3-step nilpotent lie algebra g is discussed , all of whose derivations", "start": 5, "end": 91, "i_start": 2, "i_end": 19}, "verb": {"text": "are", "start": 92, "end": 95, "i_start": 20, "i_end": 20}}], "id": 1162}, {"sent": "large deep neural networks trained on massive data sets have led to major advances in machine learning performance .", "tokens": ["large", "deep", "neural", "networks", "trained", "on", "massive", "data", "sets", "have", "led", "to", "major", "advances", "in", "machine", "learning", "performance", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "large deep neural networks trained on massive data sets", "start": 0, "end": 55, "i_start": 0, "i_end": 8}, "verb": {"text": "have led", "start": 56, "end": 64, "i_start": 9, "i_end": 10}}, {"character": {"text": "networks", "start": 18, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "led", "start": 61, "end": 64, "i_start": 10, "i_end": 10}}], "id": 1163}, {"sent": "we use a pre-trained model which is trained with imagenet-1k dataset , and then fine-tune the network .", "tokens": ["we", "use", "a", "pre", "-", "trained", "model", "which", "is", "trained", "with", "imagenet-1k", "dataset", ",", "and", "then", "fine", "-", "tune", "the", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "tune", "start": 85, "end": 89, "i_start": 18, "i_end": 18}}], "id": 1164}, {"sent": "we compare our racing dnn to the two most related and recent network architectures , the first denoted as nvidia and the second as mav .", "tokens": ["we", "compare", "our", "racing", "dnn", "to", "the", "two", "most", "related", "and", "recent", "network", "architectures", ",", "the", "first", "denoted", "as", "nvidia", "and", "the", "second", "as", "mav", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 1165}, {"sent": "quantum mechanics is a completly different framework compared with classical physics .", "tokens": ["quantum", "mechanics", "is", "a", "completly", "different", "framework", "compared", "with", "classical", "physics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum mechanics", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}], "id": 1166}, {"sent": "deep convolutional neural networks using supervised learning has been proven to be revolutionary for image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "using", "supervised", "learning", "has", "been", "proven", "to", "be", "revolutionary", "for", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks using supervised learning", "start": 0, "end": 60, "i_start": 0, "i_end": 6}, "verb": {"text": "has been proven", "start": 61, "end": 76, "i_start": 7, "i_end": 9}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "using", "start": 35, "end": 40, "i_start": 4, "i_end": 4}}], "id": 1167}, {"sent": "prove the diamond lattice is non-distributive but modular .", "tokens": ["prove", "the", "diamond", "lattice", "is", "non", "-", "distributive", "but", "modular", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "lattice", "start": 18, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "-distributive", "start": 32, "end": 45, "i_start": 6, "i_end": 7}}], "id": 1168}, {"sent": "convolutional neural networks , as one of the widely used deep learning methods , have been proven to be very successful for object recognition in images .", "tokens": ["convolutional", "neural", "networks", ",", "as", "one", "of", "the", "widely", "used", "deep", "learning", "methods", ",", "have", "been", "proven", "to", "be", "very", "successful", "for", "object", "recognition", "in", "images", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been proven", "start": 82, "end": 98, "i_start": 14, "i_end": 16}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 110, "end": 120, "i_start": 20, "i_end": 20}}], "id": 1169}, {"sent": "specifically , we utilise a u-net architecture with skip connections .", "tokens": ["specifically", ",", "we", "utilise", "a", "u", "-", "net", "architecture", "with", "skip", "connections", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "utilise", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "utilise", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}], "id": 1170}, {"sent": "the modification consists of the introduction in the particle production rate expression of a multiplicative term containing the cluster formation probability \u03b3\u03b2 where \u03b2 is the type of the emitted particle .", "tokens": ["the", "modification", "consists", "of", "the", "introduction", "in", "the", "particle", "production", "rate", "expression", "of", "a", "multiplicative", "term", "containing", "the", "cluster", "formation", "probability", "\u03b3\u03b2", "where", "\u03b2", "is", "the", "type", "of", "the", "emitted", "particle", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the modification", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 17, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "term", "start": 109, "end": 113, "i_start": 15, "i_end": 15}, "action": {"text": "containing", "start": 114, "end": 124, "i_start": 16, "i_end": 16}}], "id": 1171}, {"sent": "according to the minicolumn hypothesis such pyramidal brain cells should have a columnar arrangement perpendicular to the pial surface of the brain , and this should be highly pronounced in brodmann area 4 .", "tokens": ["according", "to", "the", "minicolumn", "hypothesis", "such", "pyramidal", "brain", "cells", "should", "have", "a", "columnar", "arrangement", "perpendicular", "to", "the", "pial", "surface", "of", "the", "brain", ",", "and", "this", "should", "be", "highly", "pronounced", "in", "brodmann", "area", "4", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "such pyramidal brain cells", "start": 39, "end": 65, "i_start": 5, "i_end": 8}, "verb": {"text": "should have", "start": 66, "end": 77, "i_start": 9, "i_end": 10}}, {"subject": {"text": "such pyramidal brain cells", "start": 39, "end": 65, "i_start": 5, "i_end": 8}, "verb": {"text": "pronounced", "start": 176, "end": 186, "i_start": 28, "i_end": 28}}, {"character": {"text": "cells", "start": 60, "end": 65, "i_start": 8, "i_end": 8}, "action": {"text": "arrangement", "start": 89, "end": 100, "i_start": 13, "i_end": 13}}], "id": 1172}, {"sent": "during the vasp calculations , the exchange-correlation functional was parametrized using the perdew-burke-ernzerhof 63 method within the generalized gradient approximation .", "tokens": ["during", "the", "vasp", "calculations", ",", "the", "exchange", "-", "correlation", "functional", "was", "parametrized", "using", "the", "perdew", "-", "burke", "-", "ernzerhof", "63", "method", "within", "the", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange-correlation functional", "start": 31, "end": 66, "i_start": 5, "i_end": 9}, "verb": {"text": "was parametrized", "start": 67, "end": 83, "i_start": 10, "i_end": 11}}], "id": 1173}, {"sent": "namely , isomorphism classes of bundle gerbes over an arbitrary smooth manifold m are classified by h 3 .", "tokens": ["namely", ",", "isomorphism", "classes", "of", "bundle", "gerbes", "over", "an", "arbitrary", "smooth", "manifold", "m", "are", "classified", "by", "h", "3", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "isomorphism classes of bundle gerbes over an arbitrary smooth manifold m", "start": 9, "end": 81, "i_start": 2, "i_end": 12}, "verb": {"text": "are classified", "start": 82, "end": 96, "i_start": 13, "i_end": 14}}], "id": 1174}, {"sent": "we use resnet-101 as the feature extractor and add the atrous spatial pyramid pooling module in deeplab at the end to capture information at different scales .", "tokens": ["we", "use", "resnet-101", "as", "the", "feature", "extractor", "and", "add", "the", "atrous", "spatial", "pyramid", "pooling", "module", "in", "deeplab", "at", "the", "end", "to", "capture", "information", "at", "different", "scales", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "add", "start": 47, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "add", "start": 47, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "module", "start": 86, "end": 92, "i_start": 14, "i_end": 14}, "action": {"text": "capture", "start": 118, "end": 125, "i_start": 21, "i_end": 21}}], "id": 1175}, {"sent": "clt and other limit theorems for fun tionals of gaussian pro esses .", "tokens": ["clt", "and", "other", "limit", "theorems", "for", "fun", "tionals", "of", "gaussian", "pro", "esses", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "theorems", "start": 20, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "limit", "start": 14, "end": 19, "i_start": 3, "i_end": 3}}], "id": 1176}, {"sent": "we argue why we can estimate the error rate in the code bits based on that in the checked bits in the protocol , that is the central point of the proof .", "tokens": ["we", "argue", "why", "we", "can", "estimate", "the", "error", "rate", "in", "the", "code", "bits", "based", "on", "that", "in", "the", "checked", "bits", "in", "the", "protocol", ",", "that", "is", "the", "central", "point", "of", "the", "proof", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "argue", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "estimate", "start": 20, "end": 28, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 118, "end": 120, "i_start": 25, "i_end": 25}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "argue", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "estimate", "start": 20, "end": 28, "i_start": 5, "i_end": 5}}], "id": 1177}, {"sent": "polar codes , introduced by arikan in , achieve the symmetric capacity of the binary-input discrete memoryless channels under successive-cancellation decoding .", "tokens": ["polar", "codes", ",", "introduced", "by", "arikan", "in", ",", "achieve", "the", "symmetric", "capacity", "of", "the", "binary", "-", "input", "discrete", "memoryless", "channels", "under", "successive", "-", "cancellation", "decoding", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "polar codes", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "achieve", "start": 40, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "codes", "start": 6, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "achieve", "start": 40, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "arikan", "start": 28, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 14, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "channels", "start": 111, "end": 119, "i_start": 19, "i_end": 19}, "action": {"text": "-", "start": 84, "end": 85, "i_start": 15, "i_end": 15}}], "id": 1178}, {"sent": "separation logic is a well-known assertion logic for reasoning about programs with dynamic data structures .", "tokens": ["separation", "logic", "is", "a", "well", "-", "known", "assertion", "logic", "for", "reasoning", "about", "programs", "with", "dynamic", "data", "structures", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "separation logic", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "logic", "start": 11, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "assertion", "start": 33, "end": 42, "i_start": 7, "i_end": 7}}], "id": 1179}, {"sent": "for the image encoder , we use a resnet-18 architecture , pretrained on imagenet .", "tokens": ["for", "the", "image", "encoder", ",", "we", "use", "a", "resnet-18", "architecture", ",", "pretrained", "on", "imagenet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 27, "end": 30, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 27, "end": 30, "i_start": 6, "i_end": 6}}], "id": 1180}, {"sent": "in the recent years , there has been a considerable effort on experimental and theoretical studies of bose-einstein condensates .", "tokens": ["in", "the", "recent", "years", ",", "there", "has", "been", "a", "considerable", "effort", "on", "experimental", "and", "theoretical", "studies", "of", "bose", "-", "einstein", "condensates", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 22, "end": 27, "i_start": 5, "i_end": 5}, "verb": {"text": "has been", "start": 28, "end": 36, "i_start": 6, "i_end": 7}}], "id": 1181}, {"sent": "results of our black hole mass estimation method .", "tokens": ["results", "of", "our", "black", "hole", "mass", "estimation", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1182}, {"sent": "reinforcement learning with deep neural networkbased policies , known as deep reinforcement learning , has recently attained impressive performance on a wide range of tasks such as atari games .", "tokens": ["reinforcement", "learning", "with", "deep", "neural", "networkbased", "policies", ",", "known", "as", "deep", "reinforcement", "learning", ",", "has", "recently", "attained", "impressive", "performance", "on", "a", "wide", "range", "of", "tasks", "such", "as", "atari", "games", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "reinforcement learning with deep neural networkbased policies", "start": 0, "end": 61, "i_start": 0, "i_end": 6}, "verb": {"text": "attained", "start": 116, "end": 124, "i_start": 16, "i_end": 16}}, {"subject": {"text": "reinforcement learning with deep neural networkbased policies", "start": 0, "end": 61, "i_start": 0, "i_end": 6}, "verb": {"text": "has", "start": 103, "end": 106, "i_start": 14, "i_end": 14}}, {"character": {"text": "learning", "start": 14, "end": 22, "i_start": 1, "i_end": 1}, "action": {"text": "attained", "start": 116, "end": 124, "i_start": 16, "i_end": 16}}], "id": 1183}, {"sent": "convolutional neural networks have demonstrated impressive performance on computer vision tasks .", "tokens": ["convolutional", "neural", "networks", "have", "demonstrated", "impressive", "performance", "on", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 30, "end": 47, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 35, "end": 47, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 59, "end": 70, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 59, "end": 70, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 48, "end": 58, "i_start": 5, "i_end": 5}}], "id": 1184}, {"sent": "fischer et al , the opal jet chamber , nucl .", "tokens": ["fischer", "et", "al", ",", "the", "opal", "jet", "chamber", ",", "nucl", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1185}, {"sent": "in , a classification of cohomogeneity one actions on simple compact lie groups was obtained .", "tokens": ["in", ",", "a", "classification", "of", "cohomogeneity", "one", "actions", "on", "simple", "compact", "lie", "groups", "was", "obtained", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a classification of cohomogeneity one actions on simple compact lie groups", "start": 5, "end": 79, "i_start": 2, "i_end": 12}, "verb": {"text": "was obtained", "start": 80, "end": 92, "i_start": 13, "i_end": 14}}], "id": 1186}, {"sent": "volovich , the two-loop six-gluon mhv amplitude in maximally supersymmetric yang-mills theory , phys .", "tokens": ["volovich", ",", "the", "two", "-", "loop", "six", "-", "gluon", "mhv", "amplitude", "in", "maximally", "supersymmetric", "yang", "-", "mills", "theory", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1187}, {"sent": "in recent years , deep convolution neural networks have achieved promising performance on many artificial intelligence tasks , including image recognition .", "tokens": ["in", "recent", "years", ",", "deep", "convolution", "neural", "networks", "have", "achieved", "promising", "performance", "on", "many", "artificial", "intelligence", "tasks", ",", "including", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolution neural networks", "start": 18, "end": 50, "i_start": 4, "i_end": 7}, "verb": {"text": "have achieved", "start": 51, "end": 64, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 42, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 56, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 42, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "performance", "start": 75, "end": 86, "i_start": 11, "i_end": 11}}, {"character": {"text": "performance", "start": 75, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "promising", "start": 65, "end": 74, "i_start": 10, "i_end": 10}}], "id": 1188}, {"sent": "the number of atoms in the condensates vs .", "tokens": ["the", "number", "of", "atoms", "in", "the", "condensates", "vs", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1189}, {"sent": "note that also this ase is signi erent from the orresponding dbb solution .", "tokens": ["note", "that", "also", "this", "ase", "is", "signi", "erent", "from", "the", "orresponding", "dbb", "solution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this ase", "start": 15, "end": 23, "i_start": 3, "i_end": 4}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "this ase", "start": 15, "end": 23, "i_start": 3, "i_end": 4}, "verb": {"text": "signi", "start": 27, "end": 32, "i_start": 6, "i_end": 6}}], "id": 1190}, {"sent": "the g peak stiffening is due to the non-adiabatic removal of the kohn anomaly at the brillouin zone centre , \u03b3 .", "tokens": ["the", "g", "peak", "stiffening", "is", "due", "to", "the", "non", "-", "adiabatic", "removal", "of", "the", "kohn", "anomaly", "at", "the", "brillouin", "zone", "centre", ",", "\u03b3", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the g peak stiffening", "start": 0, "end": 21, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}], "id": 1191}, {"sent": "moreover this dispersion relation is a function of k which has a good behavior in the short wave limit .", "tokens": ["moreover", "this", "dispersion", "relation", "is", "a", "function", "of", "k", "which", "has", "a", "good", "behavior", "in", "the", "short", "wave", "limit", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this dispersion relation", "start": 9, "end": 33, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 4, "i_end": 4}}], "id": 1192}, {"sent": "recent works such as propose more sophisticated sampling techniques so as to reduce the variance of the aggregate estimation .", "tokens": ["recent", "works", "such", "as", "propose", "more", "sophisticated", "sampling", "techniques", "so", "as", "to", "reduce", "the", "variance", "of", "the", "aggregate", "estimation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "recent works such as", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "propose", "start": 21, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "techniques", "start": 57, "end": 67, "i_start": 8, "i_end": 8}, "action": {"text": "reduce", "start": 77, "end": 83, "i_start": 12, "i_end": 12}}], "id": 1193}, {"sent": "in particular , the coupling between random walk and alignment gives rise to interesting phenomena , cf .", "tokens": ["in", "particular", ",", "the", "coupling", "between", "random", "walk", "and", "alignment", "gives", "rise", "to", "interesting", "phenomena", ",", "cf", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the coupling between random walk and alignment", "start": 16, "end": 62, "i_start": 3, "i_end": 9}, "verb": {"text": "gives", "start": 63, "end": 68, "i_start": 10, "i_end": 10}}, {"character": {"text": "coupling", "start": 20, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "rise", "start": 69, "end": 73, "i_start": 11, "i_end": 11}}, {"character": {"text": "phenomena", "start": 89, "end": 98, "i_start": 14, "i_end": 14}, "action": {"text": "interesting", "start": 77, "end": 88, "i_start": 13, "i_end": 13}}], "id": 1194}, {"sent": "recently , far-field wireless power transfer has emerged as a promising technology to address energy and lifetime bottlenecks for power-limited devices in wireless networks .", "tokens": ["recently", ",", "far", "-", "field", "wireless", "power", "transfer", "has", "emerged", "as", "a", "promising", "technology", "to", "address", "energy", "and", "lifetime", "bottlenecks", "for", "power", "-", "limited", "devices", "in", "wireless", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "far-field wireless power transfer", "start": 11, "end": 44, "i_start": 2, "i_end": 7}, "verb": {"text": "has emerged", "start": 45, "end": 56, "i_start": 8, "i_end": 9}}, {"character": {"text": "transfer", "start": 36, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "emerged", "start": 49, "end": 56, "i_start": 9, "i_end": 9}}, {"character": {"text": "technology", "start": 72, "end": 82, "i_start": 13, "i_end": 13}, "action": {"text": "promising", "start": 62, "end": 71, "i_start": 12, "i_end": 12}}, {"character": {"text": "transfer", "start": 36, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "address", "start": 86, "end": 93, "i_start": 15, "i_end": 15}}, {"character": {"text": "power", "start": 130, "end": 135, "i_start": 21, "i_end": 21}, "action": {"text": "limited", "start": 136, "end": 143, "i_start": 23, "i_end": 23}}], "id": 1195}, {"sent": "the problem is inspired by the regularized empirical risk minimization in machine learning vapnik .", "tokens": ["the", "problem", "is", "inspired", "by", "the", "regularized", "empirical", "risk", "minimization", "in", "machine", "learning", "vapnik", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the problem", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is inspired", "start": 12, "end": 23, "i_start": 2, "i_end": 3}}, {"character": {"text": "minimization", "start": 58, "end": 70, "i_start": 9, "i_end": 9}, "action": {"text": "inspired", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "vapnik", "start": 91, "end": 97, "i_start": 13, "i_end": 13}, "action": {"text": "minimization", "start": 58, "end": 70, "i_start": 9, "i_end": 9}}], "id": 1196}, {"sent": "fabre , pattern formation in optical parametric oscillators , phys .", "tokens": ["fabre", ",", "pattern", "formation", "in", "optical", "parametric", "oscillators", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1197}, {"sent": "we will use routine extensions of this principle of summability without further comment .", "tokens": ["we", "will", "use", "routine", "extensions", "of", "this", "principle", "of", "summability", "without", "further", "comment", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will use", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "comment", "start": 80, "end": 87, "i_start": 12, "i_end": 12}}], "id": 1198}, {"sent": "here , we extend the study to the case when energy levels are possibly almost degenerate .", "tokens": ["here", ",", "we", "extend", "the", "study", "to", "the", "case", "when", "energy", "levels", "are", "possibly", "almost", "degenerate", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "extend", "start": 10, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "extend", "start": 10, "end": 16, "i_start": 3, "i_end": 3}}], "id": 1199}, {"sent": "deep convolutional neural networks are the state-of-the-art solution to many vision tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "are", "the", "state", "-", "of", "-", "the", "-", "art", "solution", "to", "many", "vision", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 35, "end": 38, "i_start": 4, "i_end": 4}}], "id": 1200}, {"sent": "so the orientation is the process that the current message holder i sends the message to its neighbor h , which has the most intimacy degree with the target t .", "tokens": ["so", "the", "orientation", "is", "the", "process", "that", "the", "current", "message", "holder", "i", "sends", "the", "message", "to", "its", "neighbor", "h", ",", "which", "has", "the", "most", "intimacy", "degree", "with", "the", "target", "t", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the orientation", "start": 3, "end": 18, "i_start": 1, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "current", "start": 43, "end": 50, "i_start": 8, "i_end": 8}, "action": {"text": "sends", "start": 68, "end": 73, "i_start": 12, "i_end": 12}}, {"character": {"text": "i", "start": 66, "end": 67, "i_start": 11, "i_end": 11}, "action": {"text": "sends", "start": 68, "end": 73, "i_start": 12, "i_end": 12}}], "id": 1201}, {"sent": "analysis of turbulence in the orthonormal wavelet representation .", "tokens": ["analysis", "of", "turbulence", "in", "the", "orthonormal", "wavelet", "representation", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1202}, {"sent": "convolutional networks are among the dominant deep learning models for many vison tasks , such as image classification .", "tokens": ["convolutional", "networks", "are", "among", "the", "dominant", "deep", "learning", "models", "for", "many", "vison", "tasks", ",", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional networks", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 23, "end": 26, "i_start": 2, "i_end": 2}}, {"character": {"text": "models", "start": 60, "end": 66, "i_start": 8, "i_end": 8}, "action": {"text": "dominant", "start": 37, "end": 45, "i_start": 5, "i_end": 5}}], "id": 1203}, {"sent": "gravitational forces are calculated using a combination of the particle mesh algorithm for large distances and the hierarchical tree algorithm for short distances .", "tokens": ["gravitational", "forces", "are", "calculated", "using", "a", "combination", "of", "the", "particle", "mesh", "algorithm", "for", "large", "distances", "and", "the", "hierarchical", "tree", "algorithm", "for", "short", "distances", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "gravitational forces", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "are calculated", "start": 21, "end": 35, "i_start": 2, "i_end": 3}}], "id": 1204}, {"sent": "a profile is a finite list of linear orders on the alternatives which represent the individual choices .", "tokens": ["a", "profile", "is", "a", "finite", "list", "of", "linear", "orders", "on", "the", "alternatives", "which", "represent", "the", "individual", "choices", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a profile", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "alternatives", "start": 51, "end": 63, "i_start": 11, "i_end": 11}, "action": {"text": "represent", "start": 70, "end": 79, "i_start": 13, "i_end": 13}}], "id": 1205}, {"sent": "deep reinforcement learning has recently achieved notable successes in a variety of domains .", "tokens": ["deep", "reinforcement", "learning", "has", "recently", "achieved", "notable", "successes", "in", "a", "variety", "of", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep reinforcement learning", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 41, "end": 49, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep reinforcement learning", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "has", "start": 28, "end": 31, "i_start": 3, "i_end": 3}}, {"character": {"text": "learning", "start": 19, "end": 27, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 41, "end": 49, "i_start": 5, "i_end": 5}}], "id": 1206}, {"sent": "convolutional neural networks have surpassed many traditional machine learning approaches in solving several computer vision tasks such as classification and others .", "tokens": ["convolutional", "neural", "networks", "have", "surpassed", "many", "traditional", "machine", "learning", "approaches", "in", "solving", "several", "computer", "vision", "tasks", "such", "as", "classification", "and", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have surpassed", "start": 30, "end": 44, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "surpassed", "start": 35, "end": 44, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "solving", "start": 93, "end": 100, "i_start": 11, "i_end": 11}}], "id": 1207}, {"sent": "recently , deep neural networks have achieved impressive results for many image classification tasks .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "achieved", "impressive", "results", "for", "many", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have achieved", "start": 32, "end": 45, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "results", "start": 57, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "impressive", "start": 46, "end": 56, "i_start": 7, "i_end": 7}}], "id": 1208}, {"sent": "the generalized gradient approximation was used to account for the exchange and correlations .", "tokens": ["the", "generalized", "gradient", "approximation", "was", "used", "to", "account", "for", "the", "exchange", "and", "correlations", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation", "start": 0, "end": 38, "i_start": 0, "i_end": 3}, "verb": {"text": "was used", "start": 39, "end": 47, "i_start": 4, "i_end": 5}}, {"character": {"text": "approximation", "start": 25, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "account", "start": 51, "end": 58, "i_start": 7, "i_end": 7}}], "id": 1209}, {"sent": "khimshiashvili , extremal problems on configuration spaces , proc .", "tokens": ["khimshiashvili", ",", "extremal", "problems", "on", "configuration", "spaces", ",", "proc", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1210}, {"sent": "the proposed method is compared with popular hashing methods including bre .", "tokens": ["the", "proposed", "method", "is", "compared", "with", "popular", "hashing", "methods", "including", "bre", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the proposed method", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is compared", "start": 20, "end": 31, "i_start": 3, "i_end": 4}}], "id": 1211}, {"sent": "a polytope is the convex hull of a point set , and conv denotes the convex hull of a .", "tokens": ["a", "polytope", "is", "the", "convex", "hull", "of", "a", "point", "set", ",", "and", "conv", "denotes", "the", "convex", "hull", "of", "a", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a polytope", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}, {"subject": {"text": "conv", "start": 51, "end": 55, "i_start": 12, "i_end": 12}, "verb": {"text": "denotes", "start": 56, "end": 63, "i_start": 13, "i_end": 13}}, {"character": {"text": "polytope", "start": 2, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "denotes", "start": 56, "end": 63, "i_start": 13, "i_end": 13}}], "id": 1212}, {"sent": "neural machine translation is quickly becoming the predominant approach to machine translation .", "tokens": ["neural", "machine", "translation", "is", "quickly", "becoming", "the", "predominant", "approach", "to", "machine", "translation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural machine translation", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "becoming", "start": 38, "end": 46, "i_start": 5, "i_end": 5}}, {"subject": {"text": "neural machine translation", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "approach", "start": 63, "end": 71, "i_start": 8, "i_end": 8}, "action": {"text": "predominant", "start": 51, "end": 62, "i_start": 7, "i_end": 7}}], "id": 1213}, {"sent": "in geometric optimization and vibrational property calculations , van der waals interactions were considered at the vdw-df level with the optb88 exchange functional .", "tokens": ["in", "geometric", "optimization", "and", "vibrational", "property", "calculations", ",", "van", "der", "waals", "interactions", "were", "considered", "at", "the", "vdw", "-", "df", "level", "with", "the", "optb88", "exchange", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "van der waals interactions", "start": 66, "end": 92, "i_start": 8, "i_end": 11}, "verb": {"text": "were considered", "start": 93, "end": 108, "i_start": 12, "i_end": 13}}], "id": 1214}, {"sent": "first , we assign the particles with the cloud in cell scheme to a 512 3 grid to obtain the density \u03c1 on the grid points .", "tokens": ["first", ",", "we", "assign", "the", "particles", "with", "the", "cloud", "in", "cell", "scheme", "to", "a", "512", "3", "grid", "to", "obtain", "the", "density", "\u03c1", "on", "the", "grid", "points", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "assign", "start": 11, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "assign", "start": 11, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "particles", "start": 22, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "obtain", "start": 81, "end": 87, "i_start": 18, "i_end": 18}}], "id": 1215}, {"sent": "aytar et al explored the natural synchronization between vision and sound to learn an acoustic representation from unlabeled video .", "tokens": ["aytar", "et", "al", "explored", "the", "natural", "synchronization", "between", "vision", "and", "sound", "to", "learn", "an", "acoustic", "representation", "from", "unlabeled", "video", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "aytar et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "explored", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "aytar", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "explored", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "aytar", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "learn", "start": 77, "end": 82, "i_start": 12, "i_end": 12}}], "id": 1216}, {"sent": "al proposed an hourglass structure where feature maps are zoomed in and out through stacks for pose estimation .", "tokens": ["al", "proposed", "an", "hourglass", "structure", "where", "feature", "maps", "are", "zoomed", "in", "and", "out", "through", "stacks", "for", "pose", "estimation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "al", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "proposed", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "al", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 1217}, {"sent": "we evaluate our approach on pascal voc 2007 and 2012 datasets which are the most widely-used benchmarks in weakly supervised object detection .", "tokens": ["we", "evaluate", "our", "approach", "on", "pascal", "voc", "2007", "and", "2012", "datasets", "which", "are", "the", "most", "widely", "-", "used", "benchmarks", "in", "weakly", "supervised", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "approach", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}], "id": 1218}, {"sent": "to do so , we use scikit-learn , a collection of python machine learning modules .", "tokens": ["to", "do", "so", ",", "we", "use", "scikit", "-", "learn", ",", "a", "collection", "of", "python", "machine", "learning", "modules", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 11, "end": 13, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 14, "end": 17, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 11, "end": 13, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 14, "end": 17, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 11, "end": 13, "i_start": 4, "i_end": 4}, "action": {"text": "do", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}], "id": 1219}, {"sent": "hsia et al uses pcg method which uses average of identity matrix and diagonal matrix as preconditioner , to solve the trust region subproblem and shows that pcg could be effective to solve ill-conditioned problems .", "tokens": ["hsia", "et", "al", "uses", "pcg", "method", "which", "uses", "average", "of", "identity", "matrix", "and", "diagonal", "matrix", "as", "preconditioner", ",", "to", "solve", "the", "trust", "region", "subproblem", "and", "shows", "that", "pcg", "could", "be", "effective", "to", "solve", "ill", "-", "conditioned", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hsia et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "uses", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "hsia", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "uses", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "method", "start": 20, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "uses", "start": 33, "end": 37, "i_start": 7, "i_end": 7}}, {"character": {"text": "hsia", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "solve", "start": 108, "end": 113, "i_start": 19, "i_end": 19}}], "id": 1220}, {"sent": "in particular , convolutional neural networks has been popular in vision and audio recognition areas .", "tokens": ["in", "particular", ",", "convolutional", "neural", "networks", "has", "been", "popular", "in", "vision", "and", "audio", "recognition", "areas", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "has been", "start": 46, "end": 54, "i_start": 6, "i_end": 7}}], "id": 1221}, {"sent": "the availability of large-scale data is known to be one of the critical success factors of deep learning .", "tokens": ["the", "availability", "of", "large", "-", "scale", "data", "is", "known", "to", "be", "one", "of", "the", "critical", "success", "factors", "of", "deep", "learning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the availability of large-scale data", "start": 0, "end": 36, "i_start": 0, "i_end": 6}, "verb": {"text": "is known", "start": 37, "end": 45, "i_start": 7, "i_end": 8}}], "id": 1222}, {"sent": "for k-path systems , we can achieve this by using our characterization of nash equilibria in such systems .", "tokens": ["for", "k", "-", "path", "systems", ",", "we", "can", "achieve", "this", "by", "using", "our", "characterization", "of", "nash", "equilibria", "in", "such", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 6, "i_end": 6}, "verb": {"text": "can achieve", "start": 24, "end": 35, "i_start": 7, "i_end": 8}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 6, "i_end": 6}, "action": {"text": "achieve", "start": 28, "end": 35, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 6, "i_end": 6}, "action": {"text": "characterization", "start": 54, "end": 70, "i_start": 13, "i_end": 13}}], "id": 1223}, {"sent": "he et al proposed a residual learning framework to solve this problem by adding an identity mapping between the input and the output of a group of layers .", "tokens": ["he", "et", "al", "proposed", "a", "residual", "learning", "framework", "to", "solve", "this", "problem", "by", "adding", "an", "identity", "mapping", "between", "the", "input", "and", "the", "output", "of", "a", "group", "of", "layers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "he et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "he", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "he", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "solve", "start": 51, "end": 56, "i_start": 9, "i_end": 9}}, {"character": {"text": "he", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adding", "start": 73, "end": 79, "i_start": 13, "i_end": 13}}], "id": 1224}, {"sent": "chen and geelen recently showed that each of the classes of frame and lifted-graphic matroids have infinitely many excluded minors .", "tokens": ["chen", "and", "geelen", "recently", "showed", "that", "each", "of", "the", "classes", "of", "frame", "and", "lifted", "-", "graphic", "matroids", "have", "infinitely", "many", "excluded", "minors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "chen and geelen", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 25, "end": 31, "i_start": 4, "i_end": 4}}, {"subject": {"text": "each of the classes of frame and lifted-graphic matroids have infinitely many", "start": 37, "end": 114, "i_start": 6, "i_end": 19}, "verb": {"text": "excluded", "start": 115, "end": 123, "i_start": 20, "i_end": 20}}, {"character": {"text": "chen", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 25, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "geelen", "start": 9, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "showed", "start": 25, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "classes", "start": 49, "end": 56, "i_start": 9, "i_end": 9}, "action": {"text": "have", "start": 94, "end": 98, "i_start": 17, "i_end": 17}}], "id": 1225}, {"sent": "we introduce the following notion to prove the theorem .", "tokens": ["we", "introduce", "the", "following", "notion", "to", "prove", "the", "theorem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "introduce", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "introduce", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "prove", "start": 37, "end": 42, "i_start": 6, "i_end": 6}}], "id": 1226}, {"sent": "in the second part of the paper , we address applications of the operadic cobar construction to the homotopy of algebras over operads .", "tokens": ["in", "the", "second", "part", "of", "the", "paper", ",", "we", "address", "applications", "of", "the", "operadic", "cobar", "construction", "to", "the", "homotopy", "of", "algebras", "over", "operads", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 34, "end": 36, "i_start": 8, "i_end": 8}, "verb": {"text": "address", "start": 37, "end": 44, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 8, "i_end": 8}, "action": {"text": "address", "start": 37, "end": 44, "i_start": 9, "i_end": 9}}], "id": 1227}, {"sent": "we need some standard model theoretic preparations .", "tokens": ["we", "need", "some", "standard", "model", "theoretic", "preparations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "need", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "need", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 1228}, {"sent": "different variants of distributed gradient methods under quantized communication have been studied in .", "tokens": ["different", "variants", "of", "distributed", "gradient", "methods", "under", "quantized", "communication", "have", "been", "studied", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "different variants of distributed gradient methods under quantized communication", "start": 0, "end": 80, "i_start": 0, "i_end": 8}, "verb": {"text": "have been studied", "start": 81, "end": 98, "i_start": 9, "i_end": 11}}], "id": 1229}, {"sent": "deep convolutional neural networks have shown tremendous success in a variety of computer vision tasks , such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "shown", "tremendous", "success", "in", "a", "variety", "of", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have shown", "start": 35, "end": 45, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 57, "end": 64, "i_start": 7, "i_end": 7}}], "id": 1230}, {"sent": "as before , we use the result from because the assumptions entering the calculation are clearer .", "tokens": ["as", "before", ",", "we", "use", "the", "result", "from", "because", "the", "assumptions", "entering", "the", "calculation", "are", "clearer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 12, "end": 14, "i_start": 3, "i_end": 3}, "verb": {"text": "use", "start": 15, "end": 18, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 12, "end": 14, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 15, "end": 18, "i_start": 4, "i_end": 4}}, {"character": {"text": "clearer", "start": 88, "end": 95, "i_start": 15, "i_end": 15}, "action": {"text": "because", "start": 35, "end": 42, "i_start": 8, "i_end": 8}}, {"character": {"text": "assumptions", "start": 47, "end": 58, "i_start": 10, "i_end": 10}, "action": {"text": "entering", "start": 59, "end": 67, "i_start": 11, "i_end": 11}}], "id": 1231}, {"sent": "deep neural networks have been widely adopted in many applications such as computer vision , speech recognition , and natural language processing .", "tokens": ["deep", "neural", "networks", "have", "been", "widely", "adopted", "in", "many", "applications", "such", "as", "computer", "vision", ",", "speech", "recognition", ",", "and", "natural", "language", "processing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "adopted", "start": 38, "end": 45, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}], "id": 1232}, {"sent": "this will be important for the discussion later in this section .", "tokens": ["this", "will", "be", "important", "for", "the", "discussion", "later", "in", "this", "section", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "will be", "start": 5, "end": 12, "i_start": 1, "i_end": 2}}], "id": 1233}, {"sent": "quantum mechanics is the mechanics of quantum states which do not exist independent of their realizations at least in principle , i .", "tokens": ["quantum", "mechanics", "is", "the", "mechanics", "of", "quantum", "states", "which", "do", "not", "exist", "independent", "of", "their", "realizations", "at", "least", "in", "principle", ",", "i", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum mechanics", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "realizations", "start": 93, "end": 105, "i_start": 15, "i_end": 15}, "action": {"text": "independent", "start": 72, "end": 83, "i_start": 12, "i_end": 12}}], "id": 1234}, {"sent": "dixon et al introduced a xor fragment of pt l and showed its tractability .", "tokens": ["dixon", "et", "al", "introduced", "a", "xor", "fragment", "of", "pt", "l", "and", "showed", "its", "tractability", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "dixon et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "introduced", "start": 12, "end": 22, "i_start": 3, "i_end": 3}}, {"subject": {"text": "dixon et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 50, "end": 56, "i_start": 11, "i_end": 11}}, {"character": {"text": "dixon", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 12, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "dixon", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 50, "end": 56, "i_start": 11, "i_end": 11}}], "id": 1235}, {"sent": "recent methods based on convolutional neural networks have been shown to produce results of high accuracy for a wide range of challenging computer vision tasks like image recognition .", "tokens": ["recent", "methods", "based", "on", "convolutional", "neural", "networks", "have", "been", "shown", "to", "produce", "results", "of", "high", "accuracy", "for", "a", "wide", "range", "of", "challenging", "computer", "vision", "tasks", "like", "image", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "recent methods based on convolutional neural networks", "start": 0, "end": 53, "i_start": 0, "i_end": 6}, "verb": {"text": "have been shown", "start": 54, "end": 69, "i_start": 7, "i_end": 9}}, {"character": {"text": "methods", "start": 7, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "produce", "start": 73, "end": 80, "i_start": 11, "i_end": 11}}, {"character": {"text": "tasks", "start": 154, "end": 159, "i_start": 24, "i_end": 24}, "action": {"text": "challenging", "start": 126, "end": 137, "i_start": 21, "i_end": 21}}], "id": 1236}, {"sent": "in this subsection , we modify the semigroup argument due to bakry and ledoux to prove two logarithmic sobolev inequalities for the time dependent witten laplacian on complete riemannian manifolds with k-super perelmam ricci flow .", "tokens": ["in", "this", "subsection", ",", "we", "modify", "the", "semigroup", "argument", "due", "to", "bakry", "and", "ledoux", "to", "prove", "two", "logarithmic", "sobolev", "inequalities", "for", "the", "time", "dependent", "witten", "laplacian", "on", "complete", "riemannian", "manifolds", "with", "k", "-", "super", "perelmam", "ricci", "flow", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "modify", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "modify", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "bakry", "start": 61, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "prove", "start": 81, "end": 86, "i_start": 15, "i_end": 15}}, {"character": {"text": "ledoux", "start": 71, "end": 77, "i_start": 13, "i_end": 13}, "action": {"text": "prove", "start": 81, "end": 86, "i_start": 15, "i_end": 15}}, {"character": {"text": "two logarithmic sobolev inequalities for the time dependent witten laplacian on complete riemannian manifolds with k-", "start": 87, "end": 204, "i_start": 16, "i_end": 32}, "action": {"text": "dependent", "start": 137, "end": 146, "i_start": 23, "i_end": 23}}], "id": 1237}, {"sent": "moreover , we prove here stronger results by taking into account the commutativity and semi-commutativity information .", "tokens": ["moreover", ",", "we", "prove", "here", "stronger", "results", "by", "taking", "into", "account", "the", "commutativity", "and", "semi", "-", "commutativity", "information", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "verb": {"text": "prove", "start": 14, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "prove", "start": 14, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "taking", "start": 45, "end": 51, "i_start": 8, "i_end": 8}}], "id": 1238}, {"sent": "cosmic strings are one-dimensional topological defects that can form during phase transitions in the early universe .", "tokens": ["cosmic", "strings", "are", "one", "-", "dimensional", "topological", "defects", "that", "can", "form", "during", "phase", "transitions", "in", "the", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}], "id": 1239}, {"sent": "the ellipses denote the o in the pion da .", "tokens": ["the", "ellipses", "denote", "the", "o", "in", "the", "pion", "da", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ellipses", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "denote", "start": 13, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "ellipses", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 13, "end": 19, "i_start": 2, "i_end": 2}}], "id": 1240}, {"sent": "is often called the displacement vector in the spatial representation .", "tokens": ["is", "often", "called", "the", "displacement", "vector", "in", "the", "spatial", "representation", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1241}, {"sent": "the ldg method was first introduced to solve a convection-diffusion problems by cockburn and shu .", "tokens": ["the", "ldg", "method", "was", "first", "introduced", "to", "solve", "a", "convection", "-", "diffusion", "problems", "by", "cockburn", "and", "shu", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ldg method", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "introduced", "start": 25, "end": 35, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the ldg method", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "was", "start": 15, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "method", "start": 8, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "solve", "start": 39, "end": 44, "i_start": 7, "i_end": 7}}], "id": 1242}, {"sent": "for the kriging experiments , we use the scikit-learn implementation .", "tokens": ["for", "the", "kriging", "experiments", ",", "we", "use", "the", "scikit", "-", "learn", "implementation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 33, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 33, "end": 36, "i_start": 6, "i_end": 6}}], "id": 1243}, {"sent": "to alleviate those limitations , various types of side information have been incorporated in mf , such as item images .", "tokens": ["to", "alleviate", "those", "limitations", ",", "various", "types", "of", "side", "information", "have", "been", "incorporated", "in", "mf", ",", "such", "as", "item", "images", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "various types of side information", "start": 33, "end": 66, "i_start": 5, "i_end": 9}, "verb": {"text": "have been incorporated", "start": 67, "end": 89, "i_start": 10, "i_end": 12}}, {"character": {"text": "incorporated", "start": 77, "end": 89, "i_start": 12, "i_end": 12}, "action": {"text": "alleviate", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}], "id": 1244}, {"sent": "ming et al studied a specialized classification problem on heterogeneous networks , where different types of nodes share a same set of label concepts .", "tokens": ["ming", "et", "al", "studied", "a", "specialized", "classification", "problem", "on", "heterogeneous", "networks", ",", "where", "different", "types", "of", "nodes", "share", "a", "same", "set", "of", "label", "concepts", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 5, "end": 10, "i_start": 1, "i_end": 2}, "verb": {"text": "ming", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "et al", "start": 5, "end": 10, "i_start": 1, "i_end": 2}, "verb": {"text": "studied", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "ming", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "studied", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "types", "start": 100, "end": 105, "i_start": 14, "i_end": 14}, "action": {"text": "share", "start": 115, "end": 120, "i_start": 17, "i_end": 17}}], "id": 1245}, {"sent": "we used the adam optimiser for training the model to avoid challenging points in the optimisation space .", "tokens": ["we", "used", "the", "adam", "optimiser", "for", "training", "the", "model", "to", "avoid", "challenging", "points", "in", "the", "optimisation", "space", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "training", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "avoid", "start": 53, "end": 58, "i_start": 10, "i_end": 10}}, {"character": {"text": "points", "start": 71, "end": 77, "i_start": 12, "i_end": 12}, "action": {"text": "challenging", "start": 59, "end": 70, "i_start": 11, "i_end": 11}}], "id": 1246}, {"sent": "in graphene , this is the case when the bandgap is close to the frequency detuning between the pump and the signal , ie , w cv w s .", "tokens": ["in", "graphene", ",", "this", "is", "the", "case", "when", "the", "bandgap", "is", "close", "to", "the", "frequency", "detuning", "between", "the", "pump", "and", "the", "signal", ",", "ie", ",", "w", "cv", "w", "s", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 14, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 4, "i_end": 4}}], "id": 1247}, {"sent": "these bianchi identities combined with the self-duality constraint imply the equations of motion for the self dual field .", "tokens": ["these", "bianchi", "identities", "combined", "with", "the", "self", "-", "duality", "constraint", "imply", "the", "equations", "of", "motion", "for", "the", "self", "dual", "field", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "these bianchi identities combined with the self-duality constraint", "start": 0, "end": 66, "i_start": 0, "i_end": 9}, "verb": {"text": "imply", "start": 67, "end": 72, "i_start": 10, "i_end": 10}}, {"character": {"text": "identities", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "imply", "start": 67, "end": 72, "i_start": 10, "i_end": 10}}], "id": 1248}, {"sent": "for this reason , we improve the theory of cooperpairs by taking also into account the effect of the interactions between the noncondensed pairs .", "tokens": ["for", "this", "reason", ",", "we", "improve", "the", "theory", "of", "cooperpairs", "by", "taking", "also", "into", "account", "the", "effect", "of", "the", "interactions", "between", "the", "noncondensed", "pairs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "improve", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "improve", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "taking", "start": 58, "end": 64, "i_start": 11, "i_end": 11}}, {"character": {"text": "pairs", "start": 139, "end": 144, "i_start": 23, "i_end": 23}, "action": {"text": "interactions", "start": 101, "end": 113, "i_start": 19, "i_end": 19}}], "id": 1249}, {"sent": "in this section we generalise this situation to nonclassical entangled two-photon polarisation states .", "tokens": ["in", "this", "section", "we", "generalise", "this", "situation", "to", "nonclassical", "entangled", "two", "-", "photon", "polarisation", "states", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "generalise", "start": 19, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "generalise", "start": 19, "end": 29, "i_start": 4, "i_end": 4}}], "id": 1250}, {"sent": "finally , we formalize our constrained inference process .", "tokens": ["finally", ",", "we", "formalize", "our", "constrained", "inference", "process", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "formalize", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "formalize", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "process", "start": 49, "end": 56, "i_start": 7, "i_end": 7}}], "id": 1251}, {"sent": "this identity shows that the product on the right hand side is in fact independent of the choice of z .", "tokens": ["this", "identity", "shows", "that", "the", "product", "on", "the", "right", "hand", "side", "is", "in", "fact", "independent", "of", "the", "choice", "of", "z", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this identity", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "shows", "start": 14, "end": 19, "i_start": 2, "i_end": 2}}, {"subject": {"text": "this identity", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 60, "end": 62, "i_start": 11, "i_end": 11}}, {"character": {"text": "identity", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "shows", "start": 14, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "product", "start": 29, "end": 36, "i_start": 5, "i_end": 5}, "action": {"text": "independent", "start": 71, "end": 82, "i_start": 14, "i_end": 14}}], "id": 1252}, {"sent": "first , in , qualitative results are provided for the scalability of the trickle algorithm , but a complete analysis is not given .", "tokens": ["first", ",", "in", ",", "qualitative", "results", "are", "provided", "for", "the", "scalability", "of", "the", "trickle", "algorithm", ",", "but", "a", "complete", "analysis", "is", "not", "given", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "qualitative results", "start": 13, "end": 32, "i_start": 4, "i_end": 5}, "verb": {"text": "are provided", "start": 33, "end": 45, "i_start": 6, "i_end": 7}}, {"subject": {"text": "a complete analysis", "start": 97, "end": 116, "i_start": 17, "i_end": 19}, "verb": {"text": "given", "start": 124, "end": 129, "i_start": 22, "i_end": 22}}], "id": 1253}, {"sent": "we also suggest that the random walk is a useful tool in studying the structure of networks .", "tokens": ["we", "also", "suggest", "that", "the", "random", "walk", "is", "a", "useful", "tool", "in", "studying", "the", "structure", "of", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "suggest", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 37, "end": 39, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "suggest", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}], "id": 1254}, {"sent": "the initialization of deep neural networks has received a significant amount of interest from many researchers in the field .", "tokens": ["the", "initialization", "of", "deep", "neural", "networks", "has", "received", "a", "significant", "amount", "of", "interest", "from", "many", "researchers", "in", "the", "field", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the initialization of deep neural networks", "start": 0, "end": 42, "i_start": 0, "i_end": 5}, "verb": {"text": "has received", "start": 43, "end": 55, "i_start": 6, "i_end": 7}}, {"character": {"text": "initialization", "start": 4, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "received", "start": 47, "end": 55, "i_start": 7, "i_end": 7}}], "id": 1255}, {"sent": "in recent years , convolutional neural networks have become the dominant approach for various tasks including classification .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "become", "the", "dominant", "approach", "for", "various", "tasks", "including", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have become", "start": 48, "end": 59, "i_start": 7, "i_end": 8}}, {"character": {"text": "approach", "start": 73, "end": 81, "i_start": 11, "i_end": 11}, "action": {"text": "dominant", "start": 64, "end": 72, "i_start": 10, "i_end": 10}}], "id": 1256}, {"sent": "for classification , we use a linear svm learned with the liblinear package in a one-vs-all manner .", "tokens": ["for", "classification", ",", "we", "use", "a", "linear", "svm", "learned", "with", "the", "liblinear", "package", "in", "a", "one", "-", "vs", "-", "all", "manner", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 3, "i_end": 3}, "verb": {"text": "use", "start": 24, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 24, "end": 27, "i_start": 4, "i_end": 4}}], "id": 1257}, {"sent": "circuit-qed systems , which are composed of superconducting artificial atoms coupled to superconducting resonators , offer promising platforms for quantum engineering and quantum-information processing .", "tokens": ["circuit", "-", "qed", "systems", ",", "which", "are", "composed", "of", "superconducting", "artificial", "atoms", "coupled", "to", "superconducting", "resonators", ",", "offer", "promising", "platforms", "for", "quantum", "engineering", "and", "quantum", "-", "information", "processing", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "circuit-qed systems", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "offer", "start": 117, "end": 122, "i_start": 17, "i_end": 17}}, {"character": {"text": "systems", "start": 12, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "offer", "start": 117, "end": 122, "i_start": 17, "i_end": 17}}], "id": 1258}, {"sent": "the frequently used peaks signal to noise ratio and structural similarity index metric are taken as the metrics of quantitative evaluation .", "tokens": ["the", "frequently", "used", "peaks", "signal", "to", "noise", "ratio", "and", "structural", "similarity", "index", "metric", "are", "taken", "as", "the", "metrics", "of", "quantitative", "evaluation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the frequently used peaks", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "signal", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}], "id": 1259}, {"sent": "recently , deep convolutional neural networks have achieved great successes in computer vision topics such as image classification .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "achieved", "great", "successes", "in", "computer", "vision", "topics", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "successes", "start": 66, "end": 75, "i_start": 9, "i_end": 9}}], "id": 1260}, {"sent": "deep convolutional neural networks have gained tremendous attention recently due to their great success in boosting the performance of image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "gained", "tremendous", "attention", "recently", "due", "to", "their", "great", "success", "in", "boosting", "the", "performance", "of", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have gained", "start": 35, "end": 46, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "gained", "start": 40, "end": 46, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 96, "end": 103, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "boosting", "start": 107, "end": 115, "i_start": 15, "i_end": 15}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 120, "end": 131, "i_start": 17, "i_end": 17}}], "id": 1261}, {"sent": "deep convolutional neural networks have seen great success in a range of computer vision tasks , including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "seen", "great", "success", "in", "a", "range", "of", "computer", "vision", "tasks", ",", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have seen", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "seen", "start": 40, "end": 44, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 51, "end": 58, "i_start": 7, "i_end": 7}}], "id": 1262}, {"sent": "we make use of the resnet-50 architecture trained on the imagenet natural image dataset .", "tokens": ["we", "make", "use", "of", "the", "resnet-50", "architecture", "trained", "on", "the", "imagenet", "natural", "image", "dataset", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "make", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}], "id": 1263}, {"sent": "a computational model of cuneothalamic projection neurons .", "tokens": ["a", "computational", "model", "of", "cuneothalamic", "projection", "neurons", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "neurons", "start": 50, "end": 57, "i_start": 6, "i_end": 6}, "action": {"text": "projection", "start": 39, "end": 49, "i_start": 5, "i_end": 5}}], "id": 1264}, {"sent": "this object is isomorphic to k 1 by the map .", "tokens": ["this", "object", "is", "isomorphic", "to", "k", "1", "by", "the", "map", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this object", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 1265}, {"sent": "some sort of noncommutative geometry are in fact interpreted by open string theories .", "tokens": ["some", "sort", "of", "noncommutative", "geometry", "are", "in", "fact", "interpreted", "by", "open", "string", "theories", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "some sort of noncommutative geometry", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "are", "start": 37, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "theories", "start": 76, "end": 84, "i_start": 12, "i_end": 12}, "action": {"text": "interpreted", "start": 49, "end": 60, "i_start": 8, "i_end": 8}}], "id": 1266}, {"sent": "besides higher-order modulation , we can also try to apply the technique to joint design with precoder .", "tokens": ["besides", "higher", "-", "order", "modulation", ",", "we", "can", "also", "try", "to", "apply", "the", "technique", "to", "joint", "design", "with", "precoder", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "verb": {"text": "try", "start": 46, "end": 49, "i_start": 9, "i_end": 9}}, {"subject": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "verb": {"text": "can", "start": 37, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "try", "start": 46, "end": 49, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "apply", "start": 53, "end": 58, "i_start": 11, "i_end": 11}}], "id": 1267}, {"sent": "the collapse of the field lines in the y-direction is obvious .", "tokens": ["the", "collapse", "of", "the", "field", "lines", "in", "the", "y", "-", "direction", "is", "obvious", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the collapse of the field lines in the y-direction", "start": 0, "end": 50, "i_start": 0, "i_end": 10}, "verb": {"text": "is", "start": 51, "end": 53, "i_start": 11, "i_end": 11}}], "id": 1268}, {"sent": "in the field of systems engineering , recent work on privacy includes , among others , privacy-preserving filtering of streaming data .", "tokens": ["in", "the", "field", "of", "systems", "engineering", ",", "recent", "work", "on", "privacy", "includes", ",", "among", "others", ",", "privacy", "-", "preserving", "filtering", "of", "streaming", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "recent work on privacy", "start": 38, "end": 60, "i_start": 7, "i_end": 10}, "verb": {"text": "includes", "start": 61, "end": 69, "i_start": 11, "i_end": 11}}, {"character": {"text": "filtering", "start": 106, "end": 115, "i_start": 19, "i_end": 19}, "action": {"text": "preserving", "start": 95, "end": 105, "i_start": 18, "i_end": 18}}], "id": 1269}, {"sent": "the history leading to measurement is unique and completely independent of the last instant choice of what to measure .", "tokens": ["the", "history", "leading", "to", "measurement", "is", "unique", "and", "completely", "independent", "of", "the", "last", "instant", "choice", "of", "what", "to", "measure", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the history leading to measurement", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "history", "start": 4, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "leading", "start": 12, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "history", "start": 4, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "independent", "start": 60, "end": 71, "i_start": 9, "i_end": 9}}], "id": 1270}, {"sent": "szegedy et al discovered that neural networks are particularly susceptible to such adversarial examples .", "tokens": ["szegedy", "et", "al", "discovered", "that", "neural", "networks", "are", "particularly", "susceptible", "to", "such", "adversarial", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "szegedy et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "discovered", "start": 14, "end": 24, "i_start": 3, "i_end": 3}}, {"subject": {"text": "szegedy et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 46, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "szegedy", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "discovered", "start": 14, "end": 24, "i_start": 3, "i_end": 3}}], "id": 1271}, {"sent": "however , recently researches have made a discovery that most of machine learning models , especially deep learning , are highly vulnerable to some well-designed attack methods .", "tokens": ["however", ",", "recently", "researches", "have", "made", "a", "discovery", "that", "most", "of", "machine", "learning", "models", ",", "especially", "deep", "learning", ",", "are", "highly", "vulnerable", "to", "some", "well", "-", "designed", "attack", "methods", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "researches", "start": 19, "end": 29, "i_start": 3, "i_end": 3}, "verb": {"text": "have made", "start": 30, "end": 39, "i_start": 4, "i_end": 5}}, {"character": {"text": "researches", "start": 19, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "discovery", "start": 42, "end": 51, "i_start": 7, "i_end": 7}}], "id": 1272}, {"sent": "a more detailed description of the cms detector , together with a definition of the coordinate system used , can be found in ref .", "tokens": ["a", "more", "detailed", "description", "of", "the", "cms", "detector", ",", "together", "with", "a", "definition", "of", "the", "coordinate", "system", "used", ",", "can", "be", "found", "in", "ref", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "a more detailed description of the cms detector", "start": 0, "end": 47, "i_start": 0, "i_end": 7}, "verb": {"text": "can be found", "start": 109, "end": 121, "i_start": 19, "i_end": 21}}], "id": 1273}, {"sent": "low-rank matrix estimation aims to recover the underlying low-rank matrix from its degraded observation , which has a variety of applications in computer vision and machine learning .", "tokens": ["low", "-", "rank", "matrix", "estimation", "aims", "to", "recover", "the", "underlying", "low", "-", "rank", "matrix", "from", "its", "degraded", "observation", ",", "which", "has", "a", "variety", "of", "applications", "in", "computer", "vision", "and", "machine", "learning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "low-rank matrix estimation", "start": 0, "end": 26, "i_start": 0, "i_end": 4}, "verb": {"text": "aims", "start": 27, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "estimation", "start": 16, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "aims", "start": 27, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "estimation", "start": 16, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "recover", "start": 35, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "matrix", "start": 67, "end": 73, "i_start": 13, "i_end": 13}, "action": {"text": "underlying", "start": 47, "end": 57, "i_start": 9, "i_end": 9}}, {"character": {"text": "estimation", "start": 16, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "observation", "start": 92, "end": 103, "i_start": 17, "i_end": 17}}, {"character": {"text": "observation", "start": 92, "end": 103, "i_start": 17, "i_end": 17}, "action": {"text": "has", "start": 112, "end": 115, "i_start": 20, "i_end": 20}}], "id": 1274}, {"sent": "deep neural networks have shown remarkable success in many domains , such as computer vision .", "tokens": ["deep", "neural", "networks", "have", "shown", "remarkable", "success", "in", "many", "domains", ",", "such", "as", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}], "id": 1275}, {"sent": "machine learning has shown great success in building models for pattern recognition in domains ranging from computer vision .", "tokens": ["machine", "learning", "has", "shown", "great", "success", "in", "building", "models", "for", "pattern", "recognition", "in", "domains", "ranging", "from", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "machine learning", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "has shown", "start": 17, "end": 26, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 8, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "success", "start": 33, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "learning", "start": 8, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "building", "start": 44, "end": 52, "i_start": 7, "i_end": 7}}], "id": 1276}, {"sent": "choy et al used a recurrent network with multi-view images for 3d model reconstruction .", "tokens": ["choy", "et", "al", "used", "a", "recurrent", "network", "with", "multi", "-", "view", "images", "for", "3d", "model", "reconstruction", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "choy et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "choy", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "choy", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "reconstruction", "start": 72, "end": 86, "i_start": 15, "i_end": 15}}], "id": 1277}, {"sent": "convolutional neural networks have been used in recent years to achieve state-of-the-art performance on object detection .", "tokens": ["convolutional", "neural", "networks", "have", "been", "used", "in", "recent", "years", "to", "achieve", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "object", "detection", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been used", "start": 30, "end": 44, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 64, "end": 71, "i_start": 10, "i_end": 10}}], "id": 1278}, {"sent": "it is known to be polynomially solvable for interval and proper interval graphs .", "tokens": ["it", "is", "known", "to", "be", "polynomially", "solvable", "for", "interval", "and", "proper", "interval", "graphs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is known", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}], "id": 1279}, {"sent": "moreover , fgvc datasets have minute inter-class visual differences in addition to the variations in pose , lighting and viewpoint found in standard image classification .", "tokens": ["moreover", ",", "fgvc", "datasets", "have", "minute", "inter", "-", "class", "visual", "differences", "in", "addition", "to", "the", "variations", "in", "pose", ",", "lighting", "and", "viewpoint", "found", "in", "standard", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "datasets", "start": 16, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "have", "start": 25, "end": 29, "i_start": 4, "i_end": 4}}], "id": 1280}, {"sent": "despite the existence of efficient branch and bound algorithms , these approaches suffer from worst-case exponential computational complexity .", "tokens": ["despite", "the", "existence", "of", "efficient", "branch", "and", "bound", "algorithms", ",", "these", "approaches", "suffer", "from", "worst", "-", "case", "exponential", "computational", "complexity", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "these approaches", "start": 65, "end": 81, "i_start": 10, "i_end": 11}, "verb": {"text": "suffer", "start": 82, "end": 88, "i_start": 12, "i_end": 12}}, {"character": {"text": "approaches", "start": 71, "end": 81, "i_start": 11, "i_end": 11}, "action": {"text": "suffer", "start": 82, "end": 88, "i_start": 12, "i_end": 12}}], "id": 1281}, {"sent": "such varieties z are called non-degenerate .", "tokens": ["such", "varieties", "z", "are", "called", "non", "-", "degenerate", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such varieties z", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "are called", "start": 17, "end": 27, "i_start": 3, "i_end": 4}}], "id": 1282}, {"sent": "here we disregard such details and concentrate on the symmetry issues .", "tokens": ["here", "we", "disregard", "such", "details", "and", "concentrate", "on", "the", "symmetry", "issues", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "disregard", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "concentrate", "start": 35, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "disregard", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "concentrate", "start": 35, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "symmetry", "start": 54, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "issues", "start": 63, "end": 69, "i_start": 10, "i_end": 10}}], "id": 1283}, {"sent": "in our setting , however , this may not be the case because the su invariance is not manifest in the low-energy four-dimensional theory .", "tokens": ["in", "our", "setting", ",", "however", ",", "this", "may", "not", "be", "the", "case", "because", "the", "su", "invariance", "is", "not", "manifest", "in", "the", "low", "-", "energy", "four", "-", "dimensional", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 27, "end": 31, "i_start": 6, "i_end": 6}, "verb": {"text": "may not be", "start": 32, "end": 42, "i_start": 7, "i_end": 9}}, {"character": {"text": "not manifest", "start": 81, "end": 93, "i_start": 17, "i_end": 18}, "action": {"text": "because", "start": 52, "end": 59, "i_start": 12, "i_end": 12}}], "id": 1284}, {"sent": "despite considerable e ort in this area , baseline correction remains a challenging problem , especially for a fully automatic system .", "tokens": ["despite", "considerable", "e", "ort", "in", "this", "area", ",", "baseline", "correction", "remains", "a", "challenging", "problem", ",", "especially", "for", "a", "fully", "automatic", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "baseline correction", "start": 42, "end": 61, "i_start": 8, "i_end": 9}, "verb": {"text": "remains", "start": 62, "end": 69, "i_start": 10, "i_end": 10}}, {"character": {"text": "problem", "start": 84, "end": 91, "i_start": 13, "i_end": 13}, "action": {"text": "challenging", "start": 72, "end": 83, "i_start": 12, "i_end": 12}}], "id": 1285}, {"sent": "the physics objects are the objects returned by a jet finding algorithm applied to all charged tracks associated with the vertex , plus the corresponding associated missing transverse momentum .", "tokens": ["the", "physics", "objects", "are", "the", "objects", "returned", "by", "a", "jet", "finding", "algorithm", "applied", "to", "all", "charged", "tracks", "associated", "with", "the", "vertex", ",", "plus", "the", "corresponding", "associated", "missing", "transverse", "momentum", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the physics objects", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 20, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithm", "start": 62, "end": 71, "i_start": 11, "i_end": 11}, "action": {"text": "returned", "start": 36, "end": 44, "i_start": 6, "i_end": 6}}], "id": 1286}, {"sent": "now we just recall the definition of complex lie algebra .", "tokens": ["now", "we", "just", "recall", "the", "definition", "of", "complex", "lie", "algebra", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "recall", "start": 12, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "recall", "start": 12, "end": 18, "i_start": 3, "i_end": 3}}], "id": 1287}, {"sent": "separation quality was measured using the bss-eval toolbox and is quantified in terms of signal-to-distortion ratio , signalto-artefact ratio and signal-to-interference ratio .", "tokens": ["separation", "quality", "was", "measured", "using", "the", "bss", "-", "eval", "toolbox", "and", "is", "quantified", "in", "terms", "of", "signal", "-", "to", "-", "distortion", "ratio", ",", "signalto", "-", "artefact", "ratio", "and", "signal", "-", "to", "-", "interference", "ratio", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "separation quality", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "was measured", "start": 19, "end": 31, "i_start": 2, "i_end": 3}}, {"subject": {"text": "separation quality", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "quantified", "start": 66, "end": 76, "i_start": 12, "i_end": 12}}], "id": 1288}, {"sent": "we also employ batch normalization technique in rcnn-ctc , which is used for normalizing each layers input to reduce internal covariance shift .", "tokens": ["we", "also", "employ", "batch", "normalization", "technique", "in", "rcnn", "-", "ctc", ",", "which", "is", "used", "for", "normalizing", "each", "layers", "input", "to", "reduce", "internal", "covariance", "shift", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employ", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}], "id": 1289}, {"sent": "the imagenet dataset consists 14,197,122 images with 1,000 classes .", "tokens": ["the", "imagenet", "dataset", "consists", "14,197,122", "images", "with", "1,000", "classes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the imagenet dataset", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 21, "end": 29, "i_start": 3, "i_end": 3}}], "id": 1290}, {"sent": "uses of convolutional and recurrent neural networks have been shown to achieve state-of-the-art performance in various fields .", "tokens": ["uses", "of", "convolutional", "and", "recurrent", "neural", "networks", "have", "been", "shown", "to", "achieve", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "various", "fields", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "uses of convolutional and recurrent neural networks", "start": 0, "end": 51, "i_start": 0, "i_end": 6}, "verb": {"text": "have been shown", "start": 52, "end": 67, "i_start": 7, "i_end": 9}}, {"character": {"text": "networks", "start": 43, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "achieve", "start": 71, "end": 78, "i_start": 11, "i_end": 11}}, {"character": {"text": "convolutional", "start": 8, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 71, "end": 78, "i_start": 11, "i_end": 11}}, {"character": {"text": "neural", "start": 36, "end": 42, "i_start": 5, "i_end": 5}, "action": {"text": "achieve", "start": 71, "end": 78, "i_start": 11, "i_end": 11}}], "id": 1291}, {"sent": "the functorial properties can easily be seen from this .", "tokens": ["the", "functorial", "properties", "can", "easily", "be", "seen", "from", "this", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the functorial properties", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "be seen", "start": 37, "end": 44, "i_start": 5, "i_end": 6}}, {"subject": {"text": "the functorial properties", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "can", "start": 26, "end": 29, "i_start": 3, "i_end": 3}}], "id": 1292}, {"sent": "two evaluation metrics of pd-noma networks including outage probability and ergodic rate have been proposed in , where the outage behaviors of users and ergodic rate have been discussed by applying stochastic geometry .", "tokens": ["two", "evaluation", "metrics", "of", "pd", "-", "noma", "networks", "including", "outage", "probability", "and", "ergodic", "rate", "have", "been", "proposed", "in", ",", "where", "the", "outage", "behaviors", "of", "users", "and", "ergodic", "rate", "have", "been", "discussed", "by", "applying", "stochastic", "geometry", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "two evaluation metrics of pd-noma networks including outage probability and ergodic rate", "start": 0, "end": 88, "i_start": 0, "i_end": 13}, "verb": {"text": "have been proposed", "start": 89, "end": 107, "i_start": 14, "i_end": 16}}], "id": 1293}, {"sent": "then , we deduce that almost every point on the free boundary respect to hn belongs to the reduced free boundary .", "tokens": ["then", ",", "we", "deduce", "that", "almost", "every", "point", "on", "the", "free", "boundary", "respect", "to", "hn", "belongs", "to", "the", "reduced", "free", "boundary", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "deduce", "start": 10, "end": 16, "i_start": 3, "i_end": 3}}, {"subject": {"text": "almost every point on the free boundary respect to hn", "start": 22, "end": 75, "i_start": 5, "i_end": 14}, "verb": {"text": "belongs", "start": 76, "end": 83, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "deduce", "start": 10, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "point", "start": 35, "end": 40, "i_start": 7, "i_end": 7}, "action": {"text": "belongs", "start": 76, "end": 83, "i_start": 15, "i_end": 15}}], "id": 1294}, {"sent": "and 8 show that the finite length performance of our codes is equal to or slightly better than the codes in .", "tokens": ["and", "8", "show", "that", "the", "finite", "length", "performance", "of", "our", "codes", "is", "equal", "to", "or", "slightly", "better", "than", "the", "codes", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "codes", "start": 53, "end": 58, "i_start": 10, "i_end": 10}, "action": {"text": "performance", "start": 34, "end": 45, "i_start": 7, "i_end": 7}}], "id": 1295}, {"sent": "the opacity consists of a grey continuum and a single atomic line .", "tokens": ["the", "opacity", "consists", "of", "a", "grey", "continuum", "and", "a", "single", "atomic", "line", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the opacity", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 12, "end": 20, "i_start": 2, "i_end": 2}}], "id": 1296}, {"sent": "all rcc-opf modeling was done using jumpchance modeling language .", "tokens": ["all", "rcc", "-", "opf", "modeling", "was", "done", "using", "jumpchance", "modeling", "language", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all rcc-opf modeling", "start": 0, "end": 20, "i_start": 0, "i_end": 4}, "verb": {"text": "was done", "start": 21, "end": 29, "i_start": 5, "i_end": 6}}], "id": 1297}, {"sent": "tests based on algorithmic information theory the results of the shapiro-wilk test are presented in table viii .", "tokens": ["tests", "based", "on", "algorithmic", "information", "theory", "the", "results", "of", "the", "shapiro", "-", "wilk", "test", "are", "presented", "in", "table", "viii", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "tests based on algorithmic information theory the results of the shapiro-wilk test", "start": 0, "end": 82, "i_start": 0, "i_end": 13}, "verb": {"text": "are presented", "start": 83, "end": 96, "i_start": 14, "i_end": 15}}], "id": 1298}, {"sent": "recently , deep convolutional neural networks have achieved great successes in computer vision topics such as image classification .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "achieved", "great", "successes", "in", "computer", "vision", "topics", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "successes", "start": 66, "end": 75, "i_start": 9, "i_end": 9}}], "id": 1299}, {"sent": "in fact , the change of variable was introduced by faccanoni and mangeney to study the shock and rarefaction waves of the riemann problem for the shallow water equations with a with coulomb-like friction term .", "tokens": ["in", "fact", ",", "the", "change", "of", "variable", "was", "introduced", "by", "faccanoni", "and", "mangeney", "to", "study", "the", "shock", "and", "rarefaction", "waves", "of", "the", "riemann", "problem", "for", "the", "shallow", "water", "equations", "with", "a", "with", "coulomb", "-", "like", "friction", "term", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the change of variable", "start": 10, "end": 32, "i_start": 3, "i_end": 6}, "verb": {"text": "was introduced", "start": 33, "end": 47, "i_start": 7, "i_end": 8}}, {"character": {"text": "faccanoni", "start": 51, "end": 60, "i_start": 10, "i_end": 10}, "action": {"text": "introduced", "start": 37, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "mangeney", "start": 65, "end": 73, "i_start": 12, "i_end": 12}, "action": {"text": "introduced", "start": 37, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "faccanoni", "start": 51, "end": 60, "i_start": 10, "i_end": 10}, "action": {"text": "study", "start": 77, "end": 82, "i_start": 14, "i_end": 14}}, {"character": {"text": "mangeney", "start": 65, "end": 73, "i_start": 12, "i_end": 12}, "action": {"text": "study", "start": 77, "end": 82, "i_start": 14, "i_end": 14}}, {"character": {"text": "problem", "start": 130, "end": 137, "i_start": 23, "i_end": 23}, "action": {"text": "shock", "start": 87, "end": 92, "i_start": 16, "i_end": 16}}], "id": 1300}, {"sent": "baum-welch training is an expectation maximization algorithm .", "tokens": ["baum", "-", "welch", "training", "is", "an", "expectation", "maximization", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "baum-welch training", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 4, "i_end": 4}}, {"character": {"text": "algorithm", "start": 51, "end": 60, "i_start": 8, "i_end": 8}, "action": {"text": "maximization", "start": 38, "end": 50, "i_start": 7, "i_end": 7}}], "id": 1301}, {"sent": "more specifically , we choose the pretrained vgg-19 network and finetune it with the facescrub dataset .", "tokens": ["more", "specifically", ",", "we", "choose", "the", "pretrained", "vgg-19", "network", "and", "finetune", "it", "with", "the", "facescrub", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "verb": {"text": "choose", "start": 23, "end": 29, "i_start": 4, "i_end": 4}}, {"subject": {"text": "we", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "verb": {"text": "finetune", "start": 64, "end": 72, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "choose", "start": 23, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "finetune", "start": 64, "end": 72, "i_start": 10, "i_end": 10}}], "id": 1302}, {"sent": "the middle pane on each plot illustrates the relative composition of the vincia uncertainty band .", "tokens": ["the", "middle", "pane", "on", "each", "plot", "illustrates", "the", "relative", "composition", "of", "the", "vincia", "uncertainty", "band", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the middle pane on each plot", "start": 0, "end": 28, "i_start": 0, "i_end": 5}, "verb": {"text": "illustrates", "start": 29, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "pane", "start": 11, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "illustrates", "start": 29, "end": 40, "i_start": 6, "i_end": 6}}], "id": 1303}, {"sent": "this type of growth is known as the heterogeneous condensation .", "tokens": ["this", "type", "of", "growth", "is", "known", "as", "the", "heterogeneous", "condensation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this type of growth", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "is known", "start": 20, "end": 28, "i_start": 4, "i_end": 5}}], "id": 1304}, {"sent": "to meet these different goals , we initialize our weights by adding these variances , while others take the arithmetic mean of these variances or ignore the backpropagation variance altogether .", "tokens": ["to", "meet", "these", "different", "goals", ",", "we", "initialize", "our", "weights", "by", "adding", "these", "variances", ",", "while", "others", "take", "the", "arithmetic", "mean", "of", "these", "variances", "or", "ignore", "the", "backpropagation", "variance", "altogether", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 32, "end": 34, "i_start": 6, "i_end": 6}, "verb": {"text": "initialize", "start": 35, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 32, "end": 34, "i_start": 6, "i_end": 6}, "action": {"text": "initialize", "start": 35, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 32, "end": 34, "i_start": 6, "i_end": 6}, "action": {"text": "adding", "start": 61, "end": 67, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 32, "end": 34, "i_start": 6, "i_end": 6}, "action": {"text": "meet", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 1305}, {"sent": "deep neural networks have been significantly successful in many artificial intelligence tasks such as im- age classification .", "tokens": ["deep", "neural", "networks", "have", "been", "significantly", "successful", "in", "many", "artificial", "intelligence", "tasks", "such", "as", "im-", "age", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 45, "end": 55, "i_start": 6, "i_end": 6}}], "id": 1306}, {"sent": "the qubit consists of a loop with three josephson junctions .", "tokens": ["the", "qubit", "consists", "of", "a", "loop", "with", "three", "josephson", "junctions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the qubit", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 10, "end": 18, "i_start": 2, "i_end": 2}}], "id": 1307}, {"sent": "later on various other types of solutions have been proposed and investigated with respect to various aspects .", "tokens": ["later", "on", "various", "other", "types", "of", "solutions", "have", "been", "proposed", "and", "investigated", "with", "respect", "to", "various", "aspects", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1308}, {"sent": "deep learning and deep convolutional neural networks in particular , have recently shown impressive performance on a number of multimedia information retrieval tasks .", "tokens": ["deep", "learning", "and", "deep", "convolutional", "neural", "networks", "in", "particular", ",", "have", "recently", "shown", "impressive", "performance", "on", "a", "number", "of", "multimedia", "information", "retrieval", "tasks", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "deep learning and deep convolutional neural networks in particular", "start": 0, "end": 66, "i_start": 0, "i_end": 8}, "verb": {"text": "shown", "start": 83, "end": 88, "i_start": 12, "i_end": 12}}, {"subject": {"text": "deep learning and deep convolutional neural networks in particular", "start": 0, "end": 66, "i_start": 0, "i_end": 8}, "verb": {"text": "have", "start": 69, "end": 73, "i_start": 10, "i_end": 10}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "shown", "start": 83, "end": 88, "i_start": 12, "i_end": 12}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "shown", "start": 83, "end": 88, "i_start": 12, "i_end": 12}}, {"character": {"text": "convolutional", "start": 23, "end": 36, "i_start": 4, "i_end": 4}, "action": {"text": "shown", "start": 83, "end": 88, "i_start": 12, "i_end": 12}}, {"character": {"text": "deep", "start": 18, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 83, "end": 88, "i_start": 12, "i_end": 12}}, {"character": {"text": "particular", "start": 56, "end": 66, "i_start": 8, "i_end": 8}, "action": {"text": "shown", "start": 83, "end": 88, "i_start": 12, "i_end": 12}}], "id": 1309}, {"sent": "convolutional neural networks have surpassed many traditional machine learning approaches in solving several computer vision tasks such as classification and others .", "tokens": ["convolutional", "neural", "networks", "have", "surpassed", "many", "traditional", "machine", "learning", "approaches", "in", "solving", "several", "computer", "vision", "tasks", "such", "as", "classification", "and", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have surpassed", "start": 30, "end": 44, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "surpassed", "start": 35, "end": 44, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "solving", "start": 93, "end": 100, "i_start": 11, "i_end": 11}}], "id": 1310}, {"sent": "within the order of 10s of ms , and consequently channel estimation at the same rate is available .", "tokens": ["within", "the", "order", "of", "10s", "of", "ms", ",", "and", "consequently", "channel", "estimation", "at", "the", "same", "rate", "is", "available", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1311}, {"sent": "answer set programming is a rule-based approach to declarative problem solving .", "tokens": ["answer", "set", "programming", "is", "a", "rule", "-", "based", "approach", "to", "declarative", "problem", "solving", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "set programming", "start": 7, "end": 22, "i_start": 1, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}], "id": 1312}, {"sent": "in this case , transfer learning has been a promising approach by transferring knowledge from a labeled source domain to the target domain .", "tokens": ["in", "this", "case", ",", "transfer", "learning", "has", "been", "a", "promising", "approach", "by", "transferring", "knowledge", "from", "a", "labeled", "source", "domain", "to", "the", "target", "domain", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "transfer learning", "start": 15, "end": 32, "i_start": 4, "i_end": 5}, "verb": {"text": "has been", "start": 33, "end": 41, "i_start": 6, "i_end": 7}}], "id": 1313}, {"sent": "the expectation-maximization algorithm is an iterative procedure based on the complete-data likelihood .", "tokens": ["the", "expectation", "-", "maximization", "algorithm", "is", "an", "iterative", "procedure", "based", "on", "the", "complete", "-", "data", "likelihood", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the expectation-maximization algorithm", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 5, "i_end": 5}}], "id": 1314}, {"sent": "deep neural networks are powerful representation learning models which achieve near-human performance in image recognition tasks .", "tokens": ["deep", "neural", "networks", "are", "powerful", "representation", "learning", "models", "which", "achieve", "near", "-", "human", "performance", "in", "image", "recognition", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 58, "end": 64, "i_start": 7, "i_end": 7}, "action": {"text": "achieve", "start": 71, "end": 78, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 90, "end": 101, "i_start": 13, "i_end": 13}}], "id": 1315}, {"sent": "convolutional neural networks have proven to be effective models for tackling a variety of visual tasks .", "tokens": ["convolutional", "neural", "networks", "have", "proven", "to", "be", "effective", "models", "for", "tackling", "a", "variety", "of", "visual", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have proven", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "models", "start": 58, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "effective", "start": 48, "end": 57, "i_start": 7, "i_end": 7}}], "id": 1316}, {"sent": "a bose-einstein condensate is a classical state of the atomic field , in a way similar to the laser being a classical state of the electromagnetic field .", "tokens": ["a", "bose", "-", "einstein", "condensate", "is", "a", "classical", "state", "of", "the", "atomic", "field", ",", "in", "a", "way", "similar", "to", "the", "laser", "being", "a", "classical", "state", "of", "the", "electromagnetic", "field", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a bose-einstein condensate", "start": 0, "end": 26, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 5, "i_end": 5}}], "id": 1317}, {"sent": "isola et al proposed a framework called pix2pix , which used generative adversarial networks for image-to-image translation .", "tokens": ["isola", "et", "al", "proposed", "a", "framework", "called", "pix2pix", ",", "which", "used", "generative", "adversarial", "networks", "for", "image", "-", "to", "-", "image", "translation", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 6, "end": 11, "i_start": 1, "i_end": 2}, "verb": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "isola", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "framework", "start": 23, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "used", "start": 56, "end": 60, "i_start": 10, "i_end": 10}}], "id": 1318}, {"sent": "the wightman function also determines the response of the particle detectors in a given state of motion .", "tokens": ["the", "wightman", "function", "also", "determines", "the", "response", "of", "the", "particle", "detectors", "in", "a", "given", "state", "of", "motion", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the wightman function", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "determines", "start": 27, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "function", "start": 13, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "determines", "start": 27, "end": 37, "i_start": 4, "i_end": 4}}], "id": 1319}, {"sent": "simon et al discovered objects mined cnn patterns for a part concept and transformed the pattern knowledge into an aog model .", "tokens": ["simon", "et", "al", "discovered", "objects", "mined", "cnn", "patterns", "for", "a", "part", "concept", "and", "transformed", "the", "pattern", "knowledge", "into", "an", "aog", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "simon et al discovered objects", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "mined", "start": 31, "end": 36, "i_start": 5, "i_end": 5}}, {"subject": {"text": "simon et al discovered objects", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "transformed", "start": 73, "end": 84, "i_start": 13, "i_end": 13}}, {"character": {"text": "simon", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "discovered", "start": 12, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "objects", "start": 23, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "mined", "start": 31, "end": 36, "i_start": 5, "i_end": 5}}], "id": 1320}, {"sent": "then subspace ca v is a onedimensional aut o submodule of v .", "tokens": ["then", "subspace", "ca", "v", "is", "a", "onedimensional", "aut", "o", "submodule", "of", "v", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "subspace ca v", "start": 5, "end": 18, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 4, "i_end": 4}}], "id": 1321}, {"sent": "since the seminal work of , convolutional neural networks have become the standard tool for image classification due to their impressive performance .", "tokens": ["since", "the", "seminal", "work", "of", ",", "convolutional", "neural", "networks", "have", "become", "the", "standard", "tool", "for", "image", "classification", "due", "to", "their", "impressive", "performance", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 28, "end": 57, "i_start": 6, "i_end": 8}, "verb": {"text": "have become", "start": 58, "end": 69, "i_start": 9, "i_end": 10}}, {"character": {"text": "networks", "start": 49, "end": 57, "i_start": 8, "i_end": 8}, "action": {"text": "performance", "start": 137, "end": 148, "i_start": 21, "i_end": 21}}, {"character": {"text": "performance", "start": 137, "end": 148, "i_start": 21, "i_end": 21}, "action": {"text": "impressive", "start": 126, "end": 136, "i_start": 20, "i_end": 20}}], "id": 1322}, {"sent": "among these higher-curvature theories , we take attention to gb gravity in this paper .", "tokens": ["among", "these", "higher", "-", "curvature", "theories", ",", "we", "take", "attention", "to", "gb", "gravity", "in", "this", "paper", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 40, "end": 42, "i_start": 7, "i_end": 7}, "verb": {"text": "take", "start": 43, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 40, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "attention", "start": 48, "end": 57, "i_start": 9, "i_end": 9}}], "id": 1323}, {"sent": "a cosmological constant is a good description of the current data .", "tokens": ["a", "cosmological", "constant", "is", "a", "good", "description", "of", "the", "current", "data", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a cosmological constant", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "constant", "start": 15, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "description", "start": 34, "end": 45, "i_start": 6, "i_end": 6}}], "id": 1324}, {"sent": "propagation of the wavefront arrival time to the geocenter requires knowledge of the sgr sky position and knowledge of the satellite position relative to the geocenter .", "tokens": ["propagation", "of", "the", "wavefront", "arrival", "time", "to", "the", "geocenter", "requires", "knowledge", "of", "the", "sgr", "sky", "position", "and", "knowledge", "of", "the", "satellite", "position", "relative", "to", "the", "geocenter", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "propagation of the wavefront arrival time to the geocenter", "start": 0, "end": 58, "i_start": 0, "i_end": 8}, "verb": {"text": "requires", "start": 59, "end": 67, "i_start": 9, "i_end": 9}}, {"character": {"text": "propagation", "start": 0, "end": 11, "i_start": 0, "i_end": 0}, "action": {"text": "requires", "start": 59, "end": 67, "i_start": 9, "i_end": 9}}], "id": 1325}, {"sent": "5the scalar field yielding inflation is called the inflaton .", "tokens": ["5the", "scalar", "field", "yielding", "inflation", "is", "called", "the", "inflaton", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "5the scalar field yielding inflation", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "is called", "start": 37, "end": 46, "i_start": 5, "i_end": 6}}, {"character": {"text": "field", "start": 12, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "yielding", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}], "id": 1326}, {"sent": "we use the standard cross-entropy loss for training and train all networks for 20 epochs with a batch size of 32 using adam .", "tokens": ["we", "use", "the", "standard", "cross", "-", "entropy", "loss", "for", "training", "and", "train", "all", "networks", "for", "20", "epochs", "with", "a", "batch", "size", "of", "32", "using", "adam", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 56, "end": 61, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "training", "start": 43, "end": 51, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 113, "end": 118, "i_start": 23, "i_end": 23}}], "id": 1327}, {"sent": "convolutional neural networks have achieved superior performance in many visual tasks , such as object classification and detection .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "classification", "and", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 6, "i_end": 6}}], "id": 1328}, {"sent": "in recent years , there have been outstanding achievements in objects detection by successfully deploying a convolutional neural network .", "tokens": ["in", "recent", "years", ",", "there", "have", "been", "outstanding", "achievements", "in", "objects", "detection", "by", "successfully", "deploying", "a", "convolutional", "neural", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 18, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "have been", "start": 24, "end": 33, "i_start": 5, "i_end": 6}}], "id": 1329}, {"sent": "we follow the setting of by using 5,000 images for offline validation and 5,000 images for offline testing .", "tokens": ["we", "follow", "the", "setting", "of", "by", "using", "5,000", "images", "for", "offline", "validation", "and", "5,000", "images", "for", "offline", "testing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 28, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "validation", "start": 59, "end": 69, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "testing", "start": 99, "end": 106, "i_start": 17, "i_end": 17}}], "id": 1330}, {"sent": "recently , deep convolutional neural networks showed outstanding performance in automatic feature extraction , leading to a dramatic breakthrough in a range of fields associated with computer vision .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "showed", "outstanding", "performance", "in", "automatic", "feature", "extraction", ",", "leading", "to", "a", "dramatic", "breakthrough", "in", "a", "range", "of", "fields", "associated", "with", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "showed", "start": 46, "end": 52, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "showed", "start": 46, "end": 52, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 65, "end": 76, "i_start": 8, "i_end": 8}}, {"character": {"text": "showed", "start": 46, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "leading", "start": 111, "end": 118, "i_start": 14, "i_end": 14}}], "id": 1331}, {"sent": "temporal distance metrics for social network analysis .", "tokens": ["temporal", "distance", "metrics", "for", "social", "network", "analysis", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1332}, {"sent": "bacteria can exchange dna through diverse mechanisms including transformation , transduction , conjugation , gene transfer agents , and nanotubes 5 , 6 .", "tokens": ["bacteria", "can", "exchange", "dna", "through", "diverse", "mechanisms", "including", "transformation", ",", "transduction", ",", "conjugation", ",", "gene", "transfer", "agents", ",", "and", "nanotubes", "5", ",", "6", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bacteria", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "can exchange", "start": 9, "end": 21, "i_start": 1, "i_end": 2}}, {"character": {"text": "bacteria", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "exchange", "start": 13, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "agents", "start": 123, "end": 129, "i_start": 16, "i_end": 16}, "action": {"text": "transfer", "start": 114, "end": 122, "i_start": 15, "i_end": 15}}], "id": 1333}, {"sent": "afterwards , we describe precisely the families of curves which can be obtained by applying the generalized methods to several types of plane curves .", "tokens": ["afterwards", ",", "we", "describe", "precisely", "the", "families", "of", "curves", "which", "can", "be", "obtained", "by", "applying", "the", "generalized", "methods", "to", "several", "types", "of", "plane", "curves", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 13, "end": 15, "i_start": 2, "i_end": 2}, "verb": {"text": "describe", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "describe", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}], "id": 1334}, {"sent": "the positive samples are all types of vehicles from the ua-detrac-train dataset , while the kitti-d dataset is used for hard negative mining .", "tokens": ["the", "positive", "samples", "are", "all", "types", "of", "vehicles", "from", "the", "ua", "-", "detrac", "-", "train", "dataset", ",", "while", "the", "kitti", "-", "d", "dataset", "is", "used", "for", "hard", "negative", "mining", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the positive samples", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}], "id": 1335}, {"sent": "based on these measurements , we can compute the ionization fractions for these elements within the lic .", "tokens": ["based", "on", "these", "measurements", ",", "we", "can", "compute", "the", "ionization", "fractions", "for", "these", "elements", "within", "the", "lic", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "verb": {"text": "can compute", "start": 33, "end": 44, "i_start": 6, "i_end": 7}}, {"character": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "compute", "start": 37, "end": 44, "i_start": 7, "i_end": 7}}], "id": 1336}, {"sent": "fernandez de la vega and lueker proposed the first polynomial-time approximation scheme for 1-dimensional bin-packing problems and proved that 2-dimensional packing problems can not have a polynomial-time approximation scheme .", "tokens": ["fernandez", "de", "la", "vega", "and", "lueker", "proposed", "the", "first", "polynomial", "-", "time", "approximation", "scheme", "for", "1", "-", "dimensional", "bin", "-", "packing", "problems", "and", "proved", "that", "2", "-", "dimensional", "packing", "problems", "can", "not", "have", "a", "polynomial", "-", "time", "approximation", "scheme", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "fernandez de la vega and lueker", "start": 0, "end": 31, "i_start": 0, "i_end": 5}, "verb": {"text": "proposed", "start": 32, "end": 40, "i_start": 6, "i_end": 6}}, {"subject": {"text": "fernandez de la vega and lueker", "start": 0, "end": 31, "i_start": 0, "i_end": 5}, "verb": {"text": "proved", "start": 131, "end": 137, "i_start": 23, "i_end": 23}}, {"character": {"text": "fernandez de la vega", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "action": {"text": "proposed", "start": 32, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "lueker", "start": 25, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "proposed", "start": 32, "end": 40, "i_start": 6, "i_end": 6}}], "id": 1337}, {"sent": "on the other hand , along the line of phase transitions driven by the surface , the bulk layers are less ordered than the surfaces .", "tokens": ["on", "the", "other", "hand", ",", "along", "the", "line", "of", "phase", "transitions", "driven", "by", "the", "surface", ",", "the", "bulk", "layers", "are", "less", "ordered", "than", "the", "surfaces", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "surface", "start": 70, "end": 77, "i_start": 14, "i_end": 14}, "action": {"text": "driven", "start": 56, "end": 62, "i_start": 11, "i_end": 11}}], "id": 1338}, {"sent": "at high energies there is a large phase space for the emission of soft partons off the incoming hadrons .", "tokens": ["at", "high", "energies", "there", "is", "a", "large", "phase", "space", "for", "the", "emission", "of", "soft", "partons", "off", "the", "incoming", "hadrons", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 17, "end": 22, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 4, "i_end": 4}}], "id": 1339}, {"sent": "deep convolutional neural networks have shown remarkable success for various computer vision tasks in static images , such as object detection .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "shown", "remarkable", "success", "for", "various", "computer", "vision", "tasks", "in", "static", "images", ",", "such", "as", "object", "detection", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have shown", "start": 35, "end": 45, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 57, "end": 64, "i_start": 7, "i_end": 7}}], "id": 1340}, {"sent": "convolutional neural networks have recently achieved the state-of-the-art performance in many image analysis tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "achieved", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "many", "image", "analysis", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 74, "end": 85, "i_start": 14, "i_end": 14}}], "id": 1341}, {"sent": "in , we showed that any semisimple hopf action on a commutative domain over k factors through a group action .", "tokens": ["in", ",", "we", "showed", "that", "any", "semisimple", "hopf", "action", "on", "a", "commutative", "domain", "over", "k", "factors", "through", "a", "group", "action", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "verb": {"text": "showed", "start": 8, "end": 14, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "action": {"text": "showed", "start": 8, "end": 14, "i_start": 3, "i_end": 3}}], "id": 1342}, {"sent": "the rotation number is the sum of the rotations of the components .", "tokens": ["the", "rotation", "number", "is", "the", "sum", "of", "the", "rotations", "of", "the", "components", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the rotation number", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 1343}, {"sent": "the reader is directed to the survey articles el karoui , peng and quenez and the references therein for further discussion .", "tokens": ["the", "reader", "is", "directed", "to", "the", "survey", "articles", "el", "karoui", ",", "peng", "and", "quenez", "and", "the", "references", "therein", "for", "further", "discussion", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the reader", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is directed", "start": 11, "end": 22, "i_start": 2, "i_end": 3}}], "id": 1344}, {"sent": "an encoder-decoder framework is presented by kiros et al utilizing a joint multimodal space in which the lstm is a big success .", "tokens": ["an", "encoder", "-", "decoder", "framework", "is", "presented", "by", "kiros", "et", "al", "utilizing", "a", "joint", "multimodal", "space", "in", "which", "the", "lstm", "is", "a", "big", "success", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "an encoder-decoder framework", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "is presented", "start": 29, "end": 41, "i_start": 5, "i_end": 6}}, {"character": {"text": "kiros", "start": 45, "end": 50, "i_start": 8, "i_end": 8}, "action": {"text": "presented", "start": 32, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "framework", "start": 19, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "utilizing", "start": 57, "end": 66, "i_start": 11, "i_end": 11}}], "id": 1345}, {"sent": "the response of a particle detector in an arbitrary state of motion is determined by this function .", "tokens": ["the", "response", "of", "a", "particle", "detector", "in", "an", "arbitrary", "state", "of", "motion", "is", "determined", "by", "this", "function", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "the response of a particle detector in an arbitrary state of motion", "start": 0, "end": 67, "i_start": 0, "i_end": 11}, "verb": {"text": "is determined", "start": 68, "end": 81, "i_start": 12, "i_end": 13}}, {"character": {"text": "function", "start": 90, "end": 98, "i_start": 16, "i_end": 16}, "action": {"text": "determined", "start": 71, "end": 81, "i_start": 13, "i_end": 13}}], "id": 1346}, {"sent": "in this section , we will show that the stack of twisted sheaves is algebraic .", "tokens": ["in", "this", "section", ",", "we", "will", "show", "that", "the", "stack", "of", "twisted", "sheaves", "is", "algebraic", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "will show", "start": 21, "end": 30, "i_start": 5, "i_end": 6}}, {"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "is", "start": 65, "end": 67, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "show", "start": 26, "end": 30, "i_start": 6, "i_end": 6}}], "id": 1347}, {"sent": "here the superscripts on t denote the order of the coupling constant in the expansion .", "tokens": ["here", "the", "superscripts", "on", "t", "denote", "the", "order", "of", "the", "coupling", "constant", "in", "the", "expansion", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the superscripts on t", "start": 5, "end": 26, "i_start": 1, "i_end": 4}, "verb": {"text": "denote", "start": 27, "end": 33, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the superscripts on t", "start": 5, "end": 26, "i_start": 1, "i_end": 4}, "verb": {"text": "constant", "start": 60, "end": 68, "i_start": 11, "i_end": 11}}, {"character": {"text": "superscripts", "start": 9, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "denote", "start": 27, "end": 33, "i_start": 5, "i_end": 5}}], "id": 1348}, {"sent": "depth depolarization - also known as differential faraday rotation .", "tokens": ["depth", "depolarization", "-", "also", "known", "as", "differential", "faraday", "rotation", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1349}, {"sent": "deep convolutional neural networks have made great progress in visual recognition challenges such as object classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "great", "progress", "in", "visual", "recognition", "challenges", "such", "as", "object", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}], "id": 1350}, {"sent": "the pascal voc 2012 dataset we use is augmented with extra annotation by hariharan et al , resulting in 10582 training images .", "tokens": ["the", "pascal", "voc", "2012", "dataset", "we", "use", "is", "augmented", "with", "extra", "annotation", "by", "hariharan", "et", "al", ",", "resulting", "in", "10582", "training", "images", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the pascal voc 2012 dataset we use", "start": 0, "end": 34, "i_start": 0, "i_end": 6}, "verb": {"text": "is augmented", "start": 35, "end": 47, "i_start": 7, "i_end": 8}}, {"character": {"text": "we", "start": 28, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 31, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "hariharan", "start": 73, "end": 82, "i_start": 13, "i_end": 13}, "action": {"text": "annotation", "start": 59, "end": 69, "i_start": 11, "i_end": 11}}], "id": 1351}, {"sent": "convolutional neural networks have achieved great success in many fields , such as object classification , face recognition .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "many", "fields", ",", "such", "as", "object", "classification", ",", "face", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "face", "start": 107, "end": 111, "i_start": 16, "i_end": 16}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}], "id": 1352}, {"sent": "deep neural networks have shown tremendous success in several computer vision tasks in recent years .", "tokens": ["deep", "neural", "networks", "have", "shown", "tremendous", "success", "in", "several", "computer", "vision", "tasks", "in", "recent", "years", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}], "id": 1353}, {"sent": "more recently , off-the-shelf convolutional neural network representations have demonstrated great success in image retrieval .", "tokens": ["more", "recently", ",", "off", "-", "the", "-", "shelf", "convolutional", "neural", "network", "representations", "have", "demonstrated", "great", "success", "in", "image", "retrieval", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "off-the-shelf convolutional neural network representations", "start": 16, "end": 74, "i_start": 3, "i_end": 11}, "verb": {"text": "have demonstrated", "start": 75, "end": 92, "i_start": 12, "i_end": 13}}, {"character": {"text": "representations", "start": 59, "end": 74, "i_start": 11, "i_end": 11}, "action": {"text": "demonstrated", "start": 80, "end": 92, "i_start": 13, "i_end": 13}}, {"character": {"text": "representations", "start": 59, "end": 74, "i_start": 11, "i_end": 11}, "action": {"text": "success", "start": 99, "end": 106, "i_start": 15, "i_end": 15}}, {"character": {"text": "representations", "start": 59, "end": 74, "i_start": 11, "i_end": 11}, "action": {"text": "retrieval", "start": 116, "end": 125, "i_start": 18, "i_end": 18}}], "id": 1354}, {"sent": "the interdisciplinary field of complex networks has recently received considerable attention .", "tokens": ["the", "interdisciplinary", "field", "of", "complex", "networks", "has", "recently", "received", "considerable", "attention", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the interdisciplinary field of complex networks", "start": 0, "end": 47, "i_start": 0, "i_end": 5}, "verb": {"text": "received", "start": 61, "end": 69, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the interdisciplinary field of complex networks", "start": 0, "end": 47, "i_start": 0, "i_end": 5}, "verb": {"text": "has", "start": 48, "end": 51, "i_start": 6, "i_end": 6}}], "id": 1355}, {"sent": "mezic et al propose metrics of dynamical systems in the context of ergodic theory via koopman operators on l 2 -spaces .", "tokens": ["mezic", "et", "al", "propose", "metrics", "of", "dynamical", "systems", "in", "the", "context", "of", "ergodic", "theory", "via", "koopman", "operators", "on", "l", "2", "-spaces", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 6, "end": 11, "i_start": 1, "i_end": 2}, "verb": {"text": "propose", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "mezic", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}], "id": 1356}, {"sent": "recently , neural network smoothing have shown excellent performance in language modeling .", "tokens": ["recently", ",", "neural", "network", "smoothing", "have", "shown", "excellent", "performance", "in", "language", "modeling", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural network smoothing", "start": 11, "end": 35, "i_start": 2, "i_end": 4}, "verb": {"text": "have shown", "start": 36, "end": 46, "i_start": 5, "i_end": 6}}, {"character": {"text": "smoothing", "start": 26, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "shown", "start": 41, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "smoothing", "start": 26, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "performance", "start": 57, "end": 68, "i_start": 8, "i_end": 8}}], "id": 1357}, {"sent": "the solutions of canonical basis can be easily written down iteratively order by order in , all in terms of harmonic polylogarithms .", "tokens": ["the", "solutions", "of", "canonical", "basis", "can", "be", "easily", "written", "down", "iteratively", "order", "by", "order", "in", ",", "all", "in", "terms", "of", "harmonic", "polylogarithms", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the solutions of canonical basis", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "written down", "start": 47, "end": 59, "i_start": 8, "i_end": 9}}, {"subject": {"text": "the solutions of canonical basis", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "can be", "start": 33, "end": 39, "i_start": 5, "i_end": 6}}], "id": 1358}, {"sent": "the apparatus is a non-interacting bose gas , which has an easily tractable phase transition .", "tokens": ["the", "apparatus", "is", "a", "non", "-", "interacting", "bose", "gas", ",", "which", "has", "an", "easily", "tractable", "phase", "transition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the apparatus", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "gas", "start": 40, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "-interacting", "start": 22, "end": 34, "i_start": 5, "i_end": 6}}, {"character": {"text": "gas", "start": 40, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "transition", "start": 82, "end": 92, "i_start": 16, "i_end": 16}}], "id": 1359}, {"sent": "the fact that the right-handed neutrino is physically separated in the bulk from the source of lepton number violation means that the lepton number symmetry is preserved at low energies .", "tokens": ["the", "fact", "that", "the", "right", "-", "handed", "neutrino", "is", "physically", "separated", "in", "the", "bulk", "from", "the", "source", "of", "lepton", "number", "violation", "means", "that", "the", "lepton", "number", "symmetry", "is", "preserved", "at", "low", "energies", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the fact that the right-handed neutrino is physically separated in the bulk from the source of lepton number violation", "start": 0, "end": 118, "i_start": 0, "i_end": 20}, "verb": {"text": "means", "start": 119, "end": 124, "i_start": 21, "i_end": 21}}, {"subject": {"text": "the lepton number symmetry", "start": 130, "end": 156, "i_start": 23, "i_end": 26}, "verb": {"text": "preserved", "start": 160, "end": 169, "i_start": 28, "i_end": 28}}, {"character": {"text": "source", "start": 85, "end": 91, "i_start": 16, "i_end": 16}, "action": {"text": "violation", "start": 109, "end": 118, "i_start": 20, "i_end": 20}}], "id": 1360}, {"sent": "in recent years , convolutional neural networks has achieved remarkable results in a wide range of computer vision applications .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "has", "achieved", "remarkable", "results", "in", "a", "wide", "range", "of", "computer", "vision", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "has achieved", "start": 48, "end": 60, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 52, "end": 60, "i_start": 8, "i_end": 8}}], "id": 1361}, {"sent": "in addition , shrikumar et al proposed approximated influence functions to understand the influence of any training data on the model .", "tokens": ["in", "addition", ",", "shrikumar", "et", "al", "proposed", "approximated", "influence", "functions", "to", "understand", "the", "influence", "of", "any", "training", "data", "on", "the", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "shrikumar et al", "start": 14, "end": 29, "i_start": 3, "i_end": 5}, "verb": {"text": "proposed", "start": 30, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "shrikumar", "start": 14, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "proposed", "start": 30, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "shrikumar", "start": 14, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "approximated", "start": 39, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "data", "start": 116, "end": 120, "i_start": 17, "i_end": 17}, "action": {"text": "influence", "start": 90, "end": 99, "i_start": 13, "i_end": 13}}], "id": 1362}, {"sent": "assuming that filters in later layers of a cnn are responsive to object parts and other high-level features , the feature space gcn captures correlations between more abstract features in the image like object parts .", "tokens": ["assuming", "that", "filters", "in", "later", "layers", "of", "a", "cnn", "are", "responsive", "to", "object", "parts", "and", "other", "high", "-", "level", "features", ",", "the", "feature", "space", "gcn", "captures", "correlations", "between", "more", "abstract", "features", "in", "the", "image", "like", "object", "parts", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the feature space gcn", "start": 110, "end": 131, "i_start": 21, "i_end": 24}, "verb": {"text": "captures", "start": 132, "end": 140, "i_start": 25, "i_end": 25}}], "id": 1363}, {"sent": "in particular , convolutional neural networks have been very successful for image classification .", "tokens": ["in", "particular", ",", "convolutional", "neural", "networks", "have", "been", "very", "successful", "for", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "have been", "start": 46, "end": 55, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "successful", "start": 61, "end": 71, "i_start": 9, "i_end": 9}}], "id": 1364}, {"sent": "we also extend the standard relational algebra to operate on extended generalized disjunctive paraconsistent relations .", "tokens": ["we", "also", "extend", "the", "standard", "relational", "algebra", "to", "operate", "on", "extended", "generalized", "disjunctive", "paraconsistent", "relations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "extend", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extend", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "operate", "start": 50, "end": 57, "i_start": 8, "i_end": 8}}], "id": 1365}, {"sent": "on the irreducibility of locally analytic principal series representations .", "tokens": ["on", "the", "irreducibility", "of", "locally", "analytic", "principal", "series", "representations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "series", "start": 52, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "representations", "start": 59, "end": 74, "i_start": 8, "i_end": 8}}], "id": 1366}, {"sent": "note that branes with both electric and magnetic charges may exist in any space-time with electric and magnetic branes having different dimensions , branes within branes of the type of ref .", "tokens": ["note", "that", "branes", "with", "both", "electric", "and", "magnetic", "charges", "may", "exist", "in", "any", "space", "-", "time", "with", "electric", "and", "magnetic", "branes", "having", "different", "dimensions", ",", "branes", "within", "branes", "of", "the", "type", "of", "ref", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "branes with both electric and magnetic charges", "start": 10, "end": 56, "i_start": 2, "i_end": 8}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "branes with both electric and magnetic charges", "start": 10, "end": 56, "i_start": 2, "i_end": 8}, "verb": {"text": "exist", "start": 61, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "branes", "start": 112, "end": 118, "i_start": 20, "i_end": 20}, "action": {"text": "having", "start": 119, "end": 125, "i_start": 21, "i_end": 21}}, {"character": {"text": "electric", "start": 27, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "having", "start": 119, "end": 125, "i_start": 21, "i_end": 21}}, {"character": {"text": "branes", "start": 149, "end": 155, "i_start": 25, "i_end": 25}, "action": {"text": "having", "start": 119, "end": 125, "i_start": 21, "i_end": 21}}, {"character": {"text": "magnetic", "start": 40, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "having", "start": 119, "end": 125, "i_start": 21, "i_end": 21}}], "id": 1367}, {"sent": "machine learning models , such as deep neural networks , have been remarkably successful in performing many tasks .", "tokens": ["machine", "learning", "models", ",", "such", "as", "deep", "neural", "networks", ",", "have", "been", "remarkably", "successful", "in", "performing", "many", "tasks", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "machine learning models", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 57, "end": 66, "i_start": 10, "i_end": 11}}, {"character": {"text": "models", "start": 17, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 78, "end": 88, "i_start": 13, "i_end": 13}}, {"character": {"text": "models", "start": 17, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "learning", "start": 8, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "models", "start": 17, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "performing", "start": 92, "end": 102, "i_start": 15, "i_end": 15}}], "id": 1368}, {"sent": "the energy to materialize and accelerate the pair comes from the positive cosmological constant .", "tokens": ["the", "energy", "to", "materialize", "and", "accelerate", "the", "pair", "comes", "from", "the", "positive", "cosmological", "constant", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the energy to materialize and accelerate the pair", "start": 0, "end": 49, "i_start": 0, "i_end": 7}, "verb": {"text": "comes", "start": 50, "end": 55, "i_start": 8, "i_end": 8}}], "id": 1369}, {"sent": "in the next section , we will apply the symplectic gauge-invariant formalism in some second class constrained hamiltonian systems .", "tokens": ["in", "the", "next", "section", ",", "we", "will", "apply", "the", "symplectic", "gauge", "-", "invariant", "formalism", "in", "some", "second", "class", "constrained", "hamiltonian", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 22, "end": 24, "i_start": 5, "i_end": 5}, "verb": {"text": "will apply", "start": 25, "end": 35, "i_start": 6, "i_end": 7}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 5, "i_end": 5}, "action": {"text": "apply", "start": 30, "end": 35, "i_start": 7, "i_end": 7}}], "id": 1370}, {"sent": "the calculations were performed using first-principles density functional theory as implemented in the vienna ab initio simulation package .", "tokens": ["the", "calculations", "were", "performed", "using", "first", "-", "principles", "density", "functional", "theory", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the calculations", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were performed", "start": 17, "end": 31, "i_start": 2, "i_end": 3}}], "id": 1371}, {"sent": "it suffices to verify that it is a bijection .", "tokens": ["it", "suffices", "to", "verify", "that", "it", "is", "a", "bijection", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "suffices", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "verify", "start": 15, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "suffices", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 1372}, {"sent": "recently , deep convolutional neural networks have been an important tool that achieves state-of-the-art performances in many computer vision tasks .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "been", "an", "important", "tool", "that", "achieves", "state", "-", "of", "-", "the", "-", "art", "performances", "in", "many", "computer", "vision", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have been", "start": 46, "end": 55, "i_start": 6, "i_end": 7}}, {"character": {"text": "tool", "start": 69, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "achieves", "start": 79, "end": 87, "i_start": 12, "i_end": 12}}], "id": 1373}, {"sent": "introduces the convolution operation onto graph , and proposes the multi-layer graph convolution network .", "tokens": ["introduces", "the", "convolution", "operation", "onto", "graph", ",", "and", "proposes", "the", "multi", "-", "layer", "graph", "convolution", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1374}, {"sent": "the feature extraction network is composed of a fully convolutional resnet-18 architecture .", "tokens": ["the", "feature", "extraction", "network", "is", "composed", "of", "a", "fully", "convolutional", "resnet-18", "architecture", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the feature extraction network", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "is composed", "start": 31, "end": 42, "i_start": 4, "i_end": 5}}], "id": 1375}, {"sent": "for example , synergies can be used in the planning or control algorithms for fully-actuated hands .", "tokens": ["for", "example", ",", "synergies", "can", "be", "used", "in", "the", "planning", "or", "control", "algorithms", "for", "fully", "-", "actuated", "hands", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "synergies", "start": 14, "end": 23, "i_start": 3, "i_end": 3}, "verb": {"text": "can be used", "start": 24, "end": 35, "i_start": 4, "i_end": 6}}, {"subject": {"text": "synergies", "start": 14, "end": 23, "i_start": 3, "i_end": 3}, "verb": {"text": "control", "start": 55, "end": 62, "i_start": 11, "i_end": 11}}], "id": 1376}, {"sent": "generative adversial networks are a popular tool for learning data distributions .", "tokens": ["generative", "adversial", "networks", "are", "a", "popular", "tool", "for", "learning", "data", "distributions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversial networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 3, "i_end": 3}}], "id": 1377}, {"sent": "for this very simple strategy of x , but also for all other possible strategies total cooperation always leads to the maximum reward .", "tokens": ["for", "this", "very", "simple", "strategy", "of", "x", ",", "but", "also", "for", "all", "other", "possible", "strategies", "total", "cooperation", "always", "leads", "to", "the", "maximum", "reward", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "total cooperation", "start": 80, "end": 97, "i_start": 15, "i_end": 16}, "verb": {"text": "leads", "start": 105, "end": 110, "i_start": 18, "i_end": 18}}, {"character": {"text": "cooperation", "start": 86, "end": 97, "i_start": 16, "i_end": 16}, "action": {"text": "leads", "start": 105, "end": 110, "i_start": 18, "i_end": 18}}], "id": 1378}, {"sent": "the off diagonal matrix elements of observables in these coherent states are computed and shown to vanish in the long wave length limit .", "tokens": ["the", "off", "diagonal", "matrix", "elements", "of", "observables", "in", "these", "coherent", "states", "are", "computed", "and", "shown", "to", "vanish", "in", "the", "long", "wave", "length", "limit", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the off diagonal matrix elements of observables in these coherent states", "start": 0, "end": 72, "i_start": 0, "i_end": 10}, "verb": {"text": "are computed", "start": 73, "end": 85, "i_start": 11, "i_end": 12}}, {"subject": {"text": "the off diagonal matrix elements of observables in these coherent states", "start": 0, "end": 72, "i_start": 0, "i_end": 10}, "verb": {"text": "shown", "start": 90, "end": 95, "i_start": 14, "i_end": 14}}], "id": 1379}, {"sent": "we extend the variational autoencoder , to account for partial observations .", "tokens": ["we", "extend", "the", "variational", "autoencoder", ",", "to", "account", "for", "partial", "observations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "extend", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extend", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "autoencoder", "start": 26, "end": 37, "i_start": 4, "i_end": 4}, "action": {"text": "account", "start": 43, "end": 50, "i_start": 7, "i_end": 7}}], "id": 1380}, {"sent": "a further refinement consists of the ideal mhd approximation for force-free magnetospheres , which leads to the so-called pulsar equation .", "tokens": ["a", "further", "refinement", "consists", "of", "the", "ideal", "mhd", "approximation", "for", "force", "-", "free", "magnetospheres", ",", "which", "leads", "to", "the", "so", "-", "called", "pulsar", "equation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a further refinement", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 21, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "approximation", "start": 47, "end": 60, "i_start": 8, "i_end": 8}, "action": {"text": "leads", "start": 99, "end": 104, "i_start": 16, "i_end": 16}}], "id": 1381}, {"sent": "the correlation function above is derived under the assumption that , over the bandwidth of the signal , the spectral density of the noise can be considered constant .", "tokens": ["the", "correlation", "function", "above", "is", "derived", "under", "the", "assumption", "that", ",", "over", "the", "bandwidth", "of", "the", "signal", ",", "the", "spectral", "density", "of", "the", "noise", "can", "be", "considered", "constant", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the correlation function above", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "is derived", "start": 31, "end": 41, "i_start": 4, "i_end": 5}}], "id": 1382}, {"sent": "at the planck scale , however , there is a precise and very specific replacement .", "tokens": ["at", "the", "planck", "scale", ",", "however", ",", "there", "is", "a", "precise", "and", "very", "specific", "replacement", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 32, "end": 37, "i_start": 7, "i_end": 7}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 8, "i_end": 8}}], "id": 1383}, {"sent": "some of these methods have been denoted iterative quadratic maximum likelihood , originally developed for filter design .", "tokens": ["some", "of", "these", "methods", "have", "been", "denoted", "iterative", "quadratic", "maximum", "likelihood", ",", "originally", "developed", "for", "filter", "design", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "some of these methods", "start": 0, "end": 21, "i_start": 0, "i_end": 3}, "verb": {"text": "have been denoted", "start": 22, "end": 39, "i_start": 4, "i_end": 6}}], "id": 1384}, {"sent": "zhou et al propose a cnn to predict appearance flow that can be used to transfer information from input views to synthesize a new view .", "tokens": ["zhou", "et", "al", "propose", "a", "cnn", "to", "predict", "appearance", "flow", "that", "can", "be", "used", "to", "transfer", "information", "from", "input", "views", "to", "synthesize", "a", "new", "view", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 5, "end": 10, "i_start": 1, "i_end": 2}, "verb": {"text": "propose", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhou", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}], "id": 1385}, {"sent": "whereas , weaker gradients result in later onset of the saturation , and in turn , higher saturation levels .", "tokens": ["whereas", ",", "weaker", "gradients", "result", "in", "later", "onset", "of", "the", "saturation", ",", "and", "in", "turn", ",", "higher", "saturation", "levels", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "weaker gradients", "start": 10, "end": 26, "i_start": 2, "i_end": 3}, "verb": {"text": "result", "start": 27, "end": 33, "i_start": 4, "i_end": 4}}], "id": 1386}, {"sent": "the extended kalman filter and unscented kalman filter are nonlinear extensions of the standard linear kalman filter , and are well established in this setting .", "tokens": ["the", "extended", "kalman", "filter", "and", "unscented", "kalman", "filter", "are", "nonlinear", "extensions", "of", "the", "standard", "linear", "kalman", "filter", ",", "and", "are", "well", "established", "in", "this", "setting", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the extended kalman filter and unscented kalman filter", "start": 0, "end": 54, "i_start": 0, "i_end": 7}, "verb": {"text": "are", "start": 55, "end": 58, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the extended kalman filter and unscented kalman filter", "start": 0, "end": 54, "i_start": 0, "i_end": 7}, "verb": {"text": "established", "start": 132, "end": 143, "i_start": 21, "i_end": 21}}], "id": 1387}, {"sent": "it appears that the derived a posteriori bounds and the respective adaptive algorithms can be modified in a straightforward fashion to the original dg method of baker .", "tokens": ["it", "appears", "that", "the", "derived", "a", "posteriori", "bounds", "and", "the", "respective", "adaptive", "algorithms", "can", "be", "modified", "in", "a", "straightforward", "fashion", "to", "the", "original", "dg", "method", "of", "baker", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "appears", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the", "start": 16, "end": 19, "i_start": 3, "i_end": 3}, "verb": {"text": "derived", "start": 20, "end": 27, "i_start": 4, "i_end": 4}}, {"subject": {"text": "a posteriori bounds and the respective adaptive algorithms", "start": 28, "end": 86, "i_start": 5, "i_end": 12}, "verb": {"text": "modified", "start": 94, "end": 102, "i_start": 15, "i_end": 15}}, {"character": {"text": "algorithms", "start": 76, "end": 86, "i_start": 12, "i_end": 12}, "action": {"text": "adaptive", "start": 67, "end": 75, "i_start": 11, "i_end": 11}}], "id": 1388}, {"sent": "the following notation will prove useful in appendix b .", "tokens": ["the", "following", "notation", "will", "prove", "useful", "in", "appendix", "b", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the following notation", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "will prove", "start": 23, "end": 33, "i_start": 3, "i_end": 4}}], "id": 1389}, {"sent": "the exponential factor is the same as for the interaction with the surface .", "tokens": ["the", "exponential", "factor", "is", "the", "same", "as", "for", "the", "interaction", "with", "the", "surface", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exponential factor", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}], "id": 1390}, {"sent": "differential privacy aims at protecting data privacy when performing statistical queries .", "tokens": ["differential", "privacy", "aims", "at", "protecting", "data", "privacy", "when", "performing", "statistical", "queries", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "differential privacy", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "aims", "start": 21, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "privacy", "start": 13, "end": 20, "i_start": 1, "i_end": 1}, "action": {"text": "aims", "start": 21, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "privacy", "start": 13, "end": 20, "i_start": 1, "i_end": 1}, "action": {"text": "protecting", "start": 29, "end": 39, "i_start": 4, "i_end": 4}}], "id": 1391}, {"sent": "both on the academic and industrial level , krylov subspace methods are well-known as efficient solution methods for large scale linear systems in high-performance computing .", "tokens": ["both", "on", "the", "academic", "and", "industrial", "level", ",", "krylov", "subspace", "methods", "are", "well", "-", "known", "as", "efficient", "solution", "methods", "for", "large", "scale", "linear", "systems", "in", "high", "-", "performance", "computing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "krylov subspace methods", "start": 44, "end": 67, "i_start": 8, "i_end": 10}, "verb": {"text": "are", "start": 68, "end": 71, "i_start": 11, "i_end": 11}}], "id": 1392}, {"sent": "the reader is referred to for a discussion on the role of these parameters .", "tokens": ["the", "reader", "is", "referred", "to", "for", "a", "discussion", "on", "the", "role", "of", "these", "parameters", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the reader", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is referred", "start": 11, "end": 22, "i_start": 2, "i_end": 3}}], "id": 1393}, {"sent": "nevertheless , the fact that the phenomenological theory could provide an accurate approximation has been evidenced in the isotropic cosmology .", "tokens": ["nevertheless", ",", "the", "fact", "that", "the", "phenomenological", "theory", "could", "provide", "an", "accurate", "approximation", "has", "been", "evidenced", "in", "the", "isotropic", "cosmology", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the fact that the phenomenological theory could provide an accurate approximation", "start": 15, "end": 96, "i_start": 2, "i_end": 12}, "verb": {"text": "has been evidenced", "start": 97, "end": 115, "i_start": 13, "i_end": 15}}, {"character": {"text": "theory", "start": 50, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "provide", "start": 63, "end": 70, "i_start": 9, "i_end": 9}}], "id": 1394}, {"sent": "the expectation-maximization algorithm is one of the most widely used heuristics for maximizing likelihood in statistical models with latent variables .", "tokens": ["the", "expectation", "-", "maximization", "algorithm", "is", "one", "of", "the", "most", "widely", "used", "heuristics", "for", "maximizing", "likelihood", "in", "statistical", "models", "with", "latent", "variables", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the expectation-maximization algorithm", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 5, "i_end": 5}}], "id": 1395}, {"sent": "in particular , every such graph has an unfriendly partition .", "tokens": ["in", "particular", ",", "every", "such", "graph", "has", "an", "unfriendly", "partition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "every such graph", "start": 16, "end": 32, "i_start": 3, "i_end": 5}, "verb": {"text": "has", "start": 33, "end": 36, "i_start": 6, "i_end": 6}}], "id": 1396}, {"sent": "convolutional neural networks are a powerful and versatile tool in big data analysis and computer vision .", "tokens": ["convolutional", "neural", "networks", "are", "a", "powerful", "and", "versatile", "tool", "in", "big", "data", "analysis", "and", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 3, "i_end": 3}}], "id": 1397}, {"sent": "recently , deep neural network based methods have lead to breakthroughs in several vision tasks , such as classification .", "tokens": ["recently", ",", "deep", "neural", "network", "based", "methods", "have", "lead", "to", "breakthroughs", "in", "several", "vision", "tasks", ",", "such", "as", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural network based methods", "start": 11, "end": 44, "i_start": 2, "i_end": 6}, "verb": {"text": "have lead", "start": 45, "end": 54, "i_start": 7, "i_end": 8}}, {"character": {"text": "methods", "start": 37, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "lead", "start": 50, "end": 54, "i_start": 8, "i_end": 8}}], "id": 1398}, {"sent": "on the cub and sun dataset , we use a pre-trained vgg model to extract visual features .", "tokens": ["on", "the", "cub", "and", "sun", "dataset", ",", "we", "use", "a", "pre", "-", "trained", "vgg", "model", "to", "extract", "visual", "features", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 29, "end": 31, "i_start": 7, "i_end": 7}, "verb": {"text": "use", "start": 32, "end": 35, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 7, "i_end": 7}, "action": {"text": "use", "start": 32, "end": 35, "i_start": 8, "i_end": 8}}, {"character": {"text": "model", "start": 54, "end": 59, "i_start": 14, "i_end": 14}, "action": {"text": "extract", "start": 63, "end": 70, "i_start": 16, "i_end": 16}}], "id": 1399}, {"sent": "this extends the result presented in about synchronous failure-free systems , to failure-prone asynchronous systems .", "tokens": ["this", "extends", "the", "result", "presented", "in", "about", "synchronous", "failure", "-", "free", "systems", ",", "to", "failure", "-", "prone", "asynchronous", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "extends", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "extends", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}], "id": 1400}, {"sent": "note how this simple estimate matches the oscillations of the actual degree distribution accurately .", "tokens": ["note", "how", "this", "simple", "estimate", "matches", "the", "oscillations", "of", "the", "actual", "degree", "distribution", "accurately", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this simple estimate", "start": 9, "end": 29, "i_start": 2, "i_end": 4}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "this simple estimate", "start": 9, "end": 29, "i_start": 2, "i_end": 4}, "verb": {"text": "matches", "start": 30, "end": 37, "i_start": 5, "i_end": 5}}], "id": 1401}, {"sent": "to handle the cf-based mdp with continuous state space , we propose a qnetwork learning method based on dqn , which is essentially q-learning with function approximation .", "tokens": ["to", "handle", "the", "cf", "-", "based", "mdp", "with", "continuous", "state", "space", ",", "we", "propose", "a", "qnetwork", "learning", "method", "based", "on", "dqn", ",", "which", "is", "essentially", "q", "-", "learning", "with", "function", "approximation", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 57, "end": 59, "i_start": 12, "i_end": 12}, "verb": {"text": "propose", "start": 60, "end": 67, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 57, "end": 59, "i_start": 12, "i_end": 12}, "action": {"text": "propose", "start": 60, "end": 67, "i_start": 13, "i_end": 13}}], "id": 1402}, {"sent": "deep neural networks have recently been achieved breakthroughs in several domains such as computer vision .", "tokens": ["deep", "neural", "networks", "have", "recently", "been", "achieved", "breakthroughs", "in", "several", "domains", "such", "as", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "been achieved", "start": 35, "end": 48, "i_start": 5, "i_end": 6}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "breakthroughs", "start": 49, "end": 62, "i_start": 7, "i_end": 7}}], "id": 1403}, {"sent": "sardanashvily , action-angle coordinates for time dependent completely integrable hamiltonian systems , j .", "tokens": ["sardanashvily", ",", "action", "-", "angle", "coordinates", "for", "time", "dependent", "completely", "integrable", "hamiltonian", "systems", ",", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "coordinates", "start": 29, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "dependent", "start": 50, "end": 59, "i_start": 8, "i_end": 8}}], "id": 1404}, {"sent": "convolutional neural networks have achieved superior performance in many visual tasks , such as object classification and detection .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "classification", "and", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 6, "i_end": 6}}], "id": 1405}, {"sent": "the superscripts d and s denote strangeness conserving and strangeness changing amplitudes , respectively .", "tokens": ["the", "superscripts", "d", "and", "s", "denote", "strangeness", "conserving", "and", "strangeness", "changing", "amplitudes", ",", "respectively", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "superscripts", "start": 4, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 25, "end": 31, "i_start": 5, "i_end": 5}}], "id": 1406}, {"sent": "convolutional neural networks have achieved state-of-the-art performance on visual tasks such as image and video recognition in the last few years .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "visual", "tasks", "such", "as", "image", "and", "video", "recognition", "in", "the", "last", "few", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 61, "end": 72, "i_start": 12, "i_end": 12}}], "id": 1407}, {"sent": "c ompressed sensing is a new data acquisition technique that has attracted much attention over the past decade .", "tokens": ["c", "ompressed", "sensing", "is", "a", "new", "data", "acquisition", "technique", "that", "has", "attracted", "much", "attention", "over", "the", "past", "decade", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "c ompressed sensing", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "technique", "start": 46, "end": 55, "i_start": 8, "i_end": 8}, "action": {"text": "attracted", "start": 65, "end": 74, "i_start": 11, "i_end": 11}}], "id": 1408}, {"sent": "cosmic strings are topological defects that arise during phase transitions in the early universe , and are also predicted in some models of inflation .", "tokens": ["cosmic", "strings", "are", "topological", "defects", "that", "arise", "during", "phase", "transitions", "in", "the", "early", "universe", ",", "and", "are", "also", "predicted", "in", "some", "models", "of", "inflation", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}, {"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "predicted", "start": 112, "end": 121, "i_start": 18, "i_end": 18}}, {"character": {"text": "models", "start": 130, "end": 136, "i_start": 21, "i_end": 21}, "action": {"text": "predicted", "start": 112, "end": 121, "i_start": 18, "i_end": 18}}], "id": 1409}, {"sent": "also , the space k is a minimal space with these properties in the sense that each metrizable non-locally compact space contains a closed copy of k .", "tokens": ["also", ",", "the", "space", "k", "is", "a", "minimal", "space", "with", "these", "properties", "in", "the", "sense", "that", "each", "metrizable", "non", "-", "locally", "compact", "space", "contains", "a", "closed", "copy", "of", "k", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "space", "start": 114, "end": 119, "i_start": 22, "i_end": 22}, "action": {"text": "contains", "start": 120, "end": 128, "i_start": 23, "i_end": 23}}], "id": 1410}, {"sent": "we now turn to the results from chiral perturbation theory relevant to our determination of weak matrix elements .", "tokens": ["we", "now", "turn", "to", "the", "results", "from", "chiral", "perturbation", "theory", "relevant", "to", "our", "determination", "of", "weak", "matrix", "elements", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "turn", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "turn", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "determination", "start": 75, "end": 88, "i_start": 13, "i_end": 13}}], "id": 1411}, {"sent": "the exchange and correlation effects are treated using the generalized gradient approximation .", "tokens": ["the", "exchange", "and", "correlation", "effects", "are", "treated", "using", "the", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange and correlation effects", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "are treated", "start": 37, "end": 48, "i_start": 5, "i_end": 6}}], "id": 1412}, {"sent": "its phase space is a cylinder to a mixed regime with a large chaotic domain .", "tokens": ["its", "phase", "space", "is", "a", "cylinder", "to", "a", "mixed", "regime", "with", "a", "large", "chaotic", "domain", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "its phase space", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 1413}, {"sent": "the second step comprises of solving iteratively the two-dimensional problems by using data received from other two-dimensional problems .", "tokens": ["the", "second", "step", "comprises", "of", "solving", "iteratively", "the", "two", "-", "dimensional", "problems", "by", "using", "data", "received", "from", "other", "two", "-", "dimensional", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the second step", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "comprises", "start": 16, "end": 25, "i_start": 3, "i_end": 3}}], "id": 1414}, {"sent": "neural networks have been applied to solving problems in several application domains such as computer vision , natural language processing , and disease diagnosis .", "tokens": ["neural", "networks", "have", "been", "applied", "to", "solving", "problems", "in", "several", "application", "domains", "such", "as", "computer", "vision", ",", "natural", "language", "processing", ",", "and", "disease", "diagnosis", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have been applied", "start": 16, "end": 33, "i_start": 2, "i_end": 4}}], "id": 1415}, {"sent": "deep neural networks have significantly improved the performance of diverse data mining and computer vision applications .", "tokens": ["deep", "neural", "networks", "have", "significantly", "improved", "the", "performance", "of", "diverse", "data", "mining", "and", "computer", "vision", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "applications", "start": 108, "end": 120, "i_start": 15, "i_end": 15}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 7, "i_end": 7}}, {"character": {"text": "diverse", "start": 68, "end": 75, "i_start": 9, "i_end": 9}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 7, "i_end": 7}}], "id": 1416}, {"sent": "we build upon the grouped gaussian process approach of , where groups of latent functions may covary arbitrarily with a separable kernel structure .", "tokens": ["we", "build", "upon", "the", "grouped", "gaussian", "process", "approach", "of", ",", "where", "groups", "of", "latent", "functions", "may", "covary", "arbitrarily", "with", "a", "separable", "kernel", "structure", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "build", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "build", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 1417}, {"sent": "overlaid is the pure naturally weighted merlin map showing the core of ngc 1052 with sub-arcsecond resolution .", "tokens": ["overlaid", "is", "the", "pure", "naturally", "weighted", "merlin", "map", "showing", "the", "core", "of", "ngc", "1052", "with", "sub", "-", "arcsecond", "resolution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "overlaid", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "map", "start": 47, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "showing", "start": 51, "end": 58, "i_start": 8, "i_end": 8}}], "id": 1418}, {"sent": "moreover , all known de sitter critical points develop some instability in the scalar spectrum .", "tokens": ["moreover", ",", "all", "known", "de", "sitter", "critical", "points", "develop", "some", "instability", "in", "the", "scalar", "spectrum", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "all known de sitter critical points", "start": 11, "end": 46, "i_start": 2, "i_end": 7}, "verb": {"text": "develop", "start": 47, "end": 54, "i_start": 8, "i_end": 8}}, {"character": {"text": "points", "start": 40, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "develop", "start": 47, "end": 54, "i_start": 8, "i_end": 8}}], "id": 1419}, {"sent": "the most plausible explanation for this is the excitation of a nonradial mode by resonance with the main period of oscillation .", "tokens": ["the", "most", "plausible", "explanation", "for", "this", "is", "the", "excitation", "of", "a", "nonradial", "mode", "by", "resonance", "with", "the", "main", "period", "of", "oscillation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most plausible explanation for this", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 40, "end": 42, "i_start": 6, "i_end": 6}}], "id": 1420}, {"sent": "in this section , we describe the k-hyperline clustering , a 1-d subspace clustering procedure proposed in , which forms a building block of the proposed dictionary learning algorithm .", "tokens": ["in", "this", "section", ",", "we", "describe", "the", "k", "-", "hyperline", "clustering", ",", "a", "1", "-", "d", "subspace", "clustering", "procedure", "proposed", "in", ",", "which", "forms", "a", "building", "block", "of", "the", "proposed", "dictionary", "learning", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "describe", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "describe", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "clustering", "start": 46, "end": 56, "i_start": 10, "i_end": 10}, "action": {"text": "forms", "start": 115, "end": 120, "i_start": 23, "i_end": 23}}], "id": 1421}, {"sent": "we utilize the binary crossentropy as the loss function and the adam optimization algorithm .", "tokens": ["we", "utilize", "the", "binary", "crossentropy", "as", "the", "loss", "function", "and", "the", "adam", "optimization", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "utilize", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "utilize", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 1422}, {"sent": "the most robust methods for detecting objects are currently deep neural networks for object-detection such as r-cnns .", "tokens": ["the", "most", "robust", "methods", "for", "detecting", "objects", "are", "currently", "deep", "neural", "networks", "for", "object", "-", "detection", "such", "as", "r", "-", "cnns", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most robust methods for detecting objects", "start": 0, "end": 45, "i_start": 0, "i_end": 6}, "verb": {"text": "are", "start": 46, "end": 49, "i_start": 7, "i_end": 7}}], "id": 1423}, {"sent": "as in we take a metropolis-hastings mcmc approach , and refer the reader to robert and casella for technical background .", "tokens": ["as", "in", "we", "take", "a", "metropolis", "-", "hastings", "mcmc", "approach", ",", "and", "refer", "the", "reader", "to", "robert", "and", "casella", "for", "technical", "background", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "verb": {"text": "take", "start": 9, "end": 13, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "verb": {"text": "refer", "start": 56, "end": 61, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "approach", "start": 41, "end": 49, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "refer", "start": 56, "end": 61, "i_start": 12, "i_end": 12}}], "id": 1424}, {"sent": "neural machine translation based on an encoder-decoder framework has obtained state-of-theart performances on many language pairs .", "tokens": ["neural", "machine", "translation", "based", "on", "an", "encoder", "-", "decoder", "framework", "has", "obtained", "state", "-", "of", "-", "theart", "performances", "on", "many", "language", "pairs", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "neural machine translation based on an encoder-decoder framework", "start": 0, "end": 64, "i_start": 0, "i_end": 9}, "verb": {"text": "has obtained", "start": 65, "end": 77, "i_start": 10, "i_end": 11}}, {"character": {"text": "translation", "start": 15, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "obtained", "start": 69, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "framework", "start": 55, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "decoder", "start": 47, "end": 54, "i_start": 8, "i_end": 8}}], "id": 1425}, {"sent": "for a nonlinear and bounded process such as wind generation , probability distributions of future wind power for instance may be skewed and heavy-tailed distributions .", "tokens": ["for", "a", "nonlinear", "and", "bounded", "process", "such", "as", "wind", "generation", ",", "probability", "distributions", "of", "future", "wind", "power", "for", "instance", "may", "be", "skewed", "and", "heavy", "-", "tailed", "distributions", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1426}, {"sent": "in recent years , deep convolutional neural networks have been widely used in a variety of computer vision tasks and have achieved unprecedented progress .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "been", "widely", "used", "in", "a", "variety", "of", "computer", "vision", "tasks", "and", "have", "achieved", "unprecedented", "progress", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "used", "start": 70, "end": 74, "i_start": 11, "i_end": 11}}, {"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have been", "start": 53, "end": 62, "i_start": 8, "i_end": 9}}, {"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "achieved", "start": 122, "end": 130, "i_start": 21, "i_end": 21}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 122, "end": 130, "i_start": 21, "i_end": 21}}], "id": 1427}, {"sent": "cosmic strings are line-like topological defects which m a y form during phase transitions in the early universe .", "tokens": ["cosmic", "strings", "are", "line", "-", "like", "topological", "defects", "which", "m", "a", "y", "form", "during", "phase", "transitions", "in", "the", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}], "id": 1428}, {"sent": "thus , our architecture naturally supports methods of organization that emphasize incentives for high availability , such as mutual storage contracts , .", "tokens": ["thus", ",", "our", "architecture", "naturally", "supports", "methods", "of", "organization", "that", "emphasize", "incentives", "for", "high", "availability", ",", "such", "as", "mutual", "storage", "contracts", ",", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our architecture", "start": 7, "end": 23, "i_start": 2, "i_end": 3}, "verb": {"text": "supports", "start": 34, "end": 42, "i_start": 5, "i_end": 5}}, {"character": {"text": "architecture", "start": 11, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "supports", "start": 34, "end": 42, "i_start": 5, "i_end": 5}}, {"character": {"text": "methods", "start": 43, "end": 50, "i_start": 6, "i_end": 6}, "action": {"text": "emphasize", "start": 72, "end": 81, "i_start": 10, "i_end": 10}}], "id": 1429}, {"sent": "bruce , universality in the two-dimensional continuous spin model , j .", "tokens": ["bruce", ",", "universality", "in", "the", "two", "-", "dimensional", "continuous", "spin", "model", ",", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1430}, {"sent": "for example , we are not going to establish any strict limit on the accuracy required for a potential energy function to successfully predict the folding of proteins .", "tokens": ["for", "example", ",", "we", "are", "not", "going", "to", "establish", "any", "strict", "limit", "on", "the", "accuracy", "required", "for", "a", "potential", "energy", "function", "to", "successfully", "predict", "the", "folding", "of", "proteins", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "are not going", "start": 17, "end": 30, "i_start": 4, "i_end": 6}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "not going to establish", "start": 21, "end": 43, "i_start": 5, "i_end": 8}}, {"character": {"text": "function", "start": 109, "end": 117, "i_start": 20, "i_end": 20}, "action": {"text": "required", "start": 77, "end": 85, "i_start": 15, "i_end": 15}}, {"character": {"text": "function", "start": 109, "end": 117, "i_start": 20, "i_end": 20}, "action": {"text": "predict", "start": 134, "end": 141, "i_start": 23, "i_end": 23}}], "id": 1431}, {"sent": "the prediction is again in terms of an idealized measurement , one in which the time interval is so small that it can be neglected .", "tokens": ["the", "prediction", "is", "again", "in", "terms", "of", "an", "idealized", "measurement", ",", "one", "in", "which", "the", "time", "interval", "is", "so", "small", "that", "it", "can", "be", "neglected", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the prediction", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 1432}, {"sent": "hd 37903 hd 37903 is the only sightline for which we have hst data that meets our criterion as an outlier .", "tokens": ["hd", "37903", "hd", "37903", "is", "the", "only", "sightline", "for", "which", "we", "have", "hst", "data", "that", "meets", "our", "criterion", "as", "an", "outlier", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "hd 37903 hd 37903", "start": 0, "end": 17, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 50, "end": 52, "i_start": 10, "i_end": 10}, "action": {"text": "have", "start": 53, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "data", "start": 62, "end": 66, "i_start": 13, "i_end": 13}, "action": {"text": "meets", "start": 72, "end": 77, "i_start": 15, "i_end": 15}}], "id": 1433}, {"sent": "here we use a cnn for the cifar10 data set .", "tokens": ["here", "we", "use", "a", "cnn", "for", "the", "cifar10", "data", "set", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}], "id": 1434}, {"sent": "we use adam optimizer for all our experiments .", "tokens": ["we", "use", "adam", "optimizer", "for", "all", "our", "experiments", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "experiments", "start": 34, "end": 45, "i_start": 7, "i_end": 7}}], "id": 1435}, {"sent": "deep learning has had a tremendous impact in several fields , such as image processing and natural language processing .", "tokens": ["deep", "learning", "has", "had", "a", "tremendous", "impact", "in", "several", "fields", ",", "such", "as", "image", "processing", "and", "natural", "language", "processing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has had", "start": 14, "end": 21, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "impact", "start": 35, "end": 41, "i_start": 6, "i_end": 6}}], "id": 1436}, {"sent": "the most commonly used criteria are capacity maximization and data mean-square-error minimization .", "tokens": ["the", "most", "commonly", "used", "criteria", "are", "capacity", "maximization", "and", "data", "mean", "-", "square", "-", "error", "minimization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most commonly used criteria", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 5, "i_end": 5}}], "id": 1437}, {"sent": "deep neural networks have been very successful in large-scale recognition and classification tasks , some even surpassing human-level accuracy .", "tokens": ["deep", "neural", "networks", "have", "been", "very", "successful", "in", "large", "-", "scale", "recognition", "and", "classification", "tasks", ",", "some", "even", "surpassing", "human", "-", "level", "accuracy", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 36, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "surpassing", "start": 111, "end": 121, "i_start": 18, "i_end": 18}}], "id": 1438}, {"sent": "dft calculations based on plane-wave basis sets of 500 ev cutoff energy were performed with the vienna ab initio simulation package .", "tokens": ["dft", "calculations", "based", "on", "plane", "-", "wave", "basis", "sets", "of", "500", "ev", "cutoff", "energy", "were", "performed", "with", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "dft calculations based on plane-wave basis sets of 500 ev cutoff energy", "start": 0, "end": 71, "i_start": 0, "i_end": 13}, "verb": {"text": "were performed", "start": 72, "end": 86, "i_start": 14, "i_end": 15}}], "id": 1439}, {"sent": "the line-of-sight direction , indicated by the dashed arrow , makes and angle \u03b8los with the z- axis and an azimuthal angle \u03c6los with the x-axis .", "tokens": ["the", "line", "-", "of", "-", "sight", "direction", ",", "indicated", "by", "the", "dashed", "arrow", ",", "makes", "and", "angle", "\u03b8los", "with", "the", "z-", "axis", "and", "an", "azimuthal", "angle", "\u03c6los", "with", "the", "x", "-", "axis", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "direction", "start": 18, "end": 27, "i_start": 6, "i_end": 6}, "action": {"text": "makes", "start": 62, "end": 67, "i_start": 14, "i_end": 14}}, {"character": {"text": "arrow", "start": 54, "end": 59, "i_start": 12, "i_end": 12}, "action": {"text": "indicated", "start": 30, "end": 39, "i_start": 8, "i_end": 8}}], "id": 1440}, {"sent": "the shaded band displays the tau decay result within errors .", "tokens": ["the", "shaded", "band", "displays", "the", "tau", "decay", "result", "within", "errors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the shaded band", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "displays", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "band", "start": 11, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "displays", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}], "id": 1441}, {"sent": "as a result , almost all public face alignment databases such as afw are collected in medium poses .", "tokens": ["as", "a", "result", ",", "almost", "all", "public", "face", "alignment", "databases", "such", "as", "afw", "are", "collected", "in", "medium", "poses", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "almost all public face alignment databases such as afw", "start": 14, "end": 68, "i_start": 4, "i_end": 12}, "verb": {"text": "are collected", "start": 69, "end": 82, "i_start": 13, "i_end": 14}}], "id": 1442}, {"sent": "teleportation of quantum states are intriguing concepts within quantum physics and striking applications of quantum entanglement .", "tokens": ["teleportation", "of", "quantum", "states", "are", "intriguing", "concepts", "within", "quantum", "physics", "and", "striking", "applications", "of", "quantum", "entanglement", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "teleportation of quantum states", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "concepts", "start": 47, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "intriguing", "start": 36, "end": 46, "i_start": 5, "i_end": 5}}, {"character": {"text": "concepts", "start": 47, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "striking", "start": 83, "end": 91, "i_start": 11, "i_end": 11}}], "id": 1443}, {"sent": "most traditional cf methods are based on matrix factorization .", "tokens": ["most", "traditional", "cf", "methods", "are", "based", "on", "matrix", "factorization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "most traditional cf methods", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "are based", "start": 28, "end": 37, "i_start": 4, "i_end": 5}}], "id": 1444}, {"sent": "using this model , the authors of derive an mle for the pass rate of a path connecting the source to an internal node .", "tokens": ["using", "this", "model", ",", "the", "authors", "of", "derive", "an", "mle", "for", "the", "pass", "rate", "of", "a", "path", "connecting", "the", "source", "to", "an", "internal", "node", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the authors of", "start": 19, "end": 33, "i_start": 4, "i_end": 6}, "verb": {"text": "derive", "start": 34, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "this", "start": 6, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "derive", "start": 34, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "path", "start": 71, "end": 75, "i_start": 16, "i_end": 16}, "action": {"text": "connecting", "start": 76, "end": 86, "i_start": 17, "i_end": 17}}, {"character": {"text": "this", "start": 6, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "using", "start": 0, "end": 5, "i_start": 0, "i_end": 0}}], "id": 1445}, {"sent": "for example , the travel industry now has a well-defined , and documented , set of both services and data , sufficient to allow any competent software engineer to create travel agency software using entirely off-the-shelf software services .", "tokens": ["for", "example", ",", "the", "travel", "industry", "now", "has", "a", "well", "-", "defined", ",", "and", "documented", ",", "set", "of", "both", "services", "and", "data", ",", "sufficient", "to", "allow", "any", "competent", "software", "engineer", "to", "create", "travel", "agency", "software", "using", "entirely", "off", "-", "the", "-", "shelf", "software", "services", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the travel industry", "start": 14, "end": 33, "i_start": 3, "i_end": 5}, "verb": {"text": "has", "start": 38, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "industry", "start": 25, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "has", "start": 38, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "set", "start": 76, "end": 79, "i_start": 16, "i_end": 16}, "action": {"text": "sufficient", "start": 108, "end": 118, "i_start": 23, "i_end": 23}}, {"character": {"text": "set", "start": 76, "end": 79, "i_start": 16, "i_end": 16}, "action": {"text": "allow", "start": 122, "end": 127, "i_start": 25, "i_end": 25}}, {"character": {"text": "any", "start": 128, "end": 131, "i_start": 26, "i_end": 26}, "action": {"text": "create", "start": 163, "end": 169, "i_start": 31, "i_end": 31}}], "id": 1446}, {"sent": "cluster algebras have been introduced in a series of papers by fomin and zelevinsky .", "tokens": ["cluster", "algebras", "have", "been", "introduced", "in", "a", "series", "of", "papers", "by", "fomin", "and", "zelevinsky", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "have been introduced", "start": 17, "end": 37, "i_start": 2, "i_end": 4}}], "id": 1447}, {"sent": "spin-polarized dft calculations used the vienna ab initio simulation package within the perdew-burke-ernzerhof form of the generalized gradient approximation .", "tokens": ["spin", "-", "polarized", "dft", "calculations", "used", "the", "vienna", "ab", "initio", "simulation", "package", "within", "the", "perdew", "-", "burke", "-", "ernzerhof", "form", "of", "the", "generalized", "gradient", "approximation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "spin-polarized dft calculations", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "used", "start": 32, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "calculations", "start": 19, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "used", "start": 32, "end": 36, "i_start": 5, "i_end": 5}}], "id": 1448}, {"sent": "electronphonon interactions and recurrence phenomena in one-dimensional systems , phys .", "tokens": ["electronphonon", "interactions", "and", "recurrence", "phenomena", "in", "one", "-", "dimensional", "systems", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1449}, {"sent": "the band touching points can be monitored from the atomic fraction tunnelling to the excited band in bloch oscillations , as recently experimentally demonstrated to probe the dirac points and the topological phase transition in a honeycomb optical lattice .", "tokens": ["the", "band", "touching", "points", "can", "be", "monitored", "from", "the", "atomic", "fraction", "tunnelling", "to", "the", "excited", "band", "in", "bloch", "oscillations", ",", "as", "recently", "experimentally", "demonstrated", "to", "probe", "the", "dirac", "points", "and", "the", "topological", "phase", "transition", "in", "a", "honeycomb", "optical", "lattice", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the band touching points", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "can be monitored", "start": 25, "end": 41, "i_start": 4, "i_end": 6}}, {"character": {"text": "oscillations", "start": 107, "end": 119, "i_start": 18, "i_end": 18}, "action": {"text": "excited", "start": 85, "end": 92, "i_start": 14, "i_end": 14}}], "id": 1450}, {"sent": "these measured critical exponents are shown in table i .", "tokens": ["these", "measured", "critical", "exponents", "are", "shown", "in", "table", "i", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these measured critical exponents", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "are shown", "start": 34, "end": 43, "i_start": 4, "i_end": 5}}], "id": 1451}, {"sent": "now we state the continuous dependence result without further proof .", "tokens": ["now", "we", "state", "the", "continuous", "dependence", "result", "without", "further", "proof", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "state", "start": 7, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "state", "start": 7, "end": 12, "i_start": 2, "i_end": 2}}], "id": 1452}, {"sent": "in this approximation , sdisplays only the spw peak , though an additional broad peak due to vpws has been seen in numerous scattering experiments 14 , 88 .", "tokens": ["in", "this", "approximation", ",", "sdisplays", "only", "the", "spw", "peak", ",", "though", "an", "additional", "broad", "peak", "due", "to", "vpws", "has", "been", "seen", "in", "numerous", "scattering", "experiments", "14", ",", "88", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1453}, {"sent": "if an orbifold m is a manifold , then the above cq coincides with the group of usual q-dimensional singular chains of m .", "tokens": ["if", "an", "orbifold", "m", "is", "a", "manifold", ",", "then", "the", "above", "cq", "coincides", "with", "the", "group", "of", "usual", "q", "-", "dimensional", "singular", "chains", "of", "m", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "cq", "start": 48, "end": 50, "i_start": 11, "i_end": 11}, "verb": {"text": "coincides", "start": 51, "end": 60, "i_start": 12, "i_end": 12}}], "id": 1454}, {"sent": "the primary object we will be working with in this paper is called a wave front .", "tokens": ["the", "primary", "object", "we", "will", "be", "working", "with", "in", "this", "paper", "is", "called", "a", "wave", "front", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the primary object we will be working with in this paper", "start": 0, "end": 56, "i_start": 0, "i_end": 10}, "verb": {"text": "is called", "start": 57, "end": 66, "i_start": 11, "i_end": 12}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "working", "start": 30, "end": 37, "i_start": 6, "i_end": 6}}], "id": 1455}, {"sent": "it is noteworthy that several meta-learning approaches also introduce the attention mechanism to tackle few-shot learning problems .", "tokens": ["it", "is", "noteworthy", "that", "several", "meta", "-", "learning", "approaches", "also", "introduce", "the", "attention", "mechanism", "to", "tackle", "few", "-", "shot", "learning", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "several meta-learning approaches", "start": 22, "end": 54, "i_start": 4, "i_end": 8}, "verb": {"text": "introduce", "start": 60, "end": 69, "i_start": 10, "i_end": 10}}, {"character": {"text": "approaches", "start": 44, "end": 54, "i_start": 8, "i_end": 8}, "action": {"text": "introduce", "start": 60, "end": 69, "i_start": 10, "i_end": 10}}], "id": 1456}, {"sent": "this modification is the standard part of the cmb anisotropy and polarization spectrum calculations using cmbfast codes .", "tokens": ["this", "modification", "is", "the", "standard", "part", "of", "the", "cmb", "anisotropy", "and", "polarization", "spectrum", "calculations", "using", "cmbfast", "codes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this modification", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}], "id": 1457}, {"sent": "let us prove the statement by the induction on r .", "tokens": ["let", "us", "prove", "the", "statement", "by", "the", "induction", "on", "r", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "prove", "start": 7, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "prove", "start": 7, "end": 12, "i_start": 2, "i_end": 2}}], "id": 1458}, {"sent": "the analytical performance derivation of dcsk communication system is studied in for cooperative schemes .", "tokens": ["the", "analytical", "performance", "derivation", "of", "dcsk", "communication", "system", "is", "studied", "in", "for", "cooperative", "schemes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the analytical performance derivation of dcsk communication system", "start": 0, "end": 66, "i_start": 0, "i_end": 7}, "verb": {"text": "is studied", "start": 67, "end": 77, "i_start": 8, "i_end": 9}}], "id": 1459}, {"sent": "since the crystal is a semiconductor with direct bandgap , the elec tronic excited states are generated under photoexcitation .", "tokens": ["since", "the", "crystal", "is", "a", "semiconductor", "with", "direct", "bandgap", ",", "the", "elec", "tronic", "excited", "states", "are", "generated", "under", "photoexcitation", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the elec tronic excited states", "start": 59, "end": 89, "i_start": 10, "i_end": 14}, "verb": {"text": "are generated", "start": 90, "end": 103, "i_start": 15, "i_end": 16}}, {"character": {"text": "photoexcitation", "start": 110, "end": 125, "i_start": 18, "i_end": 18}, "action": {"text": "excited", "start": 75, "end": 82, "i_start": 13, "i_end": 13}}], "id": 1460}, {"sent": "savina , mr , davis , am , tripa , ce , pellin , mj , gallino , r .", "tokens": ["savina", ",", "mr", ",", "davis", ",", "am", ",", "tripa", ",", "ce", ",", "pellin", ",", "mj", ",", "gallino", ",", "r", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1461}, {"sent": "we use the 50-layer residual network to evaluate relay bp .", "tokens": ["we", "use", "the", "50", "-", "layer", "residual", "network", "to", "evaluate", "relay", "bp", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 40, "end": 48, "i_start": 9, "i_end": 9}}], "id": 1462}, {"sent": "therefore , the covariant oscillators , defined in the space-time region , can be enriched by the physics of entanglement .", "tokens": ["therefore", ",", "the", "covariant", "oscillators", ",", "defined", "in", "the", "space", "-", "time", "region", ",", "can", "be", "enriched", "by", "the", "physics", "of", "entanglement", "."], "score": [1, 0, 0, 0, 1], "labels": [{"subject": {"text": "the covariant oscillators", "start": 12, "end": 37, "i_start": 2, "i_end": 4}, "verb": {"text": "can be enriched", "start": 75, "end": 90, "i_start": 14, "i_end": 16}}, {"character": {"text": "physics", "start": 98, "end": 105, "i_start": 19, "i_end": 19}, "action": {"text": "enriched", "start": 82, "end": 90, "i_start": 16, "i_end": 16}}], "id": 1463}, {"sent": "the weights are initialized with the approach proposed by glorot and bengio .", "tokens": ["the", "weights", "are", "initialized", "with", "the", "approach", "proposed", "by", "glorot", "and", "bengio", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the weights", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "are initialized", "start": 12, "end": 27, "i_start": 2, "i_end": 3}}, {"character": {"text": "glorot", "start": 58, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "proposed", "start": 46, "end": 54, "i_start": 7, "i_end": 7}}, {"character": {"text": "bengio", "start": 69, "end": 75, "i_start": 11, "i_end": 11}, "action": {"text": "proposed", "start": 46, "end": 54, "i_start": 7, "i_end": 7}}], "id": 1464}, {"sent": "convolutional neural networks have recently achieved the state-of-the-art performance in many image analysis tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "achieved", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "many", "image", "analysis", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 74, "end": 85, "i_start": 14, "i_end": 14}}], "id": 1465}, {"sent": "the solid line shows the many-body effects on the bound-state energy .", "tokens": ["the", "solid", "line", "shows", "the", "many", "-", "body", "effects", "on", "the", "bound", "-", "state", "energy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the solid line", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "shows", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "line", "start": 10, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "shows", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}], "id": 1466}, {"sent": "the fitting was carried out using the projct routine in xspec .", "tokens": ["the", "fitting", "was", "carried", "out", "using", "the", "projct", "routine", "in", "xspec", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the fitting", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "was carried out", "start": 12, "end": 27, "i_start": 2, "i_end": 4}}], "id": 1467}, {"sent": "when the markov chain is a random walk on a group , some regularity of behavior can be established .", "tokens": ["when", "the", "markov", "chain", "is", "a", "random", "walk", "on", "a", "group", ",", "some", "regularity", "of", "behavior", "can", "be", "established", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "some regularity of behavior", "start": 52, "end": 79, "i_start": 12, "i_end": 15}, "verb": {"text": "can be established", "start": 80, "end": 98, "i_start": 16, "i_end": 18}}, {"character": {"text": "chain", "start": 16, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "walk", "start": 34, "end": 38, "i_start": 7, "i_end": 7}}], "id": 1468}, {"sent": "these models can be extended to produce good feature representations by training jointly with image encoders .", "tokens": ["these", "models", "can", "be", "extended", "to", "produce", "good", "feature", "representations", "by", "training", "jointly", "with", "image", "encoders", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "these models", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "can be extended", "start": 13, "end": 28, "i_start": 2, "i_end": 4}}, {"character": {"text": "models", "start": 6, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "produce", "start": 32, "end": 39, "i_start": 6, "i_end": 6}}], "id": 1469}, {"sent": "recently , deep neural networks have demonstrated impressive results in image classification .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "demonstrated", "impressive", "results", "in", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have demonstrated", "start": 32, "end": 49, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "demonstrated", "start": 37, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "results", "start": 61, "end": 68, "i_start": 8, "i_end": 8}, "action": {"text": "impressive", "start": 50, "end": 60, "i_start": 7, "i_end": 7}}], "id": 1470}, {"sent": "convolutional neural network has made great success in various computer vision tasks , such as image classification , object detection and tracking .", "tokens": ["convolutional", "neural", "network", "has", "made", "great", "success", "in", "various", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", ",", "object", "detection", "and", "tracking", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural network", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "has made", "start": 29, "end": 37, "i_start": 3, "i_end": 4}}, {"character": {"text": "network", "start": 21, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 44, "end": 51, "i_start": 6, "i_end": 6}}], "id": 1471}, {"sent": "leptogenesis is one of the most attractive scenarios to explain the origin of the observed matter-antimatter asymmetry of the universe .", "tokens": ["leptogenesis", "is", "one", "of", "the", "most", "attractive", "scenarios", "to", "explain", "the", "origin", "of", "the", "observed", "matter", "-", "antimatter", "asymmetry", "of", "the", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "leptogenesis", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "scenarios", "start": 43, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "attractive", "start": 32, "end": 42, "i_start": 6, "i_end": 6}}, {"character": {"text": "scenarios", "start": 43, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "explain", "start": 56, "end": 63, "i_start": 9, "i_end": 9}}], "id": 1472}, {"sent": "convolutional neural networks have recently been very successful on a variety of recognition and classification tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "been", "very", "successful", "on", "a", "variety", "of", "recognition", "and", "classification", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "been", "start": 44, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 54, "end": 64, "i_start": 7, "i_end": 7}}], "id": 1473}, {"sent": "neural networks have rapidly gained popularity over the last few years due to their success in a variety of tasks , such as image recognition , speech recognition and machine translation .", "tokens": ["neural", "networks", "have", "rapidly", "gained", "popularity", "over", "the", "last", "few", "years", "due", "to", "their", "success", "in", "a", "variety", "of", "tasks", ",", "such", "as", "image", "recognition", ",", "speech", "recognition", "and", "machine", "translation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "gained", "start": 29, "end": 35, "i_start": 4, "i_end": 4}}, {"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have", "start": 16, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "gained", "start": 29, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "success", "start": 84, "end": 91, "i_start": 14, "i_end": 14}}], "id": 1474}, {"sent": "we use the adam optimizer to update parameters with mini-batch size 32 .", "tokens": ["we", "use", "the", "adam", "optimizer", "to", "update", "parameters", "with", "mini", "-", "batch", "size", "32", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "update", "start": 29, "end": 35, "i_start": 6, "i_end": 6}}], "id": 1475}, {"sent": "reinforcement learning is a paradigm in which an active decision-making agent interacts with its environment and learns from reinforcement , that is , a numeric feedback in the form of reward or punishment .", "tokens": ["reinforcement", "learning", "is", "a", "paradigm", "in", "which", "an", "active", "decision", "-", "making", "agent", "interacts", "with", "its", "environment", "and", "learns", "from", "reinforcement", ",", "that", "is", ",", "a", "numeric", "feedback", "in", "the", "form", "of", "reward", "or", "punishment", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "agent", "start": 72, "end": 77, "i_start": 12, "i_end": 12}, "action": {"text": "interacts", "start": 78, "end": 87, "i_start": 13, "i_end": 13}}, {"character": {"text": "agent", "start": 72, "end": 77, "i_start": 12, "i_end": 12}, "action": {"text": "decision", "start": 56, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "agent", "start": 72, "end": 77, "i_start": 12, "i_end": 12}, "action": {"text": "active", "start": 49, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "agent", "start": 72, "end": 77, "i_start": 12, "i_end": 12}, "action": {"text": "learns", "start": 113, "end": 119, "i_start": 18, "i_end": 18}}], "id": 1476}, {"sent": "in particular , convolutional neural network architectures have enabled superior performance over alternative approaches in classification and pattern recognition problems in computer vision .", "tokens": ["in", "particular", ",", "convolutional", "neural", "network", "architectures", "have", "enabled", "superior", "performance", "over", "alternative", "approaches", "in", "classification", "and", "pattern", "recognition", "problems", "in", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural network architectures", "start": 16, "end": 58, "i_start": 3, "i_end": 6}, "verb": {"text": "have enabled", "start": 59, "end": 71, "i_start": 7, "i_end": 8}}, {"character": {"text": "architectures", "start": 45, "end": 58, "i_start": 6, "i_end": 6}, "action": {"text": "enabled", "start": 64, "end": 71, "i_start": 8, "i_end": 8}}], "id": 1477}, {"sent": "analyzing the above presented methods to choose the boundary condition , one can realize that their essence is the continuation of some approximation , which is valid on the upper half-plane , to the lower one .", "tokens": ["analyzing", "the", "above", "presented", "methods", "to", "choose", "the", "boundary", "condition", ",", "one", "can", "realize", "that", "their", "essence", "is", "the", "continuation", "of", "some", "approximation", ",", "which", "is", "valid", "on", "the", "upper", "half", "-", "plane", ",", "to", "the", "lower", "one", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "one", "start": 73, "end": 76, "i_start": 11, "i_end": 11}, "verb": {"text": "can realize", "start": 77, "end": 88, "i_start": 12, "i_end": 13}}, {"subject": {"text": "one", "start": 73, "end": 76, "i_start": 11, "i_end": 11}, "verb": {"text": "is", "start": 108, "end": 110, "i_start": 17, "i_end": 17}}, {"character": {"text": "one", "start": 73, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "realize", "start": 81, "end": 88, "i_start": 13, "i_end": 13}}, {"character": {"text": "one", "start": 73, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "analyzing", "start": 0, "end": 9, "i_start": 0, "i_end": 0}}, {"character": {"text": "one", "start": 73, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "choose", "start": 41, "end": 47, "i_start": 6, "i_end": 6}}], "id": 1478}, {"sent": "deep networks have been applied to almost all computer vision tasks and have achieved state-of-the-art performances , such as image classification .", "tokens": ["deep", "networks", "have", "been", "applied", "to", "almost", "all", "computer", "vision", "tasks", "and", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performances", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep networks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "have been applied", "start": 14, "end": 31, "i_start": 2, "i_end": 4}}, {"subject": {"text": "deep networks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "achieved", "start": 77, "end": 85, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "achieved", "start": 77, "end": 85, "i_start": 13, "i_end": 13}}], "id": 1479}, {"sent": "now , as before , we can expand the exponentials in order to give an expression in terms of the return characteristic function .", "tokens": ["now", ",", "as", "before", ",", "we", "can", "expand", "the", "exponentials", "in", "order", "to", "give", "an", "expression", "in", "terms", "of", "the", "return", "characteristic", "function", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 5, "i_end": 5}, "verb": {"text": "can expand", "start": 21, "end": 31, "i_start": 6, "i_end": 7}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 5, "i_end": 5}, "action": {"text": "expand", "start": 25, "end": 31, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 5, "i_end": 5}, "action": {"text": "expression", "start": 69, "end": 79, "i_start": 15, "i_end": 15}}], "id": 1480}, {"sent": "mbir regularized by tv was solved using an alternating direction method of multiplier .", "tokens": ["mbir", "regularized", "by", "tv", "was", "solved", "using", "an", "alternating", "direction", "method", "of", "multiplier", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "mbir regularized by tv", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "was solved", "start": 23, "end": 33, "i_start": 4, "i_end": 5}}], "id": 1481}, {"sent": "in addition , dropout is an effective way to prevent neural networks from overfitting .", "tokens": ["in", "addition", ",", "dropout", "is", "an", "effective", "way", "to", "prevent", "neural", "networks", "from", "overfitting", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dropout", "start": 14, "end": 21, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "way", "start": 38, "end": 41, "i_start": 7, "i_end": 7}, "action": {"text": "prevent", "start": 45, "end": 52, "i_start": 9, "i_end": 9}}, {"character": {"text": "way", "start": 38, "end": 41, "i_start": 7, "i_end": 7}, "action": {"text": "effective", "start": 28, "end": 37, "i_start": 6, "i_end": 6}}], "id": 1482}, {"sent": "our results are consistent across physical networks that follow waxman and barabasi-albert models .", "tokens": ["our", "results", "are", "consistent", "across", "physical", "networks", "that", "follow", "waxman", "and", "barabasi", "-", "albert", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our results", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 12, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "networks", "start": 43, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "follow", "start": 57, "end": 63, "i_start": 8, "i_end": 8}}], "id": 1483}, {"sent": "we also show that the energy-momentum tensor in this approximation is finite once we consider the usual mass and coupling constant renormalizations , without the need of further geometrical counter terms .", "tokens": ["we", "also", "show", "that", "the", "energy", "-", "momentum", "tensor", "in", "this", "approximation", "is", "finite", "once", "we", "consider", "the", "usual", "mass", "and", "coupling", "constant", "renormalizations", ",", "without", "the", "need", "of", "further", "geometrical", "counter", "terms", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 67, "end": 69, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "consider", "start": 85, "end": 93, "i_start": 16, "i_end": 16}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "coupling", "start": 113, "end": 121, "i_start": 21, "i_end": 21}}, {"character": {"text": "terms", "start": 198, "end": 203, "i_start": 32, "i_end": 32}, "action": {"text": "counter", "start": 190, "end": 197, "i_start": 31, "i_end": 31}}], "id": 1484}, {"sent": "huisken showed that if the second fundamental form is uniformly bounded , then the mean curvature flow can be extended over the time .", "tokens": ["huisken", "showed", "that", "if", "the", "second", "fundamental", "form", "is", "uniformly", "bounded", ",", "then", "the", "mean", "curvature", "flow", "can", "be", "extended", "over", "the", "time", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "huisken", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "showed", "start": 8, "end": 14, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the mean curvature flow", "start": 79, "end": 102, "i_start": 13, "i_end": 16}, "verb": {"text": "extended", "start": 110, "end": 118, "i_start": 19, "i_end": 19}}, {"character": {"text": "huisken", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 8, "end": 14, "i_start": 1, "i_end": 1}}], "id": 1485}, {"sent": "the triangulated knotted 3-sphere s 3 13,56 realized by lutz has only 13 vertices and 56 facets .", "tokens": ["the", "triangulated", "knotted", "3", "-", "sphere", "s", "3", "13,56", "realized", "by", "lutz", "has", "only", "13", "vertices", "and", "56", "facets", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the triangulated knotted 3-sphere s 3 13,56 realized by lutz", "start": 0, "end": 60, "i_start": 0, "i_end": 11}, "verb": {"text": "has", "start": 61, "end": 64, "i_start": 12, "i_end": 12}}, {"character": {"text": "3-sphere", "start": 25, "end": 33, "i_start": 3, "i_end": 5}, "action": {"text": "has", "start": 61, "end": 64, "i_start": 12, "i_end": 12}}, {"character": {"text": "lutz", "start": 56, "end": 60, "i_start": 11, "i_end": 11}, "action": {"text": "realized", "start": 44, "end": 52, "i_start": 9, "i_end": 9}}], "id": 1486}, {"sent": "in recent years , deep convolutional networks have achieved remarkable results in many computer vision tasks .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "networks", "have", "achieved", "remarkable", "results", "in", "many", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional networks", "start": 18, "end": 45, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 8, "i_end": 8}}], "id": 1487}, {"sent": "millimeter wave communication has drawn extensive attention as a promising technology for 5g cellular systems .", "tokens": ["millimeter", "wave", "communication", "has", "drawn", "extensive", "attention", "as", "a", "promising", "technology", "for", "5", "g", "cellular", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "millimeter wave communication", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "has drawn", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "communication", "start": 16, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "drawn", "start": 34, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "technology", "start": 75, "end": 85, "i_start": 10, "i_end": 10}, "action": {"text": "promising", "start": 65, "end": 74, "i_start": 9, "i_end": 9}}], "id": 1488}, {"sent": "wolenski , nonsmooth analysis and control theory .", "tokens": ["wolenski", ",", "nonsmooth", "analysis", "and", "control", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1489}, {"sent": "this time delay is the basis of an indirect imaging technique , known as echo tomography , to probe the structure of accretion flows on scales that can not be imaged directly , even with current interferometric techniques .", "tokens": ["this", "time", "delay", "is", "the", "basis", "of", "an", "indirect", "imaging", "technique", ",", "known", "as", "echo", "tomography", ",", "to", "probe", "the", "structure", "of", "accretion", "flows", "on", "scales", "that", "can", "not", "be", "imaged", "directly", ",", "even", "with", "current", "interferometric", "techniques", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "delay", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}, {"subject": {"text": "delay", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "verb": {"text": "flows", "start": 127, "end": 132, "i_start": 23, "i_end": 23}}, {"character": {"text": "technique", "start": 52, "end": 61, "i_start": 10, "i_end": 10}, "action": {"text": "probe", "start": 94, "end": 99, "i_start": 18, "i_end": 18}}], "id": 1490}, {"sent": "deep convolutional neural networks have seen great success in a range of computer vision tasks , including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "seen", "great", "success", "in", "a", "range", "of", "computer", "vision", "tasks", ",", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have seen", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "seen", "start": 40, "end": 44, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 51, "end": 58, "i_start": 7, "i_end": 7}}], "id": 1491}, {"sent": "for a brief account on synchronizing automata and their other applications we refer the reader to .", "tokens": ["for", "a", "brief", "account", "on", "synchronizing", "automata", "and", "their", "other", "applications", "we", "refer", "the", "reader", "to", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 75, "end": 77, "i_start": 11, "i_end": 11}, "verb": {"text": "refer", "start": 78, "end": 83, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 75, "end": 77, "i_start": 11, "i_end": 11}, "action": {"text": "refer", "start": 78, "end": 83, "i_start": 12, "i_end": 12}}], "id": 1492}, {"sent": "deep generative models , such as variational autoencoders and generative adversarial networks , have received a great deal of attention due to their ability to learn complex , high-dimensional distributions .", "tokens": ["deep", "generative", "models", ",", "such", "as", "variational", "autoencoders", "and", "generative", "adversarial", "networks", ",", "have", "received", "a", "great", "deal", "of", "attention", "due", "to", "their", "ability", "to", "learn", "complex", ",", "high", "-", "dimensional", "distributions", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep generative models", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "have received", "start": 96, "end": 109, "i_start": 13, "i_end": 14}}, {"character": {"text": "models", "start": 16, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "received", "start": 101, "end": 109, "i_start": 14, "i_end": 14}}], "id": 1493}, {"sent": "each convolution layer is followed with batch normalization layer and a relu .", "tokens": ["each", "convolution", "layer", "is", "followed", "with", "batch", "normalization", "layer", "and", "a", "relu", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each convolution layer", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is followed", "start": 23, "end": 34, "i_start": 3, "i_end": 4}}], "id": 1494}, {"sent": "bell et al used spatial recurrent neural networks to integrate muti-context information of roi .", "tokens": ["bell", "et", "al", "used", "spatial", "recurrent", "neural", "networks", "to", "integrate", "muti", "-", "context", "information", "of", "roi", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bell et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "bell", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "bell", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "integrate", "start": 53, "end": 62, "i_start": 9, "i_end": 9}}], "id": 1495}, {"sent": "string theory is the domain of particle physicists and is predominantly used to analyze the phenomena at the highest conceivable energies , approaching or surpassing the planck energy .", "tokens": ["string", "theory", "is", "the", "domain", "of", "particle", "physicists", "and", "is", "predominantly", "used", "to", "analyze", "the", "phenomena", "at", "the", "highest", "conceivable", "energies", ",", "approaching", "or", "surpassing", "the", "planck", "energy", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "string theory", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"subject": {"text": "string theory", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "used", "start": 72, "end": 76, "i_start": 11, "i_end": 11}}, {"character": {"text": "theory", "start": 7, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "analyze", "start": 80, "end": 87, "i_start": 13, "i_end": 13}}, {"character": {"text": "phenomena", "start": 92, "end": 101, "i_start": 15, "i_end": 15}, "action": {"text": "surpassing", "start": 155, "end": 165, "i_start": 24, "i_end": 24}}], "id": 1496}, {"sent": "for example , convolutional neural network can process image data , and recurrent neural network can be used in natural language processing .", "tokens": ["for", "example", ",", "convolutional", "neural", "network", "can", "process", "image", "data", ",", "and", "recurrent", "neural", "network", "can", "be", "used", "in", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural network", "start": 14, "end": 42, "i_start": 3, "i_end": 5}, "verb": {"text": "can process", "start": 43, "end": 54, "i_start": 6, "i_end": 7}}, {"subject": {"text": "recurrent neural network", "start": 72, "end": 96, "i_start": 12, "i_end": 14}, "verb": {"text": "used", "start": 104, "end": 108, "i_start": 17, "i_end": 17}}, {"character": {"text": "network", "start": 35, "end": 42, "i_start": 5, "i_end": 5}, "action": {"text": "process", "start": 47, "end": 54, "i_start": 7, "i_end": 7}}], "id": 1497}, {"sent": "the second term is the usual einstein precession .", "tokens": ["the", "second", "term", "is", "the", "usual", "einstein", "precession", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the second term", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 1498}, {"sent": "deep neural networks have been widely applied in various fields , including computer vision he et al , among many others .", "tokens": ["deep", "neural", "networks", "have", "been", "widely", "applied", "in", "various", "fields", ",", "including", "computer", "vision", "he", "et", "al", ",", "among", "many", "others", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "applied", "start": 38, "end": 45, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}], "id": 1499}, {"sent": "we minimize the cross-entropy loss using adam optimizer with a fixed learning rate of 1e-5 .", "tokens": ["we", "minimize", "the", "cross", "-", "entropy", "loss", "using", "adam", "optimizer", "with", "a", "fixed", "learning", "rate", "of", "1e-5", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "minimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "minimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 1500}, {"sent": "non-orthogonal multiple access has been considered as a promising technology to improve bandwidth efficiency in the 5g systems , by leveraging superposition coding and successive interference cancellation .", "tokens": ["non", "-", "orthogonal", "multiple", "access", "has", "been", "considered", "as", "a", "promising", "technology", "to", "improve", "bandwidth", "efficiency", "in", "the", "5", "g", "systems", ",", "by", "leveraging", "superposition", "coding", "and", "successive", "interference", "cancellation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "non-orthogonal multiple access", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "has been considered", "start": 31, "end": 50, "i_start": 5, "i_end": 7}}, {"character": {"text": "technology", "start": 66, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "promising", "start": 56, "end": 65, "i_start": 10, "i_end": 10}}], "id": 1501}, {"sent": "overfeat is the first regression-based object detector based on deep networks using sliding-window paradigm .", "tokens": ["overfeat", "is", "the", "first", "regression", "-", "based", "object", "detector", "based", "on", "deep", "networks", "using", "sliding", "-", "window", "paradigm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "overfeat", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}], "id": 1502}, {"sent": "because the imaginary part of the perturbative amplitude can be calculated from borel resummation this relation renders the real part of the nonperturbative amplitude to be calculable from the perturbation theory .", "tokens": ["because", "the", "imaginary", "part", "of", "the", "perturbative", "amplitude", "can", "be", "calculated", "from", "borel", "resummation", "this", "relation", "renders", "the", "real", "part", "of", "the", "nonperturbative", "amplitude", "to", "be", "calculable", "from", "the", "perturbation", "theory", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "this relation", "start": 98, "end": 111, "i_start": 14, "i_end": 15}, "verb": {"text": "renders", "start": 112, "end": 119, "i_start": 16, "i_end": 16}}], "id": 1503}, {"sent": "vanishing of renormalized charge in electrodynamics and meson theory .", "tokens": ["vanishing", "of", "renormalized", "charge", "in", "electrodynamics", "and", "meson", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1504}, {"sent": "this result motivated the work by wyner who introduced the notion of wiretap channel .", "tokens": ["this", "result", "motivated", "the", "work", "by", "wyner", "who", "introduced", "the", "notion", "of", "wiretap", "channel", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this result", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "motivated", "start": 12, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "result", "start": 5, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "motivated", "start": 12, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "channel", "start": 77, "end": 84, "i_start": 13, "i_end": 13}, "action": {"text": "work", "start": 26, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "wiretap", "start": 69, "end": 76, "i_start": 12, "i_end": 12}, "action": {"text": "work", "start": 26, "end": 30, "i_start": 4, "i_end": 4}}], "id": 1505}, {"sent": "the algorithm is still based on representing a given chytn instance on an exponentially sized network , as first suggested in .", "tokens": ["the", "algorithm", "is", "still", "based", "on", "representing", "a", "given", "chytn", "instance", "on", "an", "exponentially", "sized", "network", ",", "as", "first", "suggested", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the algorithm", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "based", "start": 23, "end": 28, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the algorithm", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1506}, {"sent": "deep learning has led to series of breakthroughs in many fields of applied machine learning , especially in image classification or natural language processing .", "tokens": ["deep", "learning", "has", "led", "to", "series", "of", "breakthroughs", "in", "many", "fields", "of", "applied", "machine", "learning", ",", "especially", "in", "image", "classification", "or", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has led", "start": 14, "end": 21, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 18, "end": 21, "i_start": 3, "i_end": 3}}], "id": 1507}, {"sent": "the adam optimiser algorithm was used for training and the early-stopping criterion was employed to reduce overfitting .", "tokens": ["the", "adam", "optimiser", "algorithm", "was", "used", "for", "training", "and", "the", "early", "-", "stopping", "criterion", "was", "employed", "to", "reduce", "overfitting", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the adam optimiser algorithm", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "was used", "start": 29, "end": 37, "i_start": 4, "i_end": 5}}, {"subject": {"text": "the early-stopping criterion", "start": 55, "end": 83, "i_start": 9, "i_end": 13}, "verb": {"text": "employed", "start": 88, "end": 96, "i_start": 15, "i_end": 15}}, {"character": {"text": "algorithm", "start": 19, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "optimiser", "start": 9, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "criterion", "start": 74, "end": 83, "i_start": 13, "i_end": 13}, "action": {"text": "reduce", "start": 100, "end": 106, "i_start": 17, "i_end": 17}}], "id": 1508}, {"sent": "specifically , we use the five feature maps after convolution layers of alexnet forf m .", "tokens": ["specifically", ",", "we", "use", "the", "five", "feature", "maps", "after", "convolution", "layers", "of", "alexnet", "forf", "m", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "use", "start": 18, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 18, "end": 21, "i_start": 3, "i_end": 3}}], "id": 1509}, {"sent": "hence , we use the toyota camry dataset to compare the ntp-based ids against the sota ids in terms of estimation consistency .", "tokens": ["hence", ",", "we", "use", "the", "toyota", "camry", "dataset", "to", "compare", "the", "ntp", "-", "based", "ids", "against", "the", "sota", "ids", "in", "terms", "of", "estimation", "consistency", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "use", "start": 11, "end": 14, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 11, "end": 14, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "compare", "start": 43, "end": 50, "i_start": 9, "i_end": 9}}], "id": 1510}, {"sent": "for instance , simulated annealing and genetic algorithms both use randomized search directions to determine the next place that they will search .", "tokens": ["for", "instance", ",", "simulated", "annealing", "and", "genetic", "algorithms", "both", "use", "randomized", "search", "directions", "to", "determine", "the", "next", "place", "that", "they", "will", "search", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "algorithms", "start": 47, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "use", "start": 63, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "annealing", "start": 25, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 63, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "genetic", "start": 39, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "use", "start": 63, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "both", "start": 58, "end": 62, "i_start": 8, "i_end": 8}, "action": {"text": "use", "start": 63, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "algorithms", "start": 47, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "determine", "start": 99, "end": 108, "i_start": 14, "i_end": 14}}, {"character": {"text": "annealing", "start": 25, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "determine", "start": 99, "end": 108, "i_start": 14, "i_end": 14}}, {"character": {"text": "genetic", "start": 39, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "determine", "start": 99, "end": 108, "i_start": 14, "i_end": 14}}, {"character": {"text": "both", "start": 58, "end": 62, "i_start": 8, "i_end": 8}, "action": {"text": "determine", "start": 99, "end": 108, "i_start": 14, "i_end": 14}}, {"character": {"text": "they", "start": 129, "end": 133, "i_start": 19, "i_end": 19}, "action": {"text": "search", "start": 139, "end": 145, "i_start": 21, "i_end": 21}}], "id": 1511}, {"sent": "we will return to this in sections vii and viii .", "tokens": ["we", "will", "return", "to", "this", "in", "sections", "vii", "and", "viii", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will return", "start": 3, "end": 14, "i_start": 1, "i_end": 2}}], "id": 1512}, {"sent": "indeed , as was already said , nucleon is a soliton of an effective meson lagrangian at large nc .", "tokens": ["indeed", ",", "as", "was", "already", "said", ",", "nucleon", "is", "a", "soliton", "of", "an", "effective", "meson", "lagrangian", "at", "large", "nc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "nucleon", "start": 31, "end": 38, "i_start": 7, "i_end": 7}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 8, "i_end": 8}}, {"character": {"text": "lagrangian", "start": 74, "end": 84, "i_start": 15, "i_end": 15}, "action": {"text": "effective", "start": 58, "end": 67, "i_start": 13, "i_end": 13}}], "id": 1513}, {"sent": "finally , let us partition \u03b3 into half-spaces .", "tokens": ["finally", ",", "let", "us", "partition", "\u03b3", "into", "half", "-", "spaces", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "let", "start": 10, "end": 13, "i_start": 2, "i_end": 2}}, {"subject": {"text": "us", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "partition", "start": 17, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "us", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "let", "start": 10, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "partition", "start": 17, "end": 26, "i_start": 4, "i_end": 4}}], "id": 1514}, {"sent": "such wrapped m2-branes describe massless charged matter fields in the f-theory effective action .", "tokens": ["such", "wrapped", "m2", "-", "branes", "describe", "massless", "charged", "matter", "fields", "in", "the", "f", "-", "theory", "effective", "action", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "such wrapped m2-branes", "start": 0, "end": 22, "i_start": 0, "i_end": 4}, "verb": {"text": "describe", "start": 23, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "branes", "start": 16, "end": 22, "i_start": 4, "i_end": 4}, "action": {"text": "describe", "start": 23, "end": 31, "i_start": 5, "i_end": 5}}], "id": 1515}, {"sent": "the success of convolutional neural networks dataset has propelled neural networks to achieve significant results in various visual recognition tasks .", "tokens": ["the", "success", "of", "convolutional", "neural", "networks", "dataset", "has", "propelled", "neural", "networks", "to", "achieve", "significant", "results", "in", "various", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the success of convolutional neural networks dataset", "start": 0, "end": 52, "i_start": 0, "i_end": 6}, "verb": {"text": "has propelled", "start": 53, "end": 66, "i_start": 7, "i_end": 8}}, {"character": {"text": "success", "start": 4, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "propelled", "start": 57, "end": 66, "i_start": 8, "i_end": 8}}, {"character": {"text": "dataset", "start": 45, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 4, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "networks", "start": 36, "end": 44, "i_start": 5, "i_end": 5}, "action": {"text": "achieve", "start": 86, "end": 93, "i_start": 12, "i_end": 12}}], "id": 1516}, {"sent": "this kind of approaches has been proven successful in various applications , such as node classification .", "tokens": ["this", "kind", "of", "approaches", "has", "been", "proven", "successful", "in", "various", "applications", ",", "such", "as", "node", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this kind of approaches", "start": 0, "end": 23, "i_start": 0, "i_end": 3}, "verb": {"text": "has been proven", "start": 24, "end": 39, "i_start": 4, "i_end": 6}}, {"character": {"text": "approaches", "start": 13, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "successful", "start": 40, "end": 50, "i_start": 7, "i_end": 7}}], "id": 1517}, {"sent": "however , we can often restrict the structure group to invertible zeroth order \u03c8dos .", "tokens": ["however", ",", "we", "can", "often", "restrict", "the", "structure", "group", "to", "invertible", "zeroth", "order", "\u03c8dos", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "restrict", "start": 23, "end": 31, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "can", "start": 13, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "restrict", "start": 23, "end": 31, "i_start": 5, "i_end": 5}}], "id": 1518}, {"sent": "this sca type of synchronous updating is not expected to affect the dynamical scaling behavior and provides a possibility for parallel algorithms .", "tokens": ["this", "sca", "type", "of", "synchronous", "updating", "is", "not", "expected", "to", "affect", "the", "dynamical", "scaling", "behavior", "and", "provides", "a", "possibility", "for", "parallel", "algorithms", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this sca type of synchronous updating", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "is not expected", "start": 38, "end": 53, "i_start": 6, "i_end": 8}}, {"subject": {"text": "this sca type of synchronous updating", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "provides", "start": 99, "end": 107, "i_start": 16, "i_end": 16}}, {"character": {"text": "updating", "start": 29, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "affect", "start": 57, "end": 63, "i_start": 10, "i_end": 10}}, {"character": {"text": "not expected", "start": 41, "end": 53, "i_start": 7, "i_end": 8}, "action": {"text": "provides", "start": 99, "end": 107, "i_start": 16, "i_end": 16}}], "id": 1519}, {"sent": "deep neural networks have shown improvement in state-of-the-art in different tasks , such as image classification .", "tokens": ["deep", "neural", "networks", "have", "shown", "improvement", "in", "state", "-", "of", "-", "the", "-", "art", "in", "different", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improvement", "start": 32, "end": 43, "i_start": 5, "i_end": 5}}], "id": 1520}, {"sent": "it is presently understood , in both the nonlinear optics and bec contexts , that the nonlinear dynamics described by the gp equation is typically chaotic and often non-equilibrium .", "tokens": ["it", "is", "presently", "understood", ",", "in", "both", "the", "nonlinear", "optics", "and", "bec", "contexts", ",", "that", "the", "nonlinear", "dynamics", "described", "by", "the", "gp", "equation", "is", "typically", "chaotic", "and", "often", "non", "-", "equilibrium", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "understood", "start": 16, "end": 26, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 134, "end": 136, "i_start": 23, "i_end": 23}}, {"character": {"text": "equation", "start": 125, "end": 133, "i_start": 22, "i_end": 22}, "action": {"text": "described", "start": 105, "end": 114, "i_start": 18, "i_end": 18}}], "id": 1521}, {"sent": "in quenched qcd there is a small inherent ambiguity in how those parameters can be fixed .", "tokens": ["in", "quenched", "qcd", "there", "is", "a", "small", "inherent", "ambiguity", "in", "how", "those", "parameters", "can", "be", "fixed", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 16, "end": 21, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}], "id": 1522}, {"sent": "the global methodology applied for ae-based analysistransformation-synthesis of audio signals in this study is in line with previous works .", "tokens": ["the", "global", "methodology", "applied", "for", "ae", "-", "based", "analysistransformation", "-", "synthesis", "of", "audio", "signals", "in", "this", "study", "is", "in", "line", "with", "previous", "works", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the global methodology", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "applied", "start": 23, "end": 30, "i_start": 3, "i_end": 3}}], "id": 1523}, {"sent": "even- and odd-parity states acquire an energy separation which is nonperturbative and nonanalytic in the coupling strength and is an effect which in principle can not be derived from perturbation theory alone .", "tokens": ["even-", "and", "odd", "-", "parity", "states", "acquire", "an", "energy", "separation", "which", "is", "nonperturbative", "and", "nonanalytic", "in", "the", "coupling", "strength", "and", "is", "an", "effect", "which", "in", "principle", "can", "not", "be", "derived", "from", "perturbation", "theory", "alone", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "even- and odd-parity states", "start": 0, "end": 27, "i_start": 0, "i_end": 5}, "verb": {"text": "acquire", "start": 28, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "states", "start": 21, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "acquire", "start": 28, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "even-", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "acquire", "start": 28, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "-", "start": 13, "end": 14, "i_start": 3, "i_end": 3}, "action": {"text": "acquire", "start": 28, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "parity", "start": 14, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "acquire", "start": 28, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "separation", "start": 46, "end": 56, "i_start": 9, "i_end": 9}, "action": {"text": "not be derived from perturbation", "start": 163, "end": 195, "i_start": 27, "i_end": 31}}], "id": 1524}, {"sent": "in recent years , it has found many applications in independent subspace analysis , also known as multidimensional independent component analysis and semidefinite programming .", "tokens": ["in", "recent", "years", ",", "it", "has", "found", "many", "applications", "in", "independent", "subspace", "analysis", ",", "also", "known", "as", "multidimensional", "independent", "component", "analysis", "and", "semidefinite", "programming", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "has found", "start": 21, "end": 30, "i_start": 5, "i_end": 6}}, {"character": {"text": "it", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "found", "start": 25, "end": 30, "i_start": 6, "i_end": 6}}, {"character": {"text": "subspace", "start": 64, "end": 72, "i_start": 11, "i_end": 11}, "action": {"text": "independent", "start": 52, "end": 63, "i_start": 10, "i_end": 10}}, {"character": {"text": "component", "start": 127, "end": 136, "i_start": 19, "i_end": 19}, "action": {"text": "independent", "start": 115, "end": 126, "i_start": 18, "i_end": 18}}], "id": 1525}, {"sent": "also , minimally invasive surgery is now being widely used as one of the most preferred choices for various types of operations .", "tokens": ["also", ",", "minimally", "invasive", "surgery", "is", "now", "being", "widely", "used", "as", "one", "of", "the", "most", "preferred", "choices", "for", "various", "types", "of", "operations", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "minimally invasive surgery", "start": 7, "end": 33, "i_start": 2, "i_end": 4}, "verb": {"text": "used", "start": 54, "end": 58, "i_start": 9, "i_end": 9}}, {"subject": {"text": "minimally invasive surgery", "start": 7, "end": 33, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 5, "i_end": 5}}, {"subject": {"text": "minimally invasive surgery", "start": 7, "end": 33, "i_start": 2, "i_end": 4}, "verb": {"text": "being", "start": 41, "end": 46, "i_start": 7, "i_end": 7}}], "id": 1526}, {"sent": "jaynes , in maximum entropy and bayesian methods , edited by j .", "tokens": ["jaynes", ",", "in", "maximum", "entropy", "and", "bayesian", "methods", ",", "edited", "by", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "jaynes", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "edited", "start": 51, "end": 57, "i_start": 9, "i_end": 9}}], "id": 1527}, {"sent": "no apparent mr is seen in normal state ie above tc onset , which excludes .", "tokens": ["no", "apparent", "mr", "is", "seen", "in", "normal", "state", "ie", "above", "tc", "onset", ",", "which", "excludes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "mr", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "is seen", "start": 15, "end": 22, "i_start": 3, "i_end": 4}}, {"character": {"text": "no apparent mr is seen", "start": 0, "end": 22, "i_start": 0, "i_end": 4}, "action": {"text": "excludes", "start": 65, "end": 73, "i_start": 14, "i_end": 14}}], "id": 1528}, {"sent": "an iet t is called ergodic if it is \u03bb-ergodic .", "tokens": ["an", "iet", "t", "is", "called", "ergodic", "if", "it", "is", "\u03bb", "-", "ergodic", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an iet t", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 9, "end": 18, "i_start": 3, "i_end": 4}}], "id": 1529}, {"sent": "the miriad software package was used to reduce the data .", "tokens": ["the", "miriad", "software", "package", "was", "used", "to", "reduce", "the", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the miriad software package", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "was used", "start": 28, "end": 36, "i_start": 4, "i_end": 5}}], "id": 1530}, {"sent": "in all cases we observe that the concurrence drops to zero for very strong fields .", "tokens": ["in", "all", "cases", "we", "observe", "that", "the", "concurrence", "drops", "to", "zero", "for", "very", "strong", "fields", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "observe", "start": 16, "end": 23, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the concurrence", "start": 29, "end": 44, "i_start": 6, "i_end": 7}, "verb": {"text": "drops", "start": 45, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "observe", "start": 16, "end": 23, "i_start": 4, "i_end": 4}}], "id": 1531}, {"sent": "using the derived formula , we estimate the effect of .", "tokens": ["using", "the", "derived", "formula", ",", "we", "estimate", "the", "effect", "of", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 28, "end": 30, "i_start": 5, "i_end": 5}, "verb": {"text": "estimate", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 28, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "estimate", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 28, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "using", "start": 0, "end": 5, "i_start": 0, "i_end": 0}}], "id": 1532}, {"sent": "in , only the most frequent words in the training set were used as targets whereas the remaining words were just tagged as oovs .", "tokens": ["in", ",", "only", "the", "most", "frequent", "words", "in", "the", "training", "set", "were", "used", "as", "targets", "whereas", "the", "remaining", "words", "were", "just", "tagged", "as", "oovs", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "only the most frequent words in the training set", "start": 5, "end": 53, "i_start": 2, "i_end": 10}, "verb": {"text": "were used", "start": 54, "end": 63, "i_start": 11, "i_end": 12}}], "id": 1533}, {"sent": "the energy scale is a generalized thouless energy16 , valid for a barrier that is described by an insulator that does not have either ballistic or diffusive transport .", "tokens": ["the", "energy", "scale", "is", "a", "generalized", "thouless", "energy16", ",", "valid", "for", "a", "barrier", "that", "is", "described", "by", "an", "insulator", "that", "does", "not", "have", "either", "ballistic", "or", "diffusive", "transport", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the energy scale", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "insulator", "start": 98, "end": 107, "i_start": 18, "i_end": 18}, "action": {"text": "described", "start": 82, "end": 91, "i_start": 15, "i_end": 15}}, {"character": {"text": "insulator", "start": 98, "end": 107, "i_start": 18, "i_end": 18}, "action": {"text": "not have", "start": 118, "end": 126, "i_start": 21, "i_end": 22}}], "id": 1534}, {"sent": "ramanathan , projective normality of flag varieties and schubert varieties , invent .", "tokens": ["ramanathan", ",", "projective", "normality", "of", "flag", "varieties", "and", "schubert", "varieties", ",", "invent", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "ramanathan", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "invent", "start": 77, "end": 83, "i_start": 11, "i_end": 11}}], "id": 1535}, {"sent": "in particular , fan and peng establish some asymptotic properties , as well as an oracle property , for nonconcave penalized likelihood estimators in the presence of a diverging number of parameters .", "tokens": ["in", "particular", ",", "fan", "and", "peng", "establish", "some", "asymptotic", "properties", ",", "as", "well", "as", "an", "oracle", "property", ",", "for", "nonconcave", "penalized", "likelihood", "estimators", "in", "the", "presence", "of", "a", "diverging", "number", "of", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "fan and peng", "start": 16, "end": 28, "i_start": 3, "i_end": 5}, "verb": {"text": "establish", "start": 29, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "fan", "start": 16, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "establish", "start": 29, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "peng", "start": 24, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "establish", "start": 29, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "number", "start": 178, "end": 184, "i_start": 29, "i_end": 29}, "action": {"text": "diverging", "start": 168, "end": 177, "i_start": 28, "i_end": 28}}], "id": 1536}, {"sent": "a lamination is a foliation of a closed subset of the manifold .", "tokens": ["a", "lamination", "is", "a", "foliation", "of", "a", "closed", "subset", "of", "the", "manifold", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a lamination", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 1537}, {"sent": "millimeter-wave technology is one of the essential components of future wireless networks to support extremely high data rate services .", "tokens": ["millimeter", "-", "wave", "technology", "is", "one", "of", "the", "essential", "components", "of", "future", "wireless", "networks", "to", "support", "extremely", "high", "data", "rate", "services", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "millimeter-wave technology", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "components", "start": 51, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "support", "start": 93, "end": 100, "i_start": 15, "i_end": 15}}], "id": 1538}, {"sent": "next , we consider the stability of ground states .", "tokens": ["next", ",", "we", "consider", "the", "stability", "of", "ground", "states", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "consider", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "consider", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}], "id": 1539}, {"sent": "every convolutional layers are followed by a batch normalization layer and a relu .", "tokens": ["every", "convolutional", "layers", "are", "followed", "by", "a", "batch", "normalization", "layer", "and", "a", "relu", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "every convolutional layers", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "are followed", "start": 27, "end": 39, "i_start": 3, "i_end": 4}}], "id": 1540}, {"sent": "related ideas are pursued by ma et al , who add terms to their models enforcing homophily between friends with regard to their preferences .", "tokens": ["related", "ideas", "are", "pursued", "by", "ma", "et", "al", ",", "who", "add", "terms", "to", "their", "models", "enforcing", "homophily", "between", "friends", "with", "regard", "to", "their", "preferences", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "related ideas", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "are pursued", "start": 14, "end": 25, "i_start": 2, "i_end": 3}}, {"character": {"text": "ma", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "pursued", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "between", "start": 90, "end": 97, "i_start": 17, "i_end": 17}, "action": {"text": "pursued", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "friends", "start": 98, "end": 105, "i_start": 18, "i_end": 18}, "action": {"text": "pursued", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 63, "end": 69, "i_start": 14, "i_end": 14}, "action": {"text": "enforcing", "start": 70, "end": 79, "i_start": 15, "i_end": 15}}, {"character": {"text": "ma", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "preferences", "start": 127, "end": 138, "i_start": 23, "i_end": 23}}, {"character": {"text": "between", "start": 90, "end": 97, "i_start": 17, "i_end": 17}, "action": {"text": "preferences", "start": 127, "end": 138, "i_start": 23, "i_end": 23}}, {"character": {"text": "friends", "start": 98, "end": 105, "i_start": 18, "i_end": 18}, "action": {"text": "preferences", "start": 127, "end": 138, "i_start": 23, "i_end": 23}}], "id": 1541}, {"sent": "now we shall turn to numerical simulation for the last model .", "tokens": ["now", "we", "shall", "turn", "to", "numerical", "simulation", "for", "the", "last", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "shall turn", "start": 7, "end": 17, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "turn", "start": 13, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "simulation", "start": 31, "end": 41, "i_start": 6, "i_end": 6}}], "id": 1542}, {"sent": "the most common approach to quantifying privacy guarantees in this setting is through -differential privacy .", "tokens": ["the", "most", "common", "approach", "to", "quantifying", "privacy", "guarantees", "in", "this", "setting", "is", "through", "-differential", "privacy", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the most common approach to quantifying privacy guarantees in this setting", "start": 0, "end": 74, "i_start": 0, "i_end": 10}, "verb": {"text": "is", "start": 75, "end": 77, "i_start": 11, "i_end": 11}}], "id": 1543}, {"sent": "in recent years , deep learning methods have shown great success with many computer vision tasks such as image classification .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "methods", "have", "shown", "great", "success", "with", "many", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning methods", "start": 18, "end": 39, "i_start": 4, "i_end": 6}, "verb": {"text": "have shown", "start": 40, "end": 50, "i_start": 7, "i_end": 8}}, {"character": {"text": "methods", "start": 32, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "shown", "start": 45, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "methods", "start": 32, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 57, "end": 64, "i_start": 10, "i_end": 10}}], "id": 1544}, {"sent": "since the deuteron is the simplest nucleus containing a neutron , the process of pion production on the deuteron can be used for examining pion production on a neutron .", "tokens": ["since", "the", "deuteron", "is", "the", "simplest", "nucleus", "containing", "a", "neutron", ",", "the", "process", "of", "pion", "production", "on", "the", "deuteron", "can", "be", "used", "for", "examining", "pion", "production", "on", "a", "neutron", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the process of pion production on the deuteron", "start": 66, "end": 112, "i_start": 11, "i_end": 18}, "verb": {"text": "can be used", "start": 113, "end": 124, "i_start": 19, "i_end": 21}}, {"character": {"text": "nucleus", "start": 35, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "containing", "start": 43, "end": 53, "i_start": 7, "i_end": 7}}], "id": 1545}, {"sent": "notably , for the class of finite type hypersurfaces , it is known by the work of baouendi-ebenfelt-rothschild that every formal holomorphic map actually converges .", "tokens": ["notably", ",", "for", "the", "class", "of", "finite", "type", "hypersurfaces", ",", "it", "is", "known", "by", "the", "work", "of", "baouendi", "-", "ebenfelt", "-", "rothschild", "that", "every", "formal", "holomorphic", "map", "actually", "converges", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 55, "end": 57, "i_start": 10, "i_end": 10}, "verb": {"text": "is known", "start": 58, "end": 66, "i_start": 11, "i_end": 12}}, {"character": {"text": "map", "start": 141, "end": 144, "i_start": 26, "i_end": 26}, "action": {"text": "converges", "start": 154, "end": 163, "i_start": 28, "i_end": 28}}, {"character": {"text": "baouendi", "start": 82, "end": 90, "i_start": 17, "i_end": 17}, "action": {"text": "work", "start": 74, "end": 78, "i_start": 15, "i_end": 15}}], "id": 1546}, {"sent": "thus , nowhere in the solar wind is the continuum pump light depleted by ions located at positions with smaller r values .", "tokens": ["thus", ",", "nowhere", "in", "the", "solar", "wind", "is", "the", "continuum", "pump", "light", "depleted", "by", "ions", "located", "at", "positions", "with", "smaller", "r", "values", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "ions", "start": 73, "end": 77, "i_start": 14, "i_end": 14}, "action": {"text": "depleted", "start": 61, "end": 69, "i_start": 12, "i_end": 12}}], "id": 1547}, {"sent": "the scalar-relativistic ab-initio dft calculations were performed using the projector augmented wave .", "tokens": ["the", "scalar", "-", "relativistic", "ab", "-", "initio", "dft", "calculations", "were", "performed", "using", "the", "projector", "augmented", "wave", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the scalar-relativistic ab-initio dft calculations", "start": 0, "end": 50, "i_start": 0, "i_end": 8}, "verb": {"text": "were performed", "start": 51, "end": 65, "i_start": 9, "i_end": 10}}, {"character": {"text": "projector", "start": 76, "end": 85, "i_start": 13, "i_end": 13}, "action": {"text": "augmented", "start": 86, "end": 95, "i_start": 14, "i_end": 14}}], "id": 1548}, {"sent": "this point of view was initiated by lebowitz-rose-speer and others .", "tokens": ["this", "point", "of", "view", "was", "initiated", "by", "lebowitz", "-", "rose", "-", "speer", "and", "others", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this point of view", "start": 0, "end": 18, "i_start": 0, "i_end": 3}, "verb": {"text": "was initiated", "start": 19, "end": 32, "i_start": 4, "i_end": 5}}, {"character": {"text": "lebowitz", "start": 36, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "initiated", "start": 23, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "others", "start": 60, "end": 66, "i_start": 13, "i_end": 13}, "action": {"text": "initiated", "start": 23, "end": 32, "i_start": 5, "i_end": 5}}], "id": 1549}, {"sent": "we use the pytorch 1 framework for our implementation .", "tokens": ["we", "use", "the", "pytorch", "1", "framework", "for", "our", "implementation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implementation", "start": 39, "end": 53, "i_start": 8, "i_end": 8}}], "id": 1550}, {"sent": "to optimize the network , we use a stochastic gradient descent with an adaptive sub-gradient method which is popular for its impressive history of empirical success .", "tokens": ["to", "optimize", "the", "network", ",", "we", "use", "a", "stochastic", "gradient", "descent", "with", "an", "adaptive", "sub", "-", "gradient", "method", "which", "is", "popular", "for", "its", "impressive", "history", "of", "empirical", "success", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 29, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 29, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "history", "start": 136, "end": 143, "i_start": 24, "i_end": 24}, "action": {"text": "impressive", "start": 125, "end": 135, "i_start": 23, "i_end": 23}}], "id": 1551}, {"sent": "in a previous paper we introduced a certain complex-analytic structure within the unit disk of the complex plane , and showed that it is possible to represent within that structure essentially all integrable real functions defined in a compact interval .", "tokens": ["in", "a", "previous", "paper", "we", "introduced", "a", "certain", "complex", "-", "analytic", "structure", "within", "the", "unit", "disk", "of", "the", "complex", "plane", ",", "and", "showed", "that", "it", "is", "possible", "to", "represent", "within", "that", "structure", "essentially", "all", "integrable", "real", "functions", "defined", "in", "a", "compact", "interval", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 20, "end": 22, "i_start": 4, "i_end": 4}, "verb": {"text": "introduced", "start": 23, "end": 33, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 20, "end": 22, "i_start": 4, "i_end": 4}, "verb": {"text": "showed", "start": 119, "end": 125, "i_start": 22, "i_end": 22}}, {"character": {"text": "we", "start": 20, "end": 22, "i_start": 4, "i_end": 4}, "action": {"text": "introduced", "start": 23, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 20, "end": 22, "i_start": 4, "i_end": 4}, "action": {"text": "showed", "start": 119, "end": 125, "i_start": 22, "i_end": 22}}, {"character": {"text": "structure", "start": 61, "end": 70, "i_start": 11, "i_end": 11}, "action": {"text": "represent", "start": 149, "end": 158, "i_start": 28, "i_end": 28}}], "id": 1552}, {"sent": "in this approach , we use textrank , which is a graph-based method for keyword extraction .", "tokens": ["in", "this", "approach", ",", "we", "use", "textrank", ",", "which", "is", "a", "graph", "-", "based", "method", "for", "keyword", "extraction", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 22, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 22, "end": 25, "i_start": 5, "i_end": 5}}], "id": 1553}, {"sent": "since the supergravity background of is sosymmetric , it is natural to assume that the dual of this background lies on the baryonic branch of the cascading theory .", "tokens": ["since", "the", "supergravity", "background", "of", "is", "sosymmetric", ",", "it", "is", "natural", "to", "assume", "that", "the", "dual", "of", "this", "background", "lies", "on", "the", "baryonic", "branch", "of", "the", "cascading", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 54, "end": 56, "i_start": 8, "i_end": 8}, "verb": {"text": "is", "start": 57, "end": 59, "i_start": 9, "i_end": 9}}], "id": 1554}, {"sent": "this similarity is a strong indication that the subgroups identified by the lm method are not artifacts of this method .", "tokens": ["this", "similarity", "is", "a", "strong", "indication", "that", "the", "subgroups", "identified", "by", "the", "lm", "method", "are", "not", "artifacts", "of", "this", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this similarity", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "method", "start": 79, "end": 85, "i_start": 13, "i_end": 13}, "action": {"text": "identified", "start": 58, "end": 68, "i_start": 9, "i_end": 9}}], "id": 1555}, {"sent": "over the past few years , convolutional neural networks have become the leading approach in many vision-related tasks .", "tokens": ["over", "the", "past", "few", "years", ",", "convolutional", "neural", "networks", "have", "become", "the", "leading", "approach", "in", "many", "vision", "-", "related", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 26, "end": 55, "i_start": 6, "i_end": 8}, "verb": {"text": "have become", "start": 56, "end": 67, "i_start": 9, "i_end": 10}}, {"character": {"text": "networks", "start": 47, "end": 55, "i_start": 8, "i_end": 8}, "action": {"text": "approach", "start": 80, "end": 88, "i_start": 13, "i_end": 13}}, {"character": {"text": "approach", "start": 80, "end": 88, "i_start": 13, "i_end": 13}, "action": {"text": "leading", "start": 72, "end": 79, "i_start": 12, "i_end": 12}}], "id": 1556}, {"sent": "an example is aodv , or ad hoc on demand distance vector .", "tokens": ["an", "example", "is", "aodv", ",", "or", "ad", "hoc", "on", "demand", "distance", "vector", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an example", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}], "id": 1557}, {"sent": "let p be a regular end of complete flat front , then .", "tokens": ["let", "p", "be", "a", "regular", "end", "of", "complete", "flat", "front", ",", "then", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "p", "start": 4, "end": 5, "i_start": 1, "i_end": 1}, "action": {"text": "end", "start": 19, "end": 22, "i_start": 5, "i_end": 5}}], "id": 1558}, {"sent": "it is a larger subset of imagenet with 608 classes grouped into 34 super-class nodes .", "tokens": ["it", "is", "a", "larger", "subset", "of", "imagenet", "with", "608", "classes", "grouped", "into", "34", "super", "-", "class", "nodes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}], "id": 1559}, {"sent": "a specific , very successful regularisation model is given by total variation minimisation as introduced in the seminal work by rudin , osher and fatemi .", "tokens": ["a", "specific", ",", "very", "successful", "regularisation", "model", "is", "given", "by", "total", "variation", "minimisation", "as", "introduced", "in", "the", "seminal", "work", "by", "rudin", ",", "osher", "and", "fatemi", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "a specific", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is given", "start": 50, "end": 58, "i_start": 7, "i_end": 8}}, {"character": {"text": "rudin", "start": 128, "end": 133, "i_start": 20, "i_end": 20}, "action": {"text": "work", "start": 120, "end": 124, "i_start": 18, "i_end": 18}}, {"character": {"text": "osher", "start": 136, "end": 141, "i_start": 22, "i_end": 22}, "action": {"text": "work", "start": 120, "end": 124, "i_start": 18, "i_end": 18}}, {"character": {"text": "fatemi", "start": 146, "end": 152, "i_start": 24, "i_end": 24}, "action": {"text": "work", "start": 120, "end": 124, "i_start": 18, "i_end": 18}}], "id": 1560}, {"sent": "maximum matching and minimum vertex cover are among the most studied graph optimization problems in the mpc and similar mapreduce-style computation models .", "tokens": ["maximum", "matching", "and", "minimum", "vertex", "cover", "are", "among", "the", "most", "studied", "graph", "optimization", "problems", "in", "the", "mpc", "and", "similar", "mapreduce", "-", "style", "computation", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "maximum matching and minimum vertex cover", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 42, "end": 45, "i_start": 6, "i_end": 6}}], "id": 1561}, {"sent": "the winding number is the ratio between the angular velocities along the two independent cyclic coordinates spanning the torus .", "tokens": ["the", "winding", "number", "is", "the", "ratio", "between", "the", "angular", "velocities", "along", "the", "two", "independent", "cyclic", "coordinates", "spanning", "the", "torus", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the winding number", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "two independent cyclic coordinates", "start": 73, "end": 107, "i_start": 12, "i_end": 15}, "action": {"text": "independent", "start": 77, "end": 88, "i_start": 13, "i_end": 13}}, {"character": {"text": "two independent cyclic coordinates", "start": 73, "end": 107, "i_start": 12, "i_end": 15}, "action": {"text": "spanning", "start": 108, "end": 116, "i_start": 16, "i_end": 16}}], "id": 1562}, {"sent": "the concepts of deep learning and multi-layer convolution neural network have received a wide recognition because of their demonstrated efficiency in image classification tasks .", "tokens": ["the", "concepts", "of", "deep", "learning", "and", "multi", "-", "layer", "convolution", "neural", "network", "have", "received", "a", "wide", "recognition", "because", "of", "their", "demonstrated", "efficiency", "in", "image", "classification", "tasks", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the concepts of deep learning and multi-layer convolution neural network", "start": 0, "end": 72, "i_start": 0, "i_end": 11}, "verb": {"text": "have received", "start": 73, "end": 86, "i_start": 12, "i_end": 13}}, {"character": {"text": "concepts", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "received", "start": 78, "end": 86, "i_start": 13, "i_end": 13}}], "id": 1563}, {"sent": "for the double-tensor multiplet lagrangian , the fermion-terms and susy rules can be determined by dualization .", "tokens": ["for", "the", "double", "-", "tensor", "multiplet", "lagrangian", ",", "the", "fermion", "-", "terms", "and", "susy", "rules", "can", "be", "determined", "by", "dualization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the fermion-terms and susy rules", "start": 45, "end": 77, "i_start": 8, "i_end": 14}, "verb": {"text": "can be determined", "start": 78, "end": 95, "i_start": 15, "i_end": 17}}], "id": 1564}, {"sent": "the ellipses denote terms whi h are rst order in 4 spa e-time derivatives .", "tokens": ["the", "ellipses", "denote", "terms", "whi", "h", "are", "rst", "order", "in", "4", "spa", "e", "-", "time", "derivatives", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ellipses", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "denote", "start": 13, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "ellipses", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 13, "end": 19, "i_start": 2, "i_end": 2}}], "id": 1565}, {"sent": "shows the corner portion with the walls on the top and the right .", "tokens": ["shows", "the", "corner", "portion", "with", "the", "walls", "on", "the", "top", "and", "the", "right", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1566}, {"sent": "deep convolutional neural networks trained using backpropagation are thus achieving record performance in a variety of large-scale machine vision tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "trained", "using", "backpropagation", "are", "thus", "achieving", "record", "performance", "in", "a", "variety", "of", "large", "-", "scale", "machine", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks trained using backpropagation", "start": 0, "end": 64, "i_start": 0, "i_end": 6}, "verb": {"text": "achieving", "start": 74, "end": 83, "i_start": 9, "i_end": 9}}, {"subject": {"text": "deep convolutional neural networks trained using backpropagation", "start": 0, "end": 64, "i_start": 0, "i_end": 6}, "verb": {"text": "are", "start": 65, "end": 68, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieving", "start": 74, "end": 83, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "using", "start": 43, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 91, "end": 102, "i_start": 11, "i_end": 11}}], "id": 1567}, {"sent": "model-based clustering is a popular and well established framework for clustering multivariate data .", "tokens": ["model", "-", "based", "clustering", "is", "a", "popular", "and", "well", "established", "framework", "for", "clustering", "multivariate", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "model-based clustering", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 4, "i_end": 4}}], "id": 1568}, {"sent": "exciton is a bound state of electron and hole in semiconductor , therefore we deal with two degrees of freedom in contrast to sec .", "tokens": ["exciton", "is", "a", "bound", "state", "of", "electron", "and", "hole", "in", "semiconductor", ",", "therefore", "we", "deal", "with", "two", "degrees", "of", "freedom", "in", "contrast", "to", "sec", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 75, "end": 77, "i_start": 13, "i_end": 13}, "verb": {"text": "deal", "start": 78, "end": 82, "i_start": 14, "i_end": 14}}, {"subject": {"text": "we", "start": 75, "end": 77, "i_start": 13, "i_end": 13}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 75, "end": 77, "i_start": 13, "i_end": 13}, "action": {"text": "deal", "start": 78, "end": 82, "i_start": 14, "i_end": 14}}], "id": 1569}, {"sent": "batch normalization is a recent breakthrough that is proven effective for preserving gradient in deep networks .", "tokens": ["batch", "normalization", "is", "a", "recent", "breakthrough", "that", "is", "proven", "effective", "for", "preserving", "gradient", "in", "deep", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "batch normalization", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "breakthrough", "start": 32, "end": 44, "i_start": 5, "i_end": 5}, "action": {"text": "effective", "start": 60, "end": 69, "i_start": 9, "i_end": 9}}], "id": 1570}, {"sent": "we then propose two irsvm methods by extending two most efficient irl 1 methods studied in to solve , whose subproblems are shown to have a closed-form solution .", "tokens": ["we", "then", "propose", "two", "irsvm", "methods", "by", "extending", "two", "most", "efficient", "irl", "1", "methods", "studied", "in", "to", "solve", ",", "whose", "subproblems", "are", "shown", "to", "have", "a", "closed", "-", "form", "solution", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "propose", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "two most efficient irl 1 methods", "start": 47, "end": 79, "i_start": 8, "i_end": 13}, "action": {"text": "solve", "start": 94, "end": 99, "i_start": 17, "i_end": 17}}], "id": 1571}, {"sent": "algorithms like jain and murthy are invariant to distance preserving transform on a conceptual level but as with other density based methods actual outcome depends on selected parameters .", "tokens": ["algorithms", "like", "jain", "and", "murthy", "are", "invariant", "to", "distance", "preserving", "transform", "on", "a", "conceptual", "level", "but", "as", "with", "other", "density", "based", "methods", "actual", "outcome", "depends", "on", "selected", "parameters", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "algorithms like jain and murthy", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 5, "i_end": 5}}, {"subject": {"text": "other density based methods actual outcome", "start": 113, "end": 155, "i_start": 18, "i_end": 23}, "verb": {"text": "depends", "start": 156, "end": 163, "i_start": 24, "i_end": 24}}], "id": 1572}, {"sent": "seidel , hermes collaboration , in this proceedings .", "tokens": ["seidel", ",", "hermes", "collaboration", ",", "in", "this", "proceedings", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1573}, {"sent": "the ga-fuzzy logic approach is implemented onto two levels .", "tokens": ["the", "ga", "-", "fuzzy", "logic", "approach", "is", "implemented", "onto", "two", "levels", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ga-fuzzy logic approach", "start": 0, "end": 27, "i_start": 0, "i_end": 5}, "verb": {"text": "is implemented", "start": 28, "end": 42, "i_start": 6, "i_end": 7}}], "id": 1574}, {"sent": "on the convergence properties of the em algorithm .", "tokens": ["on", "the", "convergence", "properties", "of", "the", "em", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1575}, {"sent": "thus bohmian mechanics is the minimal interpretation of nonrelativistic quantum theory , arising as it does from the assertion that a familiar word has its familiar meaning .", "tokens": ["thus", "bohmian", "mechanics", "is", "the", "minimal", "interpretation", "of", "nonrelativistic", "quantum", "theory", ",", "arising", "as", "it", "does", "from", "the", "assertion", "that", "a", "familiar", "word", "has", "its", "familiar", "meaning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "bohmian mechanics", "start": 5, "end": 22, "i_start": 1, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}], "id": 1576}, {"sent": "tzeng et al provided a comprehensive framework that subsumes several prior efforts on learning shared representations across domains .", "tokens": ["tzeng", "et", "al", "provided", "a", "comprehensive", "framework", "that", "subsumes", "several", "prior", "efforts", "on", "learning", "shared", "representations", "across", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "tzeng et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "provided", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "tzeng", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "provided", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}], "id": 1577}, {"sent": "moreover , the hom-diagrams from can be found effectively .", "tokens": ["moreover", ",", "the", "hom", "-", "diagrams", "from", "can", "be", "found", "effectively", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the hom-diagrams from", "start": 11, "end": 32, "i_start": 2, "i_end": 6}, "verb": {"text": "can be found", "start": 33, "end": 45, "i_start": 7, "i_end": 9}}], "id": 1578}, {"sent": "all our analysis and calculation are performed directly in the noncommutative phase space and not by virtue of corresponding variables in the commutative space which appear via some kind of seiberg-witten map .", "tokens": ["all", "our", "analysis", "and", "calculation", "are", "performed", "directly", "in", "the", "noncommutative", "phase", "space", "and", "not", "by", "virtue", "of", "corresponding", "variables", "in", "the", "commutative", "space", "which", "appear", "via", "some", "kind", "of", "seiberg", "-", "witten", "map", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all our analysis and calculation", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "are performed", "start": 33, "end": 46, "i_start": 5, "i_end": 6}}, {"character": {"text": "variables", "start": 125, "end": 134, "i_start": 19, "i_end": 19}, "action": {"text": "-", "start": 197, "end": 198, "i_start": 31, "i_end": 31}}], "id": 1579}, {"sent": "this quantity is similar to the one employed in experiments to measure ergodicity for a quantum system .", "tokens": ["this", "quantity", "is", "similar", "to", "the", "one", "employed", "in", "experiments", "to", "measure", "ergodicity", "for", "a", "quantum", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this quantity", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1580}, {"sent": "the models are trained using the adam optimiser with the default hyperparameters in minibatches of 80 instances .", "tokens": ["the", "models", "are", "trained", "using", "the", "adam", "optimiser", "with", "the", "default", "hyperparameters", "in", "minibatches", "of", "80", "instances", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the models", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "are trained", "start": 11, "end": 22, "i_start": 2, "i_end": 3}}], "id": 1581}, {"sent": "we have shown , in our isca 2014 paper , the existence of disturbance errors in commodity dram chips that are sold and used in the field today .", "tokens": ["we", "have", "shown", ",", "in", "our", "isca", "2014", "paper", ",", "the", "existence", "of", "disturbance", "errors", "in", "commodity", "dram", "chips", "that", "are", "sold", "and", "used", "in", "the", "field", "today", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have shown", "start": 3, "end": 13, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "shown", "start": 8, "end": 13, "i_start": 2, "i_end": 2}}], "id": 1582}, {"sent": "instead , we now formulate a variational approximation following ideas from .", "tokens": ["instead", ",", "we", "now", "formulate", "a", "variational", "approximation", "following", "ideas", "from", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "formulate", "start": 17, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "formulate", "start": 17, "end": 26, "i_start": 4, "i_end": 4}}], "id": 1583}, {"sent": "this led to significant year-over-year improvements in accuracy on image classification , which further led into improved accuracy on the other computer vision tasks .", "tokens": ["this", "led", "to", "significant", "year", "-", "over", "-", "year", "improvements", "in", "accuracy", "on", "image", "classification", ",", "which", "further", "led", "into", "improved", "accuracy", "on", "the", "other", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "led", "start": 5, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "led", "start": 5, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "improvements", "start": 39, "end": 51, "i_start": 9, "i_end": 9}, "action": {"text": "led", "start": 104, "end": 107, "i_start": 18, "i_end": 18}}], "id": 1584}, {"sent": "in string theory it is the norm to consider black holes with many independent charges excited simultaneously .", "tokens": ["in", "string", "theory", "it", "is", "the", "norm", "to", "consider", "black", "holes", "with", "many", "independent", "charges", "excited", "simultaneously", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 17, "end": 19, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 4, "i_end": 4}}, {"character": {"text": "holes", "start": 50, "end": 55, "i_start": 10, "i_end": 10}, "action": {"text": "excited", "start": 86, "end": 93, "i_start": 15, "i_end": 15}}, {"character": {"text": "charges", "start": 78, "end": 85, "i_start": 14, "i_end": 14}, "action": {"text": "independent", "start": 66, "end": 77, "i_start": 13, "i_end": 13}}], "id": 1585}, {"sent": "braham and van droogenbroeck were the first authors to use convolutional neural networks for background subtraction .", "tokens": ["braham", "and", "van", "droogenbroeck", "were", "the", "first", "authors", "to", "use", "convolutional", "neural", "networks", "for", "background", "subtraction", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "braham and van droogenbroeck", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "were", "start": 29, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "braham", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 55, "end": 58, "i_start": 9, "i_end": 9}}, {"character": {"text": "van droogenbroeck", "start": 11, "end": 28, "i_start": 2, "i_end": 3}, "action": {"text": "use", "start": 55, "end": 58, "i_start": 9, "i_end": 9}}], "id": 1586}, {"sent": "the minimization is carried out through a standard conjugated gradients algorithm .", "tokens": ["the", "minimization", "is", "carried", "out", "through", "a", "standard", "conjugated", "gradients", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the minimization", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is carried out", "start": 17, "end": 31, "i_start": 2, "i_end": 4}}], "id": 1587}, {"sent": "qi et al took full advantages of features from different cnn layers and used an adaptive hedge method to hedge several cnn trackers into a stronger one .", "tokens": ["qi", "et", "al", "took", "full", "advantages", "of", "features", "from", "different", "cnn", "layers", "and", "used", "an", "adaptive", "hedge", "method", "to", "hedge", "several", "cnn", "trackers", "into", "a", "stronger", "one", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "qi et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "took", "start": 9, "end": 13, "i_start": 3, "i_end": 3}}, {"subject": {"text": "qi et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 72, "end": 76, "i_start": 13, "i_end": 13}}, {"character": {"text": "qi", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "took", "start": 9, "end": 13, "i_start": 3, "i_end": 3}}], "id": 1588}, {"sent": "the generalized gradient approximation in the parametrization of perdew , burke and ernzerhof was used as approximation for the exchange and correlation functional .", "tokens": ["the", "generalized", "gradient", "approximation", "in", "the", "parametrization", "of", "perdew", ",", "burke", "and", "ernzerhof", "was", "used", "as", "approximation", "for", "the", "exchange", "and", "correlation", "functional", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation in the parametrization of perdew", "start": 0, "end": 71, "i_start": 0, "i_end": 8}, "verb": {"text": "was used", "start": 94, "end": 102, "i_start": 13, "i_end": 14}}], "id": 1589}, {"sent": "a hopf algebra is a bialgebra a with an antipode s .", "tokens": ["a", "hopf", "algebra", "is", "a", "bialgebra", "a", "with", "an", "antipode", "s", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a hopf algebra", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}], "id": 1590}, {"sent": "the perdew-burkeernzerhof generalized-gradient approximation is employed to describe the exchange and correlation functional .", "tokens": ["the", "perdew", "-", "burkeernzerhof", "generalized", "-", "gradient", "approximation", "is", "employed", "to", "describe", "the", "exchange", "and", "correlation", "functional", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the perdew-burkeernzerhof generalized-gradient approximation", "start": 0, "end": 60, "i_start": 0, "i_end": 7}, "verb": {"text": "is employed", "start": 61, "end": 72, "i_start": 8, "i_end": 9}}, {"character": {"text": "approximation", "start": 47, "end": 60, "i_start": 7, "i_end": 7}, "action": {"text": "describe", "start": 76, "end": 84, "i_start": 11, "i_end": 11}}], "id": 1591}, {"sent": "the kuramoto model is a mean-field model of coupled oscillators proposed by kuramoto to describe synchronization phenomena .", "tokens": ["the", "kuramoto", "model", "is", "a", "mean", "-", "field", "model", "of", "coupled", "oscillators", "proposed", "by", "kuramoto", "to", "describe", "synchronization", "phenomena", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the kuramoto model", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "field", "start": 29, "end": 34, "i_start": 7, "i_end": 7}, "action": {"text": "mean", "start": 24, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "kuramoto", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "proposed", "start": 64, "end": 72, "i_start": 12, "i_end": 12}}, {"character": {"text": "model", "start": 13, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "describe", "start": 88, "end": 96, "i_start": 16, "i_end": 16}}], "id": 1592}, {"sent": "our isca 2014 paper can reliably and consistently induce rowhammer errors in commodity amd and intel systems using vulnerable dram modules .", "tokens": ["our", "isca", "2014", "paper", "can", "reliably", "and", "consistently", "induce", "rowhammer", "errors", "in", "commodity", "amd", "and", "intel", "systems", "using", "vulnerable", "dram", "modules", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "our isca 2014 paper", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "induce", "start": 50, "end": 56, "i_start": 8, "i_end": 8}}, {"subject": {"text": "our isca 2014 paper", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "can", "start": 20, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "paper", "start": 14, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "induce", "start": 50, "end": 56, "i_start": 8, "i_end": 8}}, {"character": {"text": "and", "start": 33, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "using", "start": 109, "end": 114, "i_start": 17, "i_end": 17}}], "id": 1593}, {"sent": "for each layer of the mlp , we add a batch normalization layer to accelerate the training .", "tokens": ["for", "each", "layer", "of", "the", "mlp", ",", "we", "add", "a", "batch", "normalization", "layer", "to", "accelerate", "the", "training", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 28, "end": 30, "i_start": 7, "i_end": 7}, "verb": {"text": "add", "start": 31, "end": 34, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 28, "end": 30, "i_start": 7, "i_end": 7}, "action": {"text": "add", "start": 31, "end": 34, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 28, "end": 30, "i_start": 7, "i_end": 7}, "action": {"text": "accelerate", "start": 66, "end": 76, "i_start": 14, "i_end": 14}}], "id": 1594}, {"sent": "the grid searches were performed using the gridsearchcv class implemented in the scitkit-learn library .", "tokens": ["the", "grid", "searches", "were", "performed", "using", "the", "gridsearchcv", "class", "implemented", "in", "the", "scitkit", "-", "learn", "library", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the grid searches", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "were performed", "start": 18, "end": 32, "i_start": 3, "i_end": 4}}], "id": 1595}, {"sent": "each ll in graphene consists of four sublevels , due to spin and valley splitting .", "tokens": ["each", "ll", "in", "graphene", "consists", "of", "four", "sublevels", ",", "due", "to", "spin", "and", "valley", "splitting", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each ll in graphene", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "consists", "start": 20, "end": 28, "i_start": 4, "i_end": 4}}], "id": 1596}, {"sent": "the free energy is a sensitive and complicated function in this huge conformational space with complex constraints .", "tokens": ["the", "free", "energy", "is", "a", "sensitive", "and", "complicated", "function", "in", "this", "huge", "conformational", "space", "with", "complex", "constraints", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the free energy", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "function", "start": 47, "end": 55, "i_start": 8, "i_end": 8}, "action": {"text": "sensitive", "start": 21, "end": 30, "i_start": 5, "i_end": 5}}], "id": 1597}, {"sent": "we update the set of model parameters using adam sgd .", "tokens": ["we", "update", "the", "set", "of", "model", "parameters", "using", "adam", "sgd", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "update", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "update", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 38, "end": 43, "i_start": 7, "i_end": 7}}], "id": 1598}, {"sent": "the exchange correlation term was described using the gga functional proposed by perdew , burke , and ernzerhof .", "tokens": ["the", "exchange", "correlation", "term", "was", "described", "using", "the", "gga", "functional", "proposed", "by", "perdew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange correlation term", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "was described", "start": 30, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "perdew", "start": 81, "end": 87, "i_start": 12, "i_end": 12}, "action": {"text": "proposed", "start": 69, "end": 77, "i_start": 10, "i_end": 10}}, {"character": {"text": "burke", "start": 90, "end": 95, "i_start": 14, "i_end": 14}, "action": {"text": "proposed", "start": 69, "end": 77, "i_start": 10, "i_end": 10}}, {"character": {"text": "ernzerhof", "start": 102, "end": 111, "i_start": 17, "i_end": 17}, "action": {"text": "proposed", "start": 69, "end": 77, "i_start": 10, "i_end": 10}}], "id": 1599}, {"sent": "below , we illustrate the application of the above theorem through some examples .", "tokens": ["below", ",", "we", "illustrate", "the", "application", "of", "the", "above", "theorem", "through", "some", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "illustrate", "start": 11, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "illustrate", "start": 11, "end": 21, "i_start": 3, "i_end": 3}}], "id": 1600}, {"sent": "recurrent neural networks have recently shown great promise in tackling various sequence modeling tasks in machine learning , such as automatic speech recognition .", "tokens": ["recurrent", "neural", "networks", "have", "recently", "shown", "great", "promise", "in", "tackling", "various", "sequence", "modeling", "tasks", "in", "machine", "learning", ",", "such", "as", "automatic", "speech", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "recurrent neural networks", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "shown", "start": 40, "end": 45, "i_start": 5, "i_end": 5}}, {"subject": {"text": "recurrent neural networks", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 26, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 17, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "promise", "start": 52, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 17, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "tackling", "start": 63, "end": 71, "i_start": 9, "i_end": 9}}], "id": 1601}, {"sent": "exchangecorrelation functionals were used in the perdewburke-ernzerhof form within the generalized gradient approximation .", "tokens": ["exchangecorrelation", "functionals", "were", "used", "in", "the", "perdewburke", "-", "ernzerhof", "form", "within", "the", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "exchangecorrelation functionals", "start": 0, "end": 31, "i_start": 0, "i_end": 1}, "verb": {"text": "were used", "start": 32, "end": 41, "i_start": 2, "i_end": 3}}], "id": 1602}, {"sent": "ruan , birational cobordism invariance of uniruled symplectic manifolds , invent .", "tokens": ["ruan", ",", "birational", "cobordism", "invariance", "of", "uniruled", "symplectic", "manifolds", ",", "invent", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1603}, {"sent": "thicker disks tend to have lower amplitude and more openly wound spiral density waves .", "tokens": ["thicker", "disks", "tend", "to", "have", "lower", "amplitude", "and", "more", "openly", "wound", "spiral", "density", "waves", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "thicker disks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "tend", "start": 14, "end": 18, "i_start": 2, "i_end": 2}}], "id": 1604}, {"sent": "in the image domain , deep convolutional neural networks excel in classic computer vision tasks , including natural image classification .", "tokens": ["in", "the", "image", "domain", ",", "deep", "convolutional", "neural", "networks", "excel", "in", "classic", "computer", "vision", "tasks", ",", "including", "natural", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 22, "end": 56, "i_start": 5, "i_end": 8}, "verb": {"text": "excel", "start": 57, "end": 62, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 48, "end": 56, "i_start": 8, "i_end": 8}, "action": {"text": "excel", "start": 57, "end": 62, "i_start": 9, "i_end": 9}}], "id": 1605}, {"sent": "recently , deep convolution neural networks have been applied to solve the stereo matching problem .", "tokens": ["recently", ",", "deep", "convolution", "neural", "networks", "have", "been", "applied", "to", "solve", "the", "stereo", "matching", "problem", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolution neural networks", "start": 11, "end": 43, "i_start": 2, "i_end": 5}, "verb": {"text": "have been applied", "start": 44, "end": 61, "i_start": 6, "i_end": 8}}, {"character": {"text": "networks", "start": 35, "end": 43, "i_start": 5, "i_end": 5}, "action": {"text": "solve", "start": 65, "end": 70, "i_start": 10, "i_end": 10}}], "id": 1606}, {"sent": "we present the results obtained and compare them with the available data .", "tokens": ["we", "present", "the", "results", "obtained", "and", "compare", "them", "with", "the", "available", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "present", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "present", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 36, "end": 43, "i_start": 6, "i_end": 6}}], "id": 1607}, {"sent": "the d-dimensional generalization of a polyhedron is called a polytope .", "tokens": ["the", "d", "-", "dimensional", "generalization", "of", "a", "polyhedron", "is", "called", "a", "polytope", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the d-dimensional generalization of a polyhedron", "start": 0, "end": 48, "i_start": 0, "i_end": 7}, "verb": {"text": "is called", "start": 49, "end": 58, "i_start": 8, "i_end": 9}}], "id": 1608}, {"sent": "if an orbifold m is a manifold , then the above cq coincides with the group of usual q-dimensional singular chains of m .", "tokens": ["if", "an", "orbifold", "m", "is", "a", "manifold", ",", "then", "the", "above", "cq", "coincides", "with", "the", "group", "of", "usual", "q", "-", "dimensional", "singular", "chains", "of", "m", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "cq", "start": 48, "end": 50, "i_start": 11, "i_end": 11}, "verb": {"text": "coincides", "start": 51, "end": 60, "i_start": 12, "i_end": 12}}], "id": 1609}, {"sent": "deep convolutional neural networks have achieved great success in image classification and many others .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "image", "classification", "and", "many", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}], "id": 1610}, {"sent": "a space-time is a collection of events , ie points in space and time .", "tokens": ["a", "space", "-", "time", "is", "a", "collection", "of", "events", ",", "ie", "points", "in", "space", "and", "time", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a space-time", "start": 0, "end": 12, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 4, "i_end": 4}}, {"subject": {"text": "a space-time", "start": 0, "end": 12, "i_start": 0, "i_end": 3}, "verb": {"text": "points", "start": 44, "end": 50, "i_start": 11, "i_end": 11}}], "id": 1611}, {"sent": "moreover , b is a non-negative denote the the formal identity map from x by u .", "tokens": ["moreover", ",", "b", "is", "a", "non", "-", "negative", "denote", "the", "the", "formal", "identity", "map", "from", "x", "by", "u", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "b", "start": 11, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "-negative", "start": 21, "end": 30, "i_start": 6, "i_end": 7}, "action": {"text": "denote", "start": 31, "end": 37, "i_start": 8, "i_end": 8}}], "id": 1612}, {"sent": "we used scikitlearn python library for implementing these classifiers .", "tokens": ["we", "used", "scikitlearn", "python", "library", "for", "implementing", "these", "classifiers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implementing", "start": 39, "end": 51, "i_start": 6, "i_end": 6}}], "id": 1613}, {"sent": "superconductivity is a common phenomenon occurring in certain materials at very low temperatures .", "tokens": ["superconductivity", "is", "a", "common", "phenomenon", "occurring", "in", "certain", "materials", "at", "very", "low", "temperatures", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "superconductivity", "start": 0, "end": 17, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 1, "i_end": 1}}], "id": 1614}, {"sent": "in the last two years , the performance of object detection has been significantly improved with the success of novel deep convolutional neural networks .", "tokens": ["in", "the", "last", "two", "years", ",", "the", "performance", "of", "object", "detection", "has", "been", "significantly", "improved", "with", "the", "success", "of", "novel", "deep", "convolutional", "neural", "networks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the performance of object detection", "start": 24, "end": 59, "i_start": 6, "i_end": 10}, "verb": {"text": "improved", "start": 83, "end": 91, "i_start": 14, "i_end": 14}}, {"subject": {"text": "the performance of object detection", "start": 24, "end": 59, "i_start": 6, "i_end": 10}, "verb": {"text": "has been", "start": 60, "end": 68, "i_start": 11, "i_end": 12}}, {"character": {"text": "success", "start": 101, "end": 108, "i_start": 17, "i_end": 17}, "action": {"text": "improved", "start": 83, "end": 91, "i_start": 14, "i_end": 14}}, {"character": {"text": "networks", "start": 144, "end": 152, "i_start": 23, "i_end": 23}, "action": {"text": "success", "start": 101, "end": 108, "i_start": 17, "i_end": 17}}], "id": 1615}, {"sent": "the electrons inside the dot experience the potential energy vd .", "tokens": ["the", "electrons", "inside", "the", "dot", "experience", "the", "potential", "energy", "vd", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "electrons", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "experience", "start": 29, "end": 39, "i_start": 5, "i_end": 5}}], "id": 1616}, {"sent": "the tools are available , since masas of eand ehave already been studied .", "tokens": ["the", "tools", "are", "available", ",", "since", "masas", "of", "eand", "ehave", "already", "been", "studied", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the tools", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 10, "end": 13, "i_start": 2, "i_end": 2}}], "id": 1617}, {"sent": "but it was soon realized that these five , on the face of it , different string theories are really but different 5 aspects of one overall theory , and as such are connected by what are known as dualities .", "tokens": ["but", "it", "was", "soon", "realized", "that", "these", "five", ",", "on", "the", "face", "of", "it", ",", "different", "string", "theories", "are", "really", "but", "different", "5", "aspects", "of", "one", "overall", "theory", ",", "and", "as", "such", "are", "connected", "by", "what", "are", "known", "as", "dualities", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "realized", "start": 16, "end": 24, "i_start": 4, "i_end": 4}}, {"subject": {"text": "it", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "was", "start": 7, "end": 10, "i_start": 2, "i_end": 2}}, {"subject": {"text": "it", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "are", "start": 89, "end": 92, "i_start": 18, "i_end": 18}}], "id": 1618}, {"sent": "in recent years , deep convolutional neural networks have set the state-of-the-art on a broad range of computer vision tasks .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "set", "the", "state", "-", "of", "-", "the", "-", "art", "on", "a", "broad", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have set", "start": 53, "end": 61, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "set", "start": 58, "end": 61, "i_start": 9, "i_end": 9}}], "id": 1619}, {"sent": "the errors given are from monte carlo statistics only .", "tokens": ["the", "errors", "given", "are", "from", "monte", "carlo", "statistics", "only", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the errors given", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 17, "end": 20, "i_start": 3, "i_end": 3}}], "id": 1620}, {"sent": "band structure spin polarized calculations were carried out by using the dft scheme implemented in the projector-augmented wave method , performed with the vasp package .", "tokens": ["band", "structure", "spin", "polarized", "calculations", "were", "carried", "out", "by", "using", "the", "dft", "scheme", "implemented", "in", "the", "projector", "-", "augmented", "wave", "method", ",", "performed", "with", "the", "vasp", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "band structure spin polarized calculations", "start": 0, "end": 42, "i_start": 0, "i_end": 4}, "verb": {"text": "were carried out", "start": 43, "end": 59, "i_start": 5, "i_end": 7}}, {"character": {"text": "projector", "start": 103, "end": 112, "i_start": 16, "i_end": 16}, "action": {"text": "augmented", "start": 113, "end": 122, "i_start": 18, "i_end": 18}}], "id": 1621}, {"sent": "the inflaton is the moduli for the brane distance .", "tokens": ["the", "inflaton", "is", "the", "moduli", "for", "the", "brane", "distance", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the inflaton", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 1622}, {"sent": "the fischer decomposition for the h-action reads as follows .", "tokens": ["the", "fischer", "decomposition", "for", "the", "h", "-", "action", "reads", "as", "follows", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the fischer decomposition for the h-action", "start": 0, "end": 42, "i_start": 0, "i_end": 7}, "verb": {"text": "reads", "start": 43, "end": 48, "i_start": 8, "i_end": 8}}], "id": 1623}, {"sent": "recent works prove that deep network achieves advanced performance on visual relationship reasoning .", "tokens": ["recent", "works", "prove", "that", "deep", "network", "achieves", "advanced", "performance", "on", "visual", "relationship", "reasoning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent works", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "prove", "start": 13, "end": 18, "i_start": 2, "i_end": 2}}, {"subject": {"text": "deep network", "start": 24, "end": 36, "i_start": 4, "i_end": 5}, "verb": {"text": "achieves", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "network", "start": 29, "end": 36, "i_start": 5, "i_end": 5}, "action": {"text": "achieves", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "network", "start": 29, "end": 36, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 55, "end": 66, "i_start": 8, "i_end": 8}}], "id": 1624}, {"sent": "in recent years , convolutional neural networks have shown excellent performance on classification problems when large-scale labeled datasets are available .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "shown", "excellent", "performance", "on", "classification", "problems", "when", "large", "-", "scale", "labeled", "datasets", "are", "available", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have shown", "start": 48, "end": 58, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "shown", "start": 53, "end": 58, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 69, "end": 80, "i_start": 10, "i_end": 10}}], "id": 1625}, {"sent": "deep learning approaches , especially deep convolutional neural networks , have been very successful in object detection tasks .", "tokens": ["deep", "learning", "approaches", ",", "especially", "deep", "convolutional", "neural", "networks", ",", "have", "been", "very", "successful", "in", "object", "detection", "tasks", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "deep learning approaches", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 75, "end": 84, "i_start": 10, "i_end": 11}}, {"character": {"text": "approaches", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 90, "end": 100, "i_start": 13, "i_end": 13}}], "id": 1626}, {"sent": "in recent years , there has been an explosion of deep learning models which have lead to groundbreaking results in many fields such as computer vision .", "tokens": ["in", "recent", "years", ",", "there", "has", "been", "an", "explosion", "of", "deep", "learning", "models", "which", "have", "lead", "to", "groundbreaking", "results", "in", "many", "fields", "such", "as", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 18, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "has been", "start": 24, "end": 32, "i_start": 5, "i_end": 6}}, {"character": {"text": "models", "start": 63, "end": 69, "i_start": 12, "i_end": 12}, "action": {"text": "lead", "start": 81, "end": 85, "i_start": 15, "i_end": 15}}], "id": 1627}, {"sent": "numerous quantum algorithms already exist , where many have been proven to solve certain classes of problems exponentially faster than existing algorithms for conventional computers .", "tokens": ["numerous", "quantum", "algorithms", "already", "exist", ",", "where", "many", "have", "been", "proven", "to", "solve", "certain", "classes", "of", "problems", "exponentially", "faster", "than", "existing", "algorithms", "for", "conventional", "computers", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "numerous quantum algorithms", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "exist", "start": 36, "end": 41, "i_start": 4, "i_end": 4}}, {"character": {"text": "algorithms", "start": 17, "end": 27, "i_start": 2, "i_end": 2}, "action": {"text": "solve", "start": 75, "end": 80, "i_start": 12, "i_end": 12}}], "id": 1628}, {"sent": "we used relu nonlinearities for the hidden layers and trained using adam and early stopping .", "tokens": ["we", "used", "relu", "nonlinearities", "for", "the", "hidden", "layers", "and", "trained", "using", "adam", "and", "early", "stopping", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "trained", "start": 54, "end": 61, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "trained", "start": 54, "end": 61, "i_start": 9, "i_end": 9}}], "id": 1629}, {"sent": "the dashed curve corresponds to the high temperature behaviour obtained in .", "tokens": ["the", "dashed", "curve", "corresponds", "to", "the", "high", "temperature", "behaviour", "obtained", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dashed curve", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "corresponds", "start": 17, "end": 28, "i_start": 3, "i_end": 3}}], "id": 1630}, {"sent": "the blobs denote light-cone wave functions , and all possible configurations of spectator partons have to be summed over .", "tokens": ["the", "blobs", "denote", "light", "-", "cone", "wave", "functions", ",", "and", "all", "possible", "configurations", "of", "spectator", "partons", "have", "to", "be", "summed", "over", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the blobs denote light-cone wave functions , and all possible configurations of spectator partons", "start": 0, "end": 97, "i_start": 0, "i_end": 15}, "verb": {"text": "have", "start": 98, "end": 102, "i_start": 16, "i_end": 16}}, {"character": {"text": "blobs", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 10, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1631}, {"sent": "phd thesis , de partment of computer science , university of north carolina .", "tokens": ["phd", "thesis", ",", "de", "partment", "of", "computer", "science", ",", "university", "of", "north", "carolina", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1632}, {"sent": "stanley defined a symmetric function refinement of the chromatic polynomial , called the chromatic symmetric function of a graph .", "tokens": ["stanley", "defined", "a", "symmetric", "function", "refinement", "of", "the", "chromatic", "polynomial", ",", "called", "the", "chromatic", "symmetric", "function", "of", "a", "graph", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "stanley", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "defined", "start": 8, "end": 15, "i_start": 1, "i_end": 1}}, {"subject": {"text": "stanley", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "called", "start": 78, "end": 84, "i_start": 11, "i_end": 11}}, {"character": {"text": "stanley", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "defined", "start": 8, "end": 15, "i_start": 1, "i_end": 1}}], "id": 1633}, {"sent": "from the mathemat-ical view , the analog precoders in mmwave massive mimo with lens antenna array have stronger constraint .", "tokens": ["from", "the", "mathemat", "-", "ical", "view", ",", "the", "analog", "precoders", "in", "mmwave", "massive", "mimo", "with", "lens", "antenna", "array", "have", "stronger", "constraint", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the analog precoders in mmwave massive mimo with lens antenna array", "start": 30, "end": 97, "i_start": 7, "i_end": 17}, "verb": {"text": "have", "start": 98, "end": 102, "i_start": 18, "i_end": 18}}], "id": 1634}, {"sent": "deep neural networks have been highly successful at recognition tasks , such as image and speech recognition , and natural language processing .", "tokens": ["deep", "neural", "networks", "have", "been", "highly", "successful", "at", "recognition", "tasks", ",", "such", "as", "image", "and", "speech", "recognition", ",", "and", "natural", "language", "processing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 38, "end": 48, "i_start": 6, "i_end": 6}}], "id": 1635}, {"sent": "in figure 25 , we simulate the si and sir models on the us airline network for 500 of the busiest airports .", "tokens": ["in", "figure", "25", ",", "we", "simulate", "the", "si", "and", "sir", "models", "on", "the", "us", "airline", "network", "for", "500", "of", "the", "busiest", "airports", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "simulate", "start": 18, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "simulate", "start": 18, "end": 26, "i_start": 5, "i_end": 5}}], "id": 1636}, {"sent": "the concept of simple and semisimple quad rings is defined in an analogous way as in case of birings .", "tokens": ["the", "concept", "of", "simple", "and", "semisimple", "quad", "rings", "is", "defined", "in", "an", "analogous", "way", "as", "in", "case", "of", "birings", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the concept of simple and semisimple quad rings", "start": 0, "end": 47, "i_start": 0, "i_end": 7}, "verb": {"text": "is defined", "start": 48, "end": 58, "i_start": 8, "i_end": 9}}], "id": 1637}, {"sent": "in recent years , deep convolutional neural networks have achieved impressive results in a number of computer vision tasks such as image classification .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "achieved", "impressive", "results", "in", "a", "number", "of", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have achieved", "start": 53, "end": 66, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 58, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "results", "start": 78, "end": 85, "i_start": 11, "i_end": 11}, "action": {"text": "impressive", "start": 67, "end": 77, "i_start": 10, "i_end": 10}}], "id": 1638}, {"sent": "deep neural networks have seen great success in many cognitive applications such as image classification .", "tokens": ["deep", "neural", "networks", "have", "seen", "great", "success", "in", "many", "cognitive", "applications", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have seen", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 37, "end": 44, "i_start": 6, "i_end": 6}}], "id": 1639}, {"sent": "monti et al presented mixture model cnns , a spatial approach which provides a unified generalization of cnn architectures to graphs .", "tokens": ["monti", "et", "al", "presented", "mixture", "model", "cnns", ",", "a", "spatial", "approach", "which", "provides", "a", "unified", "generalization", "of", "cnn", "architectures", "to", "graphs", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 6, "end": 11, "i_start": 1, "i_end": 2}, "verb": {"text": "presented", "start": 12, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "monti", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "presented", "start": 12, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "approach", "start": 53, "end": 61, "i_start": 10, "i_end": 10}, "action": {"text": "provides", "start": 68, "end": 76, "i_start": 12, "i_end": 12}}], "id": 1640}, {"sent": "a few recent works adopted cnn structures as embedding functions , and use triplet losses instead of pairwise constraints to learn the model .", "tokens": ["a", "few", "recent", "works", "adopted", "cnn", "structures", "as", "embedding", "functions", ",", "and", "use", "triplet", "losses", "instead", "of", "pairwise", "constraints", "to", "learn", "the", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a few recent works", "start": 0, "end": 18, "i_start": 0, "i_end": 3}, "verb": {"text": "adopted", "start": 19, "end": 26, "i_start": 4, "i_end": 4}}, {"subject": {"text": "a few recent works", "start": 0, "end": 18, "i_start": 0, "i_end": 3}, "verb": {"text": "use", "start": 71, "end": 74, "i_start": 12, "i_end": 12}}, {"character": {"text": "works", "start": 13, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "adopted", "start": 19, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "works", "start": 13, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 71, "end": 74, "i_start": 12, "i_end": 12}}, {"character": {"text": "works", "start": 13, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "learn", "start": 125, "end": 130, "i_start": 20, "i_end": 20}}], "id": 1641}, {"sent": "deep neural networks have achieved impressive performance on tasks across a variety of domains , including vision .", "tokens": ["deep", "neural", "networks", "have", "achieved", "impressive", "performance", "on", "tasks", "across", "a", "variety", "of", "domains", ",", "including", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 46, "end": 57, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 46, "end": 57, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 35, "end": 45, "i_start": 5, "i_end": 5}}], "id": 1642}, {"sent": "the maximum and the average value is shown .", "tokens": ["the", "maximum", "and", "the", "average", "value", "is", "shown", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the maximum and the average value", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "is shown", "start": 34, "end": 42, "i_start": 6, "i_end": 7}}], "id": 1643}, {"sent": "the exchange and correlation effects were taken into account within the generalized gradient approximation .", "tokens": ["the", "exchange", "and", "correlation", "effects", "were", "taken", "into", "account", "within", "the", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange and correlation effects", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "were taken", "start": 37, "end": 47, "i_start": 5, "i_end": 6}}], "id": 1644}, {"sent": "since the deuteron is a weakly bound system , its wave function will not allow too large values of longitudinal transfer \u03be .", "tokens": ["since", "the", "deuteron", "is", "a", "weakly", "bound", "system", ",", "its", "wave", "function", "will", "not", "allow", "too", "large", "values", "of", "longitudinal", "transfer", "\u03be", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "its wave function", "start": 46, "end": 63, "i_start": 9, "i_end": 11}, "verb": {"text": "will not allow", "start": 64, "end": 78, "i_start": 12, "i_end": 14}}, {"character": {"text": "function", "start": 55, "end": 63, "i_start": 11, "i_end": 11}, "action": {"text": "not allow", "start": 69, "end": 78, "i_start": 13, "i_end": 14}}, {"character": {"text": "deuteron", "start": 10, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "function", "start": 55, "end": 63, "i_start": 11, "i_end": 11}}], "id": 1645}, {"sent": "we find that the latest-type spirals have on average less molecular gas and lower molecular gas mass fractions in their central regions than their early-type cousins .", "tokens": ["we", "find", "that", "the", "latest", "-", "type", "spirals", "have", "on", "average", "less", "molecular", "gas", "and", "lower", "molecular", "gas", "mass", "fractions", "in", "their", "central", "regions", "than", "their", "early", "-", "type", "cousins", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the latest-type spirals", "start": 13, "end": 36, "i_start": 3, "i_end": 7}, "verb": {"text": "have", "start": 37, "end": 41, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "spirals", "start": 29, "end": 36, "i_start": 7, "i_end": 7}, "action": {"text": "have", "start": 37, "end": 41, "i_start": 8, "i_end": 8}}], "id": 1646}, {"sent": "deep neural networks have achieved remarkable results in computer vision , natural language processing , and speech recognition areas .", "tokens": ["deep", "neural", "networks", "have", "achieved", "remarkable", "results", "in", "computer", "vision", ",", "natural", "language", "processing", ",", "and", "speech", "recognition", "areas", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}], "id": 1647}, {"sent": "next we proceed onto define the notion of matrix groupoids of type iii .", "tokens": ["next", "we", "proceed", "onto", "define", "the", "notion", "of", "matrix", "groupoids", "of", "type", "iii", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 21, "end": 27, "i_start": 4, "i_end": 4}}], "id": 1648}, {"sent": "deep networks have been applied to almost all computer vision tasks and have achieved state-of-the-art performances , such as image classification .", "tokens": ["deep", "networks", "have", "been", "applied", "to", "almost", "all", "computer", "vision", "tasks", "and", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performances", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep networks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "have been applied", "start": 14, "end": 31, "i_start": 2, "i_end": 4}}, {"subject": {"text": "deep networks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "achieved", "start": 77, "end": 85, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "achieved", "start": 77, "end": 85, "i_start": 13, "i_end": 13}}], "id": 1649}, {"sent": "the training of deep networks has been largely addressed by normalized initialization .", "tokens": ["the", "training", "of", "deep", "networks", "has", "been", "largely", "addressed", "by", "normalized", "initialization", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the training of deep networks", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "addressed", "start": 47, "end": 56, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the training of deep networks", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "has been", "start": 30, "end": 38, "i_start": 5, "i_end": 6}}, {"character": {"text": "initialization", "start": 71, "end": 85, "i_start": 11, "i_end": 11}, "action": {"text": "addressed", "start": 47, "end": 56, "i_start": 8, "i_end": 8}}], "id": 1650}, {"sent": "this then ensures that the three supersymmetry constraint equations are invariant under \u03c1 .", "tokens": ["this", "then", "ensures", "that", "the", "three", "supersymmetry", "constraint", "equations", "are", "invariant", "under", "\u03c1", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "ensures", "start": 10, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 68, "end": 71, "i_start": 9, "i_end": 9}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "ensures", "start": 10, "end": 17, "i_start": 2, "i_end": 2}}], "id": 1651}, {"sent": "convolutional neural networks have achieved superior performance in various tasks .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "various", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 6, "i_end": 6}}], "id": 1652}, {"sent": "deep neural networks have been extensively applied in many fields , such as image recognition .", "tokens": ["deep", "neural", "networks", "have", "been", "extensively", "applied", "in", "many", "fields", ",", "such", "as", "image", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "applied", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}], "id": 1653}, {"sent": "bose-einstein condensation of trapped atoms has been a hot topic in recent years , intensively investigated both experimentally and theoretically .", "tokens": ["bose", "-", "einstein", "condensation", "of", "trapped", "atoms", "has", "been", "a", "hot", "topic", "in", "recent", "years", ",", "intensively", "investigated", "both", "experimentally", "and", "theoretically", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "bose-einstein condensation of trapped atoms", "start": 0, "end": 43, "i_start": 0, "i_end": 6}, "verb": {"text": "has been", "start": 44, "end": 52, "i_start": 7, "i_end": 8}}], "id": 1654}, {"sent": "deep neural networks have been evolved to powerful predictive models with remarkable performance on computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "been", "evolved", "to", "powerful", "predictive", "models", "with", "remarkable", "performance", "on", "computer", "vision", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been evolved", "start": 21, "end": 38, "i_start": 3, "i_end": 5}}, {"character": {"text": "models", "start": 62, "end": 68, "i_start": 9, "i_end": 9}, "action": {"text": "predictive", "start": 51, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "models", "start": 62, "end": 68, "i_start": 9, "i_end": 9}, "action": {"text": "performance", "start": 85, "end": 96, "i_start": 12, "i_end": 12}}], "id": 1655}, {"sent": "we compare our proposed srsenet with several state-of-the-art methods such as srcnn .", "tokens": ["we", "compare", "our", "proposed", "srsenet", "with", "several", "state", "-", "of", "-", "the", "-", "art", "methods", "such", "as", "srcnn", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 1656}, {"sent": "popular approaches include class activation maps , gradient-weighted class activation mapping , and excitation backprop .", "tokens": ["popular", "approaches", "include", "class", "activation", "maps", ",", "gradient", "-", "weighted", "class", "activation", "mapping", ",", "and", "excitation", "backprop", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "popular approaches", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "include", "start": 19, "end": 26, "i_start": 2, "i_end": 2}}], "id": 1657}, {"sent": "deep convolutional neural networks have achieved dramatic accuracy improvements in many areas of computer vision .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "dramatic", "accuracy", "improvements", "in", "many", "areas", "of", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "improvements", "start": 67, "end": 79, "i_start": 8, "i_end": 8}}], "id": 1658}, {"sent": "there are spin-modulated contributions to the ultraviolet flux by the accretion funnel and by the heated white dwarf .", "tokens": ["there", "are", "spin", "-", "modulated", "contributions", "to", "the", "ultraviolet", "flux", "by", "the", "accretion", "funnel", "and", "by", "the", "heated", "white", "dwarf", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 6, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "funnel", "start": 80, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "contributions", "start": 25, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "accretion", "start": 70, "end": 79, "i_start": 12, "i_end": 12}, "action": {"text": "contributions", "start": 25, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "dwarf", "start": 111, "end": 116, "i_start": 19, "i_end": 19}, "action": {"text": "contributions", "start": 25, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "white", "start": 105, "end": 110, "i_start": 18, "i_end": 18}, "action": {"text": "contributions", "start": 25, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "spin", "start": 10, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "modulated", "start": 15, "end": 24, "i_start": 4, "i_end": 4}}], "id": 1659}, {"sent": "machine learning has shown great success in building models for pattern recognition in domains ranging from computer vision .", "tokens": ["machine", "learning", "has", "shown", "great", "success", "in", "building", "models", "for", "pattern", "recognition", "in", "domains", "ranging", "from", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "machine learning", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "has shown", "start": 17, "end": 26, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 8, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "success", "start": 33, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "learning", "start": 8, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "building", "start": 44, "end": 52, "i_start": 7, "i_end": 7}}], "id": 1660}, {"sent": "neural networks and deep learning recently produced numerous exciting results in pattern recognition and machine intelligence .", "tokens": ["neural", "networks", "and", "deep", "learning", "recently", "produced", "numerous", "exciting", "results", "in", "pattern", "recognition", "and", "machine", "intelligence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural networks and deep learning", "start": 0, "end": 33, "i_start": 0, "i_end": 4}, "verb": {"text": "produced", "start": 43, "end": 51, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "produced", "start": 43, "end": 51, "i_start": 6, "i_end": 6}}, {"character": {"text": "learning", "start": 25, "end": 33, "i_start": 4, "i_end": 4}, "action": {"text": "produced", "start": 43, "end": 51, "i_start": 6, "i_end": 6}}, {"character": {"text": "results", "start": 70, "end": 77, "i_start": 9, "i_end": 9}, "action": {"text": "exciting", "start": 61, "end": 69, "i_start": 8, "i_end": 8}}], "id": 1661}, {"sent": "is open in in case when supp is called a strictly vertical foliation .", "tokens": ["is", "open", "in", "in", "case", "when", "supp", "is", "called", "a", "strictly", "vertical", "foliation", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1662}, {"sent": "stegeman , classical harmonic analysis and locally compact abelian groups .", "tokens": ["stegeman", ",", "classical", "harmonic", "analysis", "and", "locally", "compact", "abelian", "groups", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1663}, {"sent": "in this model , the channel is assumed to remain constant over a block of t symbols and to change in an independent fashion from block to block .", "tokens": ["in", "this", "model", ",", "the", "channel", "is", "assumed", "to", "remain", "constant", "over", "a", "block", "of", "t", "symbols", "and", "to", "change", "in", "an", "independent", "fashion", "from", "block", "to", "block", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the channel", "start": 16, "end": 27, "i_start": 4, "i_end": 5}, "verb": {"text": "is assumed", "start": 28, "end": 38, "i_start": 6, "i_end": 7}}], "id": 1664}, {"sent": "he et al use the residual learning framework to ease the training of networks .", "tokens": ["he", "et", "al", "use", "the", "residual", "learning", "framework", "to", "ease", "the", "training", "of", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "he et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "use", "start": 9, "end": 12, "i_start": 3, "i_end": 3}}, {"character": {"text": "he", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 9, "end": 12, "i_start": 3, "i_end": 3}}, {"character": {"text": "he", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "ease", "start": 48, "end": 52, "i_start": 9, "i_end": 9}}], "id": 1665}, {"sent": "the ellipsis denotes other terms coming from the time derivative that do not contribute to the diffusive effects .", "tokens": ["the", "ellipsis", "denotes", "other", "terms", "coming", "from", "the", "time", "derivative", "that", "do", "not", "contribute", "to", "the", "diffusive", "effects", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ellipsis", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "denotes", "start": 13, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "ellipsis", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denotes", "start": 13, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "terms", "start": 27, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "not contribute", "start": 73, "end": 87, "i_start": 12, "i_end": 13}}], "id": 1666}, {"sent": "other parameter values are same as those in figure .", "tokens": ["other", "parameter", "values", "are", "same", "as", "those", "in", "figure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "other parameter values", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 23, "end": 26, "i_start": 3, "i_end": 3}}], "id": 1667}, {"sent": "to avoid the costly eigenvalue decomposition , defferrard et al used chebyshev polynomials to define localized filters .", "tokens": ["to", "avoid", "the", "costly", "eigenvalue", "decomposition", ",", "defferrard", "et", "al", "used", "chebyshev", "polynomials", "to", "define", "localized", "filters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "defferrard et al", "start": 47, "end": 63, "i_start": 7, "i_end": 9}, "verb": {"text": "used", "start": 64, "end": 68, "i_start": 10, "i_end": 10}}, {"character": {"text": "defferrard", "start": 47, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "used", "start": 64, "end": 68, "i_start": 10, "i_end": 10}}, {"character": {"text": "defferrard", "start": 47, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "define", "start": 94, "end": 100, "i_start": 14, "i_end": 14}}, {"character": {"text": "defferrard", "start": 47, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "avoid", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 1668}, {"sent": "thus there is no scale of fermion mass generation in the standard model .", "tokens": ["thus", "there", "is", "no", "scale", "of", "fermion", "mass", "generation", "in", "the", "standard", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 5, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}], "id": 1669}, {"sent": "the left panel shows result from ppm solver and the right panel shows result from mhd solver .", "tokens": ["the", "left", "panel", "shows", "result", "from", "ppm", "solver", "and", "the", "right", "panel", "shows", "result", "from", "mhd", "solver", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the left panel", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "shows", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the right panel", "start": 48, "end": 63, "i_start": 9, "i_end": 11}, "verb": {"text": "shows", "start": 64, "end": 69, "i_start": 12, "i_end": 12}}, {"character": {"text": "panel", "start": 9, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "shows", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}], "id": 1670}, {"sent": "conversely , in the reversely degraded relay channel , channel outputs obtained by the relay are more noisy than those obtained by the receiver .", "tokens": ["conversely", ",", "in", "the", "reversely", "degraded", "relay", "channel", ",", "channel", "outputs", "obtained", "by", "the", "relay", "are", "more", "noisy", "than", "those", "obtained", "by", "the", "receiver", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "channel outputs obtained by the relay", "start": 55, "end": 92, "i_start": 9, "i_end": 14}, "verb": {"text": "are", "start": 93, "end": 96, "i_start": 15, "i_end": 15}}, {"character": {"text": "relay", "start": 39, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "obtained", "start": 71, "end": 79, "i_start": 11, "i_end": 11}}, {"character": {"text": "receiver", "start": 135, "end": 143, "i_start": 23, "i_end": 23}, "action": {"text": "obtained", "start": 119, "end": 127, "i_start": 20, "i_end": 20}}, {"character": {"text": "channel", "start": 55, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "relay", "start": 87, "end": 92, "i_start": 14, "i_end": 14}}], "id": 1671}, {"sent": "imaging and self-calibration were performed using the difmap software package .", "tokens": ["imaging", "and", "self", "-", "calibration", "were", "performed", "using", "the", "difmap", "software", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "imaging and self-calibration", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "were performed", "start": 29, "end": 43, "i_start": 5, "i_end": 6}}], "id": 1672}, {"sent": "the trade-off is a slightly enlarged statistical uncertainty , since more cbo related parameters are fitted .", "tokens": ["the", "trade", "-", "off", "is", "a", "slightly", "enlarged", "statistical", "uncertainty", ",", "since", "more", "cbo", "related", "parameters", "are", "fitted", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the trade-off", "start": 0, "end": 13, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 4, "i_end": 4}}], "id": 1673}, {"sent": "one paradigm driving progress is deep reinforcement learning , which uses deep learning .", "tokens": ["one", "paradigm", "driving", "progress", "is", "deep", "reinforcement", "learning", ",", "which", "uses", "deep", "learning", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "one paradigm driving progress", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 52, "end": 60, "i_start": 7, "i_end": 7}, "action": {"text": "uses", "start": 69, "end": 73, "i_start": 10, "i_end": 10}}, {"character": {"text": "one paradigm", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "action": {"text": "driving", "start": 13, "end": 20, "i_start": 2, "i_end": 2}}], "id": 1674}, {"sent": "however , it is very unlikely that the detected residual non-gaussianity can be canceled exactly .", "tokens": ["however", ",", "it", "is", "very", "unlikely", "that", "the", "detected", "residual", "non", "-", "gaussianity", "can", "be", "canceled", "exactly", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the detected residual non-gaussianity", "start": 35, "end": 72, "i_start": 7, "i_end": 12}, "verb": {"text": "canceled", "start": 80, "end": 88, "i_start": 15, "i_end": 15}}], "id": 1675}, {"sent": "deep convolutional neural networks have improved performance across a wider variety of computer vision tasks , especially for image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "improved", "performance", "across", "a", "wider", "variety", "of", "computer", "vision", "tasks", ",", "especially", "for", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have improved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}], "id": 1676}, {"sent": "firstly we consider josephson junctions where the two superconductors have the spin-singlet cooper pairs .", "tokens": ["firstly", "we", "consider", "josephson", "junctions", "where", "the", "two", "superconductors", "have", "the", "spin", "-", "singlet", "cooper", "pairs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "consider", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "consider", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "two superconductors", "start": 50, "end": 69, "i_start": 7, "i_end": 8}, "action": {"text": "have", "start": 70, "end": 74, "i_start": 9, "i_end": 9}}], "id": 1677}, {"sent": "deep learning approaches have become very popular over the last few years in machine learning applications .", "tokens": ["deep", "learning", "approaches", "have", "become", "very", "popular", "over", "the", "last", "few", "years", "in", "machine", "learning", "applications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning approaches", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "have become", "start": 25, "end": 36, "i_start": 3, "i_end": 4}}], "id": 1678}, {"sent": "breglera et al presented an image-based approach called video rewrite to automatically create a new video of a person with generated mouth movements .", "tokens": ["breglera", "et", "al", "presented", "an", "image", "-", "based", "approach", "called", "video", "rewrite", "to", "automatically", "create", "a", "new", "video", "of", "a", "person", "with", "generated", "mouth", "movements", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "breglera et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "presented", "start": 15, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "person", "start": 111, "end": 117, "i_start": 20, "i_end": 20}, "action": {"text": "presented", "start": 15, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "breglera", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "presented", "start": 15, "end": 24, "i_start": 3, "i_end": 3}}], "id": 1679}, {"sent": "the so -supersymmetric gauge theory rotates both the scalars and the fermions of the gauge multiplet .", "tokens": ["the", "so", "-supersymmetric", "gauge", "theory", "rotates", "both", "the", "scalars", "and", "the", "fermions", "of", "the", "gauge", "multiplet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the so -supersymmetric gauge theory", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "rotates", "start": 36, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "theory", "start": 29, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "rotates", "start": 36, "end": 43, "i_start": 5, "i_end": 5}}], "id": 1680}, {"sent": "each binding energy is the average value of the onset energy extracted from various spectra and the error bar is the corresponding mean deviation .", "tokens": ["each", "binding", "energy", "is", "the", "average", "value", "of", "the", "onset", "energy", "extracted", "from", "various", "spectra", "and", "the", "error", "bar", "is", "the", "corresponding", "mean", "deviation", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "each binding energy", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "energy", "start": 13, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "binding", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}], "id": 1681}, {"sent": "the tensor-vector-scalar theory and its cosmology .", "tokens": ["the", "tensor", "-", "vector", "-", "scalar", "theory", "and", "its", "cosmology", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1682}, {"sent": "neural network based methods have recently demonstrated promising results on many natural language processing tasks .", "tokens": ["neural", "network", "based", "methods", "have", "recently", "demonstrated", "promising", "results", "on", "many", "natural", "language", "processing", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural network based methods", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "demonstrated", "start": 43, "end": 55, "i_start": 6, "i_end": 6}}, {"subject": {"text": "neural network based methods", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 29, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "methods", "start": 21, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "demonstrated", "start": 43, "end": 55, "i_start": 6, "i_end": 6}}, {"character": {"text": "results", "start": 66, "end": 73, "i_start": 8, "i_end": 8}, "action": {"text": "promising", "start": 56, "end": 65, "i_start": 7, "i_end": 7}}], "id": 1683}, {"sent": "large datasets like mscoco are instrumental in promoting object detection and image captioning research .", "tokens": ["large", "datasets", "like", "mscoco", "are", "instrumental", "in", "promoting", "object", "detection", "and", "image", "captioning", "research", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "large datasets like mscoco", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 27, "end": 30, "i_start": 4, "i_end": 4}}], "id": 1684}, {"sent": "our solver shows performance comparable to state-of-the-art l 0 minimization , while running faster .", "tokens": ["our", "solver", "shows", "performance", "comparable", "to", "state", "-", "of", "-", "the", "-", "art", "l", "0", "minimization", ",", "while", "running", "faster", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our solver", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "shows", "start": 11, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1685}, {"sent": "bayesian optimisation is a leading method for global optimisation for expensive black-box functions .", "tokens": ["bayesian", "optimisation", "is", "a", "leading", "method", "for", "global", "optimisation", "for", "expensive", "black", "-", "box", "functions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "bayesian optimisation", "start": 0, "end": 21, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "method", "start": 35, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "leading", "start": 27, "end": 34, "i_start": 4, "i_end": 4}}], "id": 1686}, {"sent": "large mimo is believed to be one of the key technologies for 5g wireless systems .", "tokens": ["large", "mimo", "is", "believed", "to", "be", "one", "of", "the", "key", "technologies", "for", "5", "g", "wireless", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "large mimo", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is believed", "start": 11, "end": 22, "i_start": 2, "i_end": 3}}], "id": 1687}, {"sent": "teleportation is a linear operation , which also work with mixed states .", "tokens": ["teleportation", "is", "a", "linear", "operation", ",", "which", "also", "work", "with", "mixed", "states", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "teleportation", "start": 0, "end": 13, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "operation", "start": 26, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "work", "start": 49, "end": 53, "i_start": 8, "i_end": 8}}], "id": 1688}, {"sent": "by taking some high order dominant corrections , we found that the symmetry is restored at high temperature for lh .", "tokens": ["by", "taking", "some", "high", "order", "dominant", "corrections", ",", "we", "found", "that", "the", "symmetry", "is", "restored", "at", "high", "temperature", "for", "lh", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 49, "end": 51, "i_start": 8, "i_end": 8}, "verb": {"text": "found", "start": 52, "end": 57, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the symmetry", "start": 63, "end": 75, "i_start": 11, "i_end": 12}, "verb": {"text": "restored", "start": 79, "end": 87, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 8, "i_end": 8}, "action": {"text": "found", "start": 52, "end": 57, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 8, "i_end": 8}, "action": {"text": "restored", "start": 79, "end": 87, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 8, "i_end": 8}, "action": {"text": "corrections", "start": 35, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "corrections", "start": 35, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "dominant", "start": 26, "end": 34, "i_start": 5, "i_end": 5}}], "id": 1689}, {"sent": "eaton and hull independently proved that every planar graph is 2-defective 3-choosable and every outerplanar graph is 2-defective 2-choosable .", "tokens": ["eaton", "and", "hull", "independently", "proved", "that", "every", "planar", "graph", "is", "2", "-", "defective", "3", "-", "choosable", "and", "every", "outerplanar", "graph", "is", "2", "-", "defective", "2", "-", "choosable", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "eaton and hull", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "proved", "start": 29, "end": 35, "i_start": 4, "i_end": 4}}, {"subject": {"text": "eaton and hull", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 60, "end": 62, "i_start": 9, "i_end": 9}}, {"character": {"text": "eaton", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proved", "start": 29, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "hull", "start": 10, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "proved", "start": 29, "end": 35, "i_start": 4, "i_end": 4}}], "id": 1690}, {"sent": "in fbg feedback configuration , the laser frequency has to be tuned to edges of the main lobe of fbg reflection spectrum , which leads to a significant power loss in reflection , weakening the feedback strength to the semiconductor laser .", "tokens": ["in", "fbg", "feedback", "configuration", ",", "the", "laser", "frequency", "has", "to", "be", "tuned", "to", "edges", "of", "the", "main", "lobe", "of", "fbg", "reflection", "spectrum", ",", "which", "leads", "to", "a", "significant", "power", "loss", "in", "reflection", ",", "weakening", "the", "feedback", "strength", "to", "the", "semiconductor", "laser", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the laser frequency", "start": 32, "end": 51, "i_start": 5, "i_end": 7}, "verb": {"text": "has", "start": 52, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "tuned", "start": 62, "end": 67, "i_start": 11, "i_end": 11}, "action": {"text": "leads", "start": 129, "end": 134, "i_start": 24, "i_end": 24}}, {"character": {"text": "leads", "start": 129, "end": 134, "i_start": 24, "i_end": 24}, "action": {"text": "weakening", "start": 179, "end": 188, "i_start": 33, "i_end": 33}}], "id": 1691}, {"sent": "superscripts m will denote minkowski coordinates , while superscripts e will refer to euclidean coordinates .", "tokens": ["superscripts", "m", "will", "denote", "minkowski", "coordinates", ",", "while", "superscripts", "e", "will", "refer", "to", "euclidean", "coordinates", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "superscripts m", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "will denote", "start": 15, "end": 26, "i_start": 2, "i_end": 3}}, {"character": {"text": "superscripts", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 20, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "superscripts", "start": 57, "end": 69, "i_start": 8, "i_end": 8}, "action": {"text": "refer", "start": 77, "end": 82, "i_start": 11, "i_end": 11}}], "id": 1692}, {"sent": "deep neural networks have been showing impressive performance in a variety of applications in multiple domains .", "tokens": ["deep", "neural", "networks", "have", "been", "showing", "impressive", "performance", "in", "a", "variety", "of", "applications", "in", "multiple", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been showing", "start": 21, "end": 38, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "showing", "start": 31, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 50, "end": 61, "i_start": 7, "i_end": 7}}, {"character": {"text": "performance", "start": 50, "end": 61, "i_start": 7, "i_end": 7}, "action": {"text": "impressive", "start": 39, "end": 49, "i_start": 6, "i_end": 6}}], "id": 1693}, {"sent": "we minimized the standard negative log-likelihood loss using the adam algorithm .", "tokens": ["we", "minimized", "the", "standard", "negative", "log", "-", "likelihood", "loss", "using", "the", "adam", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "minimized", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "minimized", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 55, "end": 60, "i_start": 9, "i_end": 9}}], "id": 1694}, {"sent": "in , iterative algorithms were proposed to reduce the total system backhaul capacity consumption while guaranteeing reliable communication to the mobile users .", "tokens": ["in", ",", "iterative", "algorithms", "were", "proposed", "to", "reduce", "the", "total", "system", "backhaul", "capacity", "consumption", "while", "guaranteeing", "reliable", "communication", "to", "the", "mobile", "users", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "iterative algorithms", "start": 5, "end": 25, "i_start": 2, "i_end": 3}, "verb": {"text": "were proposed", "start": 26, "end": 39, "i_start": 4, "i_end": 5}}, {"character": {"text": "algorithms", "start": 15, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "reduce", "start": 43, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "system", "start": 60, "end": 66, "i_start": 10, "i_end": 10}, "action": {"text": "consumption", "start": 85, "end": 96, "i_start": 13, "i_end": 13}}, {"character": {"text": "algorithms", "start": 15, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "guaranteeing", "start": 103, "end": 115, "i_start": 15, "i_end": 15}}], "id": 1695}, {"sent": "gromov introduced various concepts and invariants in the mm-space framework .", "tokens": ["gromov", "introduced", "various", "concepts", "and", "invariants", "in", "the", "mm", "-", "space", "framework", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "gromov", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "introduced", "start": 7, "end": 17, "i_start": 1, "i_end": 1}}, {"character": {"text": "gromov", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 7, "end": 17, "i_start": 1, "i_end": 1}}], "id": 1696}, {"sent": "for the shared encoder , we use the resnet-50 to produce rich and contextual features .", "tokens": ["for", "the", "shared", "encoder", ",", "we", "use", "the", "resnet-50", "to", "produce", "rich", "and", "contextual", "features", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 28, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 28, "end": 31, "i_start": 6, "i_end": 6}}], "id": 1697}, {"sent": "deep neural networks have recently garnered widespread interest due to their demonstrated ability to improve state-of-the-art performance in many challenging areas of research .", "tokens": ["deep", "neural", "networks", "have", "recently", "garnered", "widespread", "interest", "due", "to", "their", "demonstrated", "ability", "to", "improve", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "many", "challenging", "areas", "of", "research", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "garnered", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "garnered", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improve", "start": 101, "end": 108, "i_start": 14, "i_end": 14}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 126, "end": 137, "i_start": 22, "i_end": 22}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 77, "end": 89, "i_start": 11, "i_end": 11}}], "id": 1698}, {"sent": "the shanghaitech dataset contains 1198 images of crowded scenes with a total of 330,165 head annotations included .", "tokens": ["the", "shanghaitech", "dataset", "contains", "1198", "images", "of", "crowded", "scenes", "with", "a", "total", "of", "330,165", "head", "annotations", "included", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the shanghaitech dataset", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "contains", "start": 25, "end": 33, "i_start": 3, "i_end": 3}}, {"character": {"text": "dataset", "start": 17, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "contains", "start": 25, "end": 33, "i_start": 3, "i_end": 3}}], "id": 1699}, {"sent": "most importantly , we achieved these results without learning any attribute classifiers , as in .", "tokens": ["most", "importantly", ",", "we", "achieved", "these", "results", "without", "learning", "any", "attribute", "classifiers", ",", "as", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 3, "i_end": 3}, "verb": {"text": "achieved", "start": 22, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 22, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "learning", "start": 53, "end": 61, "i_start": 8, "i_end": 8}}], "id": 1700}, {"sent": "every completely simple semigroup is weakly cancellative , but not separative .", "tokens": ["every", "completely", "simple", "semigroup", "is", "weakly", "cancellative", ",", "but", "not", "separative", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "every completely simple semigroup", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 4, "i_end": 4}}, {"character": {"text": "semigroup", "start": 24, "end": 33, "i_start": 3, "i_end": 3}, "action": {"text": "not separative", "start": 63, "end": 77, "i_start": 9, "i_end": 10}}], "id": 1701}, {"sent": "the cox proportional hazards model is widely used for survival analysis .", "tokens": ["the", "cox", "proportional", "hazards", "model", "is", "widely", "used", "for", "survival", "analysis", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the cox proportional hazards model", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "used", "start": 45, "end": 49, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the cox proportional hazards model", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 5, "i_end": 5}}], "id": 1702}, {"sent": "the proof is left as an exercise for the reader .", "tokens": ["the", "proof", "is", "left", "as", "an", "exercise", "for", "the", "reader", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the proof", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is left", "start": 10, "end": 17, "i_start": 2, "i_end": 3}}], "id": 1703}, {"sent": "recent work has shown that two speech recognition models , a convolutional neural network model trained on the speech commands dataset , are vulnerable to adversarial attacks .", "tokens": ["recent", "work", "has", "shown", "that", "two", "speech", "recognition", "models", ",", "a", "convolutional", "neural", "network", "model", "trained", "on", "the", "speech", "commands", "dataset", ",", "are", "vulnerable", "to", "adversarial", "attacks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent work", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "has shown", "start": 12, "end": 21, "i_start": 2, "i_end": 3}}, {"subject": {"text": "a convolutional neural network model trained on the speech", "start": 59, "end": 117, "i_start": 10, "i_end": 18}, "verb": {"text": "commands", "start": 118, "end": 126, "i_start": 19, "i_end": 19}}, {"character": {"text": "work", "start": 7, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "shown", "start": 16, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "two speech recognition models", "start": 27, "end": 56, "i_start": 5, "i_end": 8}, "action": {"text": "recognition", "start": 38, "end": 49, "i_start": 7, "i_end": 7}}], "id": 1704}, {"sent": "deep convolutional neural networks have made significant breakthroughs in many visual understanding tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "significant", "breakthroughs", "in", "many", "visual", "understanding", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "breakthroughs", "start": 57, "end": 70, "i_start": 7, "i_end": 7}}], "id": 1705}, {"sent": "to mitigate this issue , we adopt a fully connected conditional random field in a post-processing step to enhance spatial coherence .", "tokens": ["to", "mitigate", "this", "issue", ",", "we", "adopt", "a", "fully", "connected", "conditional", "random", "field", "in", "a", "post", "-", "processing", "step", "to", "enhance", "spatial", "coherence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "verb": {"text": "adopt", "start": 28, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "adopt", "start": 28, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "mitigate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "enhance", "start": 106, "end": 113, "i_start": 20, "i_end": 20}}], "id": 1706}, {"sent": "motivated by the remarkable success of deep learning for large-scale image classification .", "tokens": ["motivated", "by", "the", "remarkable", "success", "of", "deep", "learning", "for", "large", "-", "scale", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "success", "start": 28, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "motivated", "start": 0, "end": 9, "i_start": 0, "i_end": 0}}, {"character": {"text": "learning", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "success", "start": 28, "end": 35, "i_start": 4, "i_end": 4}}], "id": 1707}, {"sent": "various regularization schemes have been developed to prevent overfitting in neural networks , such as early stopping , weight decay , dropout , and dropconnect .", "tokens": ["various", "regularization", "schemes", "have", "been", "developed", "to", "prevent", "overfitting", "in", "neural", "networks", ",", "such", "as", "early", "stopping", ",", "weight", "decay", ",", "dropout", ",", "and", "dropconnect", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "various regularization schemes", "start": 0, "end": 30, "i_start": 0, "i_end": 2}, "verb": {"text": "have been developed", "start": 31, "end": 50, "i_start": 3, "i_end": 5}}, {"character": {"text": "schemes", "start": 23, "end": 30, "i_start": 2, "i_end": 2}, "action": {"text": "prevent", "start": 54, "end": 61, "i_start": 7, "i_end": 7}}], "id": 1708}, {"sent": "recently , convolutional neural networks -based methods achieve great success in image classification tasks .", "tokens": ["recently", ",", "convolutional", "neural", "networks", "-based", "methods", "achieve", "great", "success", "in", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks -based methods", "start": 11, "end": 55, "i_start": 2, "i_end": 6}, "verb": {"text": "achieve", "start": 56, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "methods", "start": 48, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "achieve", "start": 56, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "methods", "start": 48, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 70, "end": 77, "i_start": 9, "i_end": 9}}], "id": 1709}, {"sent": "the long-dashed and short-dashed lines represent the pure coulomb and pure nuclear breakup contributions , respectively .", "tokens": ["the", "long", "-", "dashed", "and", "short", "-", "dashed", "lines", "represent", "the", "pure", "coulomb", "and", "pure", "nuclear", "breakup", "contributions", ",", "respectively", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the long-dashed and short-dashed lines", "start": 0, "end": 38, "i_start": 0, "i_end": 8}, "verb": {"text": "represent", "start": 39, "end": 48, "i_start": 9, "i_end": 9}}, {"character": {"text": "lines", "start": 33, "end": 38, "i_start": 8, "i_end": 8}, "action": {"text": "represent", "start": 39, "end": 48, "i_start": 9, "i_end": 9}}], "id": 1710}, {"sent": "the chemical potential \u00b5 is a diagonal color-flavor matrix depending on \u00b5 , \u00b5e , \u00b53 and \u00b58 .", "tokens": ["the", "chemical", "potential", "\u00b5", "is", "a", "diagonal", "color", "-", "flavor", "matrix", "depending", "on", "\u00b5", ",", "\u00b5e", ",", "\u00b53", "and", "\u00b58", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the chemical potential \u00b5", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "matrix", "start": 52, "end": 58, "i_start": 10, "i_end": 10}, "action": {"text": "depending", "start": 59, "end": 68, "i_start": 11, "i_end": 11}}], "id": 1711}, {"sent": "first , we applied kernel density estimation using the spatstat package for each image .", "tokens": ["first", ",", "we", "applied", "kernel", "density", "estimation", "using", "the", "spatstat", "package", "for", "each", "image", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "applied", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "applied", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "estimation", "start": 34, "end": 44, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "using", "start": 45, "end": 50, "i_start": 7, "i_end": 7}}], "id": 1712}, {"sent": "see for instance where the basis of this approach for models from evolutionary biology were established .", "tokens": ["see", "for", "instance", "where", "the", "basis", "of", "this", "approach", "for", "models", "from", "evolutionary", "biology", "were", "established", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the basis of this approach for models from evolutionary biology", "start": 23, "end": 86, "i_start": 4, "i_end": 13}, "verb": {"text": "see", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "the basis of this approach for models from evolutionary biology", "start": 23, "end": 86, "i_start": 4, "i_end": 13}, "verb": {"text": "established", "start": 92, "end": 103, "i_start": 15, "i_end": 15}}], "id": 1713}, {"sent": "privacy preserving association rule mining in vertically partitioned data .", "tokens": ["privacy", "preserving", "association", "rule", "mining", "in", "vertically", "partitioned", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1714}, {"sent": "in recent years , deep learning has achieved a remarkable success in various areas , including computer vision .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "has", "achieved", "a", "remarkable", "success", "in", "various", "areas", ",", "including", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 18, "end": 31, "i_start": 4, "i_end": 5}, "verb": {"text": "has achieved", "start": 32, "end": 44, "i_start": 6, "i_end": 7}}, {"character": {"text": "learning", "start": 23, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 36, "end": 44, "i_start": 7, "i_end": 7}}, {"character": {"text": "learning", "start": 23, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "success", "start": 58, "end": 65, "i_start": 10, "i_end": 10}}], "id": 1715}, {"sent": "the electron-ion interactions are taken into account using the projector augmented wave method .", "tokens": ["the", "electron", "-", "ion", "interactions", "are", "taken", "into", "account", "using", "the", "projector", "augmented", "wave", "method", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electron-ion interactions", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "are taken", "start": 30, "end": 39, "i_start": 5, "i_end": 6}}, {"character": {"text": "electron", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "interactions", "start": 17, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "projector", "start": 63, "end": 72, "i_start": 11, "i_end": 11}, "action": {"text": "augmented", "start": 73, "end": 82, "i_start": 12, "i_end": 12}}], "id": 1716}, {"sent": "the average slug length increases along the tube , consistent with the decrease in the slug rate .", "tokens": ["the", "average", "slug", "length", "increases", "along", "the", "tube", ",", "consistent", "with", "the", "decrease", "in", "the", "slug", "rate", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1717}, {"sent": "bekenstein , in black holes , gravitational radiation and the universe , b .", "tokens": ["bekenstein", ",", "in", "black", "holes", ",", "gravitational", "radiation", "and", "the", "universe", ",", "b", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "gravitational", "start": 30, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "radiation", "start": 44, "end": 53, "i_start": 7, "i_end": 7}}], "id": 1718}, {"sent": "miramontes , thermodynamic bethe ansatz of the homogeneous sine-gordon models , nucl .", "tokens": ["miramontes", ",", "thermodynamic", "bethe", "ansatz", "of", "the", "homogeneous", "sine", "-", "gordon", "models", ",", "nucl", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1719}, {"sent": "suematsu et al reported that some spicules appear as double and sometimes even multiple threads with evidence of spinning motion .", "tokens": ["suematsu", "et", "al", "reported", "that", "some", "spicules", "appear", "as", "double", "and", "sometimes", "even", "multiple", "threads", "with", "evidence", "of", "spinning", "motion", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "suematsu et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "reported", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"subject": {"text": "some spicules", "start": 29, "end": 42, "i_start": 5, "i_end": 6}, "verb": {"text": "appear", "start": 43, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "suematsu", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "reported", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 1720}, {"sent": "recurrent neural networks have recently seen great success at modeling sequential data , especially in natural language processing tasks .", "tokens": ["recurrent", "neural", "networks", "have", "recently", "seen", "great", "success", "at", "modeling", "sequential", "data", ",", "especially", "in", "natural", "language", "processing", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recurrent neural networks", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "seen", "start": 40, "end": 44, "i_start": 5, "i_end": 5}}, {"subject": {"text": "recurrent neural networks", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 26, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 17, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "seen", "start": 40, "end": 44, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 17, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 51, "end": 58, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 17, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "modeling", "start": 62, "end": 70, "i_start": 9, "i_end": 9}}], "id": 1721}, {"sent": "thus the operators generate the algebra gw-h .", "tokens": ["thus", "the", "operators", "generate", "the", "algebra", "gw", "-", "h", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the operators", "start": 5, "end": 18, "i_start": 1, "i_end": 2}, "verb": {"text": "generate", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}], "id": 1722}, {"sent": "all calculations were performed within density functional theory as implemented in the vienna ab initio simulation package .", "tokens": ["all", "calculations", "were", "performed", "within", "density", "functional", "theory", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all calculations", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were performed", "start": 17, "end": 31, "i_start": 2, "i_end": 3}}], "id": 1723}, {"sent": "the icecube collaboration has recently reported evidence for extraterrestrial neutrinos , after the observation of three pev neutrino cascades within three years of operation .", "tokens": ["the", "icecube", "collaboration", "has", "recently", "reported", "evidence", "for", "extraterrestrial", "neutrinos", ",", "after", "the", "observation", "of", "three", "pev", "neutrino", "cascades", "within", "three", "years", "of", "operation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the icecube collaboration", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "reported", "start": 39, "end": 47, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the icecube collaboration", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "has", "start": 26, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "collaboration", "start": 12, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "reported", "start": 39, "end": 47, "i_start": 5, "i_end": 5}}], "id": 1724}, {"sent": "deep neural networks have delivered tremendous improvements across many machine learning tasks , ranging from computer vision .", "tokens": ["deep", "neural", "networks", "have", "delivered", "tremendous", "improvements", "across", "many", "machine", "learning", "tasks", ",", "ranging", "from", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have delivered", "start": 21, "end": 35, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "delivered", "start": 26, "end": 35, "i_start": 4, "i_end": 4}}], "id": 1725}, {"sent": "in a cooperative group , each agent possesses a limited search capability through a mix of both individual and social learning .", "tokens": ["in", "a", "cooperative", "group", ",", "each", "agent", "possesses", "a", "limited", "search", "capability", "through", "a", "mix", "of", "both", "individual", "and", "social", "learning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "each agent", "start": 25, "end": 35, "i_start": 5, "i_end": 6}, "verb": {"text": "possesses", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "agent", "start": 30, "end": 35, "i_start": 6, "i_end": 6}, "action": {"text": "possesses", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "agent", "start": 30, "end": 35, "i_start": 6, "i_end": 6}, "action": {"text": "search", "start": 56, "end": 62, "i_start": 10, "i_end": 10}}, {"character": {"text": "agent", "start": 30, "end": 35, "i_start": 6, "i_end": 6}, "action": {"text": "learning", "start": 118, "end": 126, "i_start": 20, "i_end": 20}}, {"character": {"text": "group", "start": 17, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "cooperative", "start": 5, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1726}, {"sent": "now , in recent years , the concept of complex networks has also been attracting much attention as a novel approach to complex systems .", "tokens": ["now", ",", "in", "recent", "years", ",", "the", "concept", "of", "complex", "networks", "has", "also", "been", "attracting", "much", "attention", "as", "a", "novel", "approach", "to", "complex", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the concept of complex networks", "start": 24, "end": 55, "i_start": 6, "i_end": 10}, "verb": {"text": "been attracting", "start": 65, "end": 80, "i_start": 13, "i_end": 14}}, {"subject": {"text": "the concept of complex networks", "start": 24, "end": 55, "i_start": 6, "i_end": 10}, "verb": {"text": "has", "start": 56, "end": 59, "i_start": 11, "i_end": 11}}, {"character": {"text": "concept", "start": 28, "end": 35, "i_start": 7, "i_end": 7}, "action": {"text": "attracting", "start": 70, "end": 80, "i_start": 14, "i_end": 14}}], "id": 1727}, {"sent": "the relatively recent innovation of synthetic materials , made possible with ultra-cold atomic gases , has added a vitally important tool to study many-body physics in experimental systems .", "tokens": ["the", "relatively", "recent", "innovation", "of", "synthetic", "materials", ",", "made", "possible", "with", "ultra", "-", "cold", "atomic", "gases", ",", "has", "added", "a", "vitally", "important", "tool", "to", "study", "many", "-", "body", "physics", "in", "experimental", "systems", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "the relatively recent innovation of synthetic materials", "start": 0, "end": 55, "i_start": 0, "i_end": 6}, "verb": {"text": "has added", "start": 103, "end": 112, "i_start": 17, "i_end": 18}}, {"character": {"text": "innovation", "start": 22, "end": 32, "i_start": 3, "i_end": 3}, "action": {"text": "added", "start": 107, "end": 112, "i_start": 18, "i_end": 18}}], "id": 1728}, {"sent": "the metallicity is the best indicator for finding out which of these processes are most important .", "tokens": ["the", "metallicity", "is", "the", "best", "indicator", "for", "finding", "out", "which", "of", "these", "processes", "are", "most", "important", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the metallicity", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "metallicity", "start": 4, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "indicator", "start": 28, "end": 37, "i_start": 5, "i_end": 5}}], "id": 1729}, {"sent": "data-driven approaches , in particular , deep learning with convolutional neural networks , have recently attained great success in many computer vision tasks such as image classification .", "tokens": ["data", "-", "driven", "approaches", ",", "in", "particular", ",", "deep", "learning", "with", "convolutional", "neural", "networks", ",", "have", "recently", "attained", "great", "success", "in", "many", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "data-driven approaches", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "attained", "start": 106, "end": 114, "i_start": 17, "i_end": 17}}, {"subject": {"text": "data-driven approaches", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 92, "end": 96, "i_start": 15, "i_end": 15}}, {"character": {"text": "approaches", "start": 12, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "attained", "start": 106, "end": 114, "i_start": 17, "i_end": 17}}, {"character": {"text": "data", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "driven", "start": 5, "end": 11, "i_start": 2, "i_end": 2}}], "id": 1730}, {"sent": "the observation that the frequency of the identified system dynamics is limited to the sample frequency of the signal , used for identification of the model , is confirmed by the nyquistshannon theorem , .", "tokens": ["the", "observation", "that", "the", "frequency", "of", "the", "identified", "system", "dynamics", "is", "limited", "to", "the", "sample", "frequency", "of", "the", "signal", ",", "used", "for", "identification", "of", "the", "model", ",", "is", "confirmed", "by", "the", "nyquistshannon", "theorem", ",", "."], "score": [1, 0, 1, 0, 1], "labels": [{"subject": {"text": "the observation that the frequency of the identified system dynamics is limited to the sample frequency of the signal", "start": 0, "end": 117, "i_start": 0, "i_end": 18}, "verb": {"text": "is confirmed", "start": 159, "end": 171, "i_start": 27, "i_end": 28}}, {"character": {"text": "theorem", "start": 194, "end": 201, "i_start": 32, "i_end": 32}, "action": {"text": "confirmed", "start": 162, "end": 171, "i_start": 28, "i_end": 28}}], "id": 1731}, {"sent": "it has been suggested in the literature that social networks possess a topological structure where nodes are organized into communities , a feature that can account for the values for the clustering coefficient and degree correlations .", "tokens": ["it", "has", "been", "suggested", "in", "the", "literature", "that", "social", "networks", "possess", "a", "topological", "structure", "where", "nodes", "are", "organized", "into", "communities", ",", "a", "feature", "that", "can", "account", "for", "the", "values", "for", "the", "clustering", "coefficient", "and", "degree", "correlations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has been suggested", "start": 3, "end": 21, "i_start": 1, "i_end": 3}}, {"subject": {"text": "social networks", "start": 45, "end": 60, "i_start": 8, "i_end": 9}, "verb": {"text": "possess", "start": 61, "end": 68, "i_start": 10, "i_end": 10}}, {"character": {"text": "networks", "start": 52, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "possess", "start": 61, "end": 68, "i_start": 10, "i_end": 10}}, {"character": {"text": "feature", "start": 140, "end": 147, "i_start": 22, "i_end": 22}, "action": {"text": "account", "start": 157, "end": 164, "i_start": 25, "i_end": 25}}], "id": 1732}, {"sent": "we use the adam optimizer with the default configuration .", "tokens": ["we", "use", "the", "adam", "optimizer", "with", "the", "default", "configuration", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 1733}, {"sent": "since the tranche is a nonlinear function of the loss , the expectation will depend on all moments of the loss and not just on the expected loss .", "tokens": ["since", "the", "tranche", "is", "a", "nonlinear", "function", "of", "the", "loss", ",", "the", "expectation", "will", "depend", "on", "all", "moments", "of", "the", "loss", "and", "not", "just", "on", "the", "expected", "loss", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "the expectation", "start": 56, "end": 71, "i_start": 11, "i_end": 12}, "verb": {"text": "will depend", "start": 72, "end": 83, "i_start": 13, "i_end": 14}}, {"character": {"text": "expected", "start": 131, "end": 139, "i_start": 26, "i_end": 26}, "action": {"text": "depend", "start": 77, "end": 83, "i_start": 14, "i_end": 14}}], "id": 1734}, {"sent": "in the context of white lies , erat and gneezy found that women are more likely than men to tell an altruistic lie , but men are more likely than women to tell a pareto white lie .", "tokens": ["in", "the", "context", "of", "white", "lies", ",", "erat", "and", "gneezy", "found", "that", "women", "are", "more", "likely", "than", "men", "to", "tell", "an", "altruistic", "lie", ",", "but", "men", "are", "more", "likely", "than", "women", "to", "tell", "a", "pareto", "white", "lie", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "erat and gneezy", "start": 31, "end": 46, "i_start": 7, "i_end": 9}, "verb": {"text": "found", "start": 47, "end": 52, "i_start": 10, "i_end": 10}}, {"subject": {"text": "erat and gneezy", "start": 31, "end": 46, "i_start": 7, "i_end": 9}, "verb": {"text": "are", "start": 64, "end": 67, "i_start": 13, "i_end": 13}}, {"character": {"text": "erat", "start": 31, "end": 35, "i_start": 7, "i_end": 7}, "action": {"text": "found", "start": 47, "end": 52, "i_start": 10, "i_end": 10}}, {"character": {"text": "gneezy", "start": 40, "end": 46, "i_start": 9, "i_end": 9}, "action": {"text": "found", "start": 47, "end": 52, "i_start": 10, "i_end": 10}}, {"character": {"text": "women", "start": 58, "end": 63, "i_start": 12, "i_end": 12}, "action": {"text": "tell", "start": 92, "end": 96, "i_start": 19, "i_end": 19}}, {"character": {"text": "women", "start": 58, "end": 63, "i_start": 12, "i_end": 12}, "action": {"text": "lies", "start": 24, "end": 28, "i_start": 5, "i_end": 5}}], "id": 1735}, {"sent": "feedback is a ubiquitous concept in classical applications because it enables precision performance despite the presence of potentially large system uncertainty .", "tokens": ["feedback", "is", "a", "ubiquitous", "concept", "in", "classical", "applications", "because", "it", "enables", "precision", "performance", "despite", "the", "presence", "of", "potentially", "large", "system", "uncertainty", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "feedback", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "enables", "start": 70, "end": 77, "i_start": 10, "i_end": 10}, "action": {"text": "because", "start": 59, "end": 66, "i_start": 8, "i_end": 8}}, {"character": {"text": "feedback", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "enables", "start": 70, "end": 77, "i_start": 10, "i_end": 10}}], "id": 1736}, {"sent": "convolutional neural networks have recently achieved great success on various visual recognition tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "achieved", "great", "success", "on", "various", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 7, "i_end": 7}}], "id": 1737}, {"sent": "decoherence , chaos , and the correspondence principle .", "tokens": ["decoherence", ",", "chaos", ",", "and", "the", "correspondence", "principle", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1738}, {"sent": "of the droplet is a regular one , and the fluctuation and capillarity effects can be neglected .", "tokens": ["of", "the", "droplet", "is", "a", "regular", "one", ",", "and", "the", "fluctuation", "and", "capillarity", "effects", "can", "be", "neglected", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the fluctuation and capillarity effects", "start": 38, "end": 77, "i_start": 9, "i_end": 13}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the fluctuation and capillarity effects", "start": 38, "end": 77, "i_start": 9, "i_end": 13}, "verb": {"text": "neglected", "start": 85, "end": 94, "i_start": 16, "i_end": 16}}], "id": 1739}, {"sent": "deep neural networks are being successful in accomplishing challenging tasks such as image classification .", "tokens": ["deep", "neural", "networks", "are", "being", "successful", "in", "accomplishing", "challenging", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are being", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 31, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "accomplishing", "start": 45, "end": 58, "i_start": 7, "i_end": 7}}], "id": 1740}, {"sent": "first , msugra is a rather constrained model with only five free parameters .", "tokens": ["first", ",", "msugra", "is", "a", "rather", "constrained", "model", "with", "only", "five", "free", "parameters", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "msugra", "start": 8, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}], "id": 1741}, {"sent": "the energetics of island and pit nucleation .", "tokens": ["the", "energetics", "of", "island", "and", "pit", "nucleation", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1742}, {"sent": "in recent years , deep neural networks , especially convolutional neural networks , have demonstrated highly competitive results on object recognition and image classification .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", ",", "especially", "convolutional", "neural", "networks", ",", "have", "demonstrated", "highly", "competitive", "results", "on", "object", "recognition", "and", "image", "classification", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have demonstrated", "start": 84, "end": 101, "i_start": 13, "i_end": 14}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "demonstrated", "start": 89, "end": 101, "i_start": 14, "i_end": 14}}], "id": 1743}, {"sent": "goodfellow et al proposed the fast gradient sign method as a fast solution to generate adversarial examples .", "tokens": ["goodfellow", "et", "al", "proposed", "the", "fast", "gradient", "sign", "method", "as", "a", "fast", "solution", "to", "generate", "adversarial", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "goodfellow", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}], "id": 1744}, {"sent": "sl is non associative neutrosophic interval semiring of infinite order .", "tokens": ["sl", "is", "non", "associative", "neutrosophic", "interval", "semiring", "of", "infinite", "order", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "sl", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}], "id": 1745}, {"sent": "one of the central object in the study of form factors of gl-invariant models is the partition function of the six-vertex model with domain wall boundary conditions .", "tokens": ["one", "of", "the", "central", "object", "in", "the", "study", "of", "form", "factors", "of", "gl", "-", "invariant", "models", "is", "the", "partition", "function", "of", "the", "six", "-", "vertex", "model", "with", "domain", "wall", "boundary", "conditions", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "one of the central object in the study of form factors of gl-invariant models", "start": 0, "end": 77, "i_start": 0, "i_end": 15}, "verb": {"text": "is", "start": 78, "end": 80, "i_start": 16, "i_end": 16}}, {"character": {"text": "models", "start": 71, "end": 77, "i_start": 15, "i_end": 15}, "action": {"text": "function", "start": 95, "end": 103, "i_start": 19, "i_end": 19}}], "id": 1746}, {"sent": "calculations are performed in the generalized gradient approximation with the exchange-correlation functional of perdew , burke and ernzerhof .", "tokens": ["calculations", "are", "performed", "in", "the", "generalized", "gradient", "approximation", "with", "the", "exchange", "-", "correlation", "functional", "of", "perdew", ",", "burke", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "calculations", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "are performed", "start": 13, "end": 26, "i_start": 1, "i_end": 2}}, {"character": {"text": "perdew", "start": 113, "end": 119, "i_start": 15, "i_end": 15}, "action": {"text": "functional", "start": 99, "end": 109, "i_start": 13, "i_end": 13}}, {"character": {"text": "burke", "start": 122, "end": 127, "i_start": 17, "i_end": 17}, "action": {"text": "functional", "start": 99, "end": 109, "i_start": 13, "i_end": 13}}, {"character": {"text": "ernzerhof", "start": 132, "end": 141, "i_start": 19, "i_end": 19}, "action": {"text": "functional", "start": 99, "end": 109, "i_start": 13, "i_end": 13}}], "id": 1747}, {"sent": "in narrow qws , however , the measured polarization is reduced due to fast initial spin relaxation that is almost independent of the excitation energy .", "tokens": ["in", "narrow", "qws", ",", "however", ",", "the", "measured", "polarization", "is", "reduced", "due", "to", "fast", "initial", "spin", "relaxation", "that", "is", "almost", "independent", "of", "the", "excitation", "energy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the measured polarization", "start": 26, "end": 51, "i_start": 6, "i_end": 8}, "verb": {"text": "is reduced", "start": 52, "end": 62, "i_start": 9, "i_end": 10}}, {"character": {"text": "relaxation", "start": 88, "end": 98, "i_start": 16, "i_end": 16}, "action": {"text": "independent", "start": 114, "end": 125, "i_start": 20, "i_end": 20}}, {"character": {"text": "energy", "start": 144, "end": 150, "i_start": 24, "i_end": 24}, "action": {"text": "excitation", "start": 133, "end": 143, "i_start": 23, "i_end": 23}}], "id": 1748}, {"sent": "the procedure is tractable and uses the implication graph method of .", "tokens": ["the", "procedure", "is", "tractable", "and", "uses", "the", "implication", "graph", "method", "of", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the procedure", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the procedure", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "uses", "start": 31, "end": 35, "i_start": 5, "i_end": 5}}, {"character": {"text": "procedure", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "uses", "start": 31, "end": 35, "i_start": 5, "i_end": 5}}], "id": 1749}, {"sent": "we assume basic knowledge of communication complexity .", "tokens": ["we", "assume", "basic", "knowledge", "of", "communication", "complexity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 1750}, {"sent": "more recently , neural network methods have been applied to model natural language .", "tokens": ["more", "recently", ",", "neural", "network", "methods", "have", "been", "applied", "to", "model", "natural", "language", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural network methods", "start": 16, "end": 38, "i_start": 3, "i_end": 5}, "verb": {"text": "have been applied", "start": 39, "end": 56, "i_start": 6, "i_end": 8}}, {"character": {"text": "methods", "start": 31, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "model", "start": 60, "end": 65, "i_start": 10, "i_end": 10}}], "id": 1751}, {"sent": "deep learning has improved the state-of-the-art in automated tasks like image processing , and has already seen a wide range of applications in research and industry .", "tokens": ["deep", "learning", "has", "improved", "the", "state", "-", "of", "-", "the", "-", "art", "in", "automated", "tasks", "like", "image", "processing", ",", "and", "has", "already", "seen", "a", "wide", "range", "of", "applications", "in", "research", "and", "industry", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has improved", "start": 14, "end": 26, "i_start": 2, "i_end": 3}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "seen", "start": 107, "end": 111, "i_start": 22, "i_end": 22}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "improved", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "seen", "start": 107, "end": 111, "i_start": 22, "i_end": 22}}], "id": 1752}, {"sent": "multi-task learning aims to improve the generality of performance by mutually utilizing information of other related tasks .", "tokens": ["multi", "-", "task", "learning", "aims", "to", "improve", "the", "generality", "of", "performance", "by", "mutually", "utilizing", "information", "of", "other", "related", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "multi-task learning", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "aims", "start": 20, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 11, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "aims", "start": 20, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 11, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "improve", "start": 28, "end": 35, "i_start": 6, "i_end": 6}}], "id": 1753}, {"sent": "collobert et al propose the first word-level neural network model using cnn and crf .", "tokens": ["collobert", "et", "al", "propose", "the", "first", "word", "-", "level", "neural", "network", "model", "using", "cnn", "and", "crf", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "collobert et al", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 16, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "collobert", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 16, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "collobert", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 66, "end": 71, "i_start": 12, "i_end": 12}}], "id": 1754}, {"sent": "such algorithms have found applications in factoring polynomials over rationals .", "tokens": ["such", "algorithms", "have", "found", "applications", "in", "factoring", "polynomials", "over", "rationals", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "such algorithms", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have found", "start": 16, "end": 26, "i_start": 2, "i_end": 3}}, {"character": {"text": "algorithms", "start": 5, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "found", "start": 21, "end": 26, "i_start": 3, "i_end": 3}}], "id": 1755}, {"sent": "since this coefficient is a short distance property , we may work directly at the critical point .", "tokens": ["since", "this", "coefficient", "is", "a", "short", "distance", "property", ",", "we", "may", "work", "directly", "at", "the", "critical", "point", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 54, "end": 56, "i_start": 9, "i_end": 9}, "verb": {"text": "may work", "start": 57, "end": 65, "i_start": 10, "i_end": 11}}, {"character": {"text": "we", "start": 54, "end": 56, "i_start": 9, "i_end": 9}, "action": {"text": "work", "start": 61, "end": 65, "i_start": 11, "i_end": 11}}], "id": 1756}, {"sent": "two notable approaches in this area are variational auto-encoders as well as generative adversarial networks .", "tokens": ["two", "notable", "approaches", "in", "this", "area", "are", "variational", "auto", "-", "encoders", "as", "well", "as", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "two notable approaches in this area", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 36, "end": 39, "i_start": 6, "i_end": 6}}], "id": 1757}, {"sent": "li et al propose a unified framework to jointly conduct rating prediction and abstractive tips generation .", "tokens": ["li", "et", "al", "propose", "a", "unified", "framework", "to", "jointly", "conduct", "rating", "prediction", "and", "abstractive", "tips", "generation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "li et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 9, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "li", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 9, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "li", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "conduct", "start": 48, "end": 55, "i_start": 9, "i_end": 9}}], "id": 1758}, {"sent": "devinney et al devinney et al , marchette and priebe marchette and priebe , priebe et al priebe et al , priebe et al applied the concept in higher dimensions and demonstrated relatively good performance of cccd in classification .", "tokens": ["devinney", "et", "al", "devinney", "et", "al", ",", "marchette", "and", "priebe", "marchette", "and", "priebe", ",", "priebe", "et", "al", "priebe", "et", "al", ",", "priebe", "et", "al", "applied", "the", "concept", "in", "higher", "dimensions", "and", "demonstrated", "relatively", "good", "performance", "of", "cccd", "in", "classification", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "devinney et al devinney et al", "start": 0, "end": 29, "i_start": 0, "i_end": 5}, "verb": {"text": "applied", "start": 117, "end": 124, "i_start": 24, "i_end": 24}}, {"subject": {"text": "devinney et al devinney et al", "start": 0, "end": 29, "i_start": 0, "i_end": 5}, "verb": {"text": "demonstrated", "start": 162, "end": 174, "i_start": 31, "i_end": 31}}, {"character": {"text": "and", "start": 63, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "applied", "start": 117, "end": 124, "i_start": 24, "i_end": 24}}, {"character": {"text": "devinney et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "action": {"text": "applied", "start": 117, "end": 124, "i_start": 24, "i_end": 24}}, {"character": {"text": "and", "start": 158, "end": 161, "i_start": 30, "i_end": 30}, "action": {"text": "applied", "start": 117, "end": 124, "i_start": 24, "i_end": 24}}, {"character": {"text": "devinney et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "action": {"text": "applied", "start": 117, "end": 124, "i_start": 24, "i_end": 24}}, {"character": {"text": "al , marchette and priebe marchette and priebe , priebe et al priebe", "start": 27, "end": 95, "i_start": 5, "i_end": 17}, "action": {"text": "applied", "start": 117, "end": 124, "i_start": 24, "i_end": 24}}, {"character": {"text": "et al , marchette and priebe marchette and priebe , priebe et al priebe et al , priebe", "start": 24, "end": 110, "i_start": 4, "i_end": 21}, "action": {"text": "applied", "start": 117, "end": 124, "i_start": 24, "i_end": 24}}, {"character": {"text": "al , marchette and priebe marchette and priebe , priebe et al priebe", "start": 27, "end": 95, "i_start": 5, "i_end": 17}, "action": {"text": "applied", "start": 117, "end": 124, "i_start": 24, "i_end": 24}}, {"character": {"text": "al", "start": 99, "end": 101, "i_start": 19, "i_end": 19}, "action": {"text": "applied", "start": 117, "end": 124, "i_start": 24, "i_end": 24}}, {"character": {"text": "al , marchette and priebe marchette and priebe , priebe et al priebe", "start": 27, "end": 95, "i_start": 5, "i_end": 17}, "action": {"text": "applied", "start": 117, "end": 124, "i_start": 24, "i_end": 24}}, {"character": {"text": "al , marchette and priebe marchette and priebe , priebe et al priebe", "start": 27, "end": 95, "i_start": 5, "i_end": 17}, "action": {"text": "applied", "start": 117, "end": 124, "i_start": 24, "i_end": 24}}, {"character": {"text": "al", "start": 114, "end": 116, "i_start": 23, "i_end": 23}, "action": {"text": "applied", "start": 117, "end": 124, "i_start": 24, "i_end": 24}}, {"character": {"text": "applied", "start": 117, "end": 124, "i_start": 24, "i_end": 24}, "action": {"text": "applied", "start": 117, "end": 124, "i_start": 24, "i_end": 24}}, {"character": {"text": "demonstrated", "start": 162, "end": 174, "i_start": 31, "i_end": 31}, "action": {"text": "applied", "start": 117, "end": 124, "i_start": 24, "i_end": 24}}, {"character": {"text": "cccd", "start": 206, "end": 210, "i_start": 36, "i_end": 36}, "action": {"text": "applied", "start": 117, "end": 124, "i_start": 24, "i_end": 24}}, {"character": {"text": "and", "start": 63, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "demonstrated", "start": 162, "end": 174, "i_start": 31, "i_end": 31}}, {"character": {"text": "devinney et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "action": {"text": "demonstrated", "start": 162, "end": 174, "i_start": 31, "i_end": 31}}, {"character": {"text": "and", "start": 158, "end": 161, "i_start": 30, "i_end": 30}, "action": {"text": "demonstrated", "start": 162, "end": 174, "i_start": 31, "i_end": 31}}, {"character": {"text": "devinney et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "action": {"text": "demonstrated", "start": 162, "end": 174, "i_start": 31, "i_end": 31}}, {"character": {"text": "al , marchette and priebe marchette and priebe , priebe et al priebe", "start": 27, "end": 95, "i_start": 5, "i_end": 17}, "action": {"text": "demonstrated", "start": 162, "end": 174, "i_start": 31, "i_end": 31}}, {"character": {"text": "et al , marchette and priebe marchette and priebe , priebe et al priebe et al , priebe", "start": 24, "end": 110, "i_start": 4, "i_end": 21}, "action": {"text": "demonstrated", "start": 162, "end": 174, "i_start": 31, "i_end": 31}}, {"character": {"text": "al , marchette and priebe marchette and priebe , priebe et al priebe", "start": 27, "end": 95, "i_start": 5, "i_end": 17}, "action": {"text": "demonstrated", "start": 162, "end": 174, "i_start": 31, "i_end": 31}}, {"character": {"text": "al", "start": 99, "end": 101, "i_start": 19, "i_end": 19}, "action": {"text": "demonstrated", "start": 162, "end": 174, "i_start": 31, "i_end": 31}}, {"character": {"text": "al , marchette and priebe marchette and priebe , priebe et al priebe", "start": 27, "end": 95, "i_start": 5, "i_end": 17}, "action": {"text": "demonstrated", "start": 162, "end": 174, "i_start": 31, "i_end": 31}}, {"character": {"text": "al , marchette and priebe marchette and priebe , priebe et al priebe", "start": 27, "end": 95, "i_start": 5, "i_end": 17}, "action": {"text": "demonstrated", "start": 162, "end": 174, "i_start": 31, "i_end": 31}}, {"character": {"text": "al", "start": 114, "end": 116, "i_start": 23, "i_end": 23}, "action": {"text": "demonstrated", "start": 162, "end": 174, "i_start": 31, "i_end": 31}}, {"character": {"text": "applied", "start": 117, "end": 124, "i_start": 24, "i_end": 24}, "action": {"text": "demonstrated", "start": 162, "end": 174, "i_start": 31, "i_end": 31}}, {"character": {"text": "demonstrated", "start": 162, "end": 174, "i_start": 31, "i_end": 31}, "action": {"text": "demonstrated", "start": 162, "end": 174, "i_start": 31, "i_end": 31}}, {"character": {"text": "cccd", "start": 206, "end": 210, "i_start": 36, "i_end": 36}, "action": {"text": "demonstrated", "start": 162, "end": 174, "i_start": 31, "i_end": 31}}], "id": 1759}, {"sent": "ganin and lempitsky report using the adversarial learning to achieve domain adaptation and learning the distance with the discriminator .", "tokens": ["ganin", "and", "lempitsky", "report", "using", "the", "adversarial", "learning", "to", "achieve", "domain", "adaptation", "and", "learning", "the", "distance", "with", "the", "discriminator", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "ganin", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "report", "start": 20, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "lempitsky", "start": 10, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "report", "start": 20, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "report", "start": 20, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "using", "start": 27, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "ganin", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "achieve", "start": 61, "end": 68, "i_start": 9, "i_end": 9}}, {"character": {"text": "lempitsky", "start": 10, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 61, "end": 68, "i_start": 9, "i_end": 9}}], "id": 1760}, {"sent": "several optimization-based methods have been proposed for generating adversarial examples , including fast gradient sign method , and carlini and wagner attack .", "tokens": ["several", "optimization", "-", "based", "methods", "have", "been", "proposed", "for", "generating", "adversarial", "examples", ",", "including", "fast", "gradient", "sign", "method", ",", "and", "carlini", "and", "wagner", "attack", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "several optimization-based methods have been proposed for generating adversarial examples , including fast gradient sign method", "start": 0, "end": 127, "i_start": 0, "i_end": 17}, "verb": {"text": "have been proposed", "start": 35, "end": 53, "i_start": 5, "i_end": 7}}, {"character": {"text": "carlini", "start": 134, "end": 141, "i_start": 20, "i_end": 20}, "action": {"text": "attack", "start": 153, "end": 159, "i_start": 23, "i_end": 23}}, {"character": {"text": "wagner", "start": 146, "end": 152, "i_start": 22, "i_end": 22}, "action": {"text": "attack", "start": 153, "end": 159, "i_start": 23, "i_end": 23}}], "id": 1761}, {"sent": "we shall consider this issue in the next section .", "tokens": ["we", "shall", "consider", "this", "issue", "in", "the", "next", "section", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "shall consider", "start": 3, "end": 17, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "consider", "start": 9, "end": 17, "i_start": 2, "i_end": 2}}], "id": 1762}, {"sent": "convolutional neural networks have achieved state-of-the-art performance on the object detection task .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "the", "object", "detection", "task", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 61, "end": 72, "i_start": 12, "i_end": 12}}], "id": 1763}, {"sent": "comparison with that of barannikov-kontsevich suggests that these two kinds of formal frobenius manifolds should be mirror image of each other .", "tokens": ["comparison", "with", "that", "of", "barannikov", "-", "kontsevich", "suggests", "that", "these", "two", "kinds", "of", "formal", "frobenius", "manifolds", "should", "be", "mirror", "image", "of", "each", "other", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "comparison with that of barannikov-kontsevich", "start": 0, "end": 45, "i_start": 0, "i_end": 6}, "verb": {"text": "suggests", "start": 46, "end": 54, "i_start": 7, "i_end": 7}}, {"subject": {"text": "comparison with that of barannikov-kontsevich", "start": 0, "end": 45, "i_start": 0, "i_end": 6}, "verb": {"text": "be", "start": 113, "end": 115, "i_start": 17, "i_end": 17}}, {"character": {"text": "comparison", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "suggests", "start": 46, "end": 54, "i_start": 7, "i_end": 7}}], "id": 1764}, {"sent": "d eep convolutional neural networks have gained much popularity in recent years for vision-related applications since they were shown to achieve some of the highest accuracies in image classification tasks .", "tokens": ["d", "eep", "convolutional", "neural", "networks", "have", "gained", "much", "popularity", "in", "recent", "years", "for", "vision", "-", "related", "applications", "since", "they", "were", "shown", "to", "achieve", "some", "of", "the", "highest", "accuracies", "in", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "d eep convolutional neural networks", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "have gained", "start": 36, "end": 47, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 27, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "gained", "start": 41, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 27, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "achieve", "start": 137, "end": 144, "i_start": 22, "i_end": 22}}], "id": 1765}, {"sent": "li et al propose a neural network architecture for encoding and synthesizing 3d shapes based on their structures .", "tokens": ["li", "et", "al", "propose", "a", "neural", "network", "architecture", "for", "encoding", "and", "synthesizing", "3d", "shapes", "based", "on", "their", "structures", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "li et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 9, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "li", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 9, "end": 16, "i_start": 3, "i_end": 3}}], "id": 1766}, {"sent": "trivially , every strongly partition regular family of sets is also weakly partition regular .", "tokens": ["trivially", ",", "every", "strongly", "partition", "regular", "family", "of", "sets", "is", "also", "weakly", "partition", "regular", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "every strongly partition regular family of sets", "start": 12, "end": 59, "i_start": 2, "i_end": 8}, "verb": {"text": "is", "start": 60, "end": 62, "i_start": 9, "i_end": 9}}], "id": 1767}, {"sent": "on the otb50 dataset , we evaluate our approach with comparison to nine state-of-the-art trackers that only use deep learning features , including mdnet .", "tokens": ["on", "the", "otb50", "dataset", ",", "we", "evaluate", "our", "approach", "with", "comparison", "to", "nine", "state", "-", "of", "-", "the", "-", "art", "trackers", "that", "only", "use", "deep", "learning", "features", ",", "including", "mdnet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "verb": {"text": "evaluate", "start": 26, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "action": {"text": "evaluate", "start": 26, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "action": {"text": "approach", "start": 39, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "nine", "start": 67, "end": 71, "i_start": 12, "i_end": 12}, "action": {"text": "trackers", "start": 89, "end": 97, "i_start": 20, "i_end": 20}}, {"character": {"text": "nine", "start": 67, "end": 71, "i_start": 12, "i_end": 12}, "action": {"text": "use", "start": 108, "end": 111, "i_start": 23, "i_end": 23}}], "id": 1768}, {"sent": "this kind of transformation is called gravitational gauge transformation .", "tokens": ["this", "kind", "of", "transformation", "is", "called", "gravitational", "gauge", "transformation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this kind of transformation", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "is called", "start": 28, "end": 37, "i_start": 4, "i_end": 5}}], "id": 1769}, {"sent": "cfr works based on the fact that minimizing the regrets of both players makes the time-averaged strategy to approach the nash-equilibrium .", "tokens": ["cfr", "works", "based", "on", "the", "fact", "that", "minimizing", "the", "regrets", "of", "both", "players", "makes", "the", "time", "-", "averaged", "strategy", "to", "approach", "the", "nash", "-", "equilibrium", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cfr", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "works", "start": 4, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "both", "start": 59, "end": 63, "i_start": 11, "i_end": 11}, "action": {"text": "regrets", "start": 48, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "minimizing", "start": 33, "end": 43, "i_start": 7, "i_end": 7}, "action": {"text": "makes", "start": 72, "end": 77, "i_start": 13, "i_end": 13}}, {"character": {"text": "both", "start": 59, "end": 63, "i_start": 11, "i_end": 11}, "action": {"text": "averaged", "start": 87, "end": 95, "i_start": 17, "i_end": 17}}, {"character": {"text": "strategy", "start": 96, "end": 104, "i_start": 18, "i_end": 18}, "action": {"text": "approach", "start": 108, "end": 116, "i_start": 20, "i_end": 20}}], "id": 1770}, {"sent": "these nonlinearities have been exploited by researchers who have demonstrated microfluidic memory , logic , and control devices .", "tokens": ["these", "nonlinearities", "have", "been", "exploited", "by", "researchers", "who", "have", "demonstrated", "microfluidic", "memory", ",", "logic", ",", "and", "control", "devices", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "these nonlinearities", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "have been exploited", "start": 21, "end": 40, "i_start": 2, "i_end": 4}}, {"character": {"text": "memory", "start": 91, "end": 97, "i_start": 11, "i_end": 11}, "action": {"text": "exploited", "start": 31, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "microfluidic", "start": 78, "end": 90, "i_start": 10, "i_end": 10}, "action": {"text": "exploited", "start": 31, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "logic", "start": 100, "end": 105, "i_start": 13, "i_end": 13}, "action": {"text": "exploited", "start": 31, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "devices", "start": 120, "end": 127, "i_start": 17, "i_end": 17}, "action": {"text": "exploited", "start": 31, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "control", "start": 112, "end": 119, "i_start": 16, "i_end": 16}, "action": {"text": "exploited", "start": 31, "end": 40, "i_start": 4, "i_end": 4}}], "id": 1771}, {"sent": "moreover the superspace formalism of turns out to be in a frame different from the einstein frame .", "tokens": ["moreover", "the", "superspace", "formalism", "of", "turns", "out", "to", "be", "in", "a", "frame", "different", "from", "the", "einstein", "frame", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1772}, {"sent": "scharlau , quadratic and hermitian forms , grundlehren der math .", "tokens": ["scharlau", ",", "quadratic", "and", "hermitian", "forms", ",", "grundlehren", "der", "math", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1773}, {"sent": "expectation maximization is a general method allowing to compute the maximum likelihood estimate of the parameters of an underlying distribution of a dataset , when these are incomplete or have missing values .", "tokens": ["expectation", "maximization", "is", "a", "general", "method", "allowing", "to", "compute", "the", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "an", "underlying", "distribution", "of", "a", "dataset", ",", "when", "these", "are", "incomplete", "or", "have", "missing", "values", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "expectation maximization", "start": 0, "end": 24, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 2, "i_end": 2}}, {"character": {"text": "method", "start": 38, "end": 44, "i_start": 5, "i_end": 5}, "action": {"text": "allowing", "start": 45, "end": 53, "i_start": 6, "i_end": 6}}, {"character": {"text": "distribution", "start": 132, "end": 144, "i_start": 19, "i_end": 19}, "action": {"text": "underlying", "start": 121, "end": 131, "i_start": 18, "i_end": 18}}, {"character": {"text": "distribution", "start": 132, "end": 144, "i_start": 19, "i_end": 19}, "action": {"text": "have", "start": 189, "end": 193, "i_start": 29, "i_end": 29}}], "id": 1774}, {"sent": "zhao et al use also two parallel networks to obtain local and global context modeling .", "tokens": ["zhao", "et", "al", "use", "also", "two", "parallel", "networks", "to", "obtain", "local", "and", "global", "context", "modeling", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhao et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "use", "start": 11, "end": 14, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhao", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 11, "end": 14, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhao", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "obtain", "start": 45, "end": 51, "i_start": 9, "i_end": 9}}], "id": 1775}, {"sent": "generative adversarial networks have attracted much research interest since its introduction among many others .", "tokens": ["generative", "adversarial", "networks", "have", "attracted", "much", "research", "interest", "since", "its", "introduction", "among", "many", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "have attracted", "start": 32, "end": 46, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "attracted", "start": 37, "end": 46, "i_start": 4, "i_end": 4}}], "id": 1776}, {"sent": "shokri et al present the first membership inference attack against machine learning models .", "tokens": ["shokri", "et", "al", "present", "the", "first", "membership", "inference", "attack", "against", "machine", "learning", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "shokri et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "present", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "shokri", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "present", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "shokri", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "attack", "start": 52, "end": 58, "i_start": 8, "i_end": 8}}], "id": 1777}, {"sent": "however , the swing equations are inaccurate and only valid on a specific time scale up to the order of a few seconds so that asymptotic stability results are often invalid for the actual system .", "tokens": ["however", ",", "the", "swing", "equations", "are", "inaccurate", "and", "only", "valid", "on", "a", "specific", "time", "scale", "up", "to", "the", "order", "of", "a", "few", "seconds", "so", "that", "asymptotic", "stability", "results", "are", "often", "invalid", "for", "the", "actual", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the swing equations", "start": 10, "end": 29, "i_start": 2, "i_end": 4}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 5, "i_end": 5}}], "id": 1778}, {"sent": "this follows immediately from the parity formulas for the bessel functions .", "tokens": ["this", "follows", "immediately", "from", "the", "parity", "formulas", "for", "the", "bessel", "functions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "follows", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}], "id": 1779}, {"sent": "one popular reduced-rank scheme is the multistage wiener filter , which employs the minimum mean squared error .", "tokens": ["one", "popular", "reduced", "-", "rank", "scheme", "is", "the", "multistage", "wiener", "filter", ",", "which", "employs", "the", "minimum", "mean", "squared", "error", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one popular reduced-rank scheme", "start": 0, "end": 31, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "filter", "start": 57, "end": 63, "i_start": 10, "i_end": 10}, "action": {"text": "employs", "start": 72, "end": 79, "i_start": 13, "i_end": 13}}], "id": 1780}, {"sent": "the gravitino is the superpartner of the graviton .", "tokens": ["the", "gravitino", "is", "the", "superpartner", "of", "the", "graviton", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the gravitino", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1781}, {"sent": "it is shown in that l is also a first order nonnegative self-adjoint elliptic pseudodifferential operator .", "tokens": ["it", "is", "shown", "in", "that", "l", "is", "also", "a", "first", "order", "nonnegative", "self", "-", "adjoint", "elliptic", "pseudodifferential", "operator", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is shown", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 6, "i_end": 6}}, {"character": {"text": "l", "start": 20, "end": 21, "i_start": 5, "i_end": 5}, "action": {"text": "operator", "start": 97, "end": 105, "i_start": 17, "i_end": 17}}], "id": 1782}, {"sent": "for the depth network , we use the resnet-50 activation functions .", "tokens": ["for", "the", "depth", "network", ",", "we", "use", "the", "resnet-50", "activation", "functions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 27, "end": 30, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 27, "end": 30, "i_start": 6, "i_end": 6}}], "id": 1783}, {"sent": "as mentioned before , we use the resnet-152 classifier trained on imagenet as our encoder .", "tokens": ["as", "mentioned", "before", ",", "we", "use", "the", "resnet-152", "classifier", "trained", "on", "imagenet", "as", "our", "encoder", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 22, "end": 24, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 25, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 25, "end": 28, "i_start": 5, "i_end": 5}}], "id": 1784}, {"sent": "the nuclear norm is essentially an l 1 -norm of the singular values and it is well known that l 1 -norm has a shrinkage effect and leads to a biased estimator .", "tokens": ["the", "nuclear", "norm", "is", "essentially", "an", "l", "1", "-norm", "of", "the", "singular", "values", "and", "it", "is", "well", "known", "that", "l", "1", "-norm", "has", "a", "shrinkage", "effect", "and", "leads", "to", "a", "biased", "estimator", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the nuclear norm", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 1785}, {"sent": "variational autoencoders are a fascinating facet of autoencoders , supporting , among other things , random generation of new data samples .", "tokens": ["variational", "autoencoders", "are", "a", "fascinating", "facet", "of", "autoencoders", ",", "supporting", ",", "among", "other", "things", ",", "random", "generation", "of", "new", "data", "samples", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "variational autoencoders", "start": 0, "end": 24, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 25, "end": 28, "i_start": 2, "i_end": 2}}, {"character": {"text": "facet", "start": 43, "end": 48, "i_start": 5, "i_end": 5}, "action": {"text": "fascinating", "start": 31, "end": 42, "i_start": 4, "i_end": 4}}, {"character": {"text": "facet", "start": 43, "end": 48, "i_start": 5, "i_end": 5}, "action": {"text": "supporting", "start": 67, "end": 77, "i_start": 9, "i_end": 9}}], "id": 1786}, {"sent": "deep convolutional neural networks have made significant progress in classification problems , which have shown to generate good results when provided sufficient data .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "significant", "progress", "in", "classification", "problems", ",", "which", "have", "shown", "to", "generate", "good", "results", "when", "provided", "sufficient", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "problems", "start": 84, "end": 92, "i_start": 10, "i_end": 10}, "action": {"text": "generate", "start": 115, "end": 123, "i_start": 16, "i_end": 16}}, {"character": {"text": "data", "start": 162, "end": 166, "i_start": 22, "i_end": 22}, "action": {"text": "sufficient", "start": 151, "end": 161, "i_start": 21, "i_end": 21}}], "id": 1787}, {"sent": "string theory is a top-to-bottom approach to quantum supergravity in that it postulates a new object , the string , from which classical supergravity emerges as a low energy limit .", "tokens": ["string", "theory", "is", "a", "top", "-", "to", "-", "bottom", "approach", "to", "quantum", "supergravity", "in", "that", "it", "postulates", "a", "new", "object", ",", "the", "string", ",", "from", "which", "classical", "supergravity", "emerges", "as", "a", "low", "energy", "limit", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "string theory", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "theory", "start": 7, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "approach", "start": 33, "end": 41, "i_start": 9, "i_end": 9}}, {"character": {"text": "supergravity", "start": 137, "end": 149, "i_start": 27, "i_end": 27}, "action": {"text": "emerges", "start": 150, "end": 157, "i_start": 28, "i_end": 28}}], "id": 1788}, {"sent": "specifically , we have shown how to account for real heat pulse shapes and two-layer samples using the recently-proposed rear-surface integral method .", "tokens": ["specifically", ",", "we", "have", "shown", "how", "to", "account", "for", "real", "heat", "pulse", "shapes", "and", "two", "-", "layer", "samples", "using", "the", "recently", "-", "proposed", "rear", "-", "surface", "integral", "method", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "have shown", "start": 18, "end": 28, "i_start": 3, "i_end": 4}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 23, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "account", "start": 36, "end": 43, "i_start": 7, "i_end": 7}}], "id": 1789}, {"sent": "in the chemical context , it represents a chemical species with chemical potential replacing voltage and molar flow replacing current , oster et al , 1971 , oster et al , 1973 .", "tokens": ["in", "the", "chemical", "context", ",", "it", "represents", "a", "chemical", "species", "with", "chemical", "potential", "replacing", "voltage", "and", "molar", "flow", "replacing", "current", ",", "oster", "et", "al", ",", "1971", ",", "oster", "et", "al", ",", "1973", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "verb": {"text": "represents", "start": 29, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "it", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "represents", "start": 29, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "potential", "start": 73, "end": 82, "i_start": 12, "i_end": 12}, "action": {"text": "replacing", "start": 83, "end": 92, "i_start": 13, "i_end": 13}}, {"character": {"text": "flow", "start": 111, "end": 115, "i_start": 17, "i_end": 17}, "action": {"text": "replacing", "start": 116, "end": 125, "i_start": 18, "i_end": 18}}], "id": 1790}, {"sent": "in 1950 , nash introduced his fundamental concept of equilibrium for n-person games .", "tokens": ["in", "1950", ",", "nash", "introduced", "his", "fundamental", "concept", "of", "equilibrium", "for", "n", "-", "person", "games", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "nash", "start": 10, "end": 14, "i_start": 3, "i_end": 3}, "verb": {"text": "introduced", "start": 15, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "nash", "start": 10, "end": 14, "i_start": 3, "i_end": 3}, "action": {"text": "introduced", "start": 15, "end": 25, "i_start": 4, "i_end": 4}}], "id": 1791}, {"sent": "unfortunately , constructing such a coupling to a matter field generically re-introduces the bd ghost already at the classical level .", "tokens": ["unfortunately", ",", "constructing", "such", "a", "coupling", "to", "a", "matter", "field", "generically", "re", "-", "introduces", "the", "bd", "ghost", "already", "at", "the", "classical", "level", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "constructing such a coupling to a matter field generically re-", "start": 16, "end": 78, "i_start": 2, "i_end": 12}, "verb": {"text": "introduces", "start": 78, "end": 88, "i_start": 13, "i_end": 13}}], "id": 1792}, {"sent": "again the vacuum configuration is obtained by minimizing the effective potential numerically .", "tokens": ["again", "the", "vacuum", "configuration", "is", "obtained", "by", "minimizing", "the", "effective", "potential", "numerically", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the vacuum configuration", "start": 6, "end": 30, "i_start": 1, "i_end": 3}, "verb": {"text": "is obtained", "start": 31, "end": 42, "i_start": 4, "i_end": 5}}, {"character": {"text": "potential", "start": 71, "end": 80, "i_start": 10, "i_end": 10}, "action": {"text": "effective", "start": 61, "end": 70, "i_start": 9, "i_end": 9}}], "id": 1793}, {"sent": "consequently , the metallicity is a relevant parameter .", "tokens": ["consequently", ",", "the", "metallicity", "is", "a", "relevant", "parameter", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the metallicity", "start": 15, "end": 30, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 4, "i_end": 4}}], "id": 1794}, {"sent": "the caching problem has also been extended in various directions , including decentralized caching .", "tokens": ["the", "caching", "problem", "has", "also", "been", "extended", "in", "various", "directions", ",", "including", "decentralized", "caching", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the caching problem", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "been extended", "start": 29, "end": 42, "i_start": 5, "i_end": 6}}, {"subject": {"text": "the caching problem", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "has", "start": 20, "end": 23, "i_start": 3, "i_end": 3}}], "id": 1795}, {"sent": "the eigenvalue decomposition ofm3 has a complexity of o k 4 logto compute each eigenvector up to an accuracy of .", "tokens": ["the", "eigenvalue", "decomposition", "ofm3", "has", "a", "complexity", "of", "o", "k", "4", "logto", "compute", "each", "eigenvector", "up", "to", "an", "accuracy", "of", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the eigenvalue decomposition ofm3", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "has", "start": 34, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "decomposition", "start": 15, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "has", "start": 34, "end": 37, "i_start": 4, "i_end": 4}}], "id": 1796}, {"sent": "the time scattering transform extends the mel-spectrogram and partially recovers this lost structure while maintaining invariance and stability .", "tokens": ["the", "time", "scattering", "transform", "extends", "the", "mel", "-", "spectrogram", "and", "partially", "recovers", "this", "lost", "structure", "while", "maintaining", "invariance", "and", "stability", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the time scattering transform", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "extends", "start": 30, "end": 37, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the time scattering transform", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "recovers", "start": 72, "end": 80, "i_start": 11, "i_end": 11}}, {"character": {"text": "transform", "start": 20, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "extends", "start": 30, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "transform", "start": 20, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "recovers", "start": 72, "end": 80, "i_start": 11, "i_end": 11}}, {"character": {"text": "transform", "start": 20, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "maintaining", "start": 107, "end": 118, "i_start": 16, "i_end": 16}}], "id": 1797}, {"sent": "cognitive radio is an interesting technology that allows the access for unlicensed secondary users to communicate in parts of the licensed spectrum bands when they are not in use by the licensed primary users .", "tokens": ["cognitive", "radio", "is", "an", "interesting", "technology", "that", "allows", "the", "access", "for", "unlicensed", "secondary", "users", "to", "communicate", "in", "parts", "of", "the", "licensed", "spectrum", "bands", "when", "they", "are", "not", "in", "use", "by", "the", "licensed", "primary", "users", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cognitive radio", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "technology", "start": 34, "end": 44, "i_start": 5, "i_end": 5}, "action": {"text": "allows", "start": 50, "end": 56, "i_start": 7, "i_end": 7}}, {"character": {"text": "secondary", "start": 83, "end": 92, "i_start": 12, "i_end": 12}, "action": {"text": "access", "start": 61, "end": 67, "i_start": 9, "i_end": 9}}, {"character": {"text": "secondary", "start": 83, "end": 92, "i_start": 12, "i_end": 12}, "action": {"text": "communicate", "start": 102, "end": 113, "i_start": 15, "i_end": 15}}], "id": 1798}, {"sent": "pease , shostak , and lamport introduced in 1980 the byzantine agreement problem , arguably the most fundamental problem in distributed computing .", "tokens": ["pease", ",", "shostak", ",", "and", "lamport", "introduced", "in", "1980", "the", "byzantine", "agreement", "problem", ",", "arguably", "the", "most", "fundamental", "problem", "in", "distributed", "computing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "pease", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "introduced", "start": 30, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "pease", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 30, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "shostak", "start": 8, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 30, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "lamport", "start": 22, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 30, "end": 40, "i_start": 6, "i_end": 6}}], "id": 1799}, {"sent": "the details of this construction are exactly as in the proof of the existence of f .", "tokens": ["the", "details", "of", "this", "construction", "are", "exactly", "as", "in", "the", "proof", "of", "the", "existence", "of", "f", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the details of this construction", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "are", "start": 33, "end": 36, "i_start": 5, "i_end": 5}}], "id": 1800}, {"sent": "then the above geometry is the full geometry rather than just the pointwise geometry , since the geometry is the same at each point .", "tokens": ["then", "the", "above", "geometry", "is", "the", "full", "geometry", "rather", "than", "just", "the", "pointwise", "geometry", ",", "since", "the", "geometry", "is", "the", "same", "at", "each", "point", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the above geometry", "start": 5, "end": 23, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 4, "i_end": 4}}], "id": 1801}, {"sent": "we initialize a fully convolutional residual network from the original version of resnet .", "tokens": ["we", "initialize", "a", "fully", "convolutional", "residual", "network", "from", "the", "original", "version", "of", "resnet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "initialize", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "initialize", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}], "id": 1802}, {"sent": "for the shared encoder , we use the resnet-50 to produce rich and contextual features .", "tokens": ["for", "the", "shared", "encoder", ",", "we", "use", "the", "resnet-50", "to", "produce", "rich", "and", "contextual", "features", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 28, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 28, "end": 31, "i_start": 6, "i_end": 6}}], "id": 1803}, {"sent": "the panel restricted eigenvalue condition looks similar to the one introduced in bickel et al .", "tokens": ["the", "panel", "restricted", "eigenvalue", "condition", "looks", "similar", "to", "the", "one", "introduced", "in", "bickel", "et", "al", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the panel", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "restricted", "start": 10, "end": 20, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the panel", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "looks", "start": 42, "end": 47, "i_start": 5, "i_end": 5}}, {"character": {"text": "condition", "start": 32, "end": 41, "i_start": 4, "i_end": 4}, "action": {"text": "looks", "start": 42, "end": 47, "i_start": 5, "i_end": 5}}, {"character": {"text": "panel", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "restricted", "start": 10, "end": 20, "i_start": 2, "i_end": 2}}], "id": 1804}, {"sent": "deep learning has been used as a dramatically powerful tool in computer vision tasks such as image recognition .", "tokens": ["deep", "learning", "has", "been", "used", "as", "a", "dramatically", "powerful", "tool", "in", "computer", "vision", "tasks", "such", "as", "image", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has been used", "start": 14, "end": 27, "i_start": 2, "i_end": 4}}], "id": 1805}, {"sent": "mrk 1044 mrk 1044 is a nls1 with the hst in the near-ir , as is also the case in our h- and k-band images .", "tokens": ["mrk", "1044", "mrk", "1044", "is", "a", "nls1", "with", "the", "hst", "in", "the", "near", "-", "ir", ",", "as", "is", "also", "the", "case", "in", "our", "h-", "and", "k", "-", "band", "images", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "mrk 1044 mrk 1044", "start": 0, "end": 17, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 4, "i_end": 4}}], "id": 1806}, {"sent": "in , an ap-proximation algorithm for the three-dimensional bin packing problems is proposed and the performance is investigated .", "tokens": ["in", ",", "an", "ap", "-", "proximation", "algorithm", "for", "the", "three", "-", "dimensional", "bin", "packing", "problems", "is", "proposed", "and", "the", "performance", "is", "investigated", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "an ap-proximation algorithm for the three-dimensional bin packing problems", "start": 5, "end": 79, "i_start": 2, "i_end": 14}, "verb": {"text": "is proposed", "start": 80, "end": 91, "i_start": 15, "i_end": 16}}, {"subject": {"text": "the performance", "start": 96, "end": 111, "i_start": 18, "i_end": 19}, "verb": {"text": "investigated", "start": 115, "end": 127, "i_start": 21, "i_end": 21}}], "id": 1807}, {"sent": "some modelingbased age progression methods have been proposed , including active appearance model , etc .", "tokens": ["some", "modelingbased", "age", "progression", "methods", "have", "been", "proposed", ",", "including", "active", "appearance", "model", ",", "etc", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "some modelingbased age progression methods have been proposed , including active appearance model", "start": 0, "end": 97, "i_start": 0, "i_end": 12}, "verb": {"text": "have been proposed", "start": 43, "end": 61, "i_start": 5, "i_end": 7}}, {"character": {"text": "modelingbased", "start": 5, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "active", "start": 74, "end": 80, "i_start": 10, "i_end": 10}}], "id": 1808}, {"sent": "finally , we solve the problem using a recent characterization of quasi-line graphs by chudnovsky and seymour .", "tokens": ["finally", ",", "we", "solve", "the", "problem", "using", "a", "recent", "characterization", "of", "quasi", "-", "line", "graphs", "by", "chudnovsky", "and", "seymour", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "solve", "start": 13, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "solve", "start": 13, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "chudnovsky", "start": 87, "end": 97, "i_start": 16, "i_end": 16}, "action": {"text": "characterization", "start": 46, "end": 62, "i_start": 9, "i_end": 9}}, {"character": {"text": "seymour", "start": 102, "end": 109, "i_start": 18, "i_end": 18}, "action": {"text": "characterization", "start": 46, "end": 62, "i_start": 9, "i_end": 9}}], "id": 1809}, {"sent": "however , has also shown that total interpretability of an embedding is kept constant under any orthogonal transformation and it can only be redistributed across the dimensions .", "tokens": ["however", ",", "has", "also", "shown", "that", "total", "interpretability", "of", "an", "embedding", "is", "kept", "constant", "under", "any", "orthogonal", "transformation", "and", "it", "can", "only", "be", "redistributed", "across", "the", "dimensions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "that total interpretability of an embedding", "start": 25, "end": 68, "i_start": 5, "i_end": 10}, "verb": {"text": "shown", "start": 19, "end": 24, "i_start": 4, "i_end": 4}}, {"subject": {"text": "that total interpretability of an embedding", "start": 25, "end": 68, "i_start": 5, "i_end": 10}, "verb": {"text": "has", "start": 10, "end": 13, "i_start": 2, "i_end": 2}}, {"subject": {"text": "that total interpretability of an embedding", "start": 25, "end": 68, "i_start": 5, "i_end": 10}, "verb": {"text": "kept", "start": 72, "end": 76, "i_start": 12, "i_end": 12}}], "id": 1810}, {"sent": "deep convolutional neural networks have been prevailed in various computer vision tasks , such as objection classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "prevailed", "in", "various", "computer", "vision", "tasks", ",", "such", "as", "objection", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been prevailed", "start": 35, "end": 54, "i_start": 4, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "prevailed", "start": 45, "end": 54, "i_start": 6, "i_end": 6}}], "id": 1811}, {"sent": "for all systems , we use the adam optimizer with the identical settings to t2t , to tune the parameters .", "tokens": ["for", "all", "systems", ",", "we", "use", "the", "adam", "optimizer", "with", "the", "identical", "settings", "to", "t2", "t", ",", "to", "tune", "the", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 21, "end": 24, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 21, "end": 24, "i_start": 5, "i_end": 5}}], "id": 1812}, {"sent": "although their benefit in terms of low-cost personalised healthcare , however , previous literature has identified several technical and design related issues acting as barriers for wearable adoption in long-term .", "tokens": ["although", "their", "benefit", "in", "terms", "of", "low", "-", "cost", "personalised", "healthcare", ",", "however", ",", "previous", "literature", "has", "identified", "several", "technical", "and", "design", "related", "issues", "acting", "as", "barriers", "for", "wearable", "adoption", "in", "long", "-", "term", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "their benefit in terms of low-cost personalised healthcare , however , previous literature", "start": 9, "end": 99, "i_start": 1, "i_end": 15}, "verb": {"text": "has identified", "start": 100, "end": 114, "i_start": 16, "i_end": 17}}, {"character": {"text": "literature", "start": 89, "end": 99, "i_start": 15, "i_end": 15}, "action": {"text": "identified", "start": 104, "end": 114, "i_start": 17, "i_end": 17}}, {"character": {"text": "and", "start": 133, "end": 136, "i_start": 20, "i_end": 20}, "action": {"text": "acting", "start": 159, "end": 165, "i_start": 24, "i_end": 24}}], "id": 1813}, {"sent": "the time-stepping is handled via standard total-variation diminishing runge-kutta methods .", "tokens": ["the", "time", "-", "stepping", "is", "handled", "via", "standard", "total", "-", "variation", "diminishing", "runge", "-", "kutta", "methods", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the time-stepping", "start": 0, "end": 17, "i_start": 0, "i_end": 3}, "verb": {"text": "is handled", "start": 18, "end": 28, "i_start": 4, "i_end": 5}}, {"character": {"text": "methods", "start": 82, "end": 89, "i_start": 15, "i_end": 15}, "action": {"text": "diminishing", "start": 58, "end": 69, "i_start": 11, "i_end": 11}}], "id": 1814}, {"sent": "heterogeneous information network has been extensively studied as a powerful and effective paradigm to model networked data with rich and informative type information .", "tokens": ["heterogeneous", "information", "network", "has", "been", "extensively", "studied", "as", "a", "powerful", "and", "effective", "paradigm", "to", "model", "networked", "data", "with", "rich", "and", "informative", "type", "information", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "heterogeneous information network", "start": 0, "end": 33, "i_start": 0, "i_end": 2}, "verb": {"text": "studied", "start": 55, "end": 62, "i_start": 6, "i_end": 6}}, {"subject": {"text": "heterogeneous information network", "start": 0, "end": 33, "i_start": 0, "i_end": 2}, "verb": {"text": "has been", "start": 34, "end": 42, "i_start": 3, "i_end": 4}}, {"character": {"text": "information", "start": 155, "end": 166, "i_start": 22, "i_end": 22}, "action": {"text": "informative", "start": 138, "end": 149, "i_start": 20, "i_end": 20}}, {"character": {"text": "paradigm", "start": 91, "end": 99, "i_start": 12, "i_end": 12}, "action": {"text": "effective", "start": 81, "end": 90, "i_start": 11, "i_end": 11}}], "id": 1815}, {"sent": "deep convolutional neural networks have achieved dramatic accuracy improvements in many areas of computer vision .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "dramatic", "accuracy", "improvements", "in", "many", "areas", "of", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "improvements", "start": 67, "end": 79, "i_start": 8, "i_end": 8}}], "id": 1816}, {"sent": "it has recently been proved that mimo decoding based on lll reduction followed by zero-forcing achieves the receive diversity .", "tokens": ["it", "has", "recently", "been", "proved", "that", "mimo", "decoding", "based", "on", "lll", "reduction", "followed", "by", "zero", "-", "forcing", "achieves", "the", "receive", "diversity", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "mimo decoding based on lll reduction followed by zero-forcing", "start": 33, "end": 94, "i_start": 6, "i_end": 16}, "verb": {"text": "been proved", "start": 16, "end": 27, "i_start": 3, "i_end": 4}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "achieves", "start": 95, "end": 103, "i_start": 17, "i_end": 17}}, {"character": {"text": "proved", "start": 21, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "achieves", "start": 95, "end": 103, "i_start": 17, "i_end": 17}}], "id": 1817}, {"sent": "it has been pointed out that sense distinctions in wordnet might be too fine-grained to be useful for many nlp applications .", "tokens": ["it", "has", "been", "pointed", "out", "that", "sense", "distinctions", "in", "wordnet", "might", "be", "too", "fine", "-", "grained", "to", "be", "useful", "for", "many", "nlp", "applications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has been pointed out", "start": 3, "end": 23, "i_start": 1, "i_end": 4}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "be", "start": 65, "end": 67, "i_start": 11, "i_end": 11}}], "id": 1818}, {"sent": "volume of the hypersphere should be minimized for the data description .", "tokens": ["volume", "of", "the", "hypersphere", "should", "be", "minimized", "for", "the", "data", "description", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "volume of the hypersphere", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "should be minimized", "start": 26, "end": 45, "i_start": 4, "i_end": 6}}], "id": 1819}, {"sent": "all implementation is performed via pytorch an open source deep learning platform .", "tokens": ["all", "implementation", "is", "performed", "via", "pytorch", "an", "open", "source", "deep", "learning", "platform", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all implementation", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is performed", "start": 19, "end": 31, "i_start": 2, "i_end": 3}}], "id": 1820}, {"sent": "for training all networks , we use the adam optimizer with a learning rate and batch size of 1e-4 and 32 , respectively .", "tokens": ["for", "training", "all", "networks", ",", "we", "use", "the", "adam", "optimizer", "with", "a", "learning", "rate", "and", "batch", "size", "of", "1e-4", "and", "32", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 28, "end": 30, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 31, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 28, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 31, "end": 34, "i_start": 6, "i_end": 6}}], "id": 1821}, {"sent": "see , and for various characterizations of this class of spaces .", "tokens": ["see", ",", "and", "for", "various", "characterizations", "of", "this", "class", "of", "spaces", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1822}, {"sent": "where the ellipsis denotes first order terms not involving any derivatives .", "tokens": ["where", "the", "ellipsis", "denotes", "first", "order", "terms", "not", "involving", "any", "derivatives", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ellipsis", "start": 6, "end": 18, "i_start": 1, "i_end": 2}, "verb": {"text": "denotes", "start": 19, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "ellipsis", "start": 10, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "denotes", "start": 19, "end": 26, "i_start": 3, "i_end": 3}}], "id": 1823}, {"sent": "in european symposium on research in computer security , pp .", "tokens": ["in", "european", "symposium", "on", "research", "in", "computer", "security", ",", "pp", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1824}, {"sent": "doersch et al train the network by inferring the relative positions between sampled patches from an image as self-supervised information .", "tokens": ["doersch", "et", "al", "train", "the", "network", "by", "inferring", "the", "relative", "positions", "between", "sampled", "patches", "from", "an", "image", "as", "self", "-", "supervised", "information", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 8, "end": 13, "i_start": 1, "i_end": 2}, "verb": {"text": "doersch", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}, {"subject": {"text": "et al", "start": 8, "end": 13, "i_start": 1, "i_end": 2}, "verb": {"text": "train", "start": 14, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "doersch", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 14, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "doersch", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "inferring", "start": 35, "end": 44, "i_start": 7, "i_end": 7}}, {"character": {"text": "doersch", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "supervised", "start": 114, "end": 124, "i_start": 20, "i_end": 20}}], "id": 1825}, {"sent": "for the work discussed here we use the perdew-burke-ernzerhof generalized gradient approximation .", "tokens": ["for", "the", "work", "discussed", "here", "we", "use", "the", "perdew", "-", "burke", "-", "ernzerhof", "generalized", "gradient", "approximation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 28, "end": 30, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 31, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 28, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 31, "end": 34, "i_start": 6, "i_end": 6}}], "id": 1826}, {"sent": "motivated by the overwhelming success of convolutional neural networks , we adopt a similar architecture .", "tokens": ["motivated", "by", "the", "overwhelming", "success", "of", "convolutional", "neural", "networks", ",", "we", "adopt", "a", "similar", "architecture", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 73, "end": 75, "i_start": 10, "i_end": 10}, "verb": {"text": "adopt", "start": 76, "end": 81, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 73, "end": 75, "i_start": 10, "i_end": 10}, "action": {"text": "adopt", "start": 76, "end": 81, "i_start": 11, "i_end": 11}}, {"character": {"text": "success", "start": 30, "end": 37, "i_start": 4, "i_end": 4}, "action": {"text": "motivated", "start": 0, "end": 9, "i_start": 0, "i_end": 0}}, {"character": {"text": "networks", "start": 62, "end": 70, "i_start": 8, "i_end": 8}, "action": {"text": "success", "start": 30, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "success", "start": 30, "end": 37, "i_start": 4, "i_end": 4}, "action": {"text": "overwhelming", "start": 17, "end": 29, "i_start": 3, "i_end": 3}}], "id": 1827}, {"sent": "we have then extracted cosmological parameters from current data using a monte carlo markov chain analysis based on the publicly available mcmc package cosmomc .", "tokens": ["we", "have", "then", "extracted", "cosmological", "parameters", "from", "current", "data", "using", "a", "monte", "carlo", "markov", "chain", "analysis", "based", "on", "the", "publicly", "available", "mcmc", "package", "cosmomc", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "extracted", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extracted", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "analysis", "start": 98, "end": 106, "i_start": 15, "i_end": 15}}], "id": 1828}, {"sent": "the adaptive construction method works well for reducing correlations between the sampled data .", "tokens": ["the", "adaptive", "construction", "method", "works", "well", "for", "reducing", "correlations", "between", "the", "sampled", "data", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the adaptive construction method", "start": 0, "end": 32, "i_start": 0, "i_end": 3}, "verb": {"text": "works", "start": 33, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "method", "start": 26, "end": 32, "i_start": 3, "i_end": 3}, "action": {"text": "reducing", "start": 48, "end": 56, "i_start": 7, "i_end": 7}}], "id": 1829}, {"sent": "the non-uniqueness can be interpreted as a non-uniqueness of the physical vacuum .", "tokens": ["the", "non", "-", "uniqueness", "can", "be", "interpreted", "as", "a", "non", "-", "uniqueness", "of", "the", "physical", "vacuum", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the non-uniqueness", "start": 0, "end": 18, "i_start": 0, "i_end": 3}, "verb": {"text": "can be interpreted", "start": 19, "end": 37, "i_start": 4, "i_end": 6}}], "id": 1830}, {"sent": "in a parallel work , we have successfully applied this approach to achieve fourth order accuracy for 3-d hyperbolic problems where all the physical quantities are discretized as volume averages .", "tokens": ["in", "a", "parallel", "work", ",", "we", "have", "successfully", "applied", "this", "approach", "to", "achieve", "fourth", "order", "accuracy", "for", "3", "-", "d", "hyperbolic", "problems", "where", "all", "the", "physical", "quantities", "are", "discretized", "as", "volume", "averages", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 5, "i_end": 5}, "verb": {"text": "applied", "start": 42, "end": 49, "i_start": 8, "i_end": 8}}, {"subject": {"text": "we", "start": 21, "end": 23, "i_start": 5, "i_end": 5}, "verb": {"text": "have", "start": 24, "end": 28, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 5, "i_end": 5}, "action": {"text": "applied", "start": 42, "end": 49, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 5, "i_end": 5}, "action": {"text": "achieve", "start": 67, "end": 74, "i_start": 12, "i_end": 12}}], "id": 1831}, {"sent": "our postulate is a straight generalization of this principle .", "tokens": ["our", "postulate", "is", "a", "straight", "generalization", "of", "this", "principle", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our postulate", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1832}, {"sent": "success of convolutional neural networks over the past several years has lead to their extensive deployment in a wide range of computer vision tasks .", "tokens": ["success", "of", "convolutional", "neural", "networks", "over", "the", "past", "several", "years", "has", "lead", "to", "their", "extensive", "deployment", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "success of convolutional neural networks over the past several years", "start": 0, "end": 68, "i_start": 0, "i_end": 9}, "verb": {"text": "has lead", "start": 69, "end": 77, "i_start": 10, "i_end": 11}}, {"character": {"text": "success", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "lead", "start": 73, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "success", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}], "id": 1833}, {"sent": "superpotential , and this is the way we name w in this work .", "tokens": ["superpotential", ",", "and", "this", "is", "the", "way", "we", "name", "w", "in", "this", "work", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 37, "end": 39, "i_start": 7, "i_end": 7}, "action": {"text": "name", "start": 40, "end": 44, "i_start": 8, "i_end": 8}}], "id": 1834}, {"sent": "as the fabrication of an array of parallel line detectors is demanding , most experiments using integrating line detectors have been carried out using a single line detector , scanned on circular paths using scanning stages .", "tokens": ["as", "the", "fabrication", "of", "an", "array", "of", "parallel", "line", "detectors", "is", "demanding", ",", "most", "experiments", "using", "integrating", "line", "detectors", "have", "been", "carried", "out", "using", "a", "single", "line", "detector", ",", "scanned", "on", "circular", "paths", "using", "scanning", "stages", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "most experiments using integrating line detectors", "start": 73, "end": 122, "i_start": 13, "i_end": 18}, "verb": {"text": "have been carried out", "start": 123, "end": 144, "i_start": 19, "i_end": 22}}, {"subject": {"text": "most experiments using integrating line detectors", "start": 73, "end": 122, "i_start": 13, "i_end": 18}, "verb": {"text": "scanned", "start": 176, "end": 183, "i_start": 29, "i_end": 29}}, {"character": {"text": "experiments", "start": 78, "end": 89, "i_start": 14, "i_end": 14}, "action": {"text": "scanned", "start": 176, "end": 183, "i_start": 29, "i_end": 29}}], "id": 1835}, {"sent": "neural networks have attracted a significant amount of research interest in recent years due to the success of deep neural networks .", "tokens": ["neural", "networks", "have", "attracted", "a", "significant", "amount", "of", "research", "interest", "in", "recent", "years", "due", "to", "the", "success", "of", "deep", "neural", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have attracted", "start": 16, "end": 30, "i_start": 2, "i_end": 3}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "attracted", "start": 21, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 123, "end": 131, "i_start": 20, "i_end": 20}, "action": {"text": "success", "start": 100, "end": 107, "i_start": 16, "i_end": 16}}], "id": 1836}, {"sent": "frog is probably the most commonly-used approach for full characterization of ultrashort optical pulses due to its simplicity and good experimental performance .", "tokens": ["frog", "is", "probably", "the", "most", "commonly", "-", "used", "approach", "for", "full", "characterization", "of", "ultrashort", "optical", "pulses", "due", "to", "its", "simplicity", "and", "good", "experimental", "performance", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "frog", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 1837}, {"sent": "a crucial assumption in this theorem , is that the initial state approaches the euclidean vacuum for very high angular momentum modes .", "tokens": ["a", "crucial", "assumption", "in", "this", "theorem", ",", "is", "that", "the", "initial", "state", "approaches", "the", "euclidean", "vacuum", "for", "very", "high", "angular", "momentum", "modes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a crucial assumption in this theorem", "start": 0, "end": 36, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the initial state", "start": 47, "end": 64, "i_start": 9, "i_end": 11}, "verb": {"text": "approaches", "start": 65, "end": 75, "i_start": 12, "i_end": 12}}, {"character": {"text": "state", "start": 59, "end": 64, "i_start": 11, "i_end": 11}, "action": {"text": "approaches", "start": 65, "end": 75, "i_start": 12, "i_end": 12}}], "id": 1838}, {"sent": "in , achievable rate regions for the cc-ifc that consist of non-cooperative causal transmission protocols have been characterized .", "tokens": ["in", ",", "achievable", "rate", "regions", "for", "the", "cc", "-", "ifc", "that", "consist", "of", "non", "-", "cooperative", "causal", "transmission", "protocols", "have", "been", "characterized", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "achievable rate regions for the cc-ifc that consist of non-cooperative causal transmission protocols", "start": 5, "end": 105, "i_start": 2, "i_end": 18}, "verb": {"text": "have been characterized", "start": 106, "end": 129, "i_start": 19, "i_end": 21}}, {"character": {"text": "protocols", "start": 96, "end": 105, "i_start": 18, "i_end": 18}, "action": {"text": "-ifc that consist of non-cooperative", "start": 39, "end": 75, "i_start": 8, "i_end": 15}}], "id": 1839}, {"sent": "spielman and srivastava showed that sampling edges proportional to their leverage scores and rescaling them appropriately , produces a spectral sparsifier with oedges with high probability .", "tokens": ["spielman", "and", "srivastava", "showed", "that", "sampling", "edges", "proportional", "to", "their", "leverage", "scores", "and", "rescaling", "them", "appropriately", ",", "produces", "a", "spectral", "sparsifier", "with", "oedges", "with", "high", "probability", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "spielman and srivastava", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 24, "end": 30, "i_start": 3, "i_end": 3}}, {"subject": {"text": "sampling edges proportional to their leverage scores and rescaling them appropriately", "start": 36, "end": 121, "i_start": 5, "i_end": 15}, "verb": {"text": "produces", "start": 124, "end": 132, "i_start": 17, "i_end": 17}}, {"character": {"text": "spielman", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 24, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "srivastava", "start": 13, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "showed", "start": 24, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "sampling", "start": 36, "end": 44, "i_start": 5, "i_end": 5}, "action": {"text": "produces", "start": 124, "end": 132, "i_start": 17, "i_end": 17}}, {"character": {"text": "leverage", "start": 73, "end": 81, "i_start": 10, "i_end": 10}, "action": {"text": "produces", "start": 124, "end": 132, "i_start": 17, "i_end": 17}}, {"character": {"text": "and", "start": 9, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "produces", "start": 124, "end": 132, "i_start": 17, "i_end": 17}}, {"character": {"text": "spielman", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "produces", "start": 124, "end": 132, "i_start": 17, "i_end": 17}}, {"character": {"text": "srivastava", "start": 13, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "produces", "start": 124, "end": 132, "i_start": 17, "i_end": 17}}, {"character": {"text": "rescaling", "start": 93, "end": 102, "i_start": 13, "i_end": 13}, "action": {"text": "produces", "start": 124, "end": 132, "i_start": 17, "i_end": 17}}, {"character": {"text": "sampling", "start": 36, "end": 44, "i_start": 5, "i_end": 5}, "action": {"text": "produces", "start": 124, "end": 132, "i_start": 17, "i_end": 17}}, {"character": {"text": "leverage", "start": 73, "end": 81, "i_start": 10, "i_end": 10}, "action": {"text": "produces", "start": 124, "end": 132, "i_start": 17, "i_end": 17}}, {"character": {"text": "and", "start": 9, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "produces", "start": 124, "end": 132, "i_start": 17, "i_end": 17}}, {"character": {"text": "spielman", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "produces", "start": 124, "end": 132, "i_start": 17, "i_end": 17}}, {"character": {"text": "srivastava", "start": 13, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "produces", "start": 124, "end": 132, "i_start": 17, "i_end": 17}}], "id": 1840}, {"sent": "a spherical cored isothermal distribution for dark matter has been used .", "tokens": ["a", "spherical", "cored", "isothermal", "distribution", "for", "dark", "matter", "has", "been", "used", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a spherical cored isothermal distribution for dark matter", "start": 0, "end": 57, "i_start": 0, "i_end": 7}, "verb": {"text": "has been used", "start": 58, "end": 71, "i_start": 8, "i_end": 10}}], "id": 1841}, {"sent": "semantics preserving hashing transforms the provided semantic affinities to a probability distribution and approximates it with hash codes in a hamming space .", "tokens": ["semantics", "preserving", "hashing", "transforms", "the", "provided", "semantic", "affinities", "to", "a", "probability", "distribution", "and", "approximates", "it", "with", "hash", "codes", "in", "a", "hamming", "space", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "semantics preserving hashing", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "transforms", "start": 29, "end": 39, "i_start": 3, "i_end": 3}}, {"subject": {"text": "semantics preserving hashing", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "approximates", "start": 107, "end": 119, "i_start": 13, "i_end": 13}}, {"character": {"text": "semantics", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "transforms", "start": 29, "end": 39, "i_start": 3, "i_end": 3}}, {"character": {"text": "semantics", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "preserving", "start": 10, "end": 20, "i_start": 1, "i_end": 1}}, {"character": {"text": "semantics", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "approximates", "start": 107, "end": 119, "i_start": 13, "i_end": 13}}], "id": 1842}, {"sent": "for image representation , we take the output of the 2048-way pool5 layer from resnet-152 .", "tokens": ["for", "image", "representation", ",", "we", "take", "the", "output", "of", "the", "2048", "-", "way", "pool5", "layer", "from", "resnet-152", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 27, "end": 29, "i_start": 4, "i_end": 4}, "verb": {"text": "take", "start": 30, "end": 34, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 27, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "take", "start": 30, "end": 34, "i_start": 5, "i_end": 5}}], "id": 1843}, {"sent": "deep learning has achieved significant successes in prediction performance by learning latent representations from data-rich applications such as speech recognition , text understanding , and image recognition .", "tokens": ["deep", "learning", "has", "achieved", "significant", "successes", "in", "prediction", "performance", "by", "learning", "latent", "representations", "from", "data", "-", "rich", "applications", "such", "as", "speech", "recognition", ",", "text", "understanding", ",", "and", "image", "recognition", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has achieved", "start": 14, "end": 26, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 78, "end": 86, "i_start": 10, "i_end": 10}, "action": {"text": "achieved", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "learning", "start": 78, "end": 86, "i_start": 10, "i_end": 10}, "action": {"text": "successes", "start": 39, "end": 48, "i_start": 5, "i_end": 5}}], "id": 1844}, {"sent": "dialectic semantics for argumentation frameworks .", "tokens": ["dialectic", "semantics", "for", "argumentation", "frameworks", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1845}, {"sent": "we used the inception resnet model v2 , which combines inception and residual network architectures .", "tokens": ["we", "used", "the", "inception", "resnet", "model", "v2", ",", "which", "combines", "inception", "and", "residual", "network", "architectures", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "model", "start": 29, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "combines", "start": 46, "end": 54, "i_start": 9, "i_end": 9}}], "id": 1846}, {"sent": "random walk is a discrete time process with independent increments , and again a random walk under time reversal .", "tokens": ["random", "walk", "is", "a", "discrete", "time", "process", "with", "independent", "increments", ",", "and", "again", "a", "random", "walk", "under", "time", "reversal", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "random walk", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "increments", "start": 56, "end": 66, "i_start": 9, "i_end": 9}, "action": {"text": "independent", "start": 44, "end": 55, "i_start": 8, "i_end": 8}}], "id": 1847}, {"sent": "convolutional neural networks have been extensively studied in the computer vision literature to tackle a variety of tasks , such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "been", "extensively", "studied", "in", "the", "computer", "vision", "literature", "to", "tackle", "a", "variety", "of", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "studied", "start": 52, "end": 59, "i_start": 6, "i_end": 6}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "tackle", "start": 97, "end": 103, "i_start": 13, "i_end": 13}}], "id": 1848}, {"sent": "the ambiguity is due to the non-unique dependence of the kinetic energy on the metric tensor .", "tokens": ["the", "ambiguity", "is", "due", "to", "the", "non", "-", "unique", "dependence", "of", "the", "kinetic", "energy", "on", "the", "metric", "tensor", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ambiguity", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "energy", "start": 65, "end": 71, "i_start": 13, "i_end": 13}, "action": {"text": "dependence", "start": 39, "end": 49, "i_start": 9, "i_end": 9}}], "id": 1849}, {"sent": "this procedure is known as renormalization .", "tokens": ["this", "procedure", "is", "known", "as", "renormalization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this procedure", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is known", "start": 15, "end": 23, "i_start": 2, "i_end": 3}}], "id": 1850}, {"sent": "deep neural networks have achieved recordbreaking accuracy in many image classification tasks .", "tokens": ["deep", "neural", "networks", "have", "achieved", "recordbreaking", "accuracy", "in", "many", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}], "id": 1851}, {"sent": "we will be using the following notation throughout this section .", "tokens": ["we", "will", "be", "using", "the", "following", "notation", "throughout", "this", "section", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will be using", "start": 3, "end": 16, "i_start": 1, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 11, "end": 16, "i_start": 3, "i_end": 3}}], "id": 1852}, {"sent": "we recall that a strict lie 2-group is a lie groupoid equipped with a certain kind of monoidal structure .", "tokens": ["we", "recall", "that", "a", "strict", "lie", "2", "-", "group", "is", "a", "lie", "groupoid", "equipped", "with", "a", "certain", "kind", "of", "monoidal", "structure", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "recall", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 36, "end": 38, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "recall", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 1853}, {"sent": "cluster algebras are introduced by sergey fomin and andrei zelevinsky in , and so on .", "tokens": ["cluster", "algebras", "are", "introduced", "by", "sergey", "fomin", "and", "andrei", "zelevinsky", "in", ",", "and", "so", "on", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "are introduced", "start": 17, "end": 31, "i_start": 2, "i_end": 3}}, {"character": {"text": "sergey fomin", "start": 35, "end": 47, "i_start": 5, "i_end": 6}, "action": {"text": "introduced", "start": 21, "end": 31, "i_start": 3, "i_end": 3}}, {"character": {"text": "andrei zelevinsky", "start": 52, "end": 69, "i_start": 8, "i_end": 9}, "action": {"text": "introduced", "start": 21, "end": 31, "i_start": 3, "i_end": 3}}], "id": 1854}, {"sent": "except for ki and k , the z-dependence is analytic .", "tokens": ["except", "for", "ki", "and", "k", ",", "the", "z", "-", "dependence", "is", "analytic", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the z-dependence", "start": 22, "end": 38, "i_start": 6, "i_end": 9}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 10, "i_end": 10}}], "id": 1855}, {"sent": "recent results , however , have demonstrated the feasibility of full-duplex wireless communication by suppressing or cancelling self-interference in the rf and baseband level .", "tokens": ["recent", "results", ",", "however", ",", "have", "demonstrated", "the", "feasibility", "of", "full", "-", "duplex", "wireless", "communication", "by", "suppressing", "or", "cancelling", "self", "-", "interference", "in", "the", "rf", "and", "baseband", "level", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent results", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "have demonstrated", "start": 27, "end": 44, "i_start": 5, "i_end": 6}}, {"character": {"text": "results", "start": 7, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "demonstrated", "start": 32, "end": 44, "i_start": 6, "i_end": 6}}, {"character": {"text": "self", "start": 128, "end": 132, "i_start": 19, "i_end": 19}, "action": {"text": "interference", "start": 133, "end": 145, "i_start": 21, "i_end": 21}}], "id": 1856}, {"sent": "this completes the proof that is a hausdorff locally compact space .", "tokens": ["this", "completes", "the", "proof", "that", "is", "a", "hausdorff", "locally", "compact", "space", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "completes", "start": 5, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "completes", "start": 5, "end": 14, "i_start": 1, "i_end": 1}}], "id": 1857}, {"sent": "for example , finn et al presented model-agnostic meta-learning to optimize the parameters of a meta-learner with the objective of maximizing its performance on a new task after a small number of gradient steps .", "tokens": ["for", "example", ",", "finn", "et", "al", "presented", "model", "-", "agnostic", "meta", "-", "learning", "to", "optimize", "the", "parameters", "of", "a", "meta", "-", "learner", "with", "the", "objective", "of", "maximizing", "its", "performance", "on", "a", "new", "task", "after", "a", "small", "number", "of", "gradient", "steps", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "finn et al", "start": 14, "end": 24, "i_start": 3, "i_end": 5}, "verb": {"text": "presented", "start": 25, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "finn", "start": 14, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "presented", "start": 25, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "learning", "start": 55, "end": 63, "i_start": 12, "i_end": 12}, "action": {"text": "agnostic", "start": 41, "end": 49, "i_start": 9, "i_end": 9}}, {"character": {"text": "finn", "start": 14, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "optimize", "start": 67, "end": 75, "i_start": 14, "i_end": 14}}, {"character": {"text": "finn", "start": 14, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "maximizing", "start": 131, "end": 141, "i_start": 26, "i_end": 26}}, {"character": {"text": "finn", "start": 14, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 146, "end": 157, "i_start": 28, "i_end": 28}}], "id": 1858}, {"sent": "the pileup contribution is estimated and subtracted from the jet energy using the jet area method on an event-by-event basis .", "tokens": ["the", "pileup", "contribution", "is", "estimated", "and", "subtracted", "from", "the", "jet", "energy", "using", "the", "jet", "area", "method", "on", "an", "event", "-", "by", "-", "event", "basis", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the pileup contribution", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is estimated", "start": 24, "end": 36, "i_start": 3, "i_end": 4}}, {"subject": {"text": "the pileup contribution", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "subtracted", "start": 41, "end": 51, "i_start": 6, "i_end": 6}}], "id": 1859}, {"sent": "important manifold learning algorithms include isometric feature mapping , locally linear embedding and laplacian eigenmaps .", "tokens": ["important", "manifold", "learning", "algorithms", "include", "isometric", "feature", "mapping", ",", "locally", "linear", "embedding", "and", "laplacian", "eigenmaps", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "important manifold learning algorithms", "start": 0, "end": 38, "i_start": 0, "i_end": 3}, "verb": {"text": "include", "start": 39, "end": 46, "i_start": 4, "i_end": 4}}], "id": 1860}, {"sent": "here , a flavour neutrino is a mixture of neutrino gravitational eigenstates and flavour-dependent neutrino-gravity couplings serve to lift the degeneracy .", "tokens": ["here", ",", "a", "flavour", "neutrino", "is", "a", "mixture", "of", "neutrino", "gravitational", "eigenstates", "and", "flavour", "-", "dependent", "neutrino", "-", "gravity", "couplings", "serve", "to", "lift", "the", "degeneracy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a flavour neutrino", "start": 7, "end": 25, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "couplings", "start": 116, "end": 125, "i_start": 19, "i_end": 19}, "action": {"text": "dependent", "start": 89, "end": 98, "i_start": 15, "i_end": 15}}], "id": 1861}, {"sent": "as in the previous case , every hyperplane node has degree gx .", "tokens": ["as", "in", "the", "previous", "case", ",", "every", "hyperplane", "node", "has", "degree", "gx", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "node", "start": 43, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "has", "start": 48, "end": 51, "i_start": 9, "i_end": 9}}], "id": 1862}, {"sent": "the legendre transformation of composed static systems .", "tokens": ["the", "legendre", "transformation", "of", "composed", "static", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1863}, {"sent": "an offset correction is applied to jet energies to take into account the contribution from pileup .", "tokens": ["an", "offset", "correction", "is", "applied", "to", "jet", "energies", "to", "take", "into", "account", "the", "contribution", "from", "pileup", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "an offset correction", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "is applied", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "correction", "start": 10, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "take", "start": 51, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "pileup", "start": 91, "end": 97, "i_start": 15, "i_end": 15}, "action": {"text": "contribution", "start": 73, "end": 85, "i_start": 13, "i_end": 13}}], "id": 1864}, {"sent": "these solutions may be obtained just by using general formulas for nonextremal black brane solutions from , .", "tokens": ["these", "solutions", "may", "be", "obtained", "just", "by", "using", "general", "formulas", "for", "nonextremal", "black", "brane", "solutions", "from", ",", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these solutions", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "may be obtained", "start": 16, "end": 31, "i_start": 2, "i_end": 4}}], "id": 1865}, {"sent": "the model is optimized using the adam optimizer , with a mini-batch size of 128 examples .", "tokens": ["the", "model", "is", "optimized", "using", "the", "adam", "optimizer", ",", "with", "a", "mini", "-", "batch", "size", "of", "128", "examples", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is optimized", "start": 10, "end": 22, "i_start": 2, "i_end": 3}}], "id": 1866}, {"sent": "convolutional neural networks have recently demonstrated impressive performance on various computer vision tasks such as semantic image segmentation and alike .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "demonstrated", "impressive", "performance", "on", "various", "computer", "vision", "tasks", "such", "as", "semantic", "image", "segmentation", "and", "alike", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "demonstrated", "start": 44, "end": 56, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 44, "end": 56, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 68, "end": 79, "i_start": 7, "i_end": 7}}, {"character": {"text": "demonstrated", "start": 44, "end": 56, "i_start": 5, "i_end": 5}, "action": {"text": "impressive", "start": 57, "end": 67, "i_start": 6, "i_end": 6}}], "id": 1867}, {"sent": "deep learning is widely used for image classification with great success .", "tokens": ["deep", "learning", "is", "widely", "used", "for", "image", "classification", "with", "great", "success", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "used", "start": 24, "end": 28, "i_start": 4, "i_end": 4}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1868}, {"sent": "thesis , american university , washington dc .", "tokens": ["thesis", ",", "american", "university", ",", "washington", "dc", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1869}, {"sent": "convolutional neural networks have achieved tremendous progress on many pattern recognition tasks , especially large-scale images recognition problems .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "tremendous", "progress", "on", "many", "pattern", "recognition", "tasks", ",", "especially", "large", "-", "scale", "images", "recognition", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 1870}, {"sent": "maps in the universe are represented by the sheaf morphisms .", "tokens": ["maps", "in", "the", "universe", "are", "represented", "by", "the", "sheaf", "morphisms", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "maps in the universe", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "are represented", "start": 21, "end": 36, "i_start": 4, "i_end": 5}}, {"character": {"text": "morphisms", "start": 50, "end": 59, "i_start": 9, "i_end": 9}, "action": {"text": "represented", "start": 25, "end": 36, "i_start": 5, "i_end": 5}}], "id": 1871}, {"sent": "the coupling constant is the only dimensionful quantity entering the dses .", "tokens": ["the", "coupling", "constant", "is", "the", "only", "dimensionful", "quantity", "entering", "the", "dses", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the coupling constant", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 1872}, {"sent": "penalized estimation in semiparametric models .", "tokens": ["penalized", "estimation", "in", "semiparametric", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1873}, {"sent": "pga is an algebraic theory of single-pass instruction sequences that was taken as the basis of an approach to the semantics of programming languages introduced in .", "tokens": ["pga", "is", "an", "algebraic", "theory", "of", "single", "-", "pass", "instruction", "sequences", "that", "was", "taken", "as", "the", "basis", "of", "an", "approach", "to", "the", "semantics", "of", "programming", "languages", "introduced", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "pga", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 4, "end": 6, "i_start": 1, "i_end": 1}}], "id": 1874}, {"sent": "deep neural networks have demonstrated excellent performance on challenging tasks and pushed the frontiers of impactful applications such as image recognition .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "excellent", "performance", "on", "challenging", "tasks", "and", "pushed", "the", "frontiers", "of", "impactful", "applications", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "pushed", "start": 86, "end": 92, "i_start": 11, "i_end": 11}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 49, "end": 60, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "pushed", "start": 86, "end": 92, "i_start": 11, "i_end": 11}}, {"character": {"text": "applications", "start": 120, "end": 132, "i_start": 16, "i_end": 16}, "action": {"text": "impactful", "start": 110, "end": 119, "i_start": 15, "i_end": 15}}], "id": 1875}, {"sent": "this means that the total performance is limited by the latency of the network .", "tokens": ["this", "means", "that", "the", "total", "performance", "is", "limited", "by", "the", "latency", "of", "the", "network", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "means", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the total performance", "start": 16, "end": 37, "i_start": 3, "i_end": 5}, "verb": {"text": "limited", "start": 41, "end": 48, "i_start": 7, "i_end": 7}}, {"character": {"text": "latency", "start": 56, "end": 63, "i_start": 10, "i_end": 10}, "action": {"text": "limited", "start": 41, "end": 48, "i_start": 7, "i_end": 7}}], "id": 1876}, {"sent": "kenyon , the laplacian and dirac operators on critical planar graphs .", "tokens": ["kenyon", ",", "the", "laplacian", "and", "dirac", "operators", "on", "critical", "planar", "graphs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "and", "start": 23, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "operators", "start": 33, "end": 42, "i_start": 6, "i_end": 6}}], "id": 1877}, {"sent": "instead of using a nmos to cut off the sneak path , we use an operation-amplifier in each column to collect the current and transfer the current to the voltage output .", "tokens": ["instead", "of", "using", "a", "nmos", "to", "cut", "off", "the", "sneak", "path", ",", "we", "use", "an", "operation", "-", "amplifier", "in", "each", "column", "to", "collect", "the", "current", "and", "transfer", "the", "current", "to", "the", "voltage", "output", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 52, "end": 54, "i_start": 12, "i_end": 12}, "verb": {"text": "use", "start": 55, "end": 58, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 52, "end": 54, "i_start": 12, "i_end": 12}, "action": {"text": "using", "start": 11, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "amplifier", "start": 72, "end": 81, "i_start": 17, "i_end": 17}, "action": {"text": "collect", "start": 100, "end": 107, "i_start": 22, "i_end": 22}}, {"character": {"text": "amplifier", "start": 72, "end": 81, "i_start": 17, "i_end": 17}, "action": {"text": "transfer", "start": 124, "end": 132, "i_start": 26, "i_end": 26}}], "id": 1878}, {"sent": "it is essential that in the given case the gradient of the er concentration at the interface changes the sign , causing the interface to move in the opposite direction .", "tokens": ["it", "is", "essential", "that", "in", "the", "given", "case", "the", "gradient", "of", "the", "er", "concentration", "at", "the", "interface", "changes", "the", "sign", ",", "causing", "the", "interface", "to", "move", "in", "the", "opposite", "direction", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the gradient of the er concentration at the interface", "start": 39, "end": 92, "i_start": 8, "i_end": 16}, "verb": {"text": "changes", "start": 93, "end": 100, "i_start": 17, "i_end": 17}}, {"character": {"text": "gradient", "start": 43, "end": 51, "i_start": 9, "i_end": 9}, "action": {"text": "changes", "start": 93, "end": 100, "i_start": 17, "i_end": 17}}, {"character": {"text": "changes", "start": 93, "end": 100, "i_start": 17, "i_end": 17}, "action": {"text": "causing", "start": 112, "end": 119, "i_start": 21, "i_end": 21}}], "id": 1879}, {"sent": "generative models for image synthesis have shown impressive results with the arrival of adversarial training .", "tokens": ["generative", "models", "for", "image", "synthesis", "have", "shown", "impressive", "results", "with", "the", "arrival", "of", "adversarial", "training", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "generative models for image synthesis", "start": 0, "end": 37, "i_start": 0, "i_end": 4}, "verb": {"text": "have shown", "start": 38, "end": 48, "i_start": 5, "i_end": 6}}, {"character": {"text": "models", "start": 11, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "shown", "start": 43, "end": 48, "i_start": 6, "i_end": 6}}, {"character": {"text": "arrival", "start": 77, "end": 84, "i_start": 11, "i_end": 11}, "action": {"text": "results", "start": 60, "end": 67, "i_start": 8, "i_end": 8}}, {"character": {"text": "results", "start": 60, "end": 67, "i_start": 8, "i_end": 8}, "action": {"text": "impressive", "start": 49, "end": 59, "i_start": 7, "i_end": 7}}], "id": 1880}, {"sent": "the error bars represent the hipparcos determinations only .", "tokens": ["the", "error", "bars", "represent", "the", "hipparcos", "determinations", "only", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the error bars", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "represent", "start": 15, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "bars", "start": 10, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "represent", "start": 15, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "hipparcos", "start": 29, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "determinations", "start": 39, "end": 53, "i_start": 6, "i_end": 6}}], "id": 1881}, {"sent": "furthermore , the soft theorems and asymptotic symmetries are related to the traditional gravitational memory effect .", "tokens": ["furthermore", ",", "the", "soft", "theorems", "and", "asymptotic", "symmetries", "are", "related", "to", "the", "traditional", "gravitational", "memory", "effect", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the soft theorems and asymptotic symmetries", "start": 14, "end": 57, "i_start": 2, "i_end": 7}, "verb": {"text": "are related", "start": 58, "end": 69, "i_start": 8, "i_end": 9}}], "id": 1882}, {"sent": "specifically , we use vgg cnn m 1024 network models as the backbone-subnet .", "tokens": ["specifically", ",", "we", "use", "vgg", "cnn", "m", "1024", "network", "models", "as", "the", "backbone", "-", "subnet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "use", "start": 18, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 18, "end": 21, "i_start": 3, "i_end": 3}}], "id": 1883}, {"sent": "thus , the crucial feature characterizing accessibility is the matching of the claims and the outcomes of physical processes testing the claims 3 , ghirardi , p .", "tokens": ["thus", ",", "the", "crucial", "feature", "characterizing", "accessibility", "is", "the", "matching", "of", "the", "claims", "and", "the", "outcomes", "of", "physical", "processes", "testing", "the", "claims", "3", ",", "ghirardi", ",", "p", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the crucial feature characterizing accessibility", "start": 7, "end": 55, "i_start": 2, "i_end": 6}, "verb": {"text": "is", "start": 56, "end": 58, "i_start": 7, "i_end": 7}}, {"character": {"text": "feature", "start": 19, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "characterizing", "start": 27, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "processes", "start": 115, "end": 124, "i_start": 18, "i_end": 18}, "action": {"text": "testing", "start": 125, "end": 132, "i_start": 19, "i_end": 19}}], "id": 1884}, {"sent": "in summary , we have provided some conserved operators which can be diagonalised by the orthogonal state .", "tokens": ["in", "summary", ",", "we", "have", "provided", "some", "conserved", "operators", "which", "can", "be", "diagonalised", "by", "the", "orthogonal", "state", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "have provided", "start": 16, "end": 29, "i_start": 4, "i_end": 5}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "provided", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "state", "start": 99, "end": 104, "i_start": 16, "i_end": 16}, "action": {"text": "diagonalised", "start": 68, "end": 80, "i_start": 12, "i_end": 12}}], "id": 1885}, {"sent": "reference showed a connection between compressive sensing , nwidths , and the johnson-lindenstrauss lemma .", "tokens": ["reference", "showed", "a", "connection", "between", "compressive", "sensing", ",", "nwidths", ",", "and", "the", "johnson", "-", "lindenstrauss", "lemma", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "reference", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "showed", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "reference", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}], "id": 1886}, {"sent": "one earlier paper tangentially connected to estimating the poa of congestion games is .", "tokens": ["one", "earlier", "paper", "tangentially", "connected", "to", "estimating", "the", "poa", "of", "congestion", "games", "is", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "one earlier paper tangentially connected to estimating the poa of congestion games", "start": 0, "end": 82, "i_start": 0, "i_end": 11}, "verb": {"text": "is", "start": 83, "end": 85, "i_start": 12, "i_end": 12}}], "id": 1887}, {"sent": "in contrast , as demonstrated in , the bpr one-loop model with the scalar triplet as the largest weak representation exhibits , in addition to the absence of lp , perturbativity and stability up to the planck scale .", "tokens": ["in", "contrast", ",", "as", "demonstrated", "in", ",", "the", "bpr", "one", "-", "loop", "model", "with", "the", "scalar", "triplet", "as", "the", "largest", "weak", "representation", "exhibits", ",", "in", "addition", "to", "the", "absence", "of", "lp", ",", "perturbativity", "and", "stability", "up", "to", "the", "planck", "scale", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "model", "start": 52, "end": 57, "i_start": 12, "i_end": 12}, "action": {"text": "representation", "start": 102, "end": 116, "i_start": 21, "i_end": 21}}], "id": 1888}, {"sent": "importantly , it is also necessary , which can be , for example , deduced from the proof of positional determinacy for parity games due to emerson and jutla .", "tokens": ["importantly", ",", "it", "is", "also", "necessary", ",", "which", "can", "be", ",", "for", "example", ",", "deduced", "from", "the", "proof", "of", "positional", "determinacy", "for", "parity", "games", "due", "to", "emerson", "and", "jutla", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 1889}, {"sent": "any propositional formula can be represented in conjunctive normal form using a standard linear-size encoding .", "tokens": ["any", "propositional", "formula", "can", "be", "represented", "in", "conjunctive", "normal", "form", "using", "a", "standard", "linear", "-", "size", "encoding", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "any propositional formula", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "can be represented", "start": 26, "end": 44, "i_start": 3, "i_end": 5}}], "id": 1890}, {"sent": "instead , if the pressure increases , the system moves along the slow branch up to the other critical point e .", "tokens": ["instead", ",", "if", "the", "pressure", "increases", ",", "the", "system", "moves", "along", "the", "slow", "branch", "up", "to", "the", "other", "critical", "point", "e", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the system", "start": 38, "end": 48, "i_start": 7, "i_end": 8}, "verb": {"text": "moves", "start": 49, "end": 54, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the system", "start": 38, "end": 48, "i_start": 7, "i_end": 8}, "verb": {"text": "up", "start": 77, "end": 79, "i_start": 14, "i_end": 14}}], "id": 1891}, {"sent": "for instance , alps are a general consequence of the compactification of extra dimensions and string theory .", "tokens": ["for", "instance", ",", "alps", "are", "a", "general", "consequence", "of", "the", "compactification", "of", "extra", "dimensions", "and", "string", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "alps", "start": 15, "end": 19, "i_start": 3, "i_end": 3}, "verb": {"text": "are", "start": 20, "end": 23, "i_start": 4, "i_end": 4}}], "id": 1892}, {"sent": "this cancellation is a peculiarity of the melosh wave function .", "tokens": ["this", "cancellation", "is", "a", "peculiarity", "of", "the", "melosh", "wave", "function", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this cancellation", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}], "id": 1893}, {"sent": "in recent years , deep neural networks have developed advanced abilities in the feature extraction and function approximation .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "developed", "advanced", "abilities", "in", "the", "feature", "extraction", "and", "function", "approximation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have developed", "start": 39, "end": 53, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "developed", "start": 44, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "extraction", "start": 88, "end": 98, "i_start": 14, "i_end": 14}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "approximation", "start": 112, "end": 125, "i_start": 17, "i_end": 17}}], "id": 1894}, {"sent": "in this 2 as immirizi has emphasized , in the canonical transformation used to define the connection there is a family of choices generated by one non-zero , real parameter \u03b3 , .", "tokens": ["in", "this", "2", "as", "immirizi", "has", "emphasized", ",", "in", "the", "canonical", "transformation", "used", "to", "define", "the", "connection", "there", "is", "a", "family", "of", "choices", "generated", "by", "one", "non", "-", "zero", ",", "real", "parameter", "\u03b3", ",", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "there", "start": 101, "end": 106, "i_start": 17, "i_end": 17}, "verb": {"text": "is", "start": 107, "end": 109, "i_start": 18, "i_end": 18}}, {"character": {"text": "one non-zero , real parameter", "start": 143, "end": 172, "i_start": 25, "i_end": 31}, "action": {"text": "generated", "start": 130, "end": 139, "i_start": 23, "i_end": 23}}], "id": 1895}, {"sent": "their images under the sign map are known as eulerian idempotents .", "tokens": ["their", "images", "under", "the", "sign", "map", "are", "known", "as", "eulerian", "idempotents", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "their images under the sign map", "start": 0, "end": 31, "i_start": 0, "i_end": 5}, "verb": {"text": "are known", "start": 32, "end": 41, "i_start": 6, "i_end": 7}}], "id": 1896}, {"sent": "the equilibrium state for this dynamical system is called the hidden pattern .", "tokens": ["the", "equilibrium", "state", "for", "this", "dynamical", "system", "is", "called", "the", "hidden", "pattern", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the equilibrium state for this dynamical system", "start": 0, "end": 47, "i_start": 0, "i_end": 6}, "verb": {"text": "is called", "start": 48, "end": 57, "i_start": 7, "i_end": 8}}], "id": 1897}, {"sent": "techniques can be categorized into auto-encoders , autoregressive models , and conditional generative adversarial networks .", "tokens": ["techniques", "can", "be", "categorized", "into", "auto", "-", "encoders", ",", "autoregressive", "models", ",", "and", "conditional", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "techniques", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "verb": {"text": "can be categorized", "start": 11, "end": 29, "i_start": 1, "i_end": 3}}], "id": 1898}, {"sent": "multi-task learning aims to improve learning efficiency and prediction accuracy by learning multiple objectives from a shared representation .", "tokens": ["multi", "-", "task", "learning", "aims", "to", "improve", "learning", "efficiency", "and", "prediction", "accuracy", "by", "learning", "multiple", "objectives", "from", "a", "shared", "representation", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "multi-task learning", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "aims", "start": 20, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 36, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "aims", "start": 20, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 36, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "improve", "start": 28, "end": 35, "i_start": 6, "i_end": 6}}], "id": 1899}, {"sent": "cosmic strings are linear concentrations of energy that form whenever phase transitions in the early universe break axial symmetries .", "tokens": ["cosmic", "strings", "are", "linear", "concentrations", "of", "energy", "that", "form", "whenever", "phase", "transitions", "in", "the", "early", "universe", "break", "axial", "symmetries", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "transitions", "start": 76, "end": 87, "i_start": 11, "i_end": 11}, "action": {"text": "break", "start": 110, "end": 115, "i_start": 16, "i_end": 16}}], "id": 1900}, {"sent": "we implemented it using the 56-layer resnet , which produced 64-d features .", "tokens": ["we", "implemented", "it", "using", "the", "56", "-", "layer", "resnet", ",", "which", "produced", "64", "-", "d", "features", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implemented", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implemented", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 18, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "resnet", "start": 37, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "produced", "start": 52, "end": 60, "i_start": 11, "i_end": 11}}], "id": 1901}, {"sent": "its closure is a we show next that its spectrum is semi-bounded from below .", "tokens": ["its", "closure", "is", "a", "we", "show", "next", "that", "its", "spectrum", "is", "semi", "-", "bounded", "from", "below", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "its closure", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 17, "end": 19, "i_start": 4, "i_end": 4}, "action": {"text": "show", "start": 20, "end": 24, "i_start": 5, "i_end": 5}}], "id": 1902}, {"sent": "the electron exchangecorrelation functional was treated using the generalized gradient approximation in the form proposed by perdew , burke , and ernzerhof .", "tokens": ["the", "electron", "exchangecorrelation", "functional", "was", "treated", "using", "the", "generalized", "gradient", "approximation", "in", "the", "form", "proposed", "by", "perdew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electron exchangecorrelation functional", "start": 0, "end": 43, "i_start": 0, "i_end": 3}, "verb": {"text": "was treated", "start": 44, "end": 55, "i_start": 4, "i_end": 5}}, {"character": {"text": "perdew", "start": 125, "end": 131, "i_start": 16, "i_end": 16}, "action": {"text": "proposed", "start": 113, "end": 121, "i_start": 14, "i_end": 14}}, {"character": {"text": "burke", "start": 134, "end": 139, "i_start": 18, "i_end": 18}, "action": {"text": "proposed", "start": 113, "end": 121, "i_start": 14, "i_end": 14}}, {"character": {"text": "ernzerhof", "start": 146, "end": 155, "i_start": 21, "i_end": 21}, "action": {"text": "proposed", "start": 113, "end": 121, "i_start": 14, "i_end": 14}}], "id": 1903}, {"sent": "such phase transitions are called the reentrant phenomena .", "tokens": ["such", "phase", "transitions", "are", "called", "the", "reentrant", "phenomena", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such phase transitions", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "are called", "start": 23, "end": 33, "i_start": 3, "i_end": 4}}, {"character": {"text": "phenomena", "start": 48, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "reentrant", "start": 38, "end": 47, "i_start": 6, "i_end": 6}}], "id": 1904}, {"sent": "in comparison to the conventioal cell detection methods , deep neural networks recently has been applied to a variety of computer vision problems , and has achieved better performance on several benchmark vision datasets .", "tokens": ["in", "comparison", "to", "the", "conventioal", "cell", "detection", "methods", ",", "deep", "neural", "networks", "recently", "has", "been", "applied", "to", "a", "variety", "of", "computer", "vision", "problems", ",", "and", "has", "achieved", "better", "performance", "on", "several", "benchmark", "vision", "datasets", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 58, "end": 78, "i_start": 9, "i_end": 11}, "verb": {"text": "has been applied", "start": 88, "end": 104, "i_start": 13, "i_end": 15}}, {"subject": {"text": "deep neural networks", "start": 58, "end": 78, "i_start": 9, "i_end": 11}, "verb": {"text": "achieved", "start": 156, "end": 164, "i_start": 26, "i_end": 26}}, {"character": {"text": "networks", "start": 70, "end": 78, "i_start": 11, "i_end": 11}, "action": {"text": "achieved", "start": 156, "end": 164, "i_start": 26, "i_end": 26}}, {"character": {"text": "networks", "start": 70, "end": 78, "i_start": 11, "i_end": 11}, "action": {"text": "performance", "start": 172, "end": 183, "i_start": 28, "i_end": 28}}], "id": 1905}, {"sent": "recent results in deep learning indicate that over-parameterized neural networks can memorize arbitrary datasets .", "tokens": ["recent", "results", "in", "deep", "learning", "indicate", "that", "over", "-", "parameterized", "neural", "networks", "can", "memorize", "arbitrary", "datasets", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent results in deep learning", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "indicate", "start": 32, "end": 40, "i_start": 5, "i_end": 5}}, {"subject": {"text": "over-parameterized neural networks", "start": 46, "end": 80, "i_start": 7, "i_end": 11}, "verb": {"text": "memorize", "start": 85, "end": 93, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 72, "end": 80, "i_start": 11, "i_end": 11}, "action": {"text": "memorize", "start": 85, "end": 93, "i_start": 13, "i_end": 13}}], "id": 1906}, {"sent": "exchange-correlation was considered within the generalized gradient approximation , as proposed by perdew , burke , and ernzerhof .", "tokens": ["exchange", "-", "correlation", "was", "considered", "within", "the", "generalized", "gradient", "approximation", ",", "as", "proposed", "by", "perdew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "exchange-correlation", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "was considered", "start": 21, "end": 35, "i_start": 3, "i_end": 4}}, {"character": {"text": "perdew", "start": 99, "end": 105, "i_start": 14, "i_end": 14}, "action": {"text": "proposed", "start": 87, "end": 95, "i_start": 12, "i_end": 12}}, {"character": {"text": "burke", "start": 108, "end": 113, "i_start": 16, "i_end": 16}, "action": {"text": "proposed", "start": 87, "end": 95, "i_start": 12, "i_end": 12}}, {"character": {"text": "ernzerhof", "start": 120, "end": 129, "i_start": 19, "i_end": 19}, "action": {"text": "proposed", "start": 87, "end": 95, "i_start": 12, "i_end": 12}}], "id": 1907}, {"sent": "all implementation is performed via pytorch an open source deep learning platform .", "tokens": ["all", "implementation", "is", "performed", "via", "pytorch", "an", "open", "source", "deep", "learning", "platform", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all implementation", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is performed", "start": 19, "end": 31, "i_start": 2, "i_end": 3}}], "id": 1908}, {"sent": "the description of 1d many-electron systems in terms of bosonic density fluctuations is called bosonization .", "tokens": ["the", "description", "of", "1d", "many", "-", "electron", "systems", "in", "terms", "of", "bosonic", "density", "fluctuations", "is", "called", "bosonization", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the description of 1d many-electron systems in terms of bosonic density fluctuations", "start": 0, "end": 84, "i_start": 0, "i_end": 13}, "verb": {"text": "is called", "start": 85, "end": 94, "i_start": 14, "i_end": 15}}], "id": 1909}, {"sent": "temperature dependence of polarization .", "tokens": ["temperature", "dependence", "of", "polarization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "polarization", "start": 26, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "dependence", "start": 12, "end": 22, "i_start": 1, "i_end": 1}}], "id": 1910}, {"sent": "after each convolutional layer , there is a batch normalization layer and rectified linear unit activation function .", "tokens": ["after", "each", "convolutional", "layer", ",", "there", "is", "a", "batch", "normalization", "layer", "and", "rectified", "linear", "unit", "activation", "function", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 33, "end": 38, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 6, "i_end": 6}}], "id": 1911}, {"sent": "onstru tion , this is the ase if and only if all the leaves of \u03b3 are at the same level .", "tokens": ["onstru", "tion", ",", "this", "is", "the", "ase", "if", "and", "only", "if", "all", "the", "leaves", "of", "\u03b3", "are", "at", "the", "same", "level", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 14, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 4, "i_end": 4}}], "id": 1912}, {"sent": "this free energy is the difference between the free energy of a dna molecule in a bundle and that of an individual dna molecule in the bulk solution .", "tokens": ["this", "free", "energy", "is", "the", "difference", "between", "the", "free", "energy", "of", "a", "dna", "molecule", "in", "a", "bundle", "and", "that", "of", "an", "individual", "dna", "molecule", "in", "the", "bulk", "solution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this free energy", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 1913}, {"sent": "the critical wavelength , although does not depend on the nature and strength of the interaction , does depend strongly on the thicknesses and moduli of the film .", "tokens": ["the", "critical", "wavelength", ",", "although", "does", "not", "depend", "on", "the", "nature", "and", "strength", "of", "the", "interaction", ",", "does", "depend", "strongly", "on", "the", "thicknesses", "and", "moduli", "of", "the", "film", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "the critical wavelength", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "does depend", "start": 99, "end": 110, "i_start": 17, "i_end": 18}}, {"subject": {"text": "the critical wavelength", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "depend", "start": 44, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "wavelength", "start": 13, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "depend", "start": 44, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "wavelength", "start": 13, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "not depend on the nature and strength of the interaction , does depend", "start": 40, "end": 110, "i_start": 6, "i_end": 18}}], "id": 1914}, {"sent": "definition 1 21 this structure is called the tangent poisson structure on t z , while .", "tokens": ["definition", "1", "21", "this", "structure", "is", "called", "the", "tangent", "poisson", "structure", "on", "t", "z", ",", "while", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "definition 1 21 this structure", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "is called", "start": 31, "end": 40, "i_start": 5, "i_end": 6}}], "id": 1915}, {"sent": "now we proceed on to define smarandache non-associative seminear-ring ii .", "tokens": ["now", "we", "proceed", "on", "to", "define", "smarandache", "non", "-", "associative", "seminear", "-", "ring", "ii", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed on", "start": 7, "end": 17, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 1916}, {"sent": "two-dimensional materials with a honeycomb geometry have attracted increasing attention owing to their unique electronic properties .", "tokens": ["two", "-", "dimensional", "materials", "with", "a", "honeycomb", "geometry", "have", "attracted", "increasing", "attention", "owing", "to", "their", "unique", "electronic", "properties", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "two-dimensional materials with a honeycomb geometry", "start": 0, "end": 51, "i_start": 0, "i_end": 7}, "verb": {"text": "have attracted", "start": 52, "end": 66, "i_start": 8, "i_end": 9}}, {"character": {"text": "materials", "start": 16, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "attracted", "start": 57, "end": 66, "i_start": 9, "i_end": 9}}], "id": 1917}, {"sent": "our model is based on the state-of-the-art cnn architecture resnet-101 .", "tokens": ["our", "model", "is", "based", "on", "the", "state", "-", "of", "-", "the", "-", "art", "cnn", "architecture", "resnet-101", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is based", "start": 10, "end": 18, "i_start": 2, "i_end": 3}}], "id": 1918}, {"sent": "thus they are not isometries and they refer exclusively to the component form of tensor quantities and in that form they transform only some components of the whole tensor quantity .", "tokens": ["thus", "they", "are", "not", "isometries", "and", "they", "refer", "exclusively", "to", "the", "component", "form", "of", "tensor", "quantities", "and", "in", "that", "form", "they", "transform", "only", "some", "components", "of", "the", "whole", "tensor", "quantity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 5, "end": 9, "i_start": 1, "i_end": 1}, "verb": {"text": "are not", "start": 10, "end": 17, "i_start": 2, "i_end": 3}}, {"subject": {"text": "they", "start": 33, "end": 37, "i_start": 6, "i_end": 6}, "verb": {"text": "refer", "start": 38, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "they", "start": 5, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "refer", "start": 38, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "they", "start": 5, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "transform", "start": 121, "end": 130, "i_start": 21, "i_end": 21}}], "id": 1919}, {"sent": "lstm has been successfully adopted to several tasks , eg , speech recognition .", "tokens": ["lstm", "has", "been", "successfully", "adopted", "to", "several", "tasks", ",", "eg", ",", "speech", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "lstm", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "adopted", "start": 27, "end": 34, "i_start": 4, "i_end": 4}}, {"subject": {"text": "lstm", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "has been", "start": 5, "end": 13, "i_start": 1, "i_end": 2}}], "id": 1920}, {"sent": "zei , for the nomad collaboration , these proceedings .", "tokens": ["zei", ",", "for", "the", "nomad", "collaboration", ",", "these", "proceedings", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "nomad", "start": 14, "end": 19, "i_start": 4, "i_end": 4}, "action": {"text": "collaboration", "start": 20, "end": 33, "i_start": 5, "i_end": 5}}], "id": 1921}, {"sent": "we implement this baseline classifier with the scikit-learn package , with a countvectorizer including bi-gram features .", "tokens": ["we", "implement", "this", "baseline", "classifier", "with", "the", "scikit", "-", "learn", "package", ",", "with", "a", "countvectorizer", "including", "bi", "-", "gram", "features", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}], "id": 1922}, {"sent": "li et al proposed to first segment the image into crowd and non-crowd regions , and then use a head detector to identify individuals in the crowd region .", "tokens": ["li", "et", "al", "proposed", "to", "first", "segment", "the", "image", "into", "crowd", "and", "non", "-", "crowd", "regions", ",", "and", "then", "use", "a", "head", "detector", "to", "identify", "individuals", "in", "the", "crowd", "region", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "li et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "li", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "detector", "start": 100, "end": 108, "i_start": 22, "i_end": 22}, "action": {"text": "identify", "start": 112, "end": 120, "i_start": 24, "i_end": 24}}], "id": 1923}, {"sent": "please note that the vois in the cerebellum had to be excluded in 3 subjects .", "tokens": ["please", "note", "that", "the", "vois", "in", "the", "cerebellum", "had", "to", "be", "excluded", "in", "3", "subjects", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the vois in the cerebellum", "start": 17, "end": 43, "i_start": 3, "i_end": 7}, "verb": {"text": "note", "start": 7, "end": 11, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the vois in the cerebellum", "start": 17, "end": 43, "i_start": 3, "i_end": 7}, "verb": {"text": "had", "start": 44, "end": 47, "i_start": 8, "i_end": 8}}], "id": 1924}, {"sent": "if the gluino is the standard-model lsp , they will escape the detector before it decays .", "tokens": ["if", "the", "gluino", "is", "the", "standard", "-", "model", "lsp", ",", "they", "will", "escape", "the", "detector", "before", "it", "decays", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 42, "end": 46, "i_start": 10, "i_end": 10}, "verb": {"text": "will escape", "start": 47, "end": 58, "i_start": 11, "i_end": 12}}, {"character": {"text": "they", "start": 42, "end": 46, "i_start": 10, "i_end": 10}, "action": {"text": "escape", "start": 52, "end": 58, "i_start": 12, "i_end": 12}}], "id": 1925}, {"sent": "the empirical study of szegedy et al first demonstrated that deep neural networks could achieve high accuracy on previously unseen examples while being vulnerable to small adversarial perturbations .", "tokens": ["the", "empirical", "study", "of", "szegedy", "et", "al", "first", "demonstrated", "that", "deep", "neural", "networks", "could", "achieve", "high", "accuracy", "on", "previously", "unseen", "examples", "while", "being", "vulnerable", "to", "small", "adversarial", "perturbations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the empirical study of szegedy et al", "start": 0, "end": 36, "i_start": 0, "i_end": 6}, "verb": {"text": "demonstrated", "start": 43, "end": 55, "i_start": 8, "i_end": 8}}, {"subject": {"text": "deep neural networks", "start": 61, "end": 81, "i_start": 10, "i_end": 12}, "verb": {"text": "achieve", "start": 88, "end": 95, "i_start": 14, "i_end": 14}}, {"character": {"text": "study", "start": 14, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 43, "end": 55, "i_start": 8, "i_end": 8}}], "id": 1926}, {"sent": "here we use the notations and results for cell-centered functions from .", "tokens": ["here", "we", "use", "the", "notations", "and", "results", "for", "cell", "-", "centered", "functions", "from", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}], "id": 1927}, {"sent": "the visible sector consists of 3-branes at a fixed point in k6 .", "tokens": ["the", "visible", "sector", "consists", "of", "3", "-", "branes", "at", "a", "fixed", "point", "in", "k6", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the visible sector", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}], "id": 1928}, {"sent": "the exchange correlation functional is approximated by the generalized gradient approximation as parametrized by perdew , burke and ernzerhof .", "tokens": ["the", "exchange", "correlation", "functional", "is", "approximated", "by", "the", "generalized", "gradient", "approximation", "as", "parametrized", "by", "perdew", ",", "burke", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange correlation functional", "start": 0, "end": 35, "i_start": 0, "i_end": 3}, "verb": {"text": "is approximated", "start": 36, "end": 51, "i_start": 4, "i_end": 5}}, {"character": {"text": "perdew", "start": 113, "end": 119, "i_start": 14, "i_end": 14}, "action": {"text": "parametrized", "start": 97, "end": 109, "i_start": 12, "i_end": 12}}, {"character": {"text": "burke", "start": 122, "end": 127, "i_start": 16, "i_end": 16}, "action": {"text": "parametrized", "start": 97, "end": 109, "i_start": 12, "i_end": 12}}, {"character": {"text": "ernzerhof", "start": 132, "end": 141, "i_start": 18, "i_end": 18}, "action": {"text": "parametrized", "start": 97, "end": 109, "i_start": 12, "i_end": 12}}], "id": 1929}, {"sent": "the bulk resistivity of the electrode plates of the rpc is an important parameter .", "tokens": ["the", "bulk", "resistivity", "of", "the", "electrode", "plates", "of", "the", "rpc", "is", "an", "important", "parameter", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the bulk resistivity of the electrode plates of the rpc", "start": 0, "end": 55, "i_start": 0, "i_end": 9}, "verb": {"text": "is", "start": 56, "end": 58, "i_start": 10, "i_end": 10}}, {"character": {"text": "plates", "start": 38, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "resistivity", "start": 9, "end": 20, "i_start": 2, "i_end": 2}}], "id": 1930}, {"sent": "percolation is a weaker condition , since merging entails percolation but not vice versa .", "tokens": ["percolation", "is", "a", "weaker", "condition", ",", "since", "merging", "entails", "percolation", "but", "not", "vice", "versa", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "percolation", "start": 0, "end": 11, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "merging", "start": 42, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "entails", "start": 50, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "merging", "start": 42, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "not", "start": 74, "end": 77, "i_start": 11, "i_end": 11}}], "id": 1931}, {"sent": "convolutional neural networks have made great progress in various fields , such as object classification , detection and character recognition .", "tokens": ["convolutional", "neural", "networks", "have", "made", "great", "progress", "in", "various", "fields", ",", "such", "as", "object", "classification", ",", "detection", "and", "character", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have made", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}], "id": 1932}, {"sent": "shi et al proposed a convolutional lstm to enhance performance for spatiotemporal prediction .", "tokens": ["shi", "et", "al", "proposed", "a", "convolutional", "lstm", "to", "enhance", "performance", "for", "spatiotemporal", "prediction", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "shi et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "shi", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "lstm", "start": 35, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "enhance", "start": 43, "end": 50, "i_start": 8, "i_end": 8}}], "id": 1933}, {"sent": "furthermore , there are some restrictions for nonlinear systems to be stabilized by smooth feedback control .", "tokens": ["furthermore", ",", "there", "are", "some", "restrictions", "for", "nonlinear", "systems", "to", "be", "stabilized", "by", "smooth", "feedback", "control", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 14, "end": 19, "i_start": 2, "i_end": 2}, "verb": {"text": "are", "start": 20, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "control", "start": 100, "end": 107, "i_start": 15, "i_end": 15}, "action": {"text": "stabilized", "start": 70, "end": 80, "i_start": 11, "i_end": 11}}], "id": 1934}, {"sent": "in this section , we review some basic definitions in quasimap theory following .", "tokens": ["in", "this", "section", ",", "we", "review", "some", "basic", "definitions", "in", "quasimap", "theory", "following", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "review", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "review", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 1935}, {"sent": "perhaps more plausible is the possibility that massive white dwarfs apart from those found in young clusters or associations are generally the results of mergers of more ordinary , probably c-o white dwarfs .", "tokens": ["perhaps", "more", "plausible", "is", "the", "possibility", "that", "massive", "white", "dwarfs", "apart", "from", "those", "found", "in", "young", "clusters", "or", "associations", "are", "generally", "the", "results", "of", "mergers", "of", "more", "ordinary", ",", "probably", "c", "-", "o", "white", "dwarfs", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the possibility that massive white dwarfs apart from those found in young clusters or associations are generally the results of mergers of more ordinary", "start": 26, "end": 178, "i_start": 4, "i_end": 27}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}], "id": 1936}, {"sent": "convolutional neural networks have been trained to achieve near human-level performance on object detection .", "tokens": ["convolutional", "neural", "networks", "have", "been", "trained", "to", "achieve", "near", "human", "-", "level", "performance", "on", "object", "detection", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been trained", "start": 30, "end": 47, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 51, "end": 58, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 76, "end": 87, "i_start": 12, "i_end": 12}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "detection", "start": 98, "end": 107, "i_start": 15, "i_end": 15}}], "id": 1937}, {"sent": "we train each model for 30 epochs with minibatches of 100 examples , using adam as the optimizer .", "tokens": ["we", "train", "each", "model", "for", "30", "epochs", "with", "minibatches", "of", "100", "examples", ",", "using", "adam", "as", "the", "optimizer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 69, "end": 74, "i_start": 13, "i_end": 13}}, {"character": {"text": "adam", "start": 75, "end": 79, "i_start": 14, "i_end": 14}, "action": {"text": "optimizer", "start": 87, "end": 96, "i_start": 17, "i_end": 17}}], "id": 1938}, {"sent": "if no project directory is specified then the path of the current working directory at the analyst site is used .", "tokens": ["if", "no", "project", "directory", "is", "specified", "then", "the", "path", "of", "the", "current", "working", "directory", "at", "the", "analyst", "site", "is", "used", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the path of the current working directory at the analyst site", "start": 42, "end": 103, "i_start": 7, "i_end": 17}, "verb": {"text": "is used", "start": 104, "end": 111, "i_start": 18, "i_end": 19}}, {"character": {"text": "directory", "start": 14, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "working", "start": 66, "end": 73, "i_start": 12, "i_end": 12}}], "id": 1939}, {"sent": "hence , chiral symmetry is broken also explicitly by the quark mass terms .", "tokens": ["hence", ",", "chiral", "symmetry", "is", "broken", "also", "explicitly", "by", "the", "quark", "mass", "terms", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "chiral symmetry", "start": 8, "end": 23, "i_start": 2, "i_end": 3}, "verb": {"text": "is broken", "start": 24, "end": 33, "i_start": 4, "i_end": 5}}, {"character": {"text": "terms", "start": 68, "end": 73, "i_start": 12, "i_end": 12}, "action": {"text": "broken", "start": 27, "end": 33, "i_start": 5, "i_end": 5}}], "id": 1940}, {"sent": "the coronagraphic phase mask is not perfectly achromatic .", "tokens": ["the", "coronagraphic", "phase", "mask", "is", "not", "perfectly", "achromatic", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the coronagraphic phase mask", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "is not", "start": 29, "end": 35, "i_start": 4, "i_end": 5}}], "id": 1941}, {"sent": "we use the 80k training images and 40k validation images to train our model , and validate the performance on the test-dev dataset which contains 20k images .", "tokens": ["we", "use", "the", "80k", "training", "images", "and", "40k", "validation", "images", "to", "train", "our", "model", ",", "and", "validate", "the", "performance", "on", "the", "test", "-", "dev", "dataset", "which", "contains", "20k", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "training", "start": 15, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "dataset", "start": 123, "end": 130, "i_start": 24, "i_end": 24}, "action": {"text": "performance", "start": 95, "end": 106, "i_start": 18, "i_end": 18}}, {"character": {"text": "dataset", "start": 123, "end": 130, "i_start": 24, "i_end": 24}, "action": {"text": "contains", "start": 137, "end": 145, "i_start": 26, "i_end": 26}}], "id": 1942}, {"sent": "a quantum computer is a physical system , whether a system of fermions or not , and physical systems have no dynamical or fermion sign problems .", "tokens": ["a", "quantum", "computer", "is", "a", "physical", "system", ",", "whether", "a", "system", "of", "fermions", "or", "not", ",", "and", "physical", "systems", "have", "no", "dynamical", "or", "fermion", "sign", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a quantum computer", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 1943}, {"sent": "some early works on group activity recognition have addressed the group activity recognition task on surveillance and sports video datasets with probabilistic and discriminative models that utilise hand-crafted features .", "tokens": ["some", "early", "works", "on", "group", "activity", "recognition", "have", "addressed", "the", "group", "activity", "recognition", "task", "on", "surveillance", "and", "sports", "video", "datasets", "with", "probabilistic", "and", "discriminative", "models", "that", "utilise", "hand", "-", "crafted", "features", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "some early works on group activity recognition", "start": 0, "end": 46, "i_start": 0, "i_end": 6}, "verb": {"text": "have addressed", "start": 47, "end": 61, "i_start": 7, "i_end": 8}}, {"character": {"text": "works", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "addressed", "start": 52, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "models", "start": 178, "end": 184, "i_start": 24, "i_end": 24}, "action": {"text": "discriminative", "start": 163, "end": 177, "i_start": 23, "i_end": 23}}, {"character": {"text": "models", "start": 178, "end": 184, "i_start": 24, "i_end": 24}, "action": {"text": "utilise", "start": 190, "end": 197, "i_start": 26, "i_end": 26}}, {"character": {"text": "hand", "start": 198, "end": 202, "i_start": 27, "i_end": 27}, "action": {"text": "crafted", "start": 203, "end": 210, "i_start": 29, "i_end": 29}}], "id": 1944}, {"sent": "we utilize a simple encoder-decoder architecture inspired by u-net .", "tokens": ["we", "utilize", "a", "simple", "encoder", "-", "decoder", "architecture", "inspired", "by", "u", "-", "net", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "utilize", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "utilize", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 1945}, {"sent": "convolutional neural networks have shown excellent performance in various visual recognition problems such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "shown", "excellent", "performance", "in", "various", "visual", "recognition", "problems", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 35, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 51, "end": 62, "i_start": 6, "i_end": 6}}], "id": 1946}, {"sent": "in recent years , deep learning techniques have changed the performance of different applications such as speech recognition .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "techniques", "have", "changed", "the", "performance", "of", "different", "applications", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning techniques", "start": 18, "end": 42, "i_start": 4, "i_end": 6}, "verb": {"text": "have changed", "start": 43, "end": 55, "i_start": 7, "i_end": 8}}, {"character": {"text": "techniques", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "changed", "start": 48, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "applications", "start": 85, "end": 97, "i_start": 13, "i_end": 13}, "action": {"text": "performance", "start": 60, "end": 71, "i_start": 10, "i_end": 10}}], "id": 1947}, {"sent": "an excellent quantitative agreement with the theory has been achieved .", "tokens": ["an", "excellent", "quantitative", "agreement", "with", "the", "theory", "has", "been", "achieved", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an excellent quantitative agreement with the theory", "start": 0, "end": 51, "i_start": 0, "i_end": 6}, "verb": {"text": "has been achieved", "start": 52, "end": 69, "i_start": 7, "i_end": 9}}], "id": 1948}, {"sent": "in the recent years deep neural networks have been used to achieve state-of-the-art results in image recognition , speech recognition and many other fields .", "tokens": ["in", "the", "recent", "years", "deep", "neural", "networks", "have", "been", "used", "to", "achieve", "state", "-", "of", "-", "the", "-", "art", "results", "in", "image", "recognition", ",", "speech", "recognition", "and", "many", "other", "fields", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 25, "end": 40, "i_start": 5, "i_end": 6}, "verb": {"text": "have been used", "start": 41, "end": 55, "i_start": 7, "i_end": 9}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "achieve", "start": 59, "end": 66, "i_start": 11, "i_end": 11}}], "id": 1949}, {"sent": "symbols are from ac-susceptibility measurements ref .", "tokens": ["symbols", "are", "from", "ac", "-", "susceptibility", "measurements", "ref", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "symbols", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 8, "end": 11, "i_start": 1, "i_end": 1}}], "id": 1950}, {"sent": "this asymmetry is the result of malmquist bias in the fbqs sample .", "tokens": ["this", "asymmetry", "is", "the", "result", "of", "malmquist", "bias", "in", "the", "fbqs", "sample", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this asymmetry", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 1951}, {"sent": "adopting array response vectors for analog beamformer design , orthogonal matching pursuit -based algorithms were developed in .", "tokens": ["adopting", "array", "response", "vectors", "for", "analog", "beamformer", "design", ",", "orthogonal", "matching", "pursuit", "-based", "algorithms", "were", "developed", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "array response vectors for analog beamformer design", "start": 9, "end": 60, "i_start": 1, "i_end": 7}, "verb": {"text": "adopting", "start": 0, "end": 8, "i_start": 0, "i_end": 0}}, {"subject": {"text": "array response vectors for analog beamformer design", "start": 9, "end": 60, "i_start": 1, "i_end": 7}, "verb": {"text": "developed", "start": 114, "end": 123, "i_start": 15, "i_end": 15}}], "id": 1952}, {"sent": "the willmore conjecture was recently solved by marques-neves through minimax techniques .", "tokens": ["the", "willmore", "conjecture", "was", "recently", "solved", "by", "marques", "-", "neves", "through", "minimax", "techniques", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the willmore conjecture", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "solved", "start": 37, "end": 43, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the willmore conjecture", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "was", "start": 24, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "marques", "start": 47, "end": 54, "i_start": 7, "i_end": 7}, "action": {"text": "solved", "start": 37, "end": 43, "i_start": 5, "i_end": 5}}], "id": 1953}, {"sent": "on large distances , the presence of the derivative coupling acts as a friction term in the inflationary period of the cosmological evolution .", "tokens": ["on", "large", "distances", ",", "the", "presence", "of", "the", "derivative", "coupling", "acts", "as", "a", "friction", "term", "in", "the", "inflationary", "period", "of", "the", "cosmological", "evolution", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the presence of the derivative coupling", "start": 21, "end": 60, "i_start": 4, "i_end": 9}, "verb": {"text": "acts", "start": 61, "end": 65, "i_start": 10, "i_end": 10}}, {"character": {"text": "presence", "start": 25, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "acts", "start": 61, "end": 65, "i_start": 10, "i_end": 10}}], "id": 1954}, {"sent": "the state which becomes the third exited state is given by diamonds , its virtual bound state pair by triangles .", "tokens": ["the", "state", "which", "becomes", "the", "third", "exited", "state", "is", "given", "by", "diamonds", ",", "its", "virtual", "bound", "state", "pair", "by", "triangles", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the state which becomes the third exited state", "start": 0, "end": 46, "i_start": 0, "i_end": 7}, "verb": {"text": "is given", "start": 47, "end": 55, "i_start": 8, "i_end": 9}}], "id": 1955}, {"sent": "convolutional neural networks have recently achieved great success on various visual recognition tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "achieved", "great", "success", "on", "various", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 7, "i_end": 7}}], "id": 1956}, {"sent": "the numerical setup for our dsa simulations was described in detail in paper i and kang et al .", "tokens": ["the", "numerical", "setup", "for", "our", "dsa", "simulations", "was", "described", "in", "detail", "in", "paper", "i", "and", "kang", "et", "al", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the numerical setup for our dsa simulations", "start": 0, "end": 43, "i_start": 0, "i_end": 6}, "verb": {"text": "was described", "start": 44, "end": 57, "i_start": 7, "i_end": 8}}, {"character": {"text": "paper i", "start": 71, "end": 78, "i_start": 12, "i_end": 13}, "action": {"text": "described", "start": 48, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "kang", "start": 83, "end": 87, "i_start": 15, "i_end": 15}, "action": {"text": "described", "start": 48, "end": 57, "i_start": 8, "i_end": 8}}], "id": 1957}, {"sent": "in this subsection we analyze the residual gauge freedom in our initial-boundary value formulation of the linearized bssn system .", "tokens": ["in", "this", "subsection", "we", "analyze", "the", "residual", "gauge", "freedom", "in", "our", "initial", "-", "boundary", "value", "formulation", "of", "the", "linearized", "bssn", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 3, "i_end": 3}, "verb": {"text": "analyze", "start": 22, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "analyze", "start": 22, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "formulation", "start": 87, "end": 98, "i_start": 15, "i_end": 15}}], "id": 1958}, {"sent": "we use the microsoft coco dataset for the evaluation on a large amount of object instances within one image .", "tokens": ["we", "use", "the", "microsoft", "coco", "dataset", "for", "the", "evaluation", "on", "a", "large", "amount", "of", "object", "instances", "within", "one", "image", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluation", "start": 42, "end": 52, "i_start": 8, "i_end": 8}}], "id": 1959}, {"sent": "examples of recent models include denoising autoencoders and generative adversarial networks .", "tokens": ["examples", "of", "recent", "models", "include", "denoising", "autoencoders", "and", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "examples of recent models", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "include", "start": 26, "end": 33, "i_start": 4, "i_end": 4}}], "id": 1960}, {"sent": "deep neural networks are powerful learning models which have been successfully applied to vision , speech and many other tasks .", "tokens": ["deep", "neural", "networks", "are", "powerful", "learning", "models", "which", "have", "been", "successfully", "applied", "to", "vision", ",", "speech", "and", "many", "other", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}], "id": 1961}, {"sent": "along an expanding jet this sensitivity manifests itself in predictable changes in pattern speed and observed wavelength .", "tokens": ["along", "an", "expanding", "jet", "this", "sensitivity", "manifests", "itself", "in", "predictable", "changes", "in", "pattern", "speed", "and", "observed", "wavelength", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this sensitivity", "start": 23, "end": 39, "i_start": 4, "i_end": 5}, "verb": {"text": "manifests", "start": 40, "end": 49, "i_start": 6, "i_end": 6}}], "id": 1962}, {"sent": "hd 45677 hd 45677 is a well studied b2 star whose evolutionary status is still unclear .", "tokens": ["hd", "45677", "hd", "45677", "is", "a", "well", "studied", "b2", "star", "whose", "evolutionary", "status", "is", "still", "unclear", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "hd 45677 hd 45677", "start": 0, "end": 17, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 4, "i_end": 4}}], "id": 1963}, {"sent": "the parisi formula for mixed p-spin models .", "tokens": ["the", "parisi", "formula", "for", "mixed", "p", "-", "spin", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1964}, {"sent": "stackgan accepts full text sentences to synthesize a color image .", "tokens": ["stackgan", "accepts", "full", "text", "sentences", "to", "synthesize", "a", "color", "image", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "stackgan", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "accepts", "start": 9, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "stackgan", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "accepts", "start": 9, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "stackgan", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "synthesize", "start": 40, "end": 50, "i_start": 6, "i_end": 6}}], "id": 1965}, {"sent": "the nucleus is the most prominent feature , this appears surrounded by diffraction rings and atmospheric speckles .", "tokens": ["the", "nucleus", "is", "the", "most", "prominent", "feature", ",", "this", "appears", "surrounded", "by", "diffraction", "rings", "and", "atmospheric", "speckles", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 44, "end": 48, "i_start": 8, "i_end": 8}, "verb": {"text": "appears", "start": 49, "end": 56, "i_start": 9, "i_end": 9}}, {"subject": {"text": "this", "start": 44, "end": 48, "i_start": 8, "i_end": 8}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 1966}, {"sent": "pravda-starov , contraction semigroups of elliptic quadratic differential operators , math .", "tokens": ["pravda", "-", "starov", ",", "contraction", "semigroups", "of", "elliptic", "quadratic", "differential", "operators", ",", "math", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1967}, {"sent": "in , gopalan et al constructed a set of intermediate subspaces along the geodesic path that links the source and target domains on the grassmann manifold .", "tokens": ["in", ",", "gopalan", "et", "al", "constructed", "a", "set", "of", "intermediate", "subspaces", "along", "the", "geodesic", "path", "that", "links", "the", "source", "and", "target", "domains", "on", "the", "grassmann", "manifold", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "gopalan et al", "start": 5, "end": 18, "i_start": 2, "i_end": 4}, "verb": {"text": "constructed", "start": 19, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "gopalan", "start": 5, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "constructed", "start": 19, "end": 30, "i_start": 5, "i_end": 5}}], "id": 1968}, {"sent": "taking computer vision as an example , deep convolutional neural networks have been verified to yield much better performance than conventional methods in various applications , from high-level tasks such as image recognition .", "tokens": ["taking", "computer", "vision", "as", "an", "example", ",", "deep", "convolutional", "neural", "networks", "have", "been", "verified", "to", "yield", "much", "better", "performance", "than", "conventional", "methods", "in", "various", "applications", ",", "from", "high", "-", "level", "tasks", "such", "as", "image", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 39, "end": 73, "i_start": 7, "i_end": 10}, "verb": {"text": "have been verified", "start": 74, "end": 92, "i_start": 11, "i_end": 13}}, {"character": {"text": "networks", "start": 65, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "yield", "start": 96, "end": 101, "i_start": 15, "i_end": 15}}, {"character": {"text": "networks", "start": 65, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "performance", "start": 114, "end": 125, "i_start": 18, "i_end": 18}}], "id": 1969}, {"sent": "there have been multiple extensions to to overcome this shortcoming , including using a moving fixed-size tsdf volume and meshing voxels exiting this volume , frequently on gpus .", "tokens": ["there", "have", "been", "multiple", "extensions", "to", "to", "overcome", "this", "shortcoming", ",", "including", "using", "a", "moving", "fixed", "-", "size", "tsdf", "volume", "and", "meshing", "voxels", "exiting", "this", "volume", ",", "frequently", "on", "gpus", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "have been", "start": 6, "end": 15, "i_start": 1, "i_end": 2}}, {"character": {"text": "voxels", "start": 130, "end": 136, "i_start": 22, "i_end": 22}, "action": {"text": "exiting", "start": 137, "end": 144, "i_start": 23, "i_end": 23}}], "id": 1970}, {"sent": "observational constraints on dark radiation in brane cosmology .", "tokens": ["observational", "constraints", "on", "dark", "radiation", "in", "brane", "cosmology", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "observational", "start": 0, "end": 13, "i_start": 0, "i_end": 0}, "action": {"text": "constraints", "start": 14, "end": 25, "i_start": 1, "i_end": 1}}], "id": 1971}, {"sent": "deep neural networks have achieved great success in cognitive applications such as image classification .", "tokens": ["deep", "neural", "networks", "have", "achieved", "great", "success", "in", "cognitive", "applications", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 41, "end": 48, "i_start": 6, "i_end": 6}}], "id": 1972}, {"sent": "we say that a monoid m is a gaussian monoid if it is atomic , gcd definition 2 point 3 .", "tokens": ["we", "say", "that", "a", "monoid", "m", "is", "a", "gaussian", "monoid", "if", "it", "is", "atomic", ",", "gcd", "definition", "2", "point", "3", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "say", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "say", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 1973}, {"sent": "this attractor is the same stable stationary state that one obtains starting with biological conditions described above .", "tokens": ["this", "attractor", "is", "the", "same", "stable", "stationary", "state", "that", "one", "obtains", "starting", "with", "biological", "conditions", "described", "above", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this attractor", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "one", "start": 56, "end": 59, "i_start": 9, "i_end": 9}, "action": {"text": "obtains", "start": 60, "end": 67, "i_start": 10, "i_end": 10}}], "id": 1974}, {"sent": "teleportation is a clear example where the aim is to end up with a quantum state , and where classical communication is necessary .", "tokens": ["teleportation", "is", "a", "clear", "example", "where", "the", "aim", "is", "to", "end", "up", "with", "a", "quantum", "state", ",", "and", "where", "classical", "communication", "is", "necessary", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "teleportation", "start": 0, "end": 13, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 1, "i_end": 1}}], "id": 1975}, {"sent": "string theory is a top-to-bottom approach to quantum supergravity in that it postulates a new object , the string , from which classical supergravity emerges as a low energy limit .", "tokens": ["string", "theory", "is", "a", "top", "-", "to", "-", "bottom", "approach", "to", "quantum", "supergravity", "in", "that", "it", "postulates", "a", "new", "object", ",", "the", "string", ",", "from", "which", "classical", "supergravity", "emerges", "as", "a", "low", "energy", "limit", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "string theory", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "theory", "start": 7, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "approach", "start": 33, "end": 41, "i_start": 9, "i_end": 9}}, {"character": {"text": "supergravity", "start": 137, "end": 149, "i_start": 27, "i_end": 27}, "action": {"text": "emerges", "start": 150, "end": 157, "i_start": 28, "i_end": 28}}], "id": 1976}, {"sent": "the representation levels and bin edges are computed using a lloyd-max procedure .", "tokens": ["the", "representation", "levels", "and", "bin", "edges", "are", "computed", "using", "a", "lloyd", "-", "max", "procedure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the representation levels and bin edges", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "are computed", "start": 40, "end": 52, "i_start": 6, "i_end": 7}}], "id": 1977}, {"sent": "deep neural networks have set new standards of performance in many machine learning areas such as image classification .", "tokens": ["deep", "neural", "networks", "have", "set", "new", "standards", "of", "performance", "in", "many", "machine", "learning", "areas", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have set", "start": 21, "end": 29, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "set", "start": 26, "end": 29, "i_start": 4, "i_end": 4}}], "id": 1978}, {"sent": "the crosses and open circles indicate the sets of parameters for which we observe total freezeout and unimodal growth , respectively .", "tokens": ["the", "crosses", "and", "open", "circles", "indicate", "the", "sets", "of", "parameters", "for", "which", "we", "observe", "total", "freezeout", "and", "unimodal", "growth", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the crosses and open circles", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "indicate", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "crosses", "start": 4, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "indicate", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "circles", "start": 21, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "indicate", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 71, "end": 73, "i_start": 12, "i_end": 12}, "action": {"text": "observe", "start": 74, "end": 81, "i_start": 13, "i_end": 13}}], "id": 1979}, {"sent": "ii protocol for classical message transmission .", "tokens": ["ii", "protocol", "for", "classical", "message", "transmission", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1980}, {"sent": "another immediate corollary to theorem 10 is the following result .", "tokens": ["another", "immediate", "corollary", "to", "theorem", "10", "is", "the", "following", "result", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another immediate corollary to theorem 10", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 42, "end": 44, "i_start": 6, "i_end": 6}}], "id": 1981}, {"sent": "the pcp proposed in attempts to provably recover px l,0 , x s,0 q , to a good approximation , by solving a convex optimization .", "tokens": ["the", "pcp", "proposed", "in", "attempts", "to", "provably", "recover", "px", "l,0", ",", "x", "s,0", "q", ",", "to", "a", "good", "approximation", ",", "by", "solving", "a", "convex", "optimization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the pcp", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "proposed", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}], "id": 1982}, {"sent": "other layers are initialized with the pre-trained vgg-16 network .", "tokens": ["other", "layers", "are", "initialized", "with", "the", "pre", "-", "trained", "vgg-16", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "other layers", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "are initialized", "start": 13, "end": 28, "i_start": 2, "i_end": 3}}], "id": 1983}, {"sent": "in this paper , i will describe an extension of the groupoidification program of baez and dolan .", "tokens": ["in", "this", "paper", ",", "i", "will", "describe", "an", "extension", "of", "the", "groupoidification", "program", "of", "baez", "and", "dolan", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "i", "start": 16, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "will describe", "start": 18, "end": 31, "i_start": 5, "i_end": 6}}, {"character": {"text": "i", "start": 16, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "describe", "start": 23, "end": 31, "i_start": 6, "i_end": 6}}], "id": 1984}, {"sent": "the attack model and the methodology follow closely the survey by schrittweiser et al .", "tokens": ["the", "attack", "model", "and", "the", "methodology", "follow", "closely", "the", "survey", "by", "schrittweiser", "et", "al", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the attack model and the methodology", "start": 0, "end": 36, "i_start": 0, "i_end": 5}, "verb": {"text": "follow", "start": 37, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "model", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "follow", "start": 37, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "attack", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "follow", "start": 37, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "methodology", "start": 25, "end": 36, "i_start": 5, "i_end": 5}, "action": {"text": "follow", "start": 37, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "attack", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "follow", "start": 37, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "schrittweiser et", "start": 66, "end": 82, "i_start": 11, "i_end": 12}, "action": {"text": "survey", "start": 56, "end": 62, "i_start": 9, "i_end": 9}}], "id": 1985}, {"sent": "in most all cases , the instabilities are caused by a viscosity contrast at the fluid-fluid interface .", "tokens": ["in", "most", "all", "cases", ",", "the", "instabilities", "are", "caused", "by", "a", "viscosity", "contrast", "at", "the", "fluid", "-", "fluid", "interface", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the instabilities", "start": 20, "end": 37, "i_start": 5, "i_end": 6}, "verb": {"text": "are caused", "start": 38, "end": 48, "i_start": 7, "i_end": 8}}, {"character": {"text": "contrast", "start": 64, "end": 72, "i_start": 12, "i_end": 12}, "action": {"text": "caused", "start": 42, "end": 48, "i_start": 8, "i_end": 8}}], "id": 1986}, {"sent": "in this section , we validate our theory with experiments on training resnet for the image classification tasks over cifar-10 and imagenet .", "tokens": ["in", "this", "section", ",", "we", "validate", "our", "theory", "with", "experiments", "on", "training", "resnet", "for", "the", "image", "classification", "tasks", "over", "cifar-10", "and", "imagenet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "validate", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "validate", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}], "id": 1987}, {"sent": "the only modification needed is the insertion of rotation matrices from flavor eigenstates to gauge interaction eigenstates .", "tokens": ["the", "only", "modification", "needed", "is", "the", "insertion", "of", "rotation", "matrices", "from", "flavor", "eigenstates", "to", "gauge", "interaction", "eigenstates", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the only modification needed", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "matrices", "start": 58, "end": 66, "i_start": 9, "i_end": 9}, "action": {"text": "gauge", "start": 94, "end": 99, "i_start": 14, "i_end": 14}}], "id": 1988}, {"sent": "in recent years , convolutional neural networks have become the dominant approach for a variety of computer vision tasks , eg , image classification .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "become", "the", "dominant", "approach", "for", "a", "variety", "of", "computer", "vision", "tasks", ",", "eg", ",", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have become", "start": 48, "end": 59, "i_start": 7, "i_end": 8}}, {"character": {"text": "approach", "start": 73, "end": 81, "i_start": 11, "i_end": 11}, "action": {"text": "dominant", "start": 64, "end": 72, "i_start": 10, "i_end": 10}}], "id": 1989}, {"sent": "another class of methods that have gained great attention recently are the graph neural networks .", "tokens": ["another", "class", "of", "methods", "that", "have", "gained", "great", "attention", "recently", "are", "the", "graph", "neural", "networks", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "another class of methods that have gained great attention recently", "start": 0, "end": 66, "i_start": 0, "i_end": 9}, "verb": {"text": "are", "start": 67, "end": 70, "i_start": 10, "i_end": 10}}, {"character": {"text": "class", "start": 8, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "gained", "start": 35, "end": 41, "i_start": 6, "i_end": 6}}], "id": 1990}, {"sent": "the use of our energy-dependent coupling constants is meant to be consistent with the approach to asymptotic freedom at high temperature .", "tokens": ["the", "use", "of", "our", "energy", "-", "dependent", "coupling", "constants", "is", "meant", "to", "be", "consistent", "with", "the", "approach", "to", "asymptotic", "freedom", "at", "high", "temperature", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the use of our energy-dependent coupling constants", "start": 0, "end": 50, "i_start": 0, "i_end": 8}, "verb": {"text": "is meant", "start": 51, "end": 59, "i_start": 9, "i_end": 10}}, {"character": {"text": "constants", "start": 41, "end": 50, "i_start": 8, "i_end": 8}, "action": {"text": "dependent", "start": 22, "end": 31, "i_start": 6, "i_end": 6}}], "id": 1991}, {"sent": "a mesh-geometry-based solution to mixed-dimensional coupling .", "tokens": ["a", "mesh", "-", "geometry", "-", "based", "solution", "to", "mixed", "-", "dimensional", "coupling", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 1992}, {"sent": "however , our spectra are not flux-calibrated to begin with .", "tokens": ["however", ",", "our", "spectra", "are", "not", "flux", "-", "calibrated", "to", "begin", "with", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our spectra", "start": 10, "end": 21, "i_start": 2, "i_end": 3}, "verb": {"text": "are not", "start": 22, "end": 29, "i_start": 4, "i_end": 5}}], "id": 1993}, {"sent": "deep learning-based generative models , in particular generative adversarial networks , are widely used for synthesisrelated learning tasks .", "tokens": ["deep", "learning", "-", "based", "generative", "models", ",", "in", "particular", "generative", "adversarial", "networks", ",", "are", "widely", "used", "for", "synthesisrelated", "learning", "tasks", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "deep learning-based generative models", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "used", "start": 99, "end": 103, "i_start": 15, "i_end": 15}}, {"subject": {"text": "deep learning-based generative models", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 88, "end": 91, "i_start": 13, "i_end": 13}}], "id": 1994}, {"sent": "in unsigned networks , the typical modeled properties are the power law degree distribution .", "tokens": ["in", "unsigned", "networks", ",", "the", "typical", "modeled", "properties", "are", "the", "power", "law", "degree", "distribution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the typical modeled properties", "start": 23, "end": 53, "i_start": 4, "i_end": 7}, "verb": {"text": "are", "start": 54, "end": 57, "i_start": 8, "i_end": 8}}], "id": 1995}, {"sent": "a , we can apply the replica method in the path-integral formalism by generalizing the formulation for the ground state .", "tokens": ["a", ",", "we", "can", "apply", "the", "replica", "method", "in", "the", "path", "-", "integral", "formalism", "by", "generalizing", "the", "formulation", "for", "the", "ground", "state", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 2, "i_end": 2}, "verb": {"text": "can apply", "start": 7, "end": 16, "i_start": 3, "i_end": 4}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 2, "i_end": 2}, "action": {"text": "apply", "start": 11, "end": 16, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 2, "i_end": 2}, "action": {"text": "generalizing", "start": 70, "end": 82, "i_start": 15, "i_end": 15}}], "id": 1996}, {"sent": "deep networks have achieved excellent performance in a variety of domains such as computer vision .", "tokens": ["deep", "networks", "have", "achieved", "excellent", "performance", "in", "a", "variety", "of", "domains", "such", "as", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep networks", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "have achieved", "start": 14, "end": 27, "i_start": 2, "i_end": 3}}, {"character": {"text": "networks", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "achieved", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "performance", "start": 38, "end": 49, "i_start": 5, "i_end": 5}}], "id": 1997}, {"sent": "wyner introduced the notion of equivocation for the study of secrecy capacity of a wiretap channel .", "tokens": ["wyner", "introduced", "the", "notion", "of", "equivocation", "for", "the", "study", "of", "secrecy", "capacity", "of", "a", "wiretap", "channel", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "wyner", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "introduced", "start": 6, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "wyner", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 6, "end": 16, "i_start": 1, "i_end": 1}}], "id": 1998}, {"sent": "the energy gradient theory is proposed to explain the mechanism of flow instability and turbulence transition for parallel flows .", "tokens": ["the", "energy", "gradient", "theory", "is", "proposed", "to", "explain", "the", "mechanism", "of", "flow", "instability", "and", "turbulence", "transition", "for", "parallel", "flows", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the energy gradient theory", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "is proposed", "start": 27, "end": 38, "i_start": 4, "i_end": 5}}, {"character": {"text": "theory", "start": 20, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "explain", "start": 42, "end": 49, "i_start": 7, "i_end": 7}}], "id": 1999}, {"sent": "the ground state of crystals was calculated using spinpolarized generalized gradient approximation with the exchange-correlation potential pbe .", "tokens": ["the", "ground", "state", "of", "crystals", "was", "calculated", "using", "spinpolarized", "generalized", "gradient", "approximation", "with", "the", "exchange", "-", "correlation", "potential", "pbe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ground state of crystals", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "was calculated", "start": 29, "end": 43, "i_start": 5, "i_end": 6}}], "id": 2000}, {"sent": "maltoni , factorization of tree qcd amplitudes in the high-energy limit and in the collinear limit , nucl .", "tokens": ["maltoni", ",", "factorization", "of", "tree", "qcd", "amplitudes", "in", "the", "high", "-", "energy", "limit", "and", "in", "the", "collinear", "limit", ",", "nucl", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2001}, {"sent": "lomb-scargle analysis , using the mean live times .", "tokens": ["lomb", "-", "scargle", "analysis", ",", "using", "the", "mean", "live", "times", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "analysis", "start": 13, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "using", "start": 24, "end": 29, "i_start": 5, "i_end": 5}}], "id": 2002}, {"sent": "examples from show , respectively , that the nekhoroshev and the kam theorem can not be true for all perturbations .", "tokens": ["examples", "from", "show", ",", "respectively", ",", "that", "the", "nekhoroshev", "and", "the", "kam", "theorem", "can", "not", "be", "true", "for", "all", "perturbations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the nekhoroshev and the kam theorem", "start": 41, "end": 76, "i_start": 7, "i_end": 12}, "verb": {"text": "can not be", "start": 77, "end": 87, "i_start": 13, "i_end": 15}}, {"character": {"text": "examples", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 14, "end": 18, "i_start": 2, "i_end": 2}}], "id": 2003}, {"sent": "convolutional neural networks are widely used in many image recognition tasks , such as image classification , due to their significant advantages over traditional machine learning methods .", "tokens": ["convolutional", "neural", "networks", "are", "widely", "used", "in", "many", "image", "recognition", "tasks", ",", "such", "as", "image", "classification", ",", "due", "to", "their", "significant", "advantages", "over", "traditional", "machine", "learning", "methods", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 41, "end": 45, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 3, "i_end": 3}}], "id": 2004}, {"sent": "since the higgs is a scalar this interaction has an attractive nature , which makes it tempting to look for new phenomena related to the heaviest known fermion , the top quark , as well as consider what may happen if heavier fermions of the next generation exist in nature .", "tokens": ["since", "the", "higgs", "is", "a", "scalar", "this", "interaction", "has", "an", "attractive", "nature", ",", "which", "makes", "it", "tempting", "to", "look", "for", "new", "phenomena", "related", "to", "the", "heaviest", "known", "fermion", ",", "the", "top", "quark", ",", "as", "well", "as", "consider", "what", "may", "happen", "if", "heavier", "fermions", "of", "the", "next", "generation", "exist", "in", "nature", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this interaction", "start": 28, "end": 44, "i_start": 6, "i_end": 7}, "verb": {"text": "has", "start": 45, "end": 48, "i_start": 8, "i_end": 8}}, {"character": {"text": "scalar", "start": 21, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "if", "start": 214, "end": 216, "i_start": 40, "i_end": 40}}, {"character": {"text": "interaction", "start": 33, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "attractive", "start": 52, "end": 62, "i_start": 10, "i_end": 10}}, {"character": {"text": "nature", "start": 63, "end": 69, "i_start": 11, "i_end": 11}, "action": {"text": "makes", "start": 78, "end": 83, "i_start": 14, "i_end": 14}}, {"character": {"text": "look", "start": 99, "end": 103, "i_start": 18, "i_end": 18}, "action": {"text": "tempting", "start": 87, "end": 95, "i_start": 16, "i_end": 16}}, {"character": {"text": "top", "start": 166, "end": 169, "i_start": 30, "i_end": 30}, "action": {"text": "tempting", "start": 87, "end": 95, "i_start": 16, "i_end": 16}}, {"character": {"text": "consider", "start": 189, "end": 197, "i_start": 36, "i_end": 36}, "action": {"text": "tempting", "start": 87, "end": 95, "i_start": 16, "i_end": 16}}, {"character": {"text": "exist", "start": 257, "end": 262, "i_start": 47, "i_end": 47}, "action": {"text": "tempting", "start": 87, "end": 95, "i_start": 16, "i_end": 16}}, {"character": {"text": "generation", "start": 246, "end": 256, "i_start": 46, "i_end": 46}, "action": {"text": "tempting", "start": 87, "end": 95, "i_start": 16, "i_end": 16}}, {"character": {"text": "next", "start": 241, "end": 245, "i_start": 45, "i_end": 45}, "action": {"text": "tempting", "start": 87, "end": 95, "i_start": 16, "i_end": 16}}, {"character": {"text": "nature", "start": 266, "end": 272, "i_start": 49, "i_end": 49}, "action": {"text": "tempting", "start": 87, "end": 95, "i_start": 16, "i_end": 16}}], "id": 2005}, {"sent": "in this context , active learning is a process of identifying locations for additional observations that minimize the prediction error and reduce mse or uncertainty .", "tokens": ["in", "this", "context", ",", "active", "learning", "is", "a", "process", "of", "identifying", "locations", "for", "additional", "observations", "that", "minimize", "the", "prediction", "error", "and", "reduce", "mse", "or", "uncertainty", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "active learning", "start": 18, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "observations", "start": 87, "end": 99, "i_start": 14, "i_end": 14}, "action": {"text": "minimize", "start": 105, "end": 113, "i_start": 16, "i_end": 16}}, {"character": {"text": "observations", "start": 87, "end": 99, "i_start": 14, "i_end": 14}, "action": {"text": "reduce", "start": 139, "end": 145, "i_start": 21, "i_end": 21}}], "id": 2006}, {"sent": "it can been seen from all the figures that the most significant effect in this energy range , is by the trajectory modification due to the coulomb field .", "tokens": ["it", "can", "been", "seen", "from", "all", "the", "figures", "that", "the", "most", "significant", "effect", "in", "this", "energy", "range", ",", "is", "by", "the", "trajectory", "modification", "due", "to", "the", "coulomb", "field", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "can been seen", "start": 3, "end": 16, "i_start": 1, "i_end": 3}}], "id": 2007}, {"sent": "this obstruction is the non-trivial spectral flow of a family of twisted signature operators in 3-dimensions .", "tokens": ["this", "obstruction", "is", "the", "non", "-", "trivial", "spectral", "flow", "of", "a", "family", "of", "twisted", "signature", "operators", "in", "3", "-", "dimensions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this obstruction", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "flow", "start": 45, "end": 49, "i_start": 8, "i_end": 8}, "action": {"text": "obstruction", "start": 5, "end": 16, "i_start": 1, "i_end": 1}}], "id": 2008}, {"sent": "compressive sensing of sparse signals in achieving data acquisition and compression simultaneously has been extensively studied in the past few years .", "tokens": ["compressive", "sensing", "of", "sparse", "signals", "in", "achieving", "data", "acquisition", "and", "compression", "simultaneously", "has", "been", "extensively", "studied", "in", "the", "past", "few", "years", "."], "score": [1, 1, 1, 0, 1], "labels": [{"subject": {"text": "compressive sensing of sparse signals in achieving data acquisition and compression", "start": 0, "end": 83, "i_start": 0, "i_end": 10}, "verb": {"text": "studied", "start": 120, "end": 127, "i_start": 15, "i_end": 15}}, {"subject": {"text": "compressive sensing of sparse signals in achieving data acquisition and compression", "start": 0, "end": 83, "i_start": 0, "i_end": 10}, "verb": {"text": "has been", "start": 99, "end": 107, "i_start": 12, "i_end": 13}}], "id": 2009}, {"sent": "the 20 candidate image labels per topic are collected by using an information retrieval engine .", "tokens": ["the", "20", "candidate", "image", "labels", "per", "topic", "are", "collected", "by", "using", "an", "information", "retrieval", "engine", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the 20 candidate image labels per topic", "start": 0, "end": 39, "i_start": 0, "i_end": 6}, "verb": {"text": "are collected", "start": 40, "end": 53, "i_start": 7, "i_end": 8}}, {"character": {"text": "engine", "start": 88, "end": 94, "i_start": 14, "i_end": 14}, "action": {"text": "retrieval", "start": 78, "end": 87, "i_start": 13, "i_end": 13}}], "id": 2010}, {"sent": "the supervised hashing methods try to preserve the label similarity of samples using labelled training data .", "tokens": ["the", "supervised", "hashing", "methods", "try", "to", "preserve", "the", "label", "similarity", "of", "samples", "using", "labelled", "training", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the supervised hashing methods", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "try", "start": 31, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "methods", "start": 23, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "try", "start": 31, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "methods", "start": 23, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "preserve", "start": 38, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "methods", "start": 23, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "using", "start": 79, "end": 84, "i_start": 12, "i_end": 12}}], "id": 2011}, {"sent": "deep convolutional neural networks have led to major breakthroughs in many computer vision tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "led", "to", "major", "breakthroughs", "in", "many", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have led", "start": 35, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "led", "start": 40, "end": 43, "i_start": 5, "i_end": 5}}], "id": 2012}, {"sent": "the reliability performance can be easily measured using density evolution recursion .", "tokens": ["the", "reliability", "performance", "can", "be", "easily", "measured", "using", "density", "evolution", "recursion", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the reliability performance", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "measured", "start": 42, "end": 50, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the reliability performance", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "can be", "start": 28, "end": 34, "i_start": 3, "i_end": 4}}], "id": 2013}, {"sent": "by using results from , the authors choose \u03c1 n to be the radius of a circle of area 100 log n n on a sphere of unit area .", "tokens": ["by", "using", "results", "from", ",", "the", "authors", "choose", "\u03c1", "n", "to", "be", "the", "radius", "of", "a", "circle", "of", "area", "100", "log", "n", "n", "on", "a", "sphere", "of", "unit", "area", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 24, "end": 35, "i_start": 5, "i_end": 6}, "verb": {"text": "choose", "start": 36, "end": 42, "i_start": 7, "i_end": 7}}], "id": 2014}, {"sent": "we use adam as the optimizer to perform stochastic gradient ascent .", "tokens": ["we", "use", "adam", "as", "the", "optimizer", "to", "perform", "stochastic", "gradient", "ascent", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "adam", "start": 7, "end": 11, "i_start": 2, "i_end": 2}, "action": {"text": "optimizer", "start": 19, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "perform", "start": 32, "end": 39, "i_start": 7, "i_end": 7}}], "id": 2015}, {"sent": "on a graph with bounded degree , the policy in achieves sublinear time to extinction , but requires a curing budget that is proportional to the number of nodes .", "tokens": ["on", "a", "graph", "with", "bounded", "degree", ",", "the", "policy", "in", "achieves", "sublinear", "time", "to", "extinction", ",", "but", "requires", "a", "curing", "budget", "that", "is", "proportional", "to", "the", "number", "of", "nodes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the policy in", "start": 33, "end": 46, "i_start": 7, "i_end": 9}, "verb": {"text": "achieves", "start": 47, "end": 55, "i_start": 10, "i_end": 10}}, {"subject": {"text": "the policy in", "start": 33, "end": 46, "i_start": 7, "i_end": 9}, "verb": {"text": "requires", "start": 91, "end": 99, "i_start": 17, "i_end": 17}}, {"character": {"text": "policy", "start": 37, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "achieves", "start": 47, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "policy", "start": 37, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "requires", "start": 91, "end": 99, "i_start": 17, "i_end": 17}}], "id": 2016}, {"sent": "in particular , every connected finite strongly simple bol loop is moufang .", "tokens": ["in", "particular", ",", "every", "connected", "finite", "strongly", "simple", "bol", "loop", "is", "moufang", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "every connected finite strongly simple bol loop", "start": 16, "end": 63, "i_start": 3, "i_end": 9}, "verb": {"text": "is", "start": 64, "end": 66, "i_start": 10, "i_end": 10}}], "id": 2017}, {"sent": "this may be also spelled out that vacuum is a most degenerate state of a system .", "tokens": ["this", "may", "be", "also", "spelled", "out", "that", "vacuum", "is", "a", "most", "degenerate", "state", "of", "a", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "spelled out", "start": 17, "end": 28, "i_start": 4, "i_end": 5}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "may be", "start": 5, "end": 11, "i_start": 1, "i_end": 2}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 41, "end": 43, "i_start": 8, "i_end": 8}}], "id": 2018}, {"sent": "the phase space is then said to consist of one pair of canonical variables per space point .", "tokens": ["the", "phase", "space", "is", "then", "said", "to", "consist", "of", "one", "pair", "of", "canonical", "variables", "per", "space", "point", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the phase space", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "said", "start": 24, "end": 28, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the phase space", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 2019}, {"sent": "this comparative study showed that methyl esters larger than methyl octanoate behave very similarly with some slight differences in the ntc region .", "tokens": ["this", "comparative", "study", "showed", "that", "methyl", "esters", "larger", "than", "methyl", "octanoate", "behave", "very", "similarly", "with", "some", "slight", "differences", "in", "the", "ntc", "region", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this comparative study", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 23, "end": 29, "i_start": 3, "i_end": 3}}, {"subject": {"text": "methyl esters larger than methyl octanoate", "start": 35, "end": 77, "i_start": 5, "i_end": 10}, "verb": {"text": "behave", "start": 78, "end": 84, "i_start": 11, "i_end": 11}}, {"character": {"text": "study", "start": 17, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "showed", "start": 23, "end": 29, "i_start": 3, "i_end": 3}}], "id": 2020}, {"sent": "however , bertschinger et al provided a counterexample showing that nonnegativity of the pid terms is not ensured when the identity axiom is assumed .", "tokens": ["however", ",", "bertschinger", "et", "al", "provided", "a", "counterexample", "showing", "that", "nonnegativity", "of", "the", "pid", "terms", "is", "not", "ensured", "when", "the", "identity", "axiom", "is", "assumed", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bertschinger et al", "start": 10, "end": 28, "i_start": 2, "i_end": 4}, "verb": {"text": "provided", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "bertschinger", "start": 10, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "provided", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "counterexample", "start": 40, "end": 54, "i_start": 7, "i_end": 7}, "action": {"text": "showing", "start": 55, "end": 62, "i_start": 8, "i_end": 8}}], "id": 2021}, {"sent": "deep convolutional neural networks have been prevailed in various computer vision tasks , such as objection classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "prevailed", "in", "various", "computer", "vision", "tasks", ",", "such", "as", "objection", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been prevailed", "start": 35, "end": 54, "i_start": 4, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "prevailed", "start": 45, "end": 54, "i_start": 6, "i_end": 6}}], "id": 2022}, {"sent": "deep learning using convolutional neural networks has achieved excellent performance for a wide range of tasks , such as image recognition .", "tokens": ["deep", "learning", "using", "convolutional", "neural", "networks", "has", "achieved", "excellent", "performance", "for", "a", "wide", "range", "of", "tasks", ",", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning using convolutional neural networks", "start": 0, "end": 49, "i_start": 0, "i_end": 5}, "verb": {"text": "has achieved", "start": 50, "end": 62, "i_start": 6, "i_end": 7}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "achieved", "start": 54, "end": 62, "i_start": 7, "i_end": 7}}], "id": 2023}, {"sent": "in this paper , we propose to use generative adversarial networks .", "tokens": ["in", "this", "paper", ",", "we", "propose", "to", "use", "generative", "adversarial", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "propose", "start": 19, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "propose", "start": 19, "end": 26, "i_start": 5, "i_end": 5}}], "id": 2024}, {"sent": "a transport layer approach for achieving aggregate bandwidths on multi-homed mobile hosts .", "tokens": ["a", "transport", "layer", "approach", "for", "achieving", "aggregate", "bandwidths", "on", "multi", "-", "homed", "mobile", "hosts", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2025}, {"sent": "stability conditions on an -singularities .", "tokens": ["stability", "conditions", "on", "an", "-singularities", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2026}, {"sent": "the shot noise is a direct consequence of the granularity of the electric charge .", "tokens": ["the", "shot", "noise", "is", "a", "direct", "consequence", "of", "the", "granularity", "of", "the", "electric", "charge", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the shot noise", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}], "id": 2027}, {"sent": "sindagi et al proposed a contextual pyramid cnn to incorporate contextual information of crowds for achieving lower counting error and high-quality density maps .", "tokens": ["sindagi", "et", "al", "proposed", "a", "contextual", "pyramid", "cnn", "to", "incorporate", "contextual", "information", "of", "crowds", "for", "achieving", "lower", "counting", "error", "and", "high", "-", "quality", "density", "maps", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "sindagi et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "sindagi", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}], "id": 2028}, {"sent": "convolutional neural networks have achieved state-of-the-art results on several computer vision tasks .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "results", "on", "several", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 2029}, {"sent": "we point out that the mechanism can work under non-zero dirichlet bcs that give appropriate vevs .", "tokens": ["we", "point", "out", "that", "the", "mechanism", "can", "work", "under", "non", "-", "zero", "dirichlet", "bcs", "that", "give", "appropriate", "vevs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "point out", "start": 3, "end": 12, "i_start": 1, "i_end": 2}}, {"subject": {"text": "the mechanism", "start": 18, "end": 31, "i_start": 4, "i_end": 5}, "verb": {"text": "work", "start": 36, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "point", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2030}, {"sent": "convolutional neural networks have achieved great success on visual recognition tasks .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "great", "success", "on", "visual", "recognition", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}], "id": 2031}, {"sent": "we employed the perdew-burke-ernzerhof exchange correlation functional in the generalized gradient approximation .", "tokens": ["we", "employed", "the", "perdew", "-", "burke", "-", "ernzerhof", "exchange", "correlation", "functional", "in", "the", "generalized", "gradient", "approximation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employed", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employed", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2032}, {"sent": "string theory is the leading candidate for a theory of quantum gravity .", "tokens": ["string", "theory", "is", "the", "leading", "candidate", "for", "a", "theory", "of", "quantum", "gravity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "string theory", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "candidate", "start": 29, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "leading", "start": 21, "end": 28, "i_start": 4, "i_end": 4}}], "id": 2033}, {"sent": "by eigenstate thermalization hypothesis , a typical highly excited energy eigenstate in a quantum chaotic system behaves like a thermal state .", "tokens": ["by", "eigenstate", "thermalization", "hypothesis", ",", "a", "typical", "highly", "excited", "energy", "eigenstate", "in", "a", "quantum", "chaotic", "system", "behaves", "like", "a", "thermal", "state", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "a typical highly excited energy eigenstate in a quantum chaotic system", "start": 42, "end": 112, "i_start": 5, "i_end": 15}, "verb": {"text": "behaves", "start": 113, "end": 120, "i_start": 16, "i_end": 16}}, {"character": {"text": "eigenstate", "start": 3, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "behaves", "start": 113, "end": 120, "i_start": 16, "i_end": 16}}], "id": 2034}, {"sent": "deep neural networks have achieved a great success on many tasks such as image classification when a large set of labeled examples are available .", "tokens": ["deep", "neural", "networks", "have", "achieved", "a", "great", "success", "on", "many", "tasks", "such", "as", "image", "classification", "when", "a", "large", "set", "of", "labeled", "examples", "are", "available", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 43, "end": 50, "i_start": 7, "i_end": 7}}], "id": 2035}, {"sent": "we use the gradient-weighted class activation mapping to present the responsible regions in an image for deciding a class .", "tokens": ["we", "use", "the", "gradient", "-", "weighted", "class", "activation", "mapping", "to", "present", "the", "responsible", "regions", "in", "an", "image", "for", "deciding", "a", "class", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "present", "start": 57, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "regions", "start": 81, "end": 88, "i_start": 13, "i_end": 13}, "action": {"text": "responsible", "start": 69, "end": 80, "i_start": 12, "i_end": 12}}], "id": 2036}, {"sent": "we employ the vienna ab initio simulation package code with the projector augmented wave method to perform the dft calculations .", "tokens": ["we", "employ", "the", "vienna", "ab", "initio", "simulation", "package", "code", "with", "the", "projector", "augmented", "wave", "method", "to", "perform", "the", "dft", "calculations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "code", "start": 50, "end": 54, "i_start": 8, "i_end": 8}, "action": {"text": "perform", "start": 99, "end": 106, "i_start": 16, "i_end": 16}}, {"character": {"text": "projector", "start": 64, "end": 73, "i_start": 11, "i_end": 11}, "action": {"text": "augmented", "start": 74, "end": 83, "i_start": 12, "i_end": 12}}], "id": 2037}, {"sent": "huang et al proposed a context-modulated attention scheme to selectively focus on pairwise instances appearing in both image and sentence .", "tokens": ["huang", "et", "al", "proposed", "a", "context", "-", "modulated", "attention", "scheme", "to", "selectively", "focus", "on", "pairwise", "instances", "appearing", "in", "both", "image", "and", "sentence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "huang et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "huang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}], "id": 2038}, {"sent": "in contrast the quadrupole term is characterised by three quaternionic constants , the interpretation of which is less clear .", "tokens": ["in", "contrast", "the", "quadrupole", "term", "is", "characterised", "by", "three", "quaternionic", "constants", ",", "the", "interpretation", "of", "which", "is", "less", "clear", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quadrupole term", "start": 12, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "is characterised", "start": 32, "end": 48, "i_start": 5, "i_end": 6}}], "id": 2039}, {"sent": "in this approach , they extend the auto-encoder graph embedding model of sdne , which is designed to transfer knowledge from one neural network to a second model .", "tokens": ["in", "this", "approach", ",", "they", "extend", "the", "auto", "-", "encoder", "graph", "embedding", "model", "of", "sdne", ",", "which", "is", "designed", "to", "transfer", "knowledge", "from", "one", "neural", "network", "to", "a", "second", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 19, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "extend", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "they", "start": 19, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "extend", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "graph", "start": 48, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "encoder", "start": 40, "end": 47, "i_start": 9, "i_end": 9}}, {"character": {"text": "model", "start": 64, "end": 69, "i_start": 12, "i_end": 12}, "action": {"text": "transfer", "start": 101, "end": 109, "i_start": 20, "i_end": 20}}], "id": 2040}, {"sent": "topological invariants in momentum space protect also the bulk gapless fermions in dirac and weyl semi -metals .", "tokens": ["topological", "invariants", "in", "momentum", "space", "protect", "also", "the", "bulk", "gapless", "fermions", "in", "dirac", "and", "weyl", "semi", "-metals", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "topological invariants in momentum space", "start": 0, "end": 40, "i_start": 0, "i_end": 4}, "verb": {"text": "protect", "start": 41, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "invariants", "start": 12, "end": 22, "i_start": 1, "i_end": 1}, "action": {"text": "protect", "start": 41, "end": 48, "i_start": 5, "i_end": 5}}], "id": 2041}, {"sent": "over the course of time , the difference tends to grow , showing that the steady state is unstable .", "tokens": ["over", "the", "course", "of", "time", ",", "the", "difference", "tends", "to", "grow", ",", "showing", "that", "the", "steady", "state", "is", "unstable", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the difference", "start": 26, "end": 40, "i_start": 6, "i_end": 7}, "verb": {"text": "tends", "start": 41, "end": 46, "i_start": 8, "i_end": 8}}, {"character": {"text": "tends", "start": 41, "end": 46, "i_start": 8, "i_end": 8}, "action": {"text": "showing", "start": 57, "end": 64, "i_start": 12, "i_end": 12}}], "id": 2042}, {"sent": "deep neural networks have been proven impressively successful on certain supervised learning tasks .", "tokens": ["deep", "neural", "networks", "have", "been", "proven", "impressively", "successful", "on", "certain", "supervised", "learning", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been proven", "start": 21, "end": 37, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 51, "end": 61, "i_start": 7, "i_end": 7}}, {"character": {"text": "successful", "start": 51, "end": 61, "i_start": 7, "i_end": 7}, "action": {"text": "impressively", "start": 38, "end": 50, "i_start": 6, "i_end": 6}}], "id": 2043}, {"sent": "the network is trained using the adaptive moment estimation optimizer .", "tokens": ["the", "network", "is", "trained", "using", "the", "adaptive", "moment", "estimation", "optimizer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the network", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is trained", "start": 12, "end": 22, "i_start": 2, "i_end": 3}}], "id": 2044}, {"sent": "the free energy is the negative of the maximum value of this entropy .", "tokens": ["the", "free", "energy", "is", "the", "negative", "of", "the", "maximum", "value", "of", "this", "entropy", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the free energy", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "energy", "start": 9, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "negative", "start": 23, "end": 31, "i_start": 5, "i_end": 5}}], "id": 2045}, {"sent": "the lower panel shows the fractional difference from the gr result .", "tokens": ["the", "lower", "panel", "shows", "the", "fractional", "difference", "from", "the", "gr", "result", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the lower panel", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "shows", "start": 16, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "panel", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "shows", "start": 16, "end": 21, "i_start": 3, "i_end": 3}}], "id": 2046}, {"sent": "differential privacy is a strong , mathematically rigorous framework for privacy protection .", "tokens": ["differential", "privacy", "is", "a", "strong", ",", "mathematically", "rigorous", "framework", "for", "privacy", "protection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "differential privacy", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 2, "i_end": 2}}], "id": 2047}, {"sent": "we could also adopt implementations of stronger objects like the ones presented in but we preferred to show the simplest modification in a fundamental algorithm .", "tokens": ["we", "could", "also", "adopt", "implementations", "of", "stronger", "objects", "like", "the", "ones", "presented", "in", "but", "we", "preferred", "to", "show", "the", "simplest", "modification", "in", "a", "fundamental", "algorithm", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 87, "end": 89, "i_start": 14, "i_end": 14}, "verb": {"text": "adopt", "start": 14, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "could", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "preferred", "start": 90, "end": 99, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adopt", "start": 14, "end": 19, "i_start": 3, "i_end": 3}}], "id": 2048}, {"sent": "this section gives a terse definition of the abstract tile assembly model .", "tokens": ["this", "section", "gives", "a", "terse", "definition", "of", "the", "abstract", "tile", "assembly", "model", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this section", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "gives", "start": 13, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "section", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "definition", "start": 27, "end": 37, "i_start": 5, "i_end": 5}}], "id": 2049}, {"sent": "in addition , we use batch normalization to accelerate the training stage .", "tokens": ["in", "addition", ",", "we", "use", "batch", "normalization", "to", "accelerate", "the", "training", "stage", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "use", "start": 17, "end": 20, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 17, "end": 20, "i_start": 4, "i_end": 4}}, {"character": {"text": "normalization", "start": 27, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "accelerate", "start": 44, "end": 54, "i_start": 8, "i_end": 8}}], "id": 2050}, {"sent": "these methods have also been replacing highly optimized handdesigned algorithms in low-level vision tasks such as image denoising .", "tokens": ["these", "methods", "have", "also", "been", "replacing", "highly", "optimized", "handdesigned", "algorithms", "in", "low", "-", "level", "vision", "tasks", "such", "as", "image", "denoising", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "these methods", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "been replacing", "start": 24, "end": 38, "i_start": 4, "i_end": 5}}, {"subject": {"text": "these methods", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "have", "start": 14, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "methods", "start": 6, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "replacing", "start": 29, "end": 38, "i_start": 5, "i_end": 5}}], "id": 2051}, {"sent": "minimizing nonconvex objectives , which may exhibit many stationary points , is in general np-hard .", "tokens": ["minimizing", "nonconvex", "objectives", ",", "which", "may", "exhibit", "many", "stationary", "points", ",", "is", "in", "general", "np", "-", "hard", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "minimizing nonconvex objectives", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 77, "end": 79, "i_start": 11, "i_end": 11}}, {"character": {"text": "objectives", "start": 21, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "exhibit", "start": 44, "end": 51, "i_start": 6, "i_end": 6}}], "id": 2052}, {"sent": "in synergy with the results obtained in ref , our analysis reveals that the effective theory always underestimates the bounce volume and overestimates the energy density at the bounce .", "tokens": ["in", "synergy", "with", "the", "results", "obtained", "in", "ref", ",", "our", "analysis", "reveals", "that", "the", "effective", "theory", "always", "underestimates", "the", "bounce", "volume", "and", "overestimates", "the", "energy", "density", "at", "the", "bounce", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our analysis", "start": 46, "end": 58, "i_start": 9, "i_end": 10}, "verb": {"text": "reveals", "start": 59, "end": 66, "i_start": 11, "i_end": 11}}, {"subject": {"text": "the effective theory", "start": 72, "end": 92, "i_start": 13, "i_end": 15}, "verb": {"text": "underestimates", "start": 100, "end": 114, "i_start": 17, "i_end": 17}}, {"character": {"text": "analysis", "start": 50, "end": 58, "i_start": 10, "i_end": 10}, "action": {"text": "reveals", "start": 59, "end": 66, "i_start": 11, "i_end": 11}}, {"character": {"text": "theory", "start": 86, "end": 92, "i_start": 15, "i_end": 15}, "action": {"text": "underestimates", "start": 100, "end": 114, "i_start": 17, "i_end": 17}}, {"character": {"text": "theory", "start": 86, "end": 92, "i_start": 15, "i_end": 15}, "action": {"text": "effective", "start": 76, "end": 85, "i_start": 14, "i_end": 14}}, {"character": {"text": "theory", "start": 86, "end": 92, "i_start": 15, "i_end": 15}, "action": {"text": "overestimates", "start": 137, "end": 150, "i_start": 22, "i_end": 22}}], "id": 2053}, {"sent": "we discretize the second-order terms using the local discontinuous galerkin method .", "tokens": ["we", "discretize", "the", "second", "-", "order", "terms", "using", "the", "local", "discontinuous", "galerkin", "method", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "discretize", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "discretize", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}], "id": 2054}, {"sent": "one successful approach to automatic verification of termination properties of higher-order functional programs is based on sized types .", "tokens": ["one", "successful", "approach", "to", "automatic", "verification", "of", "termination", "properties", "of", "higher", "-", "order", "functional", "programs", "is", "based", "on", "sized", "types", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "one successful approach to automatic verification of termination properties of higher-order functional programs", "start": 0, "end": 111, "i_start": 0, "i_end": 14}, "verb": {"text": "is based", "start": 112, "end": 120, "i_start": 15, "i_end": 16}}], "id": 2055}, {"sent": "every arithmetic subsequence of an ultimately periodic sequence is ultimately periodic .", "tokens": ["every", "arithmetic", "subsequence", "of", "an", "ultimately", "periodic", "sequence", "is", "ultimately", "periodic", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "every arithmetic subsequence of an ultimately periodic sequence", "start": 0, "end": 63, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 64, "end": 66, "i_start": 8, "i_end": 8}}], "id": 2056}, {"sent": "we use the scikit-learn implementation of a linear svm with default parameters .", "tokens": ["we", "use", "the", "scikit", "-", "learn", "implementation", "of", "a", "linear", "svm", "with", "default", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 2057}, {"sent": "the elasticity and configuration of lipid vesicles have attracted much theoretical attention of physicists .", "tokens": ["the", "elasticity", "and", "configuration", "of", "lipid", "vesicles", "have", "attracted", "much", "theoretical", "attention", "of", "physicists", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the elasticity and configuration of lipid vesicles", "start": 0, "end": 50, "i_start": 0, "i_end": 6}, "verb": {"text": "have attracted", "start": 51, "end": 65, "i_start": 7, "i_end": 8}}, {"character": {"text": "elasticity", "start": 4, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "attracted", "start": 56, "end": 65, "i_start": 8, "i_end": 8}}, {"character": {"text": "vesicles", "start": 42, "end": 50, "i_start": 6, "i_end": 6}, "action": {"text": "attracted", "start": 56, "end": 65, "i_start": 8, "i_end": 8}}, {"character": {"text": "lipid", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "attracted", "start": 56, "end": 65, "i_start": 8, "i_end": 8}}, {"character": {"text": "lipid", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "attracted", "start": 56, "end": 65, "i_start": 8, "i_end": 8}}, {"character": {"text": "physicists", "start": 96, "end": 106, "i_start": 13, "i_end": 13}, "action": {"text": "attention", "start": 83, "end": 92, "i_start": 11, "i_end": 11}}], "id": 2058}, {"sent": "an infinitesimal version of this relation is identical to the canonical commutation relation of canonical quantum gravity formulated in terms of ashtekar variables 1 .", "tokens": ["an", "infinitesimal", "version", "of", "this", "relation", "is", "identical", "to", "the", "canonical", "commutation", "relation", "of", "canonical", "quantum", "gravity", "formulated", "in", "terms", "of", "ashtekar", "variables", "1", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an infinitesimal version of this relation", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 42, "end": 44, "i_start": 6, "i_end": 6}}], "id": 2059}, {"sent": "recent advances in deep learning have revolutionized the application of machine learning in areas such as computer vision , speech recognition and natural language processing .", "tokens": ["recent", "advances", "in", "deep", "learning", "have", "revolutionized", "the", "application", "of", "machine", "learning", "in", "areas", "such", "as", "computer", "vision", ",", "speech", "recognition", "and", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent advances in deep learning", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "have revolutionized", "start": 33, "end": 52, "i_start": 5, "i_end": 6}}, {"character": {"text": "advances", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "revolutionized", "start": 38, "end": 52, "i_start": 6, "i_end": 6}}], "id": 2060}, {"sent": "deep learning is attracting much attention in the fields of visual object recognition , speech recognition , object detection , among many others .", "tokens": ["deep", "learning", "is", "attracting", "much", "attention", "in", "the", "fields", "of", "visual", "object", "recognition", ",", "speech", "recognition", ",", "object", "detection", ",", "among", "many", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is attracting", "start": 14, "end": 27, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "attracting", "start": 17, "end": 27, "i_start": 3, "i_end": 3}}], "id": 2061}, {"sent": "visual inspection seems to show that target 2 1 is a good description at high momenta , but may overestimate the pion production at low x values .", "tokens": ["visual", "inspection", "seems", "to", "show", "that", "target", "2", "1", "is", "a", "good", "description", "at", "high", "momenta", ",", "but", "may", "overestimate", "the", "pion", "production", "at", "low", "x", "values", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "visual inspection", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "seems", "start": 18, "end": 23, "i_start": 2, "i_end": 2}}, {"subject": {"text": "visual inspection", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "overestimate", "start": 96, "end": 108, "i_start": 19, "i_end": 19}}, {"character": {"text": "inspection", "start": 7, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 27, "end": 31, "i_start": 4, "i_end": 4}}], "id": 2062}, {"sent": "matrix theory is a supersymmetric quantum mechanics theory with matrix degrees of freedom .", "tokens": ["matrix", "theory", "is", "a", "supersymmetric", "quantum", "mechanics", "theory", "with", "matrix", "degrees", "of", "freedom", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "matrix theory", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 2063}, {"sent": "thus instead of making the user directly color an image , other studies take a more indirect approach by utilizing color palettes to recolor an image .", "tokens": ["thus", "instead", "of", "making", "the", "user", "directly", "color", "an", "image", ",", "other", "studies", "take", "a", "more", "indirect", "approach", "by", "utilizing", "color", "palettes", "to", "recolor", "an", "image", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "other studies", "start": 58, "end": 71, "i_start": 11, "i_end": 12}, "verb": {"text": "take", "start": 72, "end": 76, "i_start": 13, "i_end": 13}}, {"character": {"text": "studies", "start": 64, "end": 71, "i_start": 12, "i_end": 12}, "action": {"text": "approach", "start": 93, "end": 101, "i_start": 17, "i_end": 17}}, {"character": {"text": "studies", "start": 64, "end": 71, "i_start": 12, "i_end": 12}, "action": {"text": "utilizing", "start": 105, "end": 114, "i_start": 19, "i_end": 19}}, {"character": {"text": "studies", "start": 64, "end": 71, "i_start": 12, "i_end": 12}, "action": {"text": "recolor", "start": 133, "end": 140, "i_start": 23, "i_end": 23}}, {"character": {"text": "studies", "start": 64, "end": 71, "i_start": 12, "i_end": 12}, "action": {"text": "making", "start": 16, "end": 22, "i_start": 3, "i_end": 3}}], "id": 2064}, {"sent": "graphene is a one-atom-thick sheet of sp2-bonded carbon atoms that are densely packed in a bipartite crystal lattice .", "tokens": ["graphene", "is", "a", "one", "-", "atom", "-", "thick", "sheet", "of", "sp2", "-", "bonded", "carbon", "atoms", "that", "are", "densely", "packed", "in", "a", "bipartite", "crystal", "lattice", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "graphene", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2065}, {"sent": "motors are specialized protein molecules that move along the cytoskeletal polymer scaffold and perform directed intracellular transport .", "tokens": ["motors", "are", "specialized", "protein", "molecules", "that", "move", "along", "the", "cytoskeletal", "polymer", "scaffold", "and", "perform", "directed", "intracellular", "transport", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "motors", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 7, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "molecules", "start": 31, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "move", "start": 46, "end": 50, "i_start": 6, "i_end": 6}}, {"character": {"text": "molecules", "start": 31, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "perform", "start": 95, "end": 102, "i_start": 13, "i_end": 13}}], "id": 2066}, {"sent": "yet , recent studies demonstrate that neural networks are surprisingly fragile -the neural network policies are all vulnerable to adversarial examples and attacks .", "tokens": ["yet", ",", "recent", "studies", "demonstrate", "that", "neural", "networks", "are", "surprisingly", "fragile", "-the", "neural", "network", "policies", "are", "all", "vulnerable", "to", "adversarial", "examples", "and", "attacks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent studies", "start": 6, "end": 20, "i_start": 2, "i_end": 3}, "verb": {"text": "demonstrate", "start": 21, "end": 32, "i_start": 4, "i_end": 4}}, {"subject": {"text": "recent studies", "start": 6, "end": 20, "i_start": 2, "i_end": 3}, "verb": {"text": "are", "start": 54, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "studies", "start": 13, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "demonstrate", "start": 21, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "fragile", "start": 71, "end": 78, "i_start": 10, "i_end": 10}, "action": {"text": "surprisingly", "start": 58, "end": 70, "i_start": 9, "i_end": 9}}], "id": 2067}, {"sent": "the telescope can therefore be operated in closed loop .", "tokens": ["the", "telescope", "can", "therefore", "be", "operated", "in", "closed", "loop", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the telescope", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "be operated", "start": 28, "end": 39, "i_start": 4, "i_end": 5}}, {"subject": {"text": "the telescope", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "can", "start": 14, "end": 17, "i_start": 2, "i_end": 2}}], "id": 2068}, {"sent": "millimeter wave communication is a promising technology for addressing the high throughput requirement for the fifth generation mobile networks .", "tokens": ["millimeter", "wave", "communication", "is", "a", "promising", "technology", "for", "addressing", "the", "high", "throughput", "requirement", "for", "the", "fifth", "generation", "mobile", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "millimeter wave communication", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "technology", "start": 45, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "promising", "start": 35, "end": 44, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 135, "end": 143, "i_start": 18, "i_end": 18}, "action": {"text": "requirement", "start": 91, "end": 102, "i_start": 12, "i_end": 12}}], "id": 2069}, {"sent": "cosmic strings are line-like topological defects which may have formed during a phase transition in the early universe .", "tokens": ["cosmic", "strings", "are", "line", "-", "like", "topological", "defects", "which", "may", "have", "formed", "during", "a", "phase", "transition", "in", "the", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}], "id": 2070}, {"sent": "the weights of the final layer were initialized using the xavier initialization .", "tokens": ["the", "weights", "of", "the", "final", "layer", "were", "initialized", "using", "the", "xavier", "initialization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the weights of the final layer", "start": 0, "end": 30, "i_start": 0, "i_end": 5}, "verb": {"text": "were initialized", "start": 31, "end": 47, "i_start": 6, "i_end": 7}}], "id": 2071}, {"sent": "connes , spectral sequence and homology of currents for operator algebras .", "tokens": ["connes", ",", "spectral", "sequence", "and", "homology", "of", "currents", "for", "operator", "algebras", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "algebras", "start": 65, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "operator", "start": 56, "end": 64, "i_start": 9, "i_end": 9}}], "id": 2072}, {"sent": "deep neural networks have achieved remarkable results in computer vision , natural language processing , and speech recognition areas .", "tokens": ["deep", "neural", "networks", "have", "achieved", "remarkable", "results", "in", "computer", "vision", ",", "natural", "language", "processing", ",", "and", "speech", "recognition", "areas", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}], "id": 2073}, {"sent": "they showed that any c 1 -small perturbation of a higher-rank algebraic anosov action with semisimple linear part is smoothly conjugate to the original action .", "tokens": ["they", "showed", "that", "any", "c", "1", "-small", "perturbation", "of", "a", "higher", "-", "rank", "algebraic", "anosov", "action", "with", "semisimple", "linear", "part", "is", "smoothly", "conjugate", "to", "the", "original", "action", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "showed", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}, {"subject": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 114, "end": 116, "i_start": 20, "i_end": 20}}, {"character": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2074}, {"sent": "in recent years , deep learning has been actively applied in various fields including computer vision .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "has", "been", "actively", "applied", "in", "various", "fields", "including", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 18, "end": 31, "i_start": 4, "i_end": 5}, "verb": {"text": "applied", "start": 50, "end": 57, "i_start": 9, "i_end": 9}}, {"subject": {"text": "deep learning", "start": 18, "end": 31, "i_start": 4, "i_end": 5}, "verb": {"text": "has been", "start": 32, "end": 40, "i_start": 6, "i_end": 7}}], "id": 2075}, {"sent": "the interrupted the dt straight line was obtained by ls method .", "tokens": ["the", "interrupted", "the", "dt", "straight", "line", "was", "obtained", "by", "ls", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the interrupted the dt straight line", "start": 0, "end": 36, "i_start": 0, "i_end": 5}, "verb": {"text": "was obtained", "start": 37, "end": 49, "i_start": 6, "i_end": 7}}], "id": 2076}, {"sent": "let us turn our attention to actual examples of two-photon states produced by pdc .", "tokens": ["let", "us", "turn", "our", "attention", "to", "actual", "examples", "of", "two", "-", "photon", "states", "produced", "by", "pdc", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "turn", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "attention", "start": 16, "end": 25, "i_start": 4, "i_end": 4}}], "id": 2077}, {"sent": "the generative adversarial network is a powerful generative model that can generate plausible images .", "tokens": ["the", "generative", "adversarial", "network", "is", "a", "powerful", "generative", "model", "that", "can", "generate", "plausible", "images", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the generative adversarial network", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "model", "start": 60, "end": 65, "i_start": 8, "i_end": 8}, "action": {"text": "generate", "start": 75, "end": 83, "i_start": 11, "i_end": 11}}], "id": 2078}, {"sent": "in recent years , deep convolutional neural networks have proven to be highly effective general models for a multitude of computer vision problems .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "proven", "to", "be", "highly", "effective", "general", "models", "for", "a", "multitude", "of", "computer", "vision", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have proven", "start": 53, "end": 64, "i_start": 8, "i_end": 9}}, {"character": {"text": "models", "start": 96, "end": 102, "i_start": 15, "i_end": 15}, "action": {"text": "effective", "start": 78, "end": 87, "i_start": 13, "i_end": 13}}], "id": 2079}, {"sent": "this geometry is a trumpet with curvature singularity at the origin of the coordinate system , and it is dual to the semi-infinite cigar .", "tokens": ["this", "geometry", "is", "a", "trumpet", "with", "curvature", "singularity", "at", "the", "origin", "of", "the", "coordinate", "system", ",", "and", "it", "is", "dual", "to", "the", "semi", "-", "infinite", "cigar", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this geometry", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 2080}, {"sent": "the standard error for each data point is not shown since it is smaller than the point itself in all cases .", "tokens": ["the", "standard", "error", "for", "each", "data", "point", "is", "not", "shown", "since", "it", "is", "smaller", "than", "the", "point", "itself", "in", "all", "cases", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2081}, {"sent": "to solve this saddle-point problem efficiently , we resort to the recent algorithm of chambolle and pock .", "tokens": ["to", "solve", "this", "saddle", "-", "point", "problem", "efficiently", ",", "we", "resort", "to", "the", "recent", "algorithm", "of", "chambolle", "and", "pock", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "verb": {"text": "resort", "start": 52, "end": 58, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "action": {"text": "resort", "start": 52, "end": 58, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "action": {"text": "solve", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2082}, {"sent": "we assume familiarity with quantum computing for more details , also on the relation between query complexity and certificate complexity .", "tokens": ["we", "assume", "familiarity", "with", "quantum", "computing", "for", "more", "details", ",", "also", "on", "the", "relation", "between", "query", "complexity", "and", "certificate", "complexity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 2083}, {"sent": "polar codes are the first family of codes proven to be capacity achieving for any binary input discrete memoryless channel and with an explicit construction method under low complexity successive cancellation decoding .", "tokens": ["polar", "codes", "are", "the", "first", "family", "of", "codes", "proven", "to", "be", "capacity", "achieving", "for", "any", "binary", "input", "discrete", "memoryless", "channel", "and", "with", "an", "explicit", "construction", "method", "under", "low", "complexity", "successive", "cancellation", "decoding", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "polar codes", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 12, "end": 15, "i_start": 2, "i_end": 2}}], "id": 2084}, {"sent": "the perturbation thus consists of slightly altering the kicking period about its mean .", "tokens": ["the", "perturbation", "thus", "consists", "of", "slightly", "altering", "the", "kicking", "period", "about", "its", "mean", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the perturbation", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 22, "end": 30, "i_start": 3, "i_end": 3}}], "id": 2085}, {"sent": "graphene is a fascinating material with unusual electronic , magnetic , optical and thermal properties 1 .", "tokens": ["graphene", "is", "a", "fascinating", "material", "with", "unusual", "electronic", ",", "magnetic", ",", "optical", "and", "thermal", "properties", "1", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "graphene", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2086}, {"sent": "isola et al put forward a general-purpose framework to solve multiple image translation tasks .", "tokens": ["isola", "et", "al", "put", "forward", "a", "general", "-", "purpose", "framework", "to", "solve", "multiple", "image", "translation", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 6, "end": 11, "i_start": 1, "i_end": 2}, "verb": {"text": "put forward", "start": 12, "end": 23, "i_start": 3, "i_end": 4}}, {"character": {"text": "isola", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "solve", "start": 55, "end": 60, "i_start": 11, "i_end": 11}}], "id": 2087}, {"sent": "we find that the dispersion diagram is symmetric with the time when the thread is located at the center of the magnetic tube in slab geometry .", "tokens": ["we", "find", "that", "the", "dispersion", "diagram", "is", "symmetric", "with", "the", "time", "when", "the", "thread", "is", "located", "at", "the", "center", "of", "the", "magnetic", "tube", "in", "slab", "geometry", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 36, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 2088}, {"sent": "deep learning approaches , in particularly deep convolutional neural networks , have achieved tremendous successes in various visual recognition tasks .", "tokens": ["deep", "learning", "approaches", ",", "in", "particularly", "deep", "convolutional", "neural", "networks", ",", "have", "achieved", "tremendous", "successes", "in", "various", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep learning approaches", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 80, "end": 93, "i_start": 11, "i_end": 12}}, {"character": {"text": "approaches", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 85, "end": 93, "i_start": 12, "i_end": 12}}], "id": 2089}, {"sent": "the quantum channel consists of a source that emits pairs of spin onehalf particles , in a singlet state .", "tokens": ["the", "quantum", "channel", "consists", "of", "a", "source", "that", "emits", "pairs", "of", "spin", "onehalf", "particles", ",", "in", "a", "singlet", "state", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quantum channel", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 20, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "source", "start": 34, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "emits", "start": 46, "end": 51, "i_start": 8, "i_end": 8}}], "id": 2090}, {"sent": "we use a combination of adam and simple sgd as our the optimizing algorithms .", "tokens": ["we", "use", "a", "combination", "of", "adam", "and", "simple", "sgd", "as", "our", "the", "optimizing", "algorithms", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 2091}, {"sent": "the ordinate is the velocity integrated line flux density , normalized to the co line , except for the milky way , for which the values are normalized at co .", "tokens": ["the", "ordinate", "is", "the", "velocity", "integrated", "line", "flux", "density", ",", "normalized", "to", "the", "co", "line", ",", "except", "for", "the", "milky", "way", ",", "for", "which", "the", "values", "are", "normalized", "at", "co", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ordinate", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 2092}, {"sent": "in this section , we conduct extensive experiments on the imagenet dataset for reproducible proof of concept .", "tokens": ["in", "this", "section", ",", "we", "conduct", "extensive", "experiments", "on", "the", "imagenet", "dataset", "for", "reproducible", "proof", "of", "concept", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "conduct", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "conduct", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "experiments", "start": 39, "end": 50, "i_start": 7, "i_end": 7}}], "id": 2093}, {"sent": "we adopt the packet and frame structure as in , where the crc bits of each packet facilitate perfect error detection .", "tokens": ["we", "adopt", "the", "packet", "and", "frame", "structure", "as", "in", ",", "where", "the", "crc", "bits", "of", "each", "packet", "facilitate", "perfect", "error", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "bits", "start": 62, "end": 66, "i_start": 13, "i_end": 13}, "action": {"text": "facilitate", "start": 82, "end": 92, "i_start": 17, "i_end": 17}}], "id": 2094}, {"sent": "a rich litterature has been devoted to this subject , one may consult a new class of alternating minimization algorithms with costs-to-move has been introduced .", "tokens": ["a", "rich", "litterature", "has", "been", "devoted", "to", "this", "subject", ",", "one", "may", "consult", "a", "new", "class", "of", "alternating", "minimization", "algorithms", "with", "costs", "-", "to", "-", "move", "has", "been", "introduced", "."], "score": [0, 0, 0, 1, 1], "labels": [{"subject": {"text": "one", "start": 54, "end": 57, "i_start": 10, "i_end": 10}, "verb": {"text": "has been introduced", "start": 140, "end": 159, "i_start": 26, "i_end": 28}}, {"subject": {"text": "one", "start": 54, "end": 57, "i_start": 10, "i_end": 10}, "verb": {"text": "consult", "start": 62, "end": 69, "i_start": 12, "i_end": 12}}, {"character": {"text": "one", "start": 54, "end": 57, "i_start": 10, "i_end": 10}, "action": {"text": "consult", "start": 62, "end": 69, "i_start": 12, "i_end": 12}}], "id": 2095}, {"sent": "we obtained our ab initio results from dft calculations employing the vienna ab initio simulation package .", "tokens": ["we", "obtained", "our", "ab", "initio", "results", "from", "dft", "calculations", "employing", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "obtained", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "obtained", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "calculations", "start": 43, "end": 55, "i_start": 8, "i_end": 8}, "action": {"text": "employing", "start": 56, "end": 65, "i_start": 9, "i_end": 9}}], "id": 2096}, {"sent": "in addition , the optimal configuration of the proposed spherical coil array is found and its communication performances are similar as the ideal m 2 i predicted in .", "tokens": ["in", "addition", ",", "the", "optimal", "configuration", "of", "the", "proposed", "spherical", "coil", "array", "is", "found", "and", "its", "communication", "performances", "are", "similar", "as", "the", "ideal", "m", "2", "i", "predicted", "in", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the optimal configuration of the proposed spherical coil array", "start": 14, "end": 76, "i_start": 3, "i_end": 11}, "verb": {"text": "is found", "start": 77, "end": 85, "i_start": 12, "i_end": 13}}, {"character": {"text": "array", "start": 71, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "performances", "start": 108, "end": 120, "i_start": 17, "i_end": 17}}, {"character": {"text": "array", "start": 71, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "communication", "start": 94, "end": 107, "i_start": 16, "i_end": 16}}, {"character": {"text": "i", "start": 150, "end": 151, "i_start": 25, "i_end": 25}, "action": {"text": "predicted", "start": 152, "end": 161, "i_start": 26, "i_end": 26}}], "id": 2097}, {"sent": "in recent years , convolutional neural networks have achieved significant success in many computer vision tasks , including the super-resolution problem .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "achieved", "significant", "success", "in", "many", "computer", "vision", "tasks", ",", "including", "the", "super", "-", "resolution", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 48, "end": 61, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 53, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 74, "end": 81, "i_start": 10, "i_end": 10}}], "id": 2098}, {"sent": "this is in agreement with the fact that the algebra of physical closed-string states is always supercommutative .", "tokens": ["this", "is", "in", "agreement", "with", "the", "fact", "that", "the", "algebra", "of", "physical", "closed", "-", "string", "states", "is", "always", "supercommutative", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "agreement", "start": 11, "end": 20, "i_start": 3, "i_end": 3}}], "id": 2099}, {"sent": "recently , luo et al showed that a unified lattice boltzmann model matches the linear and finite amplitude stability criteria of the subcritical bifurcation in ec flow for both 2d and 3d flow scenarios .", "tokens": ["recently", ",", "luo", "et", "al", "showed", "that", "a", "unified", "lattice", "boltzmann", "model", "matches", "the", "linear", "and", "finite", "amplitude", "stability", "criteria", "of", "the", "subcritical", "bifurcation", "in", "ec", "flow", "for", "both", "2d", "and", "3d", "flow", "scenarios", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "luo et al", "start": 11, "end": 20, "i_start": 2, "i_end": 4}, "verb": {"text": "showed", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}, {"subject": {"text": "a unified lattice boltzmann model", "start": 33, "end": 66, "i_start": 7, "i_end": 11}, "verb": {"text": "matches", "start": 67, "end": 74, "i_start": 12, "i_end": 12}}, {"character": {"text": "luo", "start": 11, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "showed", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 2100}, {"sent": "in most cases , the averaged versions of perceptrons and mira work empirically better than naive versions of perceptron and mira .", "tokens": ["in", "most", "cases", ",", "the", "averaged", "versions", "of", "perceptrons", "and", "mira", "work", "empirically", "better", "than", "naive", "versions", "of", "perceptron", "and", "mira", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the averaged versions of perceptrons and mira", "start": 16, "end": 61, "i_start": 4, "i_end": 10}, "verb": {"text": "work", "start": 62, "end": 66, "i_start": 11, "i_end": 11}}], "id": 2101}, {"sent": "the theory of complex networks has recently produced a great deal of interest in a very multidisciplinary community .", "tokens": ["the", "theory", "of", "complex", "networks", "has", "recently", "produced", "a", "great", "deal", "of", "interest", "in", "a", "very", "multidisciplinary", "community", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the theory of complex networks", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "produced", "start": 44, "end": 52, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the theory of complex networks", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "has", "start": 31, "end": 34, "i_start": 5, "i_end": 5}}, {"character": {"text": "theory", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "produced", "start": 44, "end": 52, "i_start": 7, "i_end": 7}}], "id": 2102}, {"sent": "xiong et al studied the problem of obtaining the top-k similar object pairs based on user-specified join paths .", "tokens": ["xiong", "et", "al", "studied", "the", "problem", "of", "obtaining", "the", "top", "-", "k", "similar", "object", "pairs", "based", "on", "user", "-", "specified", "join", "paths", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "xiong et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "studied", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "xiong", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "studied", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}], "id": 2103}, {"sent": "lattice boltzmann model of immiscible fluids .", "tokens": ["lattice", "boltzmann", "model", "of", "immiscible", "fluids", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2104}, {"sent": "therefore , the low energy spectrum consists of an r-axion and a goldstino .", "tokens": ["therefore", ",", "the", "low", "energy", "spectrum", "consists", "of", "an", "r", "-", "axion", "and", "a", "goldstino", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the low energy spectrum", "start": 12, "end": 35, "i_start": 2, "i_end": 5}, "verb": {"text": "consists", "start": 36, "end": 44, "i_start": 6, "i_end": 6}}], "id": 2105}, {"sent": "in particular , convolutional neural networks has been popular in vision and audio recognition areas .", "tokens": ["in", "particular", ",", "convolutional", "neural", "networks", "has", "been", "popular", "in", "vision", "and", "audio", "recognition", "areas", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "has been", "start": 46, "end": 54, "i_start": 6, "i_end": 7}}], "id": 2106}, {"sent": "the feature encoder consists of 3 convolutional blocks , each of which comprises a convolutional layer , a batch normalization layer , a max pooling layer , and an activation layer .", "tokens": ["the", "feature", "encoder", "consists", "of", "3", "convolutional", "blocks", ",", "each", "of", "which", "comprises", "a", "convolutional", "layer", ",", "a", "batch", "normalization", "layer", ",", "a", "max", "pooling", "layer", ",", "and", "an", "activation", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the feature encoder", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 20, "end": 28, "i_start": 3, "i_end": 3}}], "id": 2107}, {"sent": "language model pre-training has achieved strong performance in many nlp tasks .", "tokens": ["language", "model", "pre", "-", "training", "has", "achieved", "strong", "performance", "in", "many", "nlp", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "language model pre-training", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "has achieved", "start": 28, "end": 40, "i_start": 5, "i_end": 6}}, {"character": {"text": "training", "start": 19, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 32, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "training", "start": 19, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "performance", "start": 48, "end": 59, "i_start": 8, "i_end": 8}}], "id": 2108}, {"sent": "the missing ingredient is the boundary confor ditions .", "tokens": ["the", "missing", "ingredient", "is", "the", "boundary", "confor", "ditions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the missing ingredient", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}], "id": 2109}, {"sent": "generative adversarial networks are an unsupervised learning method that is able to generate realistic looking images from noise .", "tokens": ["generative", "adversarial", "networks", "are", "an", "unsupervised", "learning", "method", "that", "is", "able", "to", "generate", "realistic", "looking", "images", "from", "noise", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "method", "start": 61, "end": 67, "i_start": 7, "i_end": 7}, "action": {"text": "generate", "start": 84, "end": 92, "i_start": 12, "i_end": 12}}, {"character": {"text": "images", "start": 111, "end": 117, "i_start": 15, "i_end": 15}, "action": {"text": "looking", "start": 103, "end": 110, "i_start": 14, "i_end": 14}}], "id": 2110}, {"sent": "there exists an extension of topological vertex formalism that computes the refined topological string partition functions on toric geometries .", "tokens": ["there", "exists", "an", "extension", "of", "topological", "vertex", "formalism", "that", "computes", "the", "refined", "topological", "string", "partition", "functions", "on", "toric", "geometries", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "exists", "start": 6, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "extension", "start": 16, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "computes", "start": 63, "end": 71, "i_start": 9, "i_end": 9}}], "id": 2111}, {"sent": "one of these methods is sequential matching network , which matches a response with each utterance in the context at multiple levels of granularity and leads to state-of-the-art performance on two multi-turn conversation corpora .", "tokens": ["one", "of", "these", "methods", "is", "sequential", "matching", "network", ",", "which", "matches", "a", "response", "with", "each", "utterance", "in", "the", "context", "at", "multiple", "levels", "of", "granularity", "and", "leads", "to", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "two", "multi", "-", "turn", "conversation", "corpora", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one of these methods", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "network", "start": 44, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "matches", "start": 60, "end": 67, "i_start": 10, "i_end": 10}}, {"character": {"text": "network", "start": 44, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "matching", "start": 35, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "network", "start": 44, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "leads", "start": 152, "end": 157, "i_start": 25, "i_end": 25}}], "id": 2112}, {"sent": "low-rank representation captures the global structure of the data by imposing a low-rank constraint on the data representation matrix .", "tokens": ["low", "-", "rank", "representation", "captures", "the", "global", "structure", "of", "the", "data", "by", "imposing", "a", "low", "-", "rank", "constraint", "on", "the", "data", "representation", "matrix", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "low-rank representation", "start": 0, "end": 23, "i_start": 0, "i_end": 3}, "verb": {"text": "captures", "start": 24, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "representation", "start": 9, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "captures", "start": 24, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "representation", "start": 9, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "imposing", "start": 69, "end": 77, "i_start": 12, "i_end": 12}}], "id": 2113}, {"sent": "first we illustrate this by the following example .", "tokens": ["first", "we", "illustrate", "this", "by", "the", "following", "example", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 6, "end": 8, "i_start": 1, "i_end": 1}, "verb": {"text": "illustrate", "start": 9, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "illustrate", "start": 9, "end": 19, "i_start": 2, "i_end": 2}}], "id": 2114}, {"sent": "these ideas were later successfully applied in the quantum automata setting by ambainis and freivalds in 1998 , .", "tokens": ["these", "ideas", "were", "later", "successfully", "applied", "in", "the", "quantum", "automata", "setting", "by", "ambainis", "and", "freivalds", "in", "1998", ",", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these ideas", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "applied", "start": 36, "end": 43, "i_start": 5, "i_end": 5}}, {"subject": {"text": "these ideas", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "were", "start": 12, "end": 16, "i_start": 2, "i_end": 2}}], "id": 2115}, {"sent": "in most methods , in order to deal with such inherent difficulties , image intensity-based or gradient-based methods have been preferred to extract the boundaries of target anatomies .", "tokens": ["in", "most", "methods", ",", "in", "order", "to", "deal", "with", "such", "inherent", "difficulties", ",", "image", "intensity", "-", "based", "or", "gradient", "-", "based", "methods", "have", "been", "preferred", "to", "extract", "the", "boundaries", "of", "target", "anatomies", "."], "score": [0, 1, 1, 1, 0], "labels": [{"subject": {"text": "image intensity-based or gradient-based methods", "start": 69, "end": 116, "i_start": 13, "i_end": 21}, "verb": {"text": "have been preferred", "start": 117, "end": 136, "i_start": 22, "i_end": 24}}, {"character": {"text": "or", "start": 91, "end": 93, "i_start": 17, "i_end": 17}, "action": {"text": "extract", "start": 140, "end": 147, "i_start": 26, "i_end": 26}}], "id": 2116}, {"sent": "the thin gray shaded band represents the parametrization of ref .", "tokens": ["the", "thin", "gray", "shaded", "band", "represents", "the", "parametrization", "of", "ref", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the thin gray shaded band", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "represents", "start": 26, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "band", "start": 21, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "represents", "start": 26, "end": 36, "i_start": 5, "i_end": 5}}], "id": 2117}, {"sent": "similarly , in stochastic differential games in which one player uses impulse control and the other uses continuous controls were studied .", "tokens": ["similarly", ",", "in", "stochastic", "differential", "games", "in", "which", "one", "player", "uses", "impulse", "control", "and", "the", "other", "uses", "continuous", "controls", "were", "studied", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "the other", "start": 90, "end": 99, "i_start": 14, "i_end": 15}, "verb": {"text": "uses", "start": 100, "end": 104, "i_start": 16, "i_end": 16}}, {"subject": {"text": "the other", "start": 90, "end": 99, "i_start": 14, "i_end": 15}, "verb": {"text": "studied", "start": 130, "end": 137, "i_start": 20, "i_end": 20}}, {"character": {"text": "one", "start": 54, "end": 57, "i_start": 8, "i_end": 8}, "action": {"text": "player", "start": 58, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "other", "start": 94, "end": 99, "i_start": 15, "i_end": 15}, "action": {"text": "uses", "start": 100, "end": 104, "i_start": 16, "i_end": 16}}], "id": 2118}, {"sent": "with this definition , we can now formulate the shape reconstruction problem .", "tokens": ["with", "this", "definition", ",", "we", "can", "now", "formulate", "the", "shape", "reconstruction", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "verb": {"text": "formulate", "start": 34, "end": 43, "i_start": 7, "i_end": 7}}, {"subject": {"text": "we", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "verb": {"text": "can", "start": 26, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "formulate", "start": 34, "end": 43, "i_start": 7, "i_end": 7}}], "id": 2119}, {"sent": "on the other hand , in the superfluid phase , the existence of gapless phase modes leads to low frequency response on contours whose size increase with frequency .", "tokens": ["on", "the", "other", "hand", ",", "in", "the", "superfluid", "phase", ",", "the", "existence", "of", "gapless", "phase", "modes", "leads", "to", "low", "frequency", "response", "on", "contours", "whose", "size", "increase", "with", "frequency", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the existence of gapless phase modes", "start": 46, "end": 82, "i_start": 10, "i_end": 15}, "verb": {"text": "leads", "start": 83, "end": 88, "i_start": 16, "i_end": 16}}, {"character": {"text": "existence", "start": 50, "end": 59, "i_start": 11, "i_end": 11}, "action": {"text": "leads", "start": 83, "end": 88, "i_start": 16, "i_end": 16}}], "id": 2120}, {"sent": "for example , noisy instances are problematic for boosting algorithms where more weight is placed upon misclassified instanceswhich often include mislabeled and noisy instances .", "tokens": ["for", "example", ",", "noisy", "instances", "are", "problematic", "for", "boosting", "algorithms", "where", "more", "weight", "is", "placed", "upon", "misclassified", "instanceswhich", "often", "include", "mislabeled", "and", "noisy", "instances", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "noisy instances", "start": 14, "end": 29, "i_start": 3, "i_end": 4}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 5, "i_end": 5}}, {"subject": {"text": "noisy instances", "start": 14, "end": 29, "i_start": 3, "i_end": 4}, "verb": {"text": "include", "start": 138, "end": 145, "i_start": 19, "i_end": 19}}], "id": 2121}, {"sent": "for the singular locus consists of finitely many ordinary double points .", "tokens": ["for", "the", "singular", "locus", "consists", "of", "finitely", "many", "ordinary", "double", "points", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the singular locus", "start": 4, "end": 22, "i_start": 1, "i_end": 3}, "verb": {"text": "consists", "start": 23, "end": 31, "i_start": 4, "i_end": 4}}], "id": 2122}, {"sent": "uncorrelated , the axes of the confidence ellipsoid is parallel to the coordinates of the .", "tokens": ["uncorrelated", ",", "the", "axes", "of", "the", "confidence", "ellipsoid", "is", "parallel", "to", "the", "coordinates", "of", "the", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the axes of the confidence ellipsoid", "start": 15, "end": 51, "i_start": 2, "i_end": 7}, "verb": {"text": "is", "start": 52, "end": 54, "i_start": 8, "i_end": 8}}], "id": 2123}, {"sent": "moreover , the method can distinguish between the local minima and saddle points , since the second variation of the rayleigh functional is equal to the second variation of the lagrange modified energy functional , if the latter is evaluated in the space of normalized functions .", "tokens": ["moreover", ",", "the", "method", "can", "distinguish", "between", "the", "local", "minima", "and", "saddle", "points", ",", "since", "the", "second", "variation", "of", "the", "rayleigh", "functional", "is", "equal", "to", "the", "second", "variation", "of", "the", "lagrange", "modified", "energy", "functional", ",", "if", "the", "latter", "is", "evaluated", "in", "the", "space", "of", "normalized", "functions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the method", "start": 11, "end": 21, "i_start": 2, "i_end": 3}, "verb": {"text": "can distinguish", "start": 22, "end": 37, "i_start": 4, "i_end": 5}}, {"character": {"text": "method", "start": 15, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "distinguish", "start": 26, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "equal", "start": 140, "end": 145, "i_start": 23, "i_end": 23}, "action": {"text": "if", "start": 215, "end": 217, "i_start": 35, "i_end": 35}}], "id": 2124}, {"sent": "recently , deep convolutional neural networks have attracted a lot of attention in visual recognition , largely due to their excellent performance .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "attracted", "a", "lot", "of", "attention", "in", "visual", "recognition", ",", "largely", "due", "to", "their", "excellent", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have attracted", "start": 46, "end": 60, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "attracted", "start": 51, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 135, "end": 146, "i_start": 21, "i_end": 21}}], "id": 2125}, {"sent": "we evaluate our results on the pascal voc 2012 image segmentation benchmark , which has 21 semantic classes , including the background .", "tokens": ["we", "evaluate", "our", "results", "on", "the", "pascal", "voc", "2012", "image", "segmentation", "benchmark", ",", "which", "has", "21", "semantic", "classes", ",", "including", "the", "background", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "benchmark", "start": 66, "end": 75, "i_start": 11, "i_end": 11}, "action": {"text": "has", "start": 84, "end": 87, "i_start": 14, "i_end": 14}}], "id": 2126}, {"sent": "scientists are able to gain a greater understanding of the environmental processes through environmental sensing and monitoring .", "tokens": ["scientists", "are", "able", "to", "gain", "a", "greater", "understanding", "of", "the", "environmental", "processes", "through", "environmental", "sensing", "and", "monitoring", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "scientists", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 11, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "scientists", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "gain", "start": 23, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "scientists", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "understanding", "start": 38, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "scientists", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "monitoring", "start": 117, "end": 127, "i_start": 16, "i_end": 16}}], "id": 2127}, {"sent": "deep neural networks have been widely applied in various fields , including computer vision he et al , among many others .", "tokens": ["deep", "neural", "networks", "have", "been", "widely", "applied", "in", "various", "fields", ",", "including", "computer", "vision", "he", "et", "al", ",", "among", "many", "others", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "applied", "start": 38, "end": 45, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}], "id": 2128}, {"sent": "the representer theorem in scalar-valued rkhss was initially established by kimeldorf and wahba .", "tokens": ["the", "representer", "theorem", "in", "scalar", "-", "valued", "rkhss", "was", "initially", "established", "by", "kimeldorf", "and", "wahba", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the representer theorem in scalar-valued rkhss", "start": 0, "end": 46, "i_start": 0, "i_end": 7}, "verb": {"text": "established", "start": 61, "end": 72, "i_start": 10, "i_end": 10}}, {"subject": {"text": "the representer theorem in scalar-valued rkhss", "start": 0, "end": 46, "i_start": 0, "i_end": 7}, "verb": {"text": "was", "start": 47, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "kimeldorf", "start": 76, "end": 85, "i_start": 12, "i_end": 12}, "action": {"text": "established", "start": 61, "end": 72, "i_start": 10, "i_end": 10}}, {"character": {"text": "wahba", "start": 90, "end": 95, "i_start": 14, "i_end": 14}, "action": {"text": "established", "start": 61, "end": 72, "i_start": 10, "i_end": 10}}], "id": 2129}, {"sent": "low density parity check codes were first discovered by gallager in 1999 .", "tokens": ["low", "density", "parity", "check", "codes", "were", "first", "discovered", "by", "gallager", "in", "1999", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "low density parity check codes", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "discovered", "start": 42, "end": 52, "i_start": 7, "i_end": 7}}, {"subject": {"text": "low density parity check codes", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "were", "start": 31, "end": 35, "i_start": 5, "i_end": 5}}, {"character": {"text": "gallager", "start": 56, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "discovered", "start": 42, "end": 52, "i_start": 7, "i_end": 7}}], "id": 2130}, {"sent": "the misconception is caused by shifting imagination from dif ficult infinitesimal thinking to straightforward thinking in .", "tokens": ["the", "misconception", "is", "caused", "by", "shifting", "imagination", "from", "dif", "ficult", "infinitesimal", "thinking", "to", "straightforward", "thinking", "in", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the misconception", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is caused", "start": 18, "end": 27, "i_start": 2, "i_end": 3}}, {"character": {"text": "shifting", "start": 31, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "caused", "start": 21, "end": 27, "i_start": 3, "i_end": 3}}], "id": 2131}, {"sent": "quantum computation consists of single-qubit measurements on the cluster states and every quantum algorithm is encoded in a measurement blueprint .", "tokens": ["quantum", "computation", "consists", "of", "single", "-", "qubit", "measurements", "on", "the", "cluster", "states", "and", "every", "quantum", "algorithm", "is", "encoded", "in", "a", "measurement", "blueprint", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum computation", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 20, "end": 28, "i_start": 2, "i_end": 2}}, {"subject": {"text": "every quantum algorithm", "start": 84, "end": 107, "i_start": 13, "i_end": 15}, "verb": {"text": "encoded", "start": 111, "end": 118, "i_start": 17, "i_end": 17}}], "id": 2132}, {"sent": "our fiducial model is a middle-of-the-road fourier space .", "tokens": ["our", "fiducial", "model", "is", "a", "middle", "-", "of", "-", "the", "-", "road", "fourier", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our fiducial model", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 2133}, {"sent": "in this work we will demonstrate that the cosmological recombination spectrum also is sensitive to the branching of energy released due to dm annihilations into ionizations and excitations .", "tokens": ["in", "this", "work", "we", "will", "demonstrate", "that", "the", "cosmological", "recombination", "spectrum", "also", "is", "sensitive", "to", "the", "branching", "of", "energy", "released", "due", "to", "dm", "annihilations", "into", "ionizations", "and", "excitations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "will demonstrate", "start": 16, "end": 32, "i_start": 4, "i_end": 5}}, {"subject": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 83, "end": 85, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "demonstrate", "start": 21, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "spectrum", "start": 69, "end": 77, "i_start": 10, "i_end": 10}, "action": {"text": "sensitive", "start": 86, "end": 95, "i_start": 13, "i_end": 13}}, {"character": {"text": "annihilations", "start": 142, "end": 155, "i_start": 23, "i_end": 23}, "action": {"text": "released", "start": 123, "end": 131, "i_start": 19, "i_end": 19}}], "id": 2134}, {"sent": "we follow the coalition structure model of , where agents can form several teams simultaneously .", "tokens": ["we", "follow", "the", "coalition", "structure", "model", "of", ",", "where", "agents", "can", "form", "several", "teams", "simultaneously", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "agents", "start": 51, "end": 57, "i_start": 9, "i_end": 9}, "action": {"text": "form", "start": 62, "end": 66, "i_start": 11, "i_end": 11}}], "id": 2135}, {"sent": "in the channel coding problem , strassen , hayashi have determined the second-order capacity rate .", "tokens": ["in", "the", "channel", "coding", "problem", ",", "strassen", ",", "hayashi", "have", "determined", "the", "second", "-", "order", "capacity", "rate", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hayashi", "start": 43, "end": 50, "i_start": 8, "i_end": 8}, "verb": {"text": "have determined", "start": 51, "end": 66, "i_start": 9, "i_end": 10}}, {"character": {"text": "strassen", "start": 32, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "determined", "start": 56, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "hayashi", "start": 43, "end": 50, "i_start": 8, "i_end": 8}, "action": {"text": "determined", "start": 56, "end": 66, "i_start": 10, "i_end": 10}}], "id": 2136}, {"sent": "the mpii human pose dataset consists of around 25k images extracted from online videos .", "tokens": ["the", "mpii", "human", "pose", "dataset", "consists", "of", "around", "25k", "images", "extracted", "from", "online", "videos", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the mpii human pose dataset", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "consists", "start": 28, "end": 36, "i_start": 5, "i_end": 5}}], "id": 2137}, {"sent": "and we can still readily extract the generating functions .", "tokens": ["and", "we", "can", "still", "readily", "extract", "the", "generating", "functions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "extract", "start": 25, "end": 32, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "can", "start": 7, "end": 10, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "extract", "start": 25, "end": 32, "i_start": 5, "i_end": 5}}], "id": 2138}, {"sent": "it is worth noticing the difference with the problem studied in the field of compressive sensing .", "tokens": ["it", "is", "worth", "noticing", "the", "difference", "with", "the", "problem", "studied", "in", "the", "field", "of", "compressive", "sensing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}], "id": 2139}, {"sent": "this profile is the phase of the polyakov loop as a function of its distance to the minimal surface .", "tokens": ["this", "profile", "is", "the", "phase", "of", "the", "polyakov", "loop", "as", "a", "function", "of", "its", "distance", "to", "the", "minimal", "surface", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this profile", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "distance", "start": 68, "end": 76, "i_start": 14, "i_end": 14}, "action": {"text": "function", "start": 52, "end": 60, "i_start": 11, "i_end": 11}}], "id": 2140}, {"sent": "since the state of rbs can not be directly and accurately observed by mtcds , the random access optimization problem with the minimum system costs can be easily formulated as a pomdp .", "tokens": ["since", "the", "state", "of", "rbs", "can", "not", "be", "directly", "and", "accurately", "observed", "by", "mtcds", ",", "the", "random", "access", "optimization", "problem", "with", "the", "minimum", "system", "costs", "can", "be", "easily", "formulated", "as", "a", "pomdp", "."], "score": [1, 1, 1, 1, 0], "labels": [{"subject": {"text": "the random access optimization problem with the minimum system costs", "start": 78, "end": 146, "i_start": 15, "i_end": 24}, "verb": {"text": "formulated", "start": 161, "end": 171, "i_start": 28, "i_end": 28}}, {"subject": {"text": "the random access optimization problem with the minimum system costs", "start": 78, "end": 146, "i_start": 15, "i_end": 24}, "verb": {"text": "can be", "start": 147, "end": 153, "i_start": 25, "i_end": 26}}], "id": 2141}, {"sent": "this ensures that the routing tables converge deterministically to the shortest paths in the network .", "tokens": ["this", "ensures", "that", "the", "routing", "tables", "converge", "deterministically", "to", "the", "shortest", "paths", "in", "the", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "ensures", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the routing tables", "start": 18, "end": 36, "i_start": 3, "i_end": 5}, "verb": {"text": "converge", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "ensures", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}], "id": 2142}, {"sent": "convolutional neural network based models led to a series of breakthroughs in high-level computer vision tasks , such as image classification .", "tokens": ["convolutional", "neural", "network", "based", "models", "led", "to", "a", "series", "of", "breakthroughs", "in", "high", "-", "level", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural network based models", "start": 0, "end": 41, "i_start": 0, "i_end": 4}, "verb": {"text": "led", "start": 42, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "models", "start": 35, "end": 41, "i_start": 4, "i_end": 4}, "action": {"text": "led", "start": 42, "end": 45, "i_start": 5, "i_end": 5}}], "id": 2143}, {"sent": "in particular , we focus on the combination of their luminosities and energy-dependent pulsed fractions .", "tokens": ["in", "particular", ",", "we", "focus", "on", "the", "combination", "of", "their", "luminosities", "and", "energy", "-", "dependent", "pulsed", "fractions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "focus", "start": 19, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "focus", "start": 19, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "fractions", "start": 94, "end": 103, "i_start": 16, "i_end": 16}, "action": {"text": "dependent", "start": 77, "end": 86, "i_start": 14, "i_end": 14}}], "id": 2144}, {"sent": "the beppo-sax satellite is a joint italian and dutch program .", "tokens": ["the", "beppo", "-", "sax", "satellite", "is", "a", "joint", "italian", "and", "dutch", "program", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the beppo-sax satellite", "start": 0, "end": 23, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 5, "i_end": 5}}], "id": 2145}, {"sent": "our general result explains why the quantization conditions of are valid in the maximally supersymmetric cases .", "tokens": ["our", "general", "result", "explains", "why", "the", "quantization", "conditions", "of", "are", "valid", "in", "the", "maximally", "supersymmetric", "cases", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our general result", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "explains", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}, {"subject": {"text": "our general result", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 63, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "result", "start": 12, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "explains", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}], "id": 2146}, {"sent": "in this section , we present and discuss results obtained for these structures .", "tokens": ["in", "this", "section", ",", "we", "present", "and", "discuss", "results", "obtained", "for", "these", "structures", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "present", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "discuss", "start": 33, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "present", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "structures", "start": 68, "end": 78, "i_start": 12, "i_end": 12}, "action": {"text": "obtained", "start": 49, "end": 57, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "discuss", "start": 33, "end": 40, "i_start": 7, "i_end": 7}}], "id": 2147}, {"sent": "deep neural networks achieve state of the art performance on many problems , but are often very large in depth or width , and contain large numbers of parameters .", "tokens": ["deep", "neural", "networks", "achieve", "state", "of", "the", "art", "performance", "on", "many", "problems", ",", "but", "are", "often", "very", "large", "in", "depth", "or", "width", ",", "and", "contain", "large", "numbers", "of", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "achieve", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 46, "end": 57, "i_start": 8, "i_end": 8}}], "id": 2148}, {"sent": "we prove that , roughly speaking , they are completely determined by the semigroup automorphisms of s .", "tokens": ["we", "prove", "that", ",", "roughly", "speaking", ",", "they", "are", "completely", "determined", "by", "the", "semigroup", "automorphisms", "of", "s", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "prove", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "they", "start": 35, "end": 39, "i_start": 7, "i_end": 7}, "verb": {"text": "determined", "start": 55, "end": 65, "i_start": 10, "i_end": 10}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "automorphisms", "start": 83, "end": 96, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "prove", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "automorphisms", "start": 83, "end": 96, "i_start": 14, "i_end": 14}, "action": {"text": "determined", "start": 55, "end": 65, "i_start": 10, "i_end": 10}}], "id": 2149}, {"sent": "however , deep residual learning has shown its capability to easy the training of very deep neural networks .", "tokens": ["however", ",", "deep", "residual", "learning", "has", "shown", "its", "capability", "to", "easy", "the", "training", "of", "very", "deep", "neural", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep residual learning", "start": 10, "end": 32, "i_start": 2, "i_end": 4}, "verb": {"text": "has shown", "start": 33, "end": 42, "i_start": 5, "i_end": 6}}, {"character": {"text": "learning", "start": 24, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "shown", "start": 37, "end": 42, "i_start": 6, "i_end": 6}}], "id": 2150}, {"sent": "these operators all explicitly break gauge invariance .", "tokens": ["these", "operators", "all", "explicitly", "break", "gauge", "invariance", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "these operators", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "break", "start": 31, "end": 36, "i_start": 4, "i_end": 4}}, {"character": {"text": "all", "start": 16, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "break", "start": 31, "end": 36, "i_start": 4, "i_end": 4}}], "id": 2151}, {"sent": "a semidefinite program -based gf solver attaining a higher success probability than the nr scheme , is developed in .", "tokens": ["a", "semidefinite", "program", "-based", "gf", "solver", "attaining", "a", "higher", "success", "probability", "than", "the", "nr", "scheme", ",", "is", "developed", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a semidefinite program -based gf", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "solver", "start": 33, "end": 39, "i_start": 5, "i_end": 5}}, {"subject": {"text": "a semidefinite program -based gf", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "developed", "start": 103, "end": 112, "i_start": 17, "i_end": 17}}, {"character": {"text": "solver", "start": 33, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "attaining", "start": 40, "end": 49, "i_start": 6, "i_end": 6}}], "id": 2152}, {"sent": "this approach is further extended to the complex channel in for the compound mimo broadcast channel .", "tokens": ["this", "approach", "is", "further", "extended", "to", "the", "complex", "channel", "in", "for", "the", "compound", "mimo", "broadcast", "channel", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this approach", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "extended", "start": 25, "end": 33, "i_start": 4, "i_end": 4}}, {"subject": {"text": "this approach", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 2153}, {"sent": "we use a resnet-50 cnn for extracting the visual features .", "tokens": ["we", "use", "a", "resnet-50", "cnn", "for", "extracting", "the", "visual", "features", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extracting", "start": 27, "end": 37, "i_start": 6, "i_end": 6}}], "id": 2154}, {"sent": "an alternative way to look at the data is to plot the birefringence vs .", "tokens": ["an", "alternative", "way", "to", "look", "at", "the", "data", "is", "to", "plot", "the", "birefringence", "vs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an alternative way to look at the data", "start": 0, "end": 38, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 8, "i_end": 8}}], "id": 2155}, {"sent": "measure the first two registers to obtain the integers .", "tokens": ["measure", "the", "first", "two", "registers", "to", "obtain", "the", "integers", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2156}, {"sent": "whether the dark energy is a cosmological constant or not is a matter of profound importance in cosmology and fundamental physics .", "tokens": ["whether", "the", "dark", "energy", "is", "a", "cosmological", "constant", "or", "not", "is", "a", "matter", "of", "profound", "importance", "in", "cosmology", "and", "fundamental", "physics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dark energy", "start": 8, "end": 23, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 4, "i_end": 4}}], "id": 2157}, {"sent": "we use the popular u-net architecture as a baseline to predict 2 output classes .", "tokens": ["we", "use", "the", "popular", "u", "-", "net", "architecture", "as", "a", "baseline", "to", "predict", "2", "output", "classes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "predict", "start": 55, "end": 62, "i_start": 12, "i_end": 12}}], "id": 2158}, {"sent": "deformation is a common phenomenon in nuclear and atomic physics .", "tokens": ["deformation", "is", "a", "common", "phenomenon", "in", "nuclear", "and", "atomic", "physics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deformation", "start": 0, "end": 11, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 1, "i_end": 1}}], "id": 2159}, {"sent": "the vacuum penetrates everywhere , whether it is a dielectric or a conductor .", "tokens": ["the", "vacuum", "penetrates", "everywhere", ",", "whether", "it", "is", "a", "dielectric", "or", "a", "conductor", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the vacuum", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "penetrates", "start": 11, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "vacuum", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "penetrates", "start": 11, "end": 21, "i_start": 2, "i_end": 2}}], "id": 2160}, {"sent": "the algorithm from returns the birth density of each persistent homology class .", "tokens": ["the", "algorithm", "from", "returns", "the", "birth", "density", "of", "each", "persistent", "homology", "class", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "algorithm", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "returns", "start": 19, "end": 26, "i_start": 3, "i_end": 3}}], "id": 2161}, {"sent": "recently , deep neural networks achieve excellent performance on difficult problems such as speech recognition .", "tokens": ["recently", ",", "deep", "neural", "networks", "achieve", "excellent", "performance", "on", "difficult", "problems", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "achieve", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "achieve", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "performance", "start": 50, "end": 61, "i_start": 7, "i_end": 7}}], "id": 2162}, {"sent": "we compare our proposed affinity fields and aaf with other competing methods on the pascal voc 2012 datasets .", "tokens": ["we", "compare", "our", "proposed", "affinity", "fields", "and", "aaf", "with", "other", "competing", "methods", "on", "the", "pascal", "voc", "2012", "datasets", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "methods", "start": 69, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "competing", "start": 59, "end": 68, "i_start": 10, "i_end": 10}}], "id": 2163}, {"sent": "quantum repeaters are essential for long-distance quantum communication .", "tokens": ["quantum", "repeaters", "are", "essential", "for", "long", "-", "distance", "quantum", "communication", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum repeaters", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 18, "end": 21, "i_start": 2, "i_end": 2}}], "id": 2164}, {"sent": "instead of a discontinuity there is a continuous but quick variation of the order parameter during the transition .", "tokens": ["instead", "of", "a", "discontinuity", "there", "is", "a", "continuous", "but", "quick", "variation", "of", "the", "order", "parameter", "during", "the", "transition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 27, "end": 32, "i_start": 4, "i_end": 4}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 5, "i_end": 5}}], "id": 2165}, {"sent": "this is the reason for continued interest in the split-monopole problem .", "tokens": ["this", "is", "the", "reason", "for", "continued", "interest", "in", "the", "split", "-", "monopole", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 2166}, {"sent": "we conclude that the dewitt-brehme construction correctly calculates the electromagnetic self-force .", "tokens": ["we", "conclude", "that", "the", "dewitt", "-", "brehme", "construction", "correctly", "calculates", "the", "electromagnetic", "self", "-", "force", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "conclude", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the dewitt-brehme construction", "start": 17, "end": 47, "i_start": 3, "i_end": 7}, "verb": {"text": "calculates", "start": 58, "end": 68, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "conclude", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "construction", "start": 35, "end": 47, "i_start": 7, "i_end": 7}, "action": {"text": "calculates", "start": 58, "end": 68, "i_start": 9, "i_end": 9}}], "id": 2167}, {"sent": "elmo is a character-based model which learns dynamic word embeddings that can change depending on the context .", "tokens": ["elmo", "is", "a", "character", "-", "based", "model", "which", "learns", "dynamic", "word", "embeddings", "that", "can", "change", "depending", "on", "the", "context", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "elmo", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "model", "start": 26, "end": 31, "i_start": 6, "i_end": 6}, "action": {"text": "learns", "start": 38, "end": 44, "i_start": 8, "i_end": 8}}, {"character": {"text": "change", "start": 78, "end": 84, "i_start": 14, "i_end": 14}, "action": {"text": "depending", "start": 85, "end": 94, "i_start": 15, "i_end": 15}}], "id": 2168}, {"sent": "the patch-based feature extraction method is an example of this approach .", "tokens": ["the", "patch", "-", "based", "feature", "extraction", "method", "is", "an", "example", "of", "this", "approach", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the patch-based feature extraction method", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 42, "end": 44, "i_start": 7, "i_end": 7}}], "id": 2169}, {"sent": "kipf and welling introduced a simple but powerful architecture , and achieved the state-of-the-art performance in benchmark citation networks .", "tokens": ["kipf", "and", "welling", "introduced", "a", "simple", "but", "powerful", "architecture", ",", "and", "achieved", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "benchmark", "citation", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "welling", "start": 9, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "kipf", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "welling", "start": 9, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "introduced", "start": 17, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "kipf", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 17, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "welling", "start": 9, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 17, "end": 27, "i_start": 3, "i_end": 3}}], "id": 2170}, {"sent": "large-scale deep convolutional neural networks have been successfully applied to a wide variety of applications such as image classification .", "tokens": ["large", "-", "scale", "deep", "convolutional", "neural", "networks", "have", "been", "successfully", "applied", "to", "a", "wide", "variety", "of", "applications", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "large-scale deep convolutional neural networks", "start": 0, "end": 46, "i_start": 0, "i_end": 6}, "verb": {"text": "applied", "start": 70, "end": 77, "i_start": 10, "i_end": 10}}, {"subject": {"text": "large-scale deep convolutional neural networks", "start": 0, "end": 46, "i_start": 0, "i_end": 6}, "verb": {"text": "have been", "start": 47, "end": 56, "i_start": 7, "i_end": 8}}], "id": 2171}, {"sent": "a few recent methods attempt to solve for d and x jointly in an iterative fashion .", "tokens": ["a", "few", "recent", "methods", "attempt", "to", "solve", "for", "d", "and", "x", "jointly", "in", "an", "iterative", "fashion", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a few recent methods", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "attempt", "start": 21, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "methods", "start": 13, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "attempt", "start": 21, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "methods", "start": 13, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "solve", "start": 32, "end": 37, "i_start": 6, "i_end": 6}}], "id": 2172}, {"sent": "scenarios exploiting the opportunistic gain also studied in cooperative networks by applying an opportunistic two-hop relaying protocol .", "tokens": ["scenarios", "exploiting", "the", "opportunistic", "gain", "also", "studied", "in", "cooperative", "networks", "by", "applying", "an", "opportunistic", "two", "-", "hop", "relaying", "protocol", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "scenarios", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "exploiting", "start": 10, "end": 20, "i_start": 1, "i_end": 1}}, {"character": {"text": "two-hop", "start": 110, "end": 117, "i_start": 14, "i_end": 16}, "action": {"text": "relaying", "start": 118, "end": 126, "i_start": 17, "i_end": 17}}], "id": 2173}, {"sent": "doersch et al proposed to predict the relative position of patches cropped from images .", "tokens": ["doersch", "et", "al", "proposed", "to", "predict", "the", "relative", "position", "of", "patches", "cropped", "from", "images", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 8, "end": 13, "i_start": 1, "i_end": 2}, "verb": {"text": "proposed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "doersch", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "doersch", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "predict", "start": 26, "end": 33, "i_start": 5, "i_end": 5}}], "id": 2174}, {"sent": "in the last two years , the performance of object detection has been significantly improved with the success of novel deep convolutional neural networks .", "tokens": ["in", "the", "last", "two", "years", ",", "the", "performance", "of", "object", "detection", "has", "been", "significantly", "improved", "with", "the", "success", "of", "novel", "deep", "convolutional", "neural", "networks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the performance of object detection", "start": 24, "end": 59, "i_start": 6, "i_end": 10}, "verb": {"text": "improved", "start": 83, "end": 91, "i_start": 14, "i_end": 14}}, {"subject": {"text": "the performance of object detection", "start": 24, "end": 59, "i_start": 6, "i_end": 10}, "verb": {"text": "has been", "start": 60, "end": 68, "i_start": 11, "i_end": 12}}, {"character": {"text": "success", "start": 101, "end": 108, "i_start": 17, "i_end": 17}, "action": {"text": "improved", "start": 83, "end": 91, "i_start": 14, "i_end": 14}}, {"character": {"text": "networks", "start": 144, "end": 152, "i_start": 23, "i_end": 23}, "action": {"text": "success", "start": 101, "end": 108, "i_start": 17, "i_end": 17}}], "id": 2175}, {"sent": "neural networks have made remarkable progress in achieving encouraging results in digital image processing .", "tokens": ["neural", "networks", "have", "made", "remarkable", "progress", "in", "achieving", "encouraging", "results", "in", "digital", "image", "processing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have made", "start": 16, "end": 25, "i_start": 2, "i_end": 3}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "achieving", "start": 49, "end": 58, "i_start": 7, "i_end": 7}}, {"character": {"text": "results", "start": 71, "end": 78, "i_start": 9, "i_end": 9}, "action": {"text": "encouraging", "start": 59, "end": 70, "i_start": 8, "i_end": 8}}], "id": 2176}, {"sent": "in 2d origami , elementary single-fold operations are defined in terms of incidence constraints between pairs of objects that must be satisfied with a fold .", "tokens": ["in", "2d", "origami", ",", "elementary", "single", "-", "fold", "operations", "are", "defined", "in", "terms", "of", "incidence", "constraints", "between", "pairs", "of", "objects", "that", "must", "be", "satisfied", "with", "a", "fold", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "elementary single-fold operations", "start": 16, "end": 49, "i_start": 4, "i_end": 8}, "verb": {"text": "are defined", "start": 50, "end": 61, "i_start": 9, "i_end": 10}}], "id": 2177}, {"sent": "li et al proposed neural deep model to deal with english discourse coherence evaluation .", "tokens": ["li", "et", "al", "proposed", "neural", "deep", "model", "to", "deal", "with", "english", "discourse", "coherence", "evaluation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "li et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "li", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "model", "start": 30, "end": 35, "i_start": 6, "i_end": 6}, "action": {"text": "deal", "start": 39, "end": 43, "i_start": 8, "i_end": 8}}], "id": 2178}, {"sent": "the photometry was carried out in the same way as described above in sect .", "tokens": ["the", "photometry", "was", "carried", "out", "in", "the", "same", "way", "as", "described", "above", "in", "sect", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the photometry", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "was carried out", "start": 15, "end": 30, "i_start": 2, "i_end": 4}}], "id": 2179}, {"sent": "convolutional neural networks have shown great success in visual and semantic understanding .", "tokens": ["convolutional", "neural", "networks", "have", "shown", "great", "success", "in", "visual", "and", "semantic", "understanding", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 47, "end": 54, "i_start": 6, "i_end": 6}}], "id": 2180}, {"sent": "a polaron is a unit containing an electron .", "tokens": ["a", "polaron", "is", "a", "unit", "containing", "an", "electron", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a polaron", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "unit", "start": 15, "end": 19, "i_start": 4, "i_end": 4}, "action": {"text": "containing", "start": 20, "end": 30, "i_start": 5, "i_end": 5}}], "id": 2181}, {"sent": "recently , convolutional neural networks achieve remarkable progresses in a variety of computer vision tasks , such as image classification .", "tokens": ["recently", ",", "convolutional", "neural", "networks", "achieve", "remarkable", "progresses", "in", "a", "variety", "of", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 11, "end": 40, "i_start": 2, "i_end": 4}, "verb": {"text": "achieve", "start": 41, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "achieve", "start": 41, "end": 48, "i_start": 5, "i_end": 5}}], "id": 2182}, {"sent": "qca devices also were implemented using semiconductor quantum dots .", "tokens": ["qca", "devices", "also", "were", "implemented", "using", "semiconductor", "quantum", "dots", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "qca devices", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "were implemented", "start": 17, "end": 33, "i_start": 3, "i_end": 4}}], "id": 2183}, {"sent": "srinivasan , algebra structures on some canonical resolutions .", "tokens": ["srinivasan", ",", "algebra", "structures", "on", "some", "canonical", "resolutions", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2184}, {"sent": "small delays and moderate precision are necessary for robust stimulus competition .", "tokens": ["small", "delays", "and", "moderate", "precision", "are", "necessary", "for", "robust", "stimulus", "competition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "small delays and moderate precision", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "are", "start": 36, "end": 39, "i_start": 5, "i_end": 5}}], "id": 2185}, {"sent": "indeed , let us assume that the nucleus is a prolate spheroid with spin i along the major axis .", "tokens": ["indeed", ",", "let", "us", "assume", "that", "the", "nucleus", "is", "a", "prolate", "spheroid", "with", "spin", "i", "along", "the", "major", "axis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "let", "start": 9, "end": 12, "i_start": 2, "i_end": 2}}, {"subject": {"text": "us", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "assume", "start": 16, "end": 22, "i_start": 4, "i_end": 4}}, {"character": {"text": "us", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "let", "start": 9, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "assume", "start": 16, "end": 22, "i_start": 4, "i_end": 4}}], "id": 2186}, {"sent": "the first documented uses of comparisons in pairs date back to the thirteenth century .", "tokens": ["the", "first", "documented", "uses", "of", "comparisons", "in", "pairs", "date", "back", "to", "the", "thirteenth", "century", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2187}, {"sent": "let us recall the definition of this chain complex .", "tokens": ["let", "us", "recall", "the", "definition", "of", "this", "chain", "complex", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "recall", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "recall", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}], "id": 2188}, {"sent": "each perturbation we consider is a sum of single-qubit terms , where each term can be interpreted as a magnetic field pointing in a random direction .", "tokens": ["each", "perturbation", "we", "consider", "is", "a", "sum", "of", "single", "-", "qubit", "terms", ",", "where", "each", "term", "can", "be", "interpreted", "as", "a", "magnetic", "field", "pointing", "in", "a", "random", "direction", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "each perturbation we consider", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "consider", "start": 21, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "field", "start": 112, "end": 117, "i_start": 22, "i_end": 22}, "action": {"text": "pointing", "start": 118, "end": 126, "i_start": 23, "i_end": 23}}], "id": 2189}, {"sent": "distribution-invariant dynamic risk measures .", "tokens": ["distribution", "-", "invariant", "dynamic", "risk", "measures", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2190}, {"sent": "presented as two-dimensional equivalents of volumetric metamaterials , metasurfaces have attracted a significant interest in recent years .", "tokens": ["presented", "as", "two", "-", "dimensional", "equivalents", "of", "volumetric", "metamaterials", ",", "metasurfaces", "have", "attracted", "a", "significant", "interest", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "metasurfaces", "start": 71, "end": 83, "i_start": 10, "i_end": 10}, "verb": {"text": "have attracted", "start": 84, "end": 98, "i_start": 11, "i_end": 12}}, {"character": {"text": "metasurfaces", "start": 71, "end": 83, "i_start": 10, "i_end": 10}, "action": {"text": "attracted", "start": 89, "end": 98, "i_start": 12, "i_end": 12}}], "id": 2191}, {"sent": "however , it is well-known that eye scan patterns in an film audience follow a specific pattern after a scene change , activating the dorsal pathway .", "tokens": ["however", ",", "it", "is", "well", "-", "known", "that", "eye", "scan", "patterns", "in", "an", "film", "audience", "follow", "a", "specific", "pattern", "after", "a", "scene", "change", ",", "activating", "the", "dorsal", "pathway", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 3, "i_end": 3}}, {"subject": {"text": "eye scan patterns in an film audience", "start": 32, "end": 69, "i_start": 8, "i_end": 14}, "verb": {"text": "follow", "start": 70, "end": 76, "i_start": 15, "i_end": 15}}, {"character": {"text": "patterns", "start": 41, "end": 49, "i_start": 10, "i_end": 10}, "action": {"text": "follow", "start": 70, "end": 76, "i_start": 15, "i_end": 15}}, {"character": {"text": "follow", "start": 70, "end": 76, "i_start": 15, "i_end": 15}, "action": {"text": "activating", "start": 119, "end": 129, "i_start": 24, "i_end": 24}}], "id": 2192}, {"sent": "the number of flare events for the different brightness classes and the corresponding percentage values are listed .", "tokens": ["the", "number", "of", "flare", "events", "for", "the", "different", "brightness", "classes", "and", "the", "corresponding", "percentage", "values", "are", "listed", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the number of flare events for the different brightness classes and the corresponding percentage values", "start": 0, "end": 103, "i_start": 0, "i_end": 14}, "verb": {"text": "are listed", "start": 104, "end": 114, "i_start": 15, "i_end": 16}}], "id": 2193}, {"sent": "other examples of systems with scale separation include chemical reaction systems where there can exist a difference of several orders of magnitude among the different reaction rates .", "tokens": ["other", "examples", "of", "systems", "with", "scale", "separation", "include", "chemical", "reaction", "systems", "where", "there", "can", "exist", "a", "difference", "of", "several", "orders", "of", "magnitude", "among", "the", "different", "reaction", "rates", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "other examples of systems with scale separation", "start": 0, "end": 47, "i_start": 0, "i_end": 6}, "verb": {"text": "include", "start": 48, "end": 55, "i_start": 7, "i_end": 7}}, {"character": {"text": "systems", "start": 18, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "reaction", "start": 65, "end": 73, "i_start": 9, "i_end": 9}}], "id": 2194}, {"sent": "recently , deep convolutional neural networks have attracted a lot of attention in visual recognition due to its good performance .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "attracted", "a", "lot", "of", "attention", "in", "visual", "recognition", "due", "to", "its", "good", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have attracted", "start": 46, "end": 60, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "attracted", "start": 51, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 118, "end": 129, "i_start": 19, "i_end": 19}}], "id": 2195}, {"sent": "deep neural networks have produced state-ofthe-art results in applications such as computer vision .", "tokens": ["deep", "neural", "networks", "have", "produced", "state", "-", "ofthe", "-", "art", "results", "in", "applications", "such", "as", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have produced", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "produced", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}], "id": 2196}, {"sent": "deep neural networks are now central tools for a variety of tasks including image classification .", "tokens": ["deep", "neural", "networks", "are", "now", "central", "tools", "for", "a", "variety", "of", "tasks", "including", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2197}, {"sent": "let us now summarize the main results of this approach , as needed for the present paper .", "tokens": ["let", "us", "now", "summarize", "the", "main", "results", "of", "this", "approach", ",", "as", "needed", "for", "the", "present", "paper", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "summarize", "start": 11, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "summarize", "start": 11, "end": 20, "i_start": 3, "i_end": 3}}], "id": 2198}, {"sent": "here we compare the boomerang maps to the maps recently obtained at similar frequency and resolution by the wmap satellite .", "tokens": ["here", "we", "compare", "the", "boomerang", "maps", "to", "the", "maps", "recently", "obtained", "at", "similar", "frequency", "and", "resolution", "by", "the", "wmap", "satellite", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "compare", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "compare", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "satellite", "start": 113, "end": 122, "i_start": 19, "i_end": 19}, "action": {"text": "obtained", "start": 56, "end": 64, "i_start": 10, "i_end": 10}}], "id": 2199}, {"sent": "the reconnection rate peaks more quickly in the single perturbation simulation than the double perturbation simulation .", "tokens": ["the", "reconnection", "rate", "peaks", "more", "quickly", "in", "the", "single", "perturbation", "simulation", "than", "the", "double", "perturbation", "simulation", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2200}, {"sent": "schneider , in the physics of conventional and unconventional superconductors , edited by k .", "tokens": ["schneider", ",", "in", "the", "physics", "of", "conventional", "and", "unconventional", "superconductors", ",", "edited", "by", "k", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "schneider", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "edited", "start": 80, "end": 86, "i_start": 11, "i_end": 11}}], "id": 2201}, {"sent": "the sparse vector recovery problems emerging in many areas of scientific research and engineering practice have attracted considerable attention in recent years .", "tokens": ["the", "sparse", "vector", "recovery", "problems", "emerging", "in", "many", "areas", "of", "scientific", "research", "and", "engineering", "practice", "have", "attracted", "considerable", "attention", "in", "recent", "years", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the sparse vector recovery problems emerging in many areas of scientific research and engineering practice", "start": 0, "end": 106, "i_start": 0, "i_end": 14}, "verb": {"text": "have attracted", "start": 107, "end": 121, "i_start": 15, "i_end": 16}}, {"character": {"text": "problems", "start": 27, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "attracted", "start": 112, "end": 121, "i_start": 16, "i_end": 16}}, {"character": {"text": "problems", "start": 27, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "emerging", "start": 36, "end": 44, "i_start": 5, "i_end": 5}}], "id": 2202}, {"sent": "the relation network uses a faster-rcnn as the feature extractor .", "tokens": ["the", "relation", "network", "uses", "a", "faster", "-", "rcnn", "as", "the", "feature", "extractor", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the relation network", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "uses", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "network", "start": 13, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "uses", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}], "id": 2203}, {"sent": "recently , machine learning has seen the rise of deep learning methods , achieving state-ofthe-art results in many fields , from image classification tasks via convolutional neural networks .", "tokens": ["recently", ",", "machine", "learning", "has", "seen", "the", "rise", "of", "deep", "learning", "methods", ",", "achieving", "state", "-", "ofthe", "-", "art", "results", "in", "many", "fields", ",", "from", "image", "classification", "tasks", "via", "convolutional", "neural", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "machine learning", "start": 11, "end": 27, "i_start": 2, "i_end": 3}, "verb": {"text": "has seen", "start": 28, "end": 36, "i_start": 4, "i_end": 5}}, {"character": {"text": "learning", "start": 19, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "seen", "start": 32, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "rise", "start": 41, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "achieving", "start": 73, "end": 82, "i_start": 13, "i_end": 13}}], "id": 2204}, {"sent": "this t -duality is a mirror symmetry in the two-dimensional sense .", "tokens": ["this", "t", "-duality", "is", "a", "mirror", "symmetry", "in", "the", "two", "-", "dimensional", "sense", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this t -duality", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 2205}, {"sent": "the state of the market with maximum randomness is called equilibrium .", "tokens": ["the", "state", "of", "the", "market", "with", "maximum", "randomness", "is", "called", "equilibrium", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the state of the market with maximum randomness", "start": 0, "end": 47, "i_start": 0, "i_end": 7}, "verb": {"text": "is called", "start": 48, "end": 57, "i_start": 8, "i_end": 9}}], "id": 2206}, {"sent": "therefore the extension of the incoherent approximation must be done in the frequency domain .", "tokens": ["therefore", "the", "extension", "of", "the", "incoherent", "approximation", "must", "be", "done", "in", "the", "frequency", "domain", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the extension of the incoherent approximation", "start": 10, "end": 55, "i_start": 1, "i_end": 6}, "verb": {"text": "must be done", "start": 56, "end": 68, "i_start": 7, "i_end": 9}}], "id": 2207}, {"sent": "we now illustrate this definition by the following examples .", "tokens": ["we", "now", "illustrate", "this", "definition", "by", "the", "following", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "illustrate", "start": 7, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "illustrate", "start": 7, "end": 17, "i_start": 2, "i_end": 2}}], "id": 2208}, {"sent": "before applying our theory , we first examine the alternative approaches , in addition to that of .", "tokens": ["before", "applying", "our", "theory", ",", "we", "first", "examine", "the", "alternative", "approaches", ",", "in", "addition", "to", "that", "of", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "verb": {"text": "examine", "start": 38, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "examine", "start": 38, "end": 45, "i_start": 7, "i_end": 7}}], "id": 2209}, {"sent": "deep neural networks have been intensively studied in recent years , and many record-breaking progresses have been made on solving computer vision , speech recognition , and natural language processing problems .", "tokens": ["deep", "neural", "networks", "have", "been", "intensively", "studied", "in", "recent", "years", ",", "and", "many", "record", "-", "breaking", "progresses", "have", "been", "made", "on", "solving", "computer", "vision", ",", "speech", "recognition", ",", "and", "natural", "language", "processing", "problems", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "many record-breaking progresses", "start": 73, "end": 104, "i_start": 12, "i_end": 16}, "verb": {"text": "studied", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "made", "start": 115, "end": 119, "i_start": 19, "i_end": 19}}, {"character": {"text": "progresses", "start": 94, "end": 104, "i_start": 16, "i_end": 16}, "action": {"text": "breaking", "start": 85, "end": 93, "i_start": 15, "i_end": 15}}], "id": 2210}, {"sent": "goodfellow et al proposed a fast method called fast gradient sign method to generate adversarial examples .", "tokens": ["goodfellow", "et", "al", "proposed", "a", "fast", "method", "called", "fast", "gradient", "sign", "method", "to", "generate", "adversarial", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "goodfellow", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}], "id": 2211}, {"sent": "recently researchers who used deep convolutional neural networks for object recognition have reported great success .", "tokens": ["recently", "researchers", "who", "used", "deep", "convolutional", "neural", "networks", "for", "object", "recognition", "have", "reported", "great", "success", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "researchers who used deep convolutional neural networks for object recognition", "start": 9, "end": 87, "i_start": 1, "i_end": 10}, "verb": {"text": "have reported", "start": 88, "end": 101, "i_start": 11, "i_end": 12}}, {"character": {"text": "neural", "start": 49, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "reported", "start": 93, "end": 101, "i_start": 12, "i_end": 12}}, {"character": {"text": "convolutional", "start": 35, "end": 48, "i_start": 5, "i_end": 5}, "action": {"text": "reported", "start": 93, "end": 101, "i_start": 12, "i_end": 12}}, {"character": {"text": "neural", "start": 49, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "recognition", "start": 76, "end": 87, "i_start": 10, "i_end": 10}}, {"character": {"text": "convolutional", "start": 35, "end": 48, "i_start": 5, "i_end": 5}, "action": {"text": "recognition", "start": 76, "end": 87, "i_start": 10, "i_end": 10}}], "id": 2212}, {"sent": "sindagi et al proposed a contextual pyramid cnn to incorporate contextual information of crowds for achieving lower counting error and high-quality density maps .", "tokens": ["sindagi", "et", "al", "proposed", "a", "contextual", "pyramid", "cnn", "to", "incorporate", "contextual", "information", "of", "crowds", "for", "achieving", "lower", "counting", "error", "and", "high", "-", "quality", "density", "maps", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "sindagi et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "sindagi", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}], "id": 2213}, {"sent": "the master equation has found many applications in thermodynamics .", "tokens": ["the", "master", "equation", "has", "found", "many", "applications", "in", "thermodynamics", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the master equation", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "has found", "start": 20, "end": 29, "i_start": 3, "i_end": 4}}, {"character": {"text": "equation", "start": 11, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "found", "start": 24, "end": 29, "i_start": 4, "i_end": 4}}], "id": 2214}, {"sent": "welter r , ijjaali i , venturini g , malaman b , j .", "tokens": ["welter", "r", ",", "ijjaali", "i", ",", "venturini", "g", ",", "malaman", "b", ",", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2215}, {"sent": "symbolic execution is a program testing and debugging technique in which symbolic inputs are supplied instead of concrete inputs .", "tokens": ["symbolic", "execution", "is", "a", "program", "testing", "and", "debugging", "technique", "in", "which", "symbolic", "inputs", "are", "supplied", "instead", "of", "concrete", "inputs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "symbolic execution", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}], "id": 2216}, {"sent": "all calculations have been carried out using the projected augmented-wave formalism as implemented in the vienna ab initio simulation package .", "tokens": ["all", "calculations", "have", "been", "carried", "out", "using", "the", "projected", "augmented", "-", "wave", "formalism", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all calculations", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "have been carried out", "start": 17, "end": 38, "i_start": 2, "i_end": 5}}], "id": 2217}, {"sent": "the densenet architecture consists of a series of dense blocks where each layer within a dense block is densely connected to all preceding layers .", "tokens": ["the", "densenet", "architecture", "consists", "of", "a", "series", "of", "dense", "blocks", "where", "each", "layer", "within", "a", "dense", "block", "is", "densely", "connected", "to", "all", "preceding", "layers", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the densenet architecture", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 26, "end": 34, "i_start": 3, "i_end": 3}}], "id": 2218}, {"sent": "convolutional neural networks have achieved great success on visual recognition tasks .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "great", "success", "on", "visual", "recognition", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}], "id": 2219}, {"sent": "in , a branch-and-bound algorithm for mbbp for general graphs was studied .", "tokens": ["in", ",", "a", "branch", "-", "and", "-", "bound", "algorithm", "for", "mbbp", "for", "general", "graphs", "was", "studied", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a branch-and-bound algorithm for mbbp for general graphs", "start": 5, "end": 61, "i_start": 2, "i_end": 13}, "verb": {"text": "was studied", "start": 62, "end": 73, "i_start": 14, "i_end": 15}}], "id": 2220}, {"sent": "a concept of computational complexity is originally known in quantum information theory .", "tokens": ["a", "concept", "of", "computational", "complexity", "is", "originally", "known", "in", "quantum", "information", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a concept of computational complexity", "start": 0, "end": 37, "i_start": 0, "i_end": 4}, "verb": {"text": "known", "start": 52, "end": 57, "i_start": 7, "i_end": 7}}, {"subject": {"text": "a concept of computational complexity", "start": 0, "end": 37, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 5, "i_end": 5}}], "id": 2221}, {"sent": "the well-known k-means algorithm is one of the most influential and popular clustering methods .", "tokens": ["the", "well", "-", "known", "k", "-", "means", "algorithm", "is", "one", "of", "the", "most", "influential", "and", "popular", "clustering", "methods", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the well-known k-means algorithm", "start": 0, "end": 32, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 8, "i_end": 8}}, {"character": {"text": "methods", "start": 87, "end": 94, "i_start": 17, "i_end": 17}, "action": {"text": "influential", "start": 52, "end": 63, "i_start": 13, "i_end": 13}}], "id": 2222}, {"sent": "not surprisingly , quantization is the main feature of the quantum system .", "tokens": ["not", "surprisingly", ",", "quantization", "is", "the", "main", "feature", "of", "the", "quantum", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantization", "start": 19, "end": 31, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "feature", "start": 44, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "not surprisingly", "start": 0, "end": 16, "i_start": 0, "i_end": 1}}], "id": 2223}, {"sent": "in appendices we give the general result for lensing of any primordial bispectrum , and show how any full-sky squeezed bispectrum can be decomposed into orthogonal modes of distinct angular dependence .", "tokens": ["in", "appendices", "we", "give", "the", "general", "result", "for", "lensing", "of", "any", "primordial", "bispectrum", ",", "and", "show", "how", "any", "full", "-", "sky", "squeezed", "bispectrum", "can", "be", "decomposed", "into", "orthogonal", "modes", "of", "distinct", "angular", "dependence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "give", "start": 17, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "show", "start": 88, "end": 92, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "give", "start": 17, "end": 21, "i_start": 3, "i_end": 3}}], "id": 2224}, {"sent": "the proof of the following theorem is left as an exercise for the reader .", "tokens": ["the", "proof", "of", "the", "following", "theorem", "is", "left", "as", "an", "exercise", "for", "the", "reader", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the proof of the following theorem", "start": 0, "end": 34, "i_start": 0, "i_end": 5}, "verb": {"text": "is left", "start": 35, "end": 42, "i_start": 6, "i_end": 7}}], "id": 2225}, {"sent": "deep neural networks have defined the state-of-the-art in a wide range of problems in computer vision , speech analysis , and natural language processing .", "tokens": ["deep", "neural", "networks", "have", "defined", "the", "state", "-", "of", "-", "the", "-", "art", "in", "a", "wide", "range", "of", "problems", "in", "computer", "vision", ",", "speech", "analysis", ",", "and", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have defined", "start": 21, "end": 33, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "defined", "start": 26, "end": 33, "i_start": 4, "i_end": 4}}], "id": 2226}, {"sent": "recently , generative adversarial networks have led to large improvements in image generation tasks .", "tokens": ["recently", ",", "generative", "adversarial", "networks", "have", "led", "to", "large", "improvements", "in", "image", "generation", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 11, "end": 42, "i_start": 2, "i_end": 4}, "verb": {"text": "have led", "start": 43, "end": 51, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 34, "end": 42, "i_start": 4, "i_end": 4}, "action": {"text": "led", "start": 48, "end": 51, "i_start": 6, "i_end": 6}}], "id": 2227}, {"sent": "the simplest possibility is that of what has been termed a perfect solid , meaning one at which the elastic structure at each material position is isotropic with respect to the relaxed metric , which in that case can vary only by a conformal factor .", "tokens": ["the", "simplest", "possibility", "is", "that", "of", "what", "has", "been", "termed", "a", "perfect", "solid", ",", "meaning", "one", "at", "which", "the", "elastic", "structure", "at", "each", "material", "position", "is", "isotropic", "with", "respect", "to", "the", "relaxed", "metric", ",", "which", "in", "that", "case", "can", "vary", "only", "by", "a", "conformal", "factor", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the simplest possibility", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 3, "i_end": 3}}], "id": 2228}, {"sent": "specifically , itti et al considered low-level features at multiple scales and combined them to form the saliency map of an image .", "tokens": ["specifically", ",", "itti", "et", "al", "considered", "low", "-", "level", "features", "at", "multiple", "scales", "and", "combined", "them", "to", "form", "the", "saliency", "map", "of", "an", "image", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "itti et al", "start": 15, "end": 25, "i_start": 2, "i_end": 4}, "verb": {"text": "considered", "start": 26, "end": 36, "i_start": 5, "i_end": 5}}, {"subject": {"text": "itti et al", "start": 15, "end": 25, "i_start": 2, "i_end": 4}, "verb": {"text": "combined", "start": 79, "end": 87, "i_start": 14, "i_end": 14}}, {"character": {"text": "itti", "start": 15, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "considered", "start": 26, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "itti", "start": 15, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "combined", "start": 79, "end": 87, "i_start": 14, "i_end": 14}}, {"character": {"text": "itti", "start": 15, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "form", "start": 96, "end": 100, "i_start": 17, "i_end": 17}}], "id": 2229}, {"sent": "resnet is a deep convolutional network with residual connections to avoid vanishing gradients .", "tokens": ["resnet", "is", "a", "deep", "convolutional", "network", "with", "residual", "connections", "to", "avoid", "vanishing", "gradients", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "resnet", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 7, "end": 9, "i_start": 1, "i_end": 1}}], "id": 2230}, {"sent": "multipole expansion of the dipole radiation .", "tokens": ["multipole", "expansion", "of", "the", "dipole", "radiation", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2231}, {"sent": "sanderson and croft describe an interesting approach to automatically derive a hierarchy by considering the document a certain term appears in as context .", "tokens": ["sanderson", "and", "croft", "describe", "an", "interesting", "approach", "to", "automatically", "derive", "a", "hierarchy", "by", "considering", "the", "document", "a", "certain", "term", "appears", "in", "as", "context", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "sanderson and croft", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "describe", "start": 20, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "sanderson", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "describe", "start": 20, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "croft", "start": 14, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "describe", "start": 20, "end": 28, "i_start": 3, "i_end": 3}}], "id": 2232}, {"sent": "color x 0 x 1 , x 1 x 2 , x 2 x 3 , x 4 x 0 with 4 , 5 , 1 , 1 , respectively , and color x 3 x 4 from with respect to 1 and u \u03c6 .", "tokens": ["color", "x", "0", "x", "1", ",", "x", "1", "x", "2", ",", "x", "2", "x", "3", ",", "x", "4", "x", "0", "with", "4", ",", "5", ",", "1", ",", "1", ",", "respectively", ",", "and", "color", "x", "3", "x", "4", "from", "with", "respect", "to", "1", "and", "u", "\u03c6", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2233}, {"sent": "we evaluate our proposed methods on the voc pascal 2007 dataset , with the fast r-cnn framework by girshick .", "tokens": ["we", "evaluate", "our", "proposed", "methods", "on", "the", "voc", "pascal", "2007", "dataset", ",", "with", "the", "fast", "r", "-", "cnn", "framework", "by", "girshick", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2234}, {"sent": "the exterior differential forms elucidate an internal connection between algebra and geometry .", "tokens": ["the", "exterior", "differential", "forms", "elucidate", "an", "internal", "connection", "between", "algebra", "and", "geometry", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the exterior differential forms", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "elucidate", "start": 32, "end": 41, "i_start": 4, "i_end": 4}}, {"character": {"text": "forms", "start": 26, "end": 31, "i_start": 3, "i_end": 3}, "action": {"text": "elucidate", "start": 32, "end": 41, "i_start": 4, "i_end": 4}}], "id": 2235}, {"sent": "the dotted-dashed lines correspond to the correlation function between halos and neighbour particles in the direction perpendicular to the halo shape major axis .", "tokens": ["the", "dotted", "-", "dashed", "lines", "correspond", "to", "the", "correlation", "function", "between", "halos", "and", "neighbour", "particles", "in", "the", "direction", "perpendicular", "to", "the", "halo", "shape", "major", "axis", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dotted-dashed lines", "start": 0, "end": 23, "i_start": 0, "i_end": 4}, "verb": {"text": "correspond", "start": 24, "end": 34, "i_start": 5, "i_end": 5}}, {"character": {"text": "halos", "start": 71, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "function", "start": 54, "end": 62, "i_start": 9, "i_end": 9}}], "id": 2236}, {"sent": "similar ideas have been explored in few-shot learning with neural networks as well .", "tokens": ["similar", "ideas", "have", "been", "explored", "in", "few", "-", "shot", "learning", "with", "neural", "networks", "as", "well", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "similar ideas", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "have been explored", "start": 14, "end": 32, "i_start": 2, "i_end": 4}}], "id": 2237}, {"sent": "a bloom filter is a compact data structure for probabilistic set membership testing .", "tokens": ["a", "bloom", "filter", "is", "a", "compact", "data", "structure", "for", "probabilistic", "set", "membership", "testing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a bloom filter", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}], "id": 2238}, {"sent": "to build the cin , we used the recent pchi-c dataset of mescs from schoenfelder et al , including interactions amongst promoters and between promoters and other genomic elements .", "tokens": ["to", "build", "the", "cin", ",", "we", "used", "the", "recent", "pchi", "-", "c", "dataset", "of", "mescs", "from", "schoenfelder", "et", "al", ",", "including", "interactions", "amongst", "promoters", "and", "between", "promoters", "and", "other", "genomic", "elements", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 5, "i_end": 5}, "verb": {"text": "used", "start": 22, "end": 26, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 5, "i_end": 5}, "action": {"text": "used", "start": 22, "end": 26, "i_start": 6, "i_end": 6}}, {"character": {"text": "promoters", "start": 119, "end": 128, "i_start": 23, "i_end": 23}, "action": {"text": "interactions", "start": 98, "end": 110, "i_start": 21, "i_end": 21}}, {"character": {"text": "promoters", "start": 141, "end": 150, "i_start": 26, "i_end": 26}, "action": {"text": "interactions", "start": 98, "end": 110, "i_start": 21, "i_end": 21}}, {"character": {"text": "elements", "start": 169, "end": 177, "i_start": 30, "i_end": 30}, "action": {"text": "interactions", "start": 98, "end": 110, "i_start": 21, "i_end": 21}}], "id": 2239}, {"sent": "reconstruction of sugra parameters assuming universal masses .", "tokens": ["reconstruction", "of", "sugra", "parameters", "assuming", "universal", "masses", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "reconstruction", "start": 0, "end": 14, "i_start": 0, "i_end": 0}, "action": {"text": "assuming", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 2240}, {"sent": "the category of q-rational hodge-tate structures .", "tokens": ["the", "category", "of", "q", "-", "rational", "hodge", "-", "tate", "structures", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2241}, {"sent": "in parallel , deep convolutional neural networks have proven their effectiveness in many computer vision fields such as object classification .", "tokens": ["in", "parallel", ",", "deep", "convolutional", "neural", "networks", "have", "proven", "their", "effectiveness", "in", "many", "computer", "vision", "fields", "such", "as", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 14, "end": 48, "i_start": 3, "i_end": 6}, "verb": {"text": "have proven", "start": 49, "end": 60, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 40, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "proven", "start": 54, "end": 60, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 40, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "effectiveness", "start": 67, "end": 80, "i_start": 10, "i_end": 10}}], "id": 2242}, {"sent": "this strategy is compared with a baseline snn of in section iii-b , and is shown to outperform it , especially in the regime of small networks , and particularly so with the n-gram voting scheme .", "tokens": ["this", "strategy", "is", "compared", "with", "a", "baseline", "snn", "of", "in", "section", "iii", "-", "b", ",", "and", "is", "shown", "to", "outperform", "it", ",", "especially", "in", "the", "regime", "of", "small", "networks", ",", "and", "particularly", "so", "with", "the", "n", "-", "gram", "voting", "scheme", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this strategy", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is compared", "start": 14, "end": 25, "i_start": 2, "i_end": 3}}, {"subject": {"text": "this strategy", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "shown", "start": 75, "end": 80, "i_start": 17, "i_end": 17}}, {"character": {"text": "strategy", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "outperform", "start": 84, "end": 94, "i_start": 19, "i_end": 19}}], "id": 2243}, {"sent": "convolutional neural networks are a powerful and versatile tool in big data analysis and computer vision .", "tokens": ["convolutional", "neural", "networks", "are", "a", "powerful", "and", "versatile", "tool", "in", "big", "data", "analysis", "and", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 3, "i_end": 3}}], "id": 2244}, {"sent": "the recent resurgence of efficient deep learning architectures has facilitated significant advances in several fundamental problems in computer vision , including human action recognition .", "tokens": ["the", "recent", "resurgence", "of", "efficient", "deep", "learning", "architectures", "has", "facilitated", "significant", "advances", "in", "several", "fundamental", "problems", "in", "computer", "vision", ",", "including", "human", "action", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the recent resurgence of efficient deep learning architectures", "start": 0, "end": 62, "i_start": 0, "i_end": 7}, "verb": {"text": "has facilitated", "start": 63, "end": 78, "i_start": 8, "i_end": 9}}, {"character": {"text": "resurgence", "start": 11, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "facilitated", "start": 67, "end": 78, "i_start": 9, "i_end": 9}}], "id": 2245}, {"sent": "its maximal ideal m is the set of germs vanishing at the origin , and its residue field is c .", "tokens": ["its", "maximal", "ideal", "m", "is", "the", "set", "of", "germs", "vanishing", "at", "the", "origin", ",", "and", "its", "residue", "field", "is", "c", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "its maximal ideal m", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 4, "i_end": 4}}], "id": 2246}, {"sent": "this logic will extend the classical propositional logic .", "tokens": ["this", "logic", "will", "extend", "the", "classical", "propositional", "logic", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this logic", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "will extend", "start": 11, "end": 22, "i_start": 2, "i_end": 3}}, {"character": {"text": "logic", "start": 5, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "extend", "start": 16, "end": 22, "i_start": 3, "i_end": 3}}], "id": 2247}, {"sent": "frome et al leveraged textual data to learn semantic relationships between labels by explicitly mapping images into a common visual-semantic embedding space .", "tokens": ["frome", "et", "al", "leveraged", "textual", "data", "to", "learn", "semantic", "relationships", "between", "labels", "by", "explicitly", "mapping", "images", "into", "a", "common", "visual", "-", "semantic", "embedding", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "frome", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "leveraged", "start": 12, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "frome", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "learn", "start": 38, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "labels", "start": 75, "end": 81, "i_start": 11, "i_end": 11}, "action": {"text": "relationships", "start": 53, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "frome", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "mapping", "start": 96, "end": 103, "i_start": 14, "i_end": 14}}, {"character": {"text": "space", "start": 151, "end": 156, "i_start": 23, "i_end": 23}, "action": {"text": "embedding", "start": 141, "end": 150, "i_start": 22, "i_end": 22}}], "id": 2248}, {"sent": "both curves are arbitrarily normalised to unity at their peaks .", "tokens": ["both", "curves", "are", "arbitrarily", "normalised", "to", "unity", "at", "their", "peaks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "both curves", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 12, "end": 15, "i_start": 2, "i_end": 2}}], "id": 2249}, {"sent": "deep convolutional neural networks have improved performance of many tasks in computer vision , such as image recognition .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "improved", "performance", "of", "many", "tasks", "in", "computer", "vision", ",", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have improved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 49, "end": 60, "i_start": 6, "i_end": 6}}], "id": 2250}, {"sent": "we trained our model by using the back-propagation algorithm with the adam optimizer .", "tokens": ["we", "trained", "our", "model", "by", "using", "the", "back", "-", "propagation", "algorithm", "with", "the", "adam", "optimizer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "trained", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "trained", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 24, "end": 29, "i_start": 5, "i_end": 5}}], "id": 2251}, {"sent": "an automaton a is a quintuple if q is finite .", "tokens": ["an", "automaton", "a", "is", "a", "quintuple", "if", "q", "is", "finite", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an automaton a", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}], "id": 2252}, {"sent": "the segment polarity network is a robust developmental module .", "tokens": ["the", "segment", "polarity", "network", "is", "a", "robust", "developmental", "module", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the segment polarity network", "start": 0, "end": 28, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 4, "i_end": 4}}], "id": 2253}, {"sent": "the monoid so obtained is called the plactic monoid .", "tokens": ["the", "monoid", "so", "obtained", "is", "called", "the", "plactic", "monoid", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the monoid so obtained", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "is called", "start": 23, "end": 32, "i_start": 4, "i_end": 5}}], "id": 2254}, {"sent": "recently many analytical methods have appeared to obtain the approximate solutions of nonlinear systems , such as the parameter-expansion method , and others .", "tokens": ["recently", "many", "analytical", "methods", "have", "appeared", "to", "obtain", "the", "approximate", "solutions", "of", "nonlinear", "systems", ",", "such", "as", "the", "parameter", "-", "expansion", "method", ",", "and", "others", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "many analytical methods", "start": 9, "end": 32, "i_start": 1, "i_end": 3}, "verb": {"text": "have appeared", "start": 33, "end": 46, "i_start": 4, "i_end": 5}}, {"character": {"text": "methods", "start": 25, "end": 32, "i_start": 3, "i_end": 3}, "action": {"text": "obtain", "start": 50, "end": 56, "i_start": 7, "i_end": 7}}], "id": 2255}, {"sent": "convolutional neural networks have recently achieved great success on various visual recognition tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "achieved", "great", "success", "on", "various", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 7, "i_end": 7}}], "id": 2256}, {"sent": "in index coding , the optimal linear code length is shown to equal to the minrank , which is the minimum rank of a mixed matrix associated with the side-information graph .", "tokens": ["in", "index", "coding", ",", "the", "optimal", "linear", "code", "length", "is", "shown", "to", "equal", "to", "the", "minrank", ",", "which", "is", "the", "minimum", "rank", "of", "a", "mixed", "matrix", "associated", "with", "the", "side", "-", "information", "graph", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the optimal linear code length", "start": 18, "end": 48, "i_start": 4, "i_end": 8}, "verb": {"text": "is shown", "start": 49, "end": 57, "i_start": 9, "i_end": 10}}], "id": 2257}, {"sent": "when not taking into account the effect of the opposite neutrino directions given by eq .", "tokens": ["when", "not", "taking", "into", "account", "the", "effect", "of", "the", "opposite", "neutrino", "directions", "given", "by", "eq", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2258}, {"sent": "our perturbation theory is the expansion log z but with the characteristic function omitted .", "tokens": ["our", "perturbation", "theory", "is", "the", "expansion", "log", "z", "but", "with", "the", "characteristic", "function", "omitted", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our perturbation theory", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}], "id": 2259}, {"sent": "bayesian networks or graphical models based on directed acyclic graphs are widely used to model complex causal systems arising from a variety of research areas , including computational biology , epidemiology , sociology , and environmental management .", "tokens": ["bayesian", "networks", "or", "graphical", "models", "based", "on", "directed", "acyclic", "graphs", "are", "widely", "used", "to", "model", "complex", "causal", "systems", "arising", "from", "a", "variety", "of", "research", "areas", ",", "including", "computational", "biology", ",", "epidemiology", ",", "sociology", ",", "and", "environmental", "management", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "bayesian networks or graphical models based on directed acyclic graphs", "start": 0, "end": 70, "i_start": 0, "i_end": 9}, "verb": {"text": "used", "start": 82, "end": 86, "i_start": 12, "i_end": 12}}, {"subject": {"text": "bayesian networks or graphical models based on directed acyclic graphs", "start": 0, "end": 70, "i_start": 0, "i_end": 9}, "verb": {"text": "are", "start": 71, "end": 74, "i_start": 10, "i_end": 10}}], "id": 2260}, {"sent": "other than the source of the random lines , this scheme goes back at least to , now suppose p i is in region v of the family .", "tokens": ["other", "than", "the", "source", "of", "the", "random", "lines", ",", "this", "scheme", "goes", "back", "at", "least", "to", ",", "now", "suppose", "p", "i", "is", "in", "region", "v", "of", "the", "family", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this scheme", "start": 44, "end": 55, "i_start": 9, "i_end": 10}, "verb": {"text": "goes", "start": 56, "end": 60, "i_start": 11, "i_end": 11}}], "id": 2261}, {"sent": "this set of generators consist of isometries in \u03b3v , for which theorems 1 2 and 1 6 were verified earlier .", "tokens": ["this", "set", "of", "generators", "consist", "of", "isometries", "in", "\u03b3v", ",", "for", "which", "theorems", "1", "2", "and", "1", "6", "were", "verified", "earlier", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this set of generators", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "consist", "start": 23, "end": 30, "i_start": 4, "i_end": 4}}, {"subject": {"text": "for which theorems 1 2 and 1 6", "start": 53, "end": 83, "i_start": 10, "i_end": 17}, "verb": {"text": "verified", "start": 89, "end": 97, "i_start": 19, "i_end": 19}}], "id": 2262}, {"sent": "indeed , if for the proof of instability it is enough to show instability with respect to at least one perturbation .", "tokens": ["indeed", ",", "if", "for", "the", "proof", "of", "instability", "it", "is", "enough", "to", "show", "instability", "with", "respect", "to", "at", "least", "one", "perturbation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 41, "end": 43, "i_start": 8, "i_end": 8}, "verb": {"text": "is", "start": 44, "end": 46, "i_start": 9, "i_end": 9}}], "id": 2263}, {"sent": "the structured density functional description for the flory gel model .", "tokens": ["the", "structured", "density", "functional", "description", "for", "the", "flory", "gel", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2264}, {"sent": "we employ the gated recurrent units to implement the rnn model in this work .", "tokens": ["we", "employ", "the", "gated", "recurrent", "units", "to", "implement", "the", "rnn", "model", "in", "this", "work", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "units", "start": 30, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "implement", "start": 39, "end": 48, "i_start": 7, "i_end": 7}}], "id": 2265}, {"sent": "we discuss explicit construction of weierstrass models in the following section .", "tokens": ["we", "discuss", "explicit", "construction", "of", "weierstrass", "models", "in", "the", "following", "section", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "discuss", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "discuss", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 2266}, {"sent": "the string tension is a constant and gives the energy scale of the slope .", "tokens": ["the", "string", "tension", "is", "a", "constant", "and", "gives", "the", "energy", "scale", "of", "the", "slope", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the string tension", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the string tension", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "gives", "start": 37, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "constant", "start": 24, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "gives", "start": 37, "end": 42, "i_start": 7, "i_end": 7}}], "id": 2267}, {"sent": "to extract local visual features , we simply use the pretrained resnet50 model .", "tokens": ["to", "extract", "local", "visual", "features", ",", "we", "simply", "use", "the", "pretrained", "resnet50", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 35, "end": 37, "i_start": 6, "i_end": 6}, "verb": {"text": "use", "start": 45, "end": 48, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 35, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "use", "start": 45, "end": 48, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 35, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "extract", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 2268}, {"sent": "qian et al have theoretically shown the robustness of sampling to noise .", "tokens": ["qian", "et", "al", "have", "theoretically", "shown", "the", "robustness", "of", "sampling", "to", "noise", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "qian et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "shown", "start": 30, "end": 35, "i_start": 5, "i_end": 5}}, {"subject": {"text": "qian et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "qian", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "shown", "start": 30, "end": 35, "i_start": 5, "i_end": 5}}], "id": 2269}, {"sent": "multi-task learning aims at improving the generalization performance by jointly training multiple related tasks and utilizing their intrinsic relationships .", "tokens": ["multi", "-", "task", "learning", "aims", "at", "improving", "the", "generalization", "performance", "by", "jointly", "training", "multiple", "related", "tasks", "and", "utilizing", "their", "intrinsic", "relationships", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "multi-task learning", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "aims", "start": 20, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 11, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "aims", "start": 20, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 11, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "improving", "start": 28, "end": 37, "i_start": 6, "i_end": 6}}], "id": 2270}, {"sent": "convolutional neural networks have been used in recent years to achieve state-of-the-art performance on object detection .", "tokens": ["convolutional", "neural", "networks", "have", "been", "used", "in", "recent", "years", "to", "achieve", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "object", "detection", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been used", "start": 30, "end": 44, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 64, "end": 71, "i_start": 10, "i_end": 10}}], "id": 2271}, {"sent": "based on seven years of measurements , the icecube collaboration has observed plenty of neutrino events with energies above 30 tev , including four pev scale neutrinos .", "tokens": ["based", "on", "seven", "years", "of", "measurements", ",", "the", "icecube", "collaboration", "has", "observed", "plenty", "of", "neutrino", "events", "with", "energies", "above", "30", "tev", ",", "including", "four", "pev", "scale", "neutrinos", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the icecube collaboration", "start": 39, "end": 64, "i_start": 7, "i_end": 9}, "verb": {"text": "has observed", "start": 65, "end": 77, "i_start": 10, "i_end": 11}}, {"character": {"text": "collaboration", "start": 51, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "observed", "start": 69, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "events", "start": 97, "end": 103, "i_start": 15, "i_end": 15}, "action": {"text": "has", "start": 65, "end": 68, "i_start": 10, "i_end": 10}}], "id": 2272}, {"sent": "the network is trained end-to-end using the adam optimiser with a decaying learning rate schedule .", "tokens": ["the", "network", "is", "trained", "end", "-", "to", "-", "end", "using", "the", "adam", "optimiser", "with", "a", "decaying", "learning", "rate", "schedule", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the network", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is trained", "start": 12, "end": 22, "i_start": 2, "i_end": 3}}], "id": 2273}, {"sent": "the dice index was used to compare the similarity of the segmentations .", "tokens": ["the", "dice", "index", "was", "used", "to", "compare", "the", "similarity", "of", "the", "segmentations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dice index", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "was used", "start": 15, "end": 23, "i_start": 3, "i_end": 4}}], "id": 2274}, {"sent": "examples are marching and noise making at street demonstrations before physical confrontation with the incumbent power .", "tokens": ["examples", "are", "marching", "and", "noise", "making", "at", "street", "demonstrations", "before", "physical", "confrontation", "with", "the", "incumbent", "power", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "examples", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "are marching", "start": 9, "end": 21, "i_start": 1, "i_end": 2}}, {"subject": {"text": "examples", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "making", "start": 32, "end": 38, "i_start": 5, "i_end": 5}}], "id": 2275}, {"sent": "the global vector cross products on manifolds were first studied by gray .", "tokens": ["the", "global", "vector", "cross", "products", "on", "manifolds", "were", "first", "studied", "by", "gray", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the global vector cross products on manifolds", "start": 0, "end": 45, "i_start": 0, "i_end": 6}, "verb": {"text": "studied", "start": 57, "end": 64, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the global vector cross products on manifolds", "start": 0, "end": 45, "i_start": 0, "i_end": 6}, "verb": {"text": "were", "start": 46, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "gray", "start": 68, "end": 72, "i_start": 11, "i_end": 11}, "action": {"text": "studied", "start": 57, "end": 64, "i_start": 9, "i_end": 9}}], "id": 2276}, {"sent": "dropout can be interpreted as a way of regularizing a neural network by adding noise to its hidden units .", "tokens": ["dropout", "can", "be", "interpreted", "as", "a", "way", "of", "regularizing", "a", "neural", "network", "by", "adding", "noise", "to", "its", "hidden", "units", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dropout", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "can be interpreted", "start": 8, "end": 26, "i_start": 1, "i_end": 3}}], "id": 2277}, {"sent": "the theory of similarity in social psychology suggests that individuals prefer to cooperate with others sharing similar morphological and behavioral features , and that they tend to unconsciously coordinate their movements .", "tokens": ["the", "theory", "of", "similarity", "in", "social", "psychology", "suggests", "that", "individuals", "prefer", "to", "cooperate", "with", "others", "sharing", "similar", "morphological", "and", "behavioral", "features", ",", "and", "that", "they", "tend", "to", "unconsciously", "coordinate", "their", "movements", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the theory of similarity in social psychology", "start": 0, "end": 45, "i_start": 0, "i_end": 6}, "verb": {"text": "suggests", "start": 46, "end": 54, "i_start": 7, "i_end": 7}}, {"subject": {"text": "individuals", "start": 60, "end": 71, "i_start": 9, "i_end": 9}, "verb": {"text": "prefer", "start": 72, "end": 78, "i_start": 10, "i_end": 10}}, {"character": {"text": "theory", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "suggests", "start": 46, "end": 54, "i_start": 7, "i_end": 7}}, {"character": {"text": "individuals", "start": 60, "end": 71, "i_start": 9, "i_end": 9}, "action": {"text": "prefer", "start": 72, "end": 78, "i_start": 10, "i_end": 10}}, {"character": {"text": "individuals", "start": 60, "end": 71, "i_start": 9, "i_end": 9}, "action": {"text": "cooperate", "start": 82, "end": 91, "i_start": 12, "i_end": 12}}, {"character": {"text": "others", "start": 97, "end": 103, "i_start": 14, "i_end": 14}, "action": {"text": "sharing", "start": 104, "end": 111, "i_start": 15, "i_end": 15}}, {"character": {"text": "individuals", "start": 60, "end": 71, "i_start": 9, "i_end": 9}, "action": {"text": "coordinate", "start": 196, "end": 206, "i_start": 28, "i_end": 28}}, {"character": {"text": "individuals", "start": 60, "end": 71, "i_start": 9, "i_end": 9}, "action": {"text": "movements", "start": 213, "end": 222, "i_start": 30, "i_end": 30}}], "id": 2278}, {"sent": "in the absence of external slow and fast forcing the system represents a delayed genetic toggle switch , a synthetic gene regulatory network .", "tokens": ["in", "the", "absence", "of", "external", "slow", "and", "fast", "forcing", "the", "system", "represents", "a", "delayed", "genetic", "toggle", "switch", ",", "a", "synthetic", "gene", "regulatory", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "external", "start": 18, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "forcing", "start": 41, "end": 48, "i_start": 8, "i_end": 8}}, {"character": {"text": "system", "start": 53, "end": 59, "i_start": 10, "i_end": 10}, "action": {"text": "represents", "start": 60, "end": 70, "i_start": 11, "i_end": 11}}, {"character": {"text": "network", "start": 133, "end": 140, "i_start": 22, "i_end": 22}, "action": {"text": "regulatory", "start": 122, "end": 132, "i_start": 21, "i_end": 21}}], "id": 2279}, {"sent": "however , current mainstream neural networks have very limited capability of continual learning due to catastrophic forgetting .", "tokens": ["however", ",", "current", "mainstream", "neural", "networks", "have", "very", "limited", "capability", "of", "continual", "learning", "due", "to", "catastrophic", "forgetting", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "current mainstream neural networks", "start": 10, "end": 44, "i_start": 2, "i_end": 5}, "verb": {"text": "have", "start": 45, "end": 49, "i_start": 6, "i_end": 6}}], "id": 2280}, {"sent": "the kitti database consists of 42,382 stereo pairs from different scenes .", "tokens": ["the", "kitti", "database", "consists", "of", "42,382", "stereo", "pairs", "from", "different", "scenes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the kitti database", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}], "id": 2281}, {"sent": "this is the usual induced functor between categories of internal categories .", "tokens": ["this", "is", "the", "usual", "induced", "functor", "between", "categories", "of", "internal", "categories", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 2282}, {"sent": "such configurations are what we call actor-networks .", "tokens": ["such", "configurations", "are", "what", "we", "call", "actor", "-", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "such configurations", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 20, "end": 23, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 29, "end": 31, "i_start": 4, "i_end": 4}, "verb": {"text": "call", "start": 32, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "call", "start": 32, "end": 36, "i_start": 5, "i_end": 5}}], "id": 2283}, {"sent": "this actionable information can include rogue ip addresses , malware metadata , and indicators of compromise .", "tokens": ["this", "actionable", "information", "can", "include", "rogue", "ip", "addresses", ",", "malware", "metadata", ",", "and", "indicators", "of", "compromise", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this actionable information", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "can include", "start": 28, "end": 39, "i_start": 3, "i_end": 4}}], "id": 2284}, {"sent": "conversely , it was shown in that for every finite collection of polynomials , there exists a network , such that for every finite field f , the polynomials have a common root in f if and only if the network is scalar linearly solvable over f .", "tokens": ["conversely", ",", "it", "was", "shown", "in", "that", "for", "every", "finite", "collection", "of", "polynomials", ",", "there", "exists", "a", "network", ",", "such", "that", "for", "every", "finite", "field", "f", ",", "the", "polynomials", "have", "a", "common", "root", "in", "f", "if", "and", "only", "if", "the", "network", "is", "scalar", "linearly", "solvable", "over", "f", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "there", "start": 79, "end": 84, "i_start": 14, "i_end": 14}, "verb": {"text": "exists", "start": 85, "end": 91, "i_start": 15, "i_end": 15}}, {"subject": {"text": "it", "start": 13, "end": 15, "i_start": 2, "i_end": 2}, "verb": {"text": "shown", "start": 20, "end": 25, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the polynomials", "start": 141, "end": 156, "i_start": 27, "i_end": 28}, "verb": {"text": "have", "start": 157, "end": 161, "i_start": 29, "i_end": 29}}, {"character": {"text": "exists", "start": 85, "end": 91, "i_start": 15, "i_end": 15}, "action": {"text": "if", "start": 181, "end": 183, "i_start": 35, "i_end": 35}}], "id": 2285}, {"sent": "this paper investigates how channel coding can be used to reduce the failure rate .", "tokens": ["this", "paper", "investigates", "how", "channel", "coding", "can", "be", "used", "to", "reduce", "the", "failure", "rate", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this paper", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "investigates", "start": 11, "end": 23, "i_start": 2, "i_end": 2}}, {"subject": {"text": "channel coding", "start": 28, "end": 42, "i_start": 4, "i_end": 5}, "verb": {"text": "used", "start": 50, "end": 54, "i_start": 8, "i_end": 8}}, {"character": {"text": "paper", "start": 5, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "investigates", "start": 11, "end": 23, "i_start": 2, "i_end": 2}}], "id": 2286}, {"sent": "deep convolutional neural networks have experienced a recent surge in computer vision research due to their immense success for visual recognition tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "experienced", "a", "recent", "surge", "in", "computer", "vision", "research", "due", "to", "their", "immense", "success", "for", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have experienced", "start": 35, "end": 51, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "experienced", "start": 40, "end": 51, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 116, "end": 123, "i_start": 17, "i_end": 17}}], "id": 2287}, {"sent": "each convolution layer is followed by a batch normalization layer .", "tokens": ["each", "convolution", "layer", "is", "followed", "by", "a", "batch", "normalization", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each convolution layer", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is followed", "start": 23, "end": 34, "i_start": 3, "i_end": 4}}], "id": 2288}, {"sent": "this type of regularization is analogous to the local shrinkage term developed in .", "tokens": ["this", "type", "of", "regularization", "is", "analogous", "to", "the", "local", "shrinkage", "term", "developed", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this type of regularization", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 4, "i_end": 4}}], "id": 2289}, {"sent": "in reinforcement learning an agent tries to learn a task through interaction with the environment in which the task is defined by means of a reward signal .", "tokens": ["in", "reinforcement", "learning", "an", "agent", "tries", "to", "learn", "a", "task", "through", "interaction", "with", "the", "environment", "in", "which", "the", "task", "is", "defined", "by", "means", "of", "a", "reward", "signal", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "an agent", "start": 26, "end": 34, "i_start": 3, "i_end": 4}, "verb": {"text": "tries", "start": 35, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "agent", "start": 29, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "tries", "start": 35, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "agent", "start": 29, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "learning", "start": 17, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "agent", "start": 29, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "interaction", "start": 65, "end": 76, "i_start": 11, "i_end": 11}}, {"character": {"text": "signal", "start": 148, "end": 154, "i_start": 26, "i_end": 26}, "action": {"text": "reward", "start": 141, "end": 147, "i_start": 25, "i_end": 25}}], "id": 2290}, {"sent": "in addition , our design uses layer normalization to improve regularization .", "tokens": ["in", "addition", ",", "our", "design", "uses", "layer", "normalization", "to", "improve", "regularization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our design", "start": 14, "end": 24, "i_start": 3, "i_end": 4}, "verb": {"text": "uses", "start": 25, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "design", "start": 18, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "uses", "start": 25, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "normalization", "start": 36, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "improve", "start": 53, "end": 60, "i_start": 9, "i_end": 9}}], "id": 2291}, {"sent": "traditional 2d single human pose estimation methods often follow the framework of tree structured graphical model .", "tokens": ["traditional", "2d", "single", "human", "pose", "estimation", "methods", "often", "follow", "the", "framework", "of", "tree", "structured", "graphical", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "traditional 2d single human pose estimation methods", "start": 0, "end": 51, "i_start": 0, "i_end": 6}, "verb": {"text": "follow", "start": 58, "end": 64, "i_start": 8, "i_end": 8}}, {"character": {"text": "methods", "start": 44, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "follow", "start": 58, "end": 64, "i_start": 8, "i_end": 8}}], "id": 2292}, {"sent": "in , an iterative precoders and decorrelators design based on alternating optimization is proposed for quasi-static mimo interference channels .", "tokens": ["in", ",", "an", "iterative", "precoders", "and", "decorrelators", "design", "based", "on", "alternating", "optimization", "is", "proposed", "for", "quasi", "-", "static", "mimo", "interference", "channels", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "in", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is proposed", "start": 87, "end": 98, "i_start": 12, "i_end": 13}}, {"character": {"text": "channels", "start": 134, "end": 142, "i_start": 20, "i_end": 20}, "action": {"text": "interference", "start": 121, "end": 133, "i_start": 19, "i_end": 19}}], "id": 2293}, {"sent": "recently convolutional neural networks have performed very well on image classification tasks and are pervasive in machine learning and computer vision .", "tokens": ["recently", "convolutional", "neural", "networks", "have", "performed", "very", "well", "on", "image", "classification", "tasks", "and", "are", "pervasive", "in", "machine", "learning", "and", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 9, "end": 38, "i_start": 1, "i_end": 3}, "verb": {"text": "have performed", "start": 39, "end": 53, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "performed", "start": 44, "end": 53, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "pervasive", "start": 102, "end": 111, "i_start": 14, "i_end": 14}}], "id": 2294}, {"sent": "in this paper we show that the phenomenon of reflectionless tunneling exists also in ballistic systems , the requirement being the existence of multiple reflections from the ns interface due to the geometry of the structure .", "tokens": ["in", "this", "paper", "we", "show", "that", "the", "phenomenon", "of", "reflectionless", "tunneling", "exists", "also", "in", "ballistic", "systems", ",", "the", "requirement", "being", "the", "existence", "of", "multiple", "reflections", "from", "the", "ns", "interface", "due", "to", "the", "geometry", "of", "the", "structure", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "show", "start": 17, "end": 21, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the phenomenon of reflectionless tunneling", "start": 27, "end": 69, "i_start": 6, "i_end": 10}, "verb": {"text": "exists", "start": 70, "end": 76, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "show", "start": 17, "end": 21, "i_start": 4, "i_end": 4}}, {"character": {"text": "existence", "start": 131, "end": 140, "i_start": 21, "i_end": 21}, "action": {"text": "requirement", "start": 109, "end": 120, "i_start": 18, "i_end": 18}}], "id": 2295}, {"sent": "following the success of deep neural networks in several computer vision tasks , neural networks have also received considerable attention in the context of image processing .", "tokens": ["following", "the", "success", "of", "deep", "neural", "networks", "in", "several", "computer", "vision", "tasks", ",", "neural", "networks", "have", "also", "received", "considerable", "attention", "in", "the", "context", "of", "image", "processing", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "neural networks", "start": 81, "end": 96, "i_start": 13, "i_end": 14}, "verb": {"text": "received", "start": 107, "end": 115, "i_start": 17, "i_end": 17}}, {"subject": {"text": "neural networks", "start": 81, "end": 96, "i_start": 13, "i_end": 14}, "verb": {"text": "have", "start": 97, "end": 101, "i_start": 15, "i_end": 15}}, {"character": {"text": "networks", "start": 88, "end": 96, "i_start": 14, "i_end": 14}, "action": {"text": "success", "start": 14, "end": 21, "i_start": 2, "i_end": 2}}], "id": 2296}, {"sent": "the particle-flow algorithm aims to reconstruct and identify each individual particle in an event with an optimized combination of information from the various elements of the cms detector .", "tokens": ["the", "particle", "-", "flow", "algorithm", "aims", "to", "reconstruct", "and", "identify", "each", "individual", "particle", "in", "an", "event", "with", "an", "optimized", "combination", "of", "information", "from", "the", "various", "elements", "of", "the", "cms", "detector", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the particle-flow algorithm", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "aims", "start": 28, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "algorithm", "start": 18, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "aims", "start": 28, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "algorithm", "start": 18, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "reconstruct", "start": 36, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "algorithm", "start": 18, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "identify", "start": 52, "end": 60, "i_start": 9, "i_end": 9}}], "id": 2297}, {"sent": "the exchange and correlation functional employed was the generalized gradient approximation in the parametrization due to perdew-burke-ernzerhof .", "tokens": ["the", "exchange", "and", "correlation", "functional", "employed", "was", "the", "generalized", "gradient", "approximation", "in", "the", "parametrization", "due", "to", "perdew", "-", "burke", "-", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange and correlation functional employed", "start": 0, "end": 48, "i_start": 0, "i_end": 5}, "verb": {"text": "was", "start": 49, "end": 52, "i_start": 6, "i_end": 6}}], "id": 2298}, {"sent": "we use the adam optimizer in pytorch for both image classification and multi-modal machine translation .", "tokens": ["we", "use", "the", "adam", "optimizer", "in", "pytorch", "for", "both", "image", "classification", "and", "multi", "-", "modal", "machine", "translation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 2299}, {"sent": "the ordinate is the fraction of initial lithium remaining .", "tokens": ["the", "ordinate", "is", "the", "fraction", "of", "initial", "lithium", "remaining", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ordinate", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 2300}, {"sent": "generative adversarial learning is proposed to generate realistic-looking images from random noise using neural networks .", "tokens": ["generative", "adversarial", "learning", "is", "proposed", "to", "generate", "realistic", "-", "looking", "images", "from", "random", "noise", "using", "neural", "networks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial learning", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "is proposed", "start": 32, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "learning", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "generate", "start": 47, "end": 55, "i_start": 6, "i_end": 6}}, {"character": {"text": "images", "start": 74, "end": 80, "i_start": 10, "i_end": 10}, "action": {"text": "looking", "start": 66, "end": 73, "i_start": 9, "i_end": 9}}], "id": 2301}, {"sent": "deep learning has been applied in many different research fields to solve complicated problems , made possible through parallel computing and big datasets .", "tokens": ["deep", "learning", "has", "been", "applied", "in", "many", "different", "research", "fields", "to", "solve", "complicated", "problems", ",", "made", "possible", "through", "parallel", "computing", "and", "big", "datasets", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has been applied", "start": 14, "end": 30, "i_start": 2, "i_end": 4}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "solve", "start": 68, "end": 73, "i_start": 11, "i_end": 11}}], "id": 2302}, {"sent": "an introduction to general relativity and cosmology , cambridge university press .", "tokens": ["an", "introduction", "to", "general", "relativity", "and", "cosmology", ",", "cambridge", "university", "press", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2303}, {"sent": "in the former phase , the optimal orientation of the striped state is orthogonal to the external modulation .", "tokens": ["in", "the", "former", "phase", ",", "the", "optimal", "orientation", "of", "the", "striped", "state", "is", "orthogonal", "to", "the", "external", "modulation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the optimal orientation of the striped state", "start": 22, "end": 66, "i_start": 5, "i_end": 11}, "verb": {"text": "is", "start": 67, "end": 69, "i_start": 12, "i_end": 12}}], "id": 2304}, {"sent": "deep learning based models have achieved great advances in object detection in recent years .", "tokens": ["deep", "learning", "based", "models", "have", "achieved", "great", "advances", "in", "object", "detection", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning based models", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 27, "end": 40, "i_start": 4, "i_end": 5}}, {"character": {"text": "models", "start": 20, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 32, "end": 40, "i_start": 5, "i_end": 5}}], "id": 2305}, {"sent": "the semicolon denotes the covariant derivative .", "tokens": ["the", "semicolon", "denotes", "the", "covariant", "derivative", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the semicolon", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "denotes", "start": 14, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "semicolon", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "denotes", "start": 14, "end": 21, "i_start": 2, "i_end": 2}}], "id": 2306}, {"sent": "this simple training approach has accelerated practical achievements in developing rnns .", "tokens": ["this", "simple", "training", "approach", "has", "accelerated", "practical", "achievements", "in", "developing", "rnns", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this simple training approach", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "has accelerated", "start": 30, "end": 45, "i_start": 4, "i_end": 5}}, {"character": {"text": "approach", "start": 21, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "accelerated", "start": 34, "end": 45, "i_start": 5, "i_end": 5}}], "id": 2307}, {"sent": "in recent years , artificial neural network has been gaining significant interest by claiming several cutting-edge results in solving various nonlinear problems .", "tokens": ["in", "recent", "years", ",", "artificial", "neural", "network", "has", "been", "gaining", "significant", "interest", "by", "claiming", "several", "cutting", "-", "edge", "results", "in", "solving", "various", "nonlinear", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "artificial neural network", "start": 18, "end": 43, "i_start": 4, "i_end": 6}, "verb": {"text": "has been gaining", "start": 44, "end": 60, "i_start": 7, "i_end": 9}}, {"character": {"text": "network", "start": 36, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "gaining", "start": 53, "end": 60, "i_start": 9, "i_end": 9}}, {"character": {"text": "network", "start": 36, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "claiming", "start": 85, "end": 93, "i_start": 13, "i_end": 13}}, {"character": {"text": "network", "start": 36, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "solving", "start": 126, "end": 133, "i_start": 20, "i_end": 20}}], "id": 2308}, {"sent": "this is called gravitational bremsstrahlung .", "tokens": ["this", "is", "called", "gravitational", "bremsstrahlung", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is called", "start": 5, "end": 14, "i_start": 1, "i_end": 2}}], "id": 2309}, {"sent": "recently , deep neural networks have achieved state-of-the-art performance in various tasks such as speech recognition , visual object recognition , and image classification .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "various", "tasks", "such", "as", "speech", "recognition", ",", "visual", "object", "recognition", ",", "and", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have achieved", "start": 32, "end": 45, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "performance", "start": 63, "end": 74, "i_start": 14, "i_end": 14}}], "id": 2310}, {"sent": "by means of the representation of \u03be the notions of relative velocity and relative acceleration are introduced -spaces .", "tokens": ["by", "means", "of", "the", "representation", "of", "\u03be", "the", "notions", "of", "relative", "velocity", "and", "relative", "acceleration", "are", "introduced", "-spaces", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2311}, {"sent": "in event-triggered broadcasting , a subsystem sends its local state to the network only when it is necessary , that is , only when a measure of the local subsystem state error is above a specified threshold .", "tokens": ["in", "event", "-", "triggered", "broadcasting", ",", "a", "subsystem", "sends", "its", "local", "state", "to", "the", "network", "only", "when", "it", "is", "necessary", ",", "that", "is", ",", "only", "when", "a", "measure", "of", "the", "local", "subsystem", "state", "error", "is", "above", "a", "specified", "threshold", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a subsystem", "start": 34, "end": 45, "i_start": 6, "i_end": 7}, "verb": {"text": "sends", "start": 46, "end": 51, "i_start": 8, "i_end": 8}}, {"character": {"text": "subsystem", "start": 36, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "sends", "start": 46, "end": 51, "i_start": 8, "i_end": 8}}], "id": 2312}, {"sent": "clearly , we are not interested in the ordering of the vectors in the n-tuple .", "tokens": ["clearly", ",", "we", "are", "not", "interested", "in", "the", "ordering", "of", "the", "vectors", "in", "the", "n", "-", "tuple", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "are not", "start": 13, "end": 20, "i_start": 3, "i_end": 4}}], "id": 2313}, {"sent": "in this section , we recall the notions of cluster automorphisms , and we also introduce the notion of weak automorphisms .", "tokens": ["in", "this", "section", ",", "we", "recall", "the", "notions", "of", "cluster", "automorphisms", ",", "and", "we", "also", "introduce", "the", "notion", "of", "weak", "automorphisms", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "recall", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 71, "end": 73, "i_start": 13, "i_end": 13}, "verb": {"text": "introduce", "start": 79, "end": 88, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "recall", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "introduce", "start": 79, "end": 88, "i_start": 15, "i_end": 15}}], "id": 2314}, {"sent": "however the cfo estimator presented in requires multi-dimensional grid search and hence has high complexity with increasing number of uts .", "tokens": ["however", "the", "cfo", "estimator", "presented", "in", "requires", "multi", "-", "dimensional", "grid", "search", "and", "hence", "has", "high", "complexity", "with", "increasing", "number", "of", "uts", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the cfo estimator presented in", "start": 8, "end": 38, "i_start": 1, "i_end": 5}, "verb": {"text": "requires", "start": 39, "end": 47, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the cfo estimator presented in", "start": 8, "end": 38, "i_start": 1, "i_end": 5}, "verb": {"text": "has", "start": 88, "end": 91, "i_start": 14, "i_end": 14}}], "id": 2315}, {"sent": "interpretation of the directional derivative in terms of intersection products and many interesting applications are given in .", "tokens": ["interpretation", "of", "the", "directional", "derivative", "in", "terms", "of", "intersection", "products", "and", "many", "interesting", "applications", "are", "given", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "interpretation of the directional derivative in terms of intersection products and many interesting applications", "start": 0, "end": 112, "i_start": 0, "i_end": 13}, "verb": {"text": "are given in", "start": 113, "end": 125, "i_start": 14, "i_end": 16}}], "id": 2316}, {"sent": "in this case , the tvbw construction corresponds to the twisted dijkgraaf-witten theory of .", "tokens": ["in", "this", "case", ",", "the", "tvbw", "construction", "corresponds", "to", "the", "twisted", "dijkgraaf", "-", "witten", "theory", "of", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the tvbw construction", "start": 15, "end": 36, "i_start": 4, "i_end": 6}, "verb": {"text": "corresponds", "start": 37, "end": 48, "i_start": 7, "i_end": 7}}], "id": 2317}, {"sent": "deep neural networks have shown tremendous success in several computer vision tasks in recent years .", "tokens": ["deep", "neural", "networks", "have", "shown", "tremendous", "success", "in", "several", "computer", "vision", "tasks", "in", "recent", "years", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}], "id": 2318}, {"sent": "automatic repeat request and hybrid arq methods have been used in 5g mobile networks .", "tokens": ["automatic", "repeat", "request", "and", "hybrid", "arq", "methods", "have", "been", "used", "in", "5", "g", "mobile", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "automatic repeat request and hybrid arq methods", "start": 0, "end": 47, "i_start": 0, "i_end": 6}, "verb": {"text": "have been used", "start": 48, "end": 62, "i_start": 7, "i_end": 9}}], "id": 2319}, {"sent": "but gravity is a unique problem in that successful field approximations have been derived prior to comprehending what may be a quantized phenomenon .", "tokens": ["but", "gravity", "is", "a", "unique", "problem", "in", "that", "successful", "field", "approximations", "have", "been", "derived", "prior", "to", "comprehending", "what", "may", "be", "a", "quantized", "phenomenon", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "gravity", "start": 4, "end": 11, "i_start": 1, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}, {"subject": {"text": "gravity", "start": 4, "end": 11, "i_start": 1, "i_end": 1}, "verb": {"text": "derived", "start": 82, "end": 89, "i_start": 13, "i_end": 13}}], "id": 2320}, {"sent": "we will illustrate this by the following examples .", "tokens": ["we", "will", "illustrate", "this", "by", "the", "following", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will illustrate", "start": 3, "end": 18, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "illustrate", "start": 8, "end": 18, "i_start": 2, "i_end": 2}}], "id": 2321}, {"sent": "in particular , the green-schwarz and chern-simon terms must have the same sign .", "tokens": ["in", "particular", ",", "the", "green", "-", "schwarz", "and", "chern", "-", "simon", "terms", "must", "have", "the", "same", "sign", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the green-schwarz and chern-simon terms", "start": 16, "end": 55, "i_start": 3, "i_end": 11}, "verb": {"text": "must have", "start": 56, "end": 65, "i_start": 12, "i_end": 13}}], "id": 2322}, {"sent": "this theory is often called the type iib matrix model and has been proposed as a nonperturbative formulation of type iib string theory .", "tokens": ["this", "theory", "is", "often", "called", "the", "type", "iib", "matrix", "model", "and", "has", "been", "proposed", "as", "a", "nonperturbative", "formulation", "of", "type", "iib", "string", "theory", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this theory", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "called", "start": 21, "end": 27, "i_start": 4, "i_end": 4}}, {"subject": {"text": "this theory", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}, {"subject": {"text": "this theory", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "proposed", "start": 67, "end": 75, "i_start": 13, "i_end": 13}}, {"character": {"text": "theory", "start": 5, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "formulation", "start": 97, "end": 108, "i_start": 17, "i_end": 17}}], "id": 2323}, {"sent": "in recent years , many studies have shown excellent performance in object detection .", "tokens": ["in", "recent", "years", ",", "many", "studies", "have", "shown", "excellent", "performance", "in", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "many studies", "start": 18, "end": 30, "i_start": 4, "i_end": 5}, "verb": {"text": "have shown", "start": 31, "end": 41, "i_start": 6, "i_end": 7}}, {"character": {"text": "studies", "start": 23, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "shown", "start": 36, "end": 41, "i_start": 7, "i_end": 7}}], "id": 2324}, {"sent": "the dashed line is the linear regression for spirals in s-s pairs .", "tokens": ["the", "dashed", "line", "is", "the", "linear", "regression", "for", "spirals", "in", "s", "-", "s", "pairs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dashed line", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 2325}, {"sent": "now we proceed onto define smarandache bistructures .", "tokens": ["now", "we", "proceed", "onto", "define", "smarandache", "bistructures", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 20, "end": 26, "i_start": 4, "i_end": 4}}], "id": 2326}, {"sent": "this lagrangian is used to generate the effective potential , mass matrices and rges of the model .", "tokens": ["this", "lagrangian", "is", "used", "to", "generate", "the", "effective", "potential", ",", "mass", "matrices", "and", "rges", "of", "the", "model", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this lagrangian", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is used", "start": 16, "end": 23, "i_start": 2, "i_end": 3}}, {"character": {"text": "lagrangian", "start": 5, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "generate", "start": 27, "end": 35, "i_start": 5, "i_end": 5}}, {"character": {"text": "potential", "start": 50, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "effective", "start": 40, "end": 49, "i_start": 7, "i_end": 7}}], "id": 2327}, {"sent": "to pass sufficient information to the decoding layers , a u-net architecture with skip connections is used .", "tokens": ["to", "pass", "sufficient", "information", "to", "the", "decoding", "layers", ",", "a", "u", "-", "net", "architecture", "with", "skip", "connections", "is", "used", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a u-net architecture with skip connections", "start": 56, "end": 98, "i_start": 9, "i_end": 16}, "verb": {"text": "is used", "start": 99, "end": 106, "i_start": 17, "i_end": 18}}, {"character": {"text": "information", "start": 19, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "sufficient", "start": 8, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "layers", "start": 47, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "decoding", "start": 38, "end": 46, "i_start": 6, "i_end": 6}}], "id": 2328}, {"sent": "later , wyner introduced the notion of secure capacity via a degraded wiretap channel , in which a transmitter intends to send a confidential message to a legitimate receiver by hiding it from a degraded eavesdropper .", "tokens": ["later", ",", "wyner", "introduced", "the", "notion", "of", "secure", "capacity", "via", "a", "degraded", "wiretap", "channel", ",", "in", "which", "a", "transmitter", "intends", "to", "send", "a", "confidential", "message", "to", "a", "legitimate", "receiver", "by", "hiding", "it", "from", "a", "degraded", "eavesdropper", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "wyner", "start": 8, "end": 13, "i_start": 2, "i_end": 2}, "verb": {"text": "introduced", "start": 14, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "wyner", "start": 8, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 14, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2329}, {"sent": "the events are processed through a geant4 simulation of the detector .", "tokens": ["the", "events", "are", "processed", "through", "a", "geant4", "simulation", "of", "the", "detector", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the events", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "are processed", "start": 11, "end": 24, "i_start": 2, "i_end": 3}}], "id": 2330}, {"sent": "to this end we need to show that the unitary matrices abelian group .", "tokens": ["to", "this", "end", "we", "need", "to", "show", "that", "the", "unitary", "matrices", "abelian", "group", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 12, "end": 14, "i_start": 3, "i_end": 3}, "verb": {"text": "need", "start": 15, "end": 19, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 12, "end": 14, "i_start": 3, "i_end": 3}, "action": {"text": "need", "start": 15, "end": 19, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 12, "end": 14, "i_start": 3, "i_end": 3}, "action": {"text": "show", "start": 23, "end": 27, "i_start": 6, "i_end": 6}}], "id": 2331}, {"sent": "this vortex is the m2 brane to which the m4 brane can decay .", "tokens": ["this", "vortex", "is", "the", "m2", "brane", "to", "which", "the", "m4", "brane", "can", "decay", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this vortex", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "brane", "start": 44, "end": 49, "i_start": 10, "i_end": 10}, "action": {"text": "decay", "start": 54, "end": 59, "i_start": 12, "i_end": 12}}], "id": 2332}, {"sent": "the sets qt of lattice qubits are measured one after the other .", "tokens": ["the", "sets", "qt", "of", "lattice", "qubits", "are", "measured", "one", "after", "the", "other", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2333}, {"sent": "each subnetwork is a two layer feedforward network with relu non-linearities and dropout .", "tokens": ["each", "subnetwork", "is", "a", "two", "layer", "feedforward", "network", "with", "relu", "non", "-", "linearities", "and", "dropout", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each subnetwork", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 2334}, {"sent": "in , the asterisk denotes complex conjugation .", "tokens": ["in", ",", "the", "asterisk", "denotes", "complex", "conjugation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the asterisk", "start": 5, "end": 17, "i_start": 2, "i_end": 3}, "verb": {"text": "denotes", "start": 18, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "asterisk", "start": 9, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "denotes", "start": 18, "end": 25, "i_start": 4, "i_end": 4}}], "id": 2335}, {"sent": "in , barton found out that when weakly reflecting dielectric materials are used , the casimir force on the three dimensional piston can become repulsive when the plate separation is sufficiently large .", "tokens": ["in", ",", "barton", "found", "out", "that", "when", "weakly", "reflecting", "dielectric", "materials", "are", "used", ",", "the", "casimir", "force", "on", "the", "three", "dimensional", "piston", "can", "become", "repulsive", "when", "the", "plate", "separation", "is", "sufficiently", "large", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "barton", "start": 5, "end": 11, "i_start": 2, "i_end": 2}, "verb": {"text": "found out", "start": 12, "end": 21, "i_start": 3, "i_end": 4}}, {"subject": {"text": "the casimir force on the three dimensional piston", "start": 82, "end": 131, "i_start": 14, "i_end": 21}, "verb": {"text": "become", "start": 136, "end": 142, "i_start": 23, "i_end": 23}}, {"character": {"text": "barton", "start": 5, "end": 11, "i_start": 2, "i_end": 2}, "action": {"text": "found", "start": 12, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "force", "start": 94, "end": 99, "i_start": 16, "i_end": 16}, "action": {"text": "repulsive", "start": 143, "end": 152, "i_start": 24, "i_end": 24}}], "id": 2336}, {"sent": "dropout is a simple and efficient technique that can be used to reduce overfitting in neural networks .", "tokens": ["dropout", "is", "a", "simple", "and", "efficient", "technique", "that", "can", "be", "used", "to", "reduce", "overfitting", "in", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dropout", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}], "id": 2337}, {"sent": "in general , monotone invariants are closely connected to functorial semi-norms on homology .", "tokens": ["in", "general", ",", "monotone", "invariants", "are", "closely", "connected", "to", "functorial", "semi", "-", "norms", "on", "homology", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "general", "start": 3, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "connected", "start": 45, "end": 54, "i_start": 7, "i_end": 7}}, {"subject": {"text": "general", "start": 3, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "are", "start": 33, "end": 36, "i_start": 5, "i_end": 5}}], "id": 2338}, {"sent": "waiting time and turn around time has been calculated using the formula given below and the results were compared .", "tokens": ["waiting", "time", "and", "turn", "around", "time", "has", "been", "calculated", "using", "the", "formula", "given", "below", "and", "the", "results", "were", "compared", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "waiting time and turn around time", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "has been calculated", "start": 34, "end": 53, "i_start": 6, "i_end": 8}}, {"subject": {"text": "the results", "start": 88, "end": 99, "i_start": 15, "i_end": 16}, "verb": {"text": "compared", "start": 105, "end": 113, "i_start": 18, "i_end": 18}}], "id": 2339}, {"sent": "for l p spaces complete classifications for valuations intertwining the slwere established in .", "tokens": ["for", "l", "p", "spaces", "complete", "classifications", "for", "valuations", "intertwining", "the", "slwere", "established", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "l p spaces", "start": 4, "end": 14, "i_start": 1, "i_end": 3}, "verb": {"text": "complete", "start": 15, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "classifications", "start": 24, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "intertwining", "start": 55, "end": 67, "i_start": 8, "i_end": 8}}], "id": 2340}, {"sent": "in recent years , convolutional neural networks has achieved remarkable results in a wide range of computer vision applications .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "has", "achieved", "remarkable", "results", "in", "a", "wide", "range", "of", "computer", "vision", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "has achieved", "start": 48, "end": 60, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 52, "end": 60, "i_start": 8, "i_end": 8}}], "id": 2341}, {"sent": "we report results on mscoco which is the largest available image-caption ranking dataset .", "tokens": ["we", "report", "results", "on", "mscoco", "which", "is", "the", "largest", "available", "image", "-", "caption", "ranking", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "report", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "report", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 2342}, {"sent": "the choice of a suitable splitting mechanism holds a long standing discussion with many statistical and computational implications .", "tokens": ["the", "choice", "of", "a", "suitable", "splitting", "mechanism", "holds", "a", "long", "standing", "discussion", "with", "many", "statistical", "and", "computational", "implications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the choice of a suitable splitting mechanism", "start": 0, "end": 44, "i_start": 0, "i_end": 6}, "verb": {"text": "holds", "start": 45, "end": 50, "i_start": 7, "i_end": 7}}], "id": 2343}, {"sent": "since then , continuous crf has been applied for solving various structured regression problems , eg , remote sensing .", "tokens": ["since", "then", ",", "continuous", "crf", "has", "been", "applied", "for", "solving", "various", "structured", "regression", "problems", ",", "eg", ",", "remote", "sensing", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "continuous crf has been applied for solving various structured regression problems , eg", "start": 13, "end": 100, "i_start": 3, "i_end": 15}, "verb": {"text": "has been applied", "start": 28, "end": 44, "i_start": 5, "i_end": 7}}], "id": 2344}, {"sent": "we show an analogous result for discrete-time systems in section vi .", "tokens": ["we", "show", "an", "analogous", "result", "for", "discrete", "-", "time", "systems", "in", "section", "vi", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 2345}, {"sent": "recently , deep neural networks have led to significant improvement in several machine learning domains , from speech recognition to computer vision and machine translation .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "led", "to", "significant", "improvement", "in", "several", "machine", "learning", "domains", ",", "from", "speech", "recognition", "to", "computer", "vision", "and", "machine", "translation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have led", "start": 32, "end": 40, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "led", "start": 37, "end": 40, "i_start": 6, "i_end": 6}}], "id": 2346}, {"sent": "the spinning kerr black holes taken as particle accelerators , discussed by , they found that the ultra-energetic collisions can not occur near black holes in nature .", "tokens": ["the", "spinning", "kerr", "black", "holes", "taken", "as", "particle", "accelerators", ",", "discussed", "by", ",", "they", "found", "that", "the", "ultra", "-", "energetic", "collisions", "can", "not", "occur", "near", "black", "holes", "in", "nature", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "they", "start": 78, "end": 82, "i_start": 13, "i_end": 13}, "verb": {"text": "found", "start": 83, "end": 88, "i_start": 14, "i_end": 14}}, {"subject": {"text": "the ultra-energetic collisions", "start": 94, "end": 124, "i_start": 16, "i_end": 20}, "verb": {"text": "occur", "start": 133, "end": 138, "i_start": 23, "i_end": 23}}, {"character": {"text": "they", "start": 78, "end": 82, "i_start": 13, "i_end": 13}, "action": {"text": "found", "start": 83, "end": 88, "i_start": 14, "i_end": 14}}, {"character": {"text": "they", "start": 78, "end": 82, "i_start": 13, "i_end": 13}, "action": {"text": "discussed", "start": 63, "end": 72, "i_start": 10, "i_end": 10}}], "id": 2347}, {"sent": "the overlapping average pooling technique helps in the regularization of the network .", "tokens": ["the", "overlapping", "average", "pooling", "technique", "helps", "in", "the", "regularization", "of", "the", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the overlapping average pooling technique", "start": 0, "end": 41, "i_start": 0, "i_end": 4}, "verb": {"text": "helps", "start": 42, "end": 47, "i_start": 5, "i_end": 5}}, {"character": {"text": "technique", "start": 32, "end": 41, "i_start": 4, "i_end": 4}, "action": {"text": "helps", "start": 42, "end": 47, "i_start": 5, "i_end": 5}}], "id": 2348}, {"sent": "in this subsection we briefly review the scalar invariant approach to the algebraic classification of spacetimes introduced in .", "tokens": ["in", "this", "subsection", "we", "briefly", "review", "the", "scalar", "invariant", "approach", "to", "the", "algebraic", "classification", "of", "spacetimes", "introduced", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 3, "i_end": 3}, "verb": {"text": "review", "start": 30, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "review", "start": 30, "end": 36, "i_start": 5, "i_end": 5}}], "id": 2349}, {"sent": "recently , cho et al propose a novel max pooling matching algorithm , in which they tweak the power method to better cope with noise in the affinities .", "tokens": ["recently", ",", "cho", "et", "al", "propose", "a", "novel", "max", "pooling", "matching", "algorithm", ",", "in", "which", "they", "tweak", "the", "power", "method", "to", "better", "cope", "with", "noise", "in", "the", "affinities", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "cho et al", "start": 11, "end": 20, "i_start": 2, "i_end": 4}, "verb": {"text": "propose", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "cho", "start": 11, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "propose", "start": 21, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "cho", "start": 11, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "tweak", "start": 84, "end": 89, "i_start": 16, "i_end": 16}}, {"character": {"text": "cho", "start": 11, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "cope", "start": 117, "end": 121, "i_start": 22, "i_end": 22}}], "id": 2350}, {"sent": "such a phenomenological theory is called a chiral lagrangian .", "tokens": ["such", "a", "phenomenological", "theory", "is", "called", "a", "chiral", "lagrangian", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such a phenomenological theory", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "is called", "start": 31, "end": 40, "i_start": 4, "i_end": 5}}], "id": 2351}, {"sent": "chen et al provide a new notion of differential privacy which allows for privacy and protection against edge-disclosure attacks in the correlated setting of osns .", "tokens": ["chen", "et", "al", "provide", "a", "new", "notion", "of", "differential", "privacy", "which", "allows", "for", "privacy", "and", "protection", "against", "edge", "-", "disclosure", "attacks", "in", "the", "correlated", "setting", "of", "osns", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "chen et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "provide", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "chen", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "provide", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "notion", "start": 25, "end": 31, "i_start": 6, "i_end": 6}, "action": {"text": "allows", "start": 62, "end": 68, "i_start": 11, "i_end": 11}}], "id": 2352}, {"sent": "proton shock acceleration in laser-plasma interactions .", "tokens": ["proton", "shock", "acceleration", "in", "laser", "-", "plasma", "interactions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "interactions", "start": 42, "end": 54, "i_start": 7, "i_end": 7}, "action": {"text": "acceleration", "start": 13, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "proton", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "shock", "start": 7, "end": 12, "i_start": 1, "i_end": 1}}], "id": 2353}, {"sent": "according to the previous lemma , for any statement on weak forward bisimulations which is universally valid there is the corresponding universally valid statement on weak backward bisimulations .", "tokens": ["according", "to", "the", "previous", "lemma", ",", "for", "any", "statement", "on", "weak", "forward", "bisimulations", "which", "is", "universally", "valid", "there", "is", "the", "corresponding", "universally", "valid", "statement", "on", "weak", "backward", "bisimulations", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "there", "start": 109, "end": 114, "i_start": 17, "i_end": 17}, "verb": {"text": "is", "start": 115, "end": 117, "i_start": 18, "i_end": 18}}], "id": 2354}, {"sent": "cognitive radio is a promising technology offering enhanced spectrum efficiency via dynamic spectrum access .", "tokens": ["cognitive", "radio", "is", "a", "promising", "technology", "offering", "enhanced", "spectrum", "efficiency", "via", "dynamic", "spectrum", "access", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cognitive radio", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "technology", "start": 31, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "promising", "start": 21, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "technology", "start": 31, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "offering", "start": 42, "end": 50, "i_start": 6, "i_end": 6}}], "id": 2355}, {"sent": "previous studies have focused primarily on how data of a single modality might be processed in various tasks , eg , music genre classi cation , music information retrieval , melody extraction , image retrieval , and video classi cation .", "tokens": ["previous", "studies", "have", "focused", "primarily", "on", "how", "data", "of", "a", "single", "modality", "might", "be", "processed", "in", "various", "tasks", ",", "eg", ",", "music", "genre", "classi", "cation", ",", "music", "information", "retrieval", ",", "melody", "extraction", ",", "image", "retrieval", ",", "and", "video", "classi", "cation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "previous studies", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "have focused", "start": 17, "end": 29, "i_start": 2, "i_end": 3}}, {"character": {"text": "studies", "start": 9, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "focused", "start": 22, "end": 29, "i_start": 3, "i_end": 3}}], "id": 2356}, {"sent": "the minimal costs of the organization were met by the ngo and the science shop .", "tokens": ["the", "minimal", "costs", "of", "the", "organization", "were", "met", "by", "the", "ngo", "and", "the", "science", "shop", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the minimal costs of the organization", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "were met", "start": 38, "end": 46, "i_start": 6, "i_end": 7}}, {"character": {"text": "ngo", "start": 54, "end": 57, "i_start": 10, "i_end": 10}, "action": {"text": "met", "start": 43, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "shop", "start": 74, "end": 78, "i_start": 14, "i_end": 14}, "action": {"text": "met", "start": 43, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "science", "start": 66, "end": 73, "i_start": 13, "i_end": 13}, "action": {"text": "met", "start": 43, "end": 46, "i_start": 7, "i_end": 7}}], "id": 2357}, {"sent": "this is likely related to the higher aspect ratio of nanoflakes in cbt nanocomposites , as the effect of aspect ratio reduction was previously recognized to be detrimental in polymer nanocomposites .", "tokens": ["this", "is", "likely", "related", "to", "the", "higher", "aspect", "ratio", "of", "nanoflakes", "in", "cbt", "nanocomposites", ",", "as", "the", "effect", "of", "aspect", "ratio", "reduction", "was", "previously", "recognized", "to", "be", "detrimental", "in", "polymer", "nanocomposites", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 2358}, {"sent": "we evaluate our method on several representative datasets , including msra-b , all of which are available online .", "tokens": ["we", "evaluate", "our", "method", "on", "several", "representative", "datasets", ",", "including", "msra", "-", "b", ",", "all", "of", "which", "are", "available", "online", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "datasets", "start": 49, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "representative", "start": 34, "end": 48, "i_start": 6, "i_end": 6}}], "id": 2359}, {"sent": "a spacetime admits a temporal function if and only if it is stably causal .", "tokens": ["a", "spacetime", "admits", "a", "temporal", "function", "if", "and", "only", "if", "it", "is", "stably", "causal", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a spacetime", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "admits", "start": 12, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "spacetime", "start": 2, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "admits", "start": 12, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "spacetime", "start": 2, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "function", "start": 30, "end": 38, "i_start": 5, "i_end": 5}}], "id": 2360}, {"sent": "wallner and dyn showed that the riemannian extension of cubic subdivision yields c 1 curves .", "tokens": ["wallner", "and", "dyn", "showed", "that", "the", "riemannian", "extension", "of", "cubic", "subdivision", "yields", "c", "1", "curves", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "wallner and dyn", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 16, "end": 22, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the riemannian extension of cubic subdivision", "start": 28, "end": 73, "i_start": 5, "i_end": 10}, "verb": {"text": "yields", "start": 74, "end": 80, "i_start": 11, "i_end": 11}}, {"character": {"text": "wallner", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 16, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "dyn", "start": 12, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "showed", "start": 16, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "extension", "start": 43, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "yields", "start": 74, "end": 80, "i_start": 11, "i_end": 11}}], "id": 2361}, {"sent": "notice that the running time is the longest for the front part of the graph .", "tokens": ["notice", "that", "the", "running", "time", "is", "the", "longest", "for", "the", "front", "part", "of", "the", "graph", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2362}, {"sent": "latkineh , mssm searches at lep , paper presented at this conference .", "tokens": ["latkineh", ",", "mssm", "searches", "at", "lep", ",", "paper", "presented", "at", "this", "conference", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "at lep", "start": 25, "end": 31, "i_start": 4, "i_end": 5}, "action": {"text": "searches", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2363}, {"sent": "we set the attention size to 50 and regularize the network by using dropout .", "tokens": ["we", "set", "the", "attention", "size", "to", "50", "and", "regularize", "the", "network", "by", "using", "dropout", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "set", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "regularize", "start": 36, "end": 46, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "set", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 62, "end": 67, "i_start": 12, "i_end": 12}}], "id": 2364}, {"sent": "malek , on the summability of formal solutions of linear partial differ ential equations , j .", "tokens": ["malek", ",", "on", "the", "summability", "of", "formal", "solutions", "of", "linear", "partial", "differ", "ential", "equations", ",", "j", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "malek", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "differ", "start": 65, "end": 71, "i_start": 11, "i_end": 11}}], "id": 2365}, {"sent": "reengineering procedural into object-oriented systems .", "tokens": ["reengineering", "procedural", "into", "object", "-", "oriented", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2366}, {"sent": "we base our experiments on the deeplabv2 semantic segmentation network .", "tokens": ["we", "base", "our", "experiments", "on", "the", "deeplabv2", "semantic", "segmentation", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "base", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "base", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "experiments", "start": 12, "end": 23, "i_start": 3, "i_end": 3}}], "id": 2367}, {"sent": "let v q be the vertex operator algebra associated to the lattice q .", "tokens": ["let", "v", "q", "be", "the", "vertex", "operator", "algebra", "associated", "to", "the", "lattice", "q", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2368}, {"sent": "son et al showed that it is possible to obstruct the flight control of a drone by exploiting gyroscope using a sound signal .", "tokens": ["son", "et", "al", "showed", "that", "it", "is", "possible", "to", "obstruct", "the", "flight", "control", "of", "a", "drone", "by", "exploiting", "gyroscope", "using", "a", "sound", "signal", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "son et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 10, "end": 16, "i_start": 3, "i_end": 3}}, {"subject": {"text": "son et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 6, "i_end": 6}}], "id": 2369}, {"sent": "in this paper , we use a cnn based architecture for medical image segmentation known as unet .", "tokens": ["in", "this", "paper", ",", "we", "use", "a", "cnn", "based", "architecture", "for", "medical", "image", "segmentation", "known", "as", "unet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 19, "end": 22, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 19, "end": 22, "i_start": 5, "i_end": 5}}], "id": 2370}, {"sent": "for the purely implicational logic with one variable , the exact value of the density of true formulas have been computed in the paper of moczurad , tyszkiewicz and zaionc .", "tokens": ["for", "the", "purely", "implicational", "logic", "with", "one", "variable", ",", "the", "exact", "value", "of", "the", "density", "of", "true", "formulas", "have", "been", "computed", "in", "the", "paper", "of", "moczurad", ",", "tyszkiewicz", "and", "zaionc", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the exact value of the density of true formulas", "start": 55, "end": 102, "i_start": 9, "i_end": 17}, "verb": {"text": "have been computed", "start": 103, "end": 121, "i_start": 18, "i_end": 20}}], "id": 2371}, {"sent": "the arches cluster is a very unique cluster in the milk way , because it is a very massive and compact young cluster close to the galactic center .", "tokens": ["the", "arches", "cluster", "is", "a", "very", "unique", "cluster", "in", "the", "milk", "way", ",", "because", "it", "is", "a", "very", "massive", "and", "compact", "young", "cluster", "close", "to", "the", "galactic", "center", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the arches cluster", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 2372}, {"sent": "the adjacency , laplacian or signless laplacian tensor of g is symmetric , and it is weakly irreducible if and only if g is connected .", "tokens": ["the", "adjacency", ",", "laplacian", "or", "signless", "laplacian", "tensor", "of", "g", "is", "symmetric", ",", "and", "it", "is", "weakly", "irreducible", "if", "and", "only", "if", "g", "is", "connected", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the adjacency", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 60, "end": 62, "i_start": 10, "i_end": 10}}], "id": 2373}, {"sent": "each convolutional block consists of a convolutional layer followed by a batch normalization layer which acts as a regularizer .", "tokens": ["each", "convolutional", "block", "consists", "of", "a", "convolutional", "layer", "followed", "by", "a", "batch", "normalization", "layer", "which", "acts", "as", "a", "regularizer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each convolutional block", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 25, "end": 33, "i_start": 3, "i_end": 3}}, {"character": {"text": "layer", "start": 93, "end": 98, "i_start": 13, "i_end": 13}, "action": {"text": "normalization", "start": 79, "end": 92, "i_start": 12, "i_end": 12}}, {"character": {"text": "layer", "start": 93, "end": 98, "i_start": 13, "i_end": 13}, "action": {"text": "acts", "start": 105, "end": 109, "i_start": 15, "i_end": 15}}], "id": 2374}, {"sent": "we use the glauber approximation for the fsi , including the nuclear correlation .", "tokens": ["we", "use", "the", "glauber", "approximation", "for", "the", "fsi", ",", "including", "the", "nuclear", "correlation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "glauber", "start": 11, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "approximation", "start": 19, "end": 32, "i_start": 4, "i_end": 4}}], "id": 2375}, {"sent": "however , we may conclude that up to and beyond the chiral symmetry restoration point the quark fermi sea can have negative pressure and therefore can be mechanically unstable with an imaginary speed of sound .", "tokens": ["however", ",", "we", "may", "conclude", "that", "up", "to", "and", "beyond", "the", "chiral", "symmetry", "restoration", "point", "the", "quark", "fermi", "sea", "can", "have", "negative", "pressure", "and", "therefore", "can", "be", "mechanically", "unstable", "with", "an", "imaginary", "speed", "of", "sound", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "may conclude", "start": 13, "end": 25, "i_start": 3, "i_end": 4}}, {"subject": {"text": "the quark fermi sea", "start": 86, "end": 105, "i_start": 15, "i_end": 18}, "verb": {"text": "have", "start": 110, "end": 114, "i_start": 20, "i_end": 20}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "conclude", "start": 17, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "sea", "start": 102, "end": 105, "i_start": 18, "i_end": 18}, "action": {"text": "have", "start": 110, "end": 114, "i_start": 20, "i_end": 20}}, {"character": {"text": "pressure", "start": 124, "end": 132, "i_start": 22, "i_end": 22}, "action": {"text": "negative", "start": 115, "end": 123, "i_start": 21, "i_end": 21}}], "id": 2376}, {"sent": "let jvj and jv be the corresponding periodic range function .", "tokens": ["let", "jvj", "and", "jv", "be", "the", "corresponding", "periodic", "range", "function", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "jvj and jv", "start": 4, "end": 14, "i_start": 1, "i_end": 3}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "jvj and jv", "start": 4, "end": 14, "i_start": 1, "i_end": 3}, "verb": {"text": "be", "start": 15, "end": 17, "i_start": 4, "i_end": 4}}, {"character": {"text": "jvj", "start": 4, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "function", "start": 51, "end": 59, "i_start": 9, "i_end": 9}}, {"character": {"text": "jv", "start": 12, "end": 14, "i_start": 3, "i_end": 3}, "action": {"text": "function", "start": 51, "end": 59, "i_start": 9, "i_end": 9}}], "id": 2377}, {"sent": "the pseudopotentials are chosen according to perdew-burkeernzerhof parametrization of the generalized gradient approximation for the exchange and correlation terms of the electron-electron interaction .", "tokens": ["the", "pseudopotentials", "are", "chosen", "according", "to", "perdew", "-", "burkeernzerhof", "parametrization", "of", "the", "generalized", "gradient", "approximation", "for", "the", "exchange", "and", "correlation", "terms", "of", "the", "electron", "-", "electron", "interaction", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the pseudopotentials", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "are chosen", "start": 21, "end": 31, "i_start": 2, "i_end": 3}}, {"character": {"text": "electron", "start": 171, "end": 179, "i_start": 23, "i_end": 23}, "action": {"text": "interaction", "start": 189, "end": 200, "i_start": 26, "i_end": 26}}], "id": 2378}, {"sent": "we also used the extended stochastic gradient descent adam algorithm to optimize the loss function .", "tokens": ["we", "also", "used", "the", "extended", "stochastic", "gradient", "descent", "adam", "algorithm", "to", "optimize", "the", "loss", "function", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimize", "start": 72, "end": 80, "i_start": 11, "i_end": 11}}], "id": 2379}, {"sent": "the authors would like to thank philip gressman and antti knowles for valuable discussions .", "tokens": ["the", "authors", "would", "like", "to", "thank", "philip", "gressman", "and", "antti", "knowles", "for", "valuable", "discussions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "would like", "start": 12, "end": 22, "i_start": 2, "i_end": 3}}], "id": 2380}, {"sent": "lem me de comparaison des c-comodules quasi-colibres analytiques .", "tokens": ["lem", "me", "de", "comparaison", "des", "c", "-", "comodules", "quasi", "-", "colibres", "analytiques", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2381}, {"sent": "graphene is a two-dimensional material with the unique .", "tokens": ["graphene", "is", "a", "two", "-", "dimensional", "material", "with", "the", "unique", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "graphene", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2382}, {"sent": "here and throughout , overdots denote derivatives with respect to conformal time , and a is the scale factor normalised to unity today .", "tokens": ["here", "and", "throughout", ",", "overdots", "denote", "derivatives", "with", "respect", "to", "conformal", "time", ",", "and", "a", "is", "the", "scale", "factor", "normalised", "to", "unity", "today", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "overdots denote derivatives with respect to conformal time , and a", "start": 22, "end": 88, "i_start": 4, "i_end": 14}, "verb": {"text": "is", "start": 89, "end": 91, "i_start": 15, "i_end": 15}}, {"character": {"text": "overdots", "start": 22, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "denote", "start": 31, "end": 37, "i_start": 5, "i_end": 5}}], "id": 2383}, {"sent": "the duality here is the electric-magnetic duality that exchanges the electric and magnetic charges .", "tokens": ["the", "duality", "here", "is", "the", "electric", "-", "magnetic", "duality", "that", "exchanges", "the", "electric", "and", "magnetic", "charges", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the duality here", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "duality", "start": 42, "end": 49, "i_start": 8, "i_end": 8}, "action": {"text": "exchanges", "start": 55, "end": 64, "i_start": 10, "i_end": 10}}], "id": 2384}, {"sent": "we initialize all layer weights by he normal initializer and all bias terms by zero .", "tokens": ["we", "initialize", "all", "layer", "weights", "by", "he", "normal", "initializer", "and", "all", "bias", "terms", "by", "zero", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "initialize", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "initialize", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "he", "start": 35, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "initializer", "start": 45, "end": 56, "i_start": 8, "i_end": 8}}], "id": 2385}, {"sent": "the ordinate is the radius in logarithmic scale and the abscissa is the azimuthal angle and shown for two periods , or 0 720 degree , to delineate spiral arms .", "tokens": ["the", "ordinate", "is", "the", "radius", "in", "logarithmic", "scale", "and", "the", "abscissa", "is", "the", "azimuthal", "angle", "and", "shown", "for", "two", "periods", ",", "or", "0", "720", "degree", ",", "to", "delineate", "spiral", "arms", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ordinate", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "ordinate", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "delineate", "start": 137, "end": 146, "i_start": 27, "i_end": 27}}, {"character": {"text": "radius", "start": 20, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "delineate", "start": 137, "end": 146, "i_start": 27, "i_end": 27}}, {"character": {"text": "scale", "start": 42, "end": 47, "i_start": 7, "i_end": 7}, "action": {"text": "delineate", "start": 137, "end": 146, "i_start": 27, "i_end": 27}}, {"character": {"text": "logarithmic", "start": 30, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "delineate", "start": 137, "end": 146, "i_start": 27, "i_end": 27}}, {"character": {"text": "angle", "start": 82, "end": 87, "i_start": 14, "i_end": 14}, "action": {"text": "delineate", "start": 137, "end": 146, "i_start": 27, "i_end": 27}}, {"character": {"text": "azimuthal", "start": 72, "end": 81, "i_start": 13, "i_end": 13}, "action": {"text": "delineate", "start": 137, "end": 146, "i_start": 27, "i_end": 27}}, {"character": {"text": "abscissa", "start": 56, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "delineate", "start": 137, "end": 146, "i_start": 27, "i_end": 27}}, {"character": {"text": "shown", "start": 92, "end": 97, "i_start": 16, "i_end": 16}, "action": {"text": "delineate", "start": 137, "end": 146, "i_start": 27, "i_end": 27}}, {"character": {"text": "delineate", "start": 137, "end": 146, "i_start": 27, "i_end": 27}, "action": {"text": "delineate", "start": 137, "end": 146, "i_start": 27, "i_end": 27}}, {"character": {"text": "spiral", "start": 147, "end": 153, "i_start": 28, "i_end": 28}, "action": {"text": "delineate", "start": 137, "end": 146, "i_start": 27, "i_end": 27}}, {"character": {"text": "two periods", "start": 102, "end": 113, "i_start": 18, "i_end": 19}, "action": {"text": "delineate", "start": 137, "end": 146, "i_start": 27, "i_end": 27}}], "id": 2386}, {"sent": "many methods are heuristic , relying on holes , open boundaries , or point densities to find nbvs .", "tokens": ["many", "methods", "are", "heuristic", ",", "relying", "on", "holes", ",", "open", "boundaries", ",", "or", "point", "densities", "to", "find", "nbvs", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "many methods", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 13, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "methods", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "relying", "start": 29, "end": 36, "i_start": 5, "i_end": 5}}], "id": 2387}, {"sent": "we assume that the lemma has been proved for all simple lie algebras of rank less than the rank of g .", "tokens": ["we", "assume", "that", "the", "lemma", "has", "been", "proved", "for", "all", "simple", "lie", "algebras", "of", "rank", "less", "than", "the", "rank", "of", "g", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the lemma", "start": 15, "end": 24, "i_start": 3, "i_end": 4}, "verb": {"text": "proved", "start": 34, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 2388}, {"sent": "under the assumption of uniform matter density distribution , the exact expressions of the eigenvalues , mixing angles , and the oscillation probabilities in matter have been obtained .", "tokens": ["under", "the", "assumption", "of", "uniform", "matter", "density", "distribution", ",", "the", "exact", "expressions", "of", "the", "eigenvalues", ",", "mixing", "angles", ",", "and", "the", "oscillation", "probabilities", "in", "matter", "have", "been", "obtained", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the exact expressions of the eigenvalues , mixing angles , and the oscillation probabilities in matter", "start": 62, "end": 164, "i_start": 9, "i_end": 24}, "verb": {"text": "have been obtained", "start": 165, "end": 183, "i_start": 25, "i_end": 27}}], "id": 2389}, {"sent": "the emergence of deep convolutional neural networks has greatly contributed to advancements in solving complex tasks in computer vision with significantly improved performance .", "tokens": ["the", "emergence", "of", "deep", "convolutional", "neural", "networks", "has", "greatly", "contributed", "to", "advancements", "in", "solving", "complex", "tasks", "in", "computer", "vision", "with", "significantly", "improved", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the emergence of deep convolutional neural networks", "start": 0, "end": 51, "i_start": 0, "i_end": 6}, "verb": {"text": "contributed", "start": 64, "end": 75, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the emergence of deep convolutional neural networks", "start": 0, "end": 51, "i_start": 0, "i_end": 6}, "verb": {"text": "has", "start": 52, "end": 55, "i_start": 7, "i_end": 7}}, {"character": {"text": "emergence", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "contributed", "start": 64, "end": 75, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 43, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "emergence", "start": 4, "end": 13, "i_start": 1, "i_end": 1}}], "id": 2390}, {"sent": "the instability is the signature to a phase transition into a state with coherent radiation .", "tokens": ["the", "instability", "is", "the", "signature", "to", "a", "phase", "transition", "into", "a", "state", "with", "coherent", "radiation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the instability", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 2391}, {"sent": "lattice qcd is the most promising approach to solve the low-energy dynamics of qcd , but there is a problem in realizing the chiral symmetry on the lattice .", "tokens": ["lattice", "qcd", "is", "the", "most", "promising", "approach", "to", "solve", "the", "low", "-", "energy", "dynamics", "of", "qcd", ",", "but", "there", "is", "a", "problem", "in", "realizing", "the", "chiral", "symmetry", "on", "the", "lattice", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "lattice qcd", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}, {"subject": {"text": "there", "start": 89, "end": 94, "i_start": 18, "i_end": 18}, "verb": {"text": "is", "start": 95, "end": 97, "i_start": 19, "i_end": 19}}, {"character": {"text": "lattice", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "approach", "start": 34, "end": 42, "i_start": 6, "i_end": 6}}, {"character": {"text": "approach", "start": 34, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "promising", "start": 24, "end": 33, "i_start": 5, "i_end": 5}}], "id": 2392}, {"sent": "normalization techniques like batch normalization have been proven to be beneficial for training of deep neural networks .", "tokens": ["normalization", "techniques", "like", "batch", "normalization", "have", "been", "proven", "to", "be", "beneficial", "for", "training", "of", "deep", "neural", "networks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "normalization techniques like batch normalization", "start": 0, "end": 49, "i_start": 0, "i_end": 4}, "verb": {"text": "have been proven", "start": 50, "end": 66, "i_start": 5, "i_end": 7}}, {"character": {"text": "techniques", "start": 14, "end": 24, "i_start": 1, "i_end": 1}, "action": {"text": "beneficial", "start": 73, "end": 83, "i_start": 10, "i_end": 10}}], "id": 2393}, {"sent": "a model of authorization for next-generation database systems .", "tokens": ["a", "model", "of", "authorization", "for", "next", "-", "generation", "database", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2394}, {"sent": "massive mimo is a candidate technology to integrate next generation cellular systems , such as 5g systems , and deliver manifold enhancements in the communications link .", "tokens": ["massive", "mimo", "is", "a", "candidate", "technology", "to", "integrate", "next", "generation", "cellular", "systems", ",", "such", "as", "5", "g", "systems", ",", "and", "deliver", "manifold", "enhancements", "in", "the", "communications", "link", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "massive mimo", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 2395}, {"sent": "a polyhedron p is a refinement of a polyhedron q if the normal fan of p is a refinement of that of q , that is , the closure of each normal cone of q is the union of closures of normal cones of p .", "tokens": ["a", "polyhedron", "p", "is", "a", "refinement", "of", "a", "polyhedron", "q", "if", "the", "normal", "fan", "of", "p", "is", "a", "refinement", "of", "that", "of", "q", ",", "that", "is", ",", "the", "closure", "of", "each", "normal", "cone", "of", "q", "is", "the", "union", "of", "closures", "of", "normal", "cones", "of", "p", "."], "score": [1, 1, 1, 1, 0], "labels": [{"subject": {"text": "the closure of each normal cone of q is the union of closures of normal cones of p", "start": 113, "end": 195, "i_start": 27, "i_end": 44}, "verb": {"text": "is", "start": 150, "end": 152, "i_start": 35, "i_end": 35}}, {"subject": {"text": "the closure of each normal cone of q is the union of closures of normal cones of p", "start": 113, "end": 195, "i_start": 27, "i_end": 44}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}], "id": 2396}, {"sent": "since string theory is a proposed fundamental theory of quantum gravity , one may expect that stringy corrections to the low energy effective theory resolve causality violations .", "tokens": ["since", "string", "theory", "is", "a", "proposed", "fundamental", "theory", "of", "quantum", "gravity", ",", "one", "may", "expect", "that", "stringy", "corrections", "to", "the", "low", "energy", "effective", "theory", "resolve", "causality", "violations", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "one", "start": 74, "end": 77, "i_start": 12, "i_end": 12}, "verb": {"text": "may expect", "start": 78, "end": 88, "i_start": 13, "i_end": 14}}, {"subject": {"text": "one", "start": 74, "end": 77, "i_start": 12, "i_end": 12}, "verb": {"text": "stringy", "start": 94, "end": 101, "i_start": 16, "i_end": 16}}, {"subject": {"text": "one", "start": 74, "end": 77, "i_start": 12, "i_end": 12}, "verb": {"text": "resolve", "start": 149, "end": 156, "i_start": 24, "i_end": 24}}, {"character": {"text": "one", "start": 74, "end": 77, "i_start": 12, "i_end": 12}, "action": {"text": "expect", "start": 82, "end": 88, "i_start": 14, "i_end": 14}}, {"character": {"text": "corrections", "start": 102, "end": 113, "i_start": 17, "i_end": 17}, "action": {"text": "resolve", "start": 149, "end": 156, "i_start": 24, "i_end": 24}}, {"character": {"text": "theory", "start": 13, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "effective", "start": 132, "end": 141, "i_start": 22, "i_end": 22}}], "id": 2397}, {"sent": "each quoted uncertainty is the standard deviation of these results .", "tokens": ["each", "quoted", "uncertainty", "is", "the", "standard", "deviation", "of", "these", "results", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each quoted uncertainty", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}], "id": 2398}, {"sent": "convolutional neural networks have achieved remarkable success in many computer vision domains such as classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "remarkable", "success", "in", "many", "computer", "vision", "domains", "such", "as", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 6, "i_end": 6}}], "id": 2399}, {"sent": "for the word representations , we use the googlenews pre-trained word2vec embedding model .", "tokens": ["for", "the", "word", "representations", ",", "we", "use", "the", "googlenews", "pre", "-", "trained", "word2vec", "embedding", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}], "id": 2400}, {"sent": "the operator of total electronic angular momentum about the z-axis is z .", "tokens": ["the", "operator", "of", "total", "electronic", "angular", "momentum", "about", "the", "z", "-", "axis", "is", "z", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the operator of total electronic angular momentum about the z-axis", "start": 0, "end": 66, "i_start": 0, "i_end": 11}, "verb": {"text": "is", "start": 67, "end": 69, "i_start": 12, "i_end": 12}}], "id": 2401}, {"sent": "where the curves are truncated the system becomes ferromagnetic .", "tokens": ["where", "the", "curves", "are", "truncated", "the", "system", "becomes", "ferromagnetic", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the system", "start": 31, "end": 41, "i_start": 5, "i_end": 6}, "verb": {"text": "becomes", "start": 42, "end": 49, "i_start": 7, "i_end": 7}}], "id": 2402}, {"sent": "recent advancement in deep learning has revealed that features extracted from upper or intermediate layers of convolutional neural networks are generic features that have good transfer learning capabilities across different domains .", "tokens": ["recent", "advancement", "in", "deep", "learning", "has", "revealed", "that", "features", "extracted", "from", "upper", "or", "intermediate", "layers", "of", "convolutional", "neural", "networks", "are", "generic", "features", "that", "have", "good", "transfer", "learning", "capabilities", "across", "different", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent advancement in deep learning", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "has revealed", "start": 36, "end": 48, "i_start": 5, "i_end": 6}}, {"subject": {"text": "recent advancement in deep learning", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "are", "start": 140, "end": 143, "i_start": 19, "i_end": 19}}, {"character": {"text": "advancement", "start": 7, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "revealed", "start": 40, "end": 48, "i_start": 6, "i_end": 6}}, {"character": {"text": "features", "start": 54, "end": 62, "i_start": 8, "i_end": 8}, "action": {"text": "has", "start": 36, "end": 39, "i_start": 5, "i_end": 5}}], "id": 2403}, {"sent": "a permutation consists of one or multiple disjoint cycles .", "tokens": ["a", "permutation", "consists", "of", "one", "or", "multiple", "disjoint", "cycles", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a permutation", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 14, "end": 22, "i_start": 2, "i_end": 2}}], "id": 2404}, {"sent": "linear quantum stochastic systems are a class of models of wide use in quantum optics and elsewhere .", "tokens": ["linear", "quantum", "stochastic", "systems", "are", "a", "class", "of", "models", "of", "wide", "use", "in", "quantum", "optics", "and", "elsewhere", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "linear quantum stochastic systems", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 34, "end": 37, "i_start": 4, "i_end": 4}}], "id": 2405}, {"sent": "deep learning using convolutional neural networks has achieved excellent performance for a wide range of tasks , such as image recognition .", "tokens": ["deep", "learning", "using", "convolutional", "neural", "networks", "has", "achieved", "excellent", "performance", "for", "a", "wide", "range", "of", "tasks", ",", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning using convolutional neural networks", "start": 0, "end": 49, "i_start": 0, "i_end": 5}, "verb": {"text": "has achieved", "start": 50, "end": 62, "i_start": 6, "i_end": 7}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "achieved", "start": 54, "end": 62, "i_start": 7, "i_end": 7}}], "id": 2406}, {"sent": "our question encoder is a dynamic gated recurrent unit with a hidden state size of 1024 .", "tokens": ["our", "question", "encoder", "is", "a", "dynamic", "gated", "recurrent", "unit", "with", "a", "hidden", "state", "size", "of", "1024", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our question encoder", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 3, "i_end": 3}}], "id": 2407}, {"sent": "it is shown that the twoand three-photon bound states dramatically enhance the transmission of two- and three-photon wavepackets , respectively .", "tokens": ["it", "is", "shown", "that", "the", "twoand", "three", "-", "photon", "bound", "states", "dramatically", "enhance", "the", "transmission", "of", "two-", "and", "three", "-", "photon", "wavepackets", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is shown", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"subject": {"text": "the twoand three-photon bound states", "start": 17, "end": 53, "i_start": 4, "i_end": 10}, "verb": {"text": "enhance", "start": 67, "end": 74, "i_start": 12, "i_end": 12}}, {"character": {"text": "states", "start": 47, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "enhance", "start": 67, "end": 74, "i_start": 12, "i_end": 12}}, {"character": {"text": "photon", "start": 34, "end": 40, "i_start": 8, "i_end": 8}, "action": {"text": "enhance", "start": 67, "end": 74, "i_start": 12, "i_end": 12}}, {"character": {"text": "photon", "start": 110, "end": 116, "i_start": 20, "i_end": 20}, "action": {"text": "enhance", "start": 67, "end": 74, "i_start": 12, "i_end": 12}}], "id": 2408}, {"sent": "in 2005 , important progress made by bianchini-bressan justifies the vanishing viscosity limit in bv space even though the problem is still unsolved for the physical system such as the compressible navier-stokes equations .", "tokens": ["in", "2005", ",", "important", "progress", "made", "by", "bianchini", "-", "bressan", "justifies", "the", "vanishing", "viscosity", "limit", "in", "bv", "space", "even", "though", "the", "problem", "is", "still", "unsolved", "for", "the", "physical", "system", "such", "as", "the", "compressible", "navier", "-", "stokes", "equations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "important progress made by bianchini-bressan", "start": 10, "end": 54, "i_start": 3, "i_end": 9}, "verb": {"text": "justifies", "start": 55, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "progress", "start": 20, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "justifies", "start": 55, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "bianchini", "start": 37, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "made", "start": 29, "end": 33, "i_start": 5, "i_end": 5}}], "id": 2409}, {"sent": "training on a large number of tasks is known to help regularize multi-task models .", "tokens": ["training", "on", "a", "large", "number", "of", "tasks", "is", "known", "to", "help", "regularize", "multi", "-", "task", "models", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "training on a large number of tasks", "start": 0, "end": 35, "i_start": 0, "i_end": 6}, "verb": {"text": "is known", "start": 36, "end": 44, "i_start": 7, "i_end": 8}}, {"character": {"text": "training", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "help", "start": 48, "end": 52, "i_start": 10, "i_end": 10}}], "id": 2410}, {"sent": "convolutional neural network has achieved great success in image recognition and object detection .", "tokens": ["convolutional", "neural", "network", "has", "achieved", "great", "success", "in", "image", "recognition", "and", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural network", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "has achieved", "start": 29, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "network", "start": 21, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 33, "end": 41, "i_start": 4, "i_end": 4}}, {"character": {"text": "network", "start": 21, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 48, "end": 55, "i_start": 6, "i_end": 6}}, {"character": {"text": "network", "start": 21, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "recognition", "start": 65, "end": 76, "i_start": 9, "i_end": 9}}, {"character": {"text": "network", "start": 21, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "detection", "start": 88, "end": 97, "i_start": 12, "i_end": 12}}], "id": 2411}, {"sent": "an episode is a short ordered sequence of events where each event is tagged with an event-type from an appropriate alphabet .", "tokens": ["an", "episode", "is", "a", "short", "ordered", "sequence", "of", "events", "where", "each", "event", "is", "tagged", "with", "an", "event", "-", "type", "from", "an", "appropriate", "alphabet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an episode", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}], "id": 2412}, {"sent": "deep convolutional neural networks have been successfully applied to several pattern recognition tasks such as image recognition .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successfully", "applied", "to", "several", "pattern", "recognition", "tasks", "such", "as", "image", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "applied", "start": 58, "end": 65, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}], "id": 2413}, {"sent": "the most studied cases were spin waves in the long-wave approximation corresponding to rotating and pulsating strings in certain limits , see for instance the reviews and references therein .", "tokens": ["the", "most", "studied", "cases", "were", "spin", "waves", "in", "the", "long", "-", "wave", "approximation", "corresponding", "to", "rotating", "and", "pulsating", "strings", "in", "certain", "limits", ",", "see", "for", "instance", "the", "reviews", "and", "references", "therein", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most studied cases", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "were", "start": 23, "end": 27, "i_start": 4, "i_end": 4}}], "id": 2414}, {"sent": "however , in joint work with ueno , that the tuy-construction of the wzw-conformal field theory after twist by a fractional power of an abelian theory , satisfies all the axioms of a modular functor .", "tokens": ["however", ",", "in", "joint", "work", "with", "ueno", ",", "that", "the", "tuy", "-", "construction", "of", "the", "wzw", "-", "conformal", "field", "theory", "after", "twist", "by", "a", "fractional", "power", "of", "an", "abelian", "theory", ",", "satisfies", "all", "the", "axioms", "of", "a", "modular", "functor", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the tuy-construction of the wzw-conformal field theory after twist by a fractional power of an abelian theory", "start": 41, "end": 150, "i_start": 9, "i_end": 29}, "verb": {"text": "satisfies", "start": 153, "end": 162, "i_start": 31, "i_end": 31}}, {"character": {"text": "construction", "start": 49, "end": 61, "i_start": 12, "i_end": 12}, "action": {"text": "satisfies", "start": 153, "end": 162, "i_start": 31, "i_end": 31}}, {"character": {"text": "power", "start": 124, "end": 129, "i_start": 25, "i_end": 25}, "action": {"text": "twist", "start": 102, "end": 107, "i_start": 21, "i_end": 21}}], "id": 2415}, {"sent": "furthermore , hyry and smith have discovered a connection with a celebrated conjecture by kawamata on the non-vanishing of sections of line bundles .", "tokens": ["furthermore", ",", "hyry", "and", "smith", "have", "discovered", "a", "connection", "with", "a", "celebrated", "conjecture", "by", "kawamata", "on", "the", "non", "-", "vanishing", "of", "sections", "of", "line", "bundles", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hyry and smith", "start": 14, "end": 28, "i_start": 2, "i_end": 4}, "verb": {"text": "have discovered", "start": 29, "end": 44, "i_start": 5, "i_end": 6}}, {"character": {"text": "hyry", "start": 14, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "discovered", "start": 34, "end": 44, "i_start": 6, "i_end": 6}}, {"character": {"text": "smith", "start": 23, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "discovered", "start": 34, "end": 44, "i_start": 6, "i_end": 6}}, {"character": {"text": "kawamata", "start": 90, "end": 98, "i_start": 14, "i_end": 14}, "action": {"text": "conjecture", "start": 76, "end": 86, "i_start": 12, "i_end": 12}}], "id": 2416}, {"sent": "at the tevatron , which is a proton anti-proton collider , both the initial quark and anti-quark can be valence partons .", "tokens": ["at", "the", "tevatron", ",", "which", "is", "a", "proton", "anti", "-", "proton", "collider", ",", "both", "the", "initial", "quark", "and", "anti", "-", "quark", "can", "be", "valence", "partons", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "both the initial quark and anti-quark", "start": 59, "end": 96, "i_start": 13, "i_end": 20}, "verb": {"text": "can be", "start": 97, "end": 103, "i_start": 21, "i_end": 22}}, {"character": {"text": "collider", "start": 48, "end": 56, "i_start": 11, "i_end": 11}, "action": {"text": "anti", "start": 86, "end": 90, "i_start": 18, "i_end": 18}}], "id": 2417}, {"sent": "in early pioneering studies , the wiretap channel was characterized as the fundamental framework within which to protect information at the physical layer .", "tokens": ["in", "early", "pioneering", "studies", ",", "the", "wiretap", "channel", "was", "characterized", "as", "the", "fundamental", "framework", "within", "which", "to", "protect", "information", "at", "the", "physical", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the wiretap channel", "start": 30, "end": 49, "i_start": 5, "i_end": 7}, "verb": {"text": "was characterized", "start": 50, "end": 67, "i_start": 8, "i_end": 9}}], "id": 2418}, {"sent": "we refer the reader to for introductions to the theory of catspaces .", "tokens": ["we", "refer", "the", "reader", "to", "for", "introductions", "to", "the", "theory", "of", "catspaces", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2419}, {"sent": "in addition , a vast amount of efforts has been addressed in understanding the structure , evolution and dynamics of complex networks .", "tokens": ["in", "addition", ",", "a", "vast", "amount", "of", "efforts", "has", "been", "addressed", "in", "understanding", "the", "structure", ",", "evolution", "and", "dynamics", "of", "complex", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a vast amount of efforts", "start": 14, "end": 38, "i_start": 3, "i_end": 7}, "verb": {"text": "has been addressed", "start": 39, "end": 57, "i_start": 8, "i_end": 10}}], "id": 2420}, {"sent": "the system under investigation is a bose-einstein condensate interacting with the mode .", "tokens": ["the", "system", "under", "investigation", "is", "a", "bose", "-", "einstein", "condensate", "interacting", "with", "the", "mode", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the system under investigation", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "condensate", "start": 50, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "interacting", "start": 61, "end": 72, "i_start": 10, "i_end": 10}}], "id": 2421}, {"sent": "deep neural networks have been widely applied and achieved state-of-art performance on a variety of tasks including image recognition .", "tokens": ["deep", "neural", "networks", "have", "been", "widely", "applied", "and", "achieved", "state", "-", "of", "-", "art", "performance", "on", "a", "variety", "of", "tasks", "including", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "applied", "start": 38, "end": 45, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 50, "end": 58, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 50, "end": 58, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 72, "end": 83, "i_start": 14, "i_end": 14}}], "id": 2422}, {"sent": "in recent years , convolutional neural networks have become the dominant approach for a variety of computer vision tasks , eg , image classification .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "become", "the", "dominant", "approach", "for", "a", "variety", "of", "computer", "vision", "tasks", ",", "eg", ",", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have become", "start": 48, "end": 59, "i_start": 7, "i_end": 8}}, {"character": {"text": "approach", "start": 73, "end": 81, "i_start": 11, "i_end": 11}, "action": {"text": "dominant", "start": 64, "end": 72, "i_start": 10, "i_end": 10}}], "id": 2423}, {"sent": "for example , he et al generalized matrix factorization and factorization machines to neural collaborative filtering and achieved promising performance .", "tokens": ["for", "example", ",", "he", "et", "al", "generalized", "matrix", "factorization", "and", "factorization", "machines", "to", "neural", "collaborative", "filtering", "and", "achieved", "promising", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "he et al", "start": 14, "end": 22, "i_start": 3, "i_end": 5}, "verb": {"text": "generalized", "start": 23, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "he", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "generalized", "start": 23, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "he", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 121, "end": 129, "i_start": 17, "i_end": 17}}, {"character": {"text": "he", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 140, "end": 151, "i_start": 19, "i_end": 19}}], "id": 2424}, {"sent": "convolutional neural networks have achieved superior performance in many visual tasks , such as object detection and segmentation .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "detection", "and", "segmentation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 6, "i_end": 6}}], "id": 2425}, {"sent": "in addition , we will consider quasianalyticity property of the random power series by the residue analysis of the pade approximation .", "tokens": ["in", "addition", ",", "we", "will", "consider", "quasianalyticity", "property", "of", "the", "random", "power", "series", "by", "the", "residue", "analysis", "of", "the", "pade", "approximation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "will consider", "start": 17, "end": 30, "i_start": 4, "i_end": 5}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "consider", "start": 22, "end": 30, "i_start": 5, "i_end": 5}}], "id": 2426}, {"sent": "the second equality follows from linearity of the quantum operation n .", "tokens": ["the", "second", "equality", "follows", "from", "linearity", "of", "the", "quantum", "operation", "n", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the second equality", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "follows", "start": 20, "end": 27, "i_start": 3, "i_end": 3}}], "id": 2427}, {"sent": "the last one is to compare the performance of osga with other typical dictionary learning strategy such as the oga learning , and greedy boosting .", "tokens": ["the", "last", "one", "is", "to", "compare", "the", "performance", "of", "osga", "with", "other", "typical", "dictionary", "learning", "strategy", "such", "as", "the", "oga", "learning", ",", "and", "greedy", "boosting", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the last one", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "osga", "start": 46, "end": 50, "i_start": 9, "i_end": 9}, "action": {"text": "performance", "start": 31, "end": 42, "i_start": 7, "i_end": 7}}], "id": 2428}, {"sent": "we minimize the loss function using online adaptive gradient descent with 2 regularization on the feature weights \u03b8 .", "tokens": ["we", "minimize", "the", "loss", "function", "using", "online", "adaptive", "gradient", "descent", "with", "2", "regularization", "on", "the", "feature", "weights", "\u03b8", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "minimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "minimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2429}, {"sent": "in , subcarrier assignment and power allocation are done in two separate stages .", "tokens": ["in", ",", "subcarrier", "assignment", "and", "power", "allocation", "are", "done", "in", "two", "separate", "stages", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "subcarrier assignment and power allocation", "start": 5, "end": 47, "i_start": 2, "i_end": 6}, "verb": {"text": "are done", "start": 48, "end": 56, "i_start": 7, "i_end": 8}}], "id": 2430}, {"sent": "these topological invariants enable materials containing weyl points to exhibit a wide variety of novel phenomena including surface fermi arcs .", "tokens": ["these", "topological", "invariants", "enable", "materials", "containing", "weyl", "points", "to", "exhibit", "a", "wide", "variety", "of", "novel", "phenomena", "including", "surface", "fermi", "arcs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "these topological invariants", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "enable", "start": 29, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "invariants", "start": 18, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "enable", "start": 29, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "materials", "start": 36, "end": 45, "i_start": 4, "i_end": 4}, "action": {"text": "exhibit", "start": 72, "end": 79, "i_start": 9, "i_end": 9}}, {"character": {"text": "materials", "start": 36, "end": 45, "i_start": 4, "i_end": 4}, "action": {"text": "containing", "start": 46, "end": 56, "i_start": 5, "i_end": 5}}], "id": 2431}, {"sent": "another specific feature is the anti-colinearity of the current density j with b at .", "tokens": ["another", "specific", "feature", "is", "the", "anti", "-", "colinearity", "of", "the", "current", "density", "j", "with", "b", "at", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another specific feature", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "density", "start": 64, "end": 71, "i_start": 11, "i_end": 11}, "action": {"text": "anti", "start": 32, "end": 36, "i_start": 5, "i_end": 5}}], "id": 2432}, {"sent": "following the design study methodology of sedlmair et al , the reflection is the third contribution of a design study which enables the improvement of current guidelines .", "tokens": ["following", "the", "design", "study", "methodology", "of", "sedlmair", "et", "al", ",", "the", "reflection", "is", "the", "third", "contribution", "of", "a", "design", "study", "which", "enables", "the", "improvement", "of", "current", "guidelines", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "the reflection", "start": 59, "end": 73, "i_start": 10, "i_end": 11}, "verb": {"text": "is", "start": 74, "end": 76, "i_start": 12, "i_end": 12}}, {"character": {"text": "study", "start": 21, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "contribution", "start": 87, "end": 99, "i_start": 15, "i_end": 15}}, {"character": {"text": "reflection", "start": 63, "end": 73, "i_start": 11, "i_end": 11}, "action": {"text": "enables", "start": 124, "end": 131, "i_start": 21, "i_end": 21}}], "id": 2433}, {"sent": "we compare the proposed approach with 7 recent cnnbased methods , including mdf .", "tokens": ["we", "compare", "the", "proposed", "approach", "with", "7", "recent", "cnnbased", "methods", ",", "including", "mdf", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 2434}, {"sent": "this can be achieved by the well-known expectation-maximization algorithm .", "tokens": ["this", "can", "be", "achieved", "by", "the", "well", "-", "known", "expectation", "-", "maximization", "algorithm", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "can be achieved", "start": 5, "end": 20, "i_start": 1, "i_end": 3}}, {"character": {"text": "algorithm", "start": 64, "end": 73, "i_start": 12, "i_end": 12}, "action": {"text": "achieved", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}], "id": 2435}, {"sent": "this is an invariant of legendrian submanifolds derived from the dga .", "tokens": ["this", "is", "an", "invariant", "of", "legendrian", "submanifolds", "derived", "from", "the", "dga", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 2436}, {"sent": "one can show that all the jacobi identities involving these operators are satisfied .", "tokens": ["one", "can", "show", "that", "all", "the", "jacobi", "identities", "involving", "these", "operators", "are", "satisfied", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "can show", "start": 4, "end": 12, "i_start": 1, "i_end": 2}}, {"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 70, "end": 73, "i_start": 11, "i_end": 11}}, {"character": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}], "id": 2437}, {"sent": "performance comparison of lg-lstm with a variety of cnn models show high accuracy performance .", "tokens": ["performance", "comparison", "of", "lg", "-", "lstm", "with", "a", "variety", "of", "cnn", "models", "show", "high", "accuracy", "performance", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "performance comparison of lg-lstm with a variety of cnn models", "start": 0, "end": 62, "i_start": 0, "i_end": 11}, "verb": {"text": "show", "start": 63, "end": 67, "i_start": 12, "i_end": 12}}, {"character": {"text": "comparison", "start": 12, "end": 22, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 63, "end": 67, "i_start": 12, "i_end": 12}}], "id": 2438}, {"sent": "the bulk universality for wigner matrices of all symmetry classes was proven in for the universality of correlation functions .", "tokens": ["the", "bulk", "universality", "for", "wigner", "matrices", "of", "all", "symmetry", "classes", "was", "proven", "in", "for", "the", "universality", "of", "correlation", "functions", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the bulk universality for wigner matrices of all symmetry classes", "start": 0, "end": 65, "i_start": 0, "i_end": 9}, "verb": {"text": "was proven", "start": 66, "end": 76, "i_start": 10, "i_end": 11}}], "id": 2439}, {"sent": "convolutional neural networks have achieved state-of-the-art performance on visual tasks such as image and video recognition in the last few years .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "visual", "tasks", "such", "as", "image", "and", "video", "recognition", "in", "the", "last", "few", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 61, "end": 72, "i_start": 12, "i_end": 12}}], "id": 2440}, {"sent": "recently , juditsky et al introduced the stochastic mirror-prox algorithm for solving stochastic vis in both smooth and nonsmooth cases .", "tokens": ["recently", ",", "juditsky", "et", "al", "introduced", "the", "stochastic", "mirror", "-", "prox", "algorithm", "for", "solving", "stochastic", "vis", "in", "both", "smooth", "and", "nonsmooth", "cases", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "juditsky et al", "start": 11, "end": 25, "i_start": 2, "i_end": 4}, "verb": {"text": "introduced", "start": 26, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "juditsky", "start": 11, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 26, "end": 36, "i_start": 5, "i_end": 5}}], "id": 2441}, {"sent": "the breakthrough empirical success of deep learning has spurred strong interests in theoretical understanding of multilayer neural networks .", "tokens": ["the", "breakthrough", "empirical", "success", "of", "deep", "learning", "has", "spurred", "strong", "interests", "in", "theoretical", "understanding", "of", "multilayer", "neural", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the breakthrough empirical success of deep learning", "start": 0, "end": 51, "i_start": 0, "i_end": 6}, "verb": {"text": "has spurred", "start": 52, "end": 63, "i_start": 7, "i_end": 8}}, {"character": {"text": "success", "start": 27, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "spurred", "start": 56, "end": 63, "i_start": 8, "i_end": 8}}, {"character": {"text": "learning", "start": 43, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 27, "end": 34, "i_start": 3, "i_end": 3}}], "id": 2442}, {"sent": "more recently , sinha et al propose a method to generate the surface of an object using geometry images .", "tokens": ["more", "recently", ",", "sinha", "et", "al", "propose", "a", "method", "to", "generate", "the", "surface", "of", "an", "object", "using", "geometry", "images", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 22, "end": 27, "i_start": 4, "i_end": 5}, "verb": {"text": "propose", "start": 28, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "sinha", "start": 16, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "propose", "start": 28, "end": 35, "i_start": 6, "i_end": 6}}], "id": 2443}, {"sent": "deep learning has emerged as a leading technology for accomplishing many challenging tasks showing outstanding performance in a broad range of applications .", "tokens": ["deep", "learning", "has", "emerged", "as", "a", "leading", "technology", "for", "accomplishing", "many", "challenging", "tasks", "showing", "outstanding", "performance", "in", "a", "broad", "range", "of", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has emerged", "start": 14, "end": 25, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "emerged", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "technology", "start": 39, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "leading", "start": 31, "end": 38, "i_start": 6, "i_end": 6}}], "id": 2444}, {"sent": "let us now discuss the supersymmetric configurations of this probe brane ac tion .", "tokens": ["let", "us", "now", "discuss", "the", "supersymmetric", "configurations", "of", "this", "probe", "brane", "ac", "tion", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "discuss", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "discuss", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}], "id": 2445}, {"sent": "at low temperatures , particles in a dilute boson gas can reside in the same quantum state , forming a bose-einstein condensate .", "tokens": ["at", "low", "temperatures", ",", "particles", "in", "a", "dilute", "boson", "gas", "can", "reside", "in", "the", "same", "quantum", "state", ",", "forming", "a", "bose", "-", "einstein", "condensate", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "particles in a dilute boson gas", "start": 22, "end": 53, "i_start": 4, "i_end": 9}, "verb": {"text": "can reside", "start": 54, "end": 64, "i_start": 10, "i_end": 11}}, {"character": {"text": "particles", "start": 22, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "reside", "start": 58, "end": 64, "i_start": 11, "i_end": 11}}], "id": 2446}, {"sent": "after every search , greedyfuture will rearrange the search path to minimize the cost of future searches .", "tokens": ["after", "every", "search", ",", "greedyfuture", "will", "rearrange", "the", "search", "path", "to", "minimize", "the", "cost", "of", "future", "searches", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "greedyfuture", "start": 21, "end": 33, "i_start": 4, "i_end": 4}, "verb": {"text": "will rearrange", "start": 34, "end": 48, "i_start": 5, "i_end": 6}}, {"character": {"text": "future", "start": 89, "end": 95, "i_start": 15, "i_end": 15}, "action": {"text": "rearrange", "start": 39, "end": 48, "i_start": 6, "i_end": 6}}, {"character": {"text": "future", "start": 89, "end": 95, "i_start": 15, "i_end": 15}, "action": {"text": "minimize", "start": 68, "end": 76, "i_start": 11, "i_end": 11}}], "id": 2447}, {"sent": "this last expression implies the second assertion of the proposition .", "tokens": ["this", "last", "expression", "implies", "the", "second", "assertion", "of", "the", "proposition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this last expression", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "implies", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "expression", "start": 10, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "implies", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}], "id": 2448}, {"sent": "on this part of the diagram , there are also some radio pulsars which have not been detected in x-rays .", "tokens": ["on", "this", "part", "of", "the", "diagram", ",", "there", "are", "also", "some", "radio", "pulsars", "which", "have", "not", "been", "detected", "in", "x", "-", "rays", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 30, "end": 35, "i_start": 7, "i_end": 7}, "verb": {"text": "are", "start": 36, "end": 39, "i_start": 8, "i_end": 8}}], "id": 2449}, {"sent": "since the gravitational field is a quantum operator , these quantities are given by quantum operators .", "tokens": ["since", "the", "gravitational", "field", "is", "a", "quantum", "operator", ",", "these", "quantities", "are", "given", "by", "quantum", "operators", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "these quantities", "start": 54, "end": 70, "i_start": 9, "i_end": 10}, "verb": {"text": "are given", "start": 71, "end": 80, "i_start": 11, "i_end": 12}}, {"character": {"text": "field", "start": 24, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "operator", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "quantum", "start": 35, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "given", "start": 75, "end": 80, "i_start": 12, "i_end": 12}}], "id": 2450}, {"sent": "for this , the follow the perturbed leader algorithm is suitable .", "tokens": ["for", "this", ",", "the", "follow", "the", "perturbed", "leader", "algorithm", "is", "suitable", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the follow the perturbed leader algorithm", "start": 11, "end": 52, "i_start": 3, "i_end": 8}, "verb": {"text": "is", "start": 53, "end": 55, "i_start": 9, "i_end": 9}}], "id": 2451}, {"sent": "up to a diffeomorphism , we may suppose that d is the closed unit euclidean disk .", "tokens": ["up", "to", "a", "diffeomorphism", ",", "we", "may", "suppose", "that", "d", "is", "the", "closed", "unit", "euclidean", "disk", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "verb": {"text": "may suppose", "start": 28, "end": 39, "i_start": 6, "i_end": 7}}, {"subject": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 47, "end": 49, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "suppose", "start": 32, "end": 39, "i_start": 7, "i_end": 7}}], "id": 2452}, {"sent": "we evaluate our model on a standard benchmark for video classification , ucf-101 .", "tokens": ["we", "evaluate", "our", "model", "on", "a", "standard", "benchmark", "for", "video", "classification", ",", "ucf-101", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2453}, {"sent": "we implemented the approach in matlab and used the matcovnet framework .", "tokens": ["we", "implemented", "the", "approach", "in", "matlab", "and", "used", "the", "matcovnet", "framework", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implemented", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 42, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implemented", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 42, "end": 46, "i_start": 7, "i_end": 7}}], "id": 2454}, {"sent": "the transmission shows an energy spectrum with forbidden and allowed bands that depends on the detuning parameter of the system .", "tokens": ["the", "transmission", "shows", "an", "energy", "spectrum", "with", "forbidden", "and", "allowed", "bands", "that", "depends", "on", "the", "detuning", "parameter", "of", "the", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the transmission", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "shows", "start": 17, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "transmission", "start": 4, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "shows", "start": 17, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "spectrum", "start": 33, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "depends", "start": 80, "end": 87, "i_start": 12, "i_end": 12}}], "id": 2455}, {"sent": "networks with multi-source inputs can often be dominated by one of the inputs .", "tokens": ["networks", "with", "multi", "-", "source", "inputs", "can", "often", "be", "dominated", "by", "one", "of", "the", "inputs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "networks with multi-source inputs", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "be dominated", "start": 44, "end": 56, "i_start": 8, "i_end": 9}}, {"subject": {"text": "networks with multi-source inputs", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "can", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "inputs can often be dominated by one", "start": 27, "end": 63, "i_start": 5, "i_end": 11}, "action": {"text": "dominated", "start": 47, "end": 56, "i_start": 9, "i_end": 9}}], "id": 2456}, {"sent": "the class of physical geometries is more powerful , then the class of the axiomatizable geometries , which are logical constructions .", "tokens": ["the", "class", "of", "physical", "geometries", "is", "more", "powerful", ",", "then", "the", "class", "of", "the", "axiomatizable", "geometries", ",", "which", "are", "logical", "constructions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the class of physical geometries", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 5, "i_end": 5}}], "id": 2457}, {"sent": "erasure coding has seen itself quickly emerged as a promising technique to reduce the storage cost for a given reliability as compared to fully-replicated systems .", "tokens": ["erasure", "coding", "has", "seen", "itself", "quickly", "emerged", "as", "a", "promising", "technique", "to", "reduce", "the", "storage", "cost", "for", "a", "given", "reliability", "as", "compared", "to", "fully", "-", "replicated", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "erasure coding", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "has seen", "start": 15, "end": 23, "i_start": 2, "i_end": 3}}, {"subject": {"text": "itself", "start": 24, "end": 30, "i_start": 4, "i_end": 4}, "verb": {"text": "emerged", "start": 39, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "technique", "start": 62, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "promising", "start": 52, "end": 61, "i_start": 9, "i_end": 9}}], "id": 2458}, {"sent": "atiyah and singer introduced in an index bundle in odd k-theory for families of selfadjoint fredholm operators that is non-trivial in general .", "tokens": ["atiyah", "and", "singer", "introduced", "in", "an", "index", "bundle", "in", "odd", "k", "-", "theory", "for", "families", "of", "selfadjoint", "fredholm", "operators", "that", "is", "non", "-", "trivial", "in", "general", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "atiyah and singer", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "introduced", "start": 18, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "atiyah", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 18, "end": 28, "i_start": 3, "i_end": 3}}], "id": 2459}, {"sent": "f employs the resnet-50 architecture whose output is a 2,048-dimensional vector .", "tokens": ["f", "employs", "the", "resnet-50", "architecture", "whose", "output", "is", "a", "2,048", "-", "dimensional", "vector", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "f", "start": 0, "end": 1, "i_start": 0, "i_end": 0}, "verb": {"text": "employs", "start": 2, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "architecture", "start": 24, "end": 36, "i_start": 4, "i_end": 4}, "action": {"text": "output", "start": 43, "end": 49, "i_start": 6, "i_end": 6}}], "id": 2460}, {"sent": "reinforcement learning is a framework for sequential decision making under uncertainty with the objective of finding a policy that maximizes the sum of rewards , or return , of an agent .", "tokens": ["reinforcement", "learning", "is", "a", "framework", "for", "sequential", "decision", "making", "under", "uncertainty", "with", "the", "objective", "of", "finding", "a", "policy", "that", "maximizes", "the", "sum", "of", "rewards", ",", "or", "return", ",", "of", "an", "agent", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "policy", "start": 119, "end": 125, "i_start": 17, "i_end": 17}, "action": {"text": "maximizes", "start": 131, "end": 140, "i_start": 19, "i_end": 19}}], "id": 2461}, {"sent": "convolutional neural networks have achieved remarkable success in many computer vision domains such as classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "remarkable", "success", "in", "many", "computer", "vision", "domains", "such", "as", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 6, "i_end": 6}}], "id": 2462}, {"sent": "owing to such extraordinary features , the transverse spin am in evanescent waves has already found important applications in spin-dependent unidirectional optical interfaces .", "tokens": ["owing", "to", "such", "extraordinary", "features", ",", "the", "transverse", "spin", "am", "in", "evanescent", "waves", "has", "already", "found", "important", "applications", "in", "spin", "-", "dependent", "unidirectional", "optical", "interfaces", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the transverse spin", "start": 39, "end": 58, "i_start": 6, "i_end": 8}, "verb": {"text": "am", "start": 59, "end": 61, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the transverse spin", "start": 39, "end": 58, "i_start": 6, "i_end": 8}, "verb": {"text": "found", "start": 94, "end": 99, "i_start": 15, "i_end": 15}}, {"character": {"text": "spin", "start": 54, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "found", "start": 94, "end": 99, "i_start": 15, "i_end": 15}}, {"character": {"text": "interfaces", "start": 164, "end": 174, "i_start": 24, "i_end": 24}, "action": {"text": "-dependent", "start": 130, "end": 140, "i_start": 20, "i_end": 21}}], "id": 2463}, {"sent": "the specific case of tree-shaped computations with a more accurate model has been analyzed in .", "tokens": ["the", "specific", "case", "of", "tree", "-", "shaped", "computations", "with", "a", "more", "accurate", "model", "has", "been", "analyzed", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the specific case of tree-shaped computations with a more accurate model", "start": 0, "end": 72, "i_start": 0, "i_end": 12}, "verb": {"text": "has been analyzed", "start": 73, "end": 90, "i_start": 13, "i_end": 15}}], "id": 2464}, {"sent": "deep neural networks have shown tremendous success in several computer vision tasks in recent years .", "tokens": ["deep", "neural", "networks", "have", "shown", "tremendous", "success", "in", "several", "computer", "vision", "tasks", "in", "recent", "years", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}], "id": 2465}, {"sent": "the problem is how to estimate model parameter values given the strategic flexibility of the human cognitive system .", "tokens": ["the", "problem", "is", "how", "to", "estimate", "model", "parameter", "values", "given", "the", "strategic", "flexibility", "of", "the", "human", "cognitive", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the problem", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 2466}, {"sent": "higher resolution models tend to rely on datasets only available in data-rich regions of the world .", "tokens": ["higher", "resolution", "models", "tend", "to", "rely", "on", "datasets", "only", "available", "in", "data", "-", "rich", "regions", "of", "the", "world", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "higher resolution models", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "tend", "start": 25, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 18, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "rely", "start": 33, "end": 37, "i_start": 5, "i_end": 5}}], "id": 2467}, {"sent": "deep convolutional neural networks have been successfully applied to a wide range of image classification tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successfully", "applied", "to", "a", "wide", "range", "of", "image", "classification", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "applied", "start": 58, "end": 65, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}], "id": 2468}, {"sent": "overlaid is the 1-\u03c3 range around the best fit to global data , grsv-std .", "tokens": ["overlaid", "is", "the", "1", "-", "\u03c3", "range", "around", "the", "best", "fit", "to", "global", "data", ",", "grsv", "-", "std", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2469}, {"sent": "convolutional neural networks have become the dominant approach for many computer vision tasks .", "tokens": ["convolutional", "neural", "networks", "have", "become", "the", "dominant", "approach", "for", "many", "computer", "vision", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have become", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "approach", "start": 55, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "approach", "start": 55, "end": 63, "i_start": 7, "i_end": 7}, "action": {"text": "dominant", "start": 46, "end": 54, "i_start": 6, "i_end": 6}}], "id": 2470}, {"sent": "note that this constraint only depends on the jet reference momenta .", "tokens": ["note", "that", "this", "constraint", "only", "depends", "on", "the", "jet", "reference", "momenta", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this constraint", "start": 10, "end": 25, "i_start": 2, "i_end": 3}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "this constraint", "start": 10, "end": 25, "i_start": 2, "i_end": 3}, "verb": {"text": "depends", "start": 31, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "constraint", "start": 15, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "depends", "start": 31, "end": 38, "i_start": 5, "i_end": 5}}], "id": 2471}, {"sent": "stewart and ermon show how to learn object detectors without any labels by incorporating hand-engineered constraint functions as part of the training objective .", "tokens": ["stewart", "and", "ermon", "show", "how", "to", "learn", "object", "detectors", "without", "any", "labels", "by", "incorporating", "hand", "-", "engineered", "constraint", "functions", "as", "part", "of", "the", "training", "objective", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "stewart and ermon", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "show", "start": 18, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "stewart", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 18, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "ermon", "start": 12, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 18, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "stewart", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "learn", "start": 30, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "ermon", "start": 12, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "learn", "start": 30, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "stewart", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "incorporating", "start": 75, "end": 88, "i_start": 13, "i_end": 13}}, {"character": {"text": "ermon", "start": 12, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "incorporating", "start": 75, "end": 88, "i_start": 13, "i_end": 13}}, {"character": {"text": "hand", "start": 89, "end": 93, "i_start": 14, "i_end": 14}, "action": {"text": "engineered", "start": 94, "end": 104, "i_start": 16, "i_end": 16}}], "id": 2472}, {"sent": "recent development of deep convolutional neural networks has led to great success in a variety of tasks including image classfication and others .", "tokens": ["recent", "development", "of", "deep", "convolutional", "neural", "networks", "has", "led", "to", "great", "success", "in", "a", "variety", "of", "tasks", "including", "image", "classfication", "and", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent development of deep convolutional neural networks", "start": 0, "end": 56, "i_start": 0, "i_end": 6}, "verb": {"text": "has led", "start": 57, "end": 64, "i_start": 7, "i_end": 8}}, {"character": {"text": "development", "start": 7, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 61, "end": 64, "i_start": 8, "i_end": 8}}], "id": 2473}, {"sent": "c onvolutional neural networks have achieved state-of-the-art performance on various visual recognition tasks such as image classification .", "tokens": ["c", "onvolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "various", "visual", "recognition", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "c onvolutional neural networks", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 31, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 22, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "c onvolutional neural networks have achieved", "start": 0, "end": 44, "i_start": 0, "i_end": 5}}, {"character": {"text": "networks", "start": 22, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 62, "end": 73, "i_start": 13, "i_end": 13}}], "id": 2474}, {"sent": "for some special values of one of the parameters of the model , we were able to obtain the exact solution for the stable vacuum state and the value of the potential at the minimum .", "tokens": ["for", "some", "special", "values", "of", "one", "of", "the", "parameters", "of", "the", "model", ",", "we", "were", "able", "to", "obtain", "the", "exact", "solution", "for", "the", "stable", "vacuum", "state", "and", "the", "value", "of", "the", "potential", "at", "the", "minimum", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 64, "end": 66, "i_start": 13, "i_end": 13}, "verb": {"text": "were", "start": 67, "end": 71, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 13, "i_end": 13}, "action": {"text": "obtain", "start": 80, "end": 86, "i_start": 17, "i_end": 17}}], "id": 2475}, {"sent": "we use stochastic gradient descent with the adam solver to train our model .", "tokens": ["we", "use", "stochastic", "gradient", "descent", "with", "the", "adam", "solver", "to", "train", "our", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "solver", "start": 49, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 59, "end": 64, "i_start": 10, "i_end": 10}}], "id": 2476}, {"sent": "semisupervised learning techniques trains models with some labeled data and a much larger set of unlabeled data .", "tokens": ["semisupervised", "learning", "techniques", "trains", "models", "with", "some", "labeled", "data", "and", "a", "much", "larger", "set", "of", "unlabeled", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "techniques", "start": 24, "end": 34, "i_start": 2, "i_end": 2}, "action": {"text": "trains", "start": 35, "end": 41, "i_start": 3, "i_end": 3}}], "id": 2477}, {"sent": "deep neural networks have demonstrated their outstanding performance in different domains , ranging from image processing , text analysis to speech recognition .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "their", "outstanding", "performance", "in", "different", "domains", ",", "ranging", "from", "image", "processing", ",", "text", "analysis", "to", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 57, "end": 68, "i_start": 7, "i_end": 7}}], "id": 2478}, {"sent": "since then , many forward-secure cryptosystems were constructed , such as forward-secure signatures .", "tokens": ["since", "then", ",", "many", "forward", "-", "secure", "cryptosystems", "were", "constructed", ",", "such", "as", "forward", "-", "secure", "signatures", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many forward-secure cryptosystems", "start": 13, "end": 46, "i_start": 3, "i_end": 7}, "verb": {"text": "were constructed", "start": 47, "end": 63, "i_start": 8, "i_end": 9}}], "id": 2479}, {"sent": "based on the fdm in the spatial space , sis has been successfully applied to poiseuille flow using the bhatnagar-gross-krook kinetic model for single-species gases .", "tokens": ["based", "on", "the", "fdm", "in", "the", "spatial", "space", ",", "sis", "has", "been", "successfully", "applied", "to", "poiseuille", "flow", "using", "the", "bhatnagar", "-", "gross", "-", "krook", "kinetic", "model", "for", "single", "-", "species", "gases", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "sis", "start": 40, "end": 43, "i_start": 9, "i_end": 9}, "verb": {"text": "applied", "start": 66, "end": 73, "i_start": 13, "i_end": 13}}, {"subject": {"text": "sis", "start": 40, "end": 43, "i_start": 9, "i_end": 9}, "verb": {"text": "has been", "start": 44, "end": 52, "i_start": 10, "i_end": 11}}], "id": 2480}, {"sent": "convolutional neural networks have achieved tremendous progress on many pattern recognition tasks , especially large-scale images recognition problems .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "tremendous", "progress", "on", "many", "pattern", "recognition", "tasks", ",", "especially", "large", "-", "scale", "images", "recognition", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 2481}, {"sent": "most current constraint solvers , such as minion , are constructed to be as general as possible .", "tokens": ["most", "current", "constraint", "solvers", ",", "such", "as", "minion", ",", "are", "constructed", "to", "be", "as", "general", "as", "possible", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "most current constraint solvers", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "are constructed", "start": 51, "end": 66, "i_start": 9, "i_end": 10}}], "id": 2482}, {"sent": "ellipses denote 1 point 5\u03c3 confidence contours .", "tokens": ["ellipses", "denote", "1", "point", "5\u03c3", "confidence", "contours", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "ellipses", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "denote", "start": 9, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "ellipses", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 9, "end": 15, "i_start": 1, "i_end": 1}}], "id": 2483}, {"sent": "we employ a cosmological constant which is the simplest dark energy model that can account for the late time cosmic acceleration .", "tokens": ["we", "employ", "a", "cosmological", "constant", "which", "is", "the", "simplest", "dark", "energy", "model", "that", "can", "account", "for", "the", "late", "time", "cosmic", "acceleration", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "constant", "start": 25, "end": 33, "i_start": 4, "i_end": 4}, "action": {"text": "account", "start": 83, "end": 90, "i_start": 14, "i_end": 14}}], "id": 2484}, {"sent": "convolutional neural networks have been proven to achieve astonishing results in different research areas such as face recognition .", "tokens": ["convolutional", "neural", "networks", "have", "been", "proven", "to", "achieve", "astonishing", "results", "in", "different", "research", "areas", "such", "as", "face", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been proven", "start": 30, "end": 46, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 50, "end": 57, "i_start": 7, "i_end": 7}}, {"character": {"text": "results", "start": 70, "end": 77, "i_start": 9, "i_end": 9}, "action": {"text": "astonishing", "start": 58, "end": 69, "i_start": 8, "i_end": 8}}], "id": 2485}, {"sent": "the compressive sensing framework has sparked renewed interest in sampling and signal acquisition .", "tokens": ["the", "compressive", "sensing", "framework", "has", "sparked", "renewed", "interest", "in", "sampling", "and", "signal", "acquisition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the compressive sensing framework", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "has sparked", "start": 34, "end": 45, "i_start": 4, "i_end": 5}}, {"character": {"text": "framework", "start": 24, "end": 33, "i_start": 3, "i_end": 3}, "action": {"text": "sparked", "start": 38, "end": 45, "i_start": 5, "i_end": 5}}], "id": 2486}, {"sent": "latent dirichlet allocation is an example of a topic model used to describe collections of documents by sets of discovered topics .", "tokens": ["latent", "dirichlet", "allocation", "is", "an", "example", "of", "a", "topic", "model", "used", "to", "describe", "collections", "of", "documents", "by", "sets", "of", "discovered", "topics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "latent dirichlet allocation", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 3, "i_end": 3}}], "id": 2487}, {"sent": "all other intersection numbers depend on the triangulation .", "tokens": ["all", "other", "intersection", "numbers", "depend", "on", "the", "triangulation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "all other intersection numbers", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "depend", "start": 31, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "numbers", "start": 23, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "depend", "start": 31, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "numbers", "start": 23, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "intersection", "start": 10, "end": 22, "i_start": 2, "i_end": 2}}], "id": 2488}, {"sent": "we employ standard resnet50 as the backbone for frame feature extraction .", "tokens": ["we", "employ", "standard", "resnet50", "as", "the", "backbone", "for", "frame", "feature", "extraction", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 2489}, {"sent": "there are two activation rules for the neuron dynamics , namely sum-of-sum and sum-of-max .", "tokens": ["there", "are", "two", "activation", "rules", "for", "the", "neuron", "dynamics", ",", "namely", "sum", "-", "of", "-", "sum", "and", "sum", "-", "of", "-", "max", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 6, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "two activation rules", "start": 10, "end": 30, "i_start": 2, "i_end": 4}, "action": {"text": "activation", "start": 14, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2490}, {"sent": "there is a large number of approaches in the area of systems decomposition .", "tokens": ["there", "is", "a", "large", "number", "of", "approaches", "in", "the", "area", "of", "systems", "decomposition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2491}, {"sent": "devlin et al avoid the need for test cases by generating repairs with a rule based method and then ranking them using a neural network .", "tokens": ["devlin", "et", "al", "avoid", "the", "need", "for", "test", "cases", "by", "generating", "repairs", "with", "a", "rule", "based", "method", "and", "then", "ranking", "them", "using", "a", "neural", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "devlin et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "avoid", "start": 13, "end": 18, "i_start": 3, "i_end": 3}}, {"subject": {"text": "devlin et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "ranking", "start": 99, "end": 106, "i_start": 19, "i_end": 19}}, {"character": {"text": "devlin", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "avoid", "start": 13, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "devlin", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "generating", "start": 46, "end": 56, "i_start": 10, "i_end": 10}}, {"character": {"text": "devlin", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "ranking", "start": 99, "end": 106, "i_start": 19, "i_end": 19}}, {"character": {"text": "devlin", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 112, "end": 117, "i_start": 21, "i_end": 21}}], "id": 2492}, {"sent": "recently , convolutional neural network has achieved great success in computer vision tasks such as image classification in recent years .", "tokens": ["recently", ",", "convolutional", "neural", "network", "has", "achieved", "great", "success", "in", "computer", "vision", "tasks", "such", "as", "image", "classification", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural network", "start": 11, "end": 39, "i_start": 2, "i_end": 4}, "verb": {"text": "has achieved", "start": 40, "end": 52, "i_start": 5, "i_end": 6}}, {"character": {"text": "network", "start": 32, "end": 39, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 6, "i_end": 6}}, {"character": {"text": "network", "start": 32, "end": 39, "i_start": 4, "i_end": 4}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 8, "i_end": 8}}], "id": 2493}, {"sent": "noise-resistant lbp , robust lbpare used in noise reduction of lbp feature .", "tokens": ["noise", "-", "resistant", "lbp", ",", "robust", "lbpare", "used", "in", "noise", "reduction", "of", "lbp", "feature", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2494}, {"sent": "recent advances in machine learning and computer vision methods have provided robust frameworks that achieve significant gains in performance of face recognition systems .", "tokens": ["recent", "advances", "in", "machine", "learning", "and", "computer", "vision", "methods", "have", "provided", "robust", "frameworks", "that", "achieve", "significant", "gains", "in", "performance", "of", "face", "recognition", "systems", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "recent advances in machine learning and computer vision methods", "start": 0, "end": 63, "i_start": 0, "i_end": 8}, "verb": {"text": "have provided", "start": 64, "end": 77, "i_start": 9, "i_end": 10}}, {"character": {"text": "advances", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "provided", "start": 69, "end": 77, "i_start": 10, "i_end": 10}}, {"character": {"text": "frameworks", "start": 85, "end": 95, "i_start": 12, "i_end": 12}, "action": {"text": "achieve", "start": 101, "end": 108, "i_start": 14, "i_end": 14}}, {"character": {"text": "systems", "start": 162, "end": 169, "i_start": 22, "i_end": 22}, "action": {"text": "performance", "start": 130, "end": 141, "i_start": 18, "i_end": 18}}, {"character": {"text": "systems", "start": 162, "end": 169, "i_start": 22, "i_end": 22}, "action": {"text": "recognition", "start": 150, "end": 161, "i_start": 21, "i_end": 21}}], "id": 2495}, {"sent": "recently , banerjee et al introduced a novel ehrenfest scheme to investigate phase transitions of black holes in the grand canonical ensemble .", "tokens": ["recently", ",", "banerjee", "et", "al", "introduced", "a", "novel", "ehrenfest", "scheme", "to", "investigate", "phase", "transitions", "of", "black", "holes", "in", "the", "grand", "canonical", "ensemble", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "banerjee et al", "start": 11, "end": 25, "i_start": 2, "i_end": 4}, "verb": {"text": "introduced", "start": 26, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "banerjee", "start": 11, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 26, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "banerjee", "start": 11, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "investigate", "start": 65, "end": 76, "i_start": 11, "i_end": 11}}], "id": 2496}, {"sent": "in recent years , the success of deep learning has led to the emergence of a new set of techniques called deep rl that achieved important breakthroughs , reaching super-human level of play in many complex domains , including atari games .", "tokens": ["in", "recent", "years", ",", "the", "success", "of", "deep", "learning", "has", "led", "to", "the", "emergence", "of", "a", "new", "set", "of", "techniques", "called", "deep", "rl", "that", "achieved", "important", "breakthroughs", ",", "reaching", "super", "-", "human", "level", "of", "play", "in", "many", "complex", "domains", ",", "including", "atari", "games", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the success of deep learning", "start": 18, "end": 46, "i_start": 4, "i_end": 8}, "verb": {"text": "has led", "start": 47, "end": 54, "i_start": 9, "i_end": 10}}, {"character": {"text": "success", "start": 22, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "led", "start": 51, "end": 54, "i_start": 10, "i_end": 10}}, {"character": {"text": "learning", "start": 38, "end": 46, "i_start": 8, "i_end": 8}, "action": {"text": "success", "start": 22, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "set", "start": 81, "end": 84, "i_start": 17, "i_end": 17}, "action": {"text": "emergence", "start": 62, "end": 71, "i_start": 13, "i_end": 13}}, {"character": {"text": "techniques", "start": 88, "end": 98, "i_start": 19, "i_end": 19}, "action": {"text": "achieved", "start": 119, "end": 127, "i_start": 24, "i_end": 24}}, {"character": {"text": "techniques", "start": 88, "end": 98, "i_start": 19, "i_end": 19}, "action": {"text": "reaching", "start": 154, "end": 162, "i_start": 28, "i_end": 28}}], "id": 2497}, {"sent": "generalized dynamic programming methods in integer programming .", "tokens": ["generalized", "dynamic", "programming", "methods", "in", "integer", "programming", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2498}, {"sent": "finally , attention has also been used for both the image as well as the natural language question answering tasks .", "tokens": ["finally", ",", "attention", "has", "also", "been", "used", "for", "both", "the", "image", "as", "well", "as", "the", "natural", "language", "question", "answering", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "attention", "start": 10, "end": 19, "i_start": 2, "i_end": 2}, "verb": {"text": "been used", "start": 29, "end": 38, "i_start": 5, "i_end": 6}}, {"subject": {"text": "attention", "start": 10, "end": 19, "i_start": 2, "i_end": 2}, "verb": {"text": "has", "start": 20, "end": 23, "i_start": 3, "i_end": 3}}], "id": 2499}, {"sent": "bengio et al introduced a neural probabilistic language model that learns a distributed representation of words .", "tokens": ["bengio", "et", "al", "introduced", "a", "neural", "probabilistic", "language", "model", "that", "learns", "a", "distributed", "representation", "of", "words", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bengio et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "introduced", "start": 13, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "bengio", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 13, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "model", "start": 56, "end": 61, "i_start": 8, "i_end": 8}, "action": {"text": "learns", "start": 67, "end": 73, "i_start": 10, "i_end": 10}}], "id": 2500}, {"sent": "the axion a is a pseudo-goldstone boson from the spontaneous u p q symmetry breaking , with a decay constant fa .", "tokens": ["the", "axion", "a", "is", "a", "pseudo", "-", "goldstone", "boson", "from", "the", "spontaneous", "u", "p", "q", "symmetry", "breaking", ",", "with", "a", "decay", "constant", "fa", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the axion a", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 3, "i_end": 3}}], "id": 2501}, {"sent": "zhang et al propose a generic framework to integrate multi-level features into different resolutions for finer saliency maps .", "tokens": ["zhang", "et", "al", "propose", "a", "generic", "framework", "to", "integrate", "multi", "-", "level", "features", "into", "different", "resolutions", "for", "finer", "saliency", "maps", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhang et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}], "id": 2502}, {"sent": "the baer radical exactly is the maximal solvable ideal for every finite dimensional lie algebra .", "tokens": ["the", "baer", "radical", "exactly", "is", "the", "maximal", "solvable", "ideal", "for", "every", "finite", "dimensional", "lie", "algebra", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the baer radical", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 4, "i_end": 4}}], "id": 2503}, {"sent": "when the metric is calabi-yau , this form is parallel with respect to the metric connection .", "tokens": ["when", "the", "metric", "is", "calabi", "-", "yau", ",", "this", "form", "is", "parallel", "with", "respect", "to", "the", "metric", "connection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this form", "start": 32, "end": 41, "i_start": 8, "i_end": 9}, "verb": {"text": "is", "start": 42, "end": 44, "i_start": 10, "i_end": 10}}], "id": 2504}, {"sent": "in the gauge sector , plus the remaining scalar particle h , which is called the higgs boson .", "tokens": ["in", "the", "gauge", "sector", ",", "plus", "the", "remaining", "scalar", "particle", "h", ",", "which", "is", "called", "the", "higgs", "boson", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2505}, {"sent": "the video features were extracted with an inception v4 network , also trained on the imagenet dataset .", "tokens": ["the", "video", "features", "were", "extracted", "with", "an", "inception", "v4", "network", ",", "also", "trained", "on", "the", "imagenet", "dataset", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the video features", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "were extracted", "start": 19, "end": 33, "i_start": 3, "i_end": 4}}], "id": 2506}, {"sent": "the arcade learning environment bellemare et al , originally proposed in 2013 , is a suite of atari 2600 games which provides dozens of problems in which to train and evaluate rl agents .", "tokens": ["the", "arcade", "learning", "environment", "bellemare", "et", "al", ",", "originally", "proposed", "in", "2013", ",", "is", "a", "suite", "of", "atari", "2600", "games", "which", "provides", "dozens", "of", "problems", "in", "which", "to", "train", "and", "evaluate", "rl", "agents", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "games", "start": 105, "end": 110, "i_start": 19, "i_end": 19}, "action": {"text": "provides", "start": 117, "end": 125, "i_start": 21, "i_end": 21}}], "id": 2507}, {"sent": "in the authors presented a convex formulation of the problem using the minimum mean square error and applied it to higher modulation scheme in .", "tokens": ["in", "the", "authors", "presented", "a", "convex", "formulation", "of", "the", "problem", "using", "the", "minimum", "mean", "square", "error", "and", "applied", "it", "to", "higher", "modulation", "scheme", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "formulation", "start": 34, "end": 45, "i_start": 6, "i_end": 6}, "action": {"text": "using", "start": 61, "end": 66, "i_start": 10, "i_end": 10}}], "id": 2508}, {"sent": "the topological space xh icpt thus defined is called the canonical compactification of x over y .", "tokens": ["the", "topological", "space", "x"], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2509}, {"sent": "the spectrum of grbs prompt emission in the kev-mev energy range is typically described by the empirical band function .", "tokens": ["the", "spectrum", "of", "grbs", "prompt", "emission", "in", "the", "kev", "-", "mev", "energy", "range", "is", "typically", "described", "by", "the", "empirical", "band", "function", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "the spectrum of grbs prompt emission in the kev-mev energy range", "start": 0, "end": 64, "i_start": 0, "i_end": 12}, "verb": {"text": "described", "start": 78, "end": 87, "i_start": 15, "i_end": 15}}, {"subject": {"text": "the spectrum of grbs prompt emission in the kev-mev energy range", "start": 0, "end": 64, "i_start": 0, "i_end": 12}, "verb": {"text": "is", "start": 65, "end": 67, "i_start": 13, "i_end": 13}}, {"character": {"text": "function", "start": 110, "end": 118, "i_start": 20, "i_end": 20}, "action": {"text": "described", "start": 78, "end": 87, "i_start": 15, "i_end": 15}}], "id": 2510}, {"sent": "deep neural networks have been evolved to powerful predictive models with remarkable performance on computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "been", "evolved", "to", "powerful", "predictive", "models", "with", "remarkable", "performance", "on", "computer", "vision", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been evolved", "start": 21, "end": 38, "i_start": 3, "i_end": 5}}, {"character": {"text": "models", "start": 62, "end": 68, "i_start": 9, "i_end": 9}, "action": {"text": "predictive", "start": 51, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "models", "start": 62, "end": 68, "i_start": 9, "i_end": 9}, "action": {"text": "performance", "start": 85, "end": 96, "i_start": 12, "i_end": 12}}], "id": 2511}, {"sent": "we now proceed on to define radical for groupoid rings .", "tokens": ["we", "now", "proceed", "on", "to", "define", "radical", "for", "groupoid", "rings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "proceed on", "start": 7, "end": 17, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "define", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 2512}, {"sent": "deep features learned by cnns can disentangle explanatory factors of variations behind data distributions to boost knowledge transfer .", "tokens": ["deep", "features", "learned", "by", "cnns", "can", "disentangle", "explanatory", "factors", "of", "variations", "behind", "data", "distributions", "to", "boost", "knowledge", "transfer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep features learned by cnns", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "can disentangle", "start": 30, "end": 45, "i_start": 5, "i_end": 6}}, {"character": {"text": "features", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "disentangle", "start": 34, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "factors", "start": 58, "end": 65, "i_start": 8, "i_end": 8}, "action": {"text": "explanatory", "start": 46, "end": 57, "i_start": 7, "i_end": 7}}, {"character": {"text": "features", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "boost", "start": 109, "end": 114, "i_start": 15, "i_end": 15}}], "id": 2513}, {"sent": "dft simulations were performed via the projected augmented wave method as implemented in the vasp program .", "tokens": ["dft", "simulations", "were", "performed", "via", "the", "projected", "augmented", "wave", "method", "as", "implemented", "in", "the", "vasp", "program", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dft simulations", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "were performed", "start": 16, "end": 30, "i_start": 2, "i_end": 3}}, {"character": {"text": "program", "start": 98, "end": 105, "i_start": 15, "i_end": 15}, "action": {"text": "implemented", "start": 74, "end": 85, "i_start": 11, "i_end": 11}}], "id": 2514}, {"sent": "we initialized the contractive path with pre-trained weights of the imagenet dataset .", "tokens": ["we", "initialized", "the", "contractive", "path", "with", "pre", "-", "trained", "weights", "of", "the", "imagenet", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "initialized", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "initialized", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}], "id": 2515}, {"sent": "multi-head attention is more beneficial than a single attention function .", "tokens": ["multi", "-", "head", "attention", "is", "more", "beneficial", "than", "a", "single", "attention", "function", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "multi-head attention", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "head", "start": 6, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "attention", "start": 11, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "attention", "start": 11, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "beneficial", "start": 29, "end": 39, "i_start": 6, "i_end": 6}}], "id": 2516}, {"sent": "faster r-cnn proposes object bounding boxes directly from the convolutional features .", "tokens": ["faster", "r", "-", "cnn", "proposes", "object", "bounding", "boxes", "directly", "from", "the", "convolutional", "features", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "-cnn", "start": 8, "end": 12, "i_start": 2, "i_end": 3}, "verb": {"text": "proposes", "start": 13, "end": 21, "i_start": 4, "i_end": 4}}], "id": 2517}, {"sent": "gravitational waves is the landau-lifshitz pseudo-tensor .", "tokens": ["gravitational", "waves", "is", "the", "landau", "-", "lifshitz", "pseudo", "-", "tensor", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "gravitational waves", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 2, "i_end": 2}}], "id": 2518}, {"sent": "it is interesting that the kinetic energy gain does not occur in the electron-doped region .", "tokens": ["it", "is", "interesting", "that", "the", "kinetic", "energy", "gain", "does", "not", "occur", "in", "the", "electron", "-", "doped", "region", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the kinetic energy gain", "start": 23, "end": 46, "i_start": 4, "i_end": 7}, "verb": {"text": "occur", "start": 56, "end": 61, "i_start": 10, "i_end": 10}}], "id": 2519}, {"sent": "the package directly interfaces with post-dmft packages such as abinitiodga 71 and ladderdga .", "tokens": ["the", "package", "directly", "interfaces", "with", "post", "-", "dmft", "packages", "such", "as", "abinitiodga", "71", "and", "ladderdga", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the package", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "interfaces", "start": 21, "end": 31, "i_start": 3, "i_end": 3}}, {"character": {"text": "package", "start": 4, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "interfaces", "start": 21, "end": 31, "i_start": 3, "i_end": 3}}], "id": 2520}, {"sent": "model-agnostic meta-learning aims to train a model on a variety of learning tasks and solve a new task using only a few training examples .", "tokens": ["model", "-", "agnostic", "meta", "-", "learning", "aims", "to", "train", "a", "model", "on", "a", "variety", "of", "learning", "tasks", "and", "solve", "a", "new", "task", "using", "only", "a", "few", "training", "examples", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "meta-learning", "start": 15, "end": 28, "i_start": 3, "i_end": 5}, "verb": {"text": "aims", "start": 29, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "learning", "start": 67, "end": 75, "i_start": 15, "i_end": 15}, "action": {"text": "aims", "start": 29, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "learning", "start": 67, "end": 75, "i_start": 15, "i_end": 15}, "action": {"text": "train", "start": 37, "end": 42, "i_start": 8, "i_end": 8}}, {"character": {"text": "learning", "start": 67, "end": 75, "i_start": 15, "i_end": 15}, "action": {"text": "solve", "start": 86, "end": 91, "i_start": 18, "i_end": 18}}, {"character": {"text": "learning", "start": 67, "end": 75, "i_start": 15, "i_end": 15}, "action": {"text": "using", "start": 103, "end": 108, "i_start": 22, "i_end": 22}}], "id": 2521}, {"sent": "the object copy located at the origin server is called the origin copy and an object copy at any remaining server is called a replica .", "tokens": ["the", "object", "copy", "located", "at", "the", "origin", "server", "is", "called", "the", "origin", "copy", "and", "an", "object", "copy", "at", "any", "remaining", "server", "is", "called", "a", "replica", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the object copy located at the origin server", "start": 0, "end": 44, "i_start": 0, "i_end": 7}, "verb": {"text": "is called", "start": 45, "end": 54, "i_start": 8, "i_end": 9}}, {"subject": {"text": "an object copy at any remaining server", "start": 75, "end": 113, "i_start": 14, "i_end": 20}, "verb": {"text": "called", "start": 117, "end": 123, "i_start": 22, "i_end": 22}}], "id": 2522}, {"sent": "the class of dual divergences estimators has been recently introduced by keziou , broniatowski and keziou .", "tokens": ["the", "class", "of", "dual", "divergences", "estimators", "has", "been", "recently", "introduced", "by", "keziou", ",", "broniatowski", "and", "keziou", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the class of dual divergences estimators", "start": 0, "end": 40, "i_start": 0, "i_end": 5}, "verb": {"text": "introduced", "start": 59, "end": 69, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the class of dual divergences estimators", "start": 0, "end": 40, "i_start": 0, "i_end": 5}, "verb": {"text": "has been", "start": 41, "end": 49, "i_start": 6, "i_end": 7}}, {"character": {"text": "keziou", "start": 73, "end": 79, "i_start": 11, "i_end": 11}, "action": {"text": "introduced", "start": 59, "end": 69, "i_start": 9, "i_end": 9}}, {"character": {"text": "broniatowski", "start": 82, "end": 94, "i_start": 13, "i_end": 13}, "action": {"text": "introduced", "start": 59, "end": 69, "i_start": 9, "i_end": 9}}, {"character": {"text": "keziou", "start": 73, "end": 79, "i_start": 11, "i_end": 11}, "action": {"text": "introduced", "start": 59, "end": 69, "i_start": 9, "i_end": 9}}, {"character": {"text": "keziou", "start": 73, "end": 79, "i_start": 11, "i_end": 11}, "action": {"text": "introduced", "start": 59, "end": 69, "i_start": 9, "i_end": 9}}], "id": 2523}, {"sent": "if a continuum is a union of two funnel sections then it is a funnel section in one dimension up .", "tokens": ["if", "a", "continuum", "is", "a", "union", "of", "two", "funnel", "sections", "then", "it", "is", "a", "funnel", "section", "in", "one", "dimension", "up", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 54, "end": 56, "i_start": 11, "i_end": 11}, "verb": {"text": "is", "start": 57, "end": 59, "i_start": 12, "i_end": 12}}], "id": 2524}, {"sent": "it has been used with great success for both phoneme recognition and characterbased lvcsr .", "tokens": ["it", "has", "been", "used", "with", "great", "success", "for", "both", "phoneme", "recognition", "and", "characterbased", "lvcsr", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has been used", "start": 3, "end": 16, "i_start": 1, "i_end": 3}}], "id": 2525}, {"sent": "convolutional neural networks are very effective techniques for image classification for various important real-world applications .", "tokens": ["convolutional", "neural", "networks", "are", "very", "effective", "techniques", "for", "image", "classification", "for", "various", "important", "real", "-", "world", "applications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 3, "i_end": 3}}, {"character": {"text": "techniques", "start": 49, "end": 59, "i_start": 6, "i_end": 6}, "action": {"text": "effective", "start": 39, "end": 48, "i_start": 5, "i_end": 5}}], "id": 2526}, {"sent": "this stratification is the analogue of the shatz stratification in the theory of holomorphic vector bundles .", "tokens": ["this", "stratification", "is", "the", "analogue", "of", "the", "shatz", "stratification", "in", "the", "theory", "of", "holomorphic", "vector", "bundles", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this stratification", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 2, "i_end": 2}}], "id": 2527}, {"sent": "the attentive filtering network is initialized with xavier initialization .", "tokens": ["the", "attentive", "filtering", "network", "is", "initialized", "with", "xavier", "initialization", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the attentive filtering network", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "is initialized", "start": 32, "end": 46, "i_start": 4, "i_end": 5}}, {"character": {"text": "network", "start": 24, "end": 31, "i_start": 3, "i_end": 3}, "action": {"text": "filtering", "start": 14, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "network", "start": 24, "end": 31, "i_start": 3, "i_end": 3}, "action": {"text": "attentive", "start": 4, "end": 13, "i_start": 1, "i_end": 1}}], "id": 2528}, {"sent": "conversely , in several applications we would like to consider tight frames that have some other prescribed properties leading to what is known in the literature as frame design problems .", "tokens": ["conversely", ",", "in", "several", "applications", "we", "would", "like", "to", "consider", "tight", "frames", "that", "have", "some", "other", "prescribed", "properties", "leading", "to", "what", "is", "known", "in", "the", "literature", "as", "frame", "design", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 37, "end": 39, "i_start": 5, "i_end": 5}, "verb": {"text": "would like", "start": 40, "end": 50, "i_start": 6, "i_end": 7}}, {"character": {"text": "we", "start": 37, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "like", "start": 46, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 37, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "consider", "start": 54, "end": 62, "i_start": 9, "i_end": 9}}, {"character": {"text": "frames", "start": 69, "end": 75, "i_start": 11, "i_end": 11}, "action": {"text": "have", "start": 81, "end": 85, "i_start": 13, "i_end": 13}}, {"character": {"text": "have", "start": 81, "end": 85, "i_start": 13, "i_end": 13}, "action": {"text": "leading", "start": 119, "end": 126, "i_start": 18, "i_end": 18}}, {"character": {"text": "literature", "start": 151, "end": 161, "i_start": 25, "i_end": 25}, "action": {"text": "known", "start": 138, "end": 143, "i_start": 22, "i_end": 22}}], "id": 2529}, {"sent": "convolutional neural networks have achieved superior performance in many visual tasks , such as object detection and segmentation .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "detection", "and", "segmentation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 6, "i_end": 6}}], "id": 2530}, {"sent": "the author also proved that superinjective simplicial maps of the complexes of curves on nonorientable surfaces are induced by homeomorphisms in .", "tokens": ["the", "author", "also", "proved", "that", "superinjective", "simplicial", "maps", "of", "the", "complexes", "of", "curves", "on", "nonorientable", "surfaces", "are", "induced", "by", "homeomorphisms", "in", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the author", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "proved", "start": 16, "end": 22, "i_start": 3, "i_end": 3}}, {"subject": {"text": "superinjective simplicial maps of the complexes of curves on nonorientable surfaces", "start": 28, "end": 111, "i_start": 5, "i_end": 15}, "verb": {"text": "induced", "start": 116, "end": 123, "i_start": 17, "i_end": 17}}, {"character": {"text": "homeomorphisms", "start": 127, "end": 141, "i_start": 19, "i_end": 19}, "action": {"text": "induced", "start": 116, "end": 123, "i_start": 17, "i_end": 17}}], "id": 2531}, {"sent": "indeed , this hamiltonian arises from the chern-simons formulation of ads 3 gravity when imposing brown-henneaux boundary conditions .", "tokens": ["indeed", ",", "this", "hamiltonian", "arises", "from", "the", "chern", "-", "simons", "formulation", "of", "ads", "3", "gravity", "when", "imposing", "brown", "-", "henneaux", "boundary", "conditions", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this hamiltonian", "start": 9, "end": 25, "i_start": 2, "i_end": 3}, "verb": {"text": "arises", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "formulation", "start": 55, "end": 66, "i_start": 10, "i_end": 10}, "action": {"text": "arises", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "chern", "start": 42, "end": 47, "i_start": 7, "i_end": 7}, "action": {"text": "formulation", "start": 55, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "chern", "start": 42, "end": 47, "i_start": 7, "i_end": 7}, "action": {"text": "imposing", "start": 89, "end": 97, "i_start": 16, "i_end": 16}}], "id": 2532}, {"sent": "the isomorphism considered here is the labeled isomorphism , ie labels of the internal nodes , 0 or 1 , are preserved .", "tokens": ["the", "isomorphism", "considered", "here", "is", "the", "labeled", "isomorphism", ",", "ie", "labels", "of", "the", "internal", "nodes", ",", "0", "or", "1", ",", "are", "preserved", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the isomorphism considered here", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the labeled isomorphism", "start": 35, "end": 58, "i_start": 5, "i_end": 7}, "verb": {"text": "preserved", "start": 108, "end": 117, "i_start": 21, "i_end": 21}}], "id": 2533}, {"sent": "so , the set of matrices is a differential algebraic group .", "tokens": ["so", ",", "the", "set", "of", "matrices", "is", "a", "differential", "algebraic", "group", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the set of matrices", "start": 5, "end": 24, "i_start": 2, "i_end": 5}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 6, "i_end": 6}}], "id": 2534}, {"sent": "ldpc codes were first defined by gallager who suggested several messagepassing iterative decoding algorithms .", "tokens": ["ldpc", "codes", "were", "first", "defined", "by", "gallager", "who", "suggested", "several", "messagepassing", "iterative", "decoding", "algorithms", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "ldpc codes", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "defined", "start": 22, "end": 29, "i_start": 4, "i_end": 4}}, {"subject": {"text": "ldpc codes", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "were", "start": 11, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "gallager", "start": 33, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "defined", "start": 22, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "iterative", "start": 79, "end": 88, "i_start": 11, "i_end": 11}, "action": {"text": "defined", "start": 22, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "several", "start": 56, "end": 63, "i_start": 9, "i_end": 9}, "action": {"text": "defined", "start": 22, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "algorithms", "start": 98, "end": 108, "i_start": 13, "i_end": 13}, "action": {"text": "decoding", "start": 89, "end": 97, "i_start": 12, "i_end": 12}}], "id": 2535}, {"sent": "the inflaton is the separation between a d3-brane and an anti-d3-brane , whose annihilation leads to reheating .", "tokens": ["the", "inflaton", "is", "the", "separation", "between", "a", "d3", "-", "brane", "and", "an", "anti", "-", "d3", "-", "brane", ",", "whose", "annihilation", "leads", "to", "reheating", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the inflaton", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "brane", "start": 65, "end": 70, "i_start": 16, "i_end": 16}, "action": {"text": "anti", "start": 57, "end": 61, "i_start": 12, "i_end": 12}}, {"character": {"text": "annihilation", "start": 79, "end": 91, "i_start": 19, "i_end": 19}, "action": {"text": "leads", "start": 92, "end": 97, "i_start": 20, "i_end": 20}}], "id": 2536}, {"sent": "faster r-cnn introduces a region proposal network which integrates feature extraction and region proposal in a single network .", "tokens": ["faster", "r", "-", "cnn", "introduces", "a", "region", "proposal", "network", "which", "integrates", "feature", "extraction", "and", "region", "proposal", "in", "a", "single", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "-cnn", "start": 8, "end": 12, "i_start": 2, "i_end": 3}, "verb": {"text": "introduces", "start": 13, "end": 23, "i_start": 4, "i_end": 4}}], "id": 2537}, {"sent": "on one hand , we reproduce the results of chen et al , which noticed that the msda representations gave greater pad values than those obtained with the original data .", "tokens": ["on", "one", "hand", ",", "we", "reproduce", "the", "results", "of", "chen", "et", "al", ",", "which", "noticed", "that", "the", "msda", "representations", "gave", "greater", "pad", "values", "than", "those", "obtained", "with", "the", "original", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "verb": {"text": "reproduce", "start": 17, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "reproduce", "start": 17, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "representations", "start": 83, "end": 98, "i_start": 18, "i_end": 18}, "action": {"text": "gave", "start": 99, "end": 103, "i_start": 19, "i_end": 19}}], "id": 2538}, {"sent": "the asymmetry is a subdominant power-law too , with an exponent that we determine .", "tokens": ["the", "asymmetry", "is", "a", "subdominant", "power", "-", "law", "too", ",", "with", "an", "exponent", "that", "we", "determine", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the asymmetry", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 69, "end": 71, "i_start": 14, "i_end": 14}, "action": {"text": "determine", "start": 72, "end": 81, "i_start": 15, "i_end": 15}}], "id": 2539}, {"sent": "later , kauffman introduced the notion of a virtual knot , which is an extension of classical knot theory .", "tokens": ["later", ",", "kauffman", "introduced", "the", "notion", "of", "a", "virtual", "knot", ",", "which", "is", "an", "extension", "of", "classical", "knot", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "kauffman", "start": 8, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "introduced", "start": 17, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "kauffman", "start": 8, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 17, "end": 27, "i_start": 3, "i_end": 3}}], "id": 2540}, {"sent": "for autonomous deterministic lattice dynamical systems , we can see egfor the existence and approximations of attractors .", "tokens": ["for", "autonomous", "deterministic", "lattice", "dynamical", "systems", ",", "we", "can", "see", "egfor", "the", "existence", "and", "approximations", "of", "attractors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 57, "end": 59, "i_start": 7, "i_end": 7}, "verb": {"text": "can see", "start": 60, "end": 67, "i_start": 8, "i_end": 9}}, {"character": {"text": "we", "start": 57, "end": 59, "i_start": 7, "i_end": 7}, "action": {"text": "see", "start": 64, "end": 67, "i_start": 9, "i_end": 9}}], "id": 2541}, {"sent": "we can now determine bounds on an achievable rate region that employs the above coding strategy .", "tokens": ["we", "can", "now", "determine", "bounds", "on", "an", "achievable", "rate", "region", "that", "employs", "the", "above", "coding", "strategy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "determine", "start": 11, "end": 20, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "can", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "determine", "start": 11, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "region", "start": 50, "end": 56, "i_start": 9, "i_end": 9}, "action": {"text": "employs", "start": 62, "end": 69, "i_start": 11, "i_end": 11}}], "id": 2542}, {"sent": "the blue squares are the moving obstacles .", "tokens": ["the", "blue", "squares", "are", "the", "moving", "obstacles", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the blue squares", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 17, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "obstacles", "start": 32, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "moving", "start": 25, "end": 31, "i_start": 5, "i_end": 5}}], "id": 2543}, {"sent": "cosmic strings are topologically stable objects which may have formed during the breaking of a local ugauge symmetry in the very early universe .", "tokens": ["cosmic", "strings", "are", "topologically", "stable", "objects", "which", "may", "have", "formed", "during", "the", "breaking", "of", "a", "local", "ugauge", "symmetry", "in", "the", "very", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}], "id": 2544}, {"sent": "deep neural networks have shown remarkable success in many computer vision tasks such as image classification .", "tokens": ["deep", "neural", "networks", "have", "shown", "remarkable", "success", "in", "many", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}], "id": 2545}, {"sent": "in the last decade , convolutional neural networks have shown state of the art accuracy on a variety of visual recognition tasks such as image classification .", "tokens": ["in", "the", "last", "decade", ",", "convolutional", "neural", "networks", "have", "shown", "state", "of", "the", "art", "accuracy", "on", "a", "variety", "of", "visual", "recognition", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 21, "end": 50, "i_start": 5, "i_end": 7}, "verb": {"text": "have shown", "start": 51, "end": 61, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 42, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "shown", "start": 56, "end": 61, "i_start": 9, "i_end": 9}}], "id": 2546}, {"sent": "in recent years , throughout a series of breakthrough algorithms , convolutional neural networks significantly improved the state-of-the-art in large-scale image recognition tasks .", "tokens": ["in", "recent", "years", ",", "throughout", "a", "series", "of", "breakthrough", "algorithms", ",", "convolutional", "neural", "networks", "significantly", "improved", "the", "state", "-", "of", "-", "the", "-", "art", "in", "large", "-", "scale", "image", "recognition", "tasks", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 67, "end": 96, "i_start": 11, "i_end": 13}, "verb": {"text": "improved", "start": 111, "end": 119, "i_start": 15, "i_end": 15}}, {"character": {"text": "networks", "start": 88, "end": 96, "i_start": 13, "i_end": 13}, "action": {"text": "improved", "start": 111, "end": 119, "i_start": 15, "i_end": 15}}, {"character": {"text": "algorithms", "start": 54, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "breakthrough", "start": 41, "end": 53, "i_start": 8, "i_end": 8}}], "id": 2547}, {"sent": "recently , deep neural networks have led to significant improvement in several machine learning domains , from speech recognition to computer vision and machine translation .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "led", "to", "significant", "improvement", "in", "several", "machine", "learning", "domains", ",", "from", "speech", "recognition", "to", "computer", "vision", "and", "machine", "translation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have led", "start": 32, "end": 40, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "led", "start": 37, "end": 40, "i_start": 6, "i_end": 6}}], "id": 2548}, {"sent": "a pacific asian cluster is formed between hong kong , singapore , and indonesia .", "tokens": ["a", "pacific", "asian", "cluster", "is", "formed", "between", "hong", "kong", ",", "singapore", ",", "and", "indonesia", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a pacific asian cluster", "start": 0, "end": 23, "i_start": 0, "i_end": 3}, "verb": {"text": "is formed", "start": 24, "end": 33, "i_start": 4, "i_end": 5}}], "id": 2549}, {"sent": "since then there have been some studies of various classes of boolean functions which are particularly suited to the logical expression of gene regulation .", "tokens": ["since", "then", "there", "have", "been", "some", "studies", "of", "various", "classes", "of", "boolean", "functions", "which", "are", "particularly", "suited", "to", "the", "logical", "expression", "of", "gene", "regulation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "have been", "start": 17, "end": 26, "i_start": 3, "i_end": 4}}], "id": 2550}, {"sent": "quantum entanglement and communication complexity .", "tokens": ["quantum", "entanglement", "and", "communication", "complexity", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2551}, {"sent": "the data were fit with the x-ray spectral analysis tool xspec .", "tokens": ["the", "data", "were", "fit", "with", "the", "x", "-", "ray", "spectral", "analysis", "tool", "xspec", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "were", "start": 9, "end": 13, "i_start": 2, "i_end": 2}}], "id": 2552}, {"sent": "while mutual information is a well-established approach to evaluating the interactions between two attributes , we surveyed its generalizations as to quantify interactions between several attributes .", "tokens": ["while", "mutual", "information", "is", "a", "well", "-", "established", "approach", "to", "evaluating", "the", "interactions", "between", "two", "attributes", ",", "we", "surveyed", "its", "generalizations", "as", "to", "quantify", "interactions", "between", "several", "attributes", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 112, "end": 114, "i_start": 17, "i_end": 17}, "verb": {"text": "surveyed", "start": 115, "end": 123, "i_start": 18, "i_end": 18}}, {"character": {"text": "we", "start": 112, "end": 114, "i_start": 17, "i_end": 17}, "action": {"text": "surveyed", "start": 115, "end": 123, "i_start": 18, "i_end": 18}}, {"character": {"text": "information", "start": 13, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "generalizations", "start": 128, "end": 143, "i_start": 20, "i_end": 20}}, {"character": {"text": "information", "start": 13, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "quantify", "start": 150, "end": 158, "i_start": 23, "i_end": 23}}, {"character": {"text": "attributes", "start": 99, "end": 109, "i_start": 15, "i_end": 15}, "action": {"text": "interactions", "start": 74, "end": 86, "i_start": 12, "i_end": 12}}], "id": 2553}, {"sent": "the bfss matrix theory of is based on a discrete light cone quantization of m-theory with a compact circle .", "tokens": ["the", "bfss", "matrix", "theory", "of", "is", "based", "on", "a", "discrete", "light", "cone", "quantization", "of", "m", "-", "theory", "with", "a", "compact", "circle", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the bfss matrix theory of", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "is based", "start": 26, "end": 34, "i_start": 5, "i_end": 6}}], "id": 2554}, {"sent": "throughout the paper the notation we employ is standard and as in .", "tokens": ["throughout", "the", "paper", "the", "notation", "we", "employ", "is", "standard", "and", "as", "in", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the notation we employ", "start": 21, "end": 43, "i_start": 3, "i_end": 6}, "verb": {"text": "is", "start": 44, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 5, "i_end": 5}, "action": {"text": "employ", "start": 37, "end": 43, "i_start": 6, "i_end": 6}}], "id": 2555}, {"sent": "deep neural networks have been significantly successful in many artificial intelligence tasks such as im- age classification .", "tokens": ["deep", "neural", "networks", "have", "been", "significantly", "successful", "in", "many", "artificial", "intelligence", "tasks", "such", "as", "im-", "age", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 45, "end": 55, "i_start": 6, "i_end": 6}}], "id": 2556}, {"sent": "diffusion coefficient is a good approximation for strong shocks .", "tokens": ["diffusion", "coefficient", "is", "a", "good", "approximation", "for", "strong", "shocks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "diffusion coefficient", "start": 0, "end": 21, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 2, "i_end": 2}}], "id": 2557}, {"sent": "to prove our statement quantitatively we compare our flow fields with different number of hierarchy levels k to the state-of-the-art annf approach presented in .", "tokens": ["to", "prove", "our", "statement", "quantitatively", "we", "compare", "our", "flow", "fields", "with", "different", "number", "of", "hierarchy", "levels", "k", "to", "the", "state", "-", "of", "-", "the", "-", "art", "annf", "approach", "presented", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 38, "end": 40, "i_start": 5, "i_end": 5}, "verb": {"text": "compare", "start": 41, "end": 48, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 38, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "compare", "start": 41, "end": 48, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 38, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "prove", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 38, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "state", "start": 116, "end": 121, "i_start": 19, "i_end": 19}}], "id": 2558}, {"sent": "convolutional neural networks , cnn , have recently achieved state of the art performance in a number of computer vision tasks .", "tokens": ["convolutional", "neural", "networks", ",", "cnn", ",", "have", "recently", "achieved", "state", "of", "the", "art", "performance", "in", "a", "number", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 52, "end": 60, "i_start": 8, "i_end": 8}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 38, "end": 42, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 52, "end": 60, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 78, "end": 89, "i_start": 13, "i_end": 13}}], "id": 2559}, {"sent": "deep neural networks have been evolved to powerful predictive models with remarkable performance on computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "been", "evolved", "to", "powerful", "predictive", "models", "with", "remarkable", "performance", "on", "computer", "vision", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been evolved", "start": 21, "end": 38, "i_start": 3, "i_end": 5}}, {"character": {"text": "models", "start": 62, "end": 68, "i_start": 9, "i_end": 9}, "action": {"text": "predictive", "start": 51, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "models", "start": 62, "end": 68, "i_start": 9, "i_end": 9}, "action": {"text": "performance", "start": 85, "end": 96, "i_start": 12, "i_end": 12}}], "id": 2560}, {"sent": "in , floater and reimers proposed the meshless parameterization method for unorganized point sets .", "tokens": ["in", ",", "floater", "and", "reimers", "proposed", "the", "meshless", "parameterization", "method", "for", "unorganized", "point", "sets", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "floater and reimers", "start": 5, "end": 24, "i_start": 2, "i_end": 4}, "verb": {"text": "proposed", "start": 25, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "floater", "start": 5, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "proposed", "start": 25, "end": 33, "i_start": 5, "i_end": 5}}], "id": 2561}, {"sent": "in this section , we evaluate our approach for video object detection on the imagenet vid dataset , which has 3 , 862 and 555 training and testing video clips respectively .", "tokens": ["in", "this", "section", ",", "we", "evaluate", "our", "approach", "for", "video", "object", "detection", "on", "the", "imagenet", "vid", "dataset", ",", "which", "has", "3", ",", "862", "and", "555", "training", "and", "testing", "video", "clips", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "evaluate", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "evaluate", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "approach", "start": 34, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "video", "start": 147, "end": 152, "i_start": 28, "i_end": 28}, "action": {"text": "has", "start": 106, "end": 109, "i_start": 19, "i_end": 19}}], "id": 2562}, {"sent": "in addition to these , awodey and warren found out that types may also be regarded as , roughly speaking , topological spaces .", "tokens": ["in", "addition", "to", "these", ",", "awodey", "and", "warren", "found", "out", "that", "types", "may", "also", "be", "regarded", "as", ",", "roughly", "speaking", ",", "topological", "spaces", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "types", "start": 56, "end": 61, "i_start": 11, "i_end": 11}, "verb": {"text": "found out", "start": 41, "end": 50, "i_start": 8, "i_end": 9}}, {"subject": {"text": "types", "start": 56, "end": 61, "i_start": 11, "i_end": 11}, "verb": {"text": "regarded", "start": 74, "end": 82, "i_start": 15, "i_end": 15}}, {"character": {"text": "awodey", "start": 23, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "found", "start": 41, "end": 46, "i_start": 8, "i_end": 8}}, {"character": {"text": "warren", "start": 34, "end": 40, "i_start": 7, "i_end": 7}, "action": {"text": "found", "start": 41, "end": 46, "i_start": 8, "i_end": 8}}], "id": 2563}, {"sent": "we use a 6-layer resnet architecture to regress the xyz directions of light at each vertex from the features at the bottleneck layer of unet network .", "tokens": ["we", "use", "a", "6", "-", "layer", "resnet", "architecture", "to", "regress", "the", "xyz", "directions", "of", "light", "at", "each", "vertex", "from", "the", "features", "at", "the", "bottleneck", "layer", "of", "unet", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "regress", "start": 40, "end": 47, "i_start": 9, "i_end": 9}}, {"character": {"text": "layer", "start": 127, "end": 132, "i_start": 24, "i_end": 24}, "action": {"text": "bottleneck", "start": 116, "end": 126, "i_start": 23, "i_end": 23}}], "id": 2564}, {"sent": "the network weights were randomly initialized using the uniform glorot initialization method .", "tokens": ["the", "network", "weights", "were", "randomly", "initialized", "using", "the", "uniform", "glorot", "initialization", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the network weights", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "initialized", "start": 34, "end": 45, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the network weights", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "were", "start": 20, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2565}, {"sent": "in a second example , michel et al presented a method for predicting behavior from fmri images using total variation penalty .", "tokens": ["in", "a", "second", "example", ",", "michel", "et", "al", "presented", "a", "method", "for", "predicting", "behavior", "from", "fmri", "images", "using", "total", "variation", "penalty", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "michel et al", "start": 22, "end": 34, "i_start": 5, "i_end": 7}, "verb": {"text": "presented", "start": 35, "end": 44, "i_start": 8, "i_end": 8}}, {"character": {"text": "michel", "start": 22, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "presented", "start": 35, "end": 44, "i_start": 8, "i_end": 8}}], "id": 2566}, {"sent": "now we will define s-subsemirings and s-ideals using interval matrix semirings .", "tokens": ["now", "we", "will", "define", "s", "-", "subsemirings", "and", "s", "-", "ideals", "using", "interval", "matrix", "semirings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "will define", "start": 7, "end": 18, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 12, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "using", "start": 47, "end": 52, "i_start": 11, "i_end": 11}}], "id": 2567}, {"sent": "the exchange correlation energy was described by the generalized gradient approximation using the pbe functional .", "tokens": ["the", "exchange", "correlation", "energy", "was", "described", "by", "the", "generalized", "gradient", "approximation", "using", "the", "pbe", "functional", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the exchange correlation energy", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "was described", "start": 32, "end": 45, "i_start": 4, "i_end": 5}}, {"character": {"text": "approximation", "start": 74, "end": 87, "i_start": 10, "i_end": 10}, "action": {"text": "described", "start": 36, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "approximation", "start": 74, "end": 87, "i_start": 10, "i_end": 10}, "action": {"text": "using", "start": 88, "end": 93, "i_start": 11, "i_end": 11}}], "id": 2568}, {"sent": "the correspondences are typically obtained by matching local features such as sift .", "tokens": ["the", "correspondences", "are", "typically", "obtained", "by", "matching", "local", "features", "such", "as", "sift", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the correspondences", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "obtained", "start": 34, "end": 42, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the correspondences", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 20, "end": 23, "i_start": 2, "i_end": 2}}], "id": 2569}, {"sent": "the hpcg benchmark , for example , shows that krylov subspace methods are able to attain only a small fraction of the machine peak performance on large-scale hardware .", "tokens": ["the", "hpcg", "benchmark", ",", "for", "example", ",", "shows", "that", "krylov", "subspace", "methods", "are", "able", "to", "attain", "only", "a", "small", "fraction", "of", "the", "machine", "peak", "performance", "on", "large", "-", "scale", "hardware", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the hpcg benchmark", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "shows", "start": 35, "end": 40, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the hpcg benchmark", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 70, "end": 73, "i_start": 12, "i_end": 12}}, {"character": {"text": "benchmark", "start": 9, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "shows", "start": 35, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "methods", "start": 62, "end": 69, "i_start": 11, "i_end": 11}, "action": {"text": "attain", "start": 82, "end": 88, "i_start": 15, "i_end": 15}}, {"character": {"text": "machine", "start": 118, "end": 125, "i_start": 22, "i_end": 22}, "action": {"text": "performance", "start": 131, "end": 142, "i_start": 24, "i_end": 24}}], "id": 2570}, {"sent": "lovelock gravity is a generalization of einstein gravity including higher curvature terms in the lagrangian .", "tokens": ["lovelock", "gravity", "is", "a", "generalization", "of", "einstein", "gravity", "including", "higher", "curvature", "terms", "in", "the", "lagrangian", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "lovelock gravity", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}], "id": 2571}, {"sent": "the cartesian product is a compact hausdorff space with respect to the tychonov product topology .", "tokens": ["the", "cartesian", "product", "is", "a", "compact", "hausdorff", "space", "with", "respect", "to", "the", "tychonov", "product", "topology", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the cartesian product", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2572}, {"sent": "compressed sensing or compressive sampling theory addresses the accurate recovery of unknown sparse signals from underdetermined linear measurements .", "tokens": ["compressed", "sensing", "or", "compressive", "sampling", "theory", "addresses", "the", "accurate", "recovery", "of", "unknown", "sparse", "signals", "from", "underdetermined", "linear", "measurements", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "theory", "start": 43, "end": 49, "i_start": 5, "i_end": 5}, "action": {"text": "addresses", "start": 50, "end": 59, "i_start": 6, "i_end": 6}}], "id": 2573}, {"sent": "recently , supervised dictionary learning methods have also been proposed to increase the discriminant power of the sparse coding algorithm .", "tokens": ["recently", ",", "supervised", "dictionary", "learning", "methods", "have", "also", "been", "proposed", "to", "increase", "the", "discriminant", "power", "of", "the", "sparse", "coding", "algorithm", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "dictionary learning methods", "start": 22, "end": 49, "i_start": 3, "i_end": 5}, "verb": {"text": "supervised", "start": 11, "end": 21, "i_start": 2, "i_end": 2}}, {"subject": {"text": "dictionary learning methods", "start": 22, "end": 49, "i_start": 3, "i_end": 5}, "verb": {"text": "proposed", "start": 65, "end": 73, "i_start": 9, "i_end": 9}}, {"character": {"text": "methods", "start": 42, "end": 49, "i_start": 5, "i_end": 5}, "action": {"text": "increase", "start": 77, "end": 85, "i_start": 11, "i_end": 11}}, {"character": {"text": "power", "start": 103, "end": 108, "i_start": 14, "i_end": 14}, "action": {"text": "discriminant", "start": 90, "end": 102, "i_start": 13, "i_end": 13}}], "id": 2574}, {"sent": "the standard cosmological model has been confirmed with ever-increasing precision using cosmic microwave background data , such as from the wilkinson microwave anisotropy probe .", "tokens": ["the", "standard", "cosmological", "model", "has", "been", "confirmed", "with", "ever", "-", "increasing", "precision", "using", "cosmic", "microwave", "background", "data", ",", "such", "as", "from", "the", "wilkinson", "microwave", "anisotropy", "probe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the standard cosmological model", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "has been confirmed", "start": 32, "end": 50, "i_start": 4, "i_end": 6}}], "id": 2575}, {"sent": "in the extreme limit , where we allow all bands , it is obviously possible to construct wannier functions that are perfectly localized delta functions .", "tokens": ["in", "the", "extreme", "limit", ",", "where", "we", "allow", "all", "bands", ",", "it", "is", "obviously", "possible", "to", "construct", "wannier", "functions", "that", "are", "perfectly", "localized", "delta", "functions", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 50, "end": 52, "i_start": 11, "i_end": 11}, "verb": {"text": "is", "start": 53, "end": 55, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 6, "i_end": 6}, "action": {"text": "allow", "start": 32, "end": 37, "i_start": 7, "i_end": 7}}], "id": 2576}, {"sent": "such local hamiltonian structures are determined by differential-geometrical poisson brackets of the first order .", "tokens": ["such", "local", "hamiltonian", "structures", "are", "determined", "by", "differential", "-", "geometrical", "poisson", "brackets", "of", "the", "first", "order", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "such local hamiltonian structures", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "are determined", "start": 34, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "brackets", "start": 85, "end": 93, "i_start": 11, "i_end": 11}, "action": {"text": "determined", "start": 38, "end": 48, "i_start": 5, "i_end": 5}}], "id": 2577}, {"sent": "overlaid is the 1-\u03c3 range around the best fit to global data , grsv-std .", "tokens": ["overlaid", "is", "the", "1", "-", "\u03c3", "range", "around", "the", "best", "fit", "to", "global", "data", ",", "grsv", "-", "std", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2578}, {"sent": "deep neural networks have demonstrated stateof-the-art results in image classification .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "stateof", "-", "the", "-", "art", "results", "in", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}], "id": 2579}, {"sent": "we employed the perdew-burke-ernzerhof exchange correlation functional in the generalized gradient approximation .", "tokens": ["we", "employed", "the", "perdew", "-", "burke", "-", "ernzerhof", "exchange", "correlation", "functional", "in", "the", "generalized", "gradient", "approximation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employed", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employed", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2580}, {"sent": "the space of pair of simple algebras in this section , we define the representation of the space of pair of simple algebras , and discuss its basic properties .", "tokens": ["the", "space", "of", "pair", "of", "simple", "algebras", "in", "this", "section", ",", "we", "define", "the", "representation", "of", "the", "space", "of", "pair", "of", "simple", "algebras", ",", "and", "discuss", "its", "basic", "properties", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 55, "end": 57, "i_start": 11, "i_end": 11}, "verb": {"text": "define", "start": 58, "end": 64, "i_start": 12, "i_end": 12}}, {"subject": {"text": "we", "start": 55, "end": 57, "i_start": 11, "i_end": 11}, "verb": {"text": "discuss", "start": 130, "end": 137, "i_start": 25, "i_end": 25}}, {"character": {"text": "we", "start": 55, "end": 57, "i_start": 11, "i_end": 11}, "action": {"text": "define", "start": 58, "end": 64, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 55, "end": 57, "i_start": 11, "i_end": 11}, "action": {"text": "discuss", "start": 130, "end": 137, "i_start": 25, "i_end": 25}}], "id": 2581}, {"sent": "in a later version , abadi et al derived tighter privacy bounds for a similar gradient perturbation method .", "tokens": ["in", "a", "later", "version", ",", "abadi", "et", "al", "derived", "tighter", "privacy", "bounds", "for", "a", "similar", "gradient", "perturbation", "method", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "abadi et al", "start": 21, "end": 32, "i_start": 5, "i_end": 7}, "verb": {"text": "derived", "start": 33, "end": 40, "i_start": 8, "i_end": 8}}, {"character": {"text": "abadi", "start": 21, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "derived", "start": 33, "end": 40, "i_start": 8, "i_end": 8}}], "id": 2582}, {"sent": "the positive solution of is radial symmetric about some fixed point .", "tokens": ["the", "positive", "solution", "of", "is", "radial", "symmetric", "about", "some", "fixed", "point", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the positive solution of", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 4, "i_end": 4}}], "id": 2583}, {"sent": "to simulate hypervelocity impact processes in solid materials sale was modified to include an elasto-plastic constitutive model , fragmentation models , various eos , and multiple materials .", "tokens": ["to", "simulate", "hypervelocity", "impact", "processes", "in", "solid", "materials", "sale", "was", "modified", "to", "include", "an", "elasto", "-", "plastic", "constitutive", "model", ",", "fragmentation", "models", ",", "various", "eos", ",", "and", "multiple", "materials", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2584}, {"sent": "in chapter seven we introduce bisemirings , smarandache bisemirings , bisemivector spaces , smarandache bisemivector spaces .", "tokens": ["in", "chapter", "seven", "we", "introduce", "bisemirings", ",", "smarandache", "bisemirings", ",", "bisemivector", "spaces", ",", "smarandache", "bisemivector", "spaces", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 17, "end": 19, "i_start": 3, "i_end": 3}, "verb": {"text": "introduce", "start": 20, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 17, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "introduce", "start": 20, "end": 29, "i_start": 4, "i_end": 4}}], "id": 2585}, {"sent": "in , it is shown that lambek , goldie and any perfect hereditary torsion theories are differential .", "tokens": ["in", ",", "it", "is", "shown", "that", "lambek", ",", "goldie", "and", "any", "perfect", "hereditary", "torsion", "theories", "are", "differential", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "verb": {"text": "is shown", "start": 8, "end": 16, "i_start": 3, "i_end": 4}}, {"subject": {"text": "it", "start": 5, "end": 7, "i_start": 2, "i_end": 2}, "verb": {"text": "are", "start": 82, "end": 85, "i_start": 15, "i_end": 15}}], "id": 2586}, {"sent": "supershell structure in alkali metal nanowires .", "tokens": ["supershell", "structure", "in", "alkali", "metal", "nanowires", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2587}, {"sent": "this axion is the invention from the need to solve the strong cp problem .", "tokens": ["this", "axion", "is", "the", "invention", "from", "the", "need", "to", "solve", "the", "strong", "cp", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this axion", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "need", "start": 37, "end": 41, "i_start": 7, "i_end": 7}, "action": {"text": "invention", "start": 18, "end": 27, "i_start": 4, "i_end": 4}}], "id": 2588}, {"sent": "several such cooperative communication schemes have been investigated for wbans using either narrow-band .", "tokens": ["several", "such", "cooperative", "communication", "schemes", "have", "been", "investigated", "for", "wbans", "using", "either", "narrow", "-", "band", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "several such cooperative communication schemes", "start": 0, "end": 46, "i_start": 0, "i_end": 4}, "verb": {"text": "have been investigated", "start": 47, "end": 69, "i_start": 5, "i_end": 7}}], "id": 2589}, {"sent": "two-dimensional gravity with dynamical torsion and strings .", "tokens": ["two", "-", "dimensional", "gravity", "with", "dynamical", "torsion", "and", "strings", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2590}, {"sent": "in recent years , convolutional neural networks has achieved remarkable results in a wide range of computer vision applications .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "has", "achieved", "remarkable", "results", "in", "a", "wide", "range", "of", "computer", "vision", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "has achieved", "start": 48, "end": 60, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 52, "end": 60, "i_start": 8, "i_end": 8}}], "id": 2591}, {"sent": "we applied this procedure on real-word networks , which have been taken from the stanford large network dataset collection snap .", "tokens": ["we", "applied", "this", "procedure", "on", "real", "-", "word", "networks", ",", "which", "have", "been", "taken", "from", "the", "stanford", "large", "network", "dataset", "collection", "snap", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "applied", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "applied", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 2592}, {"sent": "nv centers are a promising qubit system for quantum information processing .", "tokens": ["nv", "centers", "are", "a", "promising", "qubit", "system", "for", "quantum", "information", "processing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "nv centers", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 11, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "system", "start": 33, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "promising", "start": 17, "end": 26, "i_start": 4, "i_end": 4}}], "id": 2593}, {"sent": "if the gravitino is the lightest supersymmetric particle , it is stable and therefore represents a good dark matter candidate .", "tokens": ["if", "the", "gravitino", "is", "the", "lightest", "supersymmetric", "particle", ",", "it", "is", "stable", "and", "therefore", "represents", "a", "good", "dark", "matter", "candidate", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 59, "end": 61, "i_start": 9, "i_end": 9}, "verb": {"text": "is", "start": 62, "end": 64, "i_start": 10, "i_end": 10}}, {"subject": {"text": "it", "start": 59, "end": 61, "i_start": 9, "i_end": 9}, "verb": {"text": "represents", "start": 86, "end": 96, "i_start": 14, "i_end": 14}}, {"character": {"text": "stable", "start": 65, "end": 71, "i_start": 11, "i_end": 11}, "action": {"text": "if", "start": 0, "end": 2, "i_start": 0, "i_end": 0}}, {"character": {"text": "gravitino", "start": 7, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "represents", "start": 86, "end": 96, "i_start": 14, "i_end": 14}}], "id": 2594}, {"sent": "in proceedings of the fifteenth conference on uncertainty in artificial intelligence , pp .", "tokens": ["in", "proceedings", "of", "the", "fifteenth", "conference", "on", "uncertainty", "in", "artificial", "intelligence", ",", "pp", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2595}, {"sent": "the best-known qkds are the bennett-brassard 1984 protocol .", "tokens": ["the", "best", "-", "known", "qkds", "are", "the", "bennett", "-", "brassard", "1984", "protocol", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the best-known qkds", "start": 0, "end": 19, "i_start": 0, "i_end": 4}, "verb": {"text": "are", "start": 20, "end": 23, "i_start": 5, "i_end": 5}}], "id": 2596}, {"sent": "the sloan digital sky survey is a joint project of the university of chicago , fermilab , the institute for advanced study , the japan participation group , the johns hopkins university , the max-planck-institute for astronomy , the max-planck-institute for astrophysics , new mexico state university , princeton university , the united states naval observatory , and the university of washington .", "tokens": ["the", "sloan", "digital", "sky", "survey", "is", "a", "joint", "project", "of", "the", "university", "of", "chicago", ",", "fermilab", ",", "the", "institute", "for", "advanced", "study", ",", "the", "japan", "participation", "group", ",", "the", "johns", "hopkins", "university", ",", "the", "max", "-", "planck", "-", "institute", "for", "astronomy", ",", "the", "max", "-", "planck", "-", "institute", "for", "astrophysics", ",", "new", "mexico", "state", "university", ",", "princeton", "university", ",", "the", "united", "states", "naval", "observatory", ",", "and", "the", "university", "of", "washington", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the sloan digital sky survey", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "group", "start": 149, "end": 154, "i_start": 26, "i_end": 26}, "action": {"text": "participation", "start": 135, "end": 148, "i_start": 25, "i_end": 25}}], "id": 2597}, {"sent": "a fast direct solver for structured linear systems by recursive skeletonization .", "tokens": ["a", "fast", "direct", "solver", "for", "structured", "linear", "systems", "by", "recursive", "skeletonization", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2598}, {"sent": "since quantum mechanics is the more fundamental theory , it seems preferable to derive probabilistic behavior purely from within the quantum theory without invoking classical concepts at the outset .", "tokens": ["since", "quantum", "mechanics", "is", "the", "more", "fundamental", "theory", ",", "it", "seems", "preferable", "to", "derive", "probabilistic", "behavior", "purely", "from", "within", "the", "quantum", "theory", "without", "invoking", "classical", "concepts", "at", "the", "outset", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 57, "end": 59, "i_start": 9, "i_end": 9}, "verb": {"text": "seems", "start": 60, "end": 65, "i_start": 10, "i_end": 10}}], "id": 2599}, {"sent": "the inferred mass-loss rates from the uv line analyses are significantly lower than the theoretically expected and predicted by hydrodynamically consistent wind models .", "tokens": ["the", "inferred", "mass", "-", "loss", "rates", "from", "the", "uv", "line", "analyses", "are", "significantly", "lower", "than", "the", "theoretically", "expected", "and", "predicted", "by", "hydrodynamically", "consistent", "wind", "models", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the inferred mass-loss rates from the uv line analyses", "start": 0, "end": 54, "i_start": 0, "i_end": 10}, "verb": {"text": "are", "start": 55, "end": 58, "i_start": 11, "i_end": 11}}, {"subject": {"text": "the inferred mass-loss rates from the uv line analyses", "start": 0, "end": 54, "i_start": 0, "i_end": 10}, "verb": {"text": "predicted", "start": 115, "end": 124, "i_start": 19, "i_end": 19}}, {"character": {"text": "analyses", "start": 46, "end": 54, "i_start": 10, "i_end": 10}, "action": {"text": "inferred", "start": 4, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "models", "start": 161, "end": 167, "i_start": 24, "i_end": 24}, "action": {"text": "expected", "start": 102, "end": 110, "i_start": 17, "i_end": 17}}, {"character": {"text": "models", "start": 161, "end": 167, "i_start": 24, "i_end": 24}, "action": {"text": "predicted", "start": 115, "end": 124, "i_start": 19, "i_end": 19}}], "id": 2600}, {"sent": "it was also shown that computing the rainbow connection number of an arbitrary graph is np-hard .", "tokens": ["it", "was", "also", "shown", "that", "computing", "the", "rainbow", "connection", "number", "of", "an", "arbitrary", "graph", "is", "np", "-", "hard", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "shown", "start": 12, "end": 17, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "was", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 85, "end": 87, "i_start": 14, "i_end": 14}}], "id": 2601}, {"sent": "here , we explore the applicability of the generative adversarial networks framework to this problem .", "tokens": ["here", ",", "we", "explore", "the", "applicability", "of", "the", "generative", "adversarial", "networks", "framework", "to", "this", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "explore", "start": 10, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "explore", "start": 10, "end": 17, "i_start": 3, "i_end": 3}}], "id": 2602}, {"sent": "the geometry we consider is a one-dimensional ring with an attached bubble and a lead connected to a reservoir at chemical potential \u00b5 .", "tokens": ["the", "geometry", "we", "consider", "is", "a", "one", "-", "dimensional", "ring", "with", "an", "attached", "bubble", "and", "a", "lead", "connected", "to", "a", "reservoir", "at", "chemical", "potential", "\u00b5", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the geometry we consider", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "consider", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2603}, {"sent": "in the last decades there were several attempts to get these equations from pure non-equilibrium thermodynamics .", "tokens": ["in", "the", "last", "decades", "there", "were", "several", "attempts", "to", "get", "these", "equations", "from", "pure", "non", "-", "equilibrium", "thermodynamics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 20, "end": 25, "i_start": 4, "i_end": 4}, "verb": {"text": "were", "start": 26, "end": 30, "i_start": 5, "i_end": 5}}], "id": 2604}, {"sent": "recently , convolutional neural networks -based methods achieve great success in image classification tasks .", "tokens": ["recently", ",", "convolutional", "neural", "networks", "-based", "methods", "achieve", "great", "success", "in", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks -based methods", "start": 11, "end": 55, "i_start": 2, "i_end": 6}, "verb": {"text": "achieve", "start": 56, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "methods", "start": 48, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "achieve", "start": 56, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "methods", "start": 48, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 70, "end": 77, "i_start": 9, "i_end": 9}}], "id": 2605}, {"sent": "we find that for this quantum walk the probability at the origin is independent of the initial coin state .", "tokens": ["we", "find", "that", "for", "this", "quantum", "walk", "the", "probability", "at", "the", "origin", "is", "independent", "of", "the", "initial", "coin", "state", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 65, "end": 67, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "probability", "start": 39, "end": 50, "i_start": 8, "i_end": 8}, "action": {"text": "independent", "start": 68, "end": 79, "i_start": 13, "i_end": 13}}], "id": 2606}, {"sent": "since the pioneering work of wilson and cowan , continuous neural field models have become a popular and effective tool in neuroscience .", "tokens": ["since", "the", "pioneering", "work", "of", "wilson", "and", "cowan", ",", "continuous", "neural", "field", "models", "have", "become", "a", "popular", "and", "effective", "tool", "in", "neuroscience", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "continuous neural field models", "start": 48, "end": 78, "i_start": 9, "i_end": 12}, "verb": {"text": "have become", "start": 79, "end": 90, "i_start": 13, "i_end": 14}}, {"character": {"text": "tool", "start": 115, "end": 119, "i_start": 19, "i_end": 19}, "action": {"text": "effective", "start": 105, "end": 114, "i_start": 18, "i_end": 18}}, {"character": {"text": "wilson", "start": 29, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "work", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "cowan", "start": 40, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "work", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "work", "start": 21, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "pioneering", "start": 10, "end": 20, "i_start": 2, "i_end": 2}}], "id": 2607}, {"sent": "relativistic conservation laws on curved backgrounds and the theory of cosmological perturbations .", "tokens": ["relativistic", "conservation", "laws", "on", "curved", "backgrounds", "and", "the", "theory", "of", "cosmological", "perturbations", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2608}, {"sent": "however , if the frequency is above the frequency of the stopband the phase velocity is increased and compensates the effect of index dispersion .", "tokens": ["however", ",", "if", "the", "frequency", "is", "above", "the", "frequency", "of", "the", "stopband", "the", "phase", "velocity", "is", "increased", "and", "compensates", "the", "effect", "of", "index", "dispersion", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "the phase velocity", "start": 66, "end": 84, "i_start": 12, "i_end": 14}, "verb": {"text": "is increased", "start": 85, "end": 97, "i_start": 15, "i_end": 16}}, {"subject": {"text": "the phase velocity", "start": 66, "end": 84, "i_start": 12, "i_end": 14}, "verb": {"text": "compensates", "start": 102, "end": 113, "i_start": 18, "i_end": 18}}, {"character": {"text": "velocity", "start": 76, "end": 84, "i_start": 14, "i_end": 14}, "action": {"text": "compensates", "start": 102, "end": 113, "i_start": 18, "i_end": 18}}], "id": 2609}, {"sent": "energy harvesting is a promising technology to provide self-sustainability to power-constrained communication devices .", "tokens": ["energy", "harvesting", "is", "a", "promising", "technology", "to", "provide", "self", "-", "sustainability", "to", "power", "-", "constrained", "communication", "devices", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "energy harvesting", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "technology", "start": 33, "end": 43, "i_start": 5, "i_end": 5}, "action": {"text": "promising", "start": 23, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "technology", "start": 33, "end": 43, "i_start": 5, "i_end": 5}, "action": {"text": "provide", "start": 47, "end": 54, "i_start": 7, "i_end": 7}}, {"character": {"text": "self", "start": 55, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "sustainability", "start": 60, "end": 74, "i_start": 10, "i_end": 10}}, {"character": {"text": "devices", "start": 110, "end": 117, "i_start": 16, "i_end": 16}, "action": {"text": "communication", "start": 96, "end": 109, "i_start": 15, "i_end": 15}}], "id": 2610}, {"sent": "the network is trained end to end using adam as an optimization scheme .", "tokens": ["the", "network", "is", "trained", "end", "to", "end", "using", "adam", "as", "an", "optimization", "scheme", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the network", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is trained", "start": 12, "end": 22, "i_start": 2, "i_end": 3}}], "id": 2611}, {"sent": "the spire data are reduced using a combination of the hipe and smap packages .", "tokens": ["the", "spire", "data", "are", "reduced", "using", "a", "combination", "of", "the", "hipe", "and", "smap", "packages", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the spire data", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "are reduced", "start": 15, "end": 26, "i_start": 3, "i_end": 4}}], "id": 2612}, {"sent": "the problem of sparse signal recovery and the related problem of compressed sensing have received much attention in recent years .", "tokens": ["the", "problem", "of", "sparse", "signal", "recovery", "and", "the", "related", "problem", "of", "compressed", "sensing", "have", "received", "much", "attention", "in", "recent", "years", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the problem of sparse signal recovery and the related problem of compressed sensing", "start": 0, "end": 83, "i_start": 0, "i_end": 12}, "verb": {"text": "have received", "start": 84, "end": 97, "i_start": 13, "i_end": 14}}], "id": 2613}, {"sent": "unfortunately , just as for other established methods , there is no clear recipe for the a priori estimation of the initial sampling , for an arbitrary function .", "tokens": ["unfortunately", ",", "just", "as", "for", "other", "established", "methods", ",", "there", "is", "no", "clear", "recipe", "for", "the", "a", "priori", "estimation", "of", "the", "initial", "sampling", ",", "for", "an", "arbitrary", "function", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 56, "end": 61, "i_start": 9, "i_end": 9}, "verb": {"text": "is", "start": 62, "end": 64, "i_start": 10, "i_end": 10}}], "id": 2614}, {"sent": "reinforcement learning is a computational framework for making decisions under uncertainty in sequential-time decision making problems .", "tokens": ["reinforcement", "learning", "is", "a", "computational", "framework", "for", "making", "decisions", "under", "uncertainty", "in", "sequential", "-", "time", "decision", "making", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 2, "i_end": 2}}], "id": 2615}, {"sent": "deep learning has been proven to achieve promising results in different research problems such as face recognition .", "tokens": ["deep", "learning", "has", "been", "proven", "to", "achieve", "promising", "results", "in", "different", "research", "problems", "such", "as", "face", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has been proven", "start": 14, "end": 29, "i_start": 2, "i_end": 4}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "achieve", "start": 33, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "results", "start": 51, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "promising", "start": 41, "end": 50, "i_start": 7, "i_end": 7}}], "id": 2616}, {"sent": "van leeuwen , in phase transitions and critical phenomena , edited by c .", "tokens": ["van", "leeuwen", ",", "in", "phase", "transitions", "and", "critical", "phenomena", ",", "edited", "by", "c", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "phenomena", "start": 48, "end": 57, "i_start": 8, "i_end": 8}, "action": {"text": "critical", "start": 39, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "van leeuwen", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "action": {"text": "edited", "start": 60, "end": 66, "i_start": 10, "i_end": 10}}], "id": 2617}, {"sent": "deep convolutional neural networks have made significant breakthroughs in many visual understanding tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "significant", "breakthroughs", "in", "many", "visual", "understanding", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "breakthroughs", "start": 57, "end": 70, "i_start": 7, "i_end": 7}}], "id": 2618}, {"sent": "deep convolutional neural networks have made great progress in visual recognition challenges such as object classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "great", "progress", "in", "visual", "recognition", "challenges", "such", "as", "object", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}], "id": 2619}, {"sent": "identification of the appropriate directions depends on the velocity of the particles , the curvature of the spacetime , and the positions of the observers .", "tokens": ["identification", "of", "the", "appropriate", "directions", "depends", "on", "the", "velocity", "of", "the", "particles", ",", "the", "curvature", "of", "the", "spacetime", ",", "and", "the", "positions", "of", "the", "observers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "identification of the appropriate directions", "start": 0, "end": 44, "i_start": 0, "i_end": 4}, "verb": {"text": "depends", "start": 45, "end": 52, "i_start": 5, "i_end": 5}}, {"character": {"text": "identification", "start": 0, "end": 14, "i_start": 0, "i_end": 0}, "action": {"text": "depends", "start": 45, "end": 52, "i_start": 5, "i_end": 5}}], "id": 2620}, {"sent": "deep learning has been widely adapted to many different problems , such as image classification , and has demonstrated state-of-the-art results for these problems .", "tokens": ["deep", "learning", "has", "been", "widely", "adapted", "to", "many", "different", "problems", ",", "such", "as", "image", "classification", ",", "and", "has", "demonstrated", "state", "-", "of", "-", "the", "-", "art", "results", "for", "these", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "adapted", "start": 30, "end": 37, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has been", "start": 14, "end": 22, "i_start": 2, "i_end": 3}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "demonstrated", "start": 106, "end": 118, "i_start": 18, "i_end": 18}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "demonstrated", "start": 106, "end": 118, "i_start": 18, "i_end": 18}}], "id": 2621}, {"sent": "deep neural networks trained in an end-to-end fashion have resulted in exceptional advances in computational perception , especially in object detection .", "tokens": ["deep", "neural", "networks", "trained", "in", "an", "end", "-", "to", "-", "end", "fashion", "have", "resulted", "in", "exceptional", "advances", "in", "computational", "perception", ",", "especially", "in", "object", "detection", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "deep neural networks trained in an end-to-end fashion", "start": 0, "end": 53, "i_start": 0, "i_end": 11}, "verb": {"text": "have resulted", "start": 54, "end": 67, "i_start": 12, "i_end": 13}}], "id": 2622}, {"sent": "this spacetime is a product of a 4-torus and spacetime that is locally a product of an s1 fiber with a 5-dimensional spacetime .", "tokens": ["this", "spacetime", "is", "a", "product", "of", "a", "4", "-", "torus", "and", "spacetime", "that", "is", "locally", "a", "product", "of", "an", "s1", "fiber", "with", "a", "5", "-", "dimensional", "spacetime", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this spacetime", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "4", "start": 33, "end": 34, "i_start": 7, "i_end": 7}, "action": {"text": "product", "start": 20, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "spacetime", "start": 5, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "product", "start": 20, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "product", "start": 20, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "s1", "start": 87, "end": 89, "i_start": 19, "i_end": 19}, "action": {"text": "product", "start": 20, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "spacetime that is locally a product of an s1 fiber with a 5", "start": 45, "end": 104, "i_start": 11, "i_end": 23}, "action": {"text": "product", "start": 20, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "dimensional", "start": 105, "end": 116, "i_start": 25, "i_end": 25}, "action": {"text": "product", "start": 20, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "fiber", "start": 90, "end": 95, "i_start": 20, "i_end": 20}, "action": {"text": "product", "start": 73, "end": 80, "i_start": 16, "i_end": 16}}], "id": 2623}, {"sent": "in order to boost the classification performance , we add batch normalization layer between convolutional layer and relu layer .", "tokens": ["in", "order", "to", "boost", "the", "classification", "performance", ",", "we", "add", "batch", "normalization", "layer", "between", "convolutional", "layer", "and", "relu", "layer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 51, "end": 53, "i_start": 8, "i_end": 8}, "verb": {"text": "add", "start": 54, "end": 57, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "add", "start": 54, "end": 57, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "boost", "start": 12, "end": 17, "i_start": 3, "i_end": 3}}], "id": 2624}, {"sent": "selvaraju et al proposes an explanation method specifically for convolutional neural networks called grad-cam .", "tokens": ["selvaraju", "et", "al", "proposes", "an", "explanation", "method", "specifically", "for", "convolutional", "neural", "networks", "called", "grad", "-", "cam", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "selvaraju et al", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "proposes", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "selvaraju", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "proposes", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2625}, {"sent": "internationaljournalofcomputerscienceandinformationsecurity , vol .", "tokens": ["internationaljournalofcomputerscienceandinformationsecurity", ",", "vol", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2626}, {"sent": "we train the network using the adam optimizer and use the binary cross-entropy as the loss function .", "tokens": ["we", "train", "the", "network", "using", "the", "adam", "optimizer", "and", "use", "the", "binary", "cross", "-", "entropy", "as", "the", "loss", "function", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimizer", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 21, "end": 26, "i_start": 4, "i_end": 4}}], "id": 2627}, {"sent": "damage models are also analytically investigated in and , there , existence , uniqueness and regularity properties are shown .", "tokens": ["damage", "models", "are", "also", "analytically", "investigated", "in", "and", ",", "there", ",", "existence", ",", "uniqueness", "and", "regularity", "properties", "are", "shown", "."], "score": [1, 1, 0, 1, 1], "labels": [{"subject": {"text": "existence", "start": 66, "end": 75, "i_start": 11, "i_end": 11}, "verb": {"text": "are shown", "start": 115, "end": 124, "i_start": 17, "i_end": 18}}, {"subject": {"text": "damage models", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "investigated", "start": 36, "end": 48, "i_start": 5, "i_end": 5}}], "id": 2628}, {"sent": "song et al employ a spatial-temporal attention model based on lstm to select discriminative spatial and temporal features .", "tokens": ["song", "et", "al", "employ", "a", "spatial", "-", "temporal", "attention", "model", "based", "on", "lstm", "to", "select", "discriminative", "spatial", "and", "temporal", "features", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "song et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "employ", "start": 11, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "song", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 11, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "song", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "select", "start": 70, "end": 76, "i_start": 14, "i_end": 14}}, {"character": {"text": "features", "start": 113, "end": 121, "i_start": 19, "i_end": 19}, "action": {"text": "discriminative", "start": 77, "end": 91, "i_start": 15, "i_end": 15}}], "id": 2629}, {"sent": "moreover , convolutional neural networks can be susceptible to white box adversarial attacks .", "tokens": ["moreover", ",", "convolutional", "neural", "networks", "can", "be", "susceptible", "to", "white", "box", "adversarial", "attacks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 11, "end": 40, "i_start": 2, "i_end": 4}, "verb": {"text": "can be", "start": 41, "end": 47, "i_start": 5, "i_end": 6}}], "id": 2630}, {"sent": "a practical situation is that of the weak measurement , typically realised using a weak system-apparatus coupling , where information about the measured observable is extracted from the system at a slow rate .", "tokens": ["a", "practical", "situation", "is", "that", "of", "the", "weak", "measurement", ",", "typically", "realised", "using", "a", "weak", "system", "-", "apparatus", "coupling", ",", "where", "information", "about", "the", "measured", "observable", "is", "extracted", "from", "the", "system", "at", "a", "slow", "rate", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a practical situation", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2631}, {"sent": "deep neural networks are powerful learning models which have been successfully applied to vision , speech and many other tasks .", "tokens": ["deep", "neural", "networks", "are", "powerful", "learning", "models", "which", "have", "been", "successfully", "applied", "to", "vision", ",", "speech", "and", "many", "other", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2632}, {"sent": "this similarity is a strong indication that the subgroups identified by the lm method are not artifacts of this method .", "tokens": ["this", "similarity", "is", "a", "strong", "indication", "that", "the", "subgroups", "identified", "by", "the", "lm", "method", "are", "not", "artifacts", "of", "this", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this similarity", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "method", "start": 79, "end": 85, "i_start": 13, "i_end": 13}, "action": {"text": "identified", "start": 58, "end": 68, "i_start": 9, "i_end": 9}}], "id": 2633}, {"sent": "collagen gel considered in experiments is converted into a computational network using the approach of stein , andrew m , et al .", "tokens": ["collagen", "gel", "considered", "in", "experiments", "is", "converted", "into", "a", "computational", "network", "using", "the", "approach", "of", "stein", ",", "andrew", "m", ",", "et", "al", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "collagen gel considered in experiments", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "is converted", "start": 39, "end": 51, "i_start": 5, "i_end": 6}}, {"character": {"text": "stein", "start": 103, "end": 108, "i_start": 15, "i_end": 15}, "action": {"text": "approach", "start": 91, "end": 99, "i_start": 13, "i_end": 13}}, {"character": {"text": "andrew m", "start": 111, "end": 119, "i_start": 17, "i_end": 18}, "action": {"text": "approach", "start": 91, "end": 99, "i_start": 13, "i_end": 13}}], "id": 2634}, {"sent": "the notion of a vertex algebra was introduced by borcherds among many other works .", "tokens": ["the", "notion", "of", "a", "vertex", "algebra", "was", "introduced", "by", "borcherds", "among", "many", "other", "works", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the notion of a vertex algebra", "start": 0, "end": 30, "i_start": 0, "i_end": 5}, "verb": {"text": "was introduced", "start": 31, "end": 45, "i_start": 6, "i_end": 7}}, {"character": {"text": "borcherds", "start": 49, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "introduced", "start": 35, "end": 45, "i_start": 7, "i_end": 7}}], "id": 2635}, {"sent": "we state the results in the form that we are going to use and all proofs are included for completeness .", "tokens": ["we", "state", "the", "results", "in", "the", "form", "that", "we", "are", "going", "to", "use", "and", "all", "proofs", "are", "included", "for", "completeness", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "state", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "all proofs", "start": 62, "end": 72, "i_start": 14, "i_end": 15}, "verb": {"text": "included", "start": 77, "end": 85, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "state", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 54, "end": 57, "i_start": 12, "i_end": 12}}], "id": 2636}, {"sent": "more importantly , string theory is a perfectly quantum mechanical theory which does include gravity .", "tokens": ["more", "importantly", ",", "string", "theory", "is", "a", "perfectly", "quantum", "mechanical", "theory", "which", "does", "include", "gravity", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "string theory", "start": 19, "end": 32, "i_start": 3, "i_end": 4}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 5, "i_end": 5}}, {"character": {"text": "theory", "start": 26, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "include", "start": 85, "end": 92, "i_start": 13, "i_end": 13}}], "id": 2637}, {"sent": "these systems are related with the different parametrisations of one geometric object .", "tokens": ["these", "systems", "are", "related", "with", "the", "different", "parametrisations", "of", "one", "geometric", "object", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these systems", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "are related", "start": 14, "end": 25, "i_start": 2, "i_end": 3}}], "id": 2638}, {"sent": "the problem set-up is adapted from the general concept of expectation over transformations .", "tokens": ["the", "problem", "set", "-", "up", "is", "adapted", "from", "the", "general", "concept", "of", "expectation", "over", "transformations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the problem set-up", "start": 0, "end": 18, "i_start": 0, "i_end": 4}, "verb": {"text": "is adapted", "start": 19, "end": 29, "i_start": 5, "i_end": 6}}], "id": 2639}, {"sent": "generative adversarial nets consist of generator and discriminator .", "tokens": ["generative", "adversarial", "nets", "consist", "of", "generator", "and", "discriminator", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial nets", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "consist", "start": 28, "end": 35, "i_start": 3, "i_end": 3}}], "id": 2640}, {"sent": "the formalism for studying the dynamics of constrained systems was discovered by dirac .", "tokens": ["the", "formalism", "for", "studying", "the", "dynamics", "of", "constrained", "systems", "was", "discovered", "by", "dirac", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "the formalism for studying the dynamics of constrained systems", "start": 0, "end": 62, "i_start": 0, "i_end": 8}, "verb": {"text": "was discovered", "start": 63, "end": 77, "i_start": 9, "i_end": 10}}, {"character": {"text": "dirac", "start": 81, "end": 86, "i_start": 12, "i_end": 12}, "action": {"text": "discovered", "start": 67, "end": 77, "i_start": 10, "i_end": 10}}], "id": 2641}, {"sent": "near-infrared pitch angle in degrees versus shear rate .", "tokens": ["near", "-", "infrared", "pitch", "angle", "in", "degrees", "versus", "shear", "rate", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2642}, {"sent": "this kind of objective is well-suited to optimization using the expectationmaximization algorithm .", "tokens": ["this", "kind", "of", "objective", "is", "well", "-", "suited", "to", "optimization", "using", "the", "expectationmaximization", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this kind of objective", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 4, "i_end": 4}}], "id": 2643}, {"sent": "we evaluate the proposed approach on two publicly available datasets , namely humaneva-i .", "tokens": ["we", "evaluate", "the", "proposed", "approach", "on", "two", "publicly", "available", "datasets", ",", "namely", "humaneva", "-", "i", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2644}, {"sent": "a detailed description of the cms detector , together with a definition of the coordinate system and the relevant kinematic variables , can be found in ref .", "tokens": ["a", "detailed", "description", "of", "the", "cms", "detector", ",", "together", "with", "a", "definition", "of", "the", "coordinate", "system", "and", "the", "relevant", "kinematic", "variables", ",", "can", "be", "found", "in", "ref", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "a detailed description of the cms detector", "start": 0, "end": 42, "i_start": 0, "i_end": 6}, "verb": {"text": "can be found", "start": 136, "end": 148, "i_start": 22, "i_end": 24}}], "id": 2645}, {"sent": "dietrich , critical casimir effect in classical binary liquid mixtures , phys .", "tokens": ["dietrich", ",", "critical", "casimir", "effect", "in", "classical", "binary", "liquid", "mixtures", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2646}, {"sent": "deep learning models have yielded outstanding results in several applications , including speech recognition .", "tokens": ["deep", "learning", "models", "have", "yielded", "outstanding", "results", "in", "several", "applications", ",", "including", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning models", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have yielded", "start": 21, "end": 33, "i_start": 3, "i_end": 4}}, {"character": {"text": "models", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "yielded", "start": 26, "end": 33, "i_start": 4, "i_end": 4}}], "id": 2647}, {"sent": "the atca data was calibrated using the miriad software package .", "tokens": ["the", "atca", "data", "was", "calibrated", "using", "the", "miriad", "software", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the atca data", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "was calibrated", "start": 14, "end": 28, "i_start": 3, "i_end": 4}}], "id": 2648}, {"sent": "underlying this idea there is the concept of distance between two unitary gates .", "tokens": ["underlying", "this", "idea", "there", "is", "the", "concept", "of", "distance", "between", "two", "unitary", "gates", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 21, "end": 26, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "concept", "start": 34, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "underlying", "start": 0, "end": 10, "i_start": 0, "i_end": 0}}], "id": 2649}, {"sent": "convolutional neural networks are widely used for solving artificial intelligence problems , such as object and voice recognition , scene labeling and others .", "tokens": ["convolutional", "neural", "networks", "are", "widely", "used", "for", "solving", "artificial", "intelligence", "problems", ",", "such", "as", "object", "and", "voice", "recognition", ",", "scene", "labeling", "and", "others", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 41, "end": 45, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 3, "i_end": 3}}], "id": 2650}, {"sent": "our approach is evaluated on the large-scale imagenet vid dataset .", "tokens": ["our", "approach", "is", "evaluated", "on", "the", "large", "-", "scale", "imagenet", "vid", "dataset", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our approach", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is evaluated", "start": 13, "end": 25, "i_start": 2, "i_end": 3}}], "id": 2651}, {"sent": "the red star is representative of the strong self-interacting scenario described in refs .", "tokens": ["the", "red", "star", "is", "representative", "of", "the", "strong", "self", "-", "interacting", "scenario", "described", "in", "refs", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the red star", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "star", "start": 8, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "representative", "start": 16, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "star", "start": 8, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "interacting", "start": 50, "end": 61, "i_start": 10, "i_end": 10}}], "id": 2652}, {"sent": "that is , the magnetic helicity is the flux of the toroidal magnetic field through the positive-x half-plane .", "tokens": ["that", "is", ",", "the", "magnetic", "helicity", "is", "the", "flux", "of", "the", "toroidal", "magnetic", "field", "through", "the", "positive", "-", "x", "half", "-", "plane", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the magnetic helicity", "start": 10, "end": 31, "i_start": 3, "i_end": 5}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 6, "i_end": 6}}], "id": 2653}, {"sent": "reinforcement learning is one category of algorithms in machine learning , which is different from supervised learning and unsupervised learning .", "tokens": ["reinforcement", "learning", "is", "one", "category", "of", "algorithms", "in", "machine", "learning", ",", "which", "is", "different", "from", "supervised", "learning", "and", "unsupervised", "learning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 2, "i_end": 2}}], "id": 2654}, {"sent": "the endomorphism \u03b8 is also called the higgs field .", "tokens": ["the", "endomorphism", "\u03b8", "is", "also", "called", "the", "higgs", "field", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the endomorphism \u03b8", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "called", "start": 27, "end": 33, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the endomorphism \u03b8", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 2655}, {"sent": "excitations in zero magnetic field for the cyclic state .", "tokens": ["excitations", "in", "zero", "magnetic", "field", "for", "the", "cyclic", "state", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "zero magnetic field", "start": 15, "end": 34, "i_start": 2, "i_end": 4}, "action": {"text": "excitations", "start": 0, "end": 11, "i_start": 0, "i_end": 0}}], "id": 2656}, {"sent": "for the power spectrum , this consists of the subtraction from the measured galaxy power spectrum of the shot noise contribution .", "tokens": ["for", "the", "power", "spectrum", ",", "this", "consists", "of", "the", "subtraction", "from", "the", "measured", "galaxy", "power", "spectrum", "of", "the", "shot", "noise", "contribution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 25, "end": 29, "i_start": 5, "i_end": 5}, "verb": {"text": "consists", "start": 30, "end": 38, "i_start": 6, "i_end": 6}}], "id": 2657}, {"sent": "furthermore , the truncated normal form can help us understanding bifurcation phenomena .", "tokens": ["furthermore", ",", "the", "truncated", "normal", "form", "can", "help", "us", "understanding", "bifurcation", "phenomena", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the truncated normal form", "start": 14, "end": 39, "i_start": 2, "i_end": 5}, "verb": {"text": "can help", "start": 40, "end": 48, "i_start": 6, "i_end": 7}}, {"subject": {"text": "us", "start": 49, "end": 51, "i_start": 8, "i_end": 8}, "verb": {"text": "understanding", "start": 52, "end": 65, "i_start": 9, "i_end": 9}}, {"character": {"text": "form", "start": 35, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "help", "start": 44, "end": 48, "i_start": 7, "i_end": 7}}, {"character": {"text": "us", "start": 49, "end": 51, "i_start": 8, "i_end": 8}, "action": {"text": "understanding", "start": 52, "end": 65, "i_start": 9, "i_end": 9}}], "id": 2658}, {"sent": "each activation layer is preceded by a layer of batch normalization .", "tokens": ["each", "activation", "layer", "is", "preceded", "by", "a", "layer", "of", "batch", "normalization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each activation layer", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is preceded", "start": 22, "end": 33, "i_start": 3, "i_end": 4}}], "id": 2659}, {"sent": "belief propagation for graph partitioning .", "tokens": ["belief", "propagation", "for", "graph", "partitioning", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2660}, {"sent": "the lagrangian is a lorentz-invariant functional of the fields \u03c6i and their derivatives .", "tokens": ["the", "lagrangian", "is", "a", "lorentz", "-", "invariant", "functional", "of", "the", "fields", "\u03c6i", "and", "their", "derivatives", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lagrangian", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "fields", "start": 56, "end": 62, "i_start": 10, "i_end": 10}, "action": {"text": "functional", "start": 38, "end": 48, "i_start": 7, "i_end": 7}}, {"character": {"text": "\u03c6i", "start": 63, "end": 65, "i_start": 11, "i_end": 11}, "action": {"text": "functional", "start": 38, "end": 48, "i_start": 7, "i_end": 7}}, {"character": {"text": "derivatives", "start": 76, "end": 87, "i_start": 14, "i_end": 14}, "action": {"text": "functional", "start": 38, "end": 48, "i_start": 7, "i_end": 7}}, {"character": {"text": "fields", "start": 56, "end": 62, "i_start": 10, "i_end": 10}, "action": {"text": "functional", "start": 38, "end": 48, "i_start": 7, "i_end": 7}}, {"character": {"text": "\u03c6i", "start": 63, "end": 65, "i_start": 11, "i_end": 11}, "action": {"text": "functional", "start": 38, "end": 48, "i_start": 7, "i_end": 7}}], "id": 2661}, {"sent": "in parallel , deep convolutional neural networks have proven their effectiveness in many computer vision fields such as object classification .", "tokens": ["in", "parallel", ",", "deep", "convolutional", "neural", "networks", "have", "proven", "their", "effectiveness", "in", "many", "computer", "vision", "fields", "such", "as", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 14, "end": 48, "i_start": 3, "i_end": 6}, "verb": {"text": "have proven", "start": 49, "end": 60, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 40, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "proven", "start": 54, "end": 60, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 40, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "effectiveness", "start": 67, "end": 80, "i_start": 10, "i_end": 10}}], "id": 2662}, {"sent": "deep neural networks are powerful methods for solving complex classification tasks in fields such as computer vision .", "tokens": ["deep", "neural", "networks", "are", "powerful", "methods", "for", "solving", "complex", "classification", "tasks", "in", "fields", "such", "as", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2663}, {"sent": "the paradigm of cosmic inflation is stunningly successful in explaining the flatness and homogeneity of our universe as well as the approximately scale invariant inhomogeneities in the cosmic microwave background .", "tokens": ["the", "paradigm", "of", "cosmic", "inflation", "is", "stunningly", "successful", "in", "explaining", "the", "flatness", "and", "homogeneity", "of", "our", "universe", "as", "well", "as", "the", "approximately", "scale", "invariant", "inhomogeneities", "in", "the", "cosmic", "microwave", "background", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the paradigm of cosmic inflation", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 5, "i_end": 5}}, {"character": {"text": "paradigm", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "successful", "start": 47, "end": 57, "i_start": 7, "i_end": 7}}, {"character": {"text": "paradigm", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "explaining", "start": 61, "end": 71, "i_start": 9, "i_end": 9}}], "id": 2664}, {"sent": "deep learning approaches , in particularly deep convolutional neural networks , have achieved tremendous successes in various visual recognition tasks .", "tokens": ["deep", "learning", "approaches", ",", "in", "particularly", "deep", "convolutional", "neural", "networks", ",", "have", "achieved", "tremendous", "successes", "in", "various", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep learning approaches", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 80, "end": 93, "i_start": 11, "i_end": 12}}, {"character": {"text": "approaches", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 85, "end": 93, "i_start": 12, "i_end": 12}}], "id": 2665}, {"sent": "the dashed curve represents the one-dimensional planewave theory .", "tokens": ["the", "dashed", "curve", "represents", "the", "one", "-", "dimensional", "planewave", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the dashed curve", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "represents", "start": 17, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "curve", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "represents", "start": 17, "end": 27, "i_start": 3, "i_end": 3}}], "id": 2666}, {"sent": "asterisks denote hls galaxies , all of which have no hblrs .", "tokens": ["asterisks", "denote", "hls", "galaxies", ",", "all", "of", "which", "have", "no", "hblrs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "asterisks", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "galaxies", "start": 21, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "have no", "start": 45, "end": 52, "i_start": 8, "i_end": 9}}], "id": 2667}, {"sent": "we have used the python implementation of the algorithms available in the scikit-learn library .", "tokens": ["we", "have", "used", "the", "python", "implementation", "of", "the", "algorithms", "available", "in", "the", "scikit", "-", "learn", "library", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have used", "start": 3, "end": 12, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implementation", "start": 24, "end": 38, "i_start": 5, "i_end": 5}}], "id": 2668}, {"sent": "the model was trained using adam gradient-based optimization algorithm with a mini-batch size of 128 .", "tokens": ["the", "model", "was", "trained", "using", "adam", "gradient", "-", "based", "optimization", "algorithm", "with", "a", "mini", "-", "batch", "size", "of", "128", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "was trained", "start": 10, "end": 21, "i_start": 2, "i_end": 3}}], "id": 2669}, {"sent": "although more recent approaches have incorporated time into these models , current methods do not focus on inferring the driving force behind animal actions and instead simply show where an animal is likely to be found .", "tokens": ["although", "more", "recent", "approaches", "have", "incorporated", "time", "into", "these", "models", ",", "current", "methods", "do", "not", "focus", "on", "inferring", "the", "driving", "force", "behind", "animal", "actions", "and", "instead", "simply", "show", "where", "an", "animal", "is", "likely", "to", "be", "found", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "current methods", "start": 75, "end": 90, "i_start": 11, "i_end": 12}, "verb": {"text": "do not focus", "start": 91, "end": 103, "i_start": 13, "i_end": 15}}, {"subject": {"text": "current methods", "start": 75, "end": 90, "i_start": 11, "i_end": 12}, "verb": {"text": "show", "start": 176, "end": 180, "i_start": 27, "i_end": 27}}, {"character": {"text": "methods", "start": 83, "end": 90, "i_start": 12, "i_end": 12}, "action": {"text": "not focus", "start": 94, "end": 103, "i_start": 14, "i_end": 15}}, {"character": {"text": "methods", "start": 83, "end": 90, "i_start": 12, "i_end": 12}, "action": {"text": "inferring", "start": 107, "end": 116, "i_start": 17, "i_end": 17}}, {"character": {"text": "force", "start": 129, "end": 134, "i_start": 20, "i_end": 20}, "action": {"text": "driving", "start": 121, "end": 128, "i_start": 19, "i_end": 19}}, {"character": {"text": "methods", "start": 83, "end": 90, "i_start": 12, "i_end": 12}, "action": {"text": "show", "start": 176, "end": 180, "i_start": 27, "i_end": 27}}], "id": 2670}, {"sent": "in this section , we evaluate the proposed methods on the pascal voc 2012 dataset and the microsoft coco dataset .", "tokens": ["in", "this", "section", ",", "we", "evaluate", "the", "proposed", "methods", "on", "the", "pascal", "voc", "2012", "dataset", "and", "the", "microsoft", "coco", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "evaluate", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "evaluate", "start": 21, "end": 29, "i_start": 5, "i_end": 5}}], "id": 2671}, {"sent": "each stream is imple- mented by two noisy linear layers and relu .", "tokens": ["each", "stream", "is", "imple-", "mented", "by", "two", "noisy", "linear", "layers", "and", "relu", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2672}, {"sent": "the value of ymax does not depend on the inclination i .", "tokens": ["the", "value", "of", "ymax", "does", "not", "depend", "on", "the", "inclination", "i", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the value of ymax", "start": 0, "end": 17, "i_start": 0, "i_end": 3}, "verb": {"text": "does not depend", "start": 18, "end": 33, "i_start": 4, "i_end": 6}}, {"character": {"text": "value", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "not depend", "start": 23, "end": 33, "i_start": 5, "i_end": 6}}], "id": 2673}, {"sent": "deep convolutional neural networks have shown promising performances on various computer vision problems such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "shown", "promising", "performances", "on", "various", "computer", "vision", "problems", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have shown", "start": 35, "end": 45, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 40, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performances", "start": 56, "end": 68, "i_start": 7, "i_end": 7}}, {"character": {"text": "performances", "start": 56, "end": 68, "i_start": 7, "i_end": 7}, "action": {"text": "promising", "start": 46, "end": 55, "i_start": 6, "i_end": 6}}], "id": 2674}, {"sent": "chirality is a property of the whole su operator will be annihilated by the same q-s .", "tokens": ["chirality", "is", "a", "property", "of", "the", "whole", "su", "operator", "will", "be", "annihilated", "by", "the", "same", "q", "-", "s", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "chirality", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 1, "i_end": 1}}, {"subject": {"text": "a property of the whole su operator", "start": 13, "end": 48, "i_start": 2, "i_end": 8}, "verb": {"text": "annihilated", "start": 57, "end": 68, "i_start": 11, "i_end": 11}}], "id": 2675}, {"sent": "ledig et al introduced adversarial loss from the generative adversarial nets to minimize the perceptually relevant distance between the sr and hr images .", "tokens": ["ledig", "et", "al", "introduced", "adversarial", "loss", "from", "the", "generative", "adversarial", "nets", "to", "minimize", "the", "perceptually", "relevant", "distance", "between", "the", "sr", "and", "hr", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "ledig et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "introduced", "start": 12, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "ledig", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 12, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "ledig", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "minimize", "start": 80, "end": 88, "i_start": 12, "i_end": 12}}], "id": 2676}, {"sent": "deep learning has contributed to dramatic advances in scalability and performance of machine learning .", "tokens": ["deep", "learning", "has", "contributed", "to", "dramatic", "advances", "in", "scalability", "and", "performance", "of", "machine", "learning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has contributed", "start": 14, "end": 29, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "contributed", "start": 18, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "learning", "start": 93, "end": 101, "i_start": 13, "i_end": 13}, "action": {"text": "performance", "start": 70, "end": 81, "i_start": 10, "i_end": 10}}], "id": 2677}, {"sent": "the vertical-east-west orientation is the only one that produces a rich array of detectable harmonics .", "tokens": ["the", "vertical", "-", "east", "-", "west", "orientation", "is", "the", "only", "one", "that", "produces", "a", "rich", "array", "of", "detectable", "harmonics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the vertical-east-west orientation", "start": 0, "end": 34, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 7, "i_end": 7}}], "id": 2678}, {"sent": "facility location is an old and well-studied problem in operations research that arises in contexts such as locating hospitals in a city or locating distribution centers in a region .", "tokens": ["facility", "location", "is", "an", "old", "and", "well", "-", "studied", "problem", "in", "operations", "research", "that", "arises", "in", "contexts", "such", "as", "locating", "hospitals", "in", "a", "city", "or", "locating", "distribution", "centers", "in", "a", "region", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "facility location", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}], "id": 2679}, {"sent": "po weighted round robin achieves the highest throughput because it distributes the packets of the single long lived connection over all interfaces .", "tokens": ["po", "weighted", "round", "robin", "achieves", "the", "highest", "throughput", "because", "it", "distributes", "the", "packets", "of", "the", "single", "long", "lived", "connection", "over", "all", "interfaces", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "po", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "weighted", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"subject": {"text": "round robin", "start": 12, "end": 23, "i_start": 2, "i_end": 3}, "verb": {"text": "achieves", "start": 24, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "distributes", "start": 67, "end": 78, "i_start": 10, "i_end": 10}, "action": {"text": "because", "start": 56, "end": 63, "i_start": 8, "i_end": 8}}], "id": 2680}, {"sent": "the dotted and dashed lines represent the pure coulomb and nuclear breakup contributions , respectively while their coherent sums are shown by solid lines .", "tokens": ["the", "dotted", "and", "dashed", "lines", "represent", "the", "pure", "coulomb", "and", "nuclear", "breakup", "contributions", ",", "respectively", "while", "their", "coherent", "sums", "are", "shown", "by", "solid", "lines", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the dotted and dashed lines", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "represent", "start": 28, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "lines", "start": 22, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "represent", "start": 28, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "lines", "start": 149, "end": 154, "i_start": 23, "i_end": 23}, "action": {"text": "represent", "start": 28, "end": 37, "i_start": 5, "i_end": 5}}], "id": 2681}, {"sent": "for instance , zhu et al introduce cyclegan framework , which achieves unpaired image-to-image translation using the cycle-consistency loss .", "tokens": ["for", "instance", ",", "zhu", "et", "al", "introduce", "cyclegan", "framework", ",", "which", "achieves", "unpaired", "image", "-", "to", "-", "image", "translation", "using", "the", "cycle", "-", "consistency", "loss", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhu et al", "start": 15, "end": 24, "i_start": 3, "i_end": 5}, "verb": {"text": "introduce", "start": 25, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "zhu", "start": 15, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "introduce", "start": 25, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "framework", "start": 44, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "achieves", "start": 62, "end": 70, "i_start": 11, "i_end": 11}}], "id": 2682}, {"sent": "the hierarchical bayesian optimization algorithm evolves a population of candidate solutions to the given problem .", "tokens": ["the", "hierarchical", "bayesian", "optimization", "algorithm", "evolves", "a", "population", "of", "candidate", "solutions", "to", "the", "given", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the hierarchical bayesian optimization algorithm", "start": 0, "end": 48, "i_start": 0, "i_end": 4}, "verb": {"text": "evolves", "start": 49, "end": 56, "i_start": 5, "i_end": 5}}, {"character": {"text": "algorithm", "start": 39, "end": 48, "i_start": 4, "i_end": 4}, "action": {"text": "evolves", "start": 49, "end": 56, "i_start": 5, "i_end": 5}}], "id": 2683}, {"sent": "deep neural networks are widely used for many applications including object recognition .", "tokens": ["deep", "neural", "networks", "are", "widely", "used", "for", "many", "applications", "including", "object", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 32, "end": 36, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2684}, {"sent": "large-scale deep convolutional neural networks have been successfully applied to a wide variety of applications such as image classification .", "tokens": ["large", "-", "scale", "deep", "convolutional", "neural", "networks", "have", "been", "successfully", "applied", "to", "a", "wide", "variety", "of", "applications", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "large-scale deep convolutional neural networks", "start": 0, "end": 46, "i_start": 0, "i_end": 6}, "verb": {"text": "applied", "start": 70, "end": 77, "i_start": 10, "i_end": 10}}, {"subject": {"text": "large-scale deep convolutional neural networks", "start": 0, "end": 46, "i_start": 0, "i_end": 6}, "verb": {"text": "have been", "start": 47, "end": 56, "i_start": 7, "i_end": 8}}], "id": 2685}, {"sent": "here , we use a 19-layer vgg network pretrained on the imagenet dataset .", "tokens": ["here", ",", "we", "use", "a", "19", "-", "layer", "vgg", "network", "pretrained", "on", "the", "imagenet", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "use", "start": 10, "end": 13, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 10, "end": 13, "i_start": 3, "i_end": 3}}], "id": 2686}, {"sent": "it is easy to see that the lagrangian is explicitly invariant under this transformation .", "tokens": ["it", "is", "easy", "to", "see", "that", "the", "lagrangian", "is", "explicitly", "invariant", "under", "this", "transformation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}], "id": 2687}, {"sent": "success of convolutional neural networks over the past several years has lead to their extensive deployment in a wide range of computer vision tasks .", "tokens": ["success", "of", "convolutional", "neural", "networks", "over", "the", "past", "several", "years", "has", "lead", "to", "their", "extensive", "deployment", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "success of convolutional neural networks over the past several years", "start": 0, "end": 68, "i_start": 0, "i_end": 9}, "verb": {"text": "has lead", "start": 69, "end": 77, "i_start": 10, "i_end": 11}}, {"character": {"text": "success", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "lead", "start": 73, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "success", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}], "id": 2688}, {"sent": "deep neural networks have been significantly successful in many artificial intelligence tasks such as im- age classification .", "tokens": ["deep", "neural", "networks", "have", "been", "significantly", "successful", "in", "many", "artificial", "intelligence", "tasks", "such", "as", "im-", "age", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 45, "end": 55, "i_start": 6, "i_end": 6}}], "id": 2689}, {"sent": "for the sake of brevity , we refer the reader to vaswani et al for more details .", "tokens": ["for", "the", "sake", "of", "brevity", ",", "we", "refer", "the", "reader", "to", "vaswani", "et", "al", "for", "more", "details", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 26, "end": 28, "i_start": 6, "i_end": 6}, "verb": {"text": "refer", "start": 29, "end": 34, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 26, "end": 28, "i_start": 6, "i_end": 6}, "action": {"text": "refer", "start": 29, "end": 34, "i_start": 7, "i_end": 7}}], "id": 2690}, {"sent": "thermal relaxation during electron transmission .", "tokens": ["thermal", "relaxation", "during", "electron", "transmission", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2691}, {"sent": "now we show that in case of the lowest singularity the hyperelliptic involution of y\u03c3 does not have real fixed points .", "tokens": ["now", "we", "show", "that", "in", "case", "of", "the", "lowest", "singularity", "the", "hyperelliptic", "involution", "of", "y\u03c3", "does", "not", "have", "real", "fixed", "points", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "show", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the hyperelliptic involution of y\u03c3", "start": 51, "end": 85, "i_start": 10, "i_end": 14}, "verb": {"text": "have", "start": 95, "end": 99, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}], "id": 2692}, {"sent": "the spacetime is a perturbed friedmann-robertson-walker universe .", "tokens": ["the", "spacetime", "is", "a", "perturbed", "friedmann", "-", "robertson", "-", "walker", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the spacetime", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 2693}, {"sent": "a soliton is the extremely robust , nonlinear excitation localized in space , which has particlelike properties .", "tokens": ["a", "soliton", "is", "the", "extremely", "robust", ",", "nonlinear", "excitation", "localized", "in", "space", ",", "which", "has", "particlelike", "properties", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a soliton", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}], "id": 2694}, {"sent": "quantum field theory is a relativistic theory .", "tokens": ["quantum", "field", "theory", "is", "a", "relativistic", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum field theory", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 3, "i_end": 3}}], "id": 2695}, {"sent": "the decoherence rates that are optimal to the ete are found by numerical simulation of the equation of motion .", "tokens": ["the", "decoherence", "rates", "that", "are", "optimal", "to", "the", "ete", "are", "found", "by", "numerical", "simulation", "of", "the", "equation", "of", "motion", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the decoherence rates that are optimal to the ete", "start": 0, "end": 49, "i_start": 0, "i_end": 8}, "verb": {"text": "are found", "start": 50, "end": 59, "i_start": 9, "i_end": 10}}], "id": 2696}, {"sent": "more general , in traditional multi-view geometry framework , multiple cameras in different poses are defined as a set of unconstrained rays , which is known as generalized camera model .", "tokens": ["more", "general", ",", "in", "traditional", "multi", "-", "view", "geometry", "framework", ",", "multiple", "cameras", "in", "different", "poses", "are", "defined", "as", "a", "set", "of", "unconstrained", "rays", ",", "which", "is", "known", "as", "generalized", "camera", "model", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "more general , in traditional multi-view geometry framework , multiple cameras in different poses", "start": 0, "end": 97, "i_start": 0, "i_end": 15}, "verb": {"text": "are defined", "start": 98, "end": 109, "i_start": 16, "i_end": 17}}], "id": 2697}, {"sent": "this allows us to constrain the ir behavior of the theory .", "tokens": ["this", "allows", "us", "to", "constrain", "the", "ir", "behavior", "of", "the", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "allows", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}, {"subject": {"text": "us", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "constrain", "start": 18, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "allows", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "us", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "constrain", "start": 18, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "theory", "start": 51, "end": 57, "i_start": 10, "i_end": 10}, "action": {"text": "behavior", "start": 35, "end": 43, "i_start": 7, "i_end": 7}}], "id": 2698}, {"sent": "constraint-based termination analysis of logic programs .", "tokens": ["constraint", "-", "based", "termination", "analysis", "of", "logic", "programs", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2699}, {"sent": "it is well known that for the micron range of wavelengths only the intensity of the scattered wave field can be measured , and the phase can not be measured .", "tokens": ["it", "is", "well", "known", "that", "for", "the", "micron", "range", "of", "wavelengths", "only", "the", "intensity", "of", "the", "scattered", "wave", "field", "can", "be", "measured", ",", "and", "the", "phase", "can", "not", "be", "measured", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "only the intensity of the scattered wave field", "start": 58, "end": 104, "i_start": 11, "i_end": 18}, "verb": {"text": "measured", "start": 112, "end": 120, "i_start": 21, "i_end": 21}}, {"subject": {"text": "the phase", "start": 127, "end": 136, "i_start": 24, "i_end": 25}, "verb": {"text": "measured", "start": 148, "end": 156, "i_start": 29, "i_end": 29}}], "id": 2700}, {"sent": "this arrange- drawing inspiration from biological neurons to implement machine learning was the topic of the first paper presented at the first machine learning conference in 1955 .", "tokens": ["this", "arrange-", "drawing", "inspiration", "from", "biological", "neurons", "to", "implement", "machine", "learning", "was", "the", "topic", "of", "the", "first", "paper", "presented", "at", "the", "first", "machine", "learning", "conference", "in", "1955", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "this arrange- drawing inspiration from biological neurons to implement machine learning", "start": 0, "end": 87, "i_start": 0, "i_end": 10}, "verb": {"text": "was", "start": 88, "end": 91, "i_start": 11, "i_end": 11}}], "id": 2701}, {"sent": "therefore , each polyhedron is a tetrahedron that is preserved by the involution .", "tokens": ["therefore", ",", "each", "polyhedron", "is", "a", "tetrahedron", "that", "is", "preserved", "by", "the", "involution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each polyhedron", "start": 12, "end": 27, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "involution", "start": 70, "end": 80, "i_start": 12, "i_end": 12}, "action": {"text": "preserved", "start": 53, "end": 62, "i_start": 9, "i_end": 9}}], "id": 2702}, {"sent": "generative adversarial networks define a framework for training a generative model by posing it as a minimax game .", "tokens": ["generative", "adversarial", "networks", "define", "a", "framework", "for", "training", "a", "generative", "model", "by", "posing", "it", "as", "a", "minimax", "game", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "define", "start": 32, "end": 38, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "define", "start": 32, "end": 38, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "posing", "start": 86, "end": 92, "i_start": 12, "i_end": 12}}], "id": 2703}, {"sent": "each node runs the redhat federo core 6 linux with the kprobe feature enabled .", "tokens": ["each", "node", "runs", "the", "redhat", "federo", "core", "6", "linux", "with", "the", "kprobe", "feature", "enabled", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "each node", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "runs", "start": 10, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "node", "start": 5, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "runs", "start": 10, "end": 14, "i_start": 2, "i_end": 2}}], "id": 2704}, {"sent": "neural networks recently have been used to solve many real-world tasks such as image recognition and can achieve high effectiveness on these tasks .", "tokens": ["neural", "networks", "recently", "have", "been", "used", "to", "solve", "many", "real", "-", "world", "tasks", "such", "as", "image", "recognition", "and", "can", "achieve", "high", "effectiveness", "on", "these", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have been used", "start": 25, "end": 39, "i_start": 3, "i_end": 5}}, {"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "achieve", "start": 105, "end": 112, "i_start": 19, "i_end": 19}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "solve", "start": 43, "end": 48, "i_start": 7, "i_end": 7}}], "id": 2705}, {"sent": "recent research shows that deep neural network classifier can be tested and further fooled by adversarial examples .", "tokens": ["recent", "research", "shows", "that", "deep", "neural", "network", "classifier", "can", "be", "tested", "and", "further", "fooled", "by", "adversarial", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent research", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "shows", "start": 16, "end": 21, "i_start": 2, "i_end": 2}}, {"subject": {"text": "deep neural network classifier", "start": 27, "end": 57, "i_start": 4, "i_end": 7}, "verb": {"text": "tested", "start": 65, "end": 71, "i_start": 10, "i_end": 10}}, {"character": {"text": "research", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "shows", "start": 16, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "examples", "start": 106, "end": 114, "i_start": 16, "i_end": 16}, "action": {"text": "fooled", "start": 84, "end": 90, "i_start": 13, "i_end": 13}}], "id": 2706}, {"sent": "then p has a subgroup p 0 of finite index which can be embedded as a lattice into a connected , simply-connected , solvable lie group \u03b3 .", "tokens": ["then", "p", "has", "a", "subgroup", "p", "0", "of", "finite", "index", "which", "can", "be", "embedded", "as", "a", "lattice", "into", "a", "connected", ",", "simply", "-", "connected", ",", "solvable", "lie", "group", "\u03b3", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "p", "start": 5, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "has", "start": 7, "end": 10, "i_start": 2, "i_end": 2}}], "id": 2707}, {"sent": "recently , deep convolutional neural networks have achieved great successes in computer vision topics such as image classification .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "achieved", "great", "successes", "in", "computer", "vision", "topics", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "successes", "start": 66, "end": 75, "i_start": 9, "i_end": 9}}], "id": 2708}, {"sent": "millimeter wave communication is deemed as a promising technique for meeting the ever-increasing traffic demand in next generation wireless communication systems .", "tokens": ["millimeter", "wave", "communication", "is", "deemed", "as", "a", "promising", "technique", "for", "meeting", "the", "ever", "-", "increasing", "traffic", "demand", "in", "next", "generation", "wireless", "communication", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "millimeter wave communication", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "is deemed", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "technique", "start": 55, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "promising", "start": 45, "end": 54, "i_start": 7, "i_end": 7}}, {"character": {"text": "systems", "start": 154, "end": 161, "i_start": 22, "i_end": 22}, "action": {"text": "demand", "start": 105, "end": 111, "i_start": 16, "i_end": 16}}], "id": 2709}, {"sent": "we will give now explicit continuous families of hypercomplex structures on some particular nilpotent lie groups .", "tokens": ["we", "will", "give", "now", "explicit", "continuous", "families", "of", "hypercomplex", "structures", "on", "some", "particular", "nilpotent", "lie", "groups", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will give", "start": 3, "end": 12, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "give", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "groups", "start": 106, "end": 112, "i_start": 15, "i_end": 15}, "action": {"text": "lie", "start": 102, "end": 105, "i_start": 14, "i_end": 14}}], "id": 2710}, {"sent": "each orbit consists of a square-free word and its images under permutation of letters , and each letter has the same mean frequency on this orbit .", "tokens": ["each", "orbit", "consists", "of", "a", "square", "-", "free", "word", "and", "its", "images", "under", "permutation", "of", "letters", ",", "and", "each", "letter", "has", "the", "same", "mean", "frequency", "on", "this", "orbit", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each orbit", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}, {"subject": {"text": "each letter", "start": 92, "end": 103, "i_start": 18, "i_end": 19}, "verb": {"text": "has", "start": 104, "end": 107, "i_start": 20, "i_end": 20}}], "id": 2711}, {"sent": "recently , convolutional neural networks -based methods achieve great success in image classification tasks .", "tokens": ["recently", ",", "convolutional", "neural", "networks", "-based", "methods", "achieve", "great", "success", "in", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks -based methods", "start": 11, "end": 55, "i_start": 2, "i_end": 6}, "verb": {"text": "achieve", "start": 56, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "methods", "start": 48, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "achieve", "start": 56, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "methods", "start": 48, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 70, "end": 77, "i_start": 9, "i_end": 9}}], "id": 2712}, {"sent": "scale invariant feature transform was used in conjunction with the bag of words to recognize adult images in .", "tokens": ["scale", "invariant", "feature", "transform", "was", "used", "in", "conjunction", "with", "the", "bag", "of", "words", "to", "recognize", "adult", "images", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "scale invariant feature transform", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "was used", "start": 34, "end": 42, "i_start": 4, "i_end": 5}}], "id": 2713}, {"sent": "since the pentaquark is a color singlet , the color wave function of the two diquarks within the pentaquark must be antisymmetric 3c .", "tokens": ["since", "the", "pentaquark", "is", "a", "color", "singlet", ",", "the", "color", "wave", "function", "of", "the", "two", "diquarks", "within", "the", "pentaquark", "must", "be", "antisymmetric", "3c", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the color wave function of the two diquarks within the pentaquark", "start": 42, "end": 107, "i_start": 8, "i_end": 18}, "verb": {"text": "must be", "start": 108, "end": 115, "i_start": 19, "i_end": 20}}, {"character": {"text": "two diquarks", "start": 73, "end": 85, "i_start": 14, "i_end": 15}, "action": {"text": "function", "start": 57, "end": 65, "i_start": 11, "i_end": 11}}], "id": 2714}, {"sent": "existing approaches to tackling this challenge include using transfer learning .", "tokens": ["existing", "approaches", "to", "tackling", "this", "challenge", "include", "using", "transfer", "learning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "existing approaches to tackling this challenge", "start": 0, "end": 46, "i_start": 0, "i_end": 5}, "verb": {"text": "include", "start": 47, "end": 54, "i_start": 6, "i_end": 6}}], "id": 2715}, {"sent": "the problem of sparse signal recovery has many potential applications and has received much attention in recent years with the development of compressed sensing .", "tokens": ["the", "problem", "of", "sparse", "signal", "recovery", "has", "many", "potential", "applications", "and", "has", "received", "much", "attention", "in", "recent", "years", "with", "the", "development", "of", "compressed", "sensing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the problem of sparse signal recovery", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "has", "start": 38, "end": 41, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the problem of sparse signal recovery", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "received", "start": 78, "end": 86, "i_start": 12, "i_end": 12}}], "id": 2716}, {"sent": "semiclassically the phase space is the natural setting whereas the quantum approach invokes high order perturbation theory involving a chain of off-resonant virtual states .", "tokens": ["semiclassically", "the", "phase", "space", "is", "the", "natural", "setting", "whereas", "the", "quantum", "approach", "invokes", "high", "order", "perturbation", "theory", "involving", "a", "chain", "of", "off", "-", "resonant", "virtual", "states", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the phase space", "start": 16, "end": 31, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "approach", "start": 75, "end": 83, "i_start": 11, "i_end": 11}, "action": {"text": "invokes", "start": 84, "end": 91, "i_start": 12, "i_end": 12}}], "id": 2717}, {"sent": "it was shown in that under average power , amplitude , and nonlinear delivered power constraints , the optimal capacity achieving distributions are discrete with a finite number of mass points for the amplitude and continuous uniform for the phase .", "tokens": ["it", "was", "shown", "in", "that", "under", "average", "power", ",", "amplitude", ",", "and", "nonlinear", "delivered", "power", "constraints", ",", "the", "optimal", "capacity", "achieving", "distributions", "are", "discrete", "with", "a", "finite", "number", "of", "mass", "points", "for", "the", "amplitude", "and", "continuous", "uniform", "for", "the", "phase", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "was shown", "start": 3, "end": 12, "i_start": 1, "i_end": 2}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "delivered", "start": 69, "end": 78, "i_start": 13, "i_end": 13}}, {"character": {"text": "capacity", "start": 111, "end": 119, "i_start": 19, "i_end": 19}, "action": {"text": "achieving", "start": 120, "end": 129, "i_start": 20, "i_end": 20}}], "id": 2718}, {"sent": "we use an implementation of regression trees from the scikit-learn machine learning module in python .", "tokens": ["we", "use", "an", "implementation", "of", "regression", "trees", "from", "the", "scikit", "-", "learn", "machine", "learning", "module", "in", "python", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implementation", "start": 10, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2719}, {"sent": "recently deep neural networks have attained impressive performance in many fields such as image classification .", "tokens": ["recently", "deep", "neural", "networks", "have", "attained", "impressive", "performance", "in", "many", "fields", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 9, "end": 29, "i_start": 1, "i_end": 3}, "verb": {"text": "have attained", "start": 30, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "attained", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 55, "end": 66, "i_start": 7, "i_end": 7}}, {"character": {"text": "performance", "start": 55, "end": 66, "i_start": 7, "i_end": 7}, "action": {"text": "impressive", "start": 44, "end": 54, "i_start": 6, "i_end": 6}}], "id": 2720}, {"sent": "recent related efforts such as lee et al also provide new insights into convergence properties of gradient descent on non-convex error surfaces , but assume the saddles to be non-degenerate .", "tokens": ["recent", "related", "efforts", "such", "as", "lee", "et", "al", "also", "provide", "new", "insights", "into", "convergence", "properties", "of", "gradient", "descent", "on", "non", "-", "convex", "error", "surfaces", ",", "but", "assume", "the", "saddles", "to", "be", "non", "-", "degenerate", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent related efforts such as lee et al", "start": 0, "end": 40, "i_start": 0, "i_end": 7}, "verb": {"text": "provide", "start": 46, "end": 53, "i_start": 9, "i_end": 9}}, {"subject": {"text": "recent related efforts such as lee et al", "start": 0, "end": 40, "i_start": 0, "i_end": 7}, "verb": {"text": "assume", "start": 150, "end": 156, "i_start": 26, "i_end": 26}}, {"character": {"text": "efforts", "start": 15, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "provide", "start": 46, "end": 53, "i_start": 9, "i_end": 9}}], "id": 2721}, {"sent": "convolutional neural networks have achieved state-of-the-art results on several computer vision tasks .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "results", "on", "several", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 2722}, {"sent": "each convolutional layer is followed by batch normalization and a relu .", "tokens": ["each", "convolutional", "layer", "is", "followed", "by", "batch", "normalization", "and", "a", "relu", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each convolutional layer", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is followed", "start": 25, "end": 36, "i_start": 3, "i_end": 4}}], "id": 2723}, {"sent": "correct localization is to test the proposed model on the training set measuring the localization accuracy .", "tokens": ["correct", "localization", "is", "to", "test", "the", "proposed", "model", "on", "the", "training", "set", "measuring", "the", "localization", "accuracy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "correct localization", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "set", "start": 67, "end": 70, "i_start": 11, "i_end": 11}, "action": {"text": "measuring", "start": 71, "end": 80, "i_start": 12, "i_end": 12}}], "id": 2724}, {"sent": "deep convolutional neural networks have improved performance of many tasks in computer vision , such as image recognition .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "improved", "performance", "of", "many", "tasks", "in", "computer", "vision", ",", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have improved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 49, "end": 60, "i_start": 6, "i_end": 6}}], "id": 2725}, {"sent": "we compared our method with other 12 algorithms , including 10 deep learning based algorithms and 2 conventional algorithms .", "tokens": ["we", "compared", "our", "method", "with", "other", "12", "algorithms", ",", "including", "10", "deep", "learning", "based", "algorithms", "and", "2", "conventional", "algorithms", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compared", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compared", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2726}, {"sent": "generative models such as variational autoencoders and generative adversarial networks have emerged as popular techniques for unsupervised learning of intractable distributions .", "tokens": ["generative", "models", "such", "as", "variational", "autoencoders", "and", "generative", "adversarial", "networks", "have", "emerged", "as", "popular", "techniques", "for", "unsupervised", "learning", "of", "intractable", "distributions", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "generative models such as variational autoencoders and generative adversarial networks", "start": 0, "end": 86, "i_start": 0, "i_end": 9}, "verb": {"text": "have emerged", "start": 87, "end": 99, "i_start": 10, "i_end": 11}}, {"character": {"text": "models", "start": 11, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "emerged", "start": 92, "end": 99, "i_start": 11, "i_end": 11}}], "id": 2727}, {"sent": "we only show the first statement , since the second one is an immediate consequence .", "tokens": ["we", "only", "show", "the", "first", "statement", ",", "since", "the", "second", "one", "is", "an", "immediate", "consequence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}], "id": 2728}, {"sent": "this execution satisfies the strongly fair scheduling .", "tokens": ["this", "execution", "satisfies", "the", "strongly", "fair", "scheduling", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this execution", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "satisfies", "start": 15, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "execution", "start": 5, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "satisfies", "start": 15, "end": 24, "i_start": 2, "i_end": 2}}], "id": 2729}, {"sent": "since it is intractable to obtain the full knowledge of each rb state directly , the mtcd needs to observe the rb state based on the state transition and optimal action taken in this time slot .", "tokens": ["since", "it", "is", "intractable", "to", "obtain", "the", "full", "knowledge", "of", "each", "rb", "state", "directly", ",", "the", "mtcd", "needs", "to", "observe", "the", "rb", "state", "based", "on", "the", "state", "transition", "and", "optimal", "action", "taken", "in", "this", "time", "slot", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the mtcd", "start": 81, "end": 89, "i_start": 15, "i_end": 16}, "verb": {"text": "needs", "start": 90, "end": 95, "i_start": 17, "i_end": 17}}, {"character": {"text": "state", "start": 64, "end": 69, "i_start": 12, "i_end": 12}, "action": {"text": "knowledge", "start": 43, "end": 52, "i_start": 8, "i_end": 8}}], "id": 2730}, {"sent": "we use the pbe exchange-correlation functional of the generalized gradient approximation to obtain adequate structures .", "tokens": ["we", "use", "the", "pbe", "exchange", "-", "correlation", "functional", "of", "the", "generalized", "gradient", "approximation", "to", "obtain", "adequate", "structures", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "approximation", "start": 75, "end": 88, "i_start": 12, "i_end": 12}, "action": {"text": "functional", "start": 36, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "obtain", "start": 92, "end": 98, "i_start": 14, "i_end": 14}}], "id": 2731}, {"sent": "mfdh proposed in this paper is compared with six state-of-the-art cross-modal hashing methods , including cca .", "tokens": ["mfdh", "proposed", "in", "this", "paper", "is", "compared", "with", "six", "state", "-", "of", "-", "the", "-", "art", "cross", "-", "modal", "hashing", "methods", ",", "including", "cca", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "mfdh", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "proposed", "start": 5, "end": 13, "i_start": 1, "i_end": 1}}, {"subject": {"text": "mfdh", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "compared", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "mfdh", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 5, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "hashing", "start": 78, "end": 85, "i_start": 19, "i_end": 19}, "action": {"text": "cross", "start": 66, "end": 71, "i_start": 16, "i_end": 16}}], "id": 2732}, {"sent": "inspired by these high-capacity models in deep learning , some deep embedding models have been developed for person re-id to learn representations against visual variations .", "tokens": ["inspired", "by", "these", "high", "-", "capacity", "models", "in", "deep", "learning", ",", "some", "deep", "embedding", "models", "have", "been", "developed", "for", "person", "re", "-", "id", "to", "learn", "representations", "against", "visual", "variations", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "some deep embedding models", "start": 58, "end": 84, "i_start": 11, "i_end": 14}, "verb": {"text": "have been developed", "start": 85, "end": 104, "i_start": 15, "i_end": 17}}, {"character": {"text": "models", "start": 78, "end": 84, "i_start": 14, "i_end": 14}, "action": {"text": "inspired", "start": 0, "end": 8, "i_start": 0, "i_end": 0}}], "id": 2733}, {"sent": "additionally , we have developed a theoretical description of local membrane deformations due to local ph variations .", "tokens": ["additionally", ",", "we", "have", "developed", "a", "theoretical", "description", "of", "local", "membrane", "deformations", "due", "to", "local", "ph", "variations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "have developed", "start": 18, "end": 32, "i_start": 3, "i_end": 4}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "developed", "start": 23, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "description", "start": 47, "end": 58, "i_start": 7, "i_end": 7}}], "id": 2734}, {"sent": "more precisely , the following result was obtained .", "tokens": ["more", "precisely", ",", "the", "following", "result", "was", "obtained", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the following result", "start": 17, "end": 37, "i_start": 3, "i_end": 5}, "verb": {"text": "was obtained", "start": 38, "end": 50, "i_start": 6, "i_end": 7}}], "id": 2735}, {"sent": "the low energy properties of one-dimensional quantum systems are commonly described in the framework of the so-called tomonaga-luttinger liquid .", "tokens": ["the", "low", "energy", "properties", "of", "one", "-", "dimensional", "quantum", "systems", "are", "commonly", "described", "in", "the", "framework", "of", "the", "so", "-", "called", "tomonaga", "-", "luttinger", "liquid", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the low energy properties of one-dimensional quantum systems", "start": 0, "end": 60, "i_start": 0, "i_end": 9}, "verb": {"text": "described", "start": 74, "end": 83, "i_start": 12, "i_end": 12}}, {"subject": {"text": "the low energy properties of one-dimensional quantum systems", "start": 0, "end": 60, "i_start": 0, "i_end": 9}, "verb": {"text": "are", "start": 61, "end": 64, "i_start": 10, "i_end": 10}}], "id": 2736}, {"sent": "since the number of string states rises exponentially with energy , there is a maximal temperature which the thermal string gas can reach , the so-called hagedorn temperature t h .", "tokens": ["since", "the", "number", "of", "string", "states", "rises", "exponentially", "with", "energy", ",", "there", "is", "a", "maximal", "temperature", "which", "the", "thermal", "string", "gas", "can", "reach", ",", "the", "so", "-", "called", "hagedorn", "temperature", "t", "h", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "there", "start": 68, "end": 73, "i_start": 11, "i_end": 11}, "verb": {"text": "is", "start": 74, "end": 76, "i_start": 12, "i_end": 12}}, {"character": {"text": "gas", "start": 124, "end": 127, "i_start": 20, "i_end": 20}, "action": {"text": "reach", "start": 132, "end": 137, "i_start": 22, "i_end": 22}}], "id": 2737}, {"sent": "this is because the run time and storage requirement of the cse algorithm in become infeasible for large lengths .", "tokens": ["this", "is", "because", "the", "run", "time", "and", "storage", "requirement", "of", "the", "cse", "algorithm", "in", "become", "infeasible", "for", "large", "lengths", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "become", "start": 77, "end": 83, "i_start": 14, "i_end": 14}, "action": {"text": "because", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "algorithm", "start": 64, "end": 73, "i_start": 12, "i_end": 12}, "action": {"text": "requirement", "start": 41, "end": 52, "i_start": 8, "i_end": 8}}], "id": 2738}, {"sent": "lavaei and low have shown that sdp relaxation of opf can provide a tight bound for opf problems .", "tokens": ["lavaei", "and", "low", "have", "shown", "that", "sdp", "relaxation", "of", "opf", "can", "provide", "a", "tight", "bound", "for", "opf", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "lavaei and low", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 15, "end": 25, "i_start": 3, "i_end": 4}}, {"subject": {"text": "that sdp relaxation of opf", "start": 26, "end": 52, "i_start": 5, "i_end": 9}, "verb": {"text": "provide", "start": 57, "end": 64, "i_start": 11, "i_end": 11}}, {"character": {"text": "lavaei", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "shown", "start": 20, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "low", "start": 11, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 20, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "relaxation", "start": 35, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "provide", "start": 57, "end": 64, "i_start": 11, "i_end": 11}}], "id": 2739}, {"sent": "indeed , boxler , use the same separation of time scales that underlies centre manifold theory to form and support low-dimensional , long therm models of sdes and spdes that have both fast and slow modes .", "tokens": ["indeed", ",", "boxler", ",", "use", "the", "same", "separation", "of", "time", "scales", "that", "underlies", "centre", "manifold", "theory", "to", "form", "and", "support", "low", "-", "dimensional", ",", "long", "therm", "models", "of", "sdes", "and", "spdes", "that", "have", "both", "fast", "and", "slow", "modes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "boxler", "start": 9, "end": 15, "i_start": 2, "i_end": 2}, "verb": {"text": "use", "start": 18, "end": 21, "i_start": 4, "i_end": 4}}, {"character": {"text": "boxler", "start": 9, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 18, "end": 21, "i_start": 4, "i_end": 4}}, {"character": {"text": "theory", "start": 88, "end": 94, "i_start": 15, "i_end": 15}, "action": {"text": "underlies", "start": 62, "end": 71, "i_start": 12, "i_end": 12}}], "id": 2740}, {"sent": "deep neural networks have been proven impressively successful on certain supervised learning tasks .", "tokens": ["deep", "neural", "networks", "have", "been", "proven", "impressively", "successful", "on", "certain", "supervised", "learning", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been proven", "start": 21, "end": 37, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 51, "end": 61, "i_start": 7, "i_end": 7}}, {"character": {"text": "successful", "start": 51, "end": 61, "i_start": 7, "i_end": 7}, "action": {"text": "impressively", "start": 38, "end": 50, "i_start": 6, "i_end": 6}}], "id": 2741}, {"sent": "a manifold n with a given symplectic form is called a phase space .", "tokens": ["a", "manifold", "n", "with", "a", "given", "symplectic", "form", "is", "called", "a", "phase", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a given symplectic form", "start": 18, "end": 41, "i_start": 4, "i_end": 7}, "verb": {"text": "is called", "start": 42, "end": 51, "i_start": 8, "i_end": 9}}], "id": 2742}, {"sent": "for any topological ring a , let ca denote the full subcategory of a-topalg whose objects are the complete and separated topological a-algebras whose topology is linear .", "tokens": ["for", "any", "topological", "ring", "a", ",", "let", "ca", "denote", "the", "full", "subcategory", "of", "a", "-", "topalg", "whose", "objects", "are", "the", "complete", "and", "separated", "topological", "a", "-", "algebras", "whose", "topology", "is", "linear", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2743}, {"sent": "most rl algorithms can be classified into being either model-free or model-based .", "tokens": ["most", "rl", "algorithms", "can", "be", "classified", "into", "being", "either", "model", "-", "free", "or", "model", "-", "based", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "most rl algorithms", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "can be classified", "start": 19, "end": 36, "i_start": 3, "i_end": 5}}], "id": 2744}, {"sent": "the significant feature is the appearance of a new fundamental constant which allows for a transition between two different theories of the same mathematical type .", "tokens": ["the", "significant", "feature", "is", "the", "appearance", "of", "a", "new", "fundamental", "constant", "which", "allows", "for", "a", "transition", "between", "two", "different", "theories", "of", "the", "same", "mathematical", "type", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the significant feature", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "constant", "start": 63, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "allows", "start": 78, "end": 84, "i_start": 12, "i_end": 12}}], "id": 2745}, {"sent": "we adopt a simple picture that was first conceived by fuchs 75 and afterwards widely used in the study of for instance anomalous skin effect 76 , 78 , 79 .", "tokens": ["we", "adopt", "a", "simple", "picture", "that", "was", "first", "conceived", "by", "fuchs", "75", "and", "afterwards", "widely", "used", "in", "the", "study", "of", "for", "instance", "anomalous", "skin", "effect", "76", ",", "78", ",", "79", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "fuchs", "start": 54, "end": 59, "i_start": 10, "i_end": 10}, "action": {"text": "conceived", "start": 41, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "75", "start": 60, "end": 62, "i_start": 11, "i_end": 11}, "action": {"text": "conceived", "start": 41, "end": 50, "i_start": 8, "i_end": 8}}], "id": 2746}, {"sent": "deep neural networks have led to significant advances in the fields of computer vision , speech processing and natural language processing .", "tokens": ["deep", "neural", "networks", "have", "led", "to", "significant", "advances", "in", "the", "fields", "of", "computer", "vision", ",", "speech", "processing", "and", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have led", "start": 21, "end": 29, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "led", "start": 26, "end": 29, "i_start": 4, "i_end": 4}}], "id": 2747}, {"sent": "gliese 337cd is a particularly vital case , as the physical parameters of the substellar components can be constrained by the properties of the stellar primaries .", "tokens": ["gliese", "337cd", "is", "a", "particularly", "vital", "case", ",", "as", "the", "physical", "parameters", "of", "the", "substellar", "components", "can", "be", "constrained", "by", "the", "properties", "of", "the", "stellar", "primaries", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "gliese 337cd", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "properties", "start": 126, "end": 136, "i_start": 21, "i_end": 21}, "action": {"text": "constrained", "start": 107, "end": 118, "i_start": 18, "i_end": 18}}], "id": 2748}, {"sent": "two inverse fourier transforms in frequency and circumferential wave number yield the sought waveforms of acoustic response in the time-space domain .", "tokens": ["two", "inverse", "fourier", "transforms", "in", "frequency", "and", "circumferential", "wave", "number", "yield", "the", "sought", "waveforms", "of", "acoustic", "response", "in", "the", "time", "-", "space", "domain", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "two inverse fourier", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "transforms", "start": 20, "end": 30, "i_start": 3, "i_end": 3}}, {"subject": {"text": "two inverse fourier", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "yield", "start": 76, "end": 81, "i_start": 10, "i_end": 10}}, {"character": {"text": "two inverse fourier transforms", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "action": {"text": "yield", "start": 76, "end": 81, "i_start": 10, "i_end": 10}}], "id": 2749}, {"sent": "then the induced map a is a weak equivalence .", "tokens": ["then", "the", "induced", "map", "a", "is", "a", "weak", "equivalence", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the induced map a", "start": 5, "end": 22, "i_start": 1, "i_end": 4}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 5, "i_end": 5}}], "id": 2750}, {"sent": "the em algorithm is the standard tool for maximum likelihood estimation of the parameters for mixture models .", "tokens": ["the", "em", "algorithm", "is", "the", "standard", "tool", "for", "maximum", "likelihood", "estimation", "of", "the", "parameters", "for", "mixture", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the em algorithm", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 2751}, {"sent": "for higher values of the coupling the minimum tends to disappear .", "tokens": ["for", "higher", "values", "of", "the", "coupling", "the", "minimum", "tends", "to", "disappear", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2752}, {"sent": "the radio emission is a second order product of the accretion process , but should also follow the scaling .", "tokens": ["the", "radio", "emission", "is", "a", "second", "order", "product", "of", "the", "accretion", "process", ",", "but", "should", "also", "follow", "the", "scaling", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the radio emission", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the radio emission", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "follow", "start": 88, "end": 94, "i_start": 16, "i_end": 16}}, {"character": {"text": "process", "start": 62, "end": 69, "i_start": 11, "i_end": 11}, "action": {"text": "product", "start": 37, "end": 44, "i_start": 7, "i_end": 7}}], "id": 2753}, {"sent": "in addition , we demonstrate that irfs can be viewed through the theory of reproducing kernel hilbert space .", "tokens": ["in", "addition", ",", "we", "demonstrate", "that", "irfs", "can", "be", "viewed", "through", "the", "theory", "of", "reproducing", "kernel", "hilbert", "space", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "demonstrate", "start": 17, "end": 28, "i_start": 4, "i_end": 4}}, {"subject": {"text": "irfs", "start": 34, "end": 38, "i_start": 6, "i_end": 6}, "verb": {"text": "viewed", "start": 46, "end": 52, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "demonstrate", "start": 17, "end": 28, "i_start": 4, "i_end": 4}}], "id": 2754}, {"sent": "missing ingredient is a caustic-crossing binary detection efficiency .", "tokens": ["missing", "ingredient", "is", "a", "caustic", "-", "crossing", "binary", "detection", "efficiency", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "missing ingredient", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "detection", "start": 48, "end": 57, "i_start": 8, "i_end": 8}, "action": {"text": "crossing", "start": 32, "end": 40, "i_start": 6, "i_end": 6}}], "id": 2755}, {"sent": "the identification of each field together with its galacto centric distance , in kpc , are labeled in top-left corner .", "tokens": ["the", "identification", "of", "each", "field", "together", "with", "its", "galacto", "centric", "distance", ",", "in", "kpc", ",", "are", "labeled", "in", "top", "-", "left", "corner", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the identification of each field together with its galacto centric distance", "start": 0, "end": 75, "i_start": 0, "i_end": 10}, "verb": {"text": "are labeled", "start": 87, "end": 98, "i_start": 15, "i_end": 16}}], "id": 2756}, {"sent": "for a recent and not complete review of the cmb circular polarization see ref .", "tokens": ["for", "a", "recent", "and", "not", "complete", "review", "of", "the", "cmb", "circular", "polarization", "see", "ref", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2757}, {"sent": "recently , deep convolutional neural networks have led to substantial improvements for numerous computer vision tasks like object detection , often achieving human-level performance .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "led", "to", "substantial", "improvements", "for", "numerous", "computer", "vision", "tasks", "like", "object", "detection", ",", "often", "achieving", "human", "-", "level", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have led", "start": 46, "end": 54, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "led", "start": 51, "end": 54, "i_start": 7, "i_end": 7}}, {"character": {"text": "improvements", "start": 70, "end": 82, "i_start": 10, "i_end": 10}, "action": {"text": "achieving", "start": 148, "end": 157, "i_start": 21, "i_end": 21}}], "id": 2758}, {"sent": "in particular framed bisimilarity has been introduced by abadi and gordon for this purpose , for the spi-calculus .", "tokens": ["in", "particular", "framed", "bisimilarity", "has", "been", "introduced", "by", "abadi", "and", "gordon", "for", "this", "purpose", ",", "for", "the", "spi", "-", "calculus", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "abadi", "start": 57, "end": 62, "i_start": 8, "i_end": 8}, "action": {"text": "introduced", "start": 43, "end": 53, "i_start": 6, "i_end": 6}}, {"character": {"text": "gordon", "start": 67, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "introduced", "start": 43, "end": 53, "i_start": 6, "i_end": 6}}], "id": 2759}, {"sent": "lower bounds for quantum communication complexity .", "tokens": ["lower", "bounds", "for", "quantum", "communication", "complexity", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2760}, {"sent": "therefore , we utilize pretrained contextual word embeddings .", "tokens": ["therefore", ",", "we", "utilize", "pretrained", "contextual", "word", "embeddings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "utilize", "start": 15, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "utilize", "start": 15, "end": 22, "i_start": 3, "i_end": 3}}], "id": 2761}, {"sent": "such analysis can help to quantitatively refute , for instance , claims that bnns are intrinsically more robust , as suggested in prior work .", "tokens": ["such", "analysis", "can", "help", "to", "quantitatively", "refute", ",", "for", "instance", ",", "claims", "that", "bnns", "are", "intrinsically", "more", "robust", ",", "as", "suggested", "in", "prior", "work", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "such analysis", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "claims", "start": 65, "end": 71, "i_start": 11, "i_end": 11}}, {"subject": {"text": "such analysis", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "help", "start": 18, "end": 22, "i_start": 3, "i_end": 3}}, {"subject": {"text": "such analysis", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 82, "end": 85, "i_start": 14, "i_end": 14}}, {"character": {"text": "analysis", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "help", "start": 18, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "analysis", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "refute", "start": 41, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "work", "start": 136, "end": 140, "i_start": 23, "i_end": 23}, "action": {"text": "suggested", "start": 117, "end": 126, "i_start": 20, "i_end": 20}}], "id": 2762}, {"sent": "similar to , we found this approach to be beneficial for short-term prediction , but we also discovered that it leads to instability in the long-term .", "tokens": ["similar", "to", ",", "we", "found", "this", "approach", "to", "be", "beneficial", "for", "short", "-", "term", "prediction", ",", "but", "we", "also", "discovered", "that", "it", "leads", "to", "instability", "in", "the", "long", "-", "term", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "found", "start": 16, "end": 21, "i_start": 4, "i_end": 4}}, {"subject": {"text": "we", "start": 85, "end": 87, "i_start": 17, "i_end": 17}, "verb": {"text": "be", "start": 39, "end": 41, "i_start": 8, "i_end": 8}}, {"subject": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "discovered", "start": 93, "end": 103, "i_start": 19, "i_end": 19}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "found", "start": 16, "end": 21, "i_start": 4, "i_end": 4}}, {"character": {"text": "approach", "start": 27, "end": 35, "i_start": 6, "i_end": 6}, "action": {"text": "beneficial", "start": 42, "end": 52, "i_start": 9, "i_end": 9}}, {"character": {"text": "approach", "start": 27, "end": 35, "i_start": 6, "i_end": 6}, "action": {"text": "leads", "start": 112, "end": 117, "i_start": 22, "i_end": 22}}], "id": 2763}, {"sent": "however , a recent development called adversarial examples showed that deep learning models are vulnerable to gradient-based attacks .", "tokens": ["however", ",", "a", "recent", "development", "called", "adversarial", "examples", "showed", "that", "deep", "learning", "models", "are", "vulnerable", "to", "gradient", "-", "based", "attacks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a recent development called adversarial examples", "start": 10, "end": 58, "i_start": 2, "i_end": 7}, "verb": {"text": "showed", "start": 59, "end": 65, "i_start": 8, "i_end": 8}}, {"subject": {"text": "a recent development called adversarial examples", "start": 10, "end": 58, "i_start": 2, "i_end": 7}, "verb": {"text": "are", "start": 92, "end": 95, "i_start": 13, "i_end": 13}}, {"character": {"text": "development", "start": 19, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "showed", "start": 59, "end": 65, "i_start": 8, "i_end": 8}}], "id": 2764}, {"sent": "in quenched qcd there is the problem described above concerning scalar mesons .", "tokens": ["in", "quenched", "qcd", "there", "is", "the", "problem", "described", "above", "concerning", "scalar", "mesons", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 16, "end": 21, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}], "id": 2765}, {"sent": "the inflaton is a natural candidate for a ngb as we have discussed , because of the necessary flatness of the potential .", "tokens": ["the", "inflaton", "is", "a", "natural", "candidate", "for", "a", "ngb", "as", "we", "have", "discussed", ",", "because", "of", "the", "necessary", "flatness", "of", "the", "potential", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the inflaton", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 10, "i_end": 10}, "action": {"text": "discussed", "start": 57, "end": 66, "i_start": 12, "i_end": 12}}, {"character": {"text": "flatness", "start": 94, "end": 102, "i_start": 18, "i_end": 18}, "action": {"text": "because", "start": 69, "end": 76, "i_start": 14, "i_end": 14}}], "id": 2766}, {"sent": "transitioning to a sustainable society will require shifts in consumer lifestyles as well as the development of new technologies .", "tokens": ["transitioning", "to", "a", "sustainable", "society", "will", "require", "shifts", "in", "consumer", "lifestyles", "as", "well", "as", "the", "development", "of", "new", "technologies", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "transitioning to a sustainable society", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "will require", "start": 39, "end": 51, "i_start": 5, "i_end": 6}}, {"character": {"text": "transitioning", "start": 0, "end": 13, "i_start": 0, "i_end": 0}, "action": {"text": "require", "start": 44, "end": 51, "i_start": 6, "i_end": 6}}], "id": 2767}, {"sent": "later , in coincides with the bisimilarity metric based on the kantorovich lifting .", "tokens": ["later", ",", "in", "coincides", "with", "the", "bisimilarity", "metric", "based", "on", "the", "kantorovich", "lifting", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2768}, {"sent": "as a result , physical layer security has been proposed as a complement to the traditional methods for improving wireless transmission security .", "tokens": ["as", "a", "result", ",", "physical", "layer", "security", "has", "been", "proposed", "as", "a", "complement", "to", "the", "traditional", "methods", "for", "improving", "wireless", "transmission", "security", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "physical layer security", "start": 14, "end": 37, "i_start": 4, "i_end": 6}, "verb": {"text": "has been proposed", "start": 38, "end": 55, "i_start": 7, "i_end": 9}}], "id": 2769}, {"sent": "during the last decade , deep learning algorithms , especially convolutional neural networks have achieved remarkable progress on numerous practical vision tasks .", "tokens": ["during", "the", "last", "decade", ",", "deep", "learning", "algorithms", ",", "especially", "convolutional", "neural", "networks", "have", "achieved", "remarkable", "progress", "on", "numerous", "practical", "vision", "tasks", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep learning algorithms", "start": 25, "end": 49, "i_start": 5, "i_end": 7}, "verb": {"text": "have achieved", "start": 93, "end": 106, "i_start": 13, "i_end": 14}}, {"character": {"text": "algorithms", "start": 39, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 98, "end": 106, "i_start": 14, "i_end": 14}}, {"character": {"text": "algorithms", "start": 39, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "learning", "start": 30, "end": 38, "i_start": 6, "i_end": 6}}], "id": 2770}, {"sent": "deep neural network models have recently demonstrated impressive learning results in many visual and speech classification problems .", "tokens": ["deep", "neural", "network", "models", "have", "recently", "demonstrated", "impressive", "learning", "results", "in", "many", "visual", "and", "speech", "classification", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural network models", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "demonstrated", "start": 41, "end": 53, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep neural network models", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 27, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "models", "start": 20, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "demonstrated", "start": 41, "end": 53, "i_start": 6, "i_end": 6}}, {"character": {"text": "results", "start": 74, "end": 81, "i_start": 9, "i_end": 9}, "action": {"text": "impressive", "start": 54, "end": 64, "i_start": 7, "i_end": 7}}], "id": 2771}, {"sent": "however , when it is non-zero , there is a finite probability that an nparticle measurement can not distinguish the two states .", "tokens": ["however", ",", "when", "it", "is", "non", "-", "zero", ",", "there", "is", "a", "finite", "probability", "that", "an", "nparticle", "measurement", "can", "not", "distinguish", "the", "two", "states", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 32, "end": 37, "i_start": 9, "i_end": 9}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 10, "i_end": 10}}, {"character": {"text": "measurement", "start": 80, "end": 91, "i_start": 17, "i_end": 17}, "action": {"text": "distinguish", "start": 100, "end": 111, "i_start": 20, "i_end": 20}}], "id": 2772}, {"sent": "in this work , we first derive and computationally implement a two variable recurrence that permits construction of the whole orthonormal matrix the derivation follows our paper in and is also of interest for other 3nj symbols .", "tokens": ["in", "this", "work", ",", "we", "first", "derive", "and", "computationally", "implement", "a", "two", "variable", "recurrence", "that", "permits", "construction", "of", "the", "whole", "orthonormal", "matrix", "the", "derivation", "follows", "our", "paper", "in", "and", "is", "also", "of", "interest", "for", "other", "3nj", "symbols", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "derive", "start": 24, "end": 30, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the derivation", "start": 145, "end": 159, "i_start": 22, "i_end": 23}, "verb": {"text": "implement", "start": 51, "end": 60, "i_start": 9, "i_end": 9}}, {"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "follows", "start": 160, "end": 167, "i_start": 24, "i_end": 24}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "derive", "start": 24, "end": 30, "i_start": 6, "i_end": 6}}, {"character": {"text": "two variable recurrence", "start": 63, "end": 86, "i_start": 11, "i_end": 13}, "action": {"text": "permits", "start": 92, "end": 99, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "implement", "start": 51, "end": 60, "i_start": 9, "i_end": 9}}], "id": 2773}, {"sent": "for instance , a flattening technique was used by comon and jurski to establish that the binary reachability of timed automata is definable in the additive theory of the reals and integers .", "tokens": ["for", "instance", ",", "a", "flattening", "technique", "was", "used", "by", "comon", "and", "jurski", "to", "establish", "that", "the", "binary", "reachability", "of", "timed", "automata", "is", "definable", "in", "the", "additive", "theory", "of", "the", "reals", "and", "integers", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "a flattening technique", "start": 15, "end": 37, "i_start": 3, "i_end": 5}, "verb": {"text": "was used", "start": 38, "end": 46, "i_start": 6, "i_end": 7}}, {"subject": {"text": "a flattening technique", "start": 15, "end": 37, "i_start": 3, "i_end": 5}, "verb": {"text": "jurski", "start": 60, "end": 66, "i_start": 11, "i_end": 11}}, {"character": {"text": "comon", "start": 50, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "used", "start": 42, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "jurski", "start": 60, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "used", "start": 42, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "comon", "start": 50, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "establish", "start": 70, "end": 79, "i_start": 13, "i_end": 13}}, {"character": {"text": "jurski", "start": 60, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "establish", "start": 70, "end": 79, "i_start": 13, "i_end": 13}}, {"character": {"text": "automata", "start": 118, "end": 126, "i_start": 20, "i_end": 20}, "action": {"text": "reachability", "start": 96, "end": 108, "i_start": 17, "i_end": 17}}, {"character": {"text": "theory", "start": 156, "end": 162, "i_start": 26, "i_end": 26}, "action": {"text": "definable", "start": 130, "end": 139, "i_start": 22, "i_end": 22}}], "id": 2774}, {"sent": "asterisks denote flares , arrows denote upper limits for non-detections .", "tokens": ["asterisks", "denote", "flares", ",", "arrows", "denote", "upper", "limits", "for", "non", "-", "detections", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "asterisks", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "arrows", "start": 26, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "denote", "start": 33, "end": 39, "i_start": 5, "i_end": 5}}], "id": 2775}, {"sent": "in section ii we review the classical map and construct its generating function .", "tokens": ["in", "section", "ii", "we", "review", "the", "classical", "map", "and", "construct", "its", "generating", "function", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "review", "start": 17, "end": 23, "i_start": 4, "i_end": 4}}, {"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "construct", "start": 46, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "review", "start": 17, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "construct", "start": 46, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "map", "start": 38, "end": 41, "i_start": 7, "i_end": 7}, "action": {"text": "function", "start": 71, "end": 79, "i_start": 12, "i_end": 12}}], "id": 2776}, {"sent": "bayesian estimation has a wide range of applications from positioning .", "tokens": ["bayesian", "estimation", "has", "a", "wide", "range", "of", "applications", "from", "positioning", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "bayesian estimation", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "has", "start": 20, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "bayesian", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "estimation", "start": 9, "end": 19, "i_start": 1, "i_end": 1}}], "id": 2777}, {"sent": "we implement our models in pytorch and use the adam optimizer for network training .", "tokens": ["we", "implement", "our", "models", "in", "pytorch", "and", "use", "the", "adam", "optimizer", "for", "network", "training", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 39, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 39, "end": 42, "i_start": 7, "i_end": 7}}], "id": 2778}, {"sent": "the ellipses denote higher order terms in the quark mass expansion .", "tokens": ["the", "ellipses", "denote", "higher", "order", "terms", "in", "the", "quark", "mass", "expansion", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ellipses", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "denote", "start": 13, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "ellipses", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 13, "end": 19, "i_start": 2, "i_end": 2}}], "id": 2779}, {"sent": "the image features are transfer-learned from a pre-trained deep residual neural network that is pre-trained on imagenet .", "tokens": ["the", "image", "features", "are", "transfer", "-", "learned", "from", "a", "pre", "-", "trained", "deep", "residual", "neural", "network", "that", "is", "pre", "-", "trained", "on", "imagenet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the image features", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 19, "end": 22, "i_start": 3, "i_end": 3}}], "id": 2780}, {"sent": "the above formula has been discussed during the conference icnaam 2006 held in greece and it appeared , with an inductive proof , in paper , .", "tokens": ["the", "above", "formula", "has", "been", "discussed", "during", "the", "conference", "icnaam", "2006", "held", "in", "greece", "and", "it", "appeared", ",", "with", "an", "inductive", "proof", ",", "in", "paper", ",", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the above formula", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "has been discussed", "start": 18, "end": 36, "i_start": 3, "i_end": 5}}, {"subject": {"text": "it", "start": 90, "end": 92, "i_start": 15, "i_end": 15}, "verb": {"text": "appeared", "start": 93, "end": 101, "i_start": 16, "i_end": 16}}], "id": 2781}, {"sent": "the translator is a standard encoder-decoder network with skip connections between corresponding encoder and decoder layers .", "tokens": ["the", "translator", "is", "a", "standard", "encoder", "-", "decoder", "network", "with", "skip", "connections", "between", "corresponding", "encoder", "and", "decoder", "layers", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the translator", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "network", "start": 45, "end": 52, "i_start": 8, "i_end": 8}, "action": {"text": "decoder", "start": 37, "end": 44, "i_start": 7, "i_end": 7}}, {"character": {"text": "layers", "start": 117, "end": 123, "i_start": 17, "i_end": 17}, "action": {"text": "decoder", "start": 109, "end": 116, "i_start": 16, "i_end": 16}}], "id": 2782}, {"sent": "we trained phrase-based smt models with moses , an open source smt system .", "tokens": ["we", "trained", "phrase", "-", "based", "smt", "models", "with", "moses", ",", "an", "open", "source", "smt", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "trained", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "trained", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 2783}, {"sent": "convolutional neural networks have proved their dominating spot in various machine learning tasks , such as speech recognition .", "tokens": ["convolutional", "neural", "networks", "have", "proved", "their", "dominating", "spot", "in", "various", "machine", "learning", "tasks", ",", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have proved", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "proved", "start": 35, "end": 41, "i_start": 4, "i_end": 4}}, {"character": {"text": "spot", "start": 59, "end": 63, "i_start": 7, "i_end": 7}, "action": {"text": "dominating", "start": 48, "end": 58, "i_start": 6, "i_end": 6}}], "id": 2784}, {"sent": "free knots and links are also called homotopy classes of gauss words and phrases .", "tokens": ["free", "knots", "and", "links", "are", "also", "called", "homotopy", "classes", "of", "gauss", "words", "and", "phrases", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "free knots and links", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "called", "start": 30, "end": 36, "i_start": 6, "i_end": 6}}, {"subject": {"text": "free knots and links", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 4, "i_end": 4}}], "id": 2785}, {"sent": "rapid development of deep convolutional neural networks has led to promising performance on various computer vision tasks .", "tokens": ["rapid", "development", "of", "deep", "convolutional", "neural", "networks", "has", "led", "to", "promising", "performance", "on", "various", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "rapid development of deep convolutional neural networks", "start": 0, "end": 55, "i_start": 0, "i_end": 6}, "verb": {"text": "has led", "start": 56, "end": 63, "i_start": 7, "i_end": 8}}, {"character": {"text": "development", "start": 6, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 60, "end": 63, "i_start": 8, "i_end": 8}}, {"character": {"text": "performance", "start": 77, "end": 88, "i_start": 11, "i_end": 11}, "action": {"text": "promising", "start": 67, "end": 76, "i_start": 10, "i_end": 10}}], "id": 2786}, {"sent": "the initial weights of these network are pre-trained on the imagenet dataset .", "tokens": ["the", "initial", "weights", "of", "these", "network", "are", "pre", "-", "trained", "on", "the", "imagenet", "dataset", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the initial weights of these network", "start": 0, "end": 36, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 37, "end": 40, "i_start": 6, "i_end": 6}}], "id": 2787}, {"sent": "let us now turn our attention to this class of gravity models .", "tokens": ["let", "us", "now", "turn", "our", "attention", "to", "this", "class", "of", "gravity", "models", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "turn", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "attention", "start": 20, "end": 29, "i_start": 5, "i_end": 5}}], "id": 2788}, {"sent": "viviania , b infn sezione di perugia a , universita di perugia b , perugia , italy d .", "tokens": ["viviania", ",", "b", "infn", "sezione", "di", "perugia", "a", ",", "universita", "di", "perugia", "b", ",", "perugia", ",", "italy", "d", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2789}, {"sent": "this concludes the proof of the proposition .", "tokens": ["this", "concludes", "the", "proof", "of", "the", "proposition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "concludes", "start": 5, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "concludes", "start": 5, "end": 14, "i_start": 1, "i_end": 1}}], "id": 2790}, {"sent": "the calculations show that it is the dimer vacancy site a1 where a deposited in atom is adsorbed most strongly .", "tokens": ["the", "calculations", "show", "that", "it", "is", "the", "dimer", "vacancy", "site", "a1", "where", "a", "deposited", "in", "atom", "is", "adsorbed", "most", "strongly", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the calculations", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "show", "start": 17, "end": 21, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the calculations", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 5, "i_end": 5}}], "id": 2791}, {"sent": "network analysis has emerged as a powerful approach to understanding complex phenomena and organization in social , technological and biological systems .", "tokens": ["network", "analysis", "has", "emerged", "as", "a", "powerful", "approach", "to", "understanding", "complex", "phenomena", "and", "organization", "in", "social", ",", "technological", "and", "biological", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "network analysis", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "has emerged", "start": 17, "end": 28, "i_start": 2, "i_end": 3}}, {"character": {"text": "analysis", "start": 8, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "emerged", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}], "id": 2792}, {"sent": "in recent years , significant advances in speed and accuracy have been achieved by detection frameworks based on convolutional neural networks .", "tokens": ["in", "recent", "years", ",", "significant", "advances", "in", "speed", "and", "accuracy", "have", "been", "achieved", "by", "detection", "frameworks", "based", "on", "convolutional", "neural", "networks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "significant advances in speed and accuracy", "start": 18, "end": 60, "i_start": 4, "i_end": 9}, "verb": {"text": "have been achieved", "start": 61, "end": 79, "i_start": 10, "i_end": 12}}, {"character": {"text": "frameworks", "start": 93, "end": 103, "i_start": 15, "i_end": 15}, "action": {"text": "achieved", "start": 71, "end": 79, "i_start": 12, "i_end": 12}}, {"character": {"text": "frameworks", "start": 93, "end": 103, "i_start": 15, "i_end": 15}, "action": {"text": "detection", "start": 83, "end": 92, "i_start": 14, "i_end": 14}}], "id": 2793}, {"sent": "convolutional networks have been applied with great success for object classification and detection .", "tokens": ["convolutional", "networks", "have", "been", "applied", "with", "great", "success", "for", "object", "classification", "and", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional networks", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "have been applied", "start": 23, "end": 40, "i_start": 2, "i_end": 4}}], "id": 2794}, {"sent": "deep convolutional neural networks have achieved great success in dealing with computer vision problems , such as image classification , object detection and semantic segmentation , etc .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "dealing", "with", "computer", "vision", "problems", ",", "such", "as", "image", "classification", ",", "object", "detection", "and", "semantic", "segmentation", ",", "etc", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "dealing", "start": 66, "end": 73, "i_start": 9, "i_end": 9}}], "id": 2795}, {"sent": "computing the whole lasso regularization path can be done via the lars algorithm .", "tokens": ["computing", "the", "whole", "lasso", "regularization", "path", "can", "be", "done", "via", "the", "lars", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2796}, {"sent": "the deflate compression compresses data using a combination of the lempel-ziv coding algorithm .", "tokens": ["the", "deflate", "compression", "compresses", "data", "using", "a", "combination", "of", "the", "lempel", "-", "ziv", "coding", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2797}, {"sent": "we used the eigen value one criterion , which is known as the kaiser criterion that indicated any component having an eigen value more than one would be retained .", "tokens": ["we", "used", "the", "eigen", "value", "one", "criterion", ",", "which", "is", "known", "as", "the", "kaiser", "criterion", "that", "indicated", "any", "component", "having", "an", "eigen", "value", "more", "than", "one", "would", "be", "retained", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "criterion", "start": 69, "end": 78, "i_start": 14, "i_end": 14}, "action": {"text": "indicated", "start": 84, "end": 93, "i_start": 16, "i_end": 16}}, {"character": {"text": "component", "start": 98, "end": 107, "i_start": 18, "i_end": 18}, "action": {"text": "having", "start": 108, "end": 114, "i_start": 19, "i_end": 19}}], "id": 2798}, {"sent": "a celebrated theorem of juschenko and monod says that this is the case for all minimal z-actions on the cantor set .", "tokens": ["a", "celebrated", "theorem", "of", "juschenko", "and", "monod", "says", "that", "this", "is", "the", "case", "for", "all", "minimal", "z", "-", "actions", "on", "the", "cantor", "set", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a celebrated theorem of juschenko and monod", "start": 0, "end": 43, "i_start": 0, "i_end": 6}, "verb": {"text": "says", "start": 44, "end": 48, "i_start": 7, "i_end": 7}}, {"subject": {"text": "a celebrated theorem of juschenko and monod", "start": 0, "end": 43, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 59, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "theorem", "start": 13, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "says", "start": 44, "end": 48, "i_start": 7, "i_end": 7}}], "id": 2799}, {"sent": "the bp-mf has to learn the noise precision to take into account the residual interference from other users even when the noise power is known .", "tokens": ["the", "bp", "-", "mf", "has", "to", "learn", "the", "noise", "precision", "to", "take", "into", "account", "the", "residual", "interference", "from", "other", "users", "even", "when", "the", "noise", "power", "is", "known", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the bp-mf", "start": 0, "end": 9, "i_start": 0, "i_end": 3}, "verb": {"text": "has", "start": 10, "end": 13, "i_start": 4, "i_end": 4}}, {"character": {"text": "other", "start": 95, "end": 100, "i_start": 18, "i_end": 18}, "action": {"text": "interference", "start": 77, "end": 89, "i_start": 16, "i_end": 16}}], "id": 2800}, {"sent": "in , the gru was found to achieve better performance than the lstm on some tasks .", "tokens": ["in", ",", "the", "gru", "was", "found", "to", "achieve", "better", "performance", "than", "the", "lstm", "on", "some", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the gru", "start": 5, "end": 12, "i_start": 2, "i_end": 3}, "verb": {"text": "was found", "start": 13, "end": 22, "i_start": 4, "i_end": 5}}], "id": 2801}, {"sent": "the optimality properties of a preemptive last generated first served service discipline in a multi-hop network are identified in .", "tokens": ["the", "optimality", "properties", "of", "a", "preemptive", "last", "generated", "first", "served", "service", "discipline", "in", "a", "multi", "-", "hop", "network", "are", "identified", "in", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the optimality properties of a preemptive last generated first served service discipline in a multi-hop network", "start": 0, "end": 111, "i_start": 0, "i_end": 17}, "verb": {"text": "are identified", "start": 112, "end": 126, "i_start": 18, "i_end": 19}}, {"character": {"text": "discipline", "start": 78, "end": 88, "i_start": 11, "i_end": 11}, "action": {"text": "preemptive", "start": 31, "end": 41, "i_start": 5, "i_end": 5}}], "id": 2802}, {"sent": "in the shaded regions , destabilization of the wta state occurs in response to the switching from asynchronous to synchronous incoming spikes .", "tokens": ["in", "the", "shaded", "regions", ",", "destabilization", "of", "the", "wta", "state", "occurs", "in", "response", "to", "the", "switching", "from", "asynchronous", "to", "synchronous", "incoming", "spikes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "destabilization of the wta state", "start": 24, "end": 56, "i_start": 5, "i_end": 9}, "verb": {"text": "occurs", "start": 57, "end": 63, "i_start": 10, "i_end": 10}}], "id": 2803}, {"sent": "we show that the restriction of this model to fermions corresponds to the non-relativistic limit of the massive thirring model .", "tokens": ["we", "show", "that", "the", "restriction", "of", "this", "model", "to", "fermions", "corresponds", "to", "the", "non", "-", "relativistic", "limit", "of", "the", "massive", "thirring", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the restriction of this model to fermions", "start": 13, "end": 54, "i_start": 3, "i_end": 9}, "verb": {"text": "corresponds", "start": 55, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "model", "start": 121, "end": 126, "i_start": 21, "i_end": 21}, "action": {"text": "thirring", "start": 112, "end": 120, "i_start": 20, "i_end": 20}}], "id": 2804}, {"sent": "since the seminal work of koenker and bassett , quantile regression has received substantial scholarly attention as an important alternative to conventional mean regression .", "tokens": ["since", "the", "seminal", "work", "of", "koenker", "and", "bassett", ",", "quantile", "regression", "has", "received", "substantial", "scholarly", "attention", "as", "an", "important", "alternative", "to", "conventional", "mean", "regression", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantile regression", "start": 48, "end": 67, "i_start": 9, "i_end": 10}, "verb": {"text": "has received", "start": 68, "end": 80, "i_start": 11, "i_end": 12}}, {"character": {"text": "koenker", "start": 26, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "work", "start": 18, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "bassett", "start": 38, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "work", "start": 18, "end": 22, "i_start": 3, "i_end": 3}}], "id": 2805}, {"sent": "we apply a u-net-based fully-convolutional architecture for frame-by-frame image segmentation .", "tokens": ["we", "apply", "a", "u", "-", "net", "-", "based", "fully", "-", "convolutional", "architecture", "for", "frame", "-", "by", "-", "frame", "image", "segmentation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "apply", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "apply", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2806}, {"sent": "we use stochastic gradient descent with the adam solver to train our model .", "tokens": ["we", "use", "stochastic", "gradient", "descent", "with", "the", "adam", "solver", "to", "train", "our", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "solver", "start": 49, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 59, "end": 64, "i_start": 10, "i_end": 10}}], "id": 2807}, {"sent": "if gravitino is the lsp , r-parity conservation leads to a long lifetime of the next-to-lsp , which becomes a stable particle in collider scale .", "tokens": ["if", "gravitino", "is", "the", "lsp", ",", "r", "-", "parity", "conservation", "leads", "to", "a", "long", "lifetime", "of", "the", "next", "-", "to", "-", "lsp", ",", "which", "becomes", "a", "stable", "particle", "in", "collider", "scale", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "conservation", "start": 35, "end": 47, "i_start": 9, "i_end": 9}, "action": {"text": "leads", "start": 48, "end": 53, "i_start": 10, "i_end": 10}}], "id": 2808}, {"sent": "parametric coupling for superconducting qubits .", "tokens": ["parametric", "coupling", "for", "superconducting", "qubits", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2809}, {"sent": "the data were reduced with iraf scripts .", "tokens": ["the", "data", "were", "reduced", "with", "iraf", "scripts", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "were reduced", "start": 9, "end": 21, "i_start": 2, "i_end": 3}}], "id": 2810}, {"sent": "this enhancement is the consequence of the increase of the phase space of soft density fluctuations as one goes from a cubic to a quasi-2d structure .", "tokens": ["this", "enhancement", "is", "the", "consequence", "of", "the", "increase", "of", "the", "phase", "space", "of", "soft", "density", "fluctuations", "as", "one", "goes", "from", "a", "cubic", "to", "a", "quasi-2d", "structure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this enhancement", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}], "id": 2811}, {"sent": "in this way , the notion of hom-leibniz algebra was firstly introduced in .", "tokens": ["in", "this", "way", ",", "the", "notion", "of", "hom", "-", "leibniz", "algebra", "was", "firstly", "introduced", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the notion of hom-leibniz algebra", "start": 14, "end": 47, "i_start": 4, "i_end": 10}, "verb": {"text": "introduced in", "start": 60, "end": 73, "i_start": 13, "i_end": 14}}, {"subject": {"text": "the notion of hom-leibniz algebra", "start": 14, "end": 47, "i_start": 4, "i_end": 10}, "verb": {"text": "was", "start": 48, "end": 51, "i_start": 11, "i_end": 11}}], "id": 2812}, {"sent": "this free energy is the difference between the free energy of a dna molecule in a bundle and that of an individual dna molecule in the bulk solution .", "tokens": ["this", "free", "energy", "is", "the", "difference", "between", "the", "free", "energy", "of", "a", "dna", "molecule", "in", "a", "bundle", "and", "that", "of", "an", "individual", "dna", "molecule", "in", "the", "bulk", "solution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this free energy", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 2813}, {"sent": "copenhagen interpretation of quantum mechanics asserts that we can not speak about the quantum properties of the system before these properties will be measured .", "tokens": ["copenhagen", "interpretation", "of", "quantum", "mechanics", "asserts", "that", "we", "can", "not", "speak", "about", "the", "quantum", "properties", "of", "the", "system", "before", "these", "properties", "will", "be", "measured", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "copenhagen interpretation of quantum mechanics", "start": 0, "end": 46, "i_start": 0, "i_end": 4}, "verb": {"text": "asserts", "start": 47, "end": 54, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 60, "end": 62, "i_start": 7, "i_end": 7}, "verb": {"text": "speak", "start": 71, "end": 76, "i_start": 10, "i_end": 10}}, {"character": {"text": "interpretation", "start": 11, "end": 25, "i_start": 1, "i_end": 1}, "action": {"text": "asserts", "start": 47, "end": 54, "i_start": 5, "i_end": 5}}, {"character": {"text": "copenhagen", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "interpretation", "start": 11, "end": 25, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 60, "end": 62, "i_start": 7, "i_end": 7}, "action": {"text": "speak", "start": 71, "end": 76, "i_start": 10, "i_end": 10}}], "id": 2814}, {"sent": "the delay experienced is the reciprocal of this download rate .", "tokens": ["the", "delay", "experienced", "is", "the", "reciprocal", "of", "this", "download", "rate", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the delay experienced", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2815}, {"sent": "recently , a number of cnn-based approaches have achieved excellent performance for general object detection .", "tokens": ["recently", ",", "a", "number", "of", "cnn", "-", "based", "approaches", "have", "achieved", "excellent", "performance", "for", "general", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a number of cnn-based approaches", "start": 11, "end": 43, "i_start": 2, "i_end": 8}, "verb": {"text": "have achieved", "start": 44, "end": 57, "i_start": 9, "i_end": 10}}, {"character": {"text": "approaches", "start": 33, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "achieved", "start": 49, "end": 57, "i_start": 10, "i_end": 10}}, {"character": {"text": "approaches", "start": 33, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "performance", "start": 68, "end": 79, "i_start": 12, "i_end": 12}}], "id": 2816}, {"sent": "deep neural networks have demonstrated stateof-the-art results in image classification .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "stateof", "-", "the", "-", "art", "results", "in", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}], "id": 2817}, {"sent": "the values for the parameters are listed in table iii .", "tokens": ["the", "values", "for", "the", "parameters", "are", "listed", "in", "table", "iii", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the values for the parameters", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "are listed", "start": 30, "end": 40, "i_start": 5, "i_end": 6}}], "id": 2818}, {"sent": "we mentioned already refs in which yamabe functional for manifolds with boundary were discussed .", "tokens": ["we", "mentioned", "already", "refs", "in", "which", "yamabe", "functional", "for", "manifolds", "with", "boundary", "were", "discussed", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "mentioned", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"subject": {"text": "yamabe functional for manifolds with boundary", "start": 35, "end": 80, "i_start": 6, "i_end": 11}, "verb": {"text": "discussed", "start": 86, "end": 95, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "mentioned", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "yamabe", "start": 35, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "functional", "start": 42, "end": 52, "i_start": 7, "i_end": 7}}], "id": 2819}, {"sent": "there is also a recent global existence result of kdv with quasi-periodic initial data by damanik-goldstein .", "tokens": ["there", "is", "also", "a", "recent", "global", "existence", "result", "of", "kdv", "with", "quasi", "-", "periodic", "initial", "data", "by", "damanik", "-", "goldstein", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2820}, {"sent": "to extrapolate the proton dipole correlator to a nucleus , we use , as in ref , the optical glauber model .", "tokens": ["to", "extrapolate", "the", "proton", "dipole", "correlator", "to", "a", "nucleus", ",", "we", "use", ",", "as", "in", "ref", ",", "the", "optical", "glauber", "model", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 59, "end": 61, "i_start": 10, "i_end": 10}, "verb": {"text": "use", "start": 62, "end": 65, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 59, "end": 61, "i_start": 10, "i_end": 10}, "action": {"text": "use", "start": 62, "end": 65, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 59, "end": 61, "i_start": 10, "i_end": 10}, "action": {"text": "extrapolate", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}], "id": 2821}, {"sent": "the exchange correlation effect was described using the perdew-burkeernzerhof within generalized gradient approximation .", "tokens": ["the", "exchange", "correlation", "effect", "was", "described", "using", "the", "perdew", "-", "burkeernzerhof", "within", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange correlation effect", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "was described", "start": 32, "end": 45, "i_start": 4, "i_end": 5}}], "id": 2822}, {"sent": "to begin , let us rephrase the seminal capacity results in this language .", "tokens": ["to", "begin", ",", "let", "us", "rephrase", "the", "seminal", "capacity", "results", "in", "this", "language", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "let", "start": 11, "end": 14, "i_start": 3, "i_end": 3}}, {"subject": {"text": "us", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "rephrase", "start": 18, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "us", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "rephrase", "start": 18, "end": 26, "i_start": 5, "i_end": 5}}], "id": 2823}, {"sent": "at the origin of this behavior there is the double-helix structure of dna and the associated uncoiling of the two strands .", "tokens": ["at", "the", "origin", "of", "this", "behavior", "there", "is", "the", "double", "-", "helix", "structure", "of", "dna", "and", "the", "associated", "uncoiling", "of", "the", "two", "strands", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 31, "end": 36, "i_start": 6, "i_end": 6}, "verb": {"text": "is", "start": 37, "end": 39, "i_start": 7, "i_end": 7}}], "id": 2824}, {"sent": "the generalized gradient approximation corrected functional by perdew et al is used for the exchange-correlation potential .", "tokens": ["the", "generalized", "gradient", "approximation", "corrected", "functional", "by", "perdew", "et", "al", "is", "used", "for", "the", "exchange", "-", "correlation", "potential", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation corrected functional by perdew et al", "start": 0, "end": 75, "i_start": 0, "i_end": 9}, "verb": {"text": "is used", "start": 76, "end": 83, "i_start": 10, "i_end": 11}}, {"character": {"text": "perdew", "start": 63, "end": 69, "i_start": 7, "i_end": 7}, "action": {"text": "used", "start": 79, "end": 83, "i_start": 11, "i_end": 11}}], "id": 2825}, {"sent": "we thus arrive at the following conclusion .", "tokens": ["we", "thus", "arrive", "at", "the", "following", "conclusion", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "arrive", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "conclusion", "start": 32, "end": 42, "i_start": 6, "i_end": 6}}], "id": 2826}, {"sent": "deep convolutional neural networks have shown promising performances on various computer vision problems such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "shown", "promising", "performances", "on", "various", "computer", "vision", "problems", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have shown", "start": 35, "end": 45, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 40, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performances", "start": 56, "end": 68, "i_start": 7, "i_end": 7}}, {"character": {"text": "performances", "start": 56, "end": 68, "i_start": 7, "i_end": 7}, "action": {"text": "promising", "start": 46, "end": 55, "i_start": 6, "i_end": 6}}], "id": 2827}, {"sent": "note that cnoiis equivalent to the number of two-step directed paths from u to v , which was shown to be useful for reciprocal edge prediction .", "tokens": ["note", "that", "cnoiis", "equivalent", "to", "the", "number", "of", "two", "-", "step", "directed", "paths", "from", "u", "to", "v", ",", "which", "was", "shown", "to", "be", "useful", "for", "reciprocal", "edge", "prediction", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2828}, {"sent": "this training set may either be the original dataset or the result of a mapping into a feature space of higher dimensionality .", "tokens": ["this", "training", "set", "may", "either", "be", "the", "original", "dataset", "or", "the", "result", "of", "a", "mapping", "into", "a", "feature", "space", "of", "higher", "dimensionality", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this training set", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "be", "start": 29, "end": 31, "i_start": 5, "i_end": 5}}, {"subject": {"text": "this training set", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "may", "start": 18, "end": 21, "i_start": 3, "i_end": 3}}], "id": 2829}, {"sent": "the internal energy , even after removing some of the lattice contribution , is still dependent on the lattice spacing because the baby-skyrme model is non-renormalisable .", "tokens": ["the", "internal", "energy", ",", "even", "after", "removing", "some", "of", "the", "lattice", "contribution", ",", "is", "still", "dependent", "on", "the", "lattice", "spacing", "because", "the", "baby", "-", "skyrme", "model", "is", "non", "-", "renormalisable", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "the internal energy", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 77, "end": 79, "i_start": 13, "i_end": 13}}, {"character": {"text": "energy", "start": 13, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "dependent", "start": 86, "end": 95, "i_start": 15, "i_end": 15}}, {"character": {"text": "-", "start": 135, "end": 136, "i_start": 23, "i_end": 23}, "action": {"text": "because", "start": 119, "end": 126, "i_start": 20, "i_end": 20}}], "id": 2830}, {"sent": "neural networks have achieved state-of-the-art results in a wide variety of supervised learning tasks , such as image recognition .", "tokens": ["neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "results", "in", "a", "wide", "variety", "of", "supervised", "learning", "tasks", ",", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have achieved", "start": 16, "end": 29, "i_start": 2, "i_end": 3}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "achieved", "start": 21, "end": 29, "i_start": 3, "i_end": 3}}], "id": 2831}, {"sent": "such forms of the metric are related to the so-called seiberg-witten limit .", "tokens": ["such", "forms", "of", "the", "metric", "are", "related", "to", "the", "so", "-", "called", "seiberg", "-", "witten", "limit", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such forms of the metric", "start": 0, "end": 24, "i_start": 0, "i_end": 4}, "verb": {"text": "are related", "start": 25, "end": 36, "i_start": 5, "i_end": 6}}], "id": 2832}, {"sent": "generative adversarial networks have been introduced as the state of the art in generative models .", "tokens": ["generative", "adversarial", "networks", "have", "been", "introduced", "as", "the", "state", "of", "the", "art", "in", "generative", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "have been introduced", "start": 32, "end": 52, "i_start": 3, "i_end": 5}}], "id": 2833}, {"sent": "the most promising results so far are based on conditional generative adversarial networks .", "tokens": ["the", "most", "promising", "results", "so", "far", "are", "based", "on", "conditional", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most promising results", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "are based", "start": 34, "end": 43, "i_start": 6, "i_end": 7}}, {"character": {"text": "based", "start": 38, "end": 43, "i_start": 7, "i_end": 7}, "action": {"text": "promising", "start": 9, "end": 18, "i_start": 2, "i_end": 2}}], "id": 2834}, {"sent": "batch normalisation is added after every convolution and before activation .", "tokens": ["batch", "normalisation", "is", "added", "after", "every", "convolution", "and", "before", "activation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "batch normalisation", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is added", "start": 20, "end": 28, "i_start": 2, "i_end": 3}}], "id": 2835}, {"sent": "the chemical potential \u00b5 is the same in both contacts .", "tokens": ["the", "chemical", "potential", "\u00b5", "is", "the", "same", "in", "both", "contacts", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the chemical potential \u00b5", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 4, "i_end": 4}}], "id": 2836}, {"sent": "weakly chaotic behavior alternates with non-chaotic behavior in the shifting time zones over the entire period of analysis .", "tokens": ["weakly", "chaotic", "behavior", "alternates", "with", "non", "-", "chaotic", "behavior", "in", "the", "shifting", "time", "zones", "over", "the", "entire", "period", "of", "analysis", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2837}, {"sent": "deep neural networks have recently proven successful at various tasks , such as computer vision , speech recognition , and in other domains .", "tokens": ["deep", "neural", "networks", "have", "recently", "proven", "successful", "at", "various", "tasks", ",", "such", "as", "computer", "vision", ",", "speech", "recognition", ",", "and", "in", "other", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "proven", "start": 35, "end": 41, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "proven", "start": 35, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 42, "end": 52, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "recognition", "start": 105, "end": 116, "i_start": 17, "i_end": 17}}], "id": 2838}, {"sent": "unlike some model-based learners such as rule-based methods and decision trees whose boundaries are triangular and straight lines , the knn is capable to implement the complicated and irregular decision boundaries .", "tokens": ["unlike", "some", "model", "-", "based", "learners", "such", "as", "rule", "-", "based", "methods", "and", "decision", "trees", "whose", "boundaries", "are", "triangular", "and", "straight", "lines", ",", "the", "knn", "is", "capable", "to", "implement", "the", "complicated", "and", "irregular", "decision", "boundaries", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the knn", "start": 132, "end": 139, "i_start": 23, "i_end": 24}, "verb": {"text": "is", "start": 140, "end": 142, "i_start": 25, "i_end": 25}}], "id": 2839}, {"sent": "the encoder is a bilstm that receives elmo pre-trained embeddings as input .", "tokens": ["the", "encoder", "is", "a", "bilstm", "that", "receives", "elmo", "pre", "-", "trained", "embeddings", "as", "input", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the encoder", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 2840}, {"sent": "neural networks have transformed machine learning , forming the backbone of models for tasks in computer vision , natural language processing , and robotics , among many other domains .", "tokens": ["neural", "networks", "have", "transformed", "machine", "learning", ",", "forming", "the", "backbone", "of", "models", "for", "tasks", "in", "computer", "vision", ",", "natural", "language", "processing", ",", "and", "robotics", ",", "among", "many", "other", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have transformed", "start": 16, "end": 32, "i_start": 2, "i_end": 3}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "transformed", "start": 21, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "forming", "start": 52, "end": 59, "i_start": 7, "i_end": 7}}], "id": 2841}, {"sent": "deep neural networks have been shown to be very efficient in image processing tasks such as content classification .", "tokens": ["deep", "neural", "networks", "have", "been", "shown", "to", "be", "very", "efficient", "in", "image", "processing", "tasks", "such", "as", "content", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been shown", "start": 21, "end": 36, "i_start": 3, "i_end": 5}}], "id": 2842}, {"sent": "on the whole , all four models used here describe reasonably well most of the measured neutron spectra , although different models agree differently with data from specific reactions and some serious discrepances are observed for some reactions .", "tokens": ["on", "the", "whole", ",", "all", "four", "models", "used", "here", "describe", "reasonably", "well", "most", "of", "the", "measured", "neutron", "spectra", ",", "although", "different", "models", "agree", "differently", "with", "data", "from", "specific", "reactions", "and", "some", "serious", "discrepances", "are", "observed", "for", "some", "reactions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "all four models used here", "start": 15, "end": 40, "i_start": 4, "i_end": 8}, "verb": {"text": "describe", "start": 41, "end": 49, "i_start": 9, "i_end": 9}}, {"character": {"text": "four models", "start": 19, "end": 30, "i_start": 5, "i_end": 6}, "action": {"text": "describe", "start": 41, "end": 49, "i_start": 9, "i_end": 9}}, {"character": {"text": "models", "start": 124, "end": 130, "i_start": 21, "i_end": 21}, "action": {"text": "agree", "start": 131, "end": 136, "i_start": 22, "i_end": 22}}], "id": 2843}, {"sent": "the cartan subalgebra consists of the diagonal generators \u03bb3 and \u03bb8 .", "tokens": ["the", "cartan", "subalgebra", "consists", "of", "the", "diagonal", "generators", "\u03bb3", "and", "\u03bb8", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the cartan subalgebra", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 22, "end": 30, "i_start": 3, "i_end": 3}}], "id": 2844}, {"sent": "such an orbit is a p1 joining the two t-fixed points p\u03c31 and p\u03c32 .", "tokens": ["such", "an", "orbit", "is", "a", "p1", "joining", "the", "two", "t", "-", "fixed", "points", "p\u03c31", "and", "p\u03c32", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such an orbit", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 3, "i_end": 3}}], "id": 2845}, {"sent": "i n recent years , deep convolutional neural networks have demonstrated an outstanding capability in various computer vision tasks , such as image classification .", "tokens": ["i", "n", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "demonstrated", "an", "outstanding", "capability", "in", "various", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 19, "end": 53, "i_start": 5, "i_end": 8}, "verb": {"text": "have demonstrated", "start": 54, "end": 71, "i_start": 9, "i_end": 10}}, {"character": {"text": "networks", "start": 45, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "demonstrated", "start": 59, "end": 71, "i_start": 10, "i_end": 10}}], "id": 2846}, {"sent": "merlin comprises an array of radio telescopes distributed across the uk with a maximum baseline of 217 km .", "tokens": ["merlin", "comprises", "an", "array", "of", "radio", "telescopes", "distributed", "across", "the", "uk", "with", "a", "maximum", "baseline", "of", "217", "km", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "merlin", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "comprises", "start": 7, "end": 16, "i_start": 1, "i_end": 1}}], "id": 2847}, {"sent": "we first compare the proposed ecpenet with previous state-of-the-art deblurring methods in a quantitative way .", "tokens": ["we", "first", "compare", "the", "proposed", "ecpenet", "with", "previous", "state", "-", "of", "-", "the", "-", "art", "deblurring", "methods", "in", "a", "quantitative", "way", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 9, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 9, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "methods", "start": 80, "end": 87, "i_start": 16, "i_end": 16}, "action": {"text": "deblurring", "start": 69, "end": 79, "i_start": 15, "i_end": 15}}], "id": 2848}, {"sent": "momentum space m is the four dimensional vector space consisting of momentum vectors pa .", "tokens": ["momentum", "space", "m", "is", "the", "four", "dimensional", "vector", "space", "consisting", "of", "momentum", "vectors", "pa", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "momentum space m", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 2849}, {"sent": "we refer the reader to , eg , for detailed accounts and additional references .", "tokens": ["we", "refer", "the", "reader", "to", ",", "eg", ",", "for", "detailed", "accounts", "and", "additional", "references", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 2850}, {"sent": "in recent years , deep convolutional neural networks have proven to be highly effective general models for a multitude of computer vision problems .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "proven", "to", "be", "highly", "effective", "general", "models", "for", "a", "multitude", "of", "computer", "vision", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have proven", "start": 53, "end": 64, "i_start": 8, "i_end": 9}}, {"character": {"text": "models", "start": 96, "end": 102, "i_start": 15, "i_end": 15}, "action": {"text": "effective", "start": 78, "end": 87, "i_start": 13, "i_end": 13}}], "id": 2851}, {"sent": "graphene consists of a honeycomb lattice of carbon atoms with two sublattices .", "tokens": ["graphene", "consists", "of", "a", "honeycomb", "lattice", "of", "carbon", "atoms", "with", "two", "sublattices", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "graphene", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "consists", "start": 9, "end": 17, "i_start": 1, "i_end": 1}}], "id": 2852}, {"sent": "we use the software package liblinear modified to handle dense matrices .", "tokens": ["we", "use", "the", "software", "package", "liblinear", "modified", "to", "handle", "dense", "matrices", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "package", "start": 20, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "handle", "start": 50, "end": 56, "i_start": 8, "i_end": 8}}], "id": 2853}, {"sent": "deep convolutional neural networks have enabled unparalleled breakthroughs in a variety of visual tasks , such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "enabled", "unparalleled", "breakthroughs", "in", "a", "variety", "of", "visual", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have enabled", "start": 35, "end": 47, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "enabled", "start": 40, "end": 47, "i_start": 5, "i_end": 5}}], "id": 2854}, {"sent": "over the past few years , neural networks has been widely used in some domains , such as large vocabulary continuous speech recognition .", "tokens": ["over", "the", "past", "few", "years", ",", "neural", "networks", "has", "been", "widely", "used", "in", "some", "domains", ",", "such", "as", "large", "vocabulary", "continuous", "speech", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 26, "end": 41, "i_start": 6, "i_end": 7}, "verb": {"text": "used", "start": 58, "end": 62, "i_start": 11, "i_end": 11}}, {"subject": {"text": "neural networks", "start": 26, "end": 41, "i_start": 6, "i_end": 7}, "verb": {"text": "has been", "start": 42, "end": 50, "i_start": 8, "i_end": 9}}], "id": 2855}, {"sent": "we use faster-rcnn to detect the bounding boxes for objects of the scene .", "tokens": ["we", "use", "faster", "-", "rcnn", "to", "detect", "the", "bounding", "boxes", "for", "objects", "of", "the", "scene", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "detect", "start": 22, "end": 28, "i_start": 6, "i_end": 6}}], "id": 2856}, {"sent": "previous work has argued that an iot framework that is built around a centralized , cloud-based broker is susceptible to cloud disconnection .", "tokens": ["previous", "work", "has", "argued", "that", "an", "iot", "framework", "that", "is", "built", "around", "a", "centralized", ",", "cloud", "-", "based", "broker", "is", "susceptible", "to", "cloud", "disconnection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "previous work", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has argued", "start": 14, "end": 24, "i_start": 2, "i_end": 3}}, {"subject": {"text": "previous work", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 103, "end": 105, "i_start": 19, "i_end": 19}}, {"character": {"text": "work", "start": 9, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "argued", "start": 18, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2857}, {"sent": "all convolutional layers are initialized using the method proposed by glorot and bengio .", "tokens": ["all", "convolutional", "layers", "are", "initialized", "using", "the", "method", "proposed", "by", "glorot", "and", "bengio", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all convolutional layers", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "are initialized", "start": 25, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "glorot", "start": 70, "end": 76, "i_start": 10, "i_end": 10}, "action": {"text": "proposed", "start": 58, "end": 66, "i_start": 8, "i_end": 8}}, {"character": {"text": "bengio", "start": 81, "end": 87, "i_start": 12, "i_end": 12}, "action": {"text": "proposed", "start": 58, "end": 66, "i_start": 8, "i_end": 8}}], "id": 2858}, {"sent": "graphs have been extensively used for machine learning , especially in the context of gcn .", "tokens": ["graphs", "have", "been", "extensively", "used", "for", "machine", "learning", ",", "especially", "in", "the", "context", "of", "gcn", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "graphs", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 29, "end": 33, "i_start": 4, "i_end": 4}}, {"subject": {"text": "graphs", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "have been", "start": 7, "end": 16, "i_start": 1, "i_end": 2}}], "id": 2859}, {"sent": "for the siamese network , we employ a standard googlenet architecture with imagenet pretrained weights .", "tokens": ["for", "the", "siamese", "network", ",", "we", "employ", "a", "standard", "googlenet", "architecture", "with", "imagenet", "pretrained", "weights", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "verb": {"text": "employ", "start": 29, "end": 35, "i_start": 6, "i_end": 6}}, {"subject": {"text": "a standard googlenet architecture with imagenet", "start": 36, "end": 83, "i_start": 7, "i_end": 12}, "verb": {"text": "pretrained", "start": 84, "end": 94, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "employ", "start": 29, "end": 35, "i_start": 6, "i_end": 6}}], "id": 2860}, {"sent": "deep neural networks , such as cnns , have recently achieved many successes in visual recognition tasks .", "tokens": ["deep", "neural", "networks", ",", "such", "as", "cnns", ",", "have", "recently", "achieved", "many", "successes", "in", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 52, "end": 60, "i_start": 10, "i_end": 10}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 38, "end": 42, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 52, "end": 60, "i_start": 10, "i_end": 10}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successes", "start": 66, "end": 75, "i_start": 12, "i_end": 12}}], "id": 2861}, {"sent": "the qubit consists of the last two vectors .", "tokens": ["the", "qubit", "consists", "of", "the", "last", "two", "vectors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the qubit", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 10, "end": 18, "i_start": 2, "i_end": 2}}], "id": 2862}, {"sent": "following the recent rise of deep learning for image and speech processing , there has been great interest in generalizing convolutional neural networks to arbitrary graph-structured data .", "tokens": ["following", "the", "recent", "rise", "of", "deep", "learning", "for", "image", "and", "speech", "processing", ",", "there", "has", "been", "great", "interest", "in", "generalizing", "convolutional", "neural", "networks", "to", "arbitrary", "graph", "-", "structured", "data", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "there", "start": 77, "end": 82, "i_start": 13, "i_end": 13}, "verb": {"text": "has been", "start": 83, "end": 91, "i_start": 14, "i_end": 15}}], "id": 2863}, {"sent": "deep convolutional neural networks have made significant breakthroughs in many visual understanding tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "significant", "breakthroughs", "in", "many", "visual", "understanding", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "breakthroughs", "start": 57, "end": 70, "i_start": 7, "i_end": 7}}], "id": 2864}, {"sent": "our method differs from earlier investigations , in which the authors directly compared the properties of the two lines .", "tokens": ["our", "method", "differs", "from", "earlier", "investigations", ",", "in", "which", "the", "authors", "directly", "compared", "the", "properties", "of", "the", "two", "lines", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "our method differs from earlier investigations , in which the authors directly compared the properties of the two lines", "start": 0, "end": 119, "i_start": 0, "i_end": 18}, "verb": {"text": "differs", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}], "id": 2865}, {"sent": "overhead quality contour in backhaul signaling qo vs .", "tokens": ["overhead", "quality", "contour", "in", "backhaul", "signaling", "qo", "vs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "contour", "start": 17, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "signaling", "start": 37, "end": 46, "i_start": 5, "i_end": 5}}], "id": 2866}, {"sent": "as such , regularisation methods , especially dropout , have been introduced to address the overfitting problem .", "tokens": ["as", "such", ",", "regularisation", "methods", ",", "especially", "dropout", ",", "have", "been", "introduced", "to", "address", "the", "overfitting", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "methods", "start": 25, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "address", "start": 80, "end": 87, "i_start": 13, "i_end": 13}}], "id": 2867}, {"sent": "the lightest neutralino is the wino which is a perfect cold dark matter candidate assuming the non-thermal production from the gravitino decay .", "tokens": ["the", "lightest", "neutralino", "is", "the", "wino", "which", "is", "a", "perfect", "cold", "dark", "matter", "candidate", "assuming", "the", "non", "-", "thermal", "production", "from", "the", "gravitino", "decay", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lightest neutralino", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "decay", "start": 137, "end": 142, "i_start": 23, "i_end": 23}, "action": {"text": "production", "start": 107, "end": 117, "i_start": 19, "i_end": 19}}, {"character": {"text": "gravitino", "start": 127, "end": 136, "i_start": 22, "i_end": 22}, "action": {"text": "decay", "start": 137, "end": 142, "i_start": 23, "i_end": 23}}], "id": 2868}, {"sent": "we used scikitlearn python library for implementing these classifiers .", "tokens": ["we", "used", "scikitlearn", "python", "library", "for", "implementing", "these", "classifiers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implementing", "start": 39, "end": 51, "i_start": 6, "i_end": 6}}], "id": 2869}, {"sent": "it is fully correlated between the data sets .", "tokens": ["it", "is", "fully", "correlated", "between", "the", "data", "sets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "correlated", "start": 12, "end": 22, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}], "id": 2870}, {"sent": "in recent years , convolutional neural networks has achieved remarkable results in a wide range of computer vision applications .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "has", "achieved", "remarkable", "results", "in", "a", "wide", "range", "of", "computer", "vision", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "has achieved", "start": 48, "end": 60, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 52, "end": 60, "i_start": 8, "i_end": 8}}], "id": 2871}, {"sent": "all first-principles calculations were carried out using the vienna ab initio simulation package based on dft .", "tokens": ["all", "first", "-", "principles", "calculations", "were", "carried", "out", "using", "the", "vienna", "ab", "initio", "simulation", "package", "based", "on", "dft", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all first-principles calculations", "start": 0, "end": 33, "i_start": 0, "i_end": 4}, "verb": {"text": "were carried out", "start": 34, "end": 50, "i_start": 5, "i_end": 7}}], "id": 2872}, {"sent": "this flow has been used by huisken and ilmanen to prove the riemannian penrose inequality in general relativity .", "tokens": ["this", "flow", "has", "been", "used", "by", "huisken", "and", "ilmanen", "to", "prove", "the", "riemannian", "penrose", "inequality", "in", "general", "relativity", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this flow", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "has been used", "start": 10, "end": 23, "i_start": 2, "i_end": 4}}, {"character": {"text": "huisken", "start": 27, "end": 34, "i_start": 6, "i_end": 6}, "action": {"text": "used", "start": 19, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "ilmanen", "start": 39, "end": 46, "i_start": 8, "i_end": 8}, "action": {"text": "used", "start": 19, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "huisken", "start": 27, "end": 34, "i_start": 6, "i_end": 6}, "action": {"text": "prove", "start": 50, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "ilmanen", "start": 39, "end": 46, "i_start": 8, "i_end": 8}, "action": {"text": "prove", "start": 50, "end": 55, "i_start": 10, "i_end": 10}}], "id": 2873}, {"sent": "deep learning-based approaches have demonstrate superior flexibility and generalization capabilities in information processing on a wide variety of tasks , such as vision , speech and language .", "tokens": ["deep", "learning", "-", "based", "approaches", "have", "demonstrate", "superior", "flexibility", "and", "generalization", "capabilities", "in", "information", "processing", "on", "a", "wide", "variety", "of", "tasks", ",", "such", "as", "vision", ",", "speech", "and", "language", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning-based approaches", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "have demonstrate", "start": 31, "end": 47, "i_start": 5, "i_end": 6}}, {"character": {"text": "approaches", "start": 20, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "demonstrate", "start": 36, "end": 47, "i_start": 6, "i_end": 6}}], "id": 2874}, {"sent": "we evaluate our method on three datasets , including scene flow , kitti2015 .", "tokens": ["we", "evaluate", "our", "method", "on", "three", "datasets", ",", "including", "scene", "flow", ",", "kitti2015", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 2875}, {"sent": "the total spectrum was fitted with two gaussian components using the spectral fitting package mpfit .", "tokens": ["the", "total", "spectrum", "was", "fitted", "with", "two", "gaussian", "components", "using", "the", "spectral", "fitting", "package", "mpfit", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the total spectrum", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "was fitted", "start": 19, "end": 29, "i_start": 3, "i_end": 4}}], "id": 2876}, {"sent": "the matrix product state forms the basis of the density matrix renormalization group algorithm .", "tokens": ["the", "matrix", "product", "state", "forms", "the", "basis", "of", "the", "density", "matrix", "renormalization", "group", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the matrix product state", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "forms", "start": 25, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "state", "start": 19, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "forms", "start": 25, "end": 30, "i_start": 4, "i_end": 4}}], "id": 2877}, {"sent": "hochschild , on the cohomology theory for associative algebras .", "tokens": ["hochschild", ",", "on", "the", "cohomology", "theory", "for", "associative", "algebras", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "algebras", "start": 54, "end": 62, "i_start": 8, "i_end": 8}, "action": {"text": "associative", "start": 42, "end": 53, "i_start": 7, "i_end": 7}}], "id": 2878}, {"sent": "in recent years , the benefits of short-cut connections in deep neural networks have been demonstrated in various empirical studies .", "tokens": ["in", "recent", "years", ",", "the", "benefits", "of", "short", "-", "cut", "connections", "in", "deep", "neural", "networks", "have", "been", "demonstrated", "in", "various", "empirical", "studies", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the benefits of short-cut connections in deep neural networks", "start": 18, "end": 79, "i_start": 4, "i_end": 14}, "verb": {"text": "have been demonstrated", "start": 80, "end": 102, "i_start": 15, "i_end": 17}}, {"character": {"text": "connections", "start": 44, "end": 55, "i_start": 10, "i_end": 10}, "action": {"text": "benefits", "start": 22, "end": 30, "i_start": 5, "i_end": 5}}], "id": 2879}, {"sent": "li et al propose a model that has soft pixel attention and hard regional attention along with simultaneous optimization of feature representations .", "tokens": ["li", "et", "al", "propose", "a", "model", "that", "has", "soft", "pixel", "attention", "and", "hard", "regional", "attention", "along", "with", "simultaneous", "optimization", "of", "feature", "representations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "li et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 9, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "li", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 9, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "model", "start": 19, "end": 24, "i_start": 5, "i_end": 5}, "action": {"text": "has", "start": 30, "end": 33, "i_start": 7, "i_end": 7}}], "id": 2880}, {"sent": "cluster algebras were introduced by fomin and zelevinsky in 2001 in order to design a combinatorial framework for studying total positivity in algebraic groups and canonical bases in quantum groups .", "tokens": ["cluster", "algebras", "were", "introduced", "by", "fomin", "and", "zelevinsky", "in", "2001", "in", "order", "to", "design", "a", "combinatorial", "framework", "for", "studying", "total", "positivity", "in", "algebraic", "groups", "and", "canonical", "bases", "in", "quantum", "groups", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were introduced", "start": 17, "end": 32, "i_start": 2, "i_end": 3}}, {"character": {"text": "fomin", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "zelevinsky", "start": 46, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "fomin", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "design", "start": 77, "end": 83, "i_start": 13, "i_end": 13}}, {"character": {"text": "zelevinsky", "start": 46, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "design", "start": 77, "end": 83, "i_start": 13, "i_end": 13}}], "id": 2881}, {"sent": "weights of the network are initialized with the xavier algorithm , and biases are initialized to 0 .", "tokens": ["weights", "of", "the", "network", "are", "initialized", "with", "the", "xavier", "algorithm", ",", "and", "biases", "are", "initialized", "to", "0", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "weights of the network", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "are initialized", "start": 23, "end": 38, "i_start": 4, "i_end": 5}}, {"subject": {"text": "biases", "start": 71, "end": 77, "i_start": 12, "i_end": 12}, "verb": {"text": "initialized", "start": 82, "end": 93, "i_start": 14, "i_end": 14}}], "id": 2882}, {"sent": "peaks in st-fmr spectra v r arise from resonant excitation of spin wave eigenmodes of the mtj 27 , 28 .", "tokens": ["peaks", "in", "st", "-", "fmr", "spectra", "v", "r", "arise", "from", "resonant", "excitation", "of", "spin", "wave", "eigenmodes", "of", "the", "mtj", "27", ",", "28", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "peaks in st-fmr spectra v r", "start": 0, "end": 27, "i_start": 0, "i_end": 7}, "verb": {"text": "arise", "start": 28, "end": 33, "i_start": 8, "i_end": 8}}, {"character": {"text": "excitation", "start": 48, "end": 58, "i_start": 11, "i_end": 11}, "action": {"text": "arise", "start": 28, "end": 33, "i_start": 8, "i_end": 8}}], "id": 2883}, {"sent": "the perdew-burkeernzerhof generalized-gradient approximation is employed to describe the exchange and correlation functional .", "tokens": ["the", "perdew", "-", "burkeernzerhof", "generalized", "-", "gradient", "approximation", "is", "employed", "to", "describe", "the", "exchange", "and", "correlation", "functional", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the perdew-burkeernzerhof generalized-gradient approximation", "start": 0, "end": 60, "i_start": 0, "i_end": 7}, "verb": {"text": "is employed", "start": 61, "end": 72, "i_start": 8, "i_end": 9}}, {"character": {"text": "approximation", "start": 47, "end": 60, "i_start": 7, "i_end": 7}, "action": {"text": "describe", "start": 76, "end": 84, "i_start": 11, "i_end": 11}}], "id": 2884}, {"sent": "a computationally efficient way of exactly solving the integer ls problem is the sphere decoder .", "tokens": ["a", "computationally", "efficient", "way", "of", "exactly", "solving", "the", "integer", "ls", "problem", "is", "the", "sphere", "decoder", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a computationally efficient way of exactly solving the integer ls problem", "start": 0, "end": 73, "i_start": 0, "i_end": 10}, "verb": {"text": "is", "start": 74, "end": 76, "i_start": 11, "i_end": 11}}], "id": 2885}, {"sent": "in recent work , an intriguing phenomenon was revealed whereby it was shown that weakly-connected graphs enable certain agents to control the opinion of other agents to great degree , irrespective of the observations sensed by these latter agents .", "tokens": ["in", "recent", "work", ",", "an", "intriguing", "phenomenon", "was", "revealed", "whereby", "it", "was", "shown", "that", "weakly", "-", "connected", "graphs", "enable", "certain", "agents", "to", "control", "the", "opinion", "of", "other", "agents", "to", "great", "degree", ",", "irrespective", "of", "the", "observations", "sensed", "by", "these", "latter", "agents", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "an intriguing phenomenon", "start": 17, "end": 41, "i_start": 4, "i_end": 6}, "verb": {"text": "was revealed", "start": 42, "end": 54, "i_start": 7, "i_end": 8}}, {"subject": {"text": "it", "start": 63, "end": 65, "i_start": 10, "i_end": 10}, "verb": {"text": "shown", "start": 70, "end": 75, "i_start": 12, "i_end": 12}}, {"character": {"text": "phenomenon", "start": 31, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "intriguing", "start": 20, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "graphs", "start": 98, "end": 104, "i_start": 17, "i_end": 17}, "action": {"text": "enable", "start": 105, "end": 111, "i_start": 18, "i_end": 18}}, {"character": {"text": "agents", "start": 120, "end": 126, "i_start": 20, "i_end": 20}, "action": {"text": "control", "start": 130, "end": 137, "i_start": 22, "i_end": 22}}, {"character": {"text": "agents", "start": 159, "end": 165, "i_start": 27, "i_end": 27}, "action": {"text": "opinion", "start": 142, "end": 149, "i_start": 24, "i_end": 24}}, {"character": {"text": "agents", "start": 120, "end": 126, "i_start": 20, "i_end": 20}, "action": {"text": "observations", "start": 204, "end": 216, "i_start": 35, "i_end": 35}}, {"character": {"text": "agents", "start": 120, "end": 126, "i_start": 20, "i_end": 20}, "action": {"text": "sensed", "start": 217, "end": 223, "i_start": 36, "i_end": 36}}], "id": 2886}, {"sent": "it was evident the integration cost per unit output energy is smaller for the whole of japan due to the small coefficient of variation .", "tokens": ["it", "was", "evident", "the", "integration", "cost", "per", "unit", "output", "energy", "is", "smaller", "for", "the", "whole", "of", "japan", "due", "to", "the", "small", "coefficient", "of", "variation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "was", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 59, "end": 61, "i_start": 10, "i_end": 10}}], "id": 2887}, {"sent": "the notion of quasi-isometry is an equivalence relation between metric spaces which plays a significant role in the study of discrete groups , for a definition and overview see .", "tokens": ["the", "notion", "of", "quasi", "-", "isometry", "is", "an", "equivalence", "relation", "between", "metric", "spaces", "which", "plays", "a", "significant", "role", "in", "the", "study", "of", "discrete", "groups", ",", "for", "a", "definition", "and", "overview", "see", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the notion of quasi-isometry", "start": 0, "end": 28, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "spaces", "start": 71, "end": 77, "i_start": 12, "i_end": 12}, "action": {"text": "plays", "start": 84, "end": 89, "i_start": 14, "i_end": 14}}], "id": 2888}, {"sent": "the other ingredient is the weight p to assign to each particle .", "tokens": ["the", "other", "ingredient", "is", "the", "weight", "p", "to", "assign", "to", "each", "particle", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the other ingredient", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 3, "i_end": 3}}], "id": 2889}, {"sent": "trager s , worthey g , faber sm , bustein d , gonzales j .", "tokens": ["trager", "s", ",", "worthey", "g", ",", "faber", "sm", ",", "bustein", "d", ",", "gonzales", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2890}, {"sent": "convolutional neural networks have been used in recent years to achieve state-of-the-art performance on object detection .", "tokens": ["convolutional", "neural", "networks", "have", "been", "used", "in", "recent", "years", "to", "achieve", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "object", "detection", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been used", "start": 30, "end": 44, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 64, "end": 71, "i_start": 10, "i_end": 10}}], "id": 2891}, {"sent": "two sided ideals and their lattice structure .", "tokens": ["two", "sided", "ideals", "and", "their", "lattice", "structure", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2892}, {"sent": "show that every unitarizable representation is uniformly bounded .", "tokens": ["show", "that", "every", "unitarizable", "representation", "is", "uniformly", "bounded", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "every unitarizable representation", "start": 10, "end": 43, "i_start": 2, "i_end": 4}, "verb": {"text": "show", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "every unitarizable representation", "start": 10, "end": 43, "i_start": 2, "i_end": 4}, "verb": {"text": "bounded", "start": 57, "end": 64, "i_start": 7, "i_end": 7}}], "id": 2893}, {"sent": "we introduce security conditions based on the average bias of the bits and the shannon entropy of the string .", "tokens": ["we", "introduce", "security", "conditions", "based", "on", "the", "average", "bias", "of", "the", "bits", "and", "the", "shannon", "entropy", "of", "the", "string", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "introduce", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "introduce", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}], "id": 2894}, {"sent": "we use the resnet50 architecture for the visual feature extractor f , with pre-trained weights on imagenet .", "tokens": ["we", "use", "the", "resnet50", "architecture", "for", "the", "visual", "feature", "extractor", "f", ",", "with", "pre", "-", "trained", "weights", "on", "imagenet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 2895}, {"sent": "this subject will be discussed in detail in section five for local models and section seven for compact calabi-yau threefolds .", "tokens": ["this", "subject", "will", "be", "discussed", "in", "detail", "in", "section", "five", "for", "local", "models", "and", "section", "seven", "for", "compact", "calabi", "-", "yau", "threefolds", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this subject", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "will be discussed", "start": 13, "end": 30, "i_start": 2, "i_end": 4}}], "id": 2896}, {"sent": "computer vision in particular has witnessed the development of multiple successful models , based on convolutional neural networks , for tasks such as classification .", "tokens": ["computer", "vision", "in", "particular", "has", "witnessed", "the", "development", "of", "multiple", "successful", "models", ",", "based", "on", "convolutional", "neural", "networks", ",", "for", "tasks", "such", "as", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "computer vision in particular", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "has witnessed", "start": 30, "end": 43, "i_start": 4, "i_end": 5}}], "id": 2897}, {"sent": "in this paper , we follow the deep q-learning framework proposed by mnih et al that estimates the action-value function via a neural network .", "tokens": ["in", "this", "paper", ",", "we", "follow", "the", "deep", "q", "-", "learning", "framework", "proposed", "by", "mnih", "et", "al", "that", "estimates", "the", "action", "-", "value", "function", "via", "a", "neural", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "follow", "start": 19, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "follow", "start": 19, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "mnih", "start": 68, "end": 72, "i_start": 14, "i_end": 14}, "action": {"text": "proposed", "start": 56, "end": 64, "i_start": 12, "i_end": 12}}, {"character": {"text": "learning", "start": 37, "end": 45, "i_start": 10, "i_end": 10}, "action": {"text": "estimates", "start": 84, "end": 93, "i_start": 18, "i_end": 18}}], "id": 2898}, {"sent": "to cancel the tadpole , we should calculate other euler number zero partition functions .", "tokens": ["to", "cancel", "the", "tadpole", ",", "we", "should", "calculate", "other", "euler", "number", "zero", "partition", "functions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "verb": {"text": "should calculate", "start": 27, "end": 43, "i_start": 6, "i_end": 7}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "calculate", "start": 34, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "cancel", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 2899}, {"sent": "the dotted lines show the periodic boundary condition in the vertical direction .", "tokens": ["the", "dotted", "lines", "show", "the", "periodic", "boundary", "condition", "in", "the", "vertical", "direction", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the dotted lines", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "show", "start": 17, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "lines", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 17, "end": 21, "i_start": 3, "i_end": 3}}], "id": 2900}, {"sent": "in recent years , convolutional neural networks have achieved significant success in many computer vision tasks , including the super-resolution problem .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "achieved", "significant", "success", "in", "many", "computer", "vision", "tasks", ",", "including", "the", "super", "-", "resolution", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 48, "end": 61, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 53, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 74, "end": 81, "i_start": 10, "i_end": 10}}], "id": 2901}, {"sent": "the noncommutative geometry of quantum groups is usually discussed in terms of covariant differential calculi .", "tokens": ["the", "noncommutative", "geometry", "of", "quantum", "groups", "is", "usually", "discussed", "in", "terms", "of", "covariant", "differential", "calculi", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the noncommutative geometry of quantum groups", "start": 0, "end": 45, "i_start": 0, "i_end": 5}, "verb": {"text": "discussed", "start": 57, "end": 66, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the noncommutative geometry of quantum groups", "start": 0, "end": 45, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 46, "end": 48, "i_start": 6, "i_end": 6}}], "id": 2902}, {"sent": "all the above networks are trained using adam with batch size 128 and 200 epochs .", "tokens": ["all", "the", "above", "networks", "are", "trained", "using", "adam", "with", "batch", "size", "128", "and", "200", "epochs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all the above networks", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "are trained", "start": 23, "end": 34, "i_start": 4, "i_end": 5}}], "id": 2903}, {"sent": "evaluate their method on ws-353 , a set of 352 pairs of english words , the semantic relatedness of which has been evaluated by 15-16 human judges .", "tokens": ["evaluate", "their", "method", "on", "ws-353", ",", "a", "set", "of", "352", "pairs", "of", "english", "words", ",", "the", "semantic", "relatedness", "of", "which", "has", "been", "evaluated", "by", "15", "-", "16", "human", "judges", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "the semantic relatedness of which", "start": 72, "end": 105, "i_start": 15, "i_end": 19}, "verb": {"text": "has been evaluated", "start": 106, "end": 124, "i_start": 20, "i_end": 22}}, {"character": {"text": "15-16", "start": 128, "end": 133, "i_start": 24, "i_end": 26}, "action": {"text": "evaluated", "start": 115, "end": 124, "i_start": 22, "i_end": 22}}, {"character": {"text": "human", "start": 134, "end": 139, "i_start": 27, "i_end": 27}, "action": {"text": "evaluated", "start": 115, "end": 124, "i_start": 22, "i_end": 22}}], "id": 2904}, {"sent": "network information is available in a wide range of contexts , from social media to political speech to historical texts .", "tokens": ["network", "information", "is", "available", "in", "a", "wide", "range", "of", "contexts", ",", "from", "social", "media", "to", "political", "speech", "to", "historical", "texts", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "network information", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 2, "i_end": 2}}], "id": 2905}, {"sent": "the proof is quite different from because of the non-compactness of \u03c3 .", "tokens": ["the", "proof", "is", "quite", "different", "from", "because", "of", "the", "non", "-", "compactness", "of", "\u03c3", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the proof", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "-compactness", "start": 52, "end": 64, "i_start": 10, "i_end": 11}, "action": {"text": "because", "start": 34, "end": 41, "i_start": 6, "i_end": 6}}], "id": 2906}, {"sent": "a logical framework for reasoning about logical specifications .", "tokens": ["a", "logical", "framework", "for", "reasoning", "about", "logical", "specifications", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2907}, {"sent": "deep neural networks recently have shown successful results on image-based recognition tasks .", "tokens": ["deep", "neural", "networks", "recently", "have", "shown", "successful", "results", "on", "image", "-", "based", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 35, "end": 40, "i_start": 5, "i_end": 5}}], "id": 2908}, {"sent": "for sparse bipartite graphs , the proposed algorithm can significantly outperform the algorithm of in terms of both computational complexity and memory requirements .", "tokens": ["for", "sparse", "bipartite", "graphs", ",", "the", "proposed", "algorithm", "can", "significantly", "outperform", "the", "algorithm", "of", "in", "terms", "of", "both", "computational", "complexity", "and", "memory", "requirements", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the proposed algorithm", "start": 30, "end": 52, "i_start": 5, "i_end": 7}, "verb": {"text": "outperform", "start": 71, "end": 81, "i_start": 10, "i_end": 10}}, {"subject": {"text": "the proposed algorithm", "start": 30, "end": 52, "i_start": 5, "i_end": 7}, "verb": {"text": "can", "start": 53, "end": 56, "i_start": 8, "i_end": 8}}, {"character": {"text": "algorithm", "start": 43, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "outperform", "start": 71, "end": 81, "i_start": 10, "i_end": 10}}], "id": 2909}, {"sent": "zeiler et al found patterns that activate hidden units via deconvolutional neural networks .", "tokens": ["zeiler", "et", "al", "found", "patterns", "that", "activate", "hidden", "units", "via", "deconvolutional", "neural", "networks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 7, "end": 12, "i_start": 1, "i_end": 2}, "verb": {"text": "found", "start": 13, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "zeiler", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "found", "start": 13, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "patterns", "start": 19, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "activate", "start": 33, "end": 41, "i_start": 6, "i_end": 6}}], "id": 2910}, {"sent": "towards these goals , we used a deep convolutional neural network as a fully accessible model of the human visual cortex .", "tokens": ["towards", "these", "goals", ",", "we", "used", "a", "deep", "convolutional", "neural", "network", "as", "a", "fully", "accessible", "model", "of", "the", "human", "visual", "cortex", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 22, "end": 24, "i_start": 4, "i_end": 4}, "verb": {"text": "used", "start": 25, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "used", "start": 25, "end": 29, "i_start": 5, "i_end": 5}}], "id": 2911}, {"sent": "there are algorithms available for quantum computers that perform particular tasks faster than any known deterministic classical algorithm .", "tokens": ["there", "are", "algorithms", "available", "for", "quantum", "computers", "that", "perform", "particular", "tasks", "faster", "than", "any", "known", "deterministic", "classical", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 6, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "algorithms", "start": 10, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "perform", "start": 58, "end": 65, "i_start": 8, "i_end": 8}}], "id": 2912}, {"sent": "we adopt stochastic gradient descent with momentum and back-propagation to train the resnet-101 model .", "tokens": ["we", "adopt", "stochastic", "gradient", "descent", "with", "momentum", "and", "back", "-", "propagation", "to", "train", "the", "resnet-101", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 75, "end": 80, "i_start": 12, "i_end": 12}}], "id": 2913}, {"sent": "without loss of generality , we take the vertices of k c to be as shown in figure 3 .", "tokens": ["without", "loss", "of", "generality", ",", "we", "take", "the", "vertices", "of", "k", "c", "to", "be", "as", "shown", "in", "figure", "3", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "verb": {"text": "take", "start": 32, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "take", "start": 32, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "figure 3", "start": 75, "end": 83, "i_start": 17, "i_end": 18}, "action": {"text": "shown", "start": 66, "end": 71, "i_start": 15, "i_end": 15}}], "id": 2914}, {"sent": "this conjugacy class is called the principal stabilizer of m .", "tokens": ["this", "conjugacy", "class", "is", "called", "the", "principal", "stabilizer", "of", "m", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this conjugacy class", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}], "id": 2915}, {"sent": "in recent years , deep neural networks have demonstrated impressive performance improvements on a wide range of challenging machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "demonstrated", "impressive", "performance", "improvements", "on", "a", "wide", "range", "of", "challenging", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have demonstrated", "start": 39, "end": 56, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "demonstrated", "start": 44, "end": 56, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "improvements", "start": 80, "end": 92, "i_start": 11, "i_end": 11}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 68, "end": 79, "i_start": 10, "i_end": 10}}, {"character": {"text": "tasks", "start": 141, "end": 146, "i_start": 20, "i_end": 20}, "action": {"text": "challenging", "start": 112, "end": 123, "i_start": 17, "i_end": 17}}, {"character": {"text": "improvements", "start": 80, "end": 92, "i_start": 11, "i_end": 11}, "action": {"text": "impressive", "start": 57, "end": 67, "i_start": 9, "i_end": 9}}], "id": 2916}, {"sent": "for moyal geometry recently it was proven that there exists a \u03b8-exact formulation of noncommutative gauge field theory based on the seiberg-witten map .", "tokens": ["for", "moyal", "geometry", "recently", "it", "was", "proven", "that", "there", "exists", "a", "\u03b8", "-", "exact", "formulation", "of", "noncommutative", "gauge", "field", "theory", "based", "on", "the", "seiberg", "-", "witten", "map", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 28, "end": 30, "i_start": 4, "i_end": 4}, "verb": {"text": "was proven", "start": 31, "end": 41, "i_start": 5, "i_end": 6}}, {"subject": {"text": "there", "start": 47, "end": 52, "i_start": 8, "i_end": 8}, "verb": {"text": "exists", "start": 53, "end": 59, "i_start": 9, "i_end": 9}}], "id": 2917}, {"sent": "counterexample in the hard spheres case with higher moment bounds .", "tokens": ["counterexample", "in", "the", "hard", "spheres", "case", "with", "higher", "moment", "bounds", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2918}, {"sent": "in the past few years , deep convolutional neural networks have shown promising results on object detection .", "tokens": ["in", "the", "past", "few", "years", ",", "deep", "convolutional", "neural", "networks", "have", "shown", "promising", "results", "on", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 24, "end": 58, "i_start": 6, "i_end": 9}, "verb": {"text": "have shown", "start": 59, "end": 69, "i_start": 10, "i_end": 11}}, {"character": {"text": "networks", "start": 50, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "shown", "start": 64, "end": 69, "i_start": 11, "i_end": 11}}, {"character": {"text": "results", "start": 80, "end": 87, "i_start": 13, "i_end": 13}, "action": {"text": "promising", "start": 70, "end": 79, "i_start": 12, "i_end": 12}}], "id": 2919}, {"sent": "in this paper , we show that the basic mathematical structure of quantum mechanics like the probability amplitude , born rule , probability density current , commutation relations , momentum operator , uncertainty relations , rules for including the scalar and vector potentials and existence of antiparticles can be derived from the definition of the mean values of the space coordinates and time .", "tokens": ["in", "this", "paper", ",", "we", "show", "that", "the", "basic", "mathematical", "structure", "of", "quantum", "mechanics", "like", "the", "probability", "amplitude", ",", "born", "rule", ",", "probability", "density", "current", ",", "commutation", "relations", ",", "momentum", "operator", ",", "uncertainty", "relations", ",", "rules", "for", "including", "the", "scalar", "and", "vector", "potentials", "and", "existence", "of", "antiparticles", "can", "be", "derived", "from", "the", "definition", "of", "the", "mean", "values", "of", "the", "space", "coordinates", "and", "time", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "show", "start": 19, "end": 23, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the basic mathematical structure of quantum mechanics like the probability amplitude , born rule , probability density current , commutation relations", "start": 29, "end": 179, "i_start": 7, "i_end": 27}, "verb": {"text": "derived", "start": 317, "end": 324, "i_start": 49, "i_end": 49}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "show", "start": 19, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "rules", "start": 226, "end": 231, "i_start": 35, "i_end": 35}, "action": {"text": "of", "start": 62, "end": 64, "i_start": 11, "i_end": 11}}], "id": 2920}, {"sent": "for example , while the results in are limited to tss and etss , in this work , we also cover letss .", "tokens": ["for", "example", ",", "while", "the", "results", "in", "are", "limited", "to", "tss", "and", "etss", ",", "in", "this", "work", ",", "we", "also", "cover", "letss", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 80, "end": 82, "i_start": 18, "i_end": 18}, "verb": {"text": "cover", "start": 88, "end": 93, "i_start": 20, "i_end": 20}}, {"character": {"text": "we", "start": 80, "end": 82, "i_start": 18, "i_end": 18}, "action": {"text": "cover", "start": 88, "end": 93, "i_start": 20, "i_end": 20}}], "id": 2921}, {"sent": "deeper convolutional neural networks have obtained state-of-the-art results in many image classification tasks .", "tokens": ["deeper", "convolutional", "neural", "networks", "have", "obtained", "state", "-", "of", "-", "the", "-", "art", "results", "in", "many", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deeper convolutional neural networks", "start": 0, "end": 36, "i_start": 0, "i_end": 3}, "verb": {"text": "have obtained", "start": 37, "end": 50, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 28, "end": 36, "i_start": 3, "i_end": 3}, "action": {"text": "obtained", "start": 42, "end": 50, "i_start": 5, "i_end": 5}}], "id": 2922}, {"sent": "energy that is not radiated away by the explosion itself travels outwards at a relativistic speed , causing a highly relativistic shock wave to propagate forward into space .", "tokens": ["energy", "that", "is", "not", "radiated", "away", "by", "the", "explosion", "itself", "travels", "outwards", "at", "a", "relativistic", "speed", ",", "causing", "a", "highly", "relativistic", "shock", "wave", "to", "propagate", "forward", "into", "space", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "energy that is not radiated away by the explosion itself", "start": 0, "end": 56, "i_start": 0, "i_end": 9}, "verb": {"text": "travels", "start": 57, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "energy", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "travels", "start": 57, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "explosion", "start": 40, "end": 49, "i_start": 8, "i_end": 8}, "action": {"text": "not radiated", "start": 15, "end": 27, "i_start": 3, "i_end": 4}}, {"character": {"text": "travels", "start": 57, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "causing", "start": 100, "end": 107, "i_start": 17, "i_end": 17}}], "id": 2923}, {"sent": "deep learning has brought significant breakthroughs in many computer vision tasks , including object detection .", "tokens": ["deep", "learning", "has", "brought", "significant", "breakthroughs", "in", "many", "computer", "vision", "tasks", ",", "including", "object", "detection", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has brought", "start": 14, "end": 25, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "breakthroughs", "start": 38, "end": 51, "i_start": 5, "i_end": 5}}], "id": 2924}, {"sent": "rebuffi et al propose adapter residual modules which achieves a high degree of parameter sharing while maintaining or even improving the accuracy of domain-specific representations .", "tokens": ["rebuffi", "et", "al", "propose", "adapter", "residual", "modules", "which", "achieves", "a", "high", "degree", "of", "parameter", "sharing", "while", "maintaining", "or", "even", "improving", "the", "accuracy", "of", "domain", "-", "specific", "representations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "rebuffi et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "rebuffi", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "modules", "start": 39, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "achieves", "start": 53, "end": 61, "i_start": 8, "i_end": 8}}], "id": 2925}, {"sent": "this result holds also for all the other data .", "tokens": ["this", "result", "holds", "also", "for", "all", "the", "other", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this result", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "holds", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "result", "start": 5, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "holds", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}], "id": 2926}, {"sent": "a quantum circuit is a computational network composed of interconnected elementary quantum gates .", "tokens": ["a", "quantum", "circuit", "is", "a", "computational", "network", "composed", "of", "interconnected", "elementary", "quantum", "gates", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a quantum circuit", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}], "id": 2927}, {"sent": "in recent years , deep neural networks have achieved great success in a variety of machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "achieved", "great", "success", "in", "a", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}], "id": 2928}, {"sent": "gallavotti and cohen provided a proof of the ft for time-reversible anosov systems .", "tokens": ["gallavotti", "and", "cohen", "provided", "a", "proof", "of", "the", "ft", "for", "time", "-", "reversible", "anosov", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "gallavotti and cohen", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "provided", "start": 21, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "gallavotti", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "provided", "start": 21, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "cohen", "start": 15, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "provided", "start": 21, "end": 29, "i_start": 3, "i_end": 3}}], "id": 2929}, {"sent": "just as the tangent algebra of a lie group is a lie algebra , the tangent algebra of a locally analytic moufang loop is a malcev algebra for discussions about connections with physics .", "tokens": ["just", "as", "the", "tangent", "algebra", "of", "a", "lie", "group", "is", "a", "lie", "algebra", ",", "the", "tangent", "algebra", "of", "a", "locally", "analytic", "moufang", "loop", "is", "a", "malcev", "algebra", "for", "discussions", "about", "connections", "with", "physics", "."], "score": [1, 1, 1, 1, 0], "labels": [{"subject": {"text": "the tangent algebra of a locally analytic moufang loop", "start": 62, "end": 116, "i_start": 14, "i_end": 22}, "verb": {"text": "is", "start": 117, "end": 119, "i_start": 23, "i_end": 23}}], "id": 2930}, {"sent": "if gyroscope is a well-distributed sphere , from eq .", "tokens": ["if", "gyroscope", "is", "a", "well", "-", "distributed", "sphere", ",", "from", "eq", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "gyroscope", "start": 3, "end": 12, "i_start": 1, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 2931}, {"sent": "however , this tachyon is a fluctuation of the massless ns-ns modes , and the polarization can be found by applying buscher duality to the vertex operator .", "tokens": ["however", ",", "this", "tachyon", "is", "a", "fluctuation", "of", "the", "massless", "ns", "-", "ns", "modes", ",", "and", "the", "polarization", "can", "be", "found", "by", "applying", "buscher", "duality", "to", "the", "vertex", "operator", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this tachyon", "start": 10, "end": 22, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the polarization", "start": 74, "end": 90, "i_start": 16, "i_end": 17}, "verb": {"text": "found", "start": 98, "end": 103, "i_start": 20, "i_end": 20}}], "id": 2932}, {"sent": "this point of view is forcefully suggested in , where a mapping is proposed between ordinary and non-commutative gauge fields which do not preserve the gauge groups but preserve the gauge equivalent classes .", "tokens": ["this", "point", "of", "view", "is", "forcefully", "suggested", "in", ",", "where", "a", "mapping", "is", "proposed", "between", "ordinary", "and", "non", "-", "commutative", "gauge", "fields", "which", "do", "not", "preserve", "the", "gauge", "groups", "but", "preserve", "the", "gauge", "equivalent", "classes", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "a mapping", "start": 54, "end": 63, "i_start": 10, "i_end": 11}, "verb": {"text": "suggested", "start": 33, "end": 42, "i_start": 6, "i_end": 6}}, {"subject": {"text": "this point of view", "start": 0, "end": 18, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 4, "i_end": 4}}, {"subject": {"text": "this point of view", "start": 0, "end": 18, "i_start": 0, "i_end": 3}, "verb": {"text": "proposed", "start": 67, "end": 75, "i_start": 13, "i_end": 13}}, {"character": {"text": "fields", "start": 119, "end": 125, "i_start": 21, "i_end": 21}, "action": {"text": "not preserve", "start": 135, "end": 147, "i_start": 24, "i_end": 25}}, {"character": {"text": "fields", "start": 119, "end": 125, "i_start": 21, "i_end": 21}, "action": {"text": "preserve", "start": 169, "end": 177, "i_start": 30, "i_end": 30}}], "id": 2933}, {"sent": "simulation results validate our analytical results and quantify the performance gains enabled by the proposed spectrum sharing policies .", "tokens": ["simulation", "results", "validate", "our", "analytical", "results", "and", "quantify", "the", "performance", "gains", "enabled", "by", "the", "proposed", "spectrum", "sharing", "policies", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "simulation results", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "validate", "start": 19, "end": 27, "i_start": 2, "i_end": 2}}, {"subject": {"text": "simulation results", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "quantify", "start": 55, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "results", "start": 11, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "validate", "start": 19, "end": 27, "i_start": 2, "i_end": 2}}, {"character": {"text": "results", "start": 11, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "quantify", "start": 55, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "policies", "start": 127, "end": 135, "i_start": 17, "i_end": 17}, "action": {"text": "enabled", "start": 86, "end": 93, "i_start": 11, "i_end": 11}}], "id": 2934}, {"sent": "recently , cnns have been successfully applied to several computer vision tasks such as object recognition , localization and tracking .", "tokens": ["recently", ",", "cnns", "have", "been", "successfully", "applied", "to", "several", "computer", "vision", "tasks", "such", "as", "object", "recognition", ",", "localization", "and", "tracking", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cnns", "start": 11, "end": 15, "i_start": 2, "i_end": 2}, "verb": {"text": "applied", "start": 39, "end": 46, "i_start": 6, "i_end": 6}}, {"subject": {"text": "cnns", "start": 11, "end": 15, "i_start": 2, "i_end": 2}, "verb": {"text": "have been", "start": 16, "end": 25, "i_start": 3, "i_end": 4}}], "id": 2935}, {"sent": "lowe proposed a method to extract distinctive invariant image features that can be used to perform robust matching between different viewpoints of an object .", "tokens": ["lowe", "proposed", "a", "method", "to", "extract", "distinctive", "invariant", "image", "features", "that", "can", "be", "used", "to", "perform", "robust", "matching", "between", "different", "viewpoints", "of", "an", "object", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "lowe", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "proposed", "start": 5, "end": 13, "i_start": 1, "i_end": 1}}], "id": 2936}, {"sent": "cluster algebras have been introduced and studied by fomin and zelevinsky in .", "tokens": ["cluster", "algebras", "have", "been", "introduced", "and", "studied", "by", "fomin", "and", "zelevinsky", "in", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "have been introduced", "start": 17, "end": 37, "i_start": 2, "i_end": 4}}, {"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "studied", "start": 42, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "fomin", "start": 53, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "introduced", "start": 27, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "zelevinsky", "start": 63, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "introduced", "start": 27, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "fomin", "start": 53, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "studied", "start": 42, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "zelevinsky", "start": 63, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "studied", "start": 42, "end": 49, "i_start": 6, "i_end": 6}}], "id": 2937}, {"sent": "however , the quantum computer is a theoretical construct currently .", "tokens": ["however", ",", "the", "quantum", "computer", "is", "a", "theoretical", "construct", "currently", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quantum computer", "start": 10, "end": 30, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 5, "i_end": 5}}], "id": 2938}, {"sent": "we thus employ the akaike information criterion and the bayesian information criterion to do the model comparison in this situation .", "tokens": ["we", "thus", "employ", "the", "akaike", "information", "criterion", "and", "the", "bayesian", "information", "criterion", "to", "do", "the", "model", "comparison", "in", "this", "situation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employ", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "comparison", "start": 103, "end": 113, "i_start": 16, "i_end": 16}}], "id": 2939}, {"sent": "on the other hand , it is verified that q-rank 1 locally symmetric spaces covered by the product of r-rank 1 symmetric spaces have positive simplicial volumes .", "tokens": ["on", "the", "other", "hand", ",", "it", "is", "verified", "that", "q", "-", "rank", "1", "locally", "symmetric", "spaces", "covered", "by", "the", "product", "of", "r", "-", "rank", "1", "symmetric", "spaces", "have", "positive", "simplicial", "volumes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 20, "end": 22, "i_start": 5, "i_end": 5}, "verb": {"text": "is verified", "start": 23, "end": 34, "i_start": 6, "i_end": 7}}, {"subject": {"text": "q-rank 1 locally symmetric spaces covered by the product of r-rank 1 symmetric spaces", "start": 40, "end": 125, "i_start": 9, "i_end": 26}, "verb": {"text": "have", "start": 126, "end": 130, "i_start": 27, "i_end": 27}}, {"character": {"text": "spaces", "start": 67, "end": 73, "i_start": 15, "i_end": 15}, "action": {"text": "have", "start": 126, "end": 130, "i_start": 27, "i_end": 27}}, {"character": {"text": "product", "start": 89, "end": 96, "i_start": 19, "i_end": 19}, "action": {"text": "covered", "start": 74, "end": 81, "i_start": 16, "i_end": 16}}], "id": 2940}, {"sent": "a similar model , and its reduction to account for multiple biological viruses in one population , is presented by levy et al .", "tokens": ["a", "similar", "model", ",", "and", "its", "reduction", "to", "account", "for", "multiple", "biological", "viruses", "in", "one", "population", ",", "is", "presented", "by", "levy", "et", "al", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "a similar model , and its reduction to account for multiple biological viruses in one population", "start": 0, "end": 96, "i_start": 0, "i_end": 15}, "verb": {"text": "is presented", "start": 99, "end": 111, "i_start": 17, "i_end": 18}}, {"character": {"text": "levy", "start": 115, "end": 119, "i_start": 20, "i_end": 20}, "action": {"text": "presented", "start": 102, "end": 111, "i_start": 18, "i_end": 18}}, {"character": {"text": "model", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "account", "start": 39, "end": 46, "i_start": 8, "i_end": 8}}], "id": 2941}, {"sent": "by the eastin-knill theorem , it is impossible to generate a complete universal encoded gate basis in transversal form .", "tokens": ["by", "the", "eastin", "-", "knill", "theorem", ",", "it", "is", "impossible", "to", "generate", "a", "complete", "universal", "encoded", "gate", "basis", "in", "transversal", "form", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 30, "end": 32, "i_start": 7, "i_end": 7}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 8, "i_end": 8}}], "id": 2942}, {"sent": "we take the pre-trained 19-layer vgg net as a fixed extractor of general high-level image features .", "tokens": ["we", "take", "the", "pre", "-", "trained", "19", "-", "layer", "vgg", "net", "as", "a", "fixed", "extractor", "of", "general", "high", "-", "level", "image", "features", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "take", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "take", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "net", "start": 37, "end": 40, "i_start": 10, "i_end": 10}, "action": {"text": "extractor", "start": 52, "end": 61, "i_start": 14, "i_end": 14}}], "id": 2943}, {"sent": "the study of complex networks has received an enormous amount of attention from the scientific community in recent years .", "tokens": ["the", "study", "of", "complex", "networks", "has", "received", "an", "enormous", "amount", "of", "attention", "from", "the", "scientific", "community", "in", "recent", "years", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the study of complex networks", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "has received", "start": 30, "end": 42, "i_start": 5, "i_end": 6}}, {"character": {"text": "community", "start": 95, "end": 104, "i_start": 15, "i_end": 15}, "action": {"text": "attention", "start": 65, "end": 74, "i_start": 11, "i_end": 11}}], "id": 2944}, {"sent": "for compact recurrent r-trees we provide bounds on the mixing time .", "tokens": ["for", "compact", "recurrent", "r", "-", "trees", "we", "provide", "bounds", "on", "the", "mixing", "time", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 30, "end": 32, "i_start": 6, "i_end": 6}, "action": {"text": "provide", "start": 33, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 30, "end": 32, "i_start": 6, "i_end": 6}, "action": {"text": "bounds", "start": 41, "end": 47, "i_start": 8, "i_end": 8}}], "id": 2945}, {"sent": "to cope with this problem , algorithms that work directly on compressed representations of strings without explicit decompression have gained attention , especially for the string pattern matching problem .", "tokens": ["to", "cope", "with", "this", "problem", ",", "algorithms", "that", "work", "directly", "on", "compressed", "representations", "of", "strings", "without", "explicit", "decompression", "have", "gained", "attention", ",", "especially", "for", "the", "string", "pattern", "matching", "problem", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "algorithms that work directly on compressed representations of strings without explicit decompression", "start": 28, "end": 129, "i_start": 6, "i_end": 17}, "verb": {"text": "have gained", "start": 130, "end": 141, "i_start": 18, "i_end": 19}}, {"character": {"text": "algorithms", "start": 28, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "gained", "start": 135, "end": 141, "i_start": 19, "i_end": 19}}, {"character": {"text": "algorithms", "start": 28, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "work", "start": 44, "end": 48, "i_start": 8, "i_end": 8}}], "id": 2946}, {"sent": "ngiam et al proposed a multimodal deep learning approach for cross modality feature learning from video and speech data .", "tokens": ["ngiam", "et", "al", "proposed", "a", "multimodal", "deep", "learning", "approach", "for", "cross", "modality", "feature", "learning", "from", "video", "and", "speech", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "ngiam et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "ngiam", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "feature", "start": 76, "end": 83, "i_start": 12, "i_end": 12}, "action": {"text": "cross", "start": 61, "end": 66, "i_start": 10, "i_end": 10}}], "id": 2947}, {"sent": "for a discussion of how these diagrams arise in the theory of finite type invariants , see .", "tokens": ["for", "a", "discussion", "of", "how", "these", "diagrams", "arise", "in", "the", "theory", "of", "finite", "type", "invariants", ",", "see", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2948}, {"sent": "here , we propose and simulate a matter-wave experiment which , for the first time , can demonstrate a bell inequality violation for pairs of momentum-entangled ultracold atoms produced in a collision of two bose-einstein condensates .", "tokens": ["here", ",", "we", "propose", "and", "simulate", "a", "matter", "-", "wave", "experiment", "which", ",", "for", "the", "first", "time", ",", "can", "demonstrate", "a", "bell", "inequality", "violation", "for", "pairs", "of", "momentum", "-", "entangled", "ultracold", "atoms", "produced", "in", "a", "collision", "of", "two", "bose", "-", "einstein", "condensates", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "propose", "start": 10, "end": 17, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "simulate", "start": 22, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "propose", "start": 10, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "experiment", "start": 45, "end": 55, "i_start": 10, "i_end": 10}, "action": {"text": "demonstrate", "start": 89, "end": 100, "i_start": 19, "i_end": 19}}, {"character": {"text": "pairs", "start": 133, "end": 138, "i_start": 25, "i_end": 25}, "action": {"text": "violation", "start": 119, "end": 128, "i_start": 23, "i_end": 23}}, {"character": {"text": "collision", "start": 191, "end": 200, "i_start": 35, "i_end": 35}, "action": {"text": "produced", "start": 177, "end": 185, "i_start": 32, "i_end": 32}}, {"character": {"text": "two bose-einstein condensates", "start": 204, "end": 233, "i_start": 37, "i_end": 41}, "action": {"text": "collision", "start": 191, "end": 200, "i_start": 35, "i_end": 35}}], "id": 2949}, {"sent": "the kolmogorov complexity of real numbers .", "tokens": ["the", "kolmogorov", "complexity", "of", "real", "numbers", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2950}, {"sent": "we use the scikit-learn implementation of a linear svm with default parameters .", "tokens": ["we", "use", "the", "scikit", "-", "learn", "implementation", "of", "a", "linear", "svm", "with", "default", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 2951}, {"sent": "for many prior symmetric transformation methods , all layers are constrained , thus enforcing exact source and target mapping consistency .", "tokens": ["for", "many", "prior", "symmetric", "transformation", "methods", ",", "all", "layers", "are", "constrained", ",", "thus", "enforcing", "exact", "source", "and", "target", "mapping", "consistency", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all layers", "start": 50, "end": 60, "i_start": 7, "i_end": 8}, "verb": {"text": "are constrained", "start": 61, "end": 76, "i_start": 9, "i_end": 10}}], "id": 2952}, {"sent": "cluster algebras were introduced and studied in a series of four articles by fomin-zelevinsky , see .", "tokens": ["cluster", "algebras", "were", "introduced", "and", "studied", "in", "a", "series", "of", "four", "articles", "by", "fomin", "-", "zelevinsky", ",", "see", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "see", "start": 96, "end": 99, "i_start": 17, "i_end": 17}}, {"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}], "id": 2953}, {"sent": "the notion of gabriel-roiter measure , an invariant assigned to any module of finite length , was defined by gabriel and ringel .", "tokens": ["the", "notion", "of", "gabriel", "-", "roiter", "measure", ",", "an", "invariant", "assigned", "to", "any", "module", "of", "finite", "length", ",", "was", "defined", "by", "gabriel", "and", "ringel", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the notion of gabriel-roiter measure , an invariant assigned to any module of finite length", "start": 0, "end": 91, "i_start": 0, "i_end": 16}, "verb": {"text": "was defined", "start": 94, "end": 105, "i_start": 18, "i_end": 19}}, {"character": {"text": "gabriel", "start": 14, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "defined", "start": 98, "end": 105, "i_start": 19, "i_end": 19}}, {"character": {"text": "ringel", "start": 121, "end": 127, "i_start": 23, "i_end": 23}, "action": {"text": "defined", "start": 98, "end": 105, "i_start": 19, "i_end": 19}}], "id": 2954}, {"sent": "leptogenesis is one of the most attractive scenarios to explain the origin of the observed matter-antimatter asymmetry of the universe .", "tokens": ["leptogenesis", "is", "one", "of", "the", "most", "attractive", "scenarios", "to", "explain", "the", "origin", "of", "the", "observed", "matter", "-", "antimatter", "asymmetry", "of", "the", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "leptogenesis", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "scenarios", "start": 43, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "attractive", "start": 32, "end": 42, "i_start": 6, "i_end": 6}}, {"character": {"text": "scenarios", "start": 43, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "explain", "start": 56, "end": 63, "i_start": 9, "i_end": 9}}], "id": 2955}, {"sent": "compared to previous unet implementations , we also apply batch normalization to accelerate the training process .", "tokens": ["compared", "to", "previous", "unet", "implementations", ",", "we", "also", "apply", "batch", "normalization", "to", "accelerate", "the", "training", "process", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 44, "end": 46, "i_start": 6, "i_end": 6}, "verb": {"text": "apply", "start": 52, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 44, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "apply", "start": 52, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 44, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "accelerate", "start": 81, "end": 91, "i_start": 12, "i_end": 12}}], "id": 2956}, {"sent": "the lac operon has been studied extensively and is one of the earliest discovered gene systems that undergoes both positive and negative control .", "tokens": ["the", "lac", "operon", "has", "been", "studied", "extensively", "and", "is", "one", "of", "the", "earliest", "discovered", "gene", "systems", "that", "undergoes", "both", "positive", "and", "negative", "control", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lac operon", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "has been studied", "start": 15, "end": 31, "i_start": 3, "i_end": 5}}], "id": 2957}, {"sent": "however , previous hand-crafted features-based unsupervised learning methods offer significantly inferior re-id matching performance , when compared to the supervised learning models .", "tokens": ["however", ",", "previous", "hand", "-", "crafted", "features", "-", "based", "unsupervised", "learning", "methods", "offer", "significantly", "inferior", "re", "-", "id", "matching", "performance", ",", "when", "compared", "to", "the", "supervised", "learning", "models", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "previous hand-crafted features-based unsupervised learning methods", "start": 10, "end": 76, "i_start": 2, "i_end": 11}, "verb": {"text": "offer", "start": 77, "end": 82, "i_start": 12, "i_end": 12}}, {"character": {"text": "methods", "start": 69, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "offer", "start": 77, "end": 82, "i_start": 12, "i_end": 12}}, {"character": {"text": "hand", "start": 19, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "crafted", "start": 24, "end": 31, "i_start": 5, "i_end": 5}}], "id": 2958}, {"sent": "we use a kernel size of 3 and stride of 1 and furthermore use batch normalization and relu activations after each convolution layer except the last one .", "tokens": ["we", "use", "a", "kernel", "size", "of", "3", "and", "stride", "of", "1", "and", "furthermore", "use", "batch", "normalization", "and", "relu", "activations", "after", "each", "convolution", "layer", "except", "the", "last", "one", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 58, "end": 61, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 58, "end": 61, "i_start": 13, "i_end": 13}}], "id": 2959}, {"sent": "one example is the random halves model proposed in , in which the number of clocks varies randomly with time instead of being a constant .", "tokens": ["one", "example", "is", "the", "random", "halves", "model", "proposed", "in", ",", "in", "which", "the", "number", "of", "clocks", "varies", "randomly", "with", "time", "instead", "of", "being", "a", "constant", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one example", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 2960}, {"sent": "recently , deep convolutional neural networks are widely applied to face recognition and provide state-of-the-art performance .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "are", "widely", "applied", "to", "face", "recognition", "and", "provide", "state", "-", "of", "-", "the", "-", "art", "performance", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "applied", "start": 57, "end": 64, "i_start": 8, "i_end": 8}}, {"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "are", "start": 46, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "provide", "start": 89, "end": 96, "i_start": 13, "i_end": 13}}], "id": 2961}, {"sent": "recently , deep neural networks have led to significant improvement in several machine learning domains , from speech recognition to computer vision and machine translation .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "led", "to", "significant", "improvement", "in", "several", "machine", "learning", "domains", ",", "from", "speech", "recognition", "to", "computer", "vision", "and", "machine", "translation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have led", "start": 32, "end": 40, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "led", "start": 37, "end": 40, "i_start": 6, "i_end": 6}}], "id": 2962}, {"sent": "specifically , we choose a resnet-152 model pretrained on imagenet as the image encoder .", "tokens": ["specifically", ",", "we", "choose", "a", "resnet-152", "model", "pretrained", "on", "imagenet", "as", "the", "image", "encoder", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "choose", "start": 18, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "choose", "start": 18, "end": 24, "i_start": 3, "i_end": 3}}], "id": 2963}, {"sent": "thus we have obtained anomalous dimensions of all the fields and rg functions of all parameters at the one-loop level of perturbative expansion based on the dimensional regularization .", "tokens": ["thus", "we", "have", "obtained", "anomalous", "dimensions", "of", "all", "the", "fields", "and", "rg", "functions", "of", "all", "parameters", "at", "the", "one", "-", "loop", "level", "of", "perturbative", "expansion", "based", "on", "the", "dimensional", "regularization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "have obtained", "start": 8, "end": 21, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "obtained", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "parameters", "start": 85, "end": 95, "i_start": 15, "i_end": 15}, "action": {"text": "functions", "start": 68, "end": 77, "i_start": 12, "i_end": 12}}], "id": 2964}, {"sent": "since the odd dimensional orthogonal groups are isomorphic to symplectic groups , we need only consider the even dimensional case .", "tokens": ["since", "the", "odd", "dimensional", "orthogonal", "groups", "are", "isomorphic", "to", "symplectic", "groups", ",", "we", "need", "only", "consider", "the", "even", "dimensional", "case", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2965}, {"sent": "isolation concepts for enumerating dense subgraphs .", "tokens": ["isolation", "concepts", "for", "enumerating", "dense", "subgraphs", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2966}, {"sent": "rettori , jj neumeier , and sb oseroff , phys .", "tokens": ["rettori", ",", "jj", "neumeier", ",", "and", "sb", "oseroff", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2967}, {"sent": "the power spectrum of the string-induced fluctuations is approximately scale-invariant .", "tokens": ["the", "power", "spectrum", "of", "the", "string", "-", "induced", "fluctuations", "is", "approximately", "scale", "-", "invariant", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the power spectrum of the string-induced fluctuations", "start": 0, "end": 53, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 54, "end": 56, "i_start": 9, "i_end": 9}}, {"character": {"text": "string", "start": 26, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "induced", "start": 33, "end": 40, "i_start": 7, "i_end": 7}}], "id": 2968}, {"sent": "in , edge swapping is proposed as a technique to increase the stopping distance of an ldpc code , and thus to improve its error floor performance over the bec .", "tokens": ["in", ",", "edge", "swapping", "is", "proposed", "as", "a", "technique", "to", "increase", "the", "stopping", "distance", "of", "an", "ldpc", "code", ",", "and", "thus", "to", "improve", "its", "error", "floor", "performance", "over", "the", "bec", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "edge swapping", "start": 5, "end": 18, "i_start": 2, "i_end": 3}, "verb": {"text": "is proposed", "start": 19, "end": 30, "i_start": 4, "i_end": 5}}, {"subject": {"text": "edge swapping", "start": 5, "end": 18, "i_start": 2, "i_end": 3}, "verb": {"text": "improve", "start": 110, "end": 117, "i_start": 22, "i_end": 22}}], "id": 2969}, {"sent": "the kernel of this map consists of polynomials of degree a which vanish on \u03b3 , so the kernel is simply the degree a piece of the ideal i\u03b3 .", "tokens": ["the", "kernel", "of", "this", "map", "consists", "of", "polynomials", "of", "degree", "a", "which", "vanish", "on", "\u03b3", ",", "so", "the", "kernel", "is", "simply", "the", "degree", "a", "piece", "of", "the", "ideal", "i\u03b3", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the kernel", "start": 82, "end": 92, "i_start": 17, "i_end": 18}, "verb": {"text": "is", "start": 93, "end": 95, "i_start": 19, "i_end": 19}}, {"subject": {"text": "the kernel of this map", "start": 0, "end": 22, "i_start": 0, "i_end": 4}, "verb": {"text": "consists", "start": 23, "end": 31, "i_start": 5, "i_end": 5}}], "id": 2970}, {"sent": "the millimeter wave bands -roughly corresponding to frequencies above 10 ghz -are a new frontier for cellular wireless communications .", "tokens": ["the", "millimeter", "wave", "bands", "-roughly", "corresponding", "to", "frequencies", "above", "10", "ghz", "-are", "a", "new", "frontier", "for", "cellular", "wireless", "communications", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 2971}, {"sent": "the data were calibrated using the miriad package .", "tokens": ["the", "data", "were", "calibrated", "using", "the", "miriad", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "were calibrated", "start": 9, "end": 24, "i_start": 2, "i_end": 3}}], "id": 2972}, {"sent": "machine learning has shown great success in building models for pattern recognition in domains ranging from computer vision .", "tokens": ["machine", "learning", "has", "shown", "great", "success", "in", "building", "models", "for", "pattern", "recognition", "in", "domains", "ranging", "from", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "machine learning", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "has shown", "start": 17, "end": 26, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 8, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "success", "start": 33, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "learning", "start": 8, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "building", "start": 44, "end": 52, "i_start": 7, "i_end": 7}}], "id": 2973}, {"sent": "this architecture is motivated by resnet where the network has skip connections .", "tokens": ["this", "architecture", "is", "motivated", "by", "resnet", "where", "the", "network", "has", "skip", "connections", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this architecture", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is motivated", "start": 18, "end": 30, "i_start": 2, "i_end": 3}}, {"character": {"text": "resnet", "start": 34, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "motivated", "start": 21, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "network", "start": 51, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "has", "start": 59, "end": 62, "i_start": 9, "i_end": 9}}], "id": 2974}, {"sent": "our encoder e is a convolutional network variant of the inception architecture .", "tokens": ["our", "encoder", "e", "is", "a", "convolutional", "network", "variant", "of", "the", "inception", "architecture", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our encoder e", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 3, "i_end": 3}}], "id": 2975}, {"sent": "in 2006 , ryu and takayanagi proposed that the quantum entanglement entropy can be directly obtained from minimal surface .", "tokens": ["in", "2006", ",", "ryu", "and", "takayanagi", "proposed", "that", "the", "quantum", "entanglement", "entropy", "can", "be", "directly", "obtained", "from", "minimal", "surface", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "ryu and takayanagi", "start": 10, "end": 28, "i_start": 3, "i_end": 5}, "verb": {"text": "proposed", "start": 29, "end": 37, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the quantum entanglement entropy", "start": 43, "end": 75, "i_start": 8, "i_end": 11}, "verb": {"text": "obtained", "start": 92, "end": 100, "i_start": 15, "i_end": 15}}, {"character": {"text": "ryu", "start": 10, "end": 13, "i_start": 3, "i_end": 3}, "action": {"text": "proposed", "start": 29, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "takayanagi", "start": 18, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "proposed", "start": 29, "end": 37, "i_start": 6, "i_end": 6}}], "id": 2976}, {"sent": "in recent years , deep neural networks have been shown to be useful in a wide range of applications including computer vision .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "been", "shown", "to", "be", "useful", "in", "a", "wide", "range", "of", "applications", "including", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have been shown", "start": 39, "end": 54, "i_start": 7, "i_end": 9}}], "id": 2977}, {"sent": "deep neural networks are powerful learning models that achieve state-of-the-art pattern recognition performance in many research areas such as bioinformatics .", "tokens": ["deep", "neural", "networks", "are", "powerful", "learning", "models", "that", "achieve", "state", "-", "of", "-", "the", "-", "art", "pattern", "recognition", "performance", "in", "many", "research", "areas", "such", "as", "bioinformatics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 43, "end": 49, "i_start": 6, "i_end": 6}, "action": {"text": "learning", "start": 34, "end": 42, "i_start": 5, "i_end": 5}}, {"character": {"text": "models", "start": 43, "end": 49, "i_start": 6, "i_end": 6}, "action": {"text": "achieve", "start": 55, "end": 62, "i_start": 8, "i_end": 8}}], "id": 2978}, {"sent": "in order to train the cnn model , we employ the adam optimizer , a commonly used type of stochastic gradient descent .", "tokens": ["in", "order", "to", "train", "the", "cnn", "model", ",", "we", "employ", "the", "adam", "optimizer", ",", "a", "commonly", "used", "type", "of", "stochastic", "gradient", "descent", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 34, "end": 36, "i_start": 8, "i_end": 8}, "verb": {"text": "employ", "start": 37, "end": 43, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 8, "i_end": 8}, "action": {"text": "employ", "start": 37, "end": 43, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 8, "i_end": 8}, "action": {"text": "train", "start": 12, "end": 17, "i_start": 3, "i_end": 3}}], "id": 2979}, {"sent": "the spin-polarized density functional theory calculations were carried out by using the projector augmented wave method 26 , 27 as implemented in the vienna ab initio simulation package .", "tokens": ["the", "spin", "-", "polarized", "density", "functional", "theory", "calculations", "were", "carried", "out", "by", "using", "the", "projector", "augmented", "wave", "method", "26", ",", "27", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the spin-polarized density functional theory calculations", "start": 0, "end": 57, "i_start": 0, "i_end": 7}, "verb": {"text": "were carried out", "start": 58, "end": 74, "i_start": 8, "i_end": 10}}, {"character": {"text": "projector", "start": 88, "end": 97, "i_start": 14, "i_end": 14}, "action": {"text": "augmented", "start": 98, "end": 107, "i_start": 15, "i_end": 15}}], "id": 2980}, {"sent": "thus , the space h 0 is a finite-dimensional rational g-module .", "tokens": ["thus", ",", "the", "space", "h", "0", "is", "a", "finite", "-", "dimensional", "rational", "g", "-", "module", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the space h 0", "start": 7, "end": 20, "i_start": 2, "i_end": 5}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 6, "i_end": 6}}], "id": 2981}, {"sent": "a function that generates pseudorandom strings from shorter but truly random seeds is known as a pseudorandom generator .", "tokens": ["a", "function", "that", "generates", "pseudorandom", "strings", "from", "shorter", "but", "truly", "random", "seeds", "is", "known", "as", "a", "pseudorandom", "generator", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "a function that generates pseudorandom strings from shorter but truly random seeds", "start": 0, "end": 82, "i_start": 0, "i_end": 11}, "verb": {"text": "is known", "start": 83, "end": 91, "i_start": 12, "i_end": 13}}, {"character": {"text": "function", "start": 2, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "generates", "start": 16, "end": 25, "i_start": 3, "i_end": 3}}], "id": 2982}, {"sent": "the auc for the whole system is the average over all users .", "tokens": ["the", "auc", "for", "the", "whole", "system", "is", "the", "average", "over", "all", "users", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the auc for the whole system", "start": 0, "end": 28, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 6, "i_end": 6}}], "id": 2983}, {"sent": "for the spectral program , we used quartz lamp dome flats to correct for pixel sensitivity .", "tokens": ["for", "the", "spectral", "program", ",", "we", "used", "quartz", "lamp", "dome", "flats", "to", "correct", "for", "pixel", "sensitivity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 27, "end": 29, "i_start": 5, "i_end": 5}, "verb": {"text": "used", "start": 30, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 27, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "used", "start": 30, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 27, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "correct", "start": 61, "end": 68, "i_start": 12, "i_end": 12}}, {"character": {"text": "pixel", "start": 73, "end": 78, "i_start": 14, "i_end": 14}, "action": {"text": "sensitivity", "start": 79, "end": 90, "i_start": 15, "i_end": 15}}], "id": 2984}, {"sent": "furthermore , while solutions with binary and ternary precisions prove effective for smaller networks with small datasets , they often lead to unacceptable accuracy loss on large datasets such as imagenet .", "tokens": ["furthermore", ",", "while", "solutions", "with", "binary", "and", "ternary", "precisions", "prove", "effective", "for", "smaller", "networks", "with", "small", "datasets", ",", "they", "often", "lead", "to", "unacceptable", "accuracy", "loss", "on", "large", "datasets", "such", "as", "imagenet", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "they", "start": 124, "end": 128, "i_start": 18, "i_end": 18}, "verb": {"text": "lead", "start": 135, "end": 139, "i_start": 20, "i_end": 20}}, {"character": {"text": "solutions", "start": 20, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "effective", "start": 71, "end": 80, "i_start": 10, "i_end": 10}}, {"character": {"text": "solutions", "start": 20, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "lead", "start": 135, "end": 139, "i_start": 20, "i_end": 20}}], "id": 2985}, {"sent": "deep neural networks have been shown to be vulnerable to adversarial examples .", "tokens": ["deep", "neural", "networks", "have", "been", "shown", "to", "be", "vulnerable", "to", "adversarial", "examples", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been shown", "start": 21, "end": 36, "i_start": 3, "i_end": 5}}], "id": 2986}, {"sent": "in this paper , we analyze the interactions of matter with gravity in such models .", "tokens": ["in", "this", "paper", ",", "we", "analyze", "the", "interactions", "of", "matter", "with", "gravity", "in", "such", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "analyze", "start": 19, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "analyze", "start": 19, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "matter", "start": 47, "end": 53, "i_start": 9, "i_end": 9}, "action": {"text": "interactions", "start": 31, "end": 43, "i_start": 7, "i_end": 7}}], "id": 2987}, {"sent": "recent studies have mainly considered local models in f-theory model building .", "tokens": ["recent", "studies", "have", "mainly", "considered", "local", "models", "in", "f", "-", "theory", "model", "building", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent studies", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "considered", "start": 27, "end": 37, "i_start": 4, "i_end": 4}}, {"subject": {"text": "recent studies", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "have", "start": 15, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "studies", "start": 7, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "considered", "start": 27, "end": 37, "i_start": 4, "i_end": 4}}], "id": 2988}, {"sent": "it may be used to speed-up the transport of trapped-ion qubits in scalable quantum information processing .", "tokens": ["it", "may", "be", "used", "to", "speed", "-", "up", "the", "transport", "of", "trapped", "-", "ion", "qubits", "in", "scalable", "quantum", "information", "processing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "may be used", "start": 3, "end": 14, "i_start": 1, "i_end": 3}}], "id": 2989}, {"sent": "when the mass parameters of the puncture are set to zero , x is nilpotent , and the orbit is called a nilpotent orbit .", "tokens": ["when", "the", "mass", "parameters", "of", "the", "puncture", "are", "set", "to", "zero", ",", "x", "is", "nilpotent", ",", "and", "the", "orbit", "is", "called", "a", "nilpotent", "orbit", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the orbit", "start": 80, "end": 89, "i_start": 17, "i_end": 18}, "verb": {"text": "is", "start": 61, "end": 63, "i_start": 13, "i_end": 13}}, {"subject": {"text": "the orbit", "start": 80, "end": 89, "i_start": 17, "i_end": 18}, "verb": {"text": "called", "start": 93, "end": 99, "i_start": 20, "i_end": 20}}], "id": 2990}, {"sent": "the restriction of the map \u03c6n is an algebraic isomorphism .", "tokens": ["the", "restriction", "of", "the", "map", "\u03c6n", "is", "an", "algebraic", "isomorphism", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the restriction of the map \u03c6n", "start": 0, "end": 29, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 6, "i_end": 6}}], "id": 2991}, {"sent": "for parameterization , we will implement the em algorithm to the arhmm .", "tokens": ["for", "parameterization", ",", "we", "will", "implement", "the", "em", "algorithm", "to", "the", "arhmm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 23, "end": 25, "i_start": 3, "i_end": 3}, "verb": {"text": "will implement", "start": 26, "end": 40, "i_start": 4, "i_end": 5}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "implement", "start": 31, "end": 40, "i_start": 5, "i_end": 5}}], "id": 2992}, {"sent": "in single-cell experiments , it was consistently observed that the mrna decays substantially faster relative to its protein counterpart .", "tokens": ["in", "single", "-", "cell", "experiments", ",", "it", "was", "consistently", "observed", "that", "the", "mrna", "decays", "substantially", "faster", "relative", "to", "its", "protein", "counterpart", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the mrna", "start": 63, "end": 71, "i_start": 11, "i_end": 12}, "verb": {"text": "observed", "start": 49, "end": 57, "i_start": 9, "i_end": 9}}, {"subject": {"text": "it", "start": 29, "end": 31, "i_start": 6, "i_end": 6}, "verb": {"text": "was", "start": 32, "end": 35, "i_start": 7, "i_end": 7}}, {"subject": {"text": "it", "start": 29, "end": 31, "i_start": 6, "i_end": 6}, "verb": {"text": "decays", "start": 72, "end": 78, "i_start": 13, "i_end": 13}}], "id": 2993}, {"sent": "in , the authors performed a similar analysis to derive the limits on lrf mediated by vector and non-vector neutral bosons assuming one mass scale dominance .", "tokens": ["in", ",", "the", "authors", "performed", "a", "similar", "analysis", "to", "derive", "the", "limits", "on", "lrf", "mediated", "by", "vector", "and", "non", "-", "vector", "neutral", "bosons", "assuming", "one", "mass", "scale", "dominance", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 5, "end": 16, "i_start": 2, "i_end": 3}, "verb": {"text": "performed", "start": 17, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "bosons", "start": 116, "end": 122, "i_start": 22, "i_end": 22}, "action": {"text": "mediated", "start": 74, "end": 82, "i_start": 14, "i_end": 14}}, {"character": {"text": "bosons", "start": 116, "end": 122, "i_start": 22, "i_end": 22}, "action": {"text": "neutral", "start": 108, "end": 115, "i_start": 21, "i_end": 21}}], "id": 2994}, {"sent": "deep convolutional neural networks have made significant breakthroughs in many visual understanding tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "significant", "breakthroughs", "in", "many", "visual", "understanding", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "breakthroughs", "start": 57, "end": 70, "i_start": 7, "i_end": 7}}], "id": 2995}, {"sent": "convolutional neural networks have achieved remarkable success in many computer vision domains such as classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "remarkable", "success", "in", "many", "computer", "vision", "domains", "such", "as", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 6, "i_end": 6}}], "id": 2996}, {"sent": "generative adversarial nets are widely applied in generative models and have outstanding performance .", "tokens": ["generative", "adversarial", "nets", "are", "widely", "applied", "in", "generative", "models", "and", "have", "outstanding", "performance", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial nets", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "applied", "start": 39, "end": 46, "i_start": 5, "i_end": 5}}, {"subject": {"text": "generative adversarial nets", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 28, "end": 31, "i_start": 3, "i_end": 3}}, {"subject": {"text": "generative adversarial nets", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 72, "end": 76, "i_start": 10, "i_end": 10}}, {"character": {"text": "nets", "start": 23, "end": 27, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 89, "end": 100, "i_start": 12, "i_end": 12}}], "id": 2997}, {"sent": "furthermore , direct numerical simulation could be employed to verify studies on the critical wave number k c at fixed ca , such as the prior work of miranda and widom .", "tokens": ["furthermore", ",", "direct", "numerical", "simulation", "could", "be", "employed", "to", "verify", "studies", "on", "the", "critical", "wave", "number", "k", "c", "at", "fixed", "ca", ",", "such", "as", "the", "prior", "work", "of", "miranda", "and", "widom", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "direct numerical simulation", "start": 14, "end": 41, "i_start": 2, "i_end": 4}, "verb": {"text": "could be employed", "start": 42, "end": 59, "i_start": 5, "i_end": 7}}, {"character": {"text": "simulation", "start": 31, "end": 41, "i_start": 4, "i_end": 4}, "action": {"text": "verify", "start": 63, "end": 69, "i_start": 9, "i_end": 9}}, {"character": {"text": "miranda", "start": 150, "end": 157, "i_start": 28, "i_end": 28}, "action": {"text": "work", "start": 142, "end": 146, "i_start": 26, "i_end": 26}}, {"character": {"text": "widom", "start": 162, "end": 167, "i_start": 30, "i_end": 30}, "action": {"text": "work", "start": 142, "end": 146, "i_start": 26, "i_end": 26}}], "id": 2998}, {"sent": "we also have the closed symmetric monoidal category gz of s g -modules .", "tokens": ["we", "also", "have", "the", "closed", "symmetric", "monoidal", "category", "gz", "of", "s", "g", "-modules", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "have", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}], "id": 2999}, {"sent": "later we show that the formulas are the same by showing that the contribution of each column is the same .", "tokens": ["later", "we", "show", "that", "the", "formulas", "are", "the", "same", "by", "showing", "that", "the", "contribution", "of", "each", "column", "is", "the", "same", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 6, "end": 8, "i_start": 1, "i_end": 1}, "verb": {"text": "show", "start": 9, "end": 13, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 6, "end": 8, "i_start": 1, "i_end": 1}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 9, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "showing", "start": 48, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "column", "start": 86, "end": 92, "i_start": 16, "i_end": 16}, "action": {"text": "contribution", "start": 65, "end": 77, "i_start": 13, "i_end": 13}}], "id": 3000}, {"sent": "an algorithm for planarity testing of graphs .", "tokens": ["an", "algorithm", "for", "planarity", "testing", "of", "graphs", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3001}, {"sent": "in contrast , poisoning attacks target the training process by maliciously modifying part of training data to cause the trained model to misbehave on some test inputs .", "tokens": ["in", "contrast", ",", "poisoning", "attacks", "target", "the", "training", "process", "by", "maliciously", "modifying", "part", "of", "training", "data", "to", "cause", "the", "trained", "model", "to", "misbehave", "on", "some", "test", "inputs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "poisoning attacks", "start": 14, "end": 31, "i_start": 3, "i_end": 4}, "verb": {"text": "target", "start": 32, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "attacks", "start": 24, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "target", "start": 32, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "attacks", "start": 24, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "modifying", "start": 75, "end": 84, "i_start": 11, "i_end": 11}}, {"character": {"text": "attacks", "start": 24, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "cause", "start": 110, "end": 115, "i_start": 17, "i_end": 17}}, {"character": {"text": "model", "start": 128, "end": 133, "i_start": 20, "i_end": 20}, "action": {"text": "misbehave", "start": 137, "end": 146, "i_start": 22, "i_end": 22}}], "id": 3002}, {"sent": "the multicarrier cvqkd modulation has been introduced via the adaptive multicarrier quadrature division framework .", "tokens": ["the", "multicarrier", "cvqkd", "modulation", "has", "been", "introduced", "via", "the", "adaptive", "multicarrier", "quadrature", "division", "framework", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the multicarrier cvqkd modulation", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "has been introduced", "start": 34, "end": 53, "i_start": 4, "i_end": 6}}], "id": 3003}, {"sent": "the exchange-correlation interaction was treated in the generalized gradient approximation in the parameterization of perdew , burke , and ernzerhof .", "tokens": ["the", "exchange", "-", "correlation", "interaction", "was", "treated", "in", "the", "generalized", "gradient", "approximation", "in", "the", "parameterization", "of", "perdew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange-correlation interaction", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "was treated", "start": 37, "end": 48, "i_start": 5, "i_end": 6}}], "id": 3004}, {"sent": "as the transition to the spin-liquid state is approached , the spectral weight of the quasiparticle peak is decreased and the incoherent continuum at intermediate to high energies grows .", "tokens": ["as", "the", "transition", "to", "the", "spin", "-", "liquid", "state", "is", "approached", ",", "the", "spectral", "weight", "of", "the", "quasiparticle", "peak", "is", "decreased", "and", "the", "incoherent", "continuum", "at", "intermediate", "to", "high", "energies", "grows", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the spectral weight of the quasiparticle peak", "start": 59, "end": 104, "i_start": 12, "i_end": 18}, "verb": {"text": "is decreased", "start": 105, "end": 117, "i_start": 19, "i_end": 20}}, {"subject": {"text": "the incoherent continuum at intermediate to high energies", "start": 122, "end": 179, "i_start": 22, "i_end": 29}, "verb": {"text": "grows", "start": 180, "end": 185, "i_start": 30, "i_end": 30}}], "id": 3005}, {"sent": "region-based approaches with convolutional neural networks have achieved great success in object detection .", "tokens": ["region", "-", "based", "approaches", "with", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "region-based approaches with convolutional neural networks", "start": 0, "end": 58, "i_start": 0, "i_end": 7}, "verb": {"text": "have achieved", "start": 59, "end": 72, "i_start": 8, "i_end": 9}}, {"character": {"text": "approaches", "start": 13, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 64, "end": 72, "i_start": 9, "i_end": 9}}, {"character": {"text": "approaches", "start": 13, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 79, "end": 86, "i_start": 11, "i_end": 11}}], "id": 3006}, {"sent": "for the task of traffic scene recognition , we used the softmax loss layer from the matconvnet platform .", "tokens": ["for", "the", "task", "of", "traffic", "scene", "recognition", ",", "we", "used", "the", "softmax", "loss", "layer", "from", "the", "matconvnet", "platform", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 44, "end": 46, "i_start": 8, "i_end": 8}, "verb": {"text": "used", "start": 47, "end": 51, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 44, "end": 46, "i_start": 8, "i_end": 8}, "action": {"text": "used", "start": 47, "end": 51, "i_start": 9, "i_end": 9}}], "id": 3007}, {"sent": "the quark mass serves to regulate any would-be final state collinear singularities .", "tokens": ["the", "quark", "mass", "serves", "to", "regulate", "any", "would", "-", "be", "final", "state", "collinear", "singularities", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quark mass", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "serves", "start": 15, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "mass", "start": 10, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "regulate", "start": 25, "end": 33, "i_start": 5, "i_end": 5}}], "id": 3008}, {"sent": "these maps are usually trained using generative adversarial networks .", "tokens": ["these", "maps", "are", "usually", "trained", "using", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these maps", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "trained", "start": 23, "end": 30, "i_start": 4, "i_end": 4}}, {"subject": {"text": "these maps", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 11, "end": 14, "i_start": 2, "i_end": 2}}], "id": 3009}, {"sent": "more concretely , in these lectures we will describe recent progress on open string field theory .", "tokens": ["more", "concretely", ",", "in", "these", "lectures", "we", "will", "describe", "recent", "progress", "on", "open", "string", "field", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 36, "end": 38, "i_start": 6, "i_end": 6}, "verb": {"text": "will describe", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "we", "start": 36, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "describe", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}], "id": 3010}, {"sent": "in refthe successful implementation of this protocol was shown for the 144 km atmospheric channel between two canary islands .", "tokens": ["in", "refthe", "successful", "implementation", "of", "this", "protocol", "was", "shown", "for", "the", "144", "km", "atmospheric", "channel", "between", "two", "canary", "islands", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "refthe successful implementation of this protocol", "start": 3, "end": 52, "i_start": 1, "i_end": 6}, "verb": {"text": "was shown", "start": 53, "end": 62, "i_start": 7, "i_end": 8}}], "id": 3011}, {"sent": "specifically , both the anion and cation distributions become more structured and their densities very close to the solute become higher as the solute charge separation is increased .", "tokens": ["specifically", ",", "both", "the", "anion", "and", "cation", "distributions", "become", "more", "structured", "and", "their", "densities", "very", "close", "to", "the", "solute", "become", "higher", "as", "the", "solute", "charge", "separation", "is", "increased", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "both the anion and cation distributions", "start": 15, "end": 54, "i_start": 2, "i_end": 7}, "verb": {"text": "become", "start": 55, "end": 61, "i_start": 8, "i_end": 8}}, {"subject": {"text": "their densities very close to the solute", "start": 82, "end": 122, "i_start": 12, "i_end": 18}, "verb": {"text": "become", "start": 123, "end": 129, "i_start": 19, "i_end": 19}}], "id": 3012}, {"sent": "the integer k guaranteed by this theorem is called the characteristic of the ordinary polytope .", "tokens": ["the", "integer", "k", "guaranteed", "by", "this", "theorem", "is", "called", "the", "characteristic", "of", "the", "ordinary", "polytope", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the integer k guaranteed by this theorem", "start": 0, "end": 40, "i_start": 0, "i_end": 6}, "verb": {"text": "is called", "start": 41, "end": 50, "i_start": 7, "i_end": 8}}, {"character": {"text": "theorem", "start": 33, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "guaranteed", "start": 14, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3013}, {"sent": "in the present case , the negative signal corresponds to excited-state absorption and not the ground state bleaching .", "tokens": ["in", "the", "present", "case", ",", "the", "negative", "signal", "corresponds", "to", "excited", "-", "state", "absorption", "and", "not", "the", "ground", "state", "bleaching", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the negative signal", "start": 22, "end": 41, "i_start": 5, "i_end": 7}, "verb": {"text": "corresponds", "start": 42, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "signal", "start": 35, "end": 41, "i_start": 7, "i_end": 7}, "action": {"text": "negative", "start": 26, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "state", "start": 65, "end": 70, "i_start": 12, "i_end": 12}, "action": {"text": "absorption", "start": 71, "end": 81, "i_start": 13, "i_end": 13}}, {"character": {"text": "state", "start": 101, "end": 106, "i_start": 18, "i_end": 18}, "action": {"text": "bleaching", "start": 107, "end": 116, "i_start": 19, "i_end": 19}}], "id": 3014}, {"sent": "large-scale deep neural networks or dnns have made breakthroughs in many fields , such as image recognition .", "tokens": ["large", "-", "scale", "deep", "neural", "networks", "or", "dnns", "have", "made", "breakthroughs", "in", "many", "fields", ",", "such", "as", "image", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "large-scale deep neural networks or dnns", "start": 0, "end": 40, "i_start": 0, "i_end": 7}, "verb": {"text": "have made", "start": 41, "end": 50, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 24, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "breakthroughs", "start": 51, "end": 64, "i_start": 10, "i_end": 10}}], "id": 3015}, {"sent": "the success of convolutional neural networks dataset has propelled neural networks to achieve significant results in various visual recognition tasks .", "tokens": ["the", "success", "of", "convolutional", "neural", "networks", "dataset", "has", "propelled", "neural", "networks", "to", "achieve", "significant", "results", "in", "various", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the success of convolutional neural networks dataset", "start": 0, "end": 52, "i_start": 0, "i_end": 6}, "verb": {"text": "has propelled", "start": 53, "end": 66, "i_start": 7, "i_end": 8}}, {"character": {"text": "success", "start": 4, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "propelled", "start": 57, "end": 66, "i_start": 8, "i_end": 8}}, {"character": {"text": "dataset", "start": 45, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 4, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "networks", "start": 36, "end": 44, "i_start": 5, "i_end": 5}, "action": {"text": "achieve", "start": 86, "end": 93, "i_start": 12, "i_end": 12}}], "id": 3016}, {"sent": "the higgs is a scalar , so its natural mass scale is the planck scale , which is 1019 gev .", "tokens": ["the", "higgs", "is", "a", "scalar", ",", "so", "its", "natural", "mass", "scale", "is", "the", "planck", "scale", ",", "which", "is", "1019", "gev", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "its natural mass scale", "start": 27, "end": 49, "i_start": 7, "i_end": 10}, "verb": {"text": "is", "start": 50, "end": 52, "i_start": 11, "i_end": 11}}, {"subject": {"text": "its natural mass scale", "start": 27, "end": 49, "i_start": 7, "i_end": 10}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}], "id": 3017}, {"sent": "gu and rigazio applied stacked denoising auto-encoders to reduce adversarial perturbations .", "tokens": ["gu", "and", "rigazio", "applied", "stacked", "denoising", "auto", "-", "encoders", "to", "reduce", "adversarial", "perturbations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "gu and rigazio", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "applied", "start": 15, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "gu", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "applied", "start": 15, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "rigazio", "start": 7, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "applied", "start": 15, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "gu", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "reduce", "start": 58, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "rigazio", "start": 7, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "reduce", "start": 58, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "adversarial", "start": 65, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "perturbations", "start": 77, "end": 90, "i_start": 12, "i_end": 12}}], "id": 3018}, {"sent": "dnns have been remarkably successful in many applications including image recognition .", "tokens": ["dnns", "have", "been", "remarkably", "successful", "in", "many", "applications", "including", "image", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dnns", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "have been", "start": 5, "end": 14, "i_start": 1, "i_end": 2}}], "id": 3019}, {"sent": "chaque chemin optique comporte un tricoupleur , quatre ou cinq croisements de .", "tokens": ["chaque", "chemin", "optique", "comporte", "un", "tricoupleur", ",", "quatre", "ou", "cinq", "croisements", "de", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3020}, {"sent": "to demonstrate the multidimensional generalised strang-fix condition , we adapt the proof of .", "tokens": ["to", "demonstrate", "the", "multidimensional", "generalised", "strang", "-", "fix", "condition", ",", "we", "adapt", "the", "proof", "of", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 71, "end": 73, "i_start": 10, "i_end": 10}, "verb": {"text": "adapt", "start": 74, "end": 79, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 71, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "adapt", "start": 74, "end": 79, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 71, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "demonstrate", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}], "id": 3021}, {"sent": "quantum entanglement is a manifestly non-classical property of the quantum state of a composite system .", "tokens": ["quantum", "entanglement", "is", "a", "manifestly", "non", "-", "classical", "property", "of", "the", "quantum", "state", "of", "a", "composite", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum entanglement", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 2, "i_end": 2}}], "id": 3022}, {"sent": "semantic pixel-wise segmentation is an active topic of research , fuelled by challenging datasets .", "tokens": ["semantic", "pixel", "-", "wise", "segmentation", "is", "an", "active", "topic", "of", "research", ",", "fuelled", "by", "challenging", "datasets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "semantic pixel-wise segmentation", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 5, "i_end": 5}}, {"character": {"text": "datasets", "start": 89, "end": 97, "i_start": 15, "i_end": 15}, "action": {"text": "fuelled", "start": 66, "end": 73, "i_start": 12, "i_end": 12}}, {"character": {"text": "datasets", "start": 89, "end": 97, "i_start": 15, "i_end": 15}, "action": {"text": "challenging", "start": 77, "end": 88, "i_start": 14, "i_end": 14}}], "id": 3023}, {"sent": "convolutional neural networksrecently have made great success in computer vision tasks .", "tokens": ["convolutional", "neural", "networksrecently", "have", "made", "great", "success", "in", "computer", "vision", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "have made", "start": 38, "end": 47, "i_start": 3, "i_end": 4}}, {"character": {"text": "networksrecently", "start": 21, "end": 37, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 54, "end": 61, "i_start": 6, "i_end": 6}}], "id": 3024}, {"sent": "schlichenmaier a cohomology class containing a representing cocycle which is local is called a local cohomology class .", "tokens": ["schlichenmaier", "a", "cohomology", "class", "containing", "a", "representing", "cocycle", "which", "is", "local", "is", "called", "a", "local", "cohomology", "class", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "a cohomology class containing a representing cocycle which is local", "start": 15, "end": 82, "i_start": 1, "i_end": 10}, "verb": {"text": "is called", "start": 83, "end": 92, "i_start": 11, "i_end": 12}}, {"character": {"text": "class", "start": 28, "end": 33, "i_start": 3, "i_end": 3}, "action": {"text": "containing", "start": 34, "end": 44, "i_start": 4, "i_end": 4}}, {"character": {"text": "cocycle", "start": 60, "end": 67, "i_start": 7, "i_end": 7}, "action": {"text": "representing", "start": 47, "end": 59, "i_start": 6, "i_end": 6}}], "id": 3025}, {"sent": "we applied batch normalization function between each layer to normalize and better learn the distribution , improving the training efficiency .", "tokens": ["we", "applied", "batch", "normalization", "function", "between", "each", "layer", "to", "normalize", "and", "better", "learn", "the", "distribution", ",", "improving", "the", "training", "efficiency", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "applied", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "applied", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "applied", "start": 3, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "improving", "start": 108, "end": 117, "i_start": 16, "i_end": 16}}], "id": 3026}, {"sent": "this geometry is the area covered by the imaging , by the set of survey tiles , and not near tycho stars .", "tokens": ["this", "geometry", "is", "the", "area", "covered", "by", "the", "imaging", ",", "by", "the", "set", "of", "survey", "tiles", ",", "and", "not", "near", "tycho", "stars", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this geometry", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "set", "start": 58, "end": 61, "i_start": 12, "i_end": 12}, "action": {"text": "covered", "start": 26, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "tiles", "start": 72, "end": 77, "i_start": 15, "i_end": 15}, "action": {"text": "covered", "start": 26, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "survey", "start": 65, "end": 71, "i_start": 14, "i_end": 14}, "action": {"text": "covered", "start": 26, "end": 33, "i_start": 5, "i_end": 5}}], "id": 3027}, {"sent": "this discovery is essential from the viewpoint of realizing the fflo state in ultracold gases experiments .", "tokens": ["this", "discovery", "is", "essential", "from", "the", "viewpoint", "of", "realizing", "the", "fflo", "state", "in", "ultracold", "gases", "experiments", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this discovery", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 3028}, {"sent": "deep neural networks have become an extremely popular learning technique , with significant deployment in a wide variety of practical domains such as image classification .", "tokens": ["deep", "neural", "networks", "have", "become", "an", "extremely", "popular", "learning", "technique", ",", "with", "significant", "deployment", "in", "a", "wide", "variety", "of", "practical", "domains", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have become", "start": 21, "end": 32, "i_start": 3, "i_end": 4}}], "id": 3029}, {"sent": "for any hilbert space hwe denote the row and the column hilbert space on h by hr and hc , respectively .", "tokens": ["for", "any", "hilbert", "space", "h"], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 3030}, {"sent": "for the highest accretion rates the location of the emission has no impact on the bh spin-up , as the spin evolution is driven by the flow itself and the effects of radiation are negligible .", "tokens": ["for", "the", "highest", "accretion", "rates", "the", "location", "of", "the", "emission", "has", "no", "impact", "on", "the", "bh", "spin", "-", "up", ",", "as", "the", "spin", "evolution", "is", "driven", "by", "the", "flow", "itself", "and", "the", "effects", "of", "radiation", "are", "negligible", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "the location of the emission", "start": 32, "end": 60, "i_start": 5, "i_end": 9}, "verb": {"text": "are", "start": 175, "end": 178, "i_start": 35, "i_end": 35}}, {"subject": {"text": "the location of the emission", "start": 32, "end": 60, "i_start": 5, "i_end": 9}, "verb": {"text": "has", "start": 61, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "location", "start": 36, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "no impact", "start": 65, "end": 74, "i_start": 11, "i_end": 12}}, {"character": {"text": "flow", "start": 134, "end": 138, "i_start": 28, "i_end": 28}, "action": {"text": "driven", "start": 120, "end": 126, "i_start": 25, "i_end": 25}}], "id": 3031}, {"sent": "definition of differential graded s-bimodules .", "tokens": ["definition", "of", "differential", "graded", "s", "-", "bimodules", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3032}, {"sent": "in recent years , deep neural networks have developed advanced abilities in the feature extraction and function approximation .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "developed", "advanced", "abilities", "in", "the", "feature", "extraction", "and", "function", "approximation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have developed", "start": 39, "end": 53, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "developed", "start": 44, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "extraction", "start": 88, "end": 98, "i_start": 14, "i_end": 14}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "approximation", "start": 112, "end": 125, "i_start": 17, "i_end": 17}}], "id": 3033}, {"sent": "as a fundamental problem in the field of image processing , image restoration has been extensively studied in the past two decades .", "tokens": ["as", "a", "fundamental", "problem", "in", "the", "field", "of", "image", "processing", ",", "image", "restoration", "has", "been", "extensively", "studied", "in", "the", "past", "two", "decades", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "image restoration", "start": 60, "end": 77, "i_start": 11, "i_end": 12}, "verb": {"text": "studied", "start": 99, "end": 106, "i_start": 16, "i_end": 16}}, {"subject": {"text": "image restoration", "start": 60, "end": 77, "i_start": 11, "i_end": 12}, "verb": {"text": "has been", "start": 78, "end": 86, "i_start": 13, "i_end": 14}}], "id": 3034}, {"sent": "from the sequential case it is known that a postorder traversal , while not optimal for all instances , provides good results .", "tokens": ["from", "the", "sequential", "case", "it", "is", "known", "that", "a", "postorder", "traversal", ",", "while", "not", "optimal", "for", "all", "instances", ",", "provides", "good", "results", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 25, "end": 27, "i_start": 4, "i_end": 4}, "verb": {"text": "is known", "start": 28, "end": 36, "i_start": 5, "i_end": 6}}, {"subject": {"text": "a postorder traversal", "start": 42, "end": 63, "i_start": 8, "i_end": 10}, "verb": {"text": "provides", "start": 104, "end": 112, "i_start": 19, "i_end": 19}}, {"character": {"text": "traversal", "start": 54, "end": 63, "i_start": 10, "i_end": 10}, "action": {"text": "provides", "start": 104, "end": 112, "i_start": 19, "i_end": 19}}], "id": 3035}, {"sent": "in the case of the black hole system , this corresponds to the static solution .", "tokens": ["in", "the", "case", "of", "the", "black", "hole", "system", ",", "this", "corresponds", "to", "the", "static", "solution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 39, "end": 43, "i_start": 9, "i_end": 9}, "verb": {"text": "corresponds", "start": 44, "end": 55, "i_start": 10, "i_end": 10}}], "id": 3036}, {"sent": "therefore , 5 and 13 are adjacent to 43 , and so 43 has degree at least 2 , which is a contradiction .", "tokens": ["therefore", ",", "5", "and", "13", "are", "adjacent", "to", "43", ",", "and", "so", "43", "has", "degree", "at", "least", "2", ",", "which", "is", "a", "contradiction", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "5 and 13", "start": 12, "end": 20, "i_start": 2, "i_end": 4}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 5, "i_end": 5}}], "id": 3037}, {"sent": "to this end we use the classical argument suggesting to subtract from the solution a more regular function satisfying the boundary conditions .", "tokens": ["to", "this", "end", "we", "use", "the", "classical", "argument", "suggesting", "to", "subtract", "from", "the", "solution", "a", "more", "regular", "function", "satisfying", "the", "boundary", "conditions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 12, "end": 14, "i_start": 3, "i_end": 3}, "verb": {"text": "use", "start": 15, "end": 18, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 12, "end": 14, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 15, "end": 18, "i_start": 4, "i_end": 4}}, {"character": {"text": "argument", "start": 33, "end": 41, "i_start": 7, "i_end": 7}, "action": {"text": "suggesting", "start": 42, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 12, "end": 14, "i_start": 3, "i_end": 3}, "action": {"text": "subtract", "start": 56, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "function", "start": 98, "end": 106, "i_start": 17, "i_end": 17}, "action": {"text": "satisfying", "start": 107, "end": 117, "i_start": 18, "i_end": 18}}], "id": 3038}, {"sent": "our coarse-grained capsid model is motivated by the recent observation that purified simian virus 40 capsid proteins assemble around ssrna molecules in vitro to form capsids comprising 12 homopentamer subunits .", "tokens": ["our", "coarse", "-", "grained", "capsid", "model", "is", "motivated", "by", "the", "recent", "observation", "that", "purified", "simian", "virus", "40", "capsid", "proteins", "assemble", "around", "ssrna", "molecules", "in", "vitro", "to", "form", "capsids", "comprising", "12", "homopentamer", "subunits", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "our coarse-grained capsid model", "start": 0, "end": 31, "i_start": 0, "i_end": 5}, "verb": {"text": "is motivated", "start": 32, "end": 44, "i_start": 6, "i_end": 7}}, {"character": {"text": "observation", "start": 59, "end": 70, "i_start": 11, "i_end": 11}, "action": {"text": "motivated", "start": 35, "end": 44, "i_start": 7, "i_end": 7}}, {"character": {"text": "40 capsid proteins", "start": 98, "end": 116, "i_start": 16, "i_end": 18}, "action": {"text": "form", "start": 161, "end": 165, "i_start": 26, "i_end": 26}}], "id": 3039}, {"sent": "the magnet consists of two mirror-symmetric halves .", "tokens": ["the", "magnet", "consists", "of", "two", "mirror", "-", "symmetric", "halves", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the magnet", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}], "id": 3040}, {"sent": "now we proceed on to define smarandache pseudo left ideals .", "tokens": ["now", "we", "proceed", "on", "to", "define", "smarandache", "pseudo", "left", "ideals", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed on", "start": 7, "end": 17, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 3041}, {"sent": "a popular example is the molecular dynamics algorithm of lubachevsky and stillinger , 1990 , which simulates a dilute system of interacting particles , whose size grows linearly in time until jamming occurs .", "tokens": ["a", "popular", "example", "is", "the", "molecular", "dynamics", "algorithm", "of", "lubachevsky", "and", "stillinger", ",", "1990", ",", "which", "simulates", "a", "dilute", "system", "of", "interacting", "particles", ",", "whose", "size", "grows", "linearly", "in", "time", "until", "jamming", "occurs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a popular example", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithm", "start": 44, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "simulates", "start": 99, "end": 108, "i_start": 16, "i_end": 16}}, {"character": {"text": "particles", "start": 140, "end": 149, "i_start": 22, "i_end": 22}, "action": {"text": "interacting", "start": 128, "end": 139, "i_start": 21, "i_end": 21}}], "id": 3042}, {"sent": "in , the authors employed deep reinforcement learning to allocate cache , computing and communication resources for mec system in vehicle networks .", "tokens": ["in", ",", "the", "authors", "employed", "deep", "reinforcement", "learning", "to", "allocate", "cache", ",", "computing", "and", "communication", "resources", "for", "mec", "system", "in", "vehicle", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 5, "end": 16, "i_start": 2, "i_end": 3}, "verb": {"text": "employed", "start": 17, "end": 25, "i_start": 4, "i_end": 4}}], "id": 3043}, {"sent": "here , we compare physical and logical models trained by quantum annealing , simulated thermal annealing , and exact gradient .", "tokens": ["here", ",", "we", "compare", "physical", "and", "logical", "models", "trained", "by", "quantum", "annealing", ",", "simulated", "thermal", "annealing", ",", "and", "exact", "gradient", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "compare", "start": 10, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "compare", "start": 10, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "annealing", "start": 65, "end": 74, "i_start": 11, "i_end": 11}, "action": {"text": "trained", "start": 46, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "quantum", "start": 57, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "trained", "start": 46, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "annealing", "start": 95, "end": 104, "i_start": 15, "i_end": 15}, "action": {"text": "trained", "start": 46, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "thermal", "start": 87, "end": 94, "i_start": 14, "i_end": 14}, "action": {"text": "trained", "start": 46, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "gradient", "start": 117, "end": 125, "i_start": 19, "i_end": 19}, "action": {"text": "trained", "start": 46, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "exact", "start": 111, "end": 116, "i_start": 18, "i_end": 18}, "action": {"text": "trained", "start": 46, "end": 53, "i_start": 8, "i_end": 8}}], "id": 3044}, {"sent": "remember that the lagrangian is a \u03c4 dependent volterra series that will be treated as a distribution .", "tokens": ["remember", "that", "the", "lagrangian", "is", "a", "\u03c4", "dependent", "volterra", "series", "that", "will", "be", "treated", "as", "a", "distribution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "series", "start": 55, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "dependent", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}], "id": 3045}, {"sent": "we check all the analytical results against the numerical results obtained from packages fiesta .", "tokens": ["we", "check", "all", "the", "analytical", "results", "against", "the", "numerical", "results", "obtained", "from", "packages", "fiesta", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "check", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "check", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3046}, {"sent": "thistlethwaite gave an expansion of the jones polynomial v l in terms of spanning trees t of g .", "tokens": ["thistlethwaite", "gave", "an", "expansion", "of", "the", "jones", "polynomial", "v", "l", "in", "terms", "of", "spanning", "trees", "t", "of", "g", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "thistlethwaite", "start": 0, "end": 14, "i_start": 0, "i_end": 0}, "verb": {"text": "gave", "start": 15, "end": 19, "i_start": 1, "i_end": 1}}, {"character": {"text": "thistlethwaite", "start": 0, "end": 14, "i_start": 0, "i_end": 0}, "action": {"text": "expansion", "start": 23, "end": 32, "i_start": 3, "i_end": 3}}], "id": 3047}, {"sent": "the second inverted arrow is on the opposite boundary to that of the first , but not directly opposite to it .", "tokens": ["the", "second", "inverted", "arrow", "is", "on", "the", "opposite", "boundary", "to", "that", "of", "the", "first", ",", "but", "not", "directly", "opposite", "to", "it", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the second inverted arrow", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 4, "i_end": 4}}], "id": 3048}, {"sent": "this invariance is a consequence of the invariance of the differential forms ea etc .", "tokens": ["this", "invariance", "is", "a", "consequence", "of", "the", "invariance", "of", "the", "differential", "forms", "ea", "etc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this invariance", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3049}, {"sent": "vaughn , regularization dependence of running couplings in softly broken supersymmetry , phys .", "tokens": ["vaughn", ",", "regularization", "dependence", "of", "running", "couplings", "in", "softly", "broken", "supersymmetry", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "couplings", "start": 46, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "dependence", "start": 24, "end": 34, "i_start": 3, "i_end": 3}}], "id": 3050}, {"sent": "zamolodchikov , expectation values of descendent fields in the sine-gordon model , nucl .", "tokens": ["zamolodchikov", ",", "expectation", "values", "of", "descendent", "fields", "in", "the", "sine", "-", "gordon", "model", ",", "nucl", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "fields", "start": 49, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "descendent", "start": 38, "end": 48, "i_start": 5, "i_end": 5}}], "id": 3051}, {"sent": "the solid curve is the result of the curve-fitting analysis .", "tokens": ["the", "solid", "curve", "is", "the", "result", "of", "the", "curve", "-", "fitting", "analysis", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the solid curve", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 3052}, {"sent": "com spacetimes admitting appropriate spatial homothetic killing vectors are called spatially homothetic spacetimes .", "tokens": ["com", "spacetimes", "admitting", "appropriate", "spatial", "homothetic", "killing", "vectors", "are", "called", "spatially", "homothetic", "spacetimes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "com spacetimes admitting appropriate spatial homothetic killing vectors", "start": 0, "end": 71, "i_start": 0, "i_end": 7}, "verb": {"text": "are called", "start": 72, "end": 82, "i_start": 8, "i_end": 9}}], "id": 3053}, {"sent": "we pretrain word embeddings of 300 dimensions on the whole corpus using word2vec .", "tokens": ["we", "pretrain", "word", "embeddings", "of", "300", "dimensions", "on", "the", "whole", "corpus", "using", "word2vec", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "pretrain", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "pretrain", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 3054}, {"sent": "the terminal t is the lexical head of its constituent .", "tokens": ["the", "terminal", "t", "is", "the", "lexical", "head", "of", "its", "constituent", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the terminal t", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "t", "start": 13, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "head", "start": 30, "end": 34, "i_start": 6, "i_end": 6}}], "id": 3055}, {"sent": "recently , deep learning technology has boosted automatic speech recognition performance significantly .", "tokens": ["recently", ",", "deep", "learning", "technology", "has", "boosted", "automatic", "speech", "recognition", "performance", "significantly", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning technology", "start": 11, "end": 35, "i_start": 2, "i_end": 4}, "verb": {"text": "has boosted", "start": 36, "end": 47, "i_start": 5, "i_end": 6}}, {"character": {"text": "technology", "start": 25, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "boosted", "start": 40, "end": 47, "i_start": 6, "i_end": 6}}], "id": 3056}, {"sent": "in prolog if then else is a built-in defined internally by the above two rules .", "tokens": ["in", "prolog", "if", "then", "else", "is", "a", "built", "-", "in", "defined", "internally", "by", "the", "above", "two", "rules", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "two rules", "start": 69, "end": 78, "i_start": 15, "i_end": 16}, "action": {"text": "defined", "start": 37, "end": 44, "i_start": 10, "i_end": 10}}], "id": 3057}, {"sent": "of the cycle and the forewing in its downstrokeis responsible for the large .", "tokens": ["of", "the", "cycle", "and", "the", "forewing", "in", "its", "downstroke"], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3058}, {"sent": "the apparatus is a non-interacting bose gas , which has an easily tractable phase transition .", "tokens": ["the", "apparatus", "is", "a", "non", "-", "interacting", "bose", "gas", ",", "which", "has", "an", "easily", "tractable", "phase", "transition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the apparatus", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "gas", "start": 40, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "-interacting", "start": 22, "end": 34, "i_start": 5, "i_end": 6}}, {"character": {"text": "gas", "start": 40, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "transition", "start": 82, "end": 92, "i_start": 16, "i_end": 16}}], "id": 3059}, {"sent": "the seiberg-witten map is a crucial part in showing the background independence of string theory .", "tokens": ["the", "seiberg", "-", "witten", "map", "is", "a", "crucial", "part", "in", "showing", "the", "background", "independence", "of", "string", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the seiberg-witten map", "start": 0, "end": 22, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "theory", "start": 90, "end": 96, "i_start": 16, "i_end": 16}, "action": {"text": "-witten map is a crucial part in showing the background independence", "start": 11, "end": 79, "i_start": 2, "i_end": 13}}], "id": 3060}, {"sent": "recent works have studied the convergence of specific learning algorithms .", "tokens": ["recent", "works", "have", "studied", "the", "convergence", "of", "specific", "learning", "algorithms", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent works", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "have studied", "start": 13, "end": 25, "i_start": 2, "i_end": 3}}, {"character": {"text": "works", "start": 7, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "studied", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}], "id": 3061}, {"sent": "deep neural networks have shown improvement in state-of-the-art in different tasks , such as image classification .", "tokens": ["deep", "neural", "networks", "have", "shown", "improvement", "in", "state", "-", "of", "-", "the", "-", "art", "in", "different", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improvement", "start": 32, "end": 43, "i_start": 5, "i_end": 5}}], "id": 3062}, {"sent": "as indicated in , the process lifetime of many parallel jobs , in particular , jobs to data centers , tends to be non-exponential .", "tokens": ["as", "indicated", "in", ",", "the", "process", "lifetime", "of", "many", "parallel", "jobs", ",", "in", "particular", ",", "jobs", "to", "data", "centers", ",", "tends", "to", "be", "non", "-", "exponential", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3063}, {"sent": "we can thereby conclude results for the integration errors .", "tokens": ["we", "can", "thereby", "conclude", "results", "for", "the", "integration", "errors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "conclude", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "can", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "conclude", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 3064}, {"sent": "deep neural networks have achieved considerable improvements in learning tasks with voluminous labeled data .", "tokens": ["deep", "neural", "networks", "have", "achieved", "considerable", "improvements", "in", "learning", "tasks", "with", "voluminous", "labeled", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improvements", "start": 48, "end": 60, "i_start": 6, "i_end": 6}}], "id": 3065}, {"sent": "this is the main result of the present paper .", "tokens": ["this", "is", "the", "main", "result", "of", "the", "present", "paper", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3066}, {"sent": "existence of optimal policies for static and a class of sequential dynamic teams has been studied recently in .", "tokens": ["existence", "of", "optimal", "policies", "for", "static", "and", "a", "class", "of", "sequential", "dynamic", "teams", "has", "been", "studied", "recently", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "existence of optimal policies for static and a class of sequential dynamic teams", "start": 0, "end": 80, "i_start": 0, "i_end": 12}, "verb": {"text": "has been studied", "start": 81, "end": 97, "i_start": 13, "i_end": 15}}], "id": 3067}, {"sent": "the kernel k-means algorithm performs clustering in feature space using mean functions as representatives of the clusters .", "tokens": ["the", "kernel", "k", "-", "means", "algorithm", "performs", "clustering", "in", "feature", "space", "using", "mean", "functions", "as", "representatives", "of", "the", "clusters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the kernel k-means algorithm", "start": 0, "end": 28, "i_start": 0, "i_end": 5}, "verb": {"text": "performs", "start": 29, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "algorithm", "start": 19, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "performs", "start": 29, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "algorithm", "start": 19, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "using", "start": 66, "end": 71, "i_start": 11, "i_end": 11}}, {"character": {"text": "functions", "start": 77, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "representatives", "start": 90, "end": 105, "i_start": 15, "i_end": 15}}], "id": 3068}, {"sent": "in addition , swipt performance is impacted by the low energy sensitivity and rf-to-direct current rectification efficiency .", "tokens": ["in", "addition", ",", "swipt", "performance", "is", "impacted", "by", "the", "low", "energy", "sensitivity", "and", "rf", "-", "to", "-", "direct", "current", "rectification", "efficiency", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "swipt performance", "start": 14, "end": 31, "i_start": 3, "i_end": 4}, "verb": {"text": "is impacted", "start": 32, "end": 43, "i_start": 5, "i_end": 6}}, {"character": {"text": "sensitivity", "start": 62, "end": 73, "i_start": 11, "i_end": 11}, "action": {"text": "impacted", "start": 35, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "efficiency", "start": 113, "end": 123, "i_start": 20, "i_end": 20}, "action": {"text": "impacted", "start": 35, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "current", "start": 91, "end": 98, "i_start": 18, "i_end": 18}, "action": {"text": "impacted", "start": 35, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "swipt", "start": 14, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 20, "end": 31, "i_start": 4, "i_end": 4}}], "id": 3069}, {"sent": "the analytical and the numerical solutions of the fractional diffusion equation are studied in .", "tokens": ["the", "analytical", "and", "the", "numerical", "solutions", "of", "the", "fractional", "diffusion", "equation", "are", "studied", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the analytical and the numerical solutions of the fractional diffusion equation", "start": 0, "end": 79, "i_start": 0, "i_end": 10}, "verb": {"text": "are studied", "start": 80, "end": 91, "i_start": 11, "i_end": 12}}], "id": 3070}, {"sent": "more precisely such a lagrangian is a function of mappings from m into gn 1 and derivatives of such mappings .", "tokens": ["more", "precisely", "such", "a", "lagrangian", "is", "a", "function", "of", "mappings", "from", "m", "into", "gn", "1", "and", "derivatives", "of", "such", "mappings", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "more precisely such a lagrangian", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 5, "i_end": 5}}, {"character": {"text": "mappings", "start": 50, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "function", "start": 38, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "m", "start": 64, "end": 65, "i_start": 11, "i_end": 11}, "action": {"text": "function", "start": 38, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "gn 1", "start": 71, "end": 75, "i_start": 13, "i_end": 14}, "action": {"text": "function", "start": 38, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "derivatives", "start": 80, "end": 91, "i_start": 16, "i_end": 16}, "action": {"text": "function", "start": 38, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "mappings", "start": 50, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "function", "start": 38, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "m", "start": 64, "end": 65, "i_start": 11, "i_end": 11}, "action": {"text": "function", "start": 38, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "gn 1", "start": 71, "end": 75, "i_start": 13, "i_end": 14}, "action": {"text": "function", "start": 38, "end": 46, "i_start": 7, "i_end": 7}}], "id": 3071}, {"sent": "harvesting energy from the environment has emerged as a promising solution for prolonging the lifetime of energy-constrained devices in wireless communication systems .", "tokens": ["harvesting", "energy", "from", "the", "environment", "has", "emerged", "as", "a", "promising", "solution", "for", "prolonging", "the", "lifetime", "of", "energy", "-", "constrained", "devices", "in", "wireless", "communication", "systems", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "energy from the environment", "start": 11, "end": 38, "i_start": 1, "i_end": 4}, "verb": {"text": "has emerged", "start": 39, "end": 50, "i_start": 5, "i_end": 6}}, {"character": {"text": "harvesting", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "emerged", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}, {"character": {"text": "energy", "start": 106, "end": 112, "i_start": 16, "i_end": 16}, "action": {"text": "constrained", "start": 113, "end": 124, "i_start": 18, "i_end": 18}}], "id": 3072}, {"sent": "quantum entanglement , enabling states with correlations that have no classical analogue , is one of the central concepts differentiating quantum information from classical information .", "tokens": ["quantum", "entanglement", ",", "enabling", "states", "with", "correlations", "that", "have", "no", "classical", "analogue", ",", "is", "one", "of", "the", "central", "concepts", "differentiating", "quantum", "information", "from", "classical", "information", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "quantum entanglement , enabling states with correlations that have no classical analogue", "start": 0, "end": 88, "i_start": 0, "i_end": 11}, "verb": {"text": "is", "start": 91, "end": 93, "i_start": 13, "i_end": 13}}, {"character": {"text": "entanglement", "start": 8, "end": 20, "i_start": 1, "i_end": 1}, "action": {"text": "enabling", "start": 23, "end": 31, "i_start": 3, "i_end": 3}}, {"character": {"text": "states", "start": 32, "end": 38, "i_start": 4, "i_end": 4}, "action": {"text": "correlations", "start": 44, "end": 56, "i_start": 6, "i_end": 6}}, {"character": {"text": "states", "start": 32, "end": 38, "i_start": 4, "i_end": 4}, "action": {"text": "have no", "start": 62, "end": 69, "i_start": 8, "i_end": 9}}], "id": 3073}, {"sent": "motivated by the demand of high data rate transmission and improving the connectivity of the network , the multiple antenna systems with security concern are considered by several authors .", "tokens": ["motivated", "by", "the", "demand", "of", "high", "data", "rate", "transmission", "and", "improving", "the", "connectivity", "of", "the", "network", ",", "the", "multiple", "antenna", "systems", "with", "security", "concern", "are", "considered", "by", "several", "authors", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "the multiple antenna systems with security concern", "start": 103, "end": 153, "i_start": 17, "i_end": 23}, "verb": {"text": "are considered", "start": 154, "end": 168, "i_start": 24, "i_end": 25}}, {"character": {"text": "several", "start": 172, "end": 179, "i_start": 27, "i_end": 27}, "action": {"text": "considered", "start": 158, "end": 168, "i_start": 25, "i_end": 25}}, {"character": {"text": "systems", "start": 124, "end": 131, "i_start": 20, "i_end": 20}, "action": {"text": "concern", "start": 146, "end": 153, "i_start": 23, "i_end": 23}}, {"character": {"text": "demand", "start": 17, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "motivated", "start": 0, "end": 9, "i_start": 0, "i_end": 0}}, {"character": {"text": "data", "start": 32, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "motivated", "start": 0, "end": 9, "i_start": 0, "i_end": 0}}, {"character": {"text": "improving", "start": 59, "end": 68, "i_start": 10, "i_end": 10}, "action": {"text": "motivated", "start": 0, "end": 9, "i_start": 0, "i_end": 0}}], "id": 3074}, {"sent": "relaxing this restriction , non-pt -symmetric complex potentials with all-real spectra have been introduced .", "tokens": ["relaxing", "this", "restriction", ",", "non", "-", "pt", "-symmetric", "complex", "potentials", "with", "all", "-", "real", "spectra", "have", "been", "introduced", "."], "score": [1, 0, 0, 0, 1], "labels": [{"subject": {"text": "relaxing this restriction", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "have been introduced", "start": 87, "end": 107, "i_start": 15, "i_end": 17}}, {"character": {"text": "potentials", "start": 54, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "have", "start": 87, "end": 91, "i_start": 15, "i_end": 15}}], "id": 3075}, {"sent": "the quantity \u03c3 is called shear of the null congruence .", "tokens": ["the", "quantity", "\u03c3", "is", "called", "shear", "of", "the", "null", "congruence", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quantity \u03c3", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 15, "end": 24, "i_start": 3, "i_end": 4}}], "id": 3076}, {"sent": "deep convolutional neural networks have led to major breakthroughs in many computer vision tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "led", "to", "major", "breakthroughs", "in", "many", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have led", "start": 35, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "led", "start": 40, "end": 43, "i_start": 5, "i_end": 5}}], "id": 3077}, {"sent": "recently , models for learning latent representation of vertices of a static networks have become very popular .", "tokens": ["recently", ",", "models", "for", "learning", "latent", "representation", "of", "vertices", "of", "a", "static", "networks", "have", "become", "very", "popular", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "models for learning latent representation of vertices of a static networks", "start": 11, "end": 85, "i_start": 2, "i_end": 12}, "verb": {"text": "have become", "start": 86, "end": 97, "i_start": 13, "i_end": 14}}], "id": 3078}, {"sent": "its collapse is a direct consequence of complementarity .", "tokens": ["its", "collapse", "is", "a", "direct", "consequence", "of", "complementarity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "its collapse", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 3079}, {"sent": "the interested reader should refer to for a thorough account on the subject of stability of functional equations .", "tokens": ["the", "interested", "reader", "should", "refer", "to", "for", "a", "thorough", "account", "on", "the", "subject", "of", "stability", "of", "functional", "equations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the interested reader", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "should refer", "start": 22, "end": 34, "i_start": 3, "i_end": 4}}], "id": 3080}, {"sent": "specifically , the key performance indicator of 1 ms over-the-air latency has been proposed as one of the core 5g requirements by such standards bodies as the international telecommunication union .", "tokens": ["specifically", ",", "the", "key", "performance", "indicator", "of", "1", "ms", "over", "-", "the", "-", "air", "latency", "has", "been", "proposed", "as", "one", "of", "the", "core", "5", "g", "requirements", "by", "such", "standards", "bodies", "as", "the", "international", "telecommunication", "union", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "the key performance indicator of 1 ms over-the-air latency", "start": 15, "end": 73, "i_start": 2, "i_end": 14}, "verb": {"text": "has been proposed", "start": 74, "end": 91, "i_start": 15, "i_end": 17}}, {"character": {"text": "bodies", "start": 145, "end": 151, "i_start": 29, "i_end": 29}, "action": {"text": "proposed", "start": 83, "end": 91, "i_start": 17, "i_end": 17}}], "id": 3081}, {"sent": "convolutional neural networks have made great progress in various fields , such as object classification , detection and character recognition .", "tokens": ["convolutional", "neural", "networks", "have", "made", "great", "progress", "in", "various", "fields", ",", "such", "as", "object", "classification", ",", "detection", "and", "character", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have made", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}], "id": 3082}, {"sent": "by exploiting the strong field localization in plasmonic nanocavities , even single-molecule strong coupling has recently been achieved .", "tokens": ["by", "exploiting", "the", "strong", "field", "localization", "in", "plasmonic", "nanocavities", ",", "even", "single", "-", "molecule", "strong", "coupling", "has", "recently", "been", "achieved", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3083}, {"sent": "the weights of the viewpoint estimation head were initialized with xavier initialization .", "tokens": ["the", "weights", "of", "the", "viewpoint", "estimation", "head", "were", "initialized", "with", "xavier", "initialization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the weights of the viewpoint estimation head", "start": 0, "end": 44, "i_start": 0, "i_end": 6}, "verb": {"text": "were initialized", "start": 45, "end": 61, "i_start": 7, "i_end": 8}}], "id": 3084}, {"sent": "this lagrangian consists of two coupled sectors .", "tokens": ["this", "lagrangian", "consists", "of", "two", "coupled", "sectors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this lagrangian", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 16, "end": 24, "i_start": 2, "i_end": 2}}], "id": 3085}, {"sent": "note that checking the positive semidefiniteness of a given symmetric polynomial matrix is np-hard in general .", "tokens": ["note", "that", "checking", "the", "positive", "semidefiniteness", "of", "a", "given", "symmetric", "polynomial", "matrix", "is", "np", "-", "hard", "in", "general", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3086}, {"sent": "generative adversarial networks have recently become a prominent method to learn high-dimensional probability distributions .", "tokens": ["generative", "adversarial", "networks", "have", "recently", "become", "a", "prominent", "method", "to", "learn", "high", "-", "dimensional", "probability", "distributions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "become", "start": 46, "end": 52, "i_start": 5, "i_end": 5}}, {"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 32, "end": 36, "i_start": 3, "i_end": 3}}], "id": 3087}, {"sent": "furthermore , the coordinate descent algorithm can be employed to further improve the computational efficiency of solving .", "tokens": ["furthermore", ",", "the", "coordinate", "descent", "algorithm", "can", "be", "employed", "to", "further", "improve", "the", "computational", "efficiency", "of", "solving", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the coordinate descent algorithm", "start": 14, "end": 46, "i_start": 2, "i_end": 5}, "verb": {"text": "can be employed", "start": 47, "end": 62, "i_start": 6, "i_end": 8}}, {"character": {"text": "algorithm", "start": 37, "end": 46, "i_start": 5, "i_end": 5}, "action": {"text": "improve", "start": 74, "end": 81, "i_start": 11, "i_end": 11}}], "id": 3088}, {"sent": "deep neural networks have demonstrated success in many machine learning tasks , including image recognition , speech recognition , and even modelling mathematical learning , among many other domains .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "success", "in", "many", "machine", "learning", "tasks", ",", "including", "image", "recognition", ",", "speech", "recognition", ",", "and", "even", "modelling", "mathematical", "learning", ",", "among", "many", "other", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 39, "end": 46, "i_start": 5, "i_end": 5}}], "id": 3089}, {"sent": "the gabor features has been applied successfully in character and text recognition .", "tokens": ["the", "gabor", "features", "has", "been", "applied", "successfully", "in", "character", "and", "text", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the gabor features", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "has been applied", "start": 19, "end": 35, "i_start": 3, "i_end": 5}}], "id": 3090}, {"sent": "in recent years , deep neural networks have achieved great success in a variety of machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "achieved", "great", "success", "in", "a", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}], "id": 3091}, {"sent": "the electronelectron exchange and correlation functional was described with the perdew-burke-ernzerhof 22 parametrization of the generalized gradient approximation .", "tokens": ["the", "electronelectron", "exchange", "and", "correlation", "functional", "was", "described", "with", "the", "perdew", "-", "burke", "-", "ernzerhof", "22", "parametrization", "of", "the", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electronelectron exchange and correlation functional", "start": 0, "end": 56, "i_start": 0, "i_end": 5}, "verb": {"text": "was described", "start": 57, "end": 70, "i_start": 6, "i_end": 7}}], "id": 3092}, {"sent": "modified gauss bonnet theory as gravitational alternative for dark energy .", "tokens": ["modified", "gauss", "bonnet", "theory", "as", "gravitational", "alternative", "for", "dark", "energy", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3093}, {"sent": "deep neural networks , such as cnns , have recently achieved many successes in visual recognition tasks .", "tokens": ["deep", "neural", "networks", ",", "such", "as", "cnns", ",", "have", "recently", "achieved", "many", "successes", "in", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 52, "end": 60, "i_start": 10, "i_end": 10}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 38, "end": 42, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 52, "end": 60, "i_start": 10, "i_end": 10}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successes", "start": 66, "end": 75, "i_start": 12, "i_end": 12}}], "id": 3094}, {"sent": "neural networks have been proven effective in several domains such as image classification .", "tokens": ["neural", "networks", "have", "been", "proven", "effective", "in", "several", "domains", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have been proven", "start": 16, "end": 32, "i_start": 2, "i_end": 4}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "effective", "start": 33, "end": 42, "i_start": 5, "i_end": 5}}], "id": 3095}, {"sent": "the cosmological model is a \u03bbcdm model with small differences in the cosmological parameters adopted in sect .", "tokens": ["the", "cosmological", "model", "is", "a", "\u03bbcdm", "model", "with", "small", "differences", "in", "the", "cosmological", "parameters", "adopted", "in", "sect", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the cosmological model", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "sect", "start": 104, "end": 108, "i_start": 16, "i_end": 16}, "action": {"text": "adopted", "start": 93, "end": 100, "i_start": 14, "i_end": 14}}], "id": 3096}, {"sent": "generative adversarial networks are a related class of deep generative models that have successfully modelled complex nonlinear distributions .", "tokens": ["generative", "adversarial", "networks", "are", "a", "related", "class", "of", "deep", "generative", "models", "that", "have", "successfully", "modelled", "complex", "nonlinear", "distributions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 71, "end": 77, "i_start": 10, "i_end": 10}, "action": {"text": "modelled", "start": 101, "end": 109, "i_start": 14, "i_end": 14}}], "id": 3097}, {"sent": "there is no total density fluctuation in this ensemble .", "tokens": ["there", "is", "no", "total", "density", "fluctuation", "in", "this", "ensemble", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3098}, {"sent": "deep neural networks are powerful models that achieve state-of-the-art performance across several domains , such as bioinformatics .", "tokens": ["deep", "neural", "networks", "are", "powerful", "models", "that", "achieve", "state", "-", "of", "-", "the", "-", "art", "performance", "across", "several", "domains", ",", "such", "as", "bioinformatics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 34, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "achieve", "start": 46, "end": 53, "i_start": 7, "i_end": 7}}], "id": 3099}, {"sent": "the reduced hamiltonian , that we shall denote by h , is explicitly time dependent .", "tokens": ["the", "reduced", "hamiltonian", ",", "that", "we", "shall", "denote", "by", "h", ",", "is", "explicitly", "time", "dependent", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "the reduced hamiltonian", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 54, "end": 56, "i_start": 11, "i_end": 11}}, {"character": {"text": "hamiltonian", "start": 12, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "dependent", "start": 73, "end": 82, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "denote", "start": 40, "end": 46, "i_start": 7, "i_end": 7}}], "id": 3100}, {"sent": "so the number of quotients of l , the quotient complexity \u03baof l , is a natural measure of complexity for l .", "tokens": ["so", "the", "number", "of", "quotients", "of", "l", ",", "the", "quotient", "complexity", "\u03baof", "l", ",", "is", "a", "natural", "measure", "of", "complexity", "for", "l", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quotient complexity", "start": 34, "end": 57, "i_start": 8, "i_end": 10}, "verb": {"text": "\u03baof", "start": 58, "end": 61, "i_start": 11, "i_end": 11}}], "id": 3101}, {"sent": "now we proceed on to define smarandache semivector spaces .", "tokens": ["now", "we", "proceed", "on", "to", "define", "smarandache", "semivector", "spaces", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed on", "start": 7, "end": 17, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 3102}, {"sent": "convolutional neural networks have made great progress in various fields , such as object classification , detection and character recognition .", "tokens": ["convolutional", "neural", "networks", "have", "made", "great", "progress", "in", "various", "fields", ",", "such", "as", "object", "classification", ",", "detection", "and", "character", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have made", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}], "id": 3103}, {"sent": "over the past decade , deep neural networks has been a game changer in various areas of machine learning research , such as computer vision .", "tokens": ["over", "the", "past", "decade", ",", "deep", "neural", "networks", "has", "been", "a", "game", "changer", "in", "various", "areas", "of", "machine", "learning", "research", ",", "such", "as", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 23, "end": 43, "i_start": 5, "i_end": 7}, "verb": {"text": "has been", "start": 44, "end": 52, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 35, "end": 43, "i_start": 7, "i_end": 7}, "action": {"text": "changer", "start": 60, "end": 67, "i_start": 12, "i_end": 12}}], "id": 3104}, {"sent": "deep convolutional neural networks have achieved great success in various computer vision tasks , including object classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "various", "computer", "vision", "tasks", ",", "including", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}], "id": 3105}, {"sent": "here , a microwave source is used to directly drive the magnon mode , therefore , the magnomechanical coupling can be enhanced .", "tokens": ["here", ",", "a", "microwave", "source", "is", "used", "to", "directly", "drive", "the", "magnon", "mode", ",", "therefore", ",", "the", "magnomechanical", "coupling", "can", "be", "enhanced", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the magnomechanical coupling", "start": 82, "end": 110, "i_start": 16, "i_end": 18}, "verb": {"text": "can be enhanced", "start": 111, "end": 126, "i_start": 19, "i_end": 21}}, {"subject": {"text": "a microwave source", "start": 7, "end": 25, "i_start": 2, "i_end": 4}, "verb": {"text": "used", "start": 29, "end": 33, "i_start": 6, "i_end": 6}}], "id": 3106}, {"sent": "it would also be interesting in this context to extend our type iib analysis for the vacuum with 32 d9branes to the type iib vacuum with n d9-antid9brane pairs mentioned above .", "tokens": ["it", "would", "also", "be", "interesting", "in", "this", "context", "to", "extend", "our", "type", "iib", "analysis", "for", "the", "vacuum", "with", "32", "d9branes", "to", "the", "type", "iib", "vacuum", "with", "n", "d9", "-", "antid9brane", "pairs", "mentioned", "above", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "be", "start": 14, "end": 16, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "would", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3107}, {"sent": "our result agrees with the third law of thermodynamics .", "tokens": ["our", "result", "agrees", "with", "the", "third", "law", "of", "thermodynamics", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our result", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "agrees", "start": 11, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "result", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "agrees", "start": 11, "end": 17, "i_start": 2, "i_end": 2}}], "id": 3108}, {"sent": "magnetic or non-magnetic dopants , have been attempted to introduce long-range ferromagnetic orders in semiconductors .", "tokens": ["magnetic", "or", "non", "-", "magnetic", "dopants", ",", "have", "been", "attempted", "to", "introduce", "long", "-", "range", "ferromagnetic", "orders", "in", "semiconductors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "magnetic or non-magnetic dopants", "start": 0, "end": 32, "i_start": 0, "i_end": 5}, "verb": {"text": "have been attempted", "start": 35, "end": 54, "i_start": 7, "i_end": 9}}, {"character": {"text": "or", "start": 9, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "attempted", "start": 45, "end": 54, "i_start": 9, "i_end": 9}}, {"character": {"text": "or", "start": 9, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "introduce", "start": 58, "end": 67, "i_start": 11, "i_end": 11}}], "id": 3109}, {"sent": "these objects correspond to jets , clustered with the jet finding algorithm using the tracks assigned to the vertex as inputs , and to the associated missing transverse momentum , defined as the negative vector sum of the p t of those jets .", "tokens": ["these", "objects", "correspond", "to", "jets", ",", "clustered", "with", "the", "jet", "finding", "algorithm", "using", "the", "tracks", "assigned", "to", "the", "vertex", "as", "inputs", ",", "and", "to", "the", "associated", "missing", "transverse", "momentum", ",", "defined", "as", "the", "negative", "vector", "sum", "of", "the", "p", "t", "of", "those", "jets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these objects", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "correspond", "start": 14, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "algorithm", "start": 66, "end": 75, "i_start": 11, "i_end": 11}, "action": {"text": "finding", "start": 58, "end": 65, "i_start": 10, "i_end": 10}}, {"character": {"text": "algorithm", "start": 66, "end": 75, "i_start": 11, "i_end": 11}, "action": {"text": "using", "start": 76, "end": 81, "i_start": 12, "i_end": 12}}], "id": 3110}, {"sent": "as our baseline we use a ner model implemented in allennlp open-source library .", "tokens": ["as", "our", "baseline", "we", "use", "a", "ner", "model", "implemented", "in", "allennlp", "open", "-", "source", "library", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "use", "start": 19, "end": 22, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 19, "end": 22, "i_start": 4, "i_end": 4}}], "id": 3111}, {"sent": "differential privacy proposed by dwork et al gives a rigorous definition on data privacy and has been widely used .", "tokens": ["differential", "privacy", "proposed", "by", "dwork", "et", "al", "gives", "a", "rigorous", "definition", "on", "data", "privacy", "and", "has", "been", "widely", "used", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "differential privacy proposed by dwork et al", "start": 0, "end": 44, "i_start": 0, "i_end": 6}, "verb": {"text": "gives", "start": 45, "end": 50, "i_start": 7, "i_end": 7}}, {"subject": {"text": "differential privacy proposed by dwork et al", "start": 0, "end": 44, "i_start": 0, "i_end": 6}, "verb": {"text": "used", "start": 109, "end": 113, "i_start": 18, "i_end": 18}}, {"character": {"text": "privacy", "start": 13, "end": 20, "i_start": 1, "i_end": 1}, "action": {"text": "definition", "start": 62, "end": 72, "i_start": 10, "i_end": 10}}, {"character": {"text": "dwork", "start": 33, "end": 38, "i_start": 4, "i_end": 4}, "action": {"text": "proposed", "start": 21, "end": 29, "i_start": 2, "i_end": 2}}], "id": 3112}, {"sent": "the main difference with the situation in is that now k is not assumed to be connected .", "tokens": ["the", "main", "difference", "with", "the", "situation", "in", "is", "that", "now", "k", "is", "not", "assumed", "to", "be", "connected", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the main difference with the situation in", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 42, "end": 44, "i_start": 7, "i_end": 7}}, {"subject": {"text": "k", "start": 54, "end": 55, "i_start": 10, "i_end": 10}, "verb": {"text": "assumed", "start": 63, "end": 70, "i_start": 13, "i_end": 13}}], "id": 3113}, {"sent": "on the savina benchmark suite , we measure the run-time overhead and memory impact of frequent snapshot creation .", "tokens": ["on", "the", "savina", "benchmark", "suite", ",", "we", "measure", "the", "run", "-", "time", "overhead", "and", "memory", "impact", "of", "frequent", "snapshot", "creation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 32, "end": 34, "i_start": 6, "i_end": 6}, "verb": {"text": "measure", "start": 35, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 32, "end": 34, "i_start": 6, "i_end": 6}, "action": {"text": "measure", "start": 35, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "creation", "start": 104, "end": 112, "i_start": 19, "i_end": 19}, "action": {"text": "impact", "start": 76, "end": 82, "i_start": 15, "i_end": 15}}], "id": 3114}, {"sent": "deep learning or deep neural networks have achieved extraordinary performance in many application domains such as image classification .", "tokens": ["deep", "learning", "or", "deep", "neural", "networks", "have", "achieved", "extraordinary", "performance", "in", "many", "application", "domains", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning or deep neural networks", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "have achieved", "start": 38, "end": 51, "i_start": 6, "i_end": 7}}, {"character": {"text": "or", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}], "id": 3115}, {"sent": "as before , the ellipses denote non-quadratic powers of p .", "tokens": ["as", "before", ",", "the", "ellipses", "denote", "non", "-", "quadratic", "powers", "of", "p", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ellipses", "start": 12, "end": 24, "i_start": 3, "i_end": 4}, "verb": {"text": "denote", "start": 25, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "ellipses", "start": 16, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "denote", "start": 25, "end": 31, "i_start": 5, "i_end": 5}}], "id": 3116}, {"sent": "one thus obtains the omplete past and future history of the system \u03c8 erential equations .", "tokens": ["one", "thus", "obtains", "the", "omplete", "past", "and", "future", "history", "of", "the", "system", "\u03c8", "erential", "equations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "obtains", "start": 9, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "obtains", "start": 9, "end": 16, "i_start": 2, "i_end": 2}}], "id": 3117}, {"sent": "image segmentation has attracted a lot of attention in the recent years , and has achieved great progress with the success of deep neural networks .", "tokens": ["image", "segmentation", "has", "attracted", "a", "lot", "of", "attention", "in", "the", "recent", "years", ",", "and", "has", "achieved", "great", "progress", "with", "the", "success", "of", "deep", "neural", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "image segmentation", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "has attracted", "start": 19, "end": 32, "i_start": 2, "i_end": 3}}, {"subject": {"text": "image segmentation", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "achieved", "start": 82, "end": 90, "i_start": 15, "i_end": 15}}, {"character": {"text": "segmentation", "start": 6, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "attracted", "start": 23, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "segmentation", "start": 6, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "achieved", "start": 82, "end": 90, "i_start": 15, "i_end": 15}}, {"character": {"text": "networks", "start": 138, "end": 146, "i_start": 24, "i_end": 24}, "action": {"text": "success", "start": 115, "end": 122, "i_start": 20, "i_end": 20}}], "id": 3118}, {"sent": "kucharczyk , for the lep collaborations , these proceedings .", "tokens": ["kucharczyk", ",", "for", "the", "lep", "collaborations", ",", "these", "proceedings", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3119}, {"sent": "such adaptivity properties have been shown for isotonic regression in the recent literature .", "tokens": ["such", "adaptivity", "properties", "have", "been", "shown", "for", "isotonic", "regression", "in", "the", "recent", "literature", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such adaptivity properties", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "have been shown", "start": 27, "end": 42, "i_start": 3, "i_end": 5}}], "id": 3120}, {"sent": "such canonical representations have been given for binary memoryless symmetric channels in .", "tokens": ["such", "canonical", "representations", "have", "been", "given", "for", "binary", "memoryless", "symmetric", "channels", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such canonical representations", "start": 0, "end": 30, "i_start": 0, "i_end": 2}, "verb": {"text": "have been given", "start": 31, "end": 46, "i_start": 3, "i_end": 5}}, {"subject": {"text": "such canonical representations", "start": 0, "end": 30, "i_start": 0, "i_end": 2}, "verb": {"text": "in", "start": 88, "end": 90, "i_start": 11, "i_end": 11}}], "id": 3121}, {"sent": "for the regularized problem , several properties , like well-posedness of the cauchy problem and existence of invariant measures can be proved .", "tokens": ["for", "the", "regularized", "problem", ",", "several", "properties", ",", "like", "well", "-", "posedness", "of", "the", "cauchy", "problem", "and", "existence", "of", "invariant", "measures", "can", "be", "proved", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "several properties", "start": 30, "end": 48, "i_start": 5, "i_end": 6}, "verb": {"text": "can be proved", "start": 129, "end": 142, "i_start": 21, "i_end": 23}}], "id": 3122}, {"sent": "exactly the same pulse height in the oscilloscope trace .", "tokens": ["exactly", "the", "same", "pulse", "height", "in", "the", "oscilloscope", "trace", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3123}, {"sent": "the fully symmetric formulas from genz and genz and keister are of the smolyak form .", "tokens": ["the", "fully", "symmetric", "formulas", "from", "genz", "and", "genz", "and", "keister", "are", "of", "the", "smolyak", "form", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the fully symmetric formulas from genz and genz and keister", "start": 0, "end": 59, "i_start": 0, "i_end": 9}, "verb": {"text": "are", "start": 60, "end": 63, "i_start": 10, "i_end": 10}}], "id": 3124}, {"sent": "more recently , convolutional neural networks have achieved unprecedented performance in a wide range of image classification problems .", "tokens": ["more", "recently", ",", "convolutional", "neural", "networks", "have", "achieved", "unprecedented", "performance", "in", "a", "wide", "range", "of", "image", "classification", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 74, "end": 85, "i_start": 9, "i_end": 9}}], "id": 3125}, {"sent": "however , gravity is a global force and poisson solvers operate on the global density field .", "tokens": ["however", ",", "gravity", "is", "a", "global", "force", "and", "poisson", "solvers", "operate", "on", "the", "global", "density", "field", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "gravity", "start": 10, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}, {"subject": {"text": "poisson solvers", "start": 40, "end": 55, "i_start": 8, "i_end": 9}, "verb": {"text": "operate", "start": 56, "end": 63, "i_start": 10, "i_end": 10}}], "id": 3126}, {"sent": "the blow-up phenomena and global existence of strong solutions to in sobolev spaces were obtained in .", "tokens": ["the", "blow", "-", "up", "phenomena", "and", "global", "existence", "of", "strong", "solutions", "to", "in", "sobolev", "spaces", "were", "obtained", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the blow-up phenomena and global existence of strong solutions to in sobolev spaces", "start": 0, "end": 83, "i_start": 0, "i_end": 14}, "verb": {"text": "were obtained", "start": 84, "end": 97, "i_start": 15, "i_end": 16}}], "id": 3127}, {"sent": "in proceedings of the tenth national conference on arti cial intel ligence , pp .", "tokens": ["in", "proceedings", "of", "the", "tenth", "national", "conference", "on", "arti", "cial", "intel", "ligence", ",", "pp", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3128}, {"sent": "two popular attack algorithms , namely , fast gradient sign method and the carlini and wagner attack are used to generate adversarial examples .", "tokens": ["two", "popular", "attack", "algorithms", ",", "namely", ",", "fast", "gradient", "sign", "method", "and", "the", "carlini", "and", "wagner", "attack", "are", "used", "to", "generate", "adversarial", "examples", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "two popular attack algorithms", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "are used", "start": 101, "end": 109, "i_start": 17, "i_end": 18}}, {"character": {"text": "carlini", "start": 75, "end": 82, "i_start": 13, "i_end": 13}, "action": {"text": "attack", "start": 94, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "wagner", "start": 87, "end": 93, "i_start": 15, "i_end": 15}, "action": {"text": "attack", "start": 94, "end": 100, "i_start": 16, "i_end": 16}}], "id": 3129}, {"sent": "for faces , we use the vgg face model from , pretrained on celeb face data for face recognition .", "tokens": ["for", "faces", ",", "we", "use", "the", "vgg", "face", "model", "from", ",", "pretrained", "on", "celeb", "face", "data", "for", "face", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 12, "end": 14, "i_start": 3, "i_end": 3}, "verb": {"text": "use", "start": 15, "end": 18, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 12, "end": 14, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 15, "end": 18, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 12, "end": 14, "i_start": 3, "i_end": 3}, "action": {"text": "pretrained", "start": 45, "end": 55, "i_start": 11, "i_end": 11}}], "id": 3130}, {"sent": "the vlq multiplets that can mix with sm quarks and a sm higgs boson have been studied , rather extensively , in the literature .", "tokens": ["the", "vlq", "multiplets", "that", "can", "mix", "with", "sm", "quarks", "and", "a", "sm", "higgs", "boson", "have", "been", "studied", ",", "rather", "extensively", ",", "in", "the", "literature", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the vlq multiplets that can mix with sm quarks and a sm higgs boson", "start": 0, "end": 67, "i_start": 0, "i_end": 13}, "verb": {"text": "have been studied", "start": 68, "end": 85, "i_start": 14, "i_end": 16}}], "id": 3131}, {"sent": "a large amount of research achievements have been made about synchronization properties of small-world , scale-free and other types of complex networks .", "tokens": ["a", "large", "amount", "of", "research", "achievements", "have", "been", "made", "about", "synchronization", "properties", "of", "small", "-", "world", ",", "scale", "-", "free", "and", "other", "types", "of", "complex", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a large amount of research achievements", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "have been made", "start": 40, "end": 54, "i_start": 6, "i_end": 8}}], "id": 3132}, {"sent": "convolutional neural networks have been trained to achieve near human-level performance on object detection .", "tokens": ["convolutional", "neural", "networks", "have", "been", "trained", "to", "achieve", "near", "human", "-", "level", "performance", "on", "object", "detection", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been trained", "start": 30, "end": 47, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 51, "end": 58, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 76, "end": 87, "i_start": 12, "i_end": 12}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "detection", "start": 98, "end": 107, "i_start": 15, "i_end": 15}}], "id": 3133}, {"sent": "based on this labeling , justin et al proposed a fully convolutional localization network to jointly generate finer level of regions and captions .", "tokens": ["based", "on", "this", "labeling", ",", "justin", "et", "al", "proposed", "a", "fully", "convolutional", "localization", "network", "to", "jointly", "generate", "finer", "level", "of", "regions", "and", "captions", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this labeling", "start": 9, "end": 22, "i_start": 2, "i_end": 3}, "verb": {"text": "proposed", "start": 38, "end": 46, "i_start": 8, "i_end": 8}}, {"character": {"text": "justin", "start": 25, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "proposed", "start": 38, "end": 46, "i_start": 8, "i_end": 8}}, {"character": {"text": "justin", "start": 25, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "generate", "start": 101, "end": 109, "i_start": 16, "i_end": 16}}], "id": 3134}, {"sent": "one of the most popular defenses against adversarial examples for neural networks is adversarial training .", "tokens": ["one", "of", "the", "most", "popular", "defenses", "against", "adversarial", "examples", "for", "neural", "networks", "is", "adversarial", "training", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "one of the most popular defenses against adversarial examples for neural networks", "start": 0, "end": 81, "i_start": 0, "i_end": 11}, "verb": {"text": "is", "start": 82, "end": 84, "i_start": 12, "i_end": 12}}], "id": 3135}, {"sent": "one can prove more generally therefore that this operator is the baryon number operator .", "tokens": ["one", "can", "prove", "more", "generally", "therefore", "that", "this", "operator", "is", "the", "baryon", "number", "operator", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "can prove", "start": 4, "end": 13, "i_start": 1, "i_end": 2}}, {"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 58, "end": 60, "i_start": 9, "i_end": 9}}, {"character": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "prove", "start": 8, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "this", "start": 44, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "operator", "start": 49, "end": 57, "i_start": 8, "i_end": 8}}], "id": 3136}, {"sent": "all the other closed subgroups are obtained by adding new connected components .", "tokens": ["all", "the", "other", "closed", "subgroups", "are", "obtained", "by", "adding", "new", "connected", "components", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all the other closed subgroups", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "are obtained", "start": 31, "end": 43, "i_start": 5, "i_end": 6}}], "id": 3137}, {"sent": "thus the density wave effects should be considered .", "tokens": ["thus", "the", "density", "wave", "effects", "should", "be", "considered", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the density wave effects", "start": 5, "end": 29, "i_start": 1, "i_end": 4}, "verb": {"text": "should be considered", "start": 30, "end": 50, "i_start": 5, "i_end": 7}}, {"character": {"text": "wave", "start": 17, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "effects", "start": 22, "end": 29, "i_start": 4, "i_end": 4}}], "id": 3138}, {"sent": "predictions using two such models , referred to as model f , were evaluated for d .", "tokens": ["predictions", "using", "two", "such", "models", ",", "referred", "to", "as", "model", "f", ",", "were", "evaluated", "for", "d", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "predictions using two such models", "start": 0, "end": 33, "i_start": 0, "i_end": 4}, "verb": {"text": "were evaluated", "start": 61, "end": 75, "i_start": 12, "i_end": 13}}, {"subject": {"text": "predictions using two such models", "start": 0, "end": 33, "i_start": 0, "i_end": 4}, "verb": {"text": "referred", "start": 36, "end": 44, "i_start": 6, "i_end": 6}}], "id": 3139}, {"sent": "deep learning has made an enormous impact on many applications in computer vision such as generic object recognition .", "tokens": ["deep", "learning", "has", "made", "an", "enormous", "impact", "on", "many", "applications", "in", "computer", "vision", "such", "as", "generic", "object", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has made", "start": 14, "end": 22, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "impact", "start": 35, "end": 41, "i_start": 6, "i_end": 6}}], "id": 3140}, {"sent": "since direct effects of astrophysical ionizing radiation on the ground are poorly understood , we will only be able to comment qualitatively on them .", "tokens": ["since", "direct", "effects", "of", "astrophysical", "ionizing", "radiation", "on", "the", "ground", "are", "poorly", "understood", ",", "we", "will", "only", "be", "able", "to", "comment", "qualitatively", "on", "them", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 95, "end": 97, "i_start": 14, "i_end": 14}, "verb": {"text": "be", "start": 108, "end": 110, "i_start": 17, "i_end": 17}}, {"subject": {"text": "we", "start": 95, "end": 97, "i_start": 14, "i_end": 14}, "verb": {"text": "will", "start": 98, "end": 102, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 95, "end": 97, "i_start": 14, "i_end": 14}, "action": {"text": "comment", "start": 119, "end": 126, "i_start": 20, "i_end": 20}}, {"character": {"text": "radiation", "start": 47, "end": 56, "i_start": 6, "i_end": 6}, "action": {"text": "effects", "start": 13, "end": 20, "i_start": 2, "i_end": 2}}], "id": 3141}, {"sent": "the stacked ks image will be made publicly available from irsa .", "tokens": ["the", "stacked", "ks", "image", "will", "be", "made", "publicly", "available", "from", "irsa", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the stacked ks image", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "will be made", "start": 21, "end": 33, "i_start": 4, "i_end": 6}}], "id": 3142}, {"sent": "recently , deep neural networks has achieved great success on computer vision .", "tokens": ["recently", ",", "deep", "neural", "networks", "has", "achieved", "great", "success", "on", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "has achieved", "start": 32, "end": 44, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 36, "end": 44, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "success", "start": 51, "end": 58, "i_start": 8, "i_end": 8}}], "id": 3143}, {"sent": "deep learning methods have recently influenced several application domains , namely computer vision , where they have enjoyed significant performance improvements compared to state-of-art methods in the respective domains .", "tokens": ["deep", "learning", "methods", "have", "recently", "influenced", "several", "application", "domains", ",", "namely", "computer", "vision", ",", "where", "they", "have", "enjoyed", "significant", "performance", "improvements", "compared", "to", "state", "-", "of", "-", "art", "methods", "in", "the", "respective", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning methods", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "influenced", "start": 36, "end": 46, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep learning methods", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 22, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "methods", "start": 14, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "influenced", "start": 36, "end": 46, "i_start": 5, "i_end": 5}}, {"character": {"text": "methods", "start": 14, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "enjoyed", "start": 118, "end": 125, "i_start": 17, "i_end": 17}}], "id": 3144}, {"sent": "in mathematics , banaszczyk firstly used it to prove the transference theorems of lattices .", "tokens": ["in", "mathematics", ",", "banaszczyk", "firstly", "used", "it", "to", "prove", "the", "transference", "theorems", "of", "lattices", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "banaszczyk", "start": 17, "end": 27, "i_start": 3, "i_end": 3}, "verb": {"text": "used", "start": 36, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "banaszczyk", "start": 17, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "used", "start": 36, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "banaszczyk", "start": 17, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "prove", "start": 47, "end": 52, "i_start": 8, "i_end": 8}}], "id": 3145}, {"sent": "learning in the s2m is slower than in the rbm , as reported with other models using dropconnect but it is effective in preventing overfitting .", "tokens": ["learning", "in", "the", "s2", "m", "is", "slower", "than", "in", "the", "rbm", ",", "as", "reported", "with", "other", "models", "using", "dropconnect", "but", "it", "is", "effective", "in", "preventing", "overfitting", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "learning in the s2m", "start": 0, "end": 19, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 5, "i_end": 5}}, {"character": {"text": "it", "start": 100, "end": 102, "i_start": 20, "i_end": 20}, "action": {"text": "effective", "start": 106, "end": 115, "i_start": 22, "i_end": 22}}, {"character": {"text": "it", "start": 100, "end": 102, "i_start": 20, "i_end": 20}, "action": {"text": "preventing", "start": 119, "end": 129, "i_start": 24, "i_end": 24}}, {"character": {"text": "models", "start": 71, "end": 77, "i_start": 16, "i_end": 16}, "action": {"text": "reported", "start": 51, "end": 59, "i_start": 13, "i_end": 13}}, {"character": {"text": "models", "start": 71, "end": 77, "i_start": 16, "i_end": 16}, "action": {"text": "using", "start": 78, "end": 83, "i_start": 17, "i_end": 17}}], "id": 3146}, {"sent": "one possible answer comes from the study of the deviation to the fluctuation dissipation theorem in an out of equilibrium system .", "tokens": ["one", "possible", "answer", "comes", "from", "the", "study", "of", "the", "deviation", "to", "the", "fluctuation", "dissipation", "theorem", "in", "an", "out", "of", "equilibrium", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one possible answer", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "comes", "start": 20, "end": 25, "i_start": 3, "i_end": 3}}], "id": 3147}, {"sent": "in the fitnet , a thick-shallow model is transformed to a thin-deep model .", "tokens": ["in", "the", "fitnet", ",", "a", "thick", "-", "shallow", "model", "is", "transformed", "to", "a", "thin", "-", "deep", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a thick-shallow model", "start": 16, "end": 37, "i_start": 4, "i_end": 8}, "verb": {"text": "is transformed", "start": 38, "end": 52, "i_start": 9, "i_end": 10}}], "id": 3148}, {"sent": "scalar-tensor cosmologies and their late time evolution .", "tokens": ["scalar", "-", "tensor", "cosmologies", "and", "their", "late", "time", "evolution", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3149}, {"sent": "raizen , observation of atomic tunneling from an accelerating optical potential , phys .", "tokens": ["raizen", ",", "observation", "of", "atomic", "tunneling", "from", "an", "accelerating", "optical", "potential", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3150}, {"sent": "this result follows essentially from an application of the chain rule for mutual information .", "tokens": ["this", "result", "follows", "essentially", "from", "an", "application", "of", "the", "chain", "rule", "for", "mutual", "information", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this result", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "follows", "start": 12, "end": 19, "i_start": 2, "i_end": 2}}], "id": 3151}, {"sent": "haghighi et al proposed a canonical correlation analysis based model for automatically learning the mapping between the words in two languages from monolingual corpora only .", "tokens": ["haghighi", "et", "al", "proposed", "a", "canonical", "correlation", "analysis", "based", "model", "for", "automatically", "learning", "the", "mapping", "between", "the", "words", "in", "two", "languages", "from", "monolingual", "corpora", "only", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "haghighi et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "haghighi", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 3152}, {"sent": "our algorithm therefore performs as well as the gs algorithm in the special case when distribution v happens to arise from a time-invariant control system .", "tokens": ["our", "algorithm", "therefore", "performs", "as", "well", "as", "the", "gs", "algorithm", "in", "the", "special", "case", "when", "distribution", "v", "happens", "to", "arise", "from", "a", "time", "-", "invariant", "control", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our algorithm", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "performs", "start": 24, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithm", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "performs", "start": 24, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "system", "start": 148, "end": 154, "i_start": 26, "i_end": 26}, "action": {"text": "arise", "start": 112, "end": 117, "i_start": 19, "i_end": 19}}, {"character": {"text": "system", "start": 148, "end": 154, "i_start": 26, "i_end": 26}, "action": {"text": "control", "start": 140, "end": 147, "i_start": 25, "i_end": 25}}], "id": 3153}, {"sent": "two of the most commonly used and efficient approaches are vae and generative adversarial networks .", "tokens": ["two", "of", "the", "most", "commonly", "used", "and", "efficient", "approaches", "are", "vae", "and", "generative", "adversarial", "networks", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "two of the most commonly used and efficient approaches", "start": 0, "end": 54, "i_start": 0, "i_end": 8}, "verb": {"text": "are", "start": 55, "end": 58, "i_start": 9, "i_end": 9}}], "id": 3154}, {"sent": "in recent years , se methods based on deep learning have been proposed and investigated extensively , such as a denoising autoencoder .", "tokens": ["in", "recent", "years", ",", "se", "methods", "based", "on", "deep", "learning", "have", "been", "proposed", "and", "investigated", "extensively", ",", "such", "as", "a", "denoising", "autoencoder", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "se methods based on deep learning", "start": 18, "end": 51, "i_start": 4, "i_end": 9}, "verb": {"text": "have been proposed", "start": 52, "end": 70, "i_start": 10, "i_end": 12}}, {"subject": {"text": "se methods based on deep learning", "start": 18, "end": 51, "i_start": 4, "i_end": 9}, "verb": {"text": "investigated", "start": 75, "end": 87, "i_start": 14, "i_end": 14}}, {"character": {"text": "autoencoder", "start": 122, "end": 133, "i_start": 21, "i_end": 21}, "action": {"text": "denoising", "start": 112, "end": 121, "i_start": 20, "i_end": 20}}], "id": 3155}, {"sent": "a quantum channel is a device which transmits classical bits or quantum states .", "tokens": ["a", "quantum", "channel", "is", "a", "device", "which", "transmits", "classical", "bits", "or", "quantum", "states", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a quantum channel", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "device", "start": 23, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "transmits", "start": 36, "end": 45, "i_start": 7, "i_end": 7}}], "id": 3156}, {"sent": "the most successful examples in this category include the restricted boltzmann machine , the deep belief network , topic models , etc .", "tokens": ["the", "most", "successful", "examples", "in", "this", "category", "include", "the", "restricted", "boltzmann", "machine", ",", "the", "deep", "belief", "network", ",", "topic", "models", ",", "etc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most successful examples in this category", "start": 0, "end": 45, "i_start": 0, "i_end": 6}, "verb": {"text": "include", "start": 46, "end": 53, "i_start": 7, "i_end": 7}}], "id": 3157}, {"sent": "however , in the general pseudo-riemanian case , the complete description of holonomy groups is a very difficult problem which still remains open and even particular examples are of interest .", "tokens": ["however", ",", "in", "the", "general", "pseudo", "-", "riemanian", "case", ",", "the", "complete", "description", "of", "holonomy", "groups", "is", "a", "very", "difficult", "problem", "which", "still", "remains", "open", "and", "even", "particular", "examples", "are", "of", "interest", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the complete description of holonomy groups", "start": 49, "end": 92, "i_start": 10, "i_end": 15}, "verb": {"text": "is", "start": 93, "end": 95, "i_start": 16, "i_end": 16}}], "id": 3158}, {"sent": "they continuously monitor the connectivity of a prefix and raise an alarm , when significant changes in the reachability are observed .", "tokens": ["they", "continuously", "monitor", "the", "connectivity", "of", "a", "prefix", "and", "raise", "an", "alarm", ",", "when", "significant", "changes", "in", "the", "reachability", "are", "observed", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "monitor", "start": 18, "end": 25, "i_start": 2, "i_end": 2}}, {"subject": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "raise", "start": 59, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "monitor", "start": 18, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "raise", "start": 59, "end": 64, "i_start": 9, "i_end": 9}}], "id": 3159}, {"sent": "variational auto-encoders and generative adversarial networks have shown promising generative performances on data from complex high-dimensional distributions .", "tokens": ["variational", "auto", "-", "encoders", "and", "generative", "adversarial", "networks", "have", "shown", "promising", "generative", "performances", "on", "data", "from", "complex", "high", "-", "dimensional", "distributions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "variational auto-encoders and generative adversarial networks", "start": 0, "end": 61, "i_start": 0, "i_end": 7}, "verb": {"text": "have shown", "start": 62, "end": 72, "i_start": 8, "i_end": 9}}, {"character": {"text": "encoders", "start": 17, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 67, "end": 72, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 53, "end": 61, "i_start": 7, "i_end": 7}, "action": {"text": "shown", "start": 67, "end": 72, "i_start": 9, "i_end": 9}}, {"character": {"text": "adversarial", "start": 41, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "shown", "start": 67, "end": 72, "i_start": 9, "i_end": 9}}, {"character": {"text": "generative", "start": 30, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "shown", "start": 67, "end": 72, "i_start": 9, "i_end": 9}}, {"character": {"text": "encoders", "start": 17, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "performances", "start": 94, "end": 106, "i_start": 12, "i_end": 12}}, {"character": {"text": "networks", "start": 53, "end": 61, "i_start": 7, "i_end": 7}, "action": {"text": "performances", "start": 94, "end": 106, "i_start": 12, "i_end": 12}}, {"character": {"text": "adversarial", "start": 41, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "performances", "start": 94, "end": 106, "i_start": 12, "i_end": 12}}, {"character": {"text": "generative", "start": 30, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "performances", "start": 94, "end": 106, "i_start": 12, "i_end": 12}}, {"character": {"text": "performances", "start": 94, "end": 106, "i_start": 12, "i_end": 12}, "action": {"text": "promising", "start": 73, "end": 82, "i_start": 10, "i_end": 10}}], "id": 3160}, {"sent": "the neutralino is the lightest supersymmetric partner and is stable under r-conservation .", "tokens": ["the", "neutralino", "is", "the", "lightest", "supersymmetric", "partner", "and", "is", "stable", "under", "r", "-", "conservation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the neutralino", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 3161}, {"sent": "thus , every involution fixes at least three distinct points , each of which lies in an appropriate block .", "tokens": ["thus", ",", "every", "involution", "fixes", "at", "least", "three", "distinct", "points", ",", "each", "of", "which", "lies", "in", "an", "appropriate", "block", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "every involution", "start": 7, "end": 23, "i_start": 2, "i_end": 3}, "verb": {"text": "fixes", "start": 24, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "involution", "start": 13, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "fixes", "start": 24, "end": 29, "i_start": 4, "i_end": 4}}], "id": 3162}, {"sent": "the qubit consists of the last two vectors .", "tokens": ["the", "qubit", "consists", "of", "the", "last", "two", "vectors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the qubit", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 10, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3163}, {"sent": "recently , a new direction of research has been established by investigating these systems from the perspective of topological phases .", "tokens": ["recently", ",", "a", "new", "direction", "of", "research", "has", "been", "established", "by", "investigating", "these", "systems", "from", "the", "perspective", "of", "topological", "phases", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a new direction of research", "start": 11, "end": 38, "i_start": 2, "i_end": 6}, "verb": {"text": "has been established", "start": 39, "end": 59, "i_start": 7, "i_end": 9}}], "id": 3164}, {"sent": "quantum mechanics is a fundamentally probabilistic theory .", "tokens": ["quantum", "mechanics", "is", "a", "fundamentally", "probabilistic", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum mechanics", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}], "id": 3165}, {"sent": "more recently , convolutional neural networks have achieved unprecedented performance in a wide range of image classification problems .", "tokens": ["more", "recently", ",", "convolutional", "neural", "networks", "have", "achieved", "unprecedented", "performance", "in", "a", "wide", "range", "of", "image", "classification", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 74, "end": 85, "i_start": 9, "i_end": 9}}], "id": 3166}, {"sent": "this instability is the origin of the formation of a critical point in the bootstrap matter .", "tokens": ["this", "instability", "is", "the", "origin", "of", "the", "formation", "of", "a", "critical", "point", "in", "the", "bootstrap", "matter", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this instability", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}], "id": 3167}, {"sent": "to this end , we exploited a pre-trained network , the vgg-face cnn , trained on rgb images for face recognition purposes .", "tokens": ["to", "this", "end", ",", "we", "exploited", "a", "pre", "-", "trained", "network", ",", "the", "vgg", "-", "face", "cnn", ",", "trained", "on", "rgb", "images", "for", "face", "recognition", "purposes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "verb": {"text": "exploited", "start": 17, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "exploited", "start": 17, "end": 26, "i_start": 5, "i_end": 5}}], "id": 3168}, {"sent": "machine learning models based on deep neural networks have achieved unprecedented performance across a wide range of tasks .", "tokens": ["machine", "learning", "models", "based", "on", "deep", "neural", "networks", "have", "achieved", "unprecedented", "performance", "across", "a", "wide", "range", "of", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "machine learning models based on deep neural networks", "start": 0, "end": 53, "i_start": 0, "i_end": 7}, "verb": {"text": "have achieved", "start": 54, "end": 67, "i_start": 8, "i_end": 9}}, {"character": {"text": "models", "start": 17, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 59, "end": 67, "i_start": 9, "i_end": 9}}, {"character": {"text": "models", "start": 17, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "learning", "start": 8, "end": 16, "i_start": 1, "i_end": 1}}], "id": 3169}, {"sent": "supergravity is the best framework within which both quintessence and inflation can be described .", "tokens": ["supergravity", "is", "the", "best", "framework", "within", "which", "both", "quintessence", "and", "inflation", "can", "be", "described", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "supergravity", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 1, "i_end": 1}}], "id": 3170}, {"sent": "we experimented with resnet-56 architecture on the cifar-10 dataset .", "tokens": ["we", "experimented", "with", "resnet-56", "architecture", "on", "the", "cifar-10", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "experimented", "start": 3, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "experimented", "start": 3, "end": 15, "i_start": 1, "i_end": 1}}], "id": 3171}, {"sent": "this fact supports the idea that dmso molecules do not penetrate to the region of polar head groups .", "tokens": ["this", "fact", "supports", "the", "idea", "that", "dmso", "molecules", "do", "not", "penetrate", "to", "the", "region", "of", "polar", "head", "groups", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this fact", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "supports", "start": 10, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "fact", "start": 5, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "supports", "start": 10, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "molecules", "start": 38, "end": 47, "i_start": 7, "i_end": 7}, "action": {"text": "not penetrate", "start": 51, "end": 64, "i_start": 9, "i_end": 10}}, {"character": {"text": "groups", "start": 93, "end": 99, "i_start": 17, "i_end": 17}, "action": {"text": "head", "start": 88, "end": 92, "i_start": 16, "i_end": 16}}], "id": 3172}, {"sent": "many different optical components such as lenses have been demonstrated using metasurfaces .", "tokens": ["many", "different", "optical", "components", "such", "as", "lenses", "have", "been", "demonstrated", "using", "metasurfaces", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many different optical components such as lenses", "start": 0, "end": 48, "i_start": 0, "i_end": 6}, "verb": {"text": "have been demonstrated", "start": 49, "end": 71, "i_start": 7, "i_end": 9}}], "id": 3173}, {"sent": "we use the tensor2tensor implementation of the transformer to train our models .", "tokens": ["we", "use", "the", "tensor2tensor", "implementation", "of", "the", "transformer", "to", "train", "our", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 62, "end": 67, "i_start": 9, "i_end": 9}}], "id": 3174}, {"sent": "among them the coadjoint orbit method , which was proposed by alekseev and shatashvili .", "tokens": ["among", "them", "the", "coadjoint", "orbit", "method", ",", "which", "was", "proposed", "by", "alekseev", "and", "shatashvili", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "alekseev", "start": 62, "end": 70, "i_start": 11, "i_end": 11}, "action": {"text": "proposed", "start": 50, "end": 58, "i_start": 9, "i_end": 9}}, {"character": {"text": "shatashvili", "start": 75, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "proposed", "start": 50, "end": 58, "i_start": 9, "i_end": 9}}], "id": 3175}, {"sent": "vortex lattices in rotating atomic bose gases with dipolar interactions .", "tokens": ["vortex", "lattices", "in", "rotating", "atomic", "bose", "gases", "with", "dipolar", "interactions", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3176}, {"sent": "if discrepancies occur between experimental observations and the inferred predictions , a new set of information constraints must be selected .", "tokens": ["if", "discrepancies", "occur", "between", "experimental", "observations", "and", "the", "inferred", "predictions", ",", "a", "new", "set", "of", "information", "constraints", "must", "be", "selected", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "a new set of information constraints", "start": 88, "end": 124, "i_start": 11, "i_end": 16}, "verb": {"text": "must be selected", "start": 125, "end": 141, "i_start": 17, "i_end": 19}}], "id": 3177}, {"sent": "ding et al showed that the complete weight enumerators could be used to compute the deception probabilities of certain authentication codes .", "tokens": ["ding", "et", "al", "showed", "that", "the", "complete", "weight", "enumerators", "could", "be", "used", "to", "compute", "the", "deception", "probabilities", "of", "certain", "authentication", "codes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "ding et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 11, "end": 17, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the complete weight enumerators", "start": 23, "end": 54, "i_start": 5, "i_end": 8}, "verb": {"text": "used", "start": 64, "end": 68, "i_start": 11, "i_end": 11}}, {"character": {"text": "ding", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 11, "end": 17, "i_start": 3, "i_end": 3}}], "id": 3178}, {"sent": "finding local community structure in networks .", "tokens": ["finding", "local", "community", "structure", "in", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3179}, {"sent": "while this paper focuses on the hard cases , those easy cases can be largely explained in terms of the recruitment into those groups , which has been elaborated by others , which denotes the bonding strength of individuals to a group .", "tokens": ["while", "this", "paper", "focuses", "on", "the", "hard", "cases", ",", "those", "easy", "cases", "can", "be", "largely", "explained", "in", "terms", "of", "the", "recruitment", "into", "those", "groups", ",", "which", "has", "been", "elaborated", "by", "others", ",", "which", "denotes", "the", "bonding", "strength", "of", "individuals", "to", "a", "group", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "those easy cases", "start": 45, "end": 61, "i_start": 9, "i_end": 11}, "verb": {"text": "explained", "start": 77, "end": 86, "i_start": 15, "i_end": 15}}, {"subject": {"text": "those easy cases", "start": 45, "end": 61, "i_start": 9, "i_end": 11}, "verb": {"text": "can be", "start": 62, "end": 68, "i_start": 12, "i_end": 13}}, {"character": {"text": "others", "start": 164, "end": 170, "i_start": 30, "i_end": 30}, "action": {"text": "elaborated", "start": 150, "end": 160, "i_start": 28, "i_end": 28}}, {"character": {"text": "recruitment", "start": 103, "end": 114, "i_start": 20, "i_end": 20}, "action": {"text": "denotes", "start": 179, "end": 186, "i_start": 33, "i_end": 33}}, {"character": {"text": "individuals", "start": 211, "end": 222, "i_start": 38, "i_end": 38}, "action": {"text": "bonding", "start": 191, "end": 198, "i_start": 35, "i_end": 35}}], "id": 3180}, {"sent": "recent work based on deep neural network aims to obtain domain invariant features by end-to-end training .", "tokens": ["recent", "work", "based", "on", "deep", "neural", "network", "aims", "to", "obtain", "domain", "invariant", "features", "by", "end", "-", "to", "-", "end", "training", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent work based on deep neural network", "start": 0, "end": 40, "i_start": 0, "i_end": 6}, "verb": {"text": "aims", "start": 41, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "work", "start": 7, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "aims", "start": 41, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "work", "start": 7, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "obtain", "start": 49, "end": 55, "i_start": 9, "i_end": 9}}], "id": 3181}, {"sent": "major approaches include variational autoencoders , generative adversarial networks .", "tokens": ["major", "approaches", "include", "variational", "autoencoders", ",", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "major approaches", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "include", "start": 17, "end": 24, "i_start": 2, "i_end": 2}}], "id": 3182}, {"sent": "it follows that the subspace , which we denote by p , is stratified homotopy equivalent to q is finitely generated as required .", "tokens": ["it", "follows", "that", "the", "subspace", ",", "which", "we", "denote", "by", "p", ",", "is", "stratified", "homotopy", "equivalent", "to", "q", "is", "finitely", "generated", "as", "required", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follows", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 54, "end": 56, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 37, "end": 39, "i_start": 7, "i_end": 7}, "action": {"text": "denote", "start": 40, "end": 46, "i_start": 8, "i_end": 8}}], "id": 3183}, {"sent": "applications such as require us to not only decompose a graph and label its nodes but to also select a subgraph .", "tokens": ["applications", "such", "as", "require", "us", "to", "not", "only", "decompose", "a", "graph", "and", "label", "its", "nodes", "but", "to", "also", "select", "a", "subgraph", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "applications such as", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "require", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "applications", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "action": {"text": "require", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 29, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "decompose", "start": 44, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "us", "start": 29, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "label", "start": 66, "end": 71, "i_start": 12, "i_end": 12}}, {"character": {"text": "us", "start": 29, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "select", "start": 94, "end": 100, "i_start": 18, "i_end": 18}}], "id": 3184}, {"sent": "hu et al proposed senet which adaptively weights the channel-wise feature responses by explicitly modeling interdependencies between channels .", "tokens": ["hu", "et", "al", "proposed", "senet", "which", "adaptively", "weights", "the", "channel", "-", "wise", "feature", "responses", "by", "explicitly", "modeling", "interdependencies", "between", "channels", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "hu", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}], "id": 3185}, {"sent": "other works have explored the optimal leader selection in leaderfollower systems without stochastic disturbances .", "tokens": ["other", "works", "have", "explored", "the", "optimal", "leader", "selection", "in", "leaderfollower", "systems", "without", "stochastic", "disturbances", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "other works", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "have explored", "start": 12, "end": 25, "i_start": 2, "i_end": 3}}], "id": 3186}, {"sent": "the optical and electronic properties of one-dimensional materials have been an important subject in the field of condensed matter physics .", "tokens": ["the", "optical", "and", "electronic", "properties", "of", "one", "-", "dimensional", "materials", "have", "been", "an", "important", "subject", "in", "the", "field", "of", "condensed", "matter", "physics", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the optical and electronic properties of one-dimensional materials", "start": 0, "end": 66, "i_start": 0, "i_end": 9}, "verb": {"text": "have been", "start": 67, "end": 76, "i_start": 10, "i_end": 11}}], "id": 3187}, {"sent": "since every interval of t is a subinterval of some interval in pj , we conclude that t is contained in at most k intervals j be the top k intervals in pj .", "tokens": ["since", "every", "interval", "of", "t", "is", "a", "subinterval", "of", "some", "interval", "in", "pj", ",", "we", "conclude", "that", "t", "is", "contained", "in", "at", "most", "k", "intervals", "j", "be", "the", "top", "k", "intervals", "in", "pj", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 68, "end": 70, "i_start": 14, "i_end": 14}, "verb": {"text": "conclude", "start": 71, "end": 79, "i_start": 15, "i_end": 15}}, {"subject": {"text": "t", "start": 85, "end": 86, "i_start": 17, "i_end": 17}, "verb": {"text": "contained", "start": 90, "end": 99, "i_start": 19, "i_end": 19}}], "id": 3188}, {"sent": "in recent years , deep convolutional networks have achieved remarkable results in many computer vision tasks .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "networks", "have", "achieved", "remarkable", "results", "in", "many", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional networks", "start": 18, "end": 45, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 8, "i_end": 8}}], "id": 3189}, {"sent": "to make the generator and the discriminator more balanced , metz et al created an unrolled objective function to enhance the generator .", "tokens": ["to", "make", "the", "generator", "and", "the", "discriminator", "more", "balanced", ",", "metz", "et", "al", "created", "an", "unrolled", "objective", "function", "to", "enhance", "the", "generator", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "et al", "start": 65, "end": 70, "i_start": 11, "i_end": 12}, "verb": {"text": "created", "start": 71, "end": 78, "i_start": 13, "i_end": 13}}, {"character": {"text": "metz", "start": 60, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "created", "start": 71, "end": 78, "i_start": 13, "i_end": 13}}, {"character": {"text": "metz", "start": 60, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "enhance", "start": 113, "end": 120, "i_start": 19, "i_end": 19}}, {"character": {"text": "metz", "start": 60, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "make", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3190}, {"sent": "verlinde , the operator algebra of orbifold models .", "tokens": ["verlinde", ",", "the", "operator", "algebra", "of", "orbifold", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "algebra", "start": 24, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "operator", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 3191}, {"sent": "therefore the contribution of this spin dependent force to the spin-faraday law is the same as that of the spin geometric phase which is half the solid angle subtended by the spin precession .", "tokens": ["therefore", "the", "contribution", "of", "this", "spin", "dependent", "force", "to", "the", "spin", "-", "faraday", "law", "is", "the", "same", "as", "that", "of", "the", "spin", "geometric", "phase", "which", "is", "half", "the", "solid", "angle", "subtended", "by", "the", "spin", "precession", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the contribution of this spin dependent force to the spin-faraday law", "start": 10, "end": 79, "i_start": 1, "i_end": 13}, "verb": {"text": "is", "start": 80, "end": 82, "i_start": 14, "i_end": 14}}, {"character": {"text": "force", "start": 50, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "contribution", "start": 14, "end": 26, "i_start": 2, "i_end": 2}}, {"character": {"text": "force", "start": 50, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "dependent", "start": 40, "end": 49, "i_start": 6, "i_end": 6}}], "id": 3192}, {"sent": "radiation consists of dephased spatial fourier component with .", "tokens": ["radiation", "consists", "of", "dephased", "spatial", "fourier", "component", "with", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "radiation", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "consists", "start": 10, "end": 18, "i_start": 1, "i_end": 1}}], "id": 3193}, {"sent": "deep neural networks have achieved state-of-the-art performance on a wide variety of machine learning tasks .", "tokens": ["deep", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "a", "wide", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 52, "end": 63, "i_start": 12, "i_end": 12}}], "id": 3194}, {"sent": "auctions were randomly assigned to an increased reserve price treatment , and the effect was estimated using difference-in-differences .", "tokens": ["auctions", "were", "randomly", "assigned", "to", "an", "increased", "reserve", "price", "treatment", ",", "and", "the", "effect", "was", "estimated", "using", "difference", "-", "in", "-", "differences", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the effect", "start": 78, "end": 88, "i_start": 12, "i_end": 13}, "verb": {"text": "assigned", "start": 23, "end": 31, "i_start": 3, "i_end": 3}}, {"subject": {"text": "auctions", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "were", "start": 9, "end": 13, "i_start": 1, "i_end": 1}}, {"subject": {"text": "auctions", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "estimated", "start": 93, "end": 102, "i_start": 15, "i_end": 15}}], "id": 3195}, {"sent": "all models are trained using mle loss and optimized using adam optimizer with a batch size 256 .", "tokens": ["all", "models", "are", "trained", "using", "mle", "loss", "and", "optimized", "using", "adam", "optimizer", "with", "a", "batch", "size", "256", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all models", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "are trained", "start": 11, "end": 22, "i_start": 2, "i_end": 3}}], "id": 3196}, {"sent": "we illustrate this situation by an example .", "tokens": ["we", "illustrate", "this", "situation", "by", "an", "example", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "illustrate", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "illustrate", "start": 3, "end": 13, "i_start": 1, "i_end": 1}}], "id": 3197}, {"sent": "the phase space is a four-dimensional euclidean space spanned by the canonical coordinates p ir2 .", "tokens": ["the", "phase", "space", "is", "a", "four", "-", "dimensional", "euclidean", "space", "spanned", "by", "the", "canonical", "coordinates", "p", "ir2", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the phase space", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 3198}, {"sent": "we are particularly interested in the mass spectrum in four dimensions .", "tokens": ["we", "are", "particularly", "interested", "in", "the", "mass", "spectrum", "in", "four", "dimensions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 3199}, {"sent": "manuel , preceedings of the international symposium on nuclear beta decays and neutrino , t .", "tokens": ["manuel", ",", "preceedings", "of", "the", "international", "symposium", "on", "nuclear", "beta", "decays", "and", "neutrino", ",", "t", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "nuclear", "start": 55, "end": 62, "i_start": 8, "i_end": 8}, "action": {"text": "decays", "start": 68, "end": 74, "i_start": 10, "i_end": 10}}], "id": 3200}, {"sent": "furthermore , we calculate the exponents by the ordinary least square method .", "tokens": ["furthermore", ",", "we", "calculate", "the", "exponents", "by", "the", "ordinary", "least", "square", "method", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "calculate", "start": 17, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "calculate", "start": 17, "end": 26, "i_start": 3, "i_end": 3}}], "id": 3201}, {"sent": "latent dirichlet allocation is one of the most popular and well-known topic models .", "tokens": ["latent", "dirichlet", "allocation", "is", "one", "of", "the", "most", "popular", "and", "well", "-", "known", "topic", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "latent dirichlet allocation", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 3, "i_end": 3}}], "id": 3202}, {"sent": "recently , convolutional neural networks -based methods achieve great success in image classification tasks .", "tokens": ["recently", ",", "convolutional", "neural", "networks", "-based", "methods", "achieve", "great", "success", "in", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks -based methods", "start": 11, "end": 55, "i_start": 2, "i_end": 6}, "verb": {"text": "achieve", "start": 56, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "methods", "start": 48, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "achieve", "start": 56, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "methods", "start": 48, "end": 55, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 70, "end": 77, "i_start": 9, "i_end": 9}}], "id": 3203}, {"sent": "on the other hand , some inverse procedural modeling approaches process real-world data to extract realistic representations .", "tokens": ["on", "the", "other", "hand", ",", "some", "inverse", "procedural", "modeling", "approaches", "process", "real", "-", "world", "data", "to", "extract", "realistic", "representations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "some inverse procedural modeling approaches", "start": 20, "end": 63, "i_start": 5, "i_end": 9}, "verb": {"text": "process", "start": 64, "end": 71, "i_start": 10, "i_end": 10}}, {"character": {"text": "approaches", "start": 53, "end": 63, "i_start": 9, "i_end": 9}, "action": {"text": "process", "start": 64, "end": 71, "i_start": 10, "i_end": 10}}, {"character": {"text": "approaches", "start": 53, "end": 63, "i_start": 9, "i_end": 9}, "action": {"text": "extract", "start": 91, "end": 98, "i_start": 16, "i_end": 16}}], "id": 3204}, {"sent": "therefore , to derive more accurate implications for new physics from fine-tuning arguments , one should consider specific possibilities for physics beyond the sm .", "tokens": ["therefore", ",", "to", "derive", "more", "accurate", "implications", "for", "new", "physics", "from", "fine", "-", "tuning", "arguments", ",", "one", "should", "consider", "specific", "possibilities", "for", "physics", "beyond", "the", "sm", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "one", "start": 94, "end": 97, "i_start": 16, "i_end": 16}, "verb": {"text": "should consider", "start": 98, "end": 113, "i_start": 17, "i_end": 18}}, {"character": {"text": "one", "start": 94, "end": 97, "i_start": 16, "i_end": 16}, "action": {"text": "consider", "start": 105, "end": 113, "i_start": 18, "i_end": 18}}, {"character": {"text": "one", "start": 94, "end": 97, "i_start": 16, "i_end": 16}, "action": {"text": "derive", "start": 15, "end": 21, "i_start": 3, "i_end": 3}}], "id": 3205}, {"sent": "superscripts in column 1 denote the source classification .", "tokens": ["superscripts", "in", "column", "1", "denote", "the", "source", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "superscripts in column 1", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "denote", "start": 25, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "superscripts", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 25, "end": 31, "i_start": 4, "i_end": 4}}], "id": 3206}, {"sent": "we evaluate our approach on two popular action recognition benchmarks , namely ucf-101 .", "tokens": ["we", "evaluate", "our", "approach", "on", "two", "popular", "action", "recognition", "benchmarks", ",", "namely", "ucf-101", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "approach", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3207}, {"sent": "the interpretation for this observation requires further study .", "tokens": ["the", "interpretation", "for", "this", "observation", "requires", "further", "study", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the interpretation for this observation", "start": 0, "end": 39, "i_start": 0, "i_end": 4}, "verb": {"text": "requires", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "interpretation", "start": 4, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "requires", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}], "id": 3208}, {"sent": "then we use madgraph 5 for hadronization and detector simulations .", "tokens": ["then", "we", "use", "madgraph", "5", "for", "hadronization", "and", "detector", "simulations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}], "id": 3209}, {"sent": "superscripts d or b denote only dressed or bare vertices , respectively , whereas no superscript refers to both .", "tokens": ["superscripts", "d", "or", "b", "denote", "only", "dressed", "or", "bare", "vertices", ",", "respectively", ",", "whereas", "no", "superscript", "refers", "to", "both", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "superscripts", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 20, "end": 26, "i_start": 4, "i_end": 4}}], "id": 3210}, {"sent": "various generative target appearance modelling algorithms have been proposed such as online density estimation .", "tokens": ["various", "generative", "target", "appearance", "modelling", "algorithms", "have", "been", "proposed", "such", "as", "online", "density", "estimation", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "various generative target appearance modelling algorithms", "start": 0, "end": 57, "i_start": 0, "i_end": 5}, "verb": {"text": "have been proposed", "start": 58, "end": 76, "i_start": 6, "i_end": 8}}, {"character": {"text": "algorithms", "start": 47, "end": 57, "i_start": 5, "i_end": 5}, "action": {"text": "modelling", "start": 37, "end": 46, "i_start": 4, "i_end": 4}}], "id": 3211}, {"sent": "one popular class of deep learning models is deep neural networks , which has been widely adopted in many artificial intelligence applications , such as image recognition .", "tokens": ["one", "popular", "class", "of", "deep", "learning", "models", "is", "deep", "neural", "networks", ",", "which", "has", "been", "widely", "adopted", "in", "many", "artificial", "intelligence", "applications", ",", "such", "as", "image", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one popular class of deep learning models", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 42, "end": 44, "i_start": 7, "i_end": 7}}], "id": 3212}, {"sent": "t he hidden markov model is a standard tool in many applications , including signal processing and speech recognition .", "tokens": ["t", "he", "hidden", "markov", "model", "is", "a", "standard", "tool", "in", "many", "applications", ",", "including", "signal", "processing", "and", "speech", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "t he hidden markov model", "start": 0, "end": 24, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 5, "i_end": 5}}], "id": 3213}, {"sent": "we leverage object detection module with pretrained resnet-101 to produce the region-level representation .", "tokens": ["we", "leverage", "object", "detection", "module", "with", "pretrained", "resnet-101", "to", "produce", "the", "region", "-", "level", "representation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "leverage", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "leverage", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "module", "start": 29, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "detection", "start": 19, "end": 28, "i_start": 3, "i_end": 3}}], "id": 3214}, {"sent": "the non-orthogonal multiple access has drawn great attention as a promising technology for improving the spectral efficiency for the next generation mobile communication networks .", "tokens": ["the", "non", "-", "orthogonal", "multiple", "access", "has", "drawn", "great", "attention", "as", "a", "promising", "technology", "for", "improving", "the", "spectral", "efficiency", "for", "the", "next", "generation", "mobile", "communication", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the non-orthogonal multiple access", "start": 0, "end": 34, "i_start": 0, "i_end": 5}, "verb": {"text": "has drawn", "start": 35, "end": 44, "i_start": 6, "i_end": 7}}, {"character": {"text": "access", "start": 28, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "drawn", "start": 39, "end": 44, "i_start": 7, "i_end": 7}}, {"character": {"text": "technology", "start": 76, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "promising", "start": 66, "end": 75, "i_start": 12, "i_end": 12}}], "id": 3215}, {"sent": "note that they use asp , which creates a different \u03c6 compared to coded mask .", "tokens": ["note", "that", "they", "use", "asp", ",", "which", "creates", "a", "different", "\u03c6", "compared", "to", "coded", "mask", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 10, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "they", "start": 10, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "use", "start": 15, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "they", "start": 10, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 15, "end": 18, "i_start": 3, "i_end": 3}}], "id": 3216}, {"sent": "in 2017 , the parseme group conducted a shared task with data spanning 18 languages 3 , focusing on several classes of verbal mwes .", "tokens": ["in", "2017", ",", "the", "parseme", "group", "conducted", "a", "shared", "task", "with", "data", "spanning", "18", "languages", "3", ",", "focusing", "on", "several", "classes", "of", "verbal", "mwes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the parseme group", "start": 10, "end": 27, "i_start": 3, "i_end": 5}, "verb": {"text": "conducted", "start": 28, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "group", "start": 22, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "conducted", "start": 28, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "data", "start": 57, "end": 61, "i_start": 11, "i_end": 11}, "action": {"text": "spanning", "start": 62, "end": 70, "i_start": 12, "i_end": 12}}, {"character": {"text": "task", "start": 47, "end": 51, "i_start": 9, "i_end": 9}, "action": {"text": "focusing", "start": 88, "end": 96, "i_start": 17, "i_end": 17}}], "id": 3217}, {"sent": "in addition to using cross-module attention , we apply self-attention within each module .", "tokens": ["in", "addition", "to", "using", "cross", "-", "module", "attention", ",", "we", "apply", "self", "-", "attention", "within", "each", "module", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 46, "end": 48, "i_start": 9, "i_end": 9}, "verb": {"text": "apply", "start": 49, "end": 54, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 46, "end": 48, "i_start": 9, "i_end": 9}, "action": {"text": "apply", "start": 49, "end": 54, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 46, "end": 48, "i_start": 9, "i_end": 9}, "action": {"text": "attention", "start": 34, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 46, "end": 48, "i_start": 9, "i_end": 9}, "action": {"text": "using", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 46, "end": 48, "i_start": 9, "i_end": 9}, "action": {"text": "attention", "start": 60, "end": 69, "i_start": 13, "i_end": 13}}, {"character": {"text": "attention", "start": 60, "end": 69, "i_start": 13, "i_end": 13}, "action": {"text": "cross", "start": 21, "end": 26, "i_start": 4, "i_end": 4}}], "id": 3218}, {"sent": "deep convolutional neural networks have achieved great success in various computer vision tasks , including object classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "various", "computer", "vision", "tasks", ",", "including", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}], "id": 3219}, {"sent": "furthermore , mmwave technology has also been considered for deploying dense cellular networks characterized by high data rates .", "tokens": ["furthermore", ",", "mmwave", "technology", "has", "also", "been", "considered", "for", "deploying", "dense", "cellular", "networks", "characterized", "by", "high", "data", "rates", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "mmwave technology", "start": 14, "end": 31, "i_start": 2, "i_end": 3}, "verb": {"text": "been considered", "start": 41, "end": 56, "i_start": 6, "i_end": 7}}, {"subject": {"text": "mmwave technology", "start": 14, "end": 31, "i_start": 2, "i_end": 3}, "verb": {"text": "has", "start": 32, "end": 35, "i_start": 4, "i_end": 4}}], "id": 3220}, {"sent": "the particle-flow algorithm aims to reconstruct each individual particle in an event with an optimized combination of information from the various elements of the cms detector .", "tokens": ["the", "particle", "-", "flow", "algorithm", "aims", "to", "reconstruct", "each", "individual", "particle", "in", "an", "event", "with", "an", "optimized", "combination", "of", "information", "from", "the", "various", "elements", "of", "the", "cms", "detector", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the particle-flow algorithm", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "aims", "start": 28, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "algorithm", "start": 18, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "aims", "start": 28, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "algorithm", "start": 18, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "reconstruct", "start": 36, "end": 47, "i_start": 7, "i_end": 7}}], "id": 3221}, {"sent": "the asterisk denotes the point where the superoutburst is triggered .", "tokens": ["the", "asterisk", "denotes", "the", "point", "where", "the", "superoutburst", "is", "triggered", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the asterisk", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "denotes", "start": 13, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "asterisk", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denotes", "start": 13, "end": 20, "i_start": 2, "i_end": 2}}], "id": 3222}, {"sent": "we demonstrate this model using a graph convolutional network encoder and a simple inner product decoder .", "tokens": ["we", "demonstrate", "this", "model", "using", "a", "graph", "convolutional", "network", "encoder", "and", "a", "simple", "inner", "product", "decoder", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "demonstrate", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"subject": {"text": "this model", "start": 15, "end": 25, "i_start": 2, "i_end": 3}, "verb": {"text": "using", "start": 26, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "demonstrate", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 26, "end": 31, "i_start": 4, "i_end": 4}}], "id": 3223}, {"sent": "powerful deep neural networks have been created and investigated for high-level computer vision tasks such as image classification .", "tokens": ["powerful", "deep", "neural", "networks", "have", "been", "created", "and", "investigated", "for", "high", "-", "level", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "powerful deep neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "have been created", "start": 30, "end": 47, "i_start": 4, "i_end": 6}}, {"subject": {"text": "powerful deep neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "investigated", "start": 52, "end": 64, "i_start": 8, "i_end": 8}}], "id": 3224}, {"sent": "it handles multiple adapters simultaneously .", "tokens": ["it", "handles", "multiple", "adapters", "simultaneously", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "handles", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "handles", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 3225}, {"sent": "we implemented our approach as a custom layer in the matconvnet framework .", "tokens": ["we", "implemented", "our", "approach", "as", "a", "custom", "layer", "in", "the", "matconvnet", "framework", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implemented", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implemented", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "approach", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}], "id": 3226}, {"sent": "this library is a set of a definite amount of simulated pulse shapes .", "tokens": ["this", "library", "is", "a", "set", "of", "a", "definite", "amount", "of", "simulated", "pulse", "shapes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this library", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 3227}, {"sent": "recent developments in deep learning have demonstrated impressive capabilities in learning useful features from images .", "tokens": ["recent", "developments", "in", "deep", "learning", "have", "demonstrated", "impressive", "capabilities", "in", "learning", "useful", "features", "from", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent developments in deep learning", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "have demonstrated", "start": 37, "end": 54, "i_start": 5, "i_end": 6}}, {"character": {"text": "developments", "start": 7, "end": 19, "i_start": 1, "i_end": 1}, "action": {"text": "demonstrated", "start": 42, "end": 54, "i_start": 6, "i_end": 6}}, {"character": {"text": "capabilities", "start": 66, "end": 78, "i_start": 8, "i_end": 8}, "action": {"text": "impressive", "start": 55, "end": 65, "i_start": 7, "i_end": 7}}], "id": 3228}, {"sent": "fine-tuning is a common strategy in transfer learning with neural networks .", "tokens": ["fine", "-", "tuning", "is", "a", "common", "strategy", "in", "transfer", "learning", "with", "neural", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "fine-tuning", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 3, "i_end": 3}}], "id": 3229}, {"sent": "in recent years , deep neural networks have achieved great success in a variety of machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "achieved", "great", "success", "in", "a", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}], "id": 3230}, {"sent": "as mentioned earlier , we can incorporate a memory factor into the update of t and hence , guarantee the convergence of algorithm i .", "tokens": ["as", "mentioned", "earlier", ",", "we", "can", "incorporate", "a", "memory", "factor", "into", "the", "update", "of", "t", "and", "hence", ",", "guarantee", "the", "convergence", "of", "algorithm", "i", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "verb": {"text": "can incorporate", "start": 26, "end": 41, "i_start": 5, "i_end": 6}}, {"subject": {"text": "we", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "verb": {"text": "guarantee", "start": 91, "end": 100, "i_start": 18, "i_end": 18}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "incorporate", "start": 30, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "guarantee", "start": 91, "end": 100, "i_start": 18, "i_end": 18}}], "id": 3231}, {"sent": "an isomorphism is a morphism that consists of unitaries .", "tokens": ["an", "isomorphism", "is", "a", "morphism", "that", "consists", "of", "unitaries", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an isomorphism", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 3232}, {"sent": "compared to traditional approaches , recent methods have exploited convolutional neural networks to obtain dramatic improvements in error rates .", "tokens": ["compared", "to", "traditional", "approaches", ",", "recent", "methods", "have", "exploited", "convolutional", "neural", "networks", "to", "obtain", "dramatic", "improvements", "in", "error", "rates", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent methods", "start": 37, "end": 51, "i_start": 5, "i_end": 6}, "verb": {"text": "have exploited", "start": 52, "end": 66, "i_start": 7, "i_end": 8}}, {"character": {"text": "methods", "start": 44, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "exploited", "start": 57, "end": 66, "i_start": 8, "i_end": 8}}, {"character": {"text": "methods", "start": 44, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "obtain", "start": 100, "end": 106, "i_start": 13, "i_end": 13}}], "id": 3233}, {"sent": "in subsequent works it has been shown that linear network coding is sufficient to achieve the capacity of multicast networks .", "tokens": ["in", "subsequent", "works", "it", "has", "been", "shown", "that", "linear", "network", "coding", "is", "sufficient", "to", "achieve", "the", "capacity", "of", "multicast", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "verb": {"text": "has been shown", "start": 23, "end": 37, "i_start": 4, "i_end": 6}}, {"subject": {"text": "it", "start": 20, "end": 22, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 65, "end": 67, "i_start": 11, "i_end": 11}}, {"character": {"text": "network", "start": 50, "end": 57, "i_start": 9, "i_end": 9}, "action": {"text": "achieve", "start": 82, "end": 89, "i_start": 14, "i_end": 14}}], "id": 3234}, {"sent": "millimeter waves , for cellular communications , is one of the main technological innovations brought by fifth generation wireless networks .", "tokens": ["millimeter", "waves", ",", "for", "cellular", "communications", ",", "is", "one", "of", "the", "main", "technological", "innovations", "brought", "by", "fifth", "generation", "wireless", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "millimeter waves", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 49, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 131, "end": 139, "i_start": 19, "i_end": 19}, "action": {"text": "brought", "start": 94, "end": 101, "i_start": 14, "i_end": 14}}], "id": 3235}, {"sent": "the genus of c is the number of interior lattice points of subdivf .", "tokens": ["the", "genus", "of", "c", "is", "the", "number", "of", "interior", "lattice", "points", "of", "subdivf", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the genus of c", "start": 0, "end": 14, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 4, "i_end": 4}}], "id": 3236}, {"sent": "the elu activation function are used at the output of every layer .", "tokens": ["the", "elu", "activation", "function", "are", "used", "at", "the", "output", "of", "every", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the elu activation function", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "are used", "start": 28, "end": 36, "i_start": 4, "i_end": 5}}], "id": 3237}, {"sent": "reinforcement learning-based control has recently achieved impressive successes in games .", "tokens": ["reinforcement", "learning", "-", "based", "control", "has", "recently", "achieved", "impressive", "successes", "in", "games", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning-based control", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "achieved", "start": 50, "end": 58, "i_start": 7, "i_end": 7}}, {"subject": {"text": "reinforcement learning-based control", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "has", "start": 37, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "control", "start": 29, "end": 36, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 50, "end": 58, "i_start": 7, "i_end": 7}}, {"character": {"text": "control", "start": 29, "end": 36, "i_start": 4, "i_end": 4}, "action": {"text": "successes", "start": 70, "end": 79, "i_start": 9, "i_end": 9}}, {"character": {"text": "successes", "start": 70, "end": 79, "i_start": 9, "i_end": 9}, "action": {"text": "impressive", "start": 59, "end": 69, "i_start": 8, "i_end": 8}}], "id": 3238}, {"sent": "recent studies by debard et al suggest that even in a long term experimental set up only a few real falls may be captured .", "tokens": ["recent", "studies", "by", "debard", "et", "al", "suggest", "that", "even", "in", "a", "long", "term", "experimental", "set", "up", "only", "a", "few", "real", "falls", "may", "be", "captured", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent studies by debard et al", "start": 0, "end": 30, "i_start": 0, "i_end": 5}, "verb": {"text": "suggest", "start": 31, "end": 38, "i_start": 6, "i_end": 6}}, {"subject": {"text": "experimental", "start": 64, "end": 76, "i_start": 13, "i_end": 13}, "verb": {"text": "set", "start": 77, "end": 80, "i_start": 14, "i_end": 14}}, {"subject": {"text": "only a few real falls", "start": 84, "end": 105, "i_start": 16, "i_end": 20}, "verb": {"text": "captured", "start": 113, "end": 121, "i_start": 23, "i_end": 23}}, {"character": {"text": "studies", "start": 7, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "suggest", "start": 31, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "debard", "start": 18, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "studies", "start": 7, "end": 14, "i_start": 1, "i_end": 1}}], "id": 3239}, {"sent": "the role of tactile feedback compared to the kinesthetic in haptics has been recently discussed and exploited for example in where the problem of missed kinesthetic feedback in wearable haptics is discussed .", "tokens": ["the", "role", "of", "tactile", "feedback", "compared", "to", "the", "kinesthetic", "in", "haptics", "has", "been", "recently", "discussed", "and", "exploited", "for", "example", "in", "where", "the", "problem", "of", "missed", "kinesthetic", "feedback", "in", "wearable", "haptics", "is", "discussed", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the role of tactile feedback compared to the kinesthetic in haptics", "start": 0, "end": 67, "i_start": 0, "i_end": 10}, "verb": {"text": "discussed", "start": 86, "end": 95, "i_start": 14, "i_end": 14}}, {"subject": {"text": "the role of tactile feedback compared to the kinesthetic in haptics", "start": 0, "end": 67, "i_start": 0, "i_end": 10}, "verb": {"text": "has been", "start": 68, "end": 76, "i_start": 11, "i_end": 12}}, {"subject": {"text": "the role of tactile feedback compared to the kinesthetic in haptics", "start": 0, "end": 67, "i_start": 0, "i_end": 10}, "verb": {"text": "exploited", "start": 100, "end": 109, "i_start": 16, "i_end": 16}}], "id": 3240}, {"sent": "belle is a large-solid-angle magnetic spectrometer that consists of a three-layer silicon vertex detector .", "tokens": ["belle", "is", "a", "large", "-", "solid", "-", "angle", "magnetic", "spectrometer", "that", "consists", "of", "a", "three", "-", "layer", "silicon", "vertex", "detector", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "belle", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3241}, {"sent": "the trainable parameters are initialized using the glorot algorithm .", "tokens": ["the", "trainable", "parameters", "are", "initialized", "using", "the", "glorot", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the trainable parameters", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "are initialized", "start": 25, "end": 40, "i_start": 3, "i_end": 4}}], "id": 3242}, {"sent": "the bispectrum is the fourier transform of the triple correlation , which is similar to the familiar autocorrelation but has one additional shift .", "tokens": ["the", "bispectrum", "is", "the", "fourier", "transform", "of", "the", "triple", "correlation", ",", "which", "is", "similar", "to", "the", "familiar", "autocorrelation", "but", "has", "one", "additional", "shift", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the bispectrum", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 3243}, {"sent": "as such , we adapt the standard soft-input viterbi decoding algorithm for pnc and mud decoding .", "tokens": ["as", "such", ",", "we", "adapt", "the", "standard", "soft", "-", "input", "viterbi", "decoding", "algorithm", "for", "pnc", "and", "mud", "decoding", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 3, "i_end": 3}, "verb": {"text": "adapt", "start": 13, "end": 18, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 3, "i_end": 3}, "action": {"text": "adapt", "start": 13, "end": 18, "i_start": 4, "i_end": 4}}], "id": 3244}, {"sent": "the generalized gradient approximation was used in conjunction with the perdew , burke , and ernzerhof density functional .", "tokens": ["the", "generalized", "gradient", "approximation", "was", "used", "in", "conjunction", "with", "the", "perdew", ",", "burke", ",", "and", "ernzerhof", "density", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation", "start": 0, "end": 38, "i_start": 0, "i_end": 3}, "verb": {"text": "was used", "start": 39, "end": 47, "i_start": 4, "i_end": 5}}], "id": 3245}, {"sent": "lcd codes can be used to protect information against side channel attacks .", "tokens": ["lcd", "codes", "can", "be", "used", "to", "protect", "information", "against", "side", "channel", "attacks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "lcd codes", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "can be used", "start": 10, "end": 21, "i_start": 2, "i_end": 4}}, {"character": {"text": "codes", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "protect", "start": 25, "end": 32, "i_start": 6, "i_end": 6}}], "id": 3246}, {"sent": "we follow the standard practice for data augmentation and optimization .", "tokens": ["we", "follow", "the", "standard", "practice", "for", "data", "augmentation", "and", "optimization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 3247}, {"sent": "it is believed that deeper networks produce better recognition results , or a set of latent visual attributes .", "tokens": ["it", "is", "believed", "that", "deeper", "networks", "produce", "better", "recognition", "results", ",", "or", "a", "set", "of", "latent", "visual", "attributes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is believed", "start": 3, "end": 14, "i_start": 1, "i_end": 2}}, {"subject": {"text": "deeper networks", "start": 20, "end": 35, "i_start": 4, "i_end": 5}, "verb": {"text": "produce", "start": 36, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 27, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "produce", "start": 36, "end": 43, "i_start": 6, "i_end": 6}}], "id": 3248}, {"sent": "deep learning has led to significant improvements in many computer vision tasks such as image classification .", "tokens": ["deep", "learning", "has", "led", "to", "significant", "improvements", "in", "many", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has led", "start": 14, "end": 21, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 18, "end": 21, "i_start": 3, "i_end": 3}}], "id": 3249}, {"sent": "for the depth network , we use the resnet-50 activation functions .", "tokens": ["for", "the", "depth", "network", ",", "we", "use", "the", "resnet-50", "activation", "functions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 27, "end": 30, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 27, "end": 30, "i_start": 6, "i_end": 6}}], "id": 3250}, {"sent": "the inhomogeneity is considered both at the on-site potential and at the coupling terms .", "tokens": ["the", "inhomogeneity", "is", "considered", "both", "at", "the", "on", "-", "site", "potential", "and", "at", "the", "coupling", "terms", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the inhomogeneity", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is considered", "start": 18, "end": 31, "i_start": 2, "i_end": 3}}], "id": 3251}, {"sent": "scott et al proposed a text to image synthesis approach using a deep convolutional generative adversarial network conditioned on text features .", "tokens": ["scott", "et", "al", "proposed", "a", "text", "to", "image", "synthesis", "approach", "using", "a", "deep", "convolutional", "generative", "adversarial", "network", "conditioned", "on", "text", "features", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "scott et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "scott", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "approach", "start": 47, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "using", "start": 56, "end": 61, "i_start": 10, "i_end": 10}}], "id": 3252}, {"sent": "be an interval polynomial subsemiring of g .", "tokens": ["be", "an", "interval", "polynomial", "subsemiring", "of", "g", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3253}, {"sent": "we refer readers to for details about properties and significance of these contour properties .", "tokens": ["we", "refer", "readers", "to", "for", "details", "about", "properties", "and", "significance", "of", "these", "contour", "properties", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3254}, {"sent": "in , the authors employ vhcs to find feasible closed orbits of underactuated mechanical systems .", "tokens": ["in", ",", "the", "authors", "employ", "vhcs", "to", "find", "feasible", "closed", "orbits", "of", "underactuated", "mechanical", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 5, "end": 16, "i_start": 2, "i_end": 3}, "verb": {"text": "employ", "start": 17, "end": 23, "i_start": 4, "i_end": 4}}], "id": 3255}, {"sent": "since f -gravity is a gauge theory , like general relativity , it is crucial the choice of suitable coordinates in order to correctly formulate the problem .", "tokens": ["since", "f", "-gravity", "is", "a", "gauge", "theory", ",", "like", "general", "relativity", ",", "it", "is", "crucial", "the", "choice", "of", "suitable", "coordinates", "in", "order", "to", "correctly", "formulate", "the", "problem", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 63, "end": 65, "i_start": 12, "i_end": 12}, "verb": {"text": "is", "start": 66, "end": 68, "i_start": 13, "i_end": 13}}], "id": 3256}, {"sent": "for more complicated functions f , we use the potentially more efficient low rank algorithm described in to compute an expansion of the form with legendre polynomials replaced by chebyshev polynomials .", "tokens": ["for", "more", "complicated", "functions", "f", ",", "we", "use", "the", "potentially", "more", "efficient", "low", "rank", "algorithm", "described", "in", "to", "compute", "an", "expansion", "of", "the", "form", "with", "legendre", "polynomials", "replaced", "by", "chebyshev", "polynomials", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 35, "end": 37, "i_start": 6, "i_end": 6}, "verb": {"text": "use", "start": 38, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 35, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "use", "start": 38, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 35, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "compute", "start": 108, "end": 115, "i_start": 18, "i_end": 18}}], "id": 3257}, {"sent": "in the past few years , deep neural network has shown its extraordinary ability in solving many complex machine learning problems , such as image classification .", "tokens": ["in", "the", "past", "few", "years", ",", "deep", "neural", "network", "has", "shown", "its", "extraordinary", "ability", "in", "solving", "many", "complex", "machine", "learning", "problems", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural network", "start": 24, "end": 43, "i_start": 6, "i_end": 8}, "verb": {"text": "has shown", "start": 44, "end": 53, "i_start": 9, "i_end": 10}}, {"character": {"text": "network", "start": 36, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "shown", "start": 48, "end": 53, "i_start": 10, "i_end": 10}}, {"character": {"text": "network", "start": 36, "end": 43, "i_start": 8, "i_end": 8}, "action": {"text": "solving", "start": 83, "end": 90, "i_start": 15, "i_end": 15}}], "id": 3258}, {"sent": "we refer to our algorithm as weighted k-means because it is based on k-means clustering .", "tokens": ["we", "refer", "to", "our", "algorithm", "as", "weighted", "k", "-", "means", "because", "it", "is", "based", "on", "k", "-", "means", "clustering", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "based", "start": 60, "end": 65, "i_start": 13, "i_end": 13}, "action": {"text": "because", "start": 46, "end": 53, "i_start": 10, "i_end": 10}}], "id": 3259}, {"sent": "the enhancement is a result of interchanging resonances between neutrino and antineutrino ensembles due to resonance waves passing through the neutrino and antineutrino spectrum .", "tokens": ["the", "enhancement", "is", "a", "result", "of", "interchanging", "resonances", "between", "neutrino", "and", "antineutrino", "ensembles", "due", "to", "resonance", "waves", "passing", "through", "the", "neutrino", "and", "antineutrino", "spectrum", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the enhancement", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "waves", "start": 117, "end": 122, "i_start": 16, "i_end": 16}, "action": {"text": "resonance", "start": 107, "end": 116, "i_start": 15, "i_end": 15}}], "id": 3260}, {"sent": "the category is called special if each of its automorphisms is special .", "tokens": ["the", "category", "is", "called", "special", "if", "each", "of", "its", "automorphisms", "is", "special", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the category", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is called", "start": 13, "end": 22, "i_start": 2, "i_end": 3}}], "id": 3261}, {"sent": "there one finds that the phase diagram depends only on the ratio of \u03c7 to the charge on the polymer , at least in the absence of fluctuations .", "tokens": ["there", "one", "finds", "that", "the", "phase", "diagram", "depends", "only", "on", "the", "ratio", "of", "\u03c7", "to", "the", "charge", "on", "the", "polymer", ",", "at", "least", "in", "the", "absence", "of", "fluctuations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 6, "end": 9, "i_start": 1, "i_end": 1}, "verb": {"text": "finds", "start": 10, "end": 15, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the phase diagram", "start": 21, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "depends", "start": 39, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "one", "start": 6, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "finds", "start": 10, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "diagram", "start": 31, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "depends", "start": 39, "end": 46, "i_start": 7, "i_end": 7}}], "id": 3262}, {"sent": "models based on neural networks , especially deep convolutional neural networks and recurrent neural networks , have achieved state-of-the-art results in various computer vision tasks .", "tokens": ["models", "based", "on", "neural", "networks", ",", "especially", "deep", "convolutional", "neural", "networks", "and", "recurrent", "neural", "networks", ",", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "results", "in", "various", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "models based on neural networks", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "have achieved", "start": 112, "end": 125, "i_start": 16, "i_end": 17}}, {"character": {"text": "models", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "achieved", "start": 117, "end": 125, "i_start": 17, "i_end": 17}}], "id": 3263}, {"sent": "over the last decade , machine learning algorithms have achieved impressive results providing solutions to practical large-scale problems .", "tokens": ["over", "the", "last", "decade", ",", "machine", "learning", "algorithms", "have", "achieved", "impressive", "results", "providing", "solutions", "to", "practical", "large", "-", "scale", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "machine learning algorithms", "start": 23, "end": 50, "i_start": 5, "i_end": 7}, "verb": {"text": "have achieved", "start": 51, "end": 64, "i_start": 8, "i_end": 9}}, {"character": {"text": "algorithms", "start": 40, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 56, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "algorithms", "start": 40, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "learning", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "algorithms", "start": 40, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "providing", "start": 84, "end": 93, "i_start": 12, "i_end": 12}}, {"character": {"text": "results", "start": 76, "end": 83, "i_start": 11, "i_end": 11}, "action": {"text": "impressive", "start": 65, "end": 75, "i_start": 10, "i_end": 10}}], "id": 3264}, {"sent": "weights were initialized following the recommendations of for the logistic activation layer .", "tokens": ["weights", "were", "initialized", "following", "the", "recommendations", "of", "for", "the", "logistic", "activation", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "weights", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "were initialized", "start": 8, "end": 24, "i_start": 1, "i_end": 2}}, {"character": {"text": "layer", "start": 86, "end": 91, "i_start": 11, "i_end": 11}, "action": {"text": "recommendations", "start": 39, "end": 54, "i_start": 5, "i_end": 5}}, {"character": {"text": "layer", "start": 86, "end": 91, "i_start": 11, "i_end": 11}, "action": {"text": "activation", "start": 75, "end": 85, "i_start": 10, "i_end": 10}}], "id": 3265}, {"sent": "the averaged atomic displacement amplitude , \u03c3 , can be calculated as function of t .", "tokens": ["the", "averaged", "atomic", "displacement", "amplitude", ",", "\u03c3", ",", "can", "be", "calculated", "as", "function", "of", "t", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the averaged atomic displacement amplitude", "start": 0, "end": 42, "i_start": 0, "i_end": 4}, "verb": {"text": "can be calculated", "start": 49, "end": 66, "i_start": 8, "i_end": 10}}], "id": 3266}, {"sent": "the complexity of the local hamiltonian problem .", "tokens": ["the", "complexity", "of", "the", "local", "hamiltonian", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3267}, {"sent": "low-density parity-check codes are a class of iteratively decoded capacity-approaching codes .", "tokens": ["low", "-", "density", "parity", "-", "check", "codes", "are", "a", "class", "of", "iteratively", "decoded", "capacity", "-", "approaching", "codes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "low-density parity-check codes", "start": 0, "end": 30, "i_start": 0, "i_end": 6}, "verb": {"text": "are", "start": 31, "end": 34, "i_start": 7, "i_end": 7}}, {"character": {"text": "codes", "start": 87, "end": 92, "i_start": 16, "i_end": 16}, "action": {"text": "check", "start": 19, "end": 24, "i_start": 5, "i_end": 5}}], "id": 3268}, {"sent": "deep convolutional neural networks have led to a series of breakthrough for visual tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "led", "to", "a", "series", "of", "breakthrough", "for", "visual", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have led", "start": 35, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "led", "start": 40, "end": 43, "i_start": 5, "i_end": 5}}], "id": 3269}, {"sent": "each one of such coefficients is a function of stress anisotropy .", "tokens": ["each", "one", "of", "such", "coefficients", "is", "a", "function", "of", "stress", "anisotropy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each one of such coefficients", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "anisotropy", "start": 54, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "function", "start": 35, "end": 43, "i_start": 7, "i_end": 7}}], "id": 3270}, {"sent": "in particular , convolutional neural network architectures have enabled superior performance over alternative approaches in classification and pattern recognition problems in computer vision .", "tokens": ["in", "particular", ",", "convolutional", "neural", "network", "architectures", "have", "enabled", "superior", "performance", "over", "alternative", "approaches", "in", "classification", "and", "pattern", "recognition", "problems", "in", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural network architectures", "start": 16, "end": 58, "i_start": 3, "i_end": 6}, "verb": {"text": "have enabled", "start": 59, "end": 71, "i_start": 7, "i_end": 8}}, {"character": {"text": "architectures", "start": 45, "end": 58, "i_start": 6, "i_end": 6}, "action": {"text": "enabled", "start": 64, "end": 71, "i_start": 8, "i_end": 8}}], "id": 3271}, {"sent": "for style transfer tasks , the affine parameters are used to control the global style of the output , and hence are uniform across spatial coordinates .", "tokens": ["for", "style", "transfer", "tasks", ",", "the", "affine", "parameters", "are", "used", "to", "control", "the", "global", "style", "of", "the", "output", ",", "and", "hence", "are", "uniform", "across", "spatial", "coordinates", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the affine parameters", "start": 27, "end": 48, "i_start": 5, "i_end": 7}, "verb": {"text": "are used", "start": 49, "end": 57, "i_start": 8, "i_end": 9}}, {"character": {"text": "parameters", "start": 38, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "control", "start": 61, "end": 68, "i_start": 11, "i_end": 11}}], "id": 3272}, {"sent": "the residual networks have shown excellent performances in many computer vision tasks .", "tokens": ["the", "residual", "networks", "have", "shown", "excellent", "performances", "in", "many", "computer", "vision", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the residual networks", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 22, "end": 32, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 13, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "performances", "start": 43, "end": 55, "i_start": 6, "i_end": 6}}], "id": 3273}, {"sent": "it should be straightforward to extend our calculation to this case .", "tokens": ["it", "should", "be", "straightforward", "to", "extend", "our", "calculation", "to", "this", "case", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "should be", "start": 3, "end": 12, "i_start": 1, "i_end": 2}}], "id": 3274}, {"sent": "especially , many approaches based on convolutional neural networks made significant advances in large-scale image classification .", "tokens": ["especially", ",", "many", "approaches", "based", "on", "convolutional", "neural", "networks", "made", "significant", "advances", "in", "large", "-", "scale", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "many approaches based on convolutional neural networks", "start": 13, "end": 67, "i_start": 2, "i_end": 8}, "verb": {"text": "made", "start": 68, "end": 72, "i_start": 9, "i_end": 9}}, {"character": {"text": "approaches", "start": 18, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "advances", "start": 85, "end": 93, "i_start": 11, "i_end": 11}}], "id": 3275}, {"sent": "the data were calibrated and reduced using the miriad package .", "tokens": ["the", "data", "were", "calibrated", "and", "reduced", "using", "the", "miriad", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "were calibrated", "start": 9, "end": 24, "i_start": 2, "i_end": 3}}, {"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "reduced", "start": 29, "end": 36, "i_start": 5, "i_end": 5}}], "id": 3276}, {"sent": "convolutional neural networks have achieved roughly human-level or better performance on vision tasks , particularly classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "roughly", "human", "-", "level", "or", "better", "performance", "on", "vision", "tasks", ",", "particularly", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 74, "end": 85, "i_start": 11, "i_end": 11}}], "id": 3277}, {"sent": "super-adiabatic sequence and the nonlinear landau-zener problem .", "tokens": ["super", "-", "adiabatic", "sequence", "and", "the", "nonlinear", "landau", "-", "zener", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3278}, {"sent": "the non-orthogonal multiple access has drawn great attention as a promising technology for improving the spectral efficiency for the next generation mobile communication networks .", "tokens": ["the", "non", "-", "orthogonal", "multiple", "access", "has", "drawn", "great", "attention", "as", "a", "promising", "technology", "for", "improving", "the", "spectral", "efficiency", "for", "the", "next", "generation", "mobile", "communication", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the non-orthogonal multiple access", "start": 0, "end": 34, "i_start": 0, "i_end": 5}, "verb": {"text": "has drawn", "start": 35, "end": 44, "i_start": 6, "i_end": 7}}, {"character": {"text": "access", "start": 28, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "drawn", "start": 39, "end": 44, "i_start": 7, "i_end": 7}}, {"character": {"text": "technology", "start": 76, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "promising", "start": 66, "end": 75, "i_start": 12, "i_end": 12}}], "id": 3279}, {"sent": "a grope is a certain 2-complex , built out of layers of surfaces .", "tokens": ["a", "grope", "is", "a", "certain", "2", "-", "complex", ",", "built", "out", "of", "layers", "of", "surfaces", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a grope", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 2, "i_end": 2}}], "id": 3280}, {"sent": "in string theory there is a preferred frame .", "tokens": ["in", "string", "theory", "there", "is", "a", "preferred", "frame", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 17, "end": 22, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 4, "i_end": 4}}], "id": 3281}, {"sent": "we have included the performance of the algorithm in that maximizes the minimum value of h h n kw k w hk h n k instead .", "tokens": ["we", "have", "included", "the", "performance", "of", "the", "algorithm", "in", "that", "maximizes", "the", "minimum", "value", "of", "h", "h", "n", "k"], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have included", "start": 3, "end": 16, "i_start": 1, "i_end": 2}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "maximizes", "start": 58, "end": 67, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "included", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "algorithm", "start": 40, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "performance", "start": 21, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "performance", "start": 21, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "maximizes", "start": 58, "end": 67, "i_start": 10, "i_end": 10}}], "id": 3282}, {"sent": "the definition of the rees algebra of a finitely generated module m , due to , is in terms of maps from m to free modules .", "tokens": ["the", "definition", "of", "the", "rees", "algebra", "of", "a", "finitely", "generated", "module", "m", ",", "due", "to", ",", "is", "in", "terms", "of", "maps", "from", "m", "to", "free", "modules", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the definition of the rees algebra of a finitely generated module m", "start": 0, "end": 67, "i_start": 0, "i_end": 11}, "verb": {"text": "is", "start": 79, "end": 81, "i_start": 16, "i_end": 16}}], "id": 3283}, {"sent": "nowadays deep learning has been widely spread to an enormous amount of tasks , including computer vision .", "tokens": ["nowadays", "deep", "learning", "has", "been", "widely", "spread", "to", "an", "enormous", "amount", "of", "tasks", ",", "including", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 9, "end": 22, "i_start": 1, "i_end": 2}, "verb": {"text": "spread", "start": 39, "end": 45, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep learning", "start": 9, "end": 22, "i_start": 1, "i_end": 2}, "verb": {"text": "has been", "start": 23, "end": 31, "i_start": 3, "i_end": 4}}], "id": 3284}, {"sent": "recently , deep neural networks achieve excellent performance on difficult problems such as speech recognition .", "tokens": ["recently", ",", "deep", "neural", "networks", "achieve", "excellent", "performance", "on", "difficult", "problems", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "achieve", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "achieve", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "performance", "start": 50, "end": 61, "i_start": 7, "i_end": 7}}], "id": 3285}, {"sent": "some methods infer the 3d scene structure and use geometric transformations to achieve view invariance .", "tokens": ["some", "methods", "infer", "the", "3d", "scene", "structure", "and", "use", "geometric", "transformations", "to", "achieve", "view", "invariance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "some methods", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "infer", "start": 13, "end": 18, "i_start": 2, "i_end": 2}}, {"subject": {"text": "some methods", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "use", "start": 46, "end": 49, "i_start": 8, "i_end": 8}}, {"character": {"text": "methods", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "infer", "start": 13, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "methods", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "use", "start": 46, "end": 49, "i_start": 8, "i_end": 8}}, {"character": {"text": "methods", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "achieve", "start": 79, "end": 86, "i_start": 12, "i_end": 12}}], "id": 3286}, {"sent": "we refer the reader to for a detailed study of banach lattices and positive operators .", "tokens": ["we", "refer", "the", "reader", "to", "for", "a", "detailed", "study", "of", "banach", "lattices", "and", "positive", "operators", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3287}, {"sent": "this formulation relates the topological string free energy to certain quantum spectral problem .", "tokens": ["this", "formulation", "relates", "the", "topological", "string", "free", "energy", "to", "certain", "quantum", "spectral", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this formulation", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "relates", "start": 17, "end": 24, "i_start": 2, "i_end": 2}}], "id": 3288}, {"sent": "the main goal of our paper is the study of several classes of submanifolds of generalized complex manifolds .", "tokens": ["the", "main", "goal", "of", "our", "paper", "is", "the", "study", "of", "several", "classes", "of", "submanifolds", "of", "generalized", "complex", "manifolds", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the main goal of our paper", "start": 0, "end": 26, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 6, "i_end": 6}}], "id": 3289}, {"sent": "onvolutional neural networks have achieved remarkable performance on vision problems such as image classification .", "tokens": ["onvolutional", "neural", "networks", "have", "achieved", "remarkable", "performance", "on", "vision", "problems", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "onvolutional neural networks", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 29, "end": 42, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 20, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 34, "end": 42, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 20, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 54, "end": 65, "i_start": 6, "i_end": 6}}], "id": 3290}, {"sent": "this kind of computing machines was first studied by moore and crutchfield independently .", "tokens": ["this", "kind", "of", "computing", "machines", "was", "first", "studied", "by", "moore", "and", "crutchfield", "independently", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this kind of computing machines", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "studied", "start": 42, "end": 49, "i_start": 7, "i_end": 7}}, {"subject": {"text": "this kind of computing machines", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "was", "start": 32, "end": 35, "i_start": 5, "i_end": 5}}, {"character": {"text": "moore", "start": 53, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "studied", "start": 42, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "crutchfield", "start": 63, "end": 74, "i_start": 11, "i_end": 11}, "action": {"text": "studied", "start": 42, "end": 49, "i_start": 7, "i_end": 7}}], "id": 3291}, {"sent": "vanwyk , higher generation subgroup sets and the \u03c3-invariants of graph groups , comment .", "tokens": ["vanwyk", ",", "higher", "generation", "subgroup", "sets", "and", "the", "\u03c3", "-", "invariants", "of", "graph", "groups", ",", "comment", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "vanwyk", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "comment", "start": 80, "end": 87, "i_start": 15, "i_end": 15}}, {"character": {"text": "sets", "start": 36, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "comment", "start": 80, "end": 87, "i_start": 15, "i_end": 15}}, {"character": {"text": "subgroup", "start": 27, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "comment", "start": 80, "end": 87, "i_start": 15, "i_end": 15}}, {"character": {"text": "generation", "start": 16, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "comment", "start": 80, "end": 87, "i_start": 15, "i_end": 15}}, {"character": {"text": "\u03c3-invariants", "start": 49, "end": 61, "i_start": 8, "i_end": 10}, "action": {"text": "comment", "start": 80, "end": 87, "i_start": 15, "i_end": 15}}, {"character": {"text": "groups", "start": 71, "end": 77, "i_start": 13, "i_end": 13}, "action": {"text": "comment", "start": 80, "end": 87, "i_start": 15, "i_end": 15}}, {"character": {"text": "graph", "start": 65, "end": 70, "i_start": 12, "i_end": 12}, "action": {"text": "comment", "start": 80, "end": 87, "i_start": 15, "i_end": 15}}], "id": 3292}, {"sent": "we note that this result has just the factorized form of eq .", "tokens": ["we", "note", "that", "this", "result", "has", "just", "the", "factorized", "form", "of", "eq", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "note", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "this result", "start": 13, "end": 24, "i_start": 3, "i_end": 4}, "verb": {"text": "has", "start": 25, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "note", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "result", "start": 18, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "has", "start": 25, "end": 28, "i_start": 5, "i_end": 5}}], "id": 3293}, {"sent": "the estimation of these models is usually done using the em algorithm .", "tokens": ["the", "estimation", "of", "these", "models", "is", "usually", "done", "using", "the", "em", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the estimation of these models", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "done", "start": 42, "end": 46, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the estimation of these models", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 5, "i_end": 5}}], "id": 3294}, {"sent": "to reduce the number of parameters in rescal , distmult constrains the p r matrices to be diagonal .", "tokens": ["to", "reduce", "the", "number", "of", "parameters", "in", "rescal", ",", "distmult", "constrains", "the", "p", "r", "matrices", "to", "be", "diagonal", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "distmult", "start": 47, "end": 55, "i_start": 9, "i_end": 9}, "verb": {"text": "constrains", "start": 56, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "distmult", "start": 47, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "constrains", "start": 56, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "distmult", "start": 47, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "reduce", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 3295}, {"sent": "smooth branes and junction conditions in einstein gauss-bonnet gravity .", "tokens": ["smooth", "branes", "and", "junction", "conditions", "in", "einstein", "gauss", "-", "bonnet", "gravity", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3296}, {"sent": "large deep neural networks have enabled breakthroughs in fields such as computer vision , speech recognition , and reinforcement learning .", "tokens": ["large", "deep", "neural", "networks", "have", "enabled", "breakthroughs", "in", "fields", "such", "as", "computer", "vision", ",", "speech", "recognition", ",", "and", "reinforcement", "learning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "large deep neural networks", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "have enabled", "start": 27, "end": 39, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 18, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "enabled", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}], "id": 3297}, {"sent": "structure theorems for singular minimal laminations .", "tokens": ["structure", "theorems", "for", "singular", "minimal", "laminations", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3298}, {"sent": "this nucleus perhaps is the most likely candidate for having a proton halo structure , as its last proton has a binding energy of only 137 kev .", "tokens": ["this", "nucleus", "perhaps", "is", "the", "most", "likely", "candidate", "for", "having", "a", "proton", "halo", "structure", ",", "as", "its", "last", "proton", "has", "a", "binding", "energy", "of", "only", "137", "kev", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this nucleus", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "nucleus", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "has", "start": 106, "end": 109, "i_start": 19, "i_end": 19}}], "id": 3299}, {"sent": "the data points are normalized to the point of maximum .", "tokens": ["the", "data", "points", "are", "normalized", "to", "the", "point", "of", "maximum", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data points", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "are normalized", "start": 16, "end": 30, "i_start": 3, "i_end": 4}}], "id": 3300}, {"sent": "a get diffs transition results in the client in question applying its pending diffs to its copy of the document , held in the gworkingdoc client side variable .", "tokens": ["a", "get", "diffs", "transition", "results", "in", "the", "client", "in", "question", "applying", "its", "pending", "diffs", "to", "its", "copy", "of", "the", "document", ",", "held", "in", "the", "gworkingdoc", "client", "side", "variable", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "client", "start": 38, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "applying", "start": 57, "end": 65, "i_start": 10, "i_end": 10}}, {"character": {"text": "client", "start": 38, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "copy", "start": 91, "end": 95, "i_start": 16, "i_end": 16}}], "id": 3301}, {"sent": "convolution-based deep neural networks have performed exceedingly well on 2d representation learning tasks .", "tokens": ["convolution", "-", "based", "deep", "neural", "networks", "have", "performed", "exceedingly", "well", "on", "2d", "representation", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolution-based deep neural networks", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "have performed", "start": 39, "end": 53, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "performed", "start": 44, "end": 53, "i_start": 7, "i_end": 7}}], "id": 3302}, {"sent": "a density functional theory for the n-i transition in a 2d system of rods has been developed and it predicts a continuous n-i transition .", "tokens": ["a", "density", "functional", "theory", "for", "the", "n", "-", "i", "transition", "in", "a", "2d", "system", "of", "rods", "has", "been", "developed", "and", "it", "predicts", "a", "continuous", "n", "-", "i", "transition", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "a density functional theory for the n-i transition in a 2d system of rods", "start": 0, "end": 73, "i_start": 0, "i_end": 15}, "verb": {"text": "has been developed", "start": 74, "end": 92, "i_start": 16, "i_end": 18}}, {"subject": {"text": "it", "start": 97, "end": 99, "i_start": 20, "i_end": 20}, "verb": {"text": "predicts", "start": 100, "end": 108, "i_start": 21, "i_end": 21}}, {"character": {"text": "theory", "start": 21, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "predicts", "start": 100, "end": 108, "i_start": 21, "i_end": 21}}], "id": 3303}, {"sent": "in , the probability density function of the number of users in each voronoi cell was derived by modeling the locations of users as a homogeneous ppp .", "tokens": ["in", ",", "the", "probability", "density", "function", "of", "the", "number", "of", "users", "in", "each", "voronoi", "cell", "was", "derived", "by", "modeling", "the", "locations", "of", "users", "as", "a", "homogeneous", "ppp", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the probability density function of the number of users in each voronoi cell", "start": 5, "end": 81, "i_start": 2, "i_end": 14}, "verb": {"text": "was derived", "start": 82, "end": 93, "i_start": 15, "i_end": 16}}, {"character": {"text": "number", "start": 45, "end": 51, "i_start": 8, "i_end": 8}, "action": {"text": "function", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}], "id": 3304}, {"sent": "a functorial embedded desingularization of quasi-excellent schemes of characteristic zero is deduced .", "tokens": ["a", "functorial", "embedded", "desingularization", "of", "quasi", "-", "excellent", "schemes", "of", "characteristic", "zero", "is", "deduced", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a functorial embedded desingularization of quasi-excellent schemes of characteristic zero", "start": 0, "end": 89, "i_start": 0, "i_end": 11}, "verb": {"text": "is deduced", "start": 90, "end": 100, "i_start": 12, "i_end": 13}}], "id": 3305}, {"sent": "considering the delays of the emission lines with respect to the continuum variations we could verify an ionization stratification of the blr .", "tokens": ["considering", "the", "delays", "of", "the", "emission", "lines", "with", "respect", "to", "the", "continuum", "variations", "we", "could", "verify", "an", "ionization", "stratification", "of", "the", "blr", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 86, "end": 88, "i_start": 13, "i_end": 13}, "verb": {"text": "could verify", "start": 89, "end": 101, "i_start": 14, "i_end": 15}}, {"character": {"text": "we", "start": 86, "end": 88, "i_start": 13, "i_end": 13}, "action": {"text": "verify", "start": 95, "end": 101, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 86, "end": 88, "i_start": 13, "i_end": 13}, "action": {"text": "considering", "start": 0, "end": 11, "i_start": 0, "i_end": 0}}], "id": 3306}, {"sent": "gauge theories on noncommutative spaces can be obtained by taking the infinite tension limit of string theory in the presence of a very strong b-field .", "tokens": ["gauge", "theories", "on", "noncommutative", "spaces", "can", "be", "obtained", "by", "taking", "the", "infinite", "tension", "limit", "of", "string", "theory", "in", "the", "presence", "of", "a", "very", "strong", "b", "-", "field", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "gauge theories on noncommutative spaces", "start": 0, "end": 39, "i_start": 0, "i_end": 4}, "verb": {"text": "can be obtained", "start": 40, "end": 55, "i_start": 5, "i_end": 7}}, {"character": {"text": "theory", "start": 103, "end": 109, "i_start": 16, "i_end": 16}, "action": {"text": "limit", "start": 87, "end": 92, "i_start": 13, "i_end": 13}}], "id": 3307}, {"sent": "the network was trained with the adam optimiser for a maximum of 40 epochs .", "tokens": ["the", "network", "was", "trained", "with", "the", "adam", "optimiser", "for", "a", "maximum", "of", "40", "epochs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the network", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "was trained", "start": 12, "end": 23, "i_start": 2, "i_end": 3}}], "id": 3308}, {"sent": "in recent years , image semantic segmentation has achieved an unprecedented high accuracy on various datasets via the use of deep convolutional neural networks .", "tokens": ["in", "recent", "years", ",", "image", "semantic", "segmentation", "has", "achieved", "an", "unprecedented", "high", "accuracy", "on", "various", "datasets", "via", "the", "use", "of", "deep", "convolutional", "neural", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "image semantic segmentation", "start": 18, "end": 45, "i_start": 4, "i_end": 6}, "verb": {"text": "has achieved", "start": 46, "end": 58, "i_start": 7, "i_end": 8}}, {"character": {"text": "segmentation", "start": 33, "end": 45, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 50, "end": 58, "i_start": 8, "i_end": 8}}], "id": 3309}, {"sent": "the jacobson-myers formula used as the holographic entanglement entropy for gauss-bonnet gravity leads to the correct universal terms expected for a generic 4-dimensional cft .", "tokens": ["the", "jacobson", "-", "myers", "formula", "used", "as", "the", "holographic", "entanglement", "entropy", "for", "gauss", "-", "bonnet", "gravity", "leads", "to", "the", "correct", "universal", "terms", "expected", "for", "a", "generic", "4", "-", "dimensional", "cft", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the jacobson-myers formula used as the holographic entanglement entropy for gauss-bonnet gravity", "start": 0, "end": 96, "i_start": 0, "i_end": 15}, "verb": {"text": "leads", "start": 97, "end": 102, "i_start": 16, "i_end": 16}}, {"character": {"text": "formula", "start": 19, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "leads", "start": 97, "end": 102, "i_start": 16, "i_end": 16}}], "id": 3310}, {"sent": "a plaquette is a closed loop consists of 4 different points .", "tokens": ["a", "plaquette", "is", "a", "closed", "loop", "consists", "of", "4", "different", "points", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a plaquette", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 3311}, {"sent": "in 2005 , qi independently introduced the concept of the eigenvalues of tensor and the spectra of tensors .", "tokens": ["in", "2005", ",", "qi", "independently", "introduced", "the", "concept", "of", "the", "eigenvalues", "of", "tensor", "and", "the", "spectra", "of", "tensors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "qi", "start": 10, "end": 12, "i_start": 3, "i_end": 3}, "verb": {"text": "introduced", "start": 27, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "qi", "start": 10, "end": 12, "i_start": 3, "i_end": 3}, "action": {"text": "introduced", "start": 27, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "qi", "start": 10, "end": 12, "i_start": 3, "i_end": 3}, "action": {"text": "independently", "start": 13, "end": 26, "i_start": 4, "i_end": 4}}], "id": 3312}, {"sent": "asterisks denote hls galaxies , all of which have no hblrs .", "tokens": ["asterisks", "denote", "hls", "galaxies", ",", "all", "of", "which", "have", "no", "hblrs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "asterisks", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "galaxies", "start": 21, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "have no", "start": 45, "end": 52, "i_start": 8, "i_end": 9}}], "id": 3313}, {"sent": "it is known that properties of high t c superconductors can be captured by the black hole physics in ads .", "tokens": ["it", "is", "known", "that", "properties", "of", "high", "t", "c", "superconductors", "can", "be", "captured", "by", "the", "black", "hole", "physics", "in", "ads", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is known", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"subject": {"text": "properties of high t c superconductors", "start": 17, "end": 55, "i_start": 4, "i_end": 9}, "verb": {"text": "captured", "start": 63, "end": 71, "i_start": 12, "i_end": 12}}, {"character": {"text": "physics", "start": 90, "end": 97, "i_start": 17, "i_end": 17}, "action": {"text": "captured", "start": 63, "end": 71, "i_start": 12, "i_end": 12}}], "id": 3314}, {"sent": "each aforenamed block is a sequence of two temporal convolutional layers , each one accompanied by a temporal batch normalization layer and a relu activation .", "tokens": ["each", "aforenamed", "block", "is", "a", "sequence", "of", "two", "temporal", "convolutional", "layers", ",", "each", "one", "accompanied", "by", "a", "temporal", "batch", "normalization", "layer", "and", "a", "relu", "activation", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "each aforenamed block is a sequence of two temporal convolutional layers , each one accompanied by a temporal batch normalization layer and a relu activation", "start": 0, "end": 157, "i_start": 0, "i_end": 24}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "layer", "start": 130, "end": 135, "i_start": 20, "i_end": 20}, "action": {"text": "accompanied", "start": 84, "end": 95, "i_start": 14, "i_end": 14}}, {"character": {"text": "normalization", "start": 116, "end": 129, "i_start": 19, "i_end": 19}, "action": {"text": "accompanied", "start": 84, "end": 95, "i_start": 14, "i_end": 14}}, {"character": {"text": "temporal", "start": 43, "end": 51, "i_start": 8, "i_end": 8}, "action": {"text": "accompanied", "start": 84, "end": 95, "i_start": 14, "i_end": 14}}, {"character": {"text": "activation", "start": 147, "end": 157, "i_start": 24, "i_end": 24}, "action": {"text": "accompanied", "start": 84, "end": 95, "i_start": 14, "i_end": 14}}], "id": 3315}, {"sent": "then operation schedule of thermal plants is calculated to integrate pv output using our unit commitment model with the estimated forecast error .", "tokens": ["then", "operation", "schedule", "of", "thermal", "plants", "is", "calculated", "to", "integrate", "pv", "output", "using", "our", "unit", "commitment", "model", "with", "the", "estimated", "forecast", "error", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "operation schedule of thermal plants", "start": 5, "end": 41, "i_start": 1, "i_end": 5}, "verb": {"text": "is calculated", "start": 42, "end": 55, "i_start": 6, "i_end": 7}}], "id": 3316}, {"sent": "in table 2 , we present the best results from all learning-based approaches and compare with bm3d .", "tokens": ["in", "table", "2", ",", "we", "present", "the", "best", "results", "from", "all", "learning", "-", "based", "approaches", "and", "compare", "with", "bm3d", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 13, "end": 15, "i_start": 4, "i_end": 4}, "verb": {"text": "present", "start": 16, "end": 23, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 13, "end": 15, "i_start": 4, "i_end": 4}, "verb": {"text": "compare", "start": 80, "end": 87, "i_start": 16, "i_end": 16}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 4, "i_end": 4}, "action": {"text": "present", "start": 16, "end": 23, "i_start": 5, "i_end": 5}}], "id": 3317}, {"sent": "the first tensegrity structures appeared in art , with the sculptures of kenneth snelson .", "tokens": ["the", "first", "tensegrity", "structures", "appeared", "in", "art", ",", "with", "the", "sculptures", "of", "kenneth", "snelson", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the first tensegrity structures", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "appeared", "start": 32, "end": 40, "i_start": 4, "i_end": 4}}], "id": 3318}, {"sent": "in some other cases , a linear-regression straight line was fit by the least squares method , a procedure which can lead to substantial biases and wrong inferences when applied to probability distributions .", "tokens": ["in", "some", "other", "cases", ",", "a", "linear", "-", "regression", "straight", "line", "was", "fit", "by", "the", "least", "squares", "method", ",", "a", "procedure", "which", "can", "lead", "to", "substantial", "biases", "and", "wrong", "inferences", "when", "applied", "to", "probability", "distributions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a linear-regression straight line", "start": 22, "end": 55, "i_start": 5, "i_end": 10}, "verb": {"text": "was", "start": 56, "end": 59, "i_start": 11, "i_end": 11}}, {"character": {"text": "method", "start": 85, "end": 91, "i_start": 17, "i_end": 17}, "action": {"text": "lead", "start": 116, "end": 120, "i_start": 23, "i_end": 23}}], "id": 3319}, {"sent": "the principal applications of these sources include quantum networks .", "tokens": ["the", "principal", "applications", "of", "these", "sources", "include", "quantum", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the principal applications of these sources", "start": 0, "end": 43, "i_start": 0, "i_end": 5}, "verb": {"text": "include", "start": 44, "end": 51, "i_start": 6, "i_end": 6}}], "id": 3320}, {"sent": "rifford , existence of lipschitz and semiconcave control-lyapunov functions , siam j .", "tokens": ["rifford", ",", "existence", "of", "lipschitz", "and", "semiconcave", "control", "-", "lyapunov", "functions", ",", "siam", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3321}, {"sent": "recently , deep convolutional neural networks have achieved great successes in computer vision topics such as image classification .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "achieved", "great", "successes", "in", "computer", "vision", "topics", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "successes", "start": 66, "end": 75, "i_start": 9, "i_end": 9}}], "id": 3322}, {"sent": "our results rely on a close analysis of the ergm glauber dynamics , following bhamidi et al , where mixing times are studied .", "tokens": ["our", "results", "rely", "on", "a", "close", "analysis", "of", "the", "ergm", "glauber", "dynamics", ",", "following", "bhamidi", "et", "al", ",", "where", "mixing", "times", "are", "studied", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our results", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "rely", "start": 12, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "results", "start": 4, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "rely", "start": 12, "end": 16, "i_start": 2, "i_end": 2}}], "id": 3323}, {"sent": "shen et al used kernels in structural equation models for identification of network topologies from graph signals .", "tokens": ["shen", "et", "al", "used", "kernels", "in", "structural", "equation", "models", "for", "identification", "of", "network", "topologies", "from", "graph", "signals", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "shen et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "shen", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "shen", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "identification", "start": 58, "end": 72, "i_start": 10, "i_end": 10}}], "id": 3324}, {"sent": "a turing machine is a universal formal system .", "tokens": ["a", "turing", "machine", "is", "a", "universal", "formal", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a turing machine", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 3325}, {"sent": "we construct semantic communities with the louvain algorithm .", "tokens": ["we", "construct", "semantic", "communities", "with", "the", "louvain", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "construct", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "construct", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}], "id": 3326}, {"sent": "the key element of most predictions involving hard inclusive reactions in high-energy physics is the factorization theorem of perturbative qcd .", "tokens": ["the", "key", "element", "of", "most", "predictions", "involving", "hard", "inclusive", "reactions", "in", "high", "-", "energy", "physics", "is", "the", "factorization", "theorem", "of", "perturbative", "qcd", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the key element of most predictions involving hard inclusive reactions in high-energy physics", "start": 0, "end": 93, "i_start": 0, "i_end": 14}, "verb": {"text": "is", "start": 94, "end": 96, "i_start": 15, "i_end": 15}}], "id": 3327}, {"sent": "the dotted line used to connect the experimental points is just for eye guidance .", "tokens": ["the", "dotted", "line", "used", "to", "connect", "the", "experimental", "points", "is", "just", "for", "eye", "guidance", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the dotted line used to connect the experimental points", "start": 0, "end": 55, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 56, "end": 58, "i_start": 9, "i_end": 9}}, {"character": {"text": "eye", "start": 68, "end": 71, "i_start": 12, "i_end": 12}, "action": {"text": "guidance", "start": 72, "end": 80, "i_start": 13, "i_end": 13}}], "id": 3328}, {"sent": "deep neural networks have substantially pushed the state-of-the-art in a wide range of tasks , especially in speech recognition .", "tokens": ["deep", "neural", "networks", "have", "substantially", "pushed", "the", "state", "-", "of", "-", "the", "-", "art", "in", "a", "wide", "range", "of", "tasks", ",", "especially", "in", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "pushed", "start": 40, "end": 46, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "pushed", "start": 40, "end": 46, "i_start": 5, "i_end": 5}}], "id": 3329}, {"sent": "this approximation was introduced by chorin , in order to deal with the difficulty induced by the incompressibility constraints in the numerical approximations to the navier stokes equation .", "tokens": ["this", "approximation", "was", "introduced", "by", "chorin", ",", "in", "order", "to", "deal", "with", "the", "difficulty", "induced", "by", "the", "incompressibility", "constraints", "in", "the", "numerical", "approximations", "to", "the", "navier", "stokes", "equation", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this approximation", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "was introduced", "start": 19, "end": 33, "i_start": 2, "i_end": 3}}, {"character": {"text": "chorin", "start": 37, "end": 43, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 23, "end": 33, "i_start": 3, "i_end": 3}}, {"character": {"text": "chorin", "start": 37, "end": 43, "i_start": 5, "i_end": 5}, "action": {"text": "deal", "start": 58, "end": 62, "i_start": 10, "i_end": 10}}, {"character": {"text": "constraints", "start": 116, "end": 127, "i_start": 18, "i_end": 18}, "action": {"text": "induced", "start": 83, "end": 90, "i_start": 14, "i_end": 14}}], "id": 3330}, {"sent": "the fermi -lat is a pair-conversion telescope that is sensitive to gamma rays in the energy range from 20 mev to more than 300 gev .", "tokens": ["the", "fermi", "-lat", "is", "a", "pair", "-", "conversion", "telescope", "that", "is", "sensitive", "to", "gamma", "rays", "in", "the", "energy", "range", "from", "20", "mev", "to", "more", "than", "300", "gev", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the fermi -lat", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "telescope", "start": 36, "end": 45, "i_start": 8, "i_end": 8}, "action": {"text": "sensitive", "start": 54, "end": 63, "i_start": 11, "i_end": 11}}], "id": 3331}, {"sent": "quantum mechanics is a completly different framework compared with classical physics .", "tokens": ["quantum", "mechanics", "is", "a", "completly", "different", "framework", "compared", "with", "classical", "physics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum mechanics", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}], "id": 3332}, {"sent": "the semantic of this program language is also briefly described in this section .", "tokens": ["the", "semantic", "of", "this", "program", "language", "is", "also", "briefly", "described", "in", "this", "section", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the semantic of this program language", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "described", "start": 54, "end": 63, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the semantic of this program language", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 6, "i_end": 6}}], "id": 3333}, {"sent": "this study was extended to the case of anisotropic plasma in and imaginary potential formula in a general curved background was obtained .", "tokens": ["this", "study", "was", "extended", "to", "the", "case", "of", "anisotropic", "plasma", "in", "and", "imaginary", "potential", "formula", "in", "a", "general", "curved", "background", "was", "obtained", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "imaginary potential formula in a general curved background", "start": 65, "end": 123, "i_start": 12, "i_end": 19}, "verb": {"text": "was obtained", "start": 124, "end": 136, "i_start": 20, "i_end": 21}}, {"subject": {"text": "this study", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "extended", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 3334}, {"sent": "we demonstrate that these families are guaranteed approximately bl-wolf-learnable with lower cost .", "tokens": ["we", "demonstrate", "that", "these", "families", "are", "guaranteed", "approximately", "bl", "-", "wolf", "-", "learnable", "with", "lower", "cost", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "demonstrate", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"subject": {"text": "these families", "start": 20, "end": 34, "i_start": 3, "i_end": 4}, "verb": {"text": "guaranteed", "start": 39, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "demonstrate", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "families", "start": 26, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "learnable", "start": 72, "end": 81, "i_start": 12, "i_end": 12}}], "id": 3335}, {"sent": "in recent years , convolutional neural networks have achieved state-of-the-art performance for many segmentation tasks .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "for", "many", "segmentation", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 48, "end": 61, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 53, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 79, "end": 90, "i_start": 16, "i_end": 16}}], "id": 3336}, {"sent": "a lyapunov approach to incremental stability properties .", "tokens": ["a", "lyapunov", "approach", "to", "incremental", "stability", "properties", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "lyapunov", "start": 2, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "approach", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}], "id": 3337}, {"sent": "second , window violation can be induced due to the larger disparity and the visual field limitation .", "tokens": ["second", ",", "window", "violation", "can", "be", "induced", "due", "to", "the", "larger", "disparity", "and", "the", "visual", "field", "limitation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "window violation", "start": 9, "end": 25, "i_start": 2, "i_end": 3}, "verb": {"text": "can be induced", "start": 26, "end": 40, "i_start": 4, "i_end": 6}}], "id": 3338}, {"sent": "when the curvaton is a pseudo-goldstone boson , the flatness requirement eq .", "tokens": ["when", "the", "curvaton", "is", "a", "pseudo", "-", "goldstone", "boson", ",", "the", "flatness", "requirement", "eq", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the curvaton", "start": 5, "end": 17, "i_start": 1, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}], "id": 3339}, {"sent": "explicit examples can be found 10 , 30 where xor was obtained as a sub-result of the controlled-not gate operation .", "tokens": ["explicit", "examples", "can", "be", "found", "10", ",", "30", "where", "xor", "was", "obtained", "as", "a", "sub", "-", "result", "of", "the", "controlled", "-", "not", "gate", "operation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "explicit examples", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "can be found", "start": 18, "end": 30, "i_start": 2, "i_end": 4}}], "id": 3340}, {"sent": "this vortex is the m2 brane to which the m4 brane can decay .", "tokens": ["this", "vortex", "is", "the", "m2", "brane", "to", "which", "the", "m4", "brane", "can", "decay", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this vortex", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "brane", "start": 44, "end": 49, "i_start": 10, "i_end": 10}, "action": {"text": "decay", "start": 54, "end": 59, "i_start": 12, "i_end": 12}}], "id": 3341}, {"sent": "type iib supergravity is the unique 10-dimensional chiral supergravity theory with 32 supercharges .", "tokens": ["type", "iib", "supergravity", "is", "the", "unique", "10", "-", "dimensional", "chiral", "supergravity", "theory", "with", "32", "supercharges", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "type iib supergravity", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3342}, {"sent": "the decoder layers are randomly initialized using the xavier weight initialization .", "tokens": ["the", "decoder", "layers", "are", "randomly", "initialized", "using", "the", "xavier", "weight", "initialization", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the decoder layers", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "initialized", "start": 32, "end": 43, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the decoder layers", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 19, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "layers", "start": 12, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "decoder", "start": 4, "end": 11, "i_start": 1, "i_end": 1}}], "id": 3343}, {"sent": "generative adversarial networks are one of the main groups of methods used to learn generative models from complicated real-world data .", "tokens": ["generative", "adversarial", "networks", "are", "one", "of", "the", "main", "groups", "of", "methods", "used", "to", "learn", "generative", "models", "from", "complicated", "real", "-", "world", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}], "id": 3344}, {"sent": "the hamiltonian h is the lowest order in the expansion with respect to the tunneling interaction .", "tokens": ["the", "hamiltonian", "h", "is", "the", "lowest", "order", "in", "the", "expansion", "with", "respect", "to", "the", "tunneling", "interaction", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the hamiltonian h", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}], "id": 3345}, {"sent": "the feature encoding module follows the base architecture of the first five convolutional blocks of vgg16 network .", "tokens": ["the", "feature", "encoding", "module", "follows", "the", "base", "architecture", "of", "the", "first", "five", "convolutional", "blocks", "of", "vgg16", "network", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the feature encoding module", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "follows", "start": 28, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "module", "start": 21, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "encoding", "start": 12, "end": 20, "i_start": 2, "i_end": 2}}], "id": 3346}, {"sent": "neural networks have been applied to solving problems in several application domains such as computer vision , natural language processing , and disease diagnosis .", "tokens": ["neural", "networks", "have", "been", "applied", "to", "solving", "problems", "in", "several", "application", "domains", "such", "as", "computer", "vision", ",", "natural", "language", "processing", ",", "and", "disease", "diagnosis", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have been applied", "start": 16, "end": 33, "i_start": 2, "i_end": 4}}], "id": 3347}, {"sent": "in a dense neutrino gas , neutrino-neutrino refraction causes nonlinear flavor oscillation phenomena .", "tokens": ["in", "a", "dense", "neutrino", "gas", ",", "neutrino", "-", "neutrino", "refraction", "causes", "nonlinear", "flavor", "oscillation", "phenomena", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neutrino-neutrino refraction", "start": 26, "end": 54, "i_start": 6, "i_end": 9}, "verb": {"text": "causes", "start": 55, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "refraction", "start": 44, "end": 54, "i_start": 9, "i_end": 9}, "action": {"text": "causes", "start": 55, "end": 61, "i_start": 10, "i_end": 10}}], "id": 3348}, {"sent": "instead , we use a numerical optimization routine based on the nelder-mead method which can handle arbitrary non-linear functions and generates local optima .", "tokens": ["instead", ",", "we", "use", "a", "numerical", "optimization", "routine", "based", "on", "the", "nelder", "-", "mead", "method", "which", "can", "handle", "arbitrary", "non", "-", "linear", "functions", "and", "generates", "local", "optima", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "use", "start": 13, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 13, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "method", "start": 75, "end": 81, "i_start": 14, "i_end": 14}, "action": {"text": "handle", "start": 92, "end": 98, "i_start": 17, "i_end": 17}}, {"character": {"text": "method", "start": 75, "end": 81, "i_start": 14, "i_end": 14}, "action": {"text": "generates", "start": 134, "end": 143, "i_start": 24, "i_end": 24}}], "id": 3349}, {"sent": "experimentally , superconductivity often is the strongest when the two competing states are nearly degenerate , near quantum critical points .", "tokens": ["experimentally", ",", "superconductivity", "often", "is", "the", "strongest", "when", "the", "two", "competing", "states", "are", "nearly", "degenerate", ",", "near", "quantum", "critical", "points", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "superconductivity", "start": 17, "end": 34, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 41, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "two competing states", "start": 67, "end": 87, "i_start": 9, "i_end": 11}, "action": {"text": "competing", "start": 71, "end": 80, "i_start": 10, "i_end": 10}}], "id": 3350}, {"sent": "note that rx terms will cancel out when we match between the lattice and continuum operators .", "tokens": ["note", "that", "rx", "terms", "will", "cancel", "out", "when", "we", "match", "between", "the", "lattice", "and", "continuum", "operators", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "rx terms", "start": 10, "end": 18, "i_start": 2, "i_end": 3}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "rx terms", "start": 10, "end": 18, "i_start": 2, "i_end": 3}, "verb": {"text": "cancel", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 40, "end": 42, "i_start": 8, "i_end": 8}, "action": {"text": "match", "start": 43, "end": 48, "i_start": 9, "i_end": 9}}], "id": 3351}, {"sent": "in this paper we present results for integrated and unintegrated gluon distribution functions according to the definitions in the linked dipole chain model , obtained from the ldcmc program .", "tokens": ["in", "this", "paper", "we", "present", "results", "for", "integrated", "and", "unintegrated", "gluon", "distribution", "functions", "according", "to", "the", "definitions", "in", "the", "linked", "dipole", "chain", "model", ",", "obtained", "from", "the", "ldcmc", "program", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "present", "start": 17, "end": 24, "i_start": 4, "i_end": 4}}, {"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "obtained", "start": 158, "end": 166, "i_start": 24, "i_end": 24}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "present", "start": 17, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "model", "start": 150, "end": 155, "i_start": 22, "i_end": 22}, "action": {"text": "definitions", "start": 111, "end": 122, "i_start": 16, "i_end": 16}}], "id": 3352}, {"sent": "deep neural networks have achieved a great success on many tasks such as image classification when a large set of labeled examples are available .", "tokens": ["deep", "neural", "networks", "have", "achieved", "a", "great", "success", "on", "many", "tasks", "such", "as", "image", "classification", "when", "a", "large", "set", "of", "labeled", "examples", "are", "available", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 43, "end": 50, "i_start": 7, "i_end": 7}}], "id": 3353}, {"sent": "early-type host dust constraints in this section we use measurements of the red sequence scatter to place constraints on the scatter of reddening affecting these galaxies .", "tokens": ["early", "-", "type", "host", "dust", "constraints", "in", "this", "section", "we", "use", "measurements", "of", "the", "red", "sequence", "scatter", "to", "place", "constraints", "on", "the", "scatter", "of", "reddening", "affecting", "these", "galaxies", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "early-type host dust constraints in this section we", "start": 0, "end": 51, "i_start": 0, "i_end": 9}, "verb": {"text": "use", "start": 52, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "action": {"text": "use", "start": 52, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "action": {"text": "place", "start": 100, "end": 105, "i_start": 18, "i_end": 18}}, {"character": {"text": "scatter", "start": 125, "end": 132, "i_start": 22, "i_end": 22}, "action": {"text": "affecting", "start": 146, "end": 155, "i_start": 25, "i_end": 25}}], "id": 3354}, {"sent": "for the past several years , deep convolution neural networks have found their extensive applications in image processing such as image classification , and so forth .", "tokens": ["for", "the", "past", "several", "years", ",", "deep", "convolution", "neural", "networks", "have", "found", "their", "extensive", "applications", "in", "image", "processing", "such", "as", "image", "classification", ",", "and", "so", "forth", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolution neural networks", "start": 29, "end": 61, "i_start": 6, "i_end": 9}, "verb": {"text": "have found", "start": 62, "end": 72, "i_start": 10, "i_end": 11}}, {"character": {"text": "networks", "start": 53, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "found", "start": 67, "end": 72, "i_start": 11, "i_end": 11}}], "id": 3355}, {"sent": "in recent years , with the development of research , various special cnn models have emerged , including resnet , and so on .", "tokens": ["in", "recent", "years", ",", "with", "the", "development", "of", "research", ",", "various", "special", "cnn", "models", "have", "emerged", ",", "including", "resnet", ",", "and", "so", "on", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "various special cnn models", "start": 53, "end": 79, "i_start": 10, "i_end": 13}, "verb": {"text": "have emerged", "start": 80, "end": 92, "i_start": 14, "i_end": 15}}, {"character": {"text": "models", "start": 73, "end": 79, "i_start": 13, "i_end": 13}, "action": {"text": "emerged", "start": 85, "end": 92, "i_start": 15, "i_end": 15}}], "id": 3356}, {"sent": "kim , on euler-barnes multiple zeta functions , russian j .", "tokens": ["kim", ",", "on", "euler", "-", "barnes", "multiple", "zeta", "functions", ",", "russian", "j", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3357}, {"sent": "in natural language processing , deep learning methods have been mostly focused on learning word vector representations .", "tokens": ["in", "natural", "language", "processing", ",", "deep", "learning", "methods", "have", "been", "mostly", "focused", "on", "learning", "word", "vector", "representations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning methods", "start": 33, "end": 54, "i_start": 5, "i_end": 7}, "verb": {"text": "focused", "start": 72, "end": 79, "i_start": 11, "i_end": 11}}, {"subject": {"text": "deep learning methods", "start": 33, "end": 54, "i_start": 5, "i_end": 7}, "verb": {"text": "have been", "start": 55, "end": 64, "i_start": 8, "i_end": 9}}], "id": 3358}, {"sent": "the ellipses denote terms analytic in quark masses or subleading in chiral power counting .", "tokens": ["the", "ellipses", "denote", "terms", "analytic", "in", "quark", "masses", "or", "subleading", "in", "chiral", "power", "counting", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ellipses", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "denote", "start": 13, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "ellipses", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 13, "end": 19, "i_start": 2, "i_end": 2}}], "id": 3359}, {"sent": "the inelastic light scattering experiments take advantage of the breakdown of wave-vector conservation that occurs under resonant excitation .", "tokens": ["the", "inelastic", "light", "scattering", "experiments", "take", "advantage", "of", "the", "breakdown", "of", "wave", "-", "vector", "conservation", "that", "occurs", "under", "resonant", "excitation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the inelastic light scattering experiments", "start": 0, "end": 42, "i_start": 0, "i_end": 4}, "verb": {"text": "take", "start": 43, "end": 47, "i_start": 5, "i_end": 5}}, {"character": {"text": "experiments", "start": 31, "end": 42, "i_start": 4, "i_end": 4}, "action": {"text": "take", "start": 43, "end": 47, "i_start": 5, "i_end": 5}}], "id": 3360}, {"sent": "we employ standard resnet50 as the backbone for frame feature extraction .", "tokens": ["we", "employ", "standard", "resnet50", "as", "the", "backbone", "for", "frame", "feature", "extraction", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 3361}, {"sent": "the response of the detectors to physics processes is simulated using the simulator for the linear collider package developed for the ilc project .", "tokens": ["the", "response", "of", "the", "detectors", "to", "physics", "processes", "is", "simulated", "using", "the", "simulator", "for", "the", "linear", "collider", "package", "developed", "for", "the", "ilc", "project", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the response of the detectors to physics processes", "start": 0, "end": 50, "i_start": 0, "i_end": 7}, "verb": {"text": "is simulated", "start": 51, "end": 63, "i_start": 8, "i_end": 9}}], "id": 3362}, {"sent": "deep neural networks have been evolved to powerful predictive models with remarkable performance on computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "been", "evolved", "to", "powerful", "predictive", "models", "with", "remarkable", "performance", "on", "computer", "vision", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been evolved", "start": 21, "end": 38, "i_start": 3, "i_end": 5}}, {"character": {"text": "models", "start": 62, "end": 68, "i_start": 9, "i_end": 9}, "action": {"text": "predictive", "start": 51, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "models", "start": 62, "end": 68, "i_start": 9, "i_end": 9}, "action": {"text": "performance", "start": 85, "end": 96, "i_start": 12, "i_end": 12}}], "id": 3363}, {"sent": "traditionally , convolution neural networks have enjoyed great success for learning useful image visual content features in recent years .", "tokens": ["traditionally", ",", "convolution", "neural", "networks", "have", "enjoyed", "great", "success", "for", "learning", "useful", "image", "visual", "content", "features", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolution neural networks", "start": 16, "end": 43, "i_start": 2, "i_end": 4}, "verb": {"text": "have enjoyed", "start": 44, "end": 56, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 35, "end": 43, "i_start": 4, "i_end": 4}, "action": {"text": "enjoyed", "start": 49, "end": 56, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 35, "end": 43, "i_start": 4, "i_end": 4}, "action": {"text": "success", "start": 63, "end": 70, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 35, "end": 43, "i_start": 4, "i_end": 4}, "action": {"text": "learning", "start": 75, "end": 83, "i_start": 10, "i_end": 10}}], "id": 3364}, {"sent": "for each layer of the mlp , we add a batch normalization layer to accelerate the training .", "tokens": ["for", "each", "layer", "of", "the", "mlp", ",", "we", "add", "a", "batch", "normalization", "layer", "to", "accelerate", "the", "training", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 28, "end": 30, "i_start": 7, "i_end": 7}, "verb": {"text": "add", "start": 31, "end": 34, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 28, "end": 30, "i_start": 7, "i_end": 7}, "action": {"text": "add", "start": 31, "end": 34, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 28, "end": 30, "i_start": 7, "i_end": 7}, "action": {"text": "accelerate", "start": 66, "end": 76, "i_start": 14, "i_end": 14}}], "id": 3365}, {"sent": "because of the confinement , there is a number of differences as compared to homogeneous superfluids .", "tokens": ["because", "of", "the", "confinement", ",", "there", "is", "a", "number", "of", "differences", "as", "compared", "to", "homogeneous", "superfluids", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 29, "end": 34, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "confinement", "start": 15, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "because", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}], "id": 3366}, {"sent": "however , recent research has shown that well-trained deep neural networks are rather vulnerable to adversarial examples .", "tokens": ["however", ",", "recent", "research", "has", "shown", "that", "well", "-", "trained", "deep", "neural", "networks", "are", "rather", "vulnerable", "to", "adversarial", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent research", "start": 10, "end": 25, "i_start": 2, "i_end": 3}, "verb": {"text": "has shown", "start": 26, "end": 35, "i_start": 4, "i_end": 5}}, {"subject": {"text": "recent research", "start": 10, "end": 25, "i_start": 2, "i_end": 3}, "verb": {"text": "are", "start": 75, "end": 78, "i_start": 13, "i_end": 13}}, {"character": {"text": "research", "start": 17, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 30, "end": 35, "i_start": 5, "i_end": 5}}], "id": 3367}, {"sent": "deep convolutional neural networks have been successful in many computer vision tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successful", "in", "many", "computer", "vision", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "successful", "start": 45, "end": 55, "i_start": 6, "i_end": 6}}], "id": 3368}, {"sent": "but , here we have that determinization is needed prior to the state reduction by means of the greatest weakly right and left invariant fuzzy quasi-orders .", "tokens": ["but", ",", "here", "we", "have", "that", "determinization", "is", "needed", "prior", "to", "the", "state", "reduction", "by", "means", "of", "the", "greatest", "weakly", "right", "and", "left", "invariant", "fuzzy", "quasi", "-", "orders", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 11, "end": 13, "i_start": 3, "i_end": 3}, "verb": {"text": "have", "start": 14, "end": 18, "i_start": 4, "i_end": 4}}, {"subject": {"text": "that determinization", "start": 19, "end": 39, "i_start": 5, "i_end": 6}, "verb": {"text": "needed", "start": 43, "end": 49, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 11, "end": 13, "i_start": 3, "i_end": 3}, "action": {"text": "have", "start": 14, "end": 18, "i_start": 4, "i_end": 4}}], "id": 3369}, {"sent": "automatic generation of propagation rules for finite domains .", "tokens": ["automatic", "generation", "of", "propagation", "rules", "for", "finite", "domains", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3370}, {"sent": "recent attempts using deep neural networks have achieved breakthrough results for image recognition .", "tokens": ["recent", "attempts", "using", "deep", "neural", "networks", "have", "achieved", "breakthrough", "results", "for", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent attempts using deep neural networks", "start": 0, "end": 42, "i_start": 0, "i_end": 5}, "verb": {"text": "have achieved", "start": 43, "end": 56, "i_start": 6, "i_end": 7}}, {"character": {"text": "attempts", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "achieved", "start": 48, "end": 56, "i_start": 7, "i_end": 7}}], "id": 3371}, {"sent": "watts and strogatz proposed a model to generate networks with the small world properties .", "tokens": ["watts", "and", "strogatz", "proposed", "a", "model", "to", "generate", "networks", "with", "the", "small", "world", "properties", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "watts and strogatz", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "watts and strogatz", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "action": {"text": "proposed", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}], "id": 3372}, {"sent": "the fos spectra is described by wills et al .", "tokens": ["the", "fos", "spectra", "is", "described", "by", "wills", "et", "al", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the fos spectra", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is described", "start": 16, "end": 28, "i_start": 3, "i_end": 4}}, {"character": {"text": "wills", "start": 32, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "described", "start": 19, "end": 28, "i_start": 4, "i_end": 4}}], "id": 3373}, {"sent": "detecting objects in static images has achieved significant progress due to the emergence of deep convolutional neural networks .", "tokens": ["detecting", "objects", "in", "static", "images", "has", "achieved", "significant", "progress", "due", "to", "the", "emergence", "of", "deep", "convolutional", "neural", "networks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "objects in static images", "start": 10, "end": 34, "i_start": 1, "i_end": 4}, "verb": {"text": "detecting", "start": 0, "end": 9, "i_start": 0, "i_end": 0}}, {"subject": {"text": "objects in static images", "start": 10, "end": 34, "i_start": 1, "i_end": 4}, "verb": {"text": "achieved", "start": 39, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "detecting", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "achieved", "start": 39, "end": 47, "i_start": 6, "i_end": 6}}], "id": 3374}, {"sent": "more formally , a von neumann algebra is a unital selfadjoint subalgebra of the algebra of all bounded linear operators on a hilbert space which is closed under the topology of pointwise convergence .", "tokens": ["more", "formally", ",", "a", "von", "neumann", "algebra", "is", "a", "unital", "selfadjoint", "subalgebra", "of", "the", "algebra", "of", "all", "bounded", "linear", "operators", "on", "a", "hilbert", "space", "which", "is", "closed", "under", "the", "topology", "of", "pointwise", "convergence", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a von neumann algebra", "start": 16, "end": 37, "i_start": 3, "i_end": 6}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 7, "i_end": 7}}], "id": 3375}, {"sent": "in particular , neither shows azimuthal symmetry , and the emission is not centered on the white dwarf but is primarily in the lower-left quadrant is qualitatively correct .", "tokens": ["in", "particular", ",", "neither", "shows", "azimuthal", "symmetry", ",", "and", "the", "emission", "is", "not", "centered", "on", "the", "white", "dwarf", "but", "is", "primarily", "in", "the", "lower", "-", "left", "quadrant", "is", "qualitatively", "correct", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neither", "start": 16, "end": 23, "i_start": 3, "i_end": 3}, "verb": {"text": "shows", "start": 24, "end": 29, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the emission", "start": 55, "end": 67, "i_start": 9, "i_end": 10}, "verb": {"text": "centered", "start": 75, "end": 83, "i_start": 13, "i_end": 13}}], "id": 3376}, {"sent": "in recent years , convolutional neural networks has achieved remarkable results in a wide range of computer vision applications .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "has", "achieved", "remarkable", "results", "in", "a", "wide", "range", "of", "computer", "vision", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "has achieved", "start": 48, "end": 60, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 52, "end": 60, "i_start": 8, "i_end": 8}}], "id": 3377}, {"sent": "for the class of perfect graphs , it is known that a maximum 1-colorable set can be found in polynomial time .", "tokens": ["for", "the", "class", "of", "perfect", "graphs", ",", "it", "is", "known", "that", "a", "maximum", "1", "-", "colorable", "set", "can", "be", "found", "in", "polynomial", "time", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 34, "end": 36, "i_start": 7, "i_end": 7}, "verb": {"text": "is known", "start": 37, "end": 45, "i_start": 8, "i_end": 9}}, {"subject": {"text": "a maximum 1-colorable set", "start": 51, "end": 76, "i_start": 11, "i_end": 16}, "verb": {"text": "found", "start": 84, "end": 89, "i_start": 19, "i_end": 19}}], "id": 3378}, {"sent": "among the potential solutions for 5g cellular communications , massive multiple-input multiple-output has been shown to be able to increase the system spectral efficiency by several times .", "tokens": ["among", "the", "potential", "solutions", "for", "5", "g", "cellular", "communications", ",", "massive", "multiple", "-", "input", "multiple", "-", "output", "has", "been", "shown", "to", "be", "able", "to", "increase", "the", "system", "spectral", "efficiency", "by", "several", "times", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "massive multiple-input multiple-output", "start": 63, "end": 101, "i_start": 10, "i_end": 16}, "verb": {"text": "has been shown", "start": 102, "end": 116, "i_start": 17, "i_end": 19}}, {"character": {"text": "output", "start": 95, "end": 101, "i_start": 16, "i_end": 16}, "action": {"text": "increase", "start": 131, "end": 139, "i_start": 24, "i_end": 24}}], "id": 3379}, {"sent": "we use the implementations provided by the scikit-learn library .", "tokens": ["we", "use", "the", "implementations", "provided", "by", "the", "scikit", "-", "learn", "library", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "library", "start": 56, "end": 63, "i_start": 10, "i_end": 10}, "action": {"text": "provided", "start": 27, "end": 35, "i_start": 4, "i_end": 4}}], "id": 3380}, {"sent": "since the pioneering work by alamouti , orthogonal designs have become an effective technique for the design of space-time block codes .", "tokens": ["since", "the", "pioneering", "work", "by", "alamouti", ",", "orthogonal", "designs", "have", "become", "an", "effective", "technique", "for", "the", "design", "of", "space", "-", "time", "block", "codes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "orthogonal designs", "start": 40, "end": 58, "i_start": 7, "i_end": 8}, "verb": {"text": "have become", "start": 59, "end": 70, "i_start": 9, "i_end": 10}}, {"character": {"text": "technique", "start": 84, "end": 93, "i_start": 13, "i_end": 13}, "action": {"text": "effective", "start": 74, "end": 83, "i_start": 12, "i_end": 12}}], "id": 3381}, {"sent": "the recent detection of gravitational waves due to the coalescing of two orbiting neutron stars opened a new window to study their tidal deformations hence , allowing the study of the properties of the matter fields that compose this kind of objects .", "tokens": ["the", "recent", "detection", "of", "gravitational", "waves", "due", "to", "the", "coalescing", "of", "two", "orbiting", "neutron", "stars", "opened", "a", "new", "window", "to", "study", "their", "tidal", "deformations", "hence", ",", "allowing", "the", "study", "of", "the", "properties", "of", "the", "matter", "fields", "that", "compose", "this", "kind", "of", "objects", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the recent detection of gravitational waves due to the coalescing of two orbiting neutron stars", "start": 0, "end": 95, "i_start": 0, "i_end": 14}, "verb": {"text": "opened", "start": 96, "end": 102, "i_start": 15, "i_end": 15}}, {"character": {"text": "detection", "start": 11, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "opened", "start": 96, "end": 102, "i_start": 15, "i_end": 15}}, {"character": {"text": "two orbiting neutron stars", "start": 69, "end": 95, "i_start": 11, "i_end": 14}, "action": {"text": "orbiting", "start": 73, "end": 81, "i_start": 12, "i_end": 12}}], "id": 3382}, {"sent": "the duality here is the electric-magnetic duality that exchanges the electric and magnetic charges .", "tokens": ["the", "duality", "here", "is", "the", "electric", "-", "magnetic", "duality", "that", "exchanges", "the", "electric", "and", "magnetic", "charges", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the duality here", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "duality", "start": 42, "end": 49, "i_start": 8, "i_end": 8}, "action": {"text": "exchanges", "start": 55, "end": 64, "i_start": 10, "i_end": 10}}], "id": 3383}, {"sent": "epidemic spreading in scale-free networks .", "tokens": ["epidemic", "spreading", "in", "scale", "-", "free", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3384}, {"sent": "typical examples include variational autoencoders and generative adversarial networks .", "tokens": ["typical", "examples", "include", "variational", "autoencoders", "and", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "typical examples", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "include", "start": 17, "end": 24, "i_start": 2, "i_end": 2}}], "id": 3385}, {"sent": "the analysis of the minimal model that leads to these conclusions is carried out in the fundamental paper and is achieved by considering commutative graded differential algebras over q which are equipped with filtrations as a new structural ingredient .", "tokens": ["the", "analysis", "of", "the", "minimal", "model", "that", "leads", "to", "these", "conclusions", "is", "carried", "out", "in", "the", "fundamental", "paper", "and", "is", "achieved", "by", "considering", "commutative", "graded", "differential", "algebras", "over", "q", "which", "are", "equipped", "with", "filtrations", "as", "a", "new", "structural", "ingredient", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the analysis of the minimal model that leads to these conclusions", "start": 0, "end": 65, "i_start": 0, "i_end": 10}, "verb": {"text": "is carried out", "start": 66, "end": 80, "i_start": 11, "i_end": 13}}, {"subject": {"text": "the analysis of the minimal model that leads to these conclusions", "start": 0, "end": 65, "i_start": 0, "i_end": 10}, "verb": {"text": "achieved", "start": 113, "end": 121, "i_start": 20, "i_end": 20}}, {"character": {"text": "model", "start": 28, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "leads", "start": 39, "end": 44, "i_start": 7, "i_end": 7}}], "id": 3386}, {"sent": "more recently , felzenszwalb et al introduce the deformable part model , which is able to successfully identify complex objects .", "tokens": ["more", "recently", ",", "felzenszwalb", "et", "al", "introduce", "the", "deformable", "part", "model", ",", "which", "is", "able", "to", "successfully", "identify", "complex", "objects", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "felzenszwalb et al", "start": 16, "end": 34, "i_start": 3, "i_end": 5}, "verb": {"text": "introduce", "start": 35, "end": 44, "i_start": 6, "i_end": 6}}, {"character": {"text": "felzenszwalb", "start": 16, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "introduce", "start": 35, "end": 44, "i_start": 6, "i_end": 6}}, {"character": {"text": "model", "start": 65, "end": 70, "i_start": 10, "i_end": 10}, "action": {"text": "identify", "start": 103, "end": 111, "i_start": 17, "i_end": 17}}], "id": 3387}, {"sent": "resnets have outperformed previous stateof-the-art models in various tasks , such as object detection .", "tokens": ["resnets", "have", "outperformed", "previous", "stateof", "-", "the", "-", "art", "models", "in", "various", "tasks", ",", "such", "as", "object", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "resnets", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "have outperformed", "start": 8, "end": 25, "i_start": 1, "i_end": 2}}], "id": 3388}, {"sent": "the chiral condensate is the natural order parameter associated the chiral symmetry breaking .", "tokens": ["the", "chiral", "condensate", "is", "the", "natural", "order", "parameter", "associated", "the", "chiral", "symmetry", "breaking", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the chiral condensate", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the natural order parameter", "start": 25, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "associated", "start": 53, "end": 63, "i_start": 8, "i_end": 8}}], "id": 3389}, {"sent": "thus 3-dimensional gravity is a degenerate example and extrapolation of its gauge properties to four dimensions seems misleading .", "tokens": ["thus", "3", "-", "dimensional", "gravity", "is", "a", "degenerate", "example", "and", "extrapolation", "of", "its", "gauge", "properties", "to", "four", "dimensions", "seems", "misleading", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "3-dimensional gravity", "start": 5, "end": 26, "i_start": 1, "i_end": 4}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 5, "i_end": 5}}, {"subject": {"text": "3-dimensional gravity", "start": 5, "end": 26, "i_start": 1, "i_end": 4}, "verb": {"text": "seems", "start": 112, "end": 117, "i_start": 18, "i_end": 18}}, {"character": {"text": "extrapolation", "start": 55, "end": 68, "i_start": 10, "i_end": 10}, "action": {"text": "misleading", "start": 118, "end": 128, "i_start": 19, "i_end": 19}}], "id": 3390}, {"sent": "deep convolutional neural networks have enabled unparalleled breakthroughs in a variety of visual tasks , such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "enabled", "unparalleled", "breakthroughs", "in", "a", "variety", "of", "visual", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have enabled", "start": 35, "end": 47, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "enabled", "start": 40, "end": 47, "i_start": 5, "i_end": 5}}], "id": 3391}, {"sent": "in this section , we demonstrate our method via an analysis of the resting-state fmri data that are collected in the autism brain imaging data exchange study .", "tokens": ["in", "this", "section", ",", "we", "demonstrate", "our", "method", "via", "an", "analysis", "of", "the", "resting", "-", "state", "fmri", "data", "that", "are", "collected", "in", "the", "autism", "brain", "imaging", "data", "exchange", "study", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "demonstrate", "start": 21, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "demonstrate", "start": 21, "end": 32, "i_start": 5, "i_end": 5}}], "id": 3392}, {"sent": "cosmic strings are linear topological defects that can be produced in the early universe via phase transitions .", "tokens": ["cosmic", "strings", "are", "linear", "topological", "defects", "that", "can", "be", "produced", "in", "the", "early", "universe", "via", "phase", "transitions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3393}, {"sent": "a virtual knot is an equivalence class of circular gauss diagrams up to this equivalence relation .", "tokens": ["a", "virtual", "knot", "is", "an", "equivalence", "class", "of", "circular", "gauss", "diagrams", "up", "to", "this", "equivalence", "relation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a virtual knot", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}], "id": 3394}, {"sent": "standard medication paths can not be easily achieved , as the course and symptoms of the disease varies significantly among patients .", "tokens": ["standard", "medication", "paths", "can", "not", "be", "easily", "achieved", ",", "as", "the", "course", "and", "symptoms", "of", "the", "disease", "varies", "significantly", "among", "patients", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "standard medication paths", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 44, "end": 52, "i_start": 7, "i_end": 7}}, {"subject": {"text": "standard medication paths", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "can not be", "start": 26, "end": 36, "i_start": 3, "i_end": 5}}], "id": 3395}, {"sent": "the extended yaleb face dataset consists of 2414 near frontal face images of 38 individuals .", "tokens": ["the", "extended", "yaleb", "face", "dataset", "consists", "of", "2414", "near", "frontal", "face", "images", "of", "38", "individuals", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the extended yaleb face dataset", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "consists", "start": 32, "end": 40, "i_start": 5, "i_end": 5}}], "id": 3396}, {"sent": "by the gottesman-knill theorem , however , they are efficiently classically simulatable and not quantum universal .", "tokens": ["by", "the", "gottesman", "-", "knill", "theorem", ",", "however", ",", "they", "are", "efficiently", "classically", "simulatable", "and", "not", "quantum", "universal", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 43, "end": 47, "i_start": 9, "i_end": 9}, "verb": {"text": "are", "start": 48, "end": 51, "i_start": 10, "i_end": 10}}], "id": 3397}, {"sent": "the adam optimizer was used with an initial learning rate 1e-4 , which decays during training .", "tokens": ["the", "adam", "optimizer", "was", "used", "with", "an", "initial", "learning", "rate", "1e-4", ",", "which", "decays", "during", "training", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the adam optimizer", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "was used", "start": 19, "end": 27, "i_start": 3, "i_end": 4}}], "id": 3398}, {"sent": "another contribution is that we analyze the phase transition for the canonical ensemble both in terms of the spin per site and the empirical measure .", "tokens": ["another", "contribution", "is", "that", "we", "analyze", "the", "phase", "transition", "for", "the", "canonical", "ensemble", "both", "in", "terms", "of", "the", "spin", "per", "site", "and", "the", "empirical", "measure", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "another contribution", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 29, "end": 31, "i_start": 4, "i_end": 4}, "verb": {"text": "analyze", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "analyze", "start": 32, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "contribution", "start": 8, "end": 20, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "analyze", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}], "id": 3399}, {"sent": "in recent years , deep neural networks have achieved great success in a variety of machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "achieved", "great", "success", "in", "a", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}], "id": 3400}, {"sent": "recently , deep learning based methods , such as faster r-cnn , have achieved significant improvement in object detection with real-time performance .", "tokens": ["recently", ",", "deep", "learning", "based", "methods", ",", "such", "as", "faster", "r", "-", "cnn", ",", "have", "achieved", "significant", "improvement", "in", "object", "detection", "with", "real", "-", "time", "performance", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep learning based methods", "start": 11, "end": 38, "i_start": 2, "i_end": 5}, "verb": {"text": "have achieved", "start": 64, "end": 77, "i_start": 14, "i_end": 15}}, {"character": {"text": "methods", "start": 31, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 69, "end": 77, "i_start": 15, "i_end": 15}}], "id": 3401}, {"sent": "in recent years , neural machine translation has achieved great success in some language pairs , rivalling the state-ofthe-art statistical machine translation .", "tokens": ["in", "recent", "years", ",", "neural", "machine", "translation", "has", "achieved", "great", "success", "in", "some", "language", "pairs", ",", "rivalling", "the", "state", "-", "ofthe", "-", "art", "statistical", "machine", "translation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural machine translation", "start": 18, "end": 44, "i_start": 4, "i_end": 6}, "verb": {"text": "has achieved", "start": 45, "end": 57, "i_start": 7, "i_end": 8}}, {"character": {"text": "translation", "start": 33, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 49, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "translation", "start": 33, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 64, "end": 71, "i_start": 10, "i_end": 10}}, {"character": {"text": "achieved", "start": 49, "end": 57, "i_start": 8, "i_end": 8}, "action": {"text": "rivalling", "start": 97, "end": 106, "i_start": 16, "i_end": 16}}], "id": 3402}, {"sent": "the above decoder is a straightforward generalization of a standard decoder that is used in classical group testing .", "tokens": ["the", "above", "decoder", "is", "a", "straightforward", "generalization", "of", "a", "standard", "decoder", "that", "is", "used", "in", "classical", "group", "testing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the above decoder", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}], "id": 3403}, {"sent": "the dashed curves denote the results by the quadrupole formula .", "tokens": ["the", "dashed", "curves", "denote", "the", "results", "by", "the", "quadrupole", "formula", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the dashed curves", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "denote", "start": 18, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "curves", "start": 11, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "denote", "start": 18, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3404}, {"sent": "in , farabet et al propose to learn hierarchical features with cnns for scene labeling .", "tokens": ["in", ",", "farabet", "et", "al", "propose", "to", "learn", "hierarchical", "features", "with", "cnns", "for", "scene", "labeling", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "farabet et al", "start": 5, "end": 18, "i_start": 2, "i_end": 4}, "verb": {"text": "propose", "start": 19, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "farabet", "start": 5, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "propose", "start": 19, "end": 26, "i_start": 5, "i_end": 5}}], "id": 3405}, {"sent": "in such a case , it is possible to show that n m iis exactly equal to 1 .", "tokens": ["in", "such", "a", "case", ",", "it", "is", "possible", "to", "show", "that", "n", "m", "iis", "exactly", "equal", "to", "1", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 17, "end": 19, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 6, "i_end": 6}}], "id": 3406}, {"sent": "applications of dec-pomdps include coordinating the operation of planetary exploration rovers .", "tokens": ["applications", "of", "dec", "-", "pomdps", "include", "coordinating", "the", "operation", "of", "planetary", "exploration", "rovers", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "applications of dec-pomdps", "start": 0, "end": 26, "i_start": 0, "i_end": 4}, "verb": {"text": "include", "start": 27, "end": 34, "i_start": 5, "i_end": 5}}], "id": 3407}, {"sent": "in this paper , we choose the universal sentence encoder to embed both the words and sentences since we found that satisfactory embeddings can be obtained for both of them .", "tokens": ["in", "this", "paper", ",", "we", "choose", "the", "universal", "sentence", "encoder", "to", "embed", "both", "the", "words", "and", "sentences", "since", "we", "found", "that", "satisfactory", "embeddings", "can", "be", "obtained", "for", "both", "of", "them", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "choose", "start": 19, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "choose", "start": 19, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "encoder", "start": 49, "end": 56, "i_start": 9, "i_end": 9}, "action": {"text": "embed", "start": 60, "end": 65, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "found", "start": 104, "end": 109, "i_start": 19, "i_end": 19}}], "id": 3408}, {"sent": "in recent years , convolutional neural networks have become the dominant approach for a variety of computer vision tasks , eg , image classification .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "become", "the", "dominant", "approach", "for", "a", "variety", "of", "computer", "vision", "tasks", ",", "eg", ",", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have become", "start": 48, "end": 59, "i_start": 7, "i_end": 8}}, {"character": {"text": "approach", "start": 73, "end": 81, "i_start": 11, "i_end": 11}, "action": {"text": "dominant", "start": 64, "end": 72, "i_start": 10, "i_end": 10}}], "id": 3409}, {"sent": "in the body-vector representation , all the elements of the rotation matrix a i are considered as dynamical variables .", "tokens": ["in", "the", "body", "-", "vector", "representation", ",", "all", "the", "elements", "of", "the", "rotation", "matrix", "a", "i", "are", "considered", "as", "dynamical", "variables", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "all the elements of the rotation matrix a i", "start": 36, "end": 79, "i_start": 7, "i_end": 15}, "verb": {"text": "are considered", "start": 80, "end": 94, "i_start": 16, "i_end": 17}}], "id": 3410}, {"sent": "spronk , ideals with bounded approximate identities in fourier algebras .", "tokens": ["spronk", ",", "ideals", "with", "bounded", "approximate", "identities", "in", "fourier", "algebras", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3411}, {"sent": "now we proceed on to define smarandache parallel .", "tokens": ["now", "we", "proceed", "on", "to", "define", "smarandache", "parallel", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed on", "start": 7, "end": 17, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 3412}, {"sent": "in , the benefits of collaborative networking for users and operators are outlined .", "tokens": ["in", ",", "the", "benefits", "of", "collaborative", "networking", "for", "users", "and", "operators", "are", "outlined", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the benefits of collaborative networking for users and operators", "start": 5, "end": 69, "i_start": 2, "i_end": 10}, "verb": {"text": "are outlined", "start": 70, "end": 82, "i_start": 11, "i_end": 12}}, {"character": {"text": "networking", "start": 35, "end": 45, "i_start": 6, "i_end": 6}, "action": {"text": "benefits", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}], "id": 3413}, {"sent": "an isomorphism f is called correct isomorphism , if 1 .", "tokens": ["an", "isomorphism", "f", "is", "called", "correct", "isomorphism", ",", "if", "1", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an isomorphism f", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 17, "end": 26, "i_start": 3, "i_end": 4}}], "id": 3414}, {"sent": "mle based on the extended kalman filter is used to estimate the parameters in sde models by several authors , such as and the references therein .", "tokens": ["mle", "based", "on", "the", "extended", "kalman", "filter", "is", "used", "to", "estimate", "the", "parameters", "in", "sde", "models", "by", "several", "authors", ",", "such", "as", "and", "the", "references", "therein", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "mle based on the extended kalman filter", "start": 0, "end": 39, "i_start": 0, "i_end": 6}, "verb": {"text": "is used", "start": 40, "end": 47, "i_start": 7, "i_end": 8}}], "id": 3415}, {"sent": "grand and small lebesgue spaces and their analogs .", "tokens": ["grand", "and", "small", "lebesgue", "spaces", "and", "their", "analogs", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3416}, {"sent": "the space of equivalence classes will be denoted by p .", "tokens": ["the", "space", "of", "equivalence", "classes", "will", "be", "denoted", "by", "p", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the space of equivalence classes", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "will be denoted", "start": 33, "end": 48, "i_start": 5, "i_end": 7}}], "id": 3417}, {"sent": "as future work we intend on improving the detector mechanism , possibly using generative adversarial networks .", "tokens": ["as", "future", "work", "we", "intend", "on", "improving", "the", "detector", "mechanism", ",", "possibly", "using", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "intend", "start": 18, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "improving", "start": 28, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "mechanism", "start": 51, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "detector", "start": 42, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "using", "start": 72, "end": 77, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "work", "start": 10, "end": 14, "i_start": 2, "i_end": 2}}], "id": 3418}, {"sent": "specifically , the authors of the paper showed that the running time of cdcl solvers is strongly correlated with community structures of sat instances .", "tokens": ["specifically", ",", "the", "authors", "of", "the", "paper", "showed", "that", "the", "running", "time", "of", "cdcl", "solvers", "is", "strongly", "correlated", "with", "community", "structures", "of", "sat", "instances", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors of the paper", "start": 15, "end": 39, "i_start": 2, "i_end": 6}, "verb": {"text": "showed", "start": 40, "end": 46, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the running time of cdcl solvers", "start": 52, "end": 84, "i_start": 9, "i_end": 14}, "verb": {"text": "correlated", "start": 97, "end": 107, "i_start": 17, "i_end": 17}}, {"character": {"text": "cdcl", "start": 72, "end": 76, "i_start": 13, "i_end": 13}, "action": {"text": "running", "start": 56, "end": 63, "i_start": 10, "i_end": 10}}], "id": 3419}, {"sent": "firstly we exploit the freedom in choosing the transformation operator ga in any arbitrary form .", "tokens": ["firstly", "we", "exploit", "the", "freedom", "in", "choosing", "the", "transformation", "operator", "ga", "in", "any", "arbitrary", "form", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "exploit", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "exploit", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3420}, {"sent": "yonezawa , in the structure and properties of matter , edited by t .", "tokens": ["yonezawa", ",", "in", "the", "structure", "and", "properties", "of", "matter", ",", "edited", "by", "t", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3421}, {"sent": "the sta bility of the bifurcating periodic solutions and the direction of the hopf bifurcation are then determined by applying the normal form theory .", "tokens": ["the", "sta", "bility", "of", "the", "bifurcating", "periodic", "solutions", "and", "the", "direction", "of", "the", "hopf", "bifurcation", "are", "then", "determined", "by", "applying", "the", "normal", "form", "theory", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "the sta bility of the bifurcating periodic solutions and the direction of the hopf bifurcation", "start": 0, "end": 94, "i_start": 0, "i_end": 14}, "verb": {"text": "determined", "start": 104, "end": 114, "i_start": 17, "i_end": 17}}, {"subject": {"text": "the sta bility of the bifurcating periodic solutions and the direction of the hopf bifurcation", "start": 0, "end": 94, "i_start": 0, "i_end": 14}, "verb": {"text": "are", "start": 95, "end": 98, "i_start": 15, "i_end": 15}}, {"character": {"text": "applying", "start": 118, "end": 126, "i_start": 19, "i_end": 19}, "action": {"text": "determined", "start": 104, "end": 114, "i_start": 17, "i_end": 17}}], "id": 3422}, {"sent": "reference generation block within the control architecture uses the algorithms developed by the authors for generating humanlike motions considering the scapulohumeral rhythms .", "tokens": ["reference", "generation", "block", "within", "the", "control", "architecture", "uses", "the", "algorithms", "developed", "by", "the", "authors", "for", "generating", "humanlike", "motions", "considering", "the", "scapulohumeral", "rhythms", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "reference generation block within the control architecture", "start": 0, "end": 58, "i_start": 0, "i_end": 6}, "verb": {"text": "uses", "start": 59, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "block", "start": 21, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "uses", "start": 59, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "block", "start": 21, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "generating", "start": 108, "end": 118, "i_start": 15, "i_end": 15}}], "id": 3423}, {"sent": "deep neural networks have shown remarkable success in many computer vision tasks such as image classification .", "tokens": ["deep", "neural", "networks", "have", "shown", "remarkable", "success", "in", "many", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}], "id": 3424}, {"sent": "indeed , it is known that every monotone graph property in randomly generated graphs has a sharp transition threshold .", "tokens": ["indeed", ",", "it", "is", "known", "that", "every", "monotone", "graph", "property", "in", "randomly", "generated", "graphs", "has", "a", "sharp", "transition", "threshold", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "verb": {"text": "is known", "start": 12, "end": 20, "i_start": 3, "i_end": 4}}, {"subject": {"text": "every monotone graph property in randomly generated graphs", "start": 26, "end": 84, "i_start": 6, "i_end": 13}, "verb": {"text": "has", "start": 85, "end": 88, "i_start": 14, "i_end": 14}}, {"character": {"text": "property", "start": 47, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "has", "start": 85, "end": 88, "i_start": 14, "i_end": 14}}], "id": 3425}, {"sent": "then , hou et al propose dense short connections to skip-layers within the hed architecture to obtain rich multi-scale features for salient object detection .", "tokens": ["then", ",", "hou", "et", "al", "propose", "dense", "short", "connections", "to", "skip", "-", "layers", "within", "the", "he", "d", "architecture", "to", "obtain", "rich", "multi", "-", "scale", "features", "for", "salient", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hou et al", "start": 7, "end": 16, "i_start": 2, "i_end": 4}, "verb": {"text": "propose", "start": 17, "end": 24, "i_start": 5, "i_end": 5}}, {"character": {"text": "hou", "start": 7, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "propose", "start": 17, "end": 24, "i_start": 5, "i_end": 5}}], "id": 3426}, {"sent": "the model was trained using mini-batch sgd with its learning rate controlled by adam and its mini-batch size set to 32 .", "tokens": ["the", "model", "was", "trained", "using", "mini", "-", "batch", "sgd", "with", "its", "learning", "rate", "controlled", "by", "adam", "and", "its", "mini", "-", "batch", "size", "set", "to", "32", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "was trained", "start": 10, "end": 21, "i_start": 2, "i_end": 3}}, {"character": {"text": "adam", "start": 80, "end": 84, "i_start": 15, "i_end": 15}, "action": {"text": "controlled", "start": 66, "end": 76, "i_start": 13, "i_end": 13}}, {"character": {"text": "model", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "learning", "start": 52, "end": 60, "i_start": 11, "i_end": 11}}], "id": 3427}, {"sent": "the move on the left is understood to preserve orientations and be between arcs of the same color .", "tokens": ["the", "move", "on", "the", "left", "is", "understood", "to", "preserve", "orientations", "and", "be", "between", "arcs", "of", "the", "same", "color", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the move on the left", "start": 0, "end": 20, "i_start": 0, "i_end": 4}, "verb": {"text": "is understood", "start": 21, "end": 34, "i_start": 5, "i_end": 6}}, {"character": {"text": "move", "start": 4, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "preserve", "start": 38, "end": 46, "i_start": 8, "i_end": 8}}], "id": 3428}, {"sent": "the cms particle-flow event algorithm reconstructs and identifies individual particles with an optimized combination of information from the various elements of the cms detector .", "tokens": ["the", "cms", "particle", "-", "flow", "event", "algorithm", "reconstructs", "and", "identifies", "individual", "particles", "with", "an", "optimized", "combination", "of", "information", "from", "the", "various", "elements", "of", "the", "cms", "detector", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the cms particle-flow event", "start": 0, "end": 27, "i_start": 0, "i_end": 5}, "verb": {"text": "reconstructs", "start": 38, "end": 50, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the cms particle-flow event", "start": 0, "end": 27, "i_start": 0, "i_end": 5}, "verb": {"text": "identifies", "start": 55, "end": 65, "i_start": 9, "i_end": 9}}, {"character": {"text": "algorithm", "start": 28, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "reconstructs", "start": 38, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "algorithm", "start": 28, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "identifies", "start": 55, "end": 65, "i_start": 9, "i_end": 9}}], "id": 3429}, {"sent": "an embedding from a substructure of a into b is called a partial isomorphism between a and b .", "tokens": ["an", "embedding", "from", "a", "substructure", "of", "a", "into", "b", "is", "called", "a", "partial", "isomorphism", "between", "a", "and", "b", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "an embedding from a substructure of a into b", "start": 0, "end": 44, "i_start": 0, "i_end": 8}, "verb": {"text": "is called", "start": 45, "end": 54, "i_start": 9, "i_end": 10}}], "id": 3430}, {"sent": "the generative adversarial network is an emerging deep learning technique for modeling high-dimensional data distributions .", "tokens": ["the", "generative", "adversarial", "network", "is", "an", "emerging", "deep", "learning", "technique", "for", "modeling", "high", "-", "dimensional", "data", "distributions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the generative adversarial network", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 4, "i_end": 4}}, {"character": {"text": "technique", "start": 64, "end": 73, "i_start": 9, "i_end": 9}, "action": {"text": "emerging", "start": 41, "end": 49, "i_start": 6, "i_end": 6}}], "id": 3431}, {"sent": "introduction to the theory of disordered systems .", "tokens": ["introduction", "to", "the", "theory", "of", "disordered", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3432}, {"sent": "thus , discrete critical measures are limit distributions of zeros of the heine-stieltjes polynomials .", "tokens": ["thus", ",", "discrete", "critical", "measures", "are", "limit", "distributions", "of", "zeros", "of", "the", "heine", "-", "stieltjes", "polynomials", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "discrete critical measures", "start": 7, "end": 33, "i_start": 2, "i_end": 4}, "verb": {"text": "are", "start": 34, "end": 37, "i_start": 5, "i_end": 5}}], "id": 3433}, {"sent": "another distinct feature of the quantum kicked rotor is the quantum resonance effect .", "tokens": ["another", "distinct", "feature", "of", "the", "quantum", "kicked", "rotor", "is", "the", "quantum", "resonance", "effect", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another distinct feature of the quantum kicked rotor", "start": 0, "end": 52, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 53, "end": 55, "i_start": 8, "i_end": 8}}], "id": 3434}, {"sent": "we can define only one substructure in this case namely pure neutrosophic interval matrix subsemigroup .", "tokens": ["we", "can", "define", "only", "one", "substructure", "in", "this", "case", "namely", "pure", "neutrosophic", "interval", "matrix", "subsemigroup", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "can define", "start": 3, "end": 13, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "define", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}], "id": 3435}, {"sent": "a general calculus of pseudodifferential operators .", "tokens": ["a", "general", "calculus", "of", "pseudodifferential", "operators", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3436}, {"sent": "note that dls are decidable fragments of fol that are incomparable with clausal logics as regards the expressive power and the semantics .", "tokens": ["note", "that", "dls", "are", "decidable", "fragments", "of", "fol", "that", "are", "incomparable", "with", "clausal", "logics", "as", "regards", "the", "expressive", "power", "and", "the", "semantics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "power", "start": 113, "end": 118, "i_start": 18, "i_end": 18}, "action": {"text": "expressive", "start": 102, "end": 112, "i_start": 17, "i_end": 17}}], "id": 3437}, {"sent": "the methods developed to study this limit , outlined in , are based on the iterated mayer expansion for a non-ideal gas of particles confined along a contour c .", "tokens": ["the", "methods", "developed", "to", "study", "this", "limit", ",", "outlined", "in", ",", "are", "based", "on", "the", "iterated", "mayer", "expansion", "for", "a", "non", "-", "ideal", "gas", "of", "particles", "confined", "along", "a", "contour", "c", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the methods", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "developed", "start": 12, "end": 21, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the methods", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "based", "start": 62, "end": 67, "i_start": 12, "i_end": 12}}], "id": 3438}, {"sent": "a strategy for verification of weather element forecasts from ensemble prediction systems .", "tokens": ["a", "strategy", "for", "verification", "of", "weather", "element", "forecasts", "from", "ensemble", "prediction", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "systems", "start": 82, "end": 89, "i_start": 11, "i_end": 11}, "action": {"text": "prediction", "start": 71, "end": 81, "i_start": 10, "i_end": 10}}], "id": 3439}, {"sent": "we learn maximum likelihood estimates of these parameters by using the expectation maximisation algorithm .", "tokens": ["we", "learn", "maximum", "likelihood", "estimates", "of", "these", "parameters", "by", "using", "the", "expectation", "maximisation", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "learn", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "learn", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 61, "end": 66, "i_start": 9, "i_end": 9}}], "id": 3440}, {"sent": "cosmic strings are topologically stable objects which may have formed during the breaking of a local ugauge symmetry in the very early universe .", "tokens": ["cosmic", "strings", "are", "topologically", "stable", "objects", "which", "may", "have", "formed", "during", "the", "breaking", "of", "a", "local", "ugauge", "symmetry", "in", "the", "very", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3441}, {"sent": "the interaction between the valence electrons and ionic cores was described by the projector augmented wave method .", "tokens": ["the", "interaction", "between", "the", "valence", "electrons", "and", "ionic", "cores", "was", "described", "by", "the", "projector", "augmented", "wave", "method", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the interaction between the valence electrons and ionic cores", "start": 0, "end": 61, "i_start": 0, "i_end": 8}, "verb": {"text": "was described", "start": 62, "end": 75, "i_start": 9, "i_end": 10}}, {"character": {"text": "method", "start": 108, "end": 114, "i_start": 16, "i_end": 16}, "action": {"text": "described", "start": 66, "end": 75, "i_start": 10, "i_end": 10}}, {"character": {"text": "projector", "start": 83, "end": 92, "i_start": 13, "i_end": 13}, "action": {"text": "augmented", "start": 93, "end": 102, "i_start": 14, "i_end": 14}}, {"character": {"text": "electrons", "start": 36, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "interaction", "start": 4, "end": 15, "i_start": 1, "i_end": 1}}], "id": 3442}, {"sent": "first order asymptotics for the travelling waves in the gross-pitaevskii equa tion .", "tokens": ["first", "order", "asymptotics", "for", "the", "travelling", "waves", "in", "the", "gross", "-", "pitaevskii", "equa", "tion", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "waves", "start": 43, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "travelling", "start": 32, "end": 42, "i_start": 5, "i_end": 5}}], "id": 3443}, {"sent": "so far , fock states and their superpositions of a resonator have been experimentally produced by using a superconducting qubit .", "tokens": ["so", "far", ",", "fock", "states", "and", "their", "superpositions", "of", "a", "resonator", "have", "been", "experimentally", "produced", "by", "using", "a", "superconducting", "qubit", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "fock states and their superpositions of a resonator", "start": 9, "end": 60, "i_start": 3, "i_end": 10}, "verb": {"text": "produced", "start": 86, "end": 94, "i_start": 14, "i_end": 14}}, {"subject": {"text": "fock states and their superpositions of a resonator", "start": 9, "end": 60, "i_start": 3, "i_end": 10}, "verb": {"text": "have been", "start": 61, "end": 70, "i_start": 11, "i_end": 12}}], "id": 3444}, {"sent": "during the last decade , deep learning algorithms , especially convolutional neural networks have achieved remarkable progress on numerous practical vision tasks .", "tokens": ["during", "the", "last", "decade", ",", "deep", "learning", "algorithms", ",", "especially", "convolutional", "neural", "networks", "have", "achieved", "remarkable", "progress", "on", "numerous", "practical", "vision", "tasks", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep learning algorithms", "start": 25, "end": 49, "i_start": 5, "i_end": 7}, "verb": {"text": "have achieved", "start": 93, "end": 106, "i_start": 13, "i_end": 14}}, {"character": {"text": "algorithms", "start": 39, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 98, "end": 106, "i_start": 14, "i_end": 14}}, {"character": {"text": "algorithms", "start": 39, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "learning", "start": 30, "end": 38, "i_start": 6, "i_end": 6}}], "id": 3445}, {"sent": "recent results include work on controllable discrete-time linear systems .", "tokens": ["recent", "results", "include", "work", "on", "controllable", "discrete", "-", "time", "linear", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "recent results", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "include", "start": 15, "end": 22, "i_start": 2, "i_end": 2}}], "id": 3446}, {"sent": "our estimates suggest that clonal interference likely occurs in the progression of colon cancer , and possibly other cancers where spatial structure matters .", "tokens": ["our", "estimates", "suggest", "that", "clonal", "interference", "likely", "occurs", "in", "the", "progression", "of", "colon", "cancer", ",", "and", "possibly", "other", "cancers", "where", "spatial", "structure", "matters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our estimates", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "suggest", "start": 14, "end": 21, "i_start": 2, "i_end": 2}}, {"subject": {"text": "clonal interference", "start": 27, "end": 46, "i_start": 4, "i_end": 5}, "verb": {"text": "occurs", "start": 54, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "estimates", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "suggest", "start": 14, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "clonal", "start": 27, "end": 33, "i_start": 4, "i_end": 4}, "action": {"text": "interference", "start": 34, "end": 46, "i_start": 5, "i_end": 5}}], "id": 3447}, {"sent": "a class of fully nonlinear bspdes , the so-called backward stochastic hamilton-jacobi-bellman equations , were proposed by peng in the study of the optimal control problems for non-markovian cases .", "tokens": ["a", "class", "of", "fully", "nonlinear", "bspdes", ",", "the", "so", "-", "called", "backward", "stochastic", "hamilton", "-", "jacobi", "-", "bellman", "equations", ",", "were", "proposed", "by", "peng", "in", "the", "study", "of", "the", "optimal", "control", "problems", "for", "non", "-", "markovian", "cases", "."], "score": [1, 0, 0, 0, 1], "labels": [{"subject": {"text": "a class of fully nonlinear bspdes", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "were proposed", "start": 106, "end": 119, "i_start": 20, "i_end": 21}}, {"character": {"text": "peng", "start": 123, "end": 127, "i_start": 23, "i_end": 23}, "action": {"text": "proposed", "start": 111, "end": 119, "i_start": 21, "i_end": 21}}], "id": 3448}, {"sent": "we use the gradient boosting classifier implemented in the scikit-learn toolkit .", "tokens": ["we", "use", "the", "gradient", "boosting", "classifier", "implemented", "in", "the", "scikit", "-", "learn", "toolkit", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "classifier", "start": 29, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "boosting", "start": 20, "end": 28, "i_start": 4, "i_end": 4}}], "id": 3449}, {"sent": "over the past few years , deep convolutional neural networks have been very successful in a wide range of computer vision tasks such as image classification .", "tokens": ["over", "the", "past", "few", "years", ",", "deep", "convolutional", "neural", "networks", "have", "been", "very", "successful", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 26, "end": 60, "i_start": 6, "i_end": 9}, "verb": {"text": "have been", "start": 61, "end": 70, "i_start": 10, "i_end": 11}}, {"character": {"text": "networks", "start": 52, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "successful", "start": 76, "end": 86, "i_start": 13, "i_end": 13}}], "id": 3450}, {"sent": "this foliation is the well-known horosphere foliation .", "tokens": ["this", "foliation", "is", "the", "well", "-", "known", "horosphere", "foliation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this foliation", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 3451}, {"sent": "floer homology of manifolds with contact type boundary .", "tokens": ["floer", "homology", "of", "manifolds", "with", "contact", "type", "boundary", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3452}, {"sent": "the exchange correlation term was described using the gga functional proposed by perdew , burke , and ernzerhof .", "tokens": ["the", "exchange", "correlation", "term", "was", "described", "using", "the", "gga", "functional", "proposed", "by", "perdew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange correlation term", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "was described", "start": 30, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "perdew", "start": 81, "end": 87, "i_start": 12, "i_end": 12}, "action": {"text": "proposed", "start": 69, "end": 77, "i_start": 10, "i_end": 10}}, {"character": {"text": "burke", "start": 90, "end": 95, "i_start": 14, "i_end": 14}, "action": {"text": "proposed", "start": 69, "end": 77, "i_start": 10, "i_end": 10}}, {"character": {"text": "ernzerhof", "start": 102, "end": 111, "i_start": 17, "i_end": 17}, "action": {"text": "proposed", "start": 69, "end": 77, "i_start": 10, "i_end": 10}}], "id": 3453}, {"sent": "the maximum entropy irl framework has proved successful at learning reward functions from expert demonstrations .", "tokens": ["the", "maximum", "entropy", "irl", "framework", "has", "proved", "successful", "at", "learning", "reward", "functions", "from", "expert", "demonstrations", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the maximum entropy irl framework", "start": 0, "end": 33, "i_start": 0, "i_end": 4}, "verb": {"text": "has proved", "start": 34, "end": 44, "i_start": 5, "i_end": 6}}, {"character": {"text": "framework", "start": 24, "end": 33, "i_start": 4, "i_end": 4}, "action": {"text": "successful", "start": 45, "end": 55, "i_start": 7, "i_end": 7}}], "id": 3454}, {"sent": "piewak et al employ a fully convolutional neural network with dogma input to classify static and moving cells .", "tokens": ["piewak", "et", "al", "employ", "a", "fully", "convolutional", "neural", "network", "with", "dogma", "input", "to", "classify", "static", "and", "moving", "cells", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "piewak et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "employ", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "piewak", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "piewak", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "classify", "start": 77, "end": 85, "i_start": 13, "i_end": 13}}], "id": 3455}, {"sent": "the parameter ccharge is used in the charge distribution in the all-order wave function calculations .", "tokens": ["the", "parameter", "ccharge", "is", "used", "in", "the", "charge", "distribution", "in", "the", "all", "-", "order", "wave", "function", "calculations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the parameter ccharge", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is used", "start": 22, "end": 29, "i_start": 3, "i_end": 4}}], "id": 3456}, {"sent": "abnormal event detection is commonly formalized as an outlier detection task , in which the general approach is to learn a model of normality from training data and label the detected outliers as abnormal events .", "tokens": ["abnormal", "event", "detection", "is", "commonly", "formalized", "as", "an", "outlier", "detection", "task", ",", "in", "which", "the", "general", "approach", "is", "to", "learn", "a", "model", "of", "normality", "from", "training", "data", "and", "label", "the", "detected", "outliers", "as", "abnormal", "events", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "abnormal event detection", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "formalized", "start": 37, "end": 47, "i_start": 5, "i_end": 5}}, {"subject": {"text": "abnormal event detection", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 3, "i_end": 3}}], "id": 3457}, {"sent": "every convolution and deconvolution layer is followed by batch normalization .", "tokens": ["every", "convolution", "and", "deconvolution", "layer", "is", "followed", "by", "batch", "normalization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "every convolution and deconvolution layer", "start": 0, "end": 41, "i_start": 0, "i_end": 4}, "verb": {"text": "is followed", "start": 42, "end": 53, "i_start": 5, "i_end": 6}}], "id": 3458}, {"sent": "neural networks recently have been used to solve many real-world tasks such as image recognition and can achieve high effectiveness on these tasks .", "tokens": ["neural", "networks", "recently", "have", "been", "used", "to", "solve", "many", "real", "-", "world", "tasks", "such", "as", "image", "recognition", "and", "can", "achieve", "high", "effectiveness", "on", "these", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have been used", "start": 25, "end": 39, "i_start": 3, "i_end": 5}}, {"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "achieve", "start": 105, "end": 112, "i_start": 19, "i_end": 19}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "solve", "start": 43, "end": 48, "i_start": 7, "i_end": 7}}], "id": 3459}, {"sent": "deep convolutional neural networks have become one of the most important methods in computer vision tasks such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "become", "one", "of", "the", "most", "important", "methods", "in", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have become", "start": 35, "end": 46, "i_start": 4, "i_end": 5}}], "id": 3460}, {"sent": "a resource derivation is closed if all of the leaves of the proof tree are instances of one of the leaf rules .", "tokens": ["a", "resource", "derivation", "is", "closed", "if", "all", "of", "the", "leaves", "of", "the", "proof", "tree", "are", "instances", "of", "one", "of", "the", "leaf", "rules", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a resource derivation", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3461}, {"sent": "the most widely used criteria are capacity maximization and data mean-square-error minimization .", "tokens": ["the", "most", "widely", "used", "criteria", "are", "capacity", "maximization", "and", "data", "mean", "-", "square", "-", "error", "minimization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most widely used criteria", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 5, "i_end": 5}}], "id": 3462}, {"sent": "hill et al introduce sequential denoising autoencoders , which employ the denoising objective to predict the original source sentence given a corrupted version .", "tokens": ["hill", "et", "al", "introduce", "sequential", "denoising", "autoencoders", ",", "which", "employ", "the", "denoising", "objective", "to", "predict", "the", "original", "source", "sentence", "given", "a", "corrupted", "version", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hill et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "introduce", "start": 11, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "hill", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "introduce", "start": 11, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "autoencoders", "start": 42, "end": 54, "i_start": 6, "i_end": 6}, "action": {"text": "denoising", "start": 32, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "autoencoders", "start": 42, "end": 54, "i_start": 6, "i_end": 6}, "action": {"text": "employ", "start": 63, "end": 69, "i_start": 9, "i_end": 9}}, {"character": {"text": "objective", "start": 84, "end": 93, "i_start": 12, "i_end": 12}, "action": {"text": "denoising", "start": 74, "end": 83, "i_start": 11, "i_end": 11}}, {"character": {"text": "autoencoders", "start": 42, "end": 54, "i_start": 6, "i_end": 6}, "action": {"text": "predict", "start": 97, "end": 104, "i_start": 14, "i_end": 14}}], "id": 3463}, {"sent": "an alternative approach was initially proposed by bengio et al , by building a language model based on a neural network architecture .", "tokens": ["an", "alternative", "approach", "was", "initially", "proposed", "by", "bengio", "et", "al", ",", "by", "building", "a", "language", "model", "based", "on", "a", "neural", "network", "architecture", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "an alternative approach", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 38, "end": 46, "i_start": 5, "i_end": 5}}, {"subject": {"text": "an alternative approach", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "was", "start": 24, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "bengio", "start": 50, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "proposed", "start": 38, "end": 46, "i_start": 5, "i_end": 5}}], "id": 3464}, {"sent": "the archived raw data were obtained and manually calibrated using the miriad data reduction package .", "tokens": ["the", "archived", "raw", "data", "were", "obtained", "and", "manually", "calibrated", "using", "the", "miriad", "data", "reduction", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the archived raw data", "start": 0, "end": 21, "i_start": 0, "i_end": 3}, "verb": {"text": "were obtained", "start": 22, "end": 35, "i_start": 4, "i_end": 5}}, {"subject": {"text": "the archived raw data", "start": 0, "end": 21, "i_start": 0, "i_end": 3}, "verb": {"text": "calibrated", "start": 49, "end": 59, "i_start": 8, "i_end": 8}}], "id": 3465}, {"sent": "we also used the risk factors of fama and french , that is , the size factor , value factor , a short-term reversal factor .", "tokens": ["we", "also", "used", "the", "risk", "factors", "of", "fama", "and", "french", ",", "that", "is", ",", "the", "size", "factor", ",", "value", "factor", ",", "a", "short", "-", "term", "reversal", "factor", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}], "id": 3466}, {"sent": "the minimal structure model has the entropy log gdof because the quantum in the ball belongs to one of gdof kinds of fields .", "tokens": ["the", "minimal", "structure", "model", "has", "the", "entropy", "log", "gdof", "because", "the", "quantum", "in", "the", "ball", "belongs", "to", "one", "of", "gdof", "kinds", "of", "fields", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the minimal structure model", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "has", "start": 28, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "belongs", "start": 85, "end": 92, "i_start": 15, "i_end": 15}, "action": {"text": "because", "start": 53, "end": 60, "i_start": 9, "i_end": 9}}, {"character": {"text": "quantum", "start": 65, "end": 72, "i_start": 11, "i_end": 11}, "action": {"text": "belongs", "start": 85, "end": 92, "i_start": 15, "i_end": 15}}], "id": 3467}, {"sent": "learning a single model which considers multiple related tasks is known as multitask learning .", "tokens": ["learning", "a", "single", "model", "which", "considers", "multiple", "related", "tasks", "is", "known", "as", "multitask", "learning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "model", "start": 18, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "considers", "start": 30, "end": 39, "i_start": 5, "i_end": 5}}], "id": 3468}, {"sent": "similarly , it is easily seen that a graph is a -map graph if and only if it has euler genus at most g .", "tokens": ["similarly", ",", "it", "is", "easily", "seen", "that", "a", "graph", "is", "a", "-map", "graph", "if", "and", "only", "if", "it", "has", "euler", "genus", "at", "most", "g", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "seen", "start": 25, "end": 29, "i_start": 5, "i_end": 5}}, {"subject": {"text": "it", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 43, "end": 45, "i_start": 9, "i_end": 9}}, {"character": {"text": "graph", "start": 37, "end": 42, "i_start": 8, "i_end": 8}, "action": {"text": "has", "start": 77, "end": 80, "i_start": 18, "i_end": 18}}], "id": 3469}, {"sent": "the original model was constructed to account for the emergence of shared vocabularies or conventions in a community of interacting agents .", "tokens": ["the", "original", "model", "was", "constructed", "to", "account", "for", "the", "emergence", "of", "shared", "vocabularies", "or", "conventions", "in", "a", "community", "of", "interacting", "agents", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the original model", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "was constructed", "start": 19, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "model", "start": 13, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "account", "start": 38, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "community", "start": 107, "end": 116, "i_start": 17, "i_end": 17}, "action": {"text": "emergence", "start": 54, "end": 63, "i_start": 9, "i_end": 9}}, {"character": {"text": "agents", "start": 132, "end": 138, "i_start": 20, "i_end": 20}, "action": {"text": "interacting", "start": 120, "end": 131, "i_start": 19, "i_end": 19}}], "id": 3470}, {"sent": "according to the universal approximation theorem , a two-layer neural network can approximate any monotonically-increasing continuous function on a compact set .", "tokens": ["according", "to", "the", "universal", "approximation", "theorem", ",", "a", "two", "-", "layer", "neural", "network", "can", "approximate", "any", "monotonically", "-", "increasing", "continuous", "function", "on", "a", "compact", "set", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a two-layer neural network", "start": 51, "end": 77, "i_start": 7, "i_end": 12}, "verb": {"text": "can approximate", "start": 78, "end": 93, "i_start": 13, "i_end": 14}}], "id": 3471}, {"sent": "the first approach utilizes unique 3d models for each face in the gallery , either inferred statistically .", "tokens": ["the", "first", "approach", "utilizes", "unique", "3d", "models", "for", "each", "face", "in", "the", "gallery", ",", "either", "inferred", "statistically", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the first approach", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "utilizes", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "approach", "start": 10, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "utilizes", "start": 19, "end": 27, "i_start": 3, "i_end": 3}}], "id": 3472}, {"sent": "this could be related to the fact that the master spaces of the four dimensional dual seiberg parents are not isomorphic .", "tokens": ["this", "could", "be", "related", "to", "the", "fact", "that", "the", "master", "spaces", "of", "the", "four", "dimensional", "dual", "seiberg", "parents", "are", "not", "isomorphic", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "could be related", "start": 5, "end": 21, "i_start": 1, "i_end": 3}}], "id": 3473}, {"sent": "ferrari and canny introduced a very efficient geometric method for determining the total space of possible resultant wrenches as long as each individual contact wrench obeys friction constraints .", "tokens": ["ferrari", "and", "canny", "introduced", "a", "very", "efficient", "geometric", "method", "for", "determining", "the", "total", "space", "of", "possible", "resultant", "wrenches", "as", "long", "as", "each", "individual", "contact", "wrench", "obeys", "friction", "constraints", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "ferrari and canny", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "introduced", "start": 18, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "ferrari", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 18, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "canny", "start": 12, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 18, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "wrench", "start": 161, "end": 167, "i_start": 24, "i_end": 24}, "action": {"text": "obeys", "start": 168, "end": 173, "i_start": 25, "i_end": 25}}, {"character": {"text": "wrench", "start": 161, "end": 167, "i_start": 24, "i_end": 24}, "action": {"text": "contact", "start": 153, "end": 160, "i_start": 23, "i_end": 23}}], "id": 3474}, {"sent": "note that the circular trajectory is considered since it not only enables the uav to serve the cell-edge users in a periodic manner , but is also practically energy-efficient for the uav movement .", "tokens": ["note", "that", "the", "circular", "trajectory", "is", "considered", "since", "it", "not", "only", "enables", "the", "uav", "to", "serve", "the", "cell", "-", "edge", "users", "in", "a", "periodic", "manner", ",", "but", "is", "also", "practically", "energy", "-", "efficient", "for", "the", "uav", "movement", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the circular trajectory", "start": 10, "end": 33, "i_start": 2, "i_end": 4}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "the circular trajectory", "start": 10, "end": 33, "i_start": 2, "i_end": 4}, "verb": {"text": "considered", "start": 37, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "trajectory", "start": 23, "end": 33, "i_start": 4, "i_end": 4}, "action": {"text": "enables", "start": 66, "end": 73, "i_start": 11, "i_end": 11}}], "id": 3475}, {"sent": "section 2 briefly reviews the method introduced in chen and zhang in utilizing a similarity graph constructed on observations for change-point detection .", "tokens": ["section", "2", "briefly", "reviews", "the", "method", "introduced", "in", "chen", "and", "zhang", "in", "utilizing", "a", "similarity", "graph", "constructed", "on", "observations", "for", "change", "-", "point", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "section 2 briefly", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "reviews", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "section 2", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "action": {"text": "reviews", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "observations", "start": 113, "end": 125, "i_start": 18, "i_end": 18}, "action": {"text": "constructed", "start": 98, "end": 109, "i_start": 16, "i_end": 16}}], "id": 3476}, {"sent": "characterize those normal rings which are not s-normal rings .", "tokens": ["characterize", "those", "normal", "rings", "which", "are", "not", "s", "-", "normal", "rings", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3477}, {"sent": "recently quasi-einstein manifolds satisfying some pseudosymmetry type conditions were investigated among others in .", "tokens": ["recently", "quasi", "-", "einstein", "manifolds", "satisfying", "some", "pseudosymmetry", "type", "conditions", "were", "investigated", "among", "others", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "quasi-einstein manifolds", "start": 9, "end": 33, "i_start": 1, "i_end": 4}, "verb": {"text": "satisfying", "start": 34, "end": 44, "i_start": 5, "i_end": 5}}, {"subject": {"text": "quasi-einstein manifolds", "start": 9, "end": 33, "i_start": 1, "i_end": 4}, "verb": {"text": "investigated", "start": 86, "end": 98, "i_start": 11, "i_end": 11}}, {"character": {"text": "manifolds", "start": 24, "end": 33, "i_start": 4, "i_end": 4}, "action": {"text": "satisfying", "start": 34, "end": 44, "i_start": 5, "i_end": 5}}], "id": 3478}, {"sent": "adaptive estimation of linear functionals by model selection .", "tokens": ["adaptive", "estimation", "of", "linear", "functionals", "by", "model", "selection", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3479}, {"sent": "we first use reduze2 to perform the reductions of all the integrals to mis .", "tokens": ["we", "first", "use", "reduze2", "to", "perform", "the", "reductions", "of", "all", "the", "integrals", "to", "mis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 9, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 9, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "perform", "start": 24, "end": 31, "i_start": 5, "i_end": 5}}], "id": 3480}, {"sent": "the notion of differential privacy provides a strong notion of individual privacy while permitting useful data analysis in machine learning tasks .", "tokens": ["the", "notion", "of", "differential", "privacy", "provides", "a", "strong", "notion", "of", "individual", "privacy", "while", "permitting", "useful", "data", "analysis", "in", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the notion of differential privacy", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "provides", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}, {"character": {"text": "notion", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "provides", "start": 35, "end": 43, "i_start": 5, "i_end": 5}}], "id": 3481}, {"sent": "the model by yu et al improves this approach by replacing the null symbol with a learned transition probability .", "tokens": ["the", "model", "by", "yu", "et", "al", "improves", "this", "approach", "by", "replacing", "the", "null", "symbol", "with", "a", "learned", "transition", "probability", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the model by yu et al", "start": 0, "end": 21, "i_start": 0, "i_end": 5}, "verb": {"text": "improves", "start": 22, "end": 30, "i_start": 6, "i_end": 6}}, {"character": {"text": "model", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "improves", "start": 22, "end": 30, "i_start": 6, "i_end": 6}}, {"character": {"text": "model", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "replacing", "start": 48, "end": 57, "i_start": 10, "i_end": 10}}], "id": 3482}, {"sent": "in recent years , deep networks have been applied to the challenging tasks of image classification and have shown substantial improvement .", "tokens": ["in", "recent", "years", ",", "deep", "networks", "have", "been", "applied", "to", "the", "challenging", "tasks", "of", "image", "classification", "and", "have", "shown", "substantial", "improvement", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep networks", "start": 18, "end": 31, "i_start": 4, "i_end": 5}, "verb": {"text": "have been applied", "start": 32, "end": 49, "i_start": 6, "i_end": 8}}, {"subject": {"text": "deep networks", "start": 18, "end": 31, "i_start": 4, "i_end": 5}, "verb": {"text": "shown", "start": 108, "end": 113, "i_start": 18, "i_end": 18}}], "id": 3483}, {"sent": "the space of densities equipped with this metric introduces an infinite-dimensional riemannian manifold , called the density manifold .", "tokens": ["the", "space", "of", "densities", "equipped", "with", "this", "metric", "introduces", "an", "infinite", "-", "dimensional", "riemannian", "manifold", ",", "called", "the", "density", "manifold", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the space of densities equipped with this metric", "start": 0, "end": 48, "i_start": 0, "i_end": 7}, "verb": {"text": "introduces", "start": 49, "end": 59, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the space of densities equipped with this metric", "start": 0, "end": 48, "i_start": 0, "i_end": 7}, "verb": {"text": "called", "start": 106, "end": 112, "i_start": 16, "i_end": 16}}, {"character": {"text": "space", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "introduces", "start": 49, "end": 59, "i_start": 8, "i_end": 8}}], "id": 3484}, {"sent": "generative adversarial networks are a promising scheme for learning generative models .", "tokens": ["generative", "adversarial", "networks", "are", "a", "promising", "scheme", "for", "learning", "generative", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "scheme", "start": 48, "end": 54, "i_start": 6, "i_end": 6}, "action": {"text": "promising", "start": 38, "end": 47, "i_start": 5, "i_end": 5}}], "id": 3485}, {"sent": "each deconvolutional layer is followed by a batch normalization layer .", "tokens": ["each", "deconvolutional", "layer", "is", "followed", "by", "a", "batch", "normalization", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each deconvolutional layer", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "is followed", "start": 27, "end": 38, "i_start": 3, "i_end": 4}}], "id": 3486}, {"sent": "in recent years , deep learning methods have shown great success with many computer vision tasks such as image classification .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "methods", "have", "shown", "great", "success", "with", "many", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning methods", "start": 18, "end": 39, "i_start": 4, "i_end": 6}, "verb": {"text": "have shown", "start": 40, "end": 50, "i_start": 7, "i_end": 8}}, {"character": {"text": "methods", "start": 32, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "shown", "start": 45, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "methods", "start": 32, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 57, "end": 64, "i_start": 10, "i_end": 10}}], "id": 3487}, {"sent": "reinforcement learning is concerned with how to map states to actions so as to maximize the cumulative rewards .", "tokens": ["reinforcement", "learning", "is", "concerned", "with", "how", "to", "map", "states", "to", "actions", "so", "as", "to", "maximize", "the", "cumulative", "rewards", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is concerned", "start": 23, "end": 35, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 14, "end": 22, "i_start": 1, "i_end": 1}, "action": {"text": "concerned", "start": 26, "end": 35, "i_start": 3, "i_end": 3}}], "id": 3488}, {"sent": "each monte carlo simulation consists of 1000 individual runs through the set of polluted stellar models .", "tokens": ["each", "monte", "carlo", "simulation", "consists", "of", "1000", "individual", "runs", "through", "the", "set", "of", "polluted", "stellar", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each monte carlo simulation", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "consists", "start": 28, "end": 36, "i_start": 4, "i_end": 4}}], "id": 3489}, {"sent": "tucker decomposition aims to represent a tensor by a small core tensor and some matrix factors .", "tokens": ["tucker", "decomposition", "aims", "to", "represent", "a", "tensor", "by", "a", "small", "core", "tensor", "and", "some", "matrix", "factors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "tucker decomposition", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "aims", "start": 21, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "decomposition", "start": 7, "end": 20, "i_start": 1, "i_end": 1}, "action": {"text": "aims", "start": 21, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "tucker", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "decomposition", "start": 7, "end": 20, "i_start": 1, "i_end": 1}}, {"character": {"text": "decomposition", "start": 7, "end": 20, "i_start": 1, "i_end": 1}, "action": {"text": "represent", "start": 29, "end": 38, "i_start": 4, "i_end": 4}}], "id": 3490}, {"sent": "recently convolutional neural networks have performed very well on image classification tasks and are pervasive in machine learning and computer vision .", "tokens": ["recently", "convolutional", "neural", "networks", "have", "performed", "very", "well", "on", "image", "classification", "tasks", "and", "are", "pervasive", "in", "machine", "learning", "and", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 9, "end": 38, "i_start": 1, "i_end": 3}, "verb": {"text": "have performed", "start": 39, "end": 53, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "performed", "start": 44, "end": 53, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "pervasive", "start": 102, "end": 111, "i_start": 14, "i_end": 14}}], "id": 3491}, {"sent": "to leverage this highly valuable information , we automatically generate dense lesion masks from recist labels using grabcut .", "tokens": ["to", "leverage", "this", "highly", "valuable", "information", ",", "we", "automatically", "generate", "dense", "lesion", "masks", "from", "recist", "labels", "using", "grabcut", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 47, "end": 49, "i_start": 7, "i_end": 7}, "verb": {"text": "generate", "start": 64, "end": 72, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 47, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "generate", "start": 64, "end": 72, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 47, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "using", "start": 111, "end": 116, "i_start": 16, "i_end": 16}}, {"character": {"text": "we", "start": 47, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "leverage", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 3492}, {"sent": "a first striking difference is the significant region mentioned earlier in this section .", "tokens": ["a", "first", "striking", "difference", "is", "the", "significant", "region", "mentioned", "earlier", "in", "this", "section", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a first striking difference", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 4, "i_end": 4}}], "id": 3493}, {"sent": "deep convolutional networks have , in recent times , achieved near-human performance on an array of visual , auditory , and other cognitive tasks .", "tokens": ["deep", "convolutional", "networks", "have", ",", "in", "recent", "times", ",", "achieved", "near", "-", "human", "performance", "on", "an", "array", "of", "visual", ",", "auditory", ",", "and", "other", "cognitive", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "networks", "start": 19, "end": 27, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 53, "end": 61, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 19, "end": 27, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 73, "end": 84, "i_start": 13, "i_end": 13}}], "id": 3494}, {"sent": "deep convolutional neural networks using supervised learning has been proven to be revolutionary for image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "using", "supervised", "learning", "has", "been", "proven", "to", "be", "revolutionary", "for", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks using supervised learning", "start": 0, "end": 60, "i_start": 0, "i_end": 6}, "verb": {"text": "has been proven", "start": 61, "end": 76, "i_start": 7, "i_end": 9}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "using", "start": 35, "end": 40, "i_start": 4, "i_end": 4}}], "id": 3495}, {"sent": "however , unlike a cosmological constant , it is a physical fluid with a physical scalar excitation , which can be described by a systematic effective field theory at low energies .", "tokens": ["however", ",", "unlike", "a", "cosmological", "constant", ",", "it", "is", "a", "physical", "fluid", "with", "a", "physical", "scalar", "excitation", ",", "which", "can", "be", "described", "by", "a", "systematic", "effective", "field", "theory", "at", "low", "energies", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 43, "end": 45, "i_start": 7, "i_end": 7}, "verb": {"text": "is", "start": 46, "end": 48, "i_start": 8, "i_end": 8}}, {"character": {"text": "theory", "start": 157, "end": 163, "i_start": 27, "i_end": 27}, "action": {"text": "described", "start": 115, "end": 124, "i_start": 21, "i_end": 21}}, {"character": {"text": "theory", "start": 157, "end": 163, "i_start": 27, "i_end": 27}, "action": {"text": "effective", "start": 141, "end": 150, "i_start": 25, "i_end": 25}}], "id": 3496}, {"sent": "propositional dynamic logic of regular programs .", "tokens": ["propositional", "dynamic", "logic", "of", "regular", "programs", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3497}, {"sent": "now we prove the boundedness of the curvatures .", "tokens": ["now", "we", "prove", "the", "boundedness", "of", "the", "curvatures", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "prove", "start": 7, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "prove", "start": 7, "end": 12, "i_start": 2, "i_end": 2}}], "id": 3498}, {"sent": "it is proved that polar codes can achieve the channel capacity of binary-input symmetric memoryless channels .", "tokens": ["it", "is", "proved", "that", "polar", "codes", "can", "achieve", "the", "channel", "capacity", "of", "binary", "-", "input", "symmetric", "memoryless", "channels", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is proved", "start": 3, "end": 12, "i_start": 1, "i_end": 2}}, {"subject": {"text": "polar codes", "start": 18, "end": 29, "i_start": 4, "i_end": 5}, "verb": {"text": "achieve", "start": 34, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "codes", "start": 24, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "achieve", "start": 34, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "channels", "start": 100, "end": 108, "i_start": 17, "i_end": 17}, "action": {"text": "-", "start": 72, "end": 73, "i_start": 13, "i_end": 13}}], "id": 3499}, {"sent": "the coulomb branch realisation of b-type nilpotent orbit closures via unitary quiver gauge theories have been constructed in .", "tokens": ["the", "coulomb", "branch", "realisation", "of", "b", "-", "type", "nilpotent", "orbit", "closures", "via", "unitary", "quiver", "gauge", "theories", "have", "been", "constructed", "in", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the coulomb branch realisation of b-type nilpotent orbit closures via unitary quiver gauge theories", "start": 0, "end": 99, "i_start": 0, "i_end": 15}, "verb": {"text": "have been constructed", "start": 100, "end": 121, "i_start": 16, "i_end": 18}}, {"character": {"text": "branch", "start": 12, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "realisation", "start": 19, "end": 30, "i_start": 3, "i_end": 3}}], "id": 3500}, {"sent": "recent developments in deep learning have led to significant progress in supervised learning tasks on complex image datasets .", "tokens": ["recent", "developments", "in", "deep", "learning", "have", "led", "to", "significant", "progress", "in", "supervised", "learning", "tasks", "on", "complex", "image", "datasets", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent developments in deep learning", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "have led", "start": 37, "end": 45, "i_start": 5, "i_end": 6}}, {"character": {"text": "developments", "start": 7, "end": 19, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 42, "end": 45, "i_start": 6, "i_end": 6}}], "id": 3501}, {"sent": "recently there has been much interest in classifying supersymmetric solutions of supergravity theories in various dimensions .", "tokens": ["recently", "there", "has", "been", "much", "interest", "in", "classifying", "supersymmetric", "solutions", "of", "supergravity", "theories", "in", "various", "dimensions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 9, "end": 14, "i_start": 1, "i_end": 1}, "verb": {"text": "has been", "start": 15, "end": 23, "i_start": 2, "i_end": 3}}], "id": 3502}, {"sent": "kamowitz , compact homomorphisms between dales-davie algebras , proc .", "tokens": ["kamowitz", ",", "compact", "homomorphisms", "between", "dales", "-", "davie", "algebras", ",", "proc", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3503}, {"sent": "there is a substantial body of work that deals with the learning of various types of single agent mab problems .", "tokens": ["there", "is", "a", "substantial", "body", "of", "work", "that", "deals", "with", "the", "learning", "of", "various", "types", "of", "single", "agent", "mab", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "body", "start": 23, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "deals", "start": 41, "end": 46, "i_start": 8, "i_end": 8}}], "id": 3504}, {"sent": "it is well known that s 1 and s 3 are the only compact connected lie groups which have free differentiable actions on homotopy spheres .", "tokens": ["it", "is", "well", "known", "that", "s", "1", "and", "s", "3", "are", "the", "only", "compact", "connected", "lie", "groups", "which", "have", "free", "differentiable", "actions", "on", "homotopy", "spheres", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"character": {"text": "groups", "start": 69, "end": 75, "i_start": 16, "i_end": 16}, "action": {"text": "lie", "start": 65, "end": 68, "i_start": 15, "i_end": 15}}, {"character": {"text": "groups", "start": 69, "end": 75, "i_start": 16, "i_end": 16}, "action": {"text": "have", "start": 82, "end": 86, "i_start": 18, "i_end": 18}}], "id": 3505}, {"sent": "the outstanding feature of lopes 3d is the deployed antenna type .", "tokens": ["the", "outstanding", "feature", "of", "lopes", "3d", "is", "the", "deployed", "antenna", "type", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the outstanding feature of lopes 3d", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 36, "end": 38, "i_start": 6, "i_end": 6}}], "id": 3506}, {"sent": "this proves the first part of the statement .", "tokens": ["this", "proves", "the", "first", "part", "of", "the", "statement", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "proves", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proves", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}], "id": 3507}, {"sent": "a powerful technique for this problem is locality sensitive hashing .", "tokens": ["a", "powerful", "technique", "for", "this", "problem", "is", "locality", "sensitive", "hashing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a powerful technique for this problem", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "hashing", "start": 60, "end": 67, "i_start": 9, "i_end": 9}, "action": {"text": "sensitive", "start": 50, "end": 59, "i_start": 8, "i_end": 8}}], "id": 3508}, {"sent": "in , image region forgery detection has been performed using stacked auto-encoder model .", "tokens": ["in", ",", "image", "region", "forgery", "detection", "has", "been", "performed", "using", "stacked", "auto", "-", "encoder", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "image region forgery detection", "start": 5, "end": 35, "i_start": 2, "i_end": 5}, "verb": {"text": "has been performed", "start": 36, "end": 54, "i_start": 6, "i_end": 8}}], "id": 3509}, {"sent": "as the phase space for the 2-sphere consists of a point , the wavefunction in this formulation is trivial .", "tokens": ["as", "the", "phase", "space", "for", "the", "2", "-", "sphere", "consists", "of", "a", "point", ",", "the", "wavefunction", "in", "this", "formulation", "is", "trivial", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the wavefunction in this formulation", "start": 58, "end": 94, "i_start": 14, "i_end": 18}, "verb": {"text": "is", "start": 95, "end": 97, "i_start": 19, "i_end": 19}}], "id": 3510}, {"sent": "convolutional neural networks are enabling major advancements in a range of machine learning problems .", "tokens": ["convolutional", "neural", "networks", "are", "enabling", "major", "advancements", "in", "a", "range", "of", "machine", "learning", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "are enabling", "start": 30, "end": 42, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "enabling", "start": 34, "end": 42, "i_start": 4, "i_end": 4}}], "id": 3511}, {"sent": "recently , great breakthroughs have been made by the methods based on generative adversarial networks .", "tokens": ["recently", ",", "great", "breakthroughs", "have", "been", "made", "by", "the", "methods", "based", "on", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "great breakthroughs", "start": 11, "end": 30, "i_start": 2, "i_end": 3}, "verb": {"text": "have been made", "start": 31, "end": 45, "i_start": 4, "i_end": 6}}, {"character": {"text": "methods", "start": 53, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "breakthroughs", "start": 17, "end": 30, "i_start": 3, "i_end": 3}}], "id": 3512}, {"sent": "all models were trained using the adam optimizer with minibatches of size 24 .", "tokens": ["all", "models", "were", "trained", "using", "the", "adam", "optimizer", "with", "minibatches", "of", "size", "24", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all models", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "were trained", "start": 11, "end": 23, "i_start": 2, "i_end": 3}}], "id": 3513}, {"sent": "we test the tracking and generalization performance of our motion module on the rgb-d tracking benchmark .", "tokens": ["we", "test", "the", "tracking", "and", "generalization", "performance", "of", "our", "motion", "module", "on", "the", "rgb", "-", "d", "tracking", "benchmark", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "test", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "test", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "module", "start": 66, "end": 72, "i_start": 10, "i_end": 10}, "action": {"text": "performance", "start": 40, "end": 51, "i_start": 6, "i_end": 6}}], "id": 3514}, {"sent": "the potentials comprise a lennard-jones type soft repulsive part , and a short-ranged attractive part .", "tokens": ["the", "potentials", "comprise", "a", "lennard", "-", "jones", "type", "soft", "repulsive", "part", ",", "and", "a", "short", "-", "ranged", "attractive", "part", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the potentials", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "comprise", "start": 15, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "part", "start": 60, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "repulsive", "start": 50, "end": 59, "i_start": 9, "i_end": 9}}, {"character": {"text": "part", "start": 97, "end": 101, "i_start": 18, "i_end": 18}, "action": {"text": "attractive", "start": 86, "end": 96, "i_start": 17, "i_end": 17}}], "id": 3515}, {"sent": "we use batch normalisation layers after every convolutional layer .", "tokens": ["we", "use", "batch", "normalisation", "layers", "after", "every", "convolutional", "layer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 3516}, {"sent": "solodukhin , classical and quantum cross-section for black hole production in particle collisions , phys .", "tokens": ["solodukhin", ",", "classical", "and", "quantum", "cross", "-", "section", "for", "black", "hole", "production", "in", "particle", "collisions", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "particle", "start": 78, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "collisions", "start": 87, "end": 97, "i_start": 14, "i_end": 14}}], "id": 3517}, {"sent": "the low energy properties of interacting 1d systems are described by the luttinger liquid model which gives a qualitative picture of the static and dynamic properties .", "tokens": ["the", "low", "energy", "properties", "of", "interacting", "1d", "systems", "are", "described", "by", "the", "luttinger", "liquid", "model", "which", "gives", "a", "qualitative", "picture", "of", "the", "static", "and", "dynamic", "properties", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the low energy properties of interacting 1d systems", "start": 0, "end": 51, "i_start": 0, "i_end": 7}, "verb": {"text": "are described", "start": 52, "end": 65, "i_start": 8, "i_end": 9}}, {"character": {"text": "model", "start": 90, "end": 95, "i_start": 14, "i_end": 14}, "action": {"text": "described", "start": 56, "end": 65, "i_start": 9, "i_end": 9}}, {"character": {"text": "model", "start": 90, "end": 95, "i_start": 14, "i_end": 14}, "action": {"text": "gives", "start": 102, "end": 107, "i_start": 16, "i_end": 16}}], "id": 3518}, {"sent": "we begin by reviewing the approach to modeling human movements that we developed in .", "tokens": ["we", "begin", "by", "reviewing", "the", "approach", "to", "modeling", "human", "movements", "that", "we", "developed", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "begin", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "begin", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "reviewing", "start": 12, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "developed", "start": 71, "end": 80, "i_start": 12, "i_end": 12}}], "id": 3519}, {"sent": "we implement this baseline classifier with the scikit-learn package , with a countvectorizer including bi-gram features .", "tokens": ["we", "implement", "this", "baseline", "classifier", "with", "the", "scikit", "-", "learn", "package", ",", "with", "a", "countvectorizer", "including", "bi", "-", "gram", "features", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}], "id": 3520}, {"sent": "for the correlation length rc in the body of the table in cm , versus the dark matter mass \u00b5 in kev and its rm s .", "tokens": ["for", "the", "correlation", "length", "rc", "in", "the", "body", "of", "the", "table", "in", "cm", ",", "versus", "the", "dark", "matter", "mass", "\u00b5", "in", "kev", "and", "its", "rm", "s", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3521}, {"sent": "recent work in computer vision has shown that convolutional neural networks considerably improve image classification .", "tokens": ["recent", "work", "in", "computer", "vision", "has", "shown", "that", "convolutional", "neural", "networks", "considerably", "improve", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent work in computer vision", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "has shown", "start": 31, "end": 40, "i_start": 5, "i_end": 6}}, {"subject": {"text": "convolutional neural networks", "start": 46, "end": 75, "i_start": 8, "i_end": 10}, "verb": {"text": "improve", "start": 89, "end": 96, "i_start": 12, "i_end": 12}}, {"character": {"text": "work", "start": 7, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "shown", "start": 35, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 67, "end": 75, "i_start": 10, "i_end": 10}, "action": {"text": "improve", "start": 89, "end": 96, "i_start": 12, "i_end": 12}}], "id": 3522}, {"sent": "success probability discussions in state that in a network with delays , anc gives rise to random processes which can be written algebraically in terms of a delay variable z .", "tokens": ["success", "probability", "discussions", "in", "state", "that", "in", "a", "network", "with", "delays", ",", "anc", "gives", "rise", "to", "random", "processes", "which", "can", "be", "written", "algebraically", "in", "terms", "of", "a", "delay", "variable", "z", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "success probability discussions in state that in a network with delays , anc", "start": 0, "end": 76, "i_start": 0, "i_end": 12}, "verb": {"text": "gives", "start": 77, "end": 82, "i_start": 13, "i_end": 13}}, {"character": {"text": "discussions", "start": 20, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "state", "start": 35, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "anc", "start": 73, "end": 76, "i_start": 12, "i_end": 12}, "action": {"text": "rise", "start": 83, "end": 87, "i_start": 14, "i_end": 14}}, {"character": {"text": "network", "start": 51, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "delay", "start": 157, "end": 162, "i_start": 27, "i_end": 27}}], "id": 3523}, {"sent": "the last two columns provide the same information for occasional blending lines .", "tokens": ["the", "last", "two", "columns", "provide", "the", "same", "information", "for", "occasional", "blending", "lines", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the last two columns", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "provide", "start": 21, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "two columns", "start": 9, "end": 20, "i_start": 2, "i_end": 3}, "action": {"text": "provide", "start": 21, "end": 28, "i_start": 4, "i_end": 4}}], "id": 3524}, {"sent": "its orientation is the orientation of the magnetic flux .", "tokens": ["its", "orientation", "is", "the", "orientation", "of", "the", "magnetic", "flux", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "its orientation", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3525}, {"sent": "several techniques have been proposed to stabilize the training process and generate compelling results .", "tokens": ["several", "techniques", "have", "been", "proposed", "to", "stabilize", "the", "training", "process", "and", "generate", "compelling", "results", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "several techniques", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "have been proposed", "start": 19, "end": 37, "i_start": 2, "i_end": 4}}, {"character": {"text": "results", "start": 96, "end": 103, "i_start": 13, "i_end": 13}, "action": {"text": "compelling", "start": 85, "end": 95, "i_start": 12, "i_end": 12}}], "id": 3526}, {"sent": "but this method can be used mainly for solving linearly constrained problems since any simple nonlinear constraint could lead to a nonconvex minimization problem .", "tokens": ["but", "this", "method", "can", "be", "used", "mainly", "for", "solving", "linearly", "constrained", "problems", "since", "any", "simple", "nonlinear", "constraint", "could", "lead", "to", "a", "nonconvex", "minimization", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this method", "start": 4, "end": 15, "i_start": 1, "i_end": 2}, "verb": {"text": "can be used", "start": 16, "end": 27, "i_start": 3, "i_end": 5}}, {"character": {"text": "constraint", "start": 104, "end": 114, "i_start": 16, "i_end": 16}, "action": {"text": "lead", "start": 121, "end": 125, "i_start": 18, "i_end": 18}}], "id": 3527}, {"sent": "for both parameters , smaller values offer stronger privacy guarantees .", "tokens": ["for", "both", "parameters", ",", "smaller", "values", "offer", "stronger", "privacy", "guarantees", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "smaller values", "start": 22, "end": 36, "i_start": 4, "i_end": 5}, "verb": {"text": "offer", "start": 37, "end": 42, "i_start": 6, "i_end": 6}}, {"character": {"text": "values", "start": 30, "end": 36, "i_start": 5, "i_end": 5}, "action": {"text": "offer", "start": 37, "end": 42, "i_start": 6, "i_end": 6}}], "id": 3528}, {"sent": "it is proven in , proposition 4 , that this jenkins serrin problem has no solution .", "tokens": ["it", "is", "proven", "in", ",", "proposition", "4", ",", "that", "this", "jenkins", "serrin", "problem", "has", "no", "solution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is proven in", "start": 3, "end": 15, "i_start": 1, "i_end": 3}}, {"subject": {"text": "this jenkins serrin problem", "start": 39, "end": 66, "i_start": 9, "i_end": 12}, "verb": {"text": "has", "start": 67, "end": 70, "i_start": 13, "i_end": 13}}], "id": 3529}, {"sent": "note that for the bg model the configurational entropy may be negative because particles are distinguishable .", "tokens": ["note", "that", "for", "the", "bg", "model", "the", "configurational", "entropy", "may", "be", "negative", "because", "particles", "are", "distinguishable", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "model", "start": 21, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "negative", "start": 62, "end": 70, "i_start": 11, "i_end": 11}}], "id": 3530}, {"sent": "in general however , an expanding thurston maps may have periodic critical points .", "tokens": ["in", "general", "however", ",", "an", "expanding", "thurston", "maps", "may", "have", "periodic", "critical", "points", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "an expanding thurston maps", "start": 21, "end": 47, "i_start": 4, "i_end": 7}, "verb": {"text": "may have", "start": 48, "end": 56, "i_start": 8, "i_end": 9}}, {"character": {"text": "maps", "start": 43, "end": 47, "i_start": 7, "i_end": 7}, "action": {"text": "have", "start": 52, "end": 56, "i_start": 9, "i_end": 9}}], "id": 3531}, {"sent": "the particles in this cube are used for producing a three-dimensional density field , by interpolating their position on a grid of 1024 3 cells using the triangular shaped cloud method .", "tokens": ["the", "particles", "in", "this", "cube", "are", "used", "for", "producing", "a", "three", "-", "dimensional", "density", "field", ",", "by", "interpolating", "their", "position", "on", "a", "grid", "of", "1024", "3", "cells", "using", "the", "triangular", "shaped", "cloud", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the particles in this cube", "start": 0, "end": 26, "i_start": 0, "i_end": 4}, "verb": {"text": "are used", "start": 27, "end": 35, "i_start": 5, "i_end": 6}}], "id": 3532}, {"sent": "besides of the range queries we mentioned above , there has also been much work on efficiently answering different types of queries over probabilistic data , such as conjunctive queries , and so on .", "tokens": ["besides", "of", "the", "range", "queries", "we", "mentioned", "above", ",", "there", "has", "also", "been", "much", "work", "on", "efficiently", "answering", "different", "types", "of", "queries", "over", "probabilistic", "data", ",", "such", "as", "conjunctive", "queries", ",", "and", "so", "on", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 50, "end": 55, "i_start": 9, "i_end": 9}, "verb": {"text": "been", "start": 65, "end": 69, "i_start": 12, "i_end": 12}}, {"subject": {"text": "there", "start": 50, "end": 55, "i_start": 9, "i_end": 9}, "verb": {"text": "has", "start": 56, "end": 59, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "mentioned", "start": 32, "end": 41, "i_start": 6, "i_end": 6}}], "id": 3533}, {"sent": "now we proceed on to define the concept of groupoid biring .", "tokens": ["now", "we", "proceed", "on", "to", "define", "the", "concept", "of", "groupoid", "biring", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed on", "start": 7, "end": 17, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 3534}, {"sent": "we compare the proposed method with state-of-the-art methods including k nearest neighbor search in table 1 .", "tokens": ["we", "compare", "the", "proposed", "method", "with", "state", "-", "of", "-", "the", "-", "art", "methods", "including", "k", "nearest", "neighbor", "search", "in", "table", "1", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 3535}, {"sent": "the network was trained using adam optimisation with a starting learning rate of 2e-4 for the generators and discriminators .", "tokens": ["the", "network", "was", "trained", "using", "adam", "optimisation", "with", "a", "starting", "learning", "rate", "of", "2e-4", "for", "the", "generators", "and", "discriminators", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the network", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "was trained", "start": 12, "end": 23, "i_start": 2, "i_end": 3}}], "id": 3536}, {"sent": "for a non-equalizing receiver , the best interleaver matrix is the one that evenly distributes the interference over all symbols , and can be found using binary linear programming .", "tokens": ["for", "a", "non", "-", "equalizing", "receiver", ",", "the", "best", "interleaver", "matrix", "is", "the", "one", "that", "evenly", "distributes", "the", "interference", "over", "all", "symbols", ",", "and", "can", "be", "found", "using", "binary", "linear", "programming", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the best interleaver matrix", "start": 32, "end": 59, "i_start": 7, "i_end": 10}, "verb": {"text": "is", "start": 60, "end": 62, "i_start": 11, "i_end": 11}}, {"subject": {"text": "the best interleaver matrix", "start": 32, "end": 59, "i_start": 7, "i_end": 10}, "verb": {"text": "found", "start": 142, "end": 147, "i_start": 26, "i_end": 26}}, {"character": {"text": "matrix", "start": 53, "end": 59, "i_start": 10, "i_end": 10}, "action": {"text": "interleaver", "start": 41, "end": 52, "i_start": 9, "i_end": 9}}], "id": 3537}, {"sent": "we discuss the relation of the field equation of the faddeev model to that of the skyrme model .", "tokens": ["we", "discuss", "the", "relation", "of", "the", "field", "equation", "of", "the", "faddeev", "model", "to", "that", "of", "the", "skyrme", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "discuss", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "discuss", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 3538}, {"sent": "yang et al proposed hierarchical attention mechanism for text sentiment analysis .", "tokens": ["yang", "et", "al", "proposed", "hierarchical", "attention", "mechanism", "for", "text", "sentiment", "analysis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "yang et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "yang", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}], "id": 3539}, {"sent": "recurrent neural networks have been extensively used in tasks like image captioning .", "tokens": ["recurrent", "neural", "networks", "have", "been", "extensively", "used", "in", "tasks", "like", "image", "captioning", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "recurrent neural networks", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 48, "end": 52, "i_start": 6, "i_end": 6}}, {"subject": {"text": "recurrent neural networks", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 26, "end": 35, "i_start": 3, "i_end": 4}}], "id": 3540}, {"sent": "from the figures , we can see that there is a shift from metal-rich stars to metal-poor ones with the increasing of apparent magnitude .", "tokens": ["from", "the", "figures", ",", "we", "can", "see", "that", "there", "is", "a", "shift", "from", "metal", "-", "rich", "stars", "to", "metal", "-", "poor", "ones", "with", "the", "increasing", "of", "apparent", "magnitude", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "verb": {"text": "can see", "start": 22, "end": 29, "i_start": 5, "i_end": 6}}, {"subject": {"text": "there", "start": 35, "end": 40, "i_start": 8, "i_end": 8}, "verb": {"text": "is", "start": 41, "end": 43, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "see", "start": 26, "end": 29, "i_start": 6, "i_end": 6}}], "id": 3541}, {"sent": "supervised learning-based networks have successfully been used for many years in image classification .", "tokens": ["supervised", "learning", "-", "based", "networks", "have", "successfully", "been", "used", "for", "many", "years", "in", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "supervised learning-based networks", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "been used", "start": 53, "end": 62, "i_start": 7, "i_end": 8}}, {"subject": {"text": "supervised learning-based networks", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 5, "i_end": 5}}], "id": 3542}, {"sent": "in blind deblurring , schuler et al employ neural networks as feature extraction modules and integrate it into a trainable deblurring system .", "tokens": ["in", "blind", "deblurring", ",", "schuler", "et", "al", "employ", "neural", "networks", "as", "feature", "extraction", "modules", "and", "integrate", "it", "into", "a", "trainable", "deblurring", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "schuler et al", "start": 22, "end": 35, "i_start": 4, "i_end": 6}, "verb": {"text": "employ", "start": 36, "end": 42, "i_start": 7, "i_end": 7}}, {"subject": {"text": "schuler et al", "start": 22, "end": 35, "i_start": 4, "i_end": 6}, "verb": {"text": "integrate", "start": 93, "end": 102, "i_start": 15, "i_end": 15}}, {"character": {"text": "schuler", "start": 22, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "employ", "start": 36, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "schuler", "start": 22, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "integrate", "start": 93, "end": 102, "i_start": 15, "i_end": 15}}, {"character": {"text": "system", "start": 134, "end": 140, "i_start": 21, "i_end": 21}, "action": {"text": "deblurring", "start": 9, "end": 19, "i_start": 2, "i_end": 2}}], "id": 3543}, {"sent": "we can mention here that one can derive this type of equations from newton mechanics at least formally , see in the quantum case .", "tokens": ["we", "can", "mention", "here", "that", "one", "can", "derive", "this", "type", "of", "equations", "from", "newton", "mechanics", "at", "least", "formally", ",", "see", "in", "the", "quantum", "case", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "can mention", "start": 3, "end": 14, "i_start": 1, "i_end": 2}}, {"subject": {"text": "one", "start": 25, "end": 28, "i_start": 5, "i_end": 5}, "verb": {"text": "derive", "start": 33, "end": 39, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "mention", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "one", "start": 25, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "derive", "start": 33, "end": 39, "i_start": 7, "i_end": 7}}], "id": 3544}, {"sent": "is the gradient , here i denotes the second order unit tensor \u03b4ij , is the divergence of the corresponding field quantity .", "tokens": ["is", "the", "gradient", ",", "here", "i", "denotes", "the", "second", "order", "unit", "tensor", "\u03b4ij", ",", "is", "the", "divergence", "of", "the", "corresponding", "field", "quantity", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "i", "start": 23, "end": 24, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 68, "end": 70, "i_start": 14, "i_end": 14}}, {"subject": {"text": "i", "start": 23, "end": 24, "i_start": 5, "i_end": 5}, "verb": {"text": "denotes", "start": 25, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "i", "start": 23, "end": 24, "i_start": 5, "i_end": 5}, "action": {"text": "denotes", "start": 25, "end": 32, "i_start": 6, "i_end": 6}}], "id": 3545}, {"sent": "duts is a large scale dataset containing 10533 training images and 5019 test images .", "tokens": ["duts", "is", "a", "large", "scale", "dataset", "containing", "10533", "training", "images", "and", "5019", "test", "images", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "duts", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "dataset", "start": 22, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "containing", "start": 30, "end": 40, "i_start": 6, "i_end": 6}}], "id": 3546}, {"sent": "generative adversarial networks , in particular , have demonstrated to be an especially powerful tool for realistic image generation .", "tokens": ["generative", "adversarial", "networks", ",", "in", "particular", ",", "have", "demonstrated", "to", "be", "an", "especially", "powerful", "tool", "for", "realistic", "image", "generation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 55, "end": 67, "i_start": 8, "i_end": 8}}], "id": 3547}, {"sent": "deep learning is currently the state of the art machine learning technique in many application areas such as computer vision or natural language processing .", "tokens": ["deep", "learning", "is", "currently", "the", "state", "of", "the", "art", "machine", "learning", "technique", "in", "many", "application", "areas", "such", "as", "computer", "vision", "or", "natural", "language", "processing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 3548}, {"sent": "we would like to thank xerox research center europe for making their xelda toolkit available to us .", "tokens": ["we", "would", "like", "to", "thank", "xerox", "research", "center", "europe", "for", "making", "their", "xelda", "toolkit", "available", "to", "us", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "would like", "start": 3, "end": 13, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "like", "start": 9, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "thank", "start": 17, "end": 22, "i_start": 4, "i_end": 4}}], "id": 3549}, {"sent": "d eep convolutional neural networks have exhibited significant effectiveness in modeling image data .", "tokens": ["d", "eep", "convolutional", "neural", "networks", "have", "exhibited", "significant", "effectiveness", "in", "modeling", "image", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "d eep convolutional neural networks", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "have exhibited", "start": 36, "end": 50, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 27, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "exhibited", "start": 41, "end": 50, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 27, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "effectiveness", "start": 63, "end": 76, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 27, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "modeling", "start": 80, "end": 88, "i_start": 10, "i_end": 10}}], "id": 3550}, {"sent": "we refer the reader to appendix a in for the detailed description of this scheme .", "tokens": ["we", "refer", "the", "reader", "to", "appendix", "a", "in", "for", "the", "detailed", "description", "of", "this", "scheme", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3551}, {"sent": "meta-surfaces are thin meta-material layers that are capable of modifying the propagation of the radio waves in fully customizable ways .", "tokens": ["meta", "-", "surfaces", "are", "thin", "meta", "-", "material", "layers", "that", "are", "capable", "of", "modifying", "the", "propagation", "of", "the", "radio", "waves", "in", "fully", "customizable", "ways", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "meta-surfaces", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 14, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "surfaces", "start": 5, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "modifying", "start": 64, "end": 73, "i_start": 13, "i_end": 13}}], "id": 3552}, {"sent": "recently , deterministic deep neural networks have demonstrated state-of-the-art performance on many supervised tasks , eg , speech recognition .", "tokens": ["recently", ",", "deterministic", "deep", "neural", "networks", "have", "demonstrated", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "many", "supervised", "tasks", ",", "eg", ",", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deterministic deep neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have demonstrated", "start": 46, "end": 63, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "demonstrated", "start": 51, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 81, "end": 92, "i_start": 15, "i_end": 15}}], "id": 3553}, {"sent": "a model of spindle rhythmicity in the isolated thalamic reticular nucleus .", "tokens": ["a", "model", "of", "spindle", "rhythmicity", "in", "the", "isolated", "thalamic", "reticular", "nucleus", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3554}, {"sent": "asterisks denote flares , arrows denote upper limits for non-detections .", "tokens": ["asterisks", "denote", "flares", ",", "arrows", "denote", "upper", "limits", "for", "non", "-", "detections", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "asterisks", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "arrows", "start": 26, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "denote", "start": 33, "end": 39, "i_start": 5, "i_end": 5}}], "id": 3555}, {"sent": "for most lines the gf -values adopted are those derived from \u03b3 cyg spectrum .", "tokens": ["for", "most", "lines", "the", "gf", "-values", "adopted", "are", "those", "derived", "from", "\u03b3", "cyg", "spectrum", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3556}, {"sent": "gans have been employed in various applications such as image synthesis , image interpolation and inpainting , style transfer , and next-frame prediction .", "tokens": ["gans", "have", "been", "employed", "in", "various", "applications", "such", "as", "image", "synthesis", ",", "image", "interpolation", "and", "inpainting", ",", "style", "transfer", ",", "and", "next", "-", "frame", "prediction", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "gans", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "have been employed", "start": 5, "end": 23, "i_start": 1, "i_end": 3}}], "id": 3557}, {"sent": "we test the accuracy of our irr-pwc on the public sintel benchmarks .", "tokens": ["we", "test", "the", "accuracy", "of", "our", "irr", "-", "pwc", "on", "the", "public", "sintel", "benchmarks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "test", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "test", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3558}, {"sent": "we verify that the teleportation process operates properly for the nonclassical input of the squeezed vacuum .", "tokens": ["we", "verify", "that", "the", "teleportation", "process", "operates", "properly", "for", "the", "nonclassical", "input", "of", "the", "squeezed", "vacuum", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "verify", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the teleportation process", "start": 15, "end": 40, "i_start": 3, "i_end": 5}, "verb": {"text": "operates", "start": 41, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "verify", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 3559}, {"sent": "dashed lines show results obtained with the experimental , non-collective deformation parameters , whereas the solid lines are obtained from the random-matrix model .", "tokens": ["dashed", "lines", "show", "results", "obtained", "with", "the", "experimental", ",", "non", "-", "collective", "deformation", "parameters", ",", "whereas", "the", "solid", "lines", "are", "obtained", "from", "the", "random", "-", "matrix", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "dashed lines", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "show", "start": 13, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "lines", "start": 7, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 13, "end": 17, "i_start": 2, "i_end": 2}}], "id": 3560}, {"sent": "we shall use the symbol p to denote the product over all prime numbers .", "tokens": ["we", "shall", "use", "the", "symbol", "p", "to", "denote", "the", "product", "over", "all", "prime", "numbers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "shall use", "start": 3, "end": 12, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 9, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 29, "end": 35, "i_start": 7, "i_end": 7}}], "id": 3561}, {"sent": "however , the radiation pattern of such a charge has a sin 2 \u03c6 dependence , about the direction of acceleration .", "tokens": ["however", ",", "the", "radiation", "pattern", "of", "such", "a", "charge", "has", "a", "sin", "2", "\u03c6", "dependence", ",", "about", "the", "direction", "of", "acceleration", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the radiation pattern of such a charge", "start": 10, "end": 48, "i_start": 2, "i_end": 8}, "verb": {"text": "has", "start": 49, "end": 52, "i_start": 9, "i_end": 9}}, {"character": {"text": "pattern", "start": 24, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "dependence", "start": 63, "end": 73, "i_start": 14, "i_end": 14}}], "id": 3562}, {"sent": "deep convolutional neural networks have enabled unparalleled breakthroughs in a variety of visual tasks , such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "enabled", "unparalleled", "breakthroughs", "in", "a", "variety", "of", "visual", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have enabled", "start": 35, "end": 47, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "enabled", "start": 40, "end": 47, "i_start": 5, "i_end": 5}}], "id": 3563}, {"sent": "in our calculations with sly4 , 40mg is the last mg isotope that is stable against the two-neutron emission .", "tokens": ["in", "our", "calculations", "with", "sly4", ",", "40", "mg", "is", "the", "last", "mg", "isotope", "that", "is", "stable", "against", "the", "two", "-", "neutron", "emission", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "40mg", "start": 32, "end": 36, "i_start": 6, "i_end": 7}, "verb": {"text": "is", "start": 37, "end": 39, "i_start": 8, "i_end": 8}}], "id": 3564}, {"sent": "the gluon field is a dynamical gauge field , while the flavor field in the dirac lagrangian is an external one .", "tokens": ["the", "gluon", "field", "is", "a", "dynamical", "gauge", "field", ",", "while", "the", "flavor", "field", "in", "the", "dirac", "lagrangian", "is", "an", "external", "one", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the gluon field", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 3565}, {"sent": "one can recognize that the overall construction of the scheme resembles a rotational pressure-correction type strategy .", "tokens": ["one", "can", "recognize", "that", "the", "overall", "construction", "of", "the", "scheme", "resembles", "a", "rotational", "pressure", "-", "correction", "type", "strategy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "can recognize", "start": 4, "end": 17, "i_start": 1, "i_end": 2}}, {"subject": {"text": "the overall construction of the scheme", "start": 23, "end": 61, "i_start": 4, "i_end": 9}, "verb": {"text": "resembles", "start": 62, "end": 71, "i_start": 10, "i_end": 10}}, {"character": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "recognize", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}], "id": 3566}, {"sent": "the exchange-correlation function was chosen to be that of the generalized gradient approximation implemented following the parametrization of perdew-burke-ernzerhof .", "tokens": ["the", "exchange", "-", "correlation", "function", "was", "chosen", "to", "be", "that", "of", "the", "generalized", "gradient", "approximation", "implemented", "following", "the", "parametrization", "of", "perdew", "-", "burke", "-", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange-correlation function", "start": 0, "end": 33, "i_start": 0, "i_end": 4}, "verb": {"text": "was chosen", "start": 34, "end": 44, "i_start": 5, "i_end": 6}}], "id": 3567}, {"sent": "without the paraxial approximation , we make use of the finite-difference time domain technique .", "tokens": ["without", "the", "paraxial", "approximation", ",", "we", "make", "use", "of", "the", "finite", "-", "difference", "time", "domain", "technique", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 37, "end": 39, "i_start": 5, "i_end": 5}, "verb": {"text": "make", "start": 40, "end": 44, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 37, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 45, "end": 48, "i_start": 7, "i_end": 7}}], "id": 3568}, {"sent": "in the classification setting , we validated stability training on the imagenet classification task .", "tokens": ["in", "the", "classification", "setting", ",", "we", "validated", "stability", "training", "on", "the", "imagenet", "classification", "task", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 32, "end": 34, "i_start": 5, "i_end": 5}, "verb": {"text": "validated", "start": 35, "end": 44, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 32, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "validated", "start": 35, "end": 44, "i_start": 6, "i_end": 6}}], "id": 3569}, {"sent": "in recent years , such traditional approaches have been largely replaced by neural networks , with two popular examples being variational autoencoders .", "tokens": ["in", "recent", "years", ",", "such", "traditional", "approaches", "have", "been", "largely", "replaced", "by", "neural", "networks", ",", "with", "two", "popular", "examples", "being", "variational", "autoencoders", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such traditional approaches", "start": 18, "end": 45, "i_start": 4, "i_end": 6}, "verb": {"text": "replaced", "start": 64, "end": 72, "i_start": 10, "i_end": 10}}, {"subject": {"text": "such traditional approaches", "start": 18, "end": 45, "i_start": 4, "i_end": 6}, "verb": {"text": "have been", "start": 46, "end": 55, "i_start": 7, "i_end": 8}}], "id": 3570}, {"sent": "we assume that the accelerated electrons remain in the same place .", "tokens": ["we", "assume", "that", "the", "accelerated", "electrons", "remain", "in", "the", "same", "place", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the accelerated electrons", "start": 15, "end": 40, "i_start": 3, "i_end": 5}, "verb": {"text": "remain", "start": 41, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 3571}, {"sent": "the expected signal production cross sections are computed at nlo with next-to-leading-logarithm accuracy .", "tokens": ["the", "expected", "signal", "production", "cross", "sections", "are", "computed", "at", "nlo", "with", "next", "-", "to", "-", "leading", "-", "logarithm", "accuracy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the expected signal production cross sections", "start": 0, "end": 45, "i_start": 0, "i_end": 5}, "verb": {"text": "are computed", "start": 46, "end": 58, "i_start": 6, "i_end": 7}}], "id": 3572}, {"sent": "recently , a particular class of nonlinear methods , deep neural networks , revolutionized the field of automated image classification by demonstrating impressive performance on large benchmark data sets .", "tokens": ["recently", ",", "a", "particular", "class", "of", "nonlinear", "methods", ",", "deep", "neural", "networks", ",", "revolutionized", "the", "field", "of", "automated", "image", "classification", "by", "demonstrating", "impressive", "performance", "on", "large", "benchmark", "data", "sets", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "a particular class of nonlinear methods", "start": 11, "end": 50, "i_start": 2, "i_end": 7}, "verb": {"text": "revolutionized", "start": 76, "end": 90, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 65, "end": 73, "i_start": 11, "i_end": 11}, "action": {"text": "revolutionized", "start": 76, "end": 90, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 65, "end": 73, "i_start": 11, "i_end": 11}, "action": {"text": "demonstrating", "start": 138, "end": 151, "i_start": 21, "i_end": 21}}, {"character": {"text": "networks", "start": 65, "end": 73, "i_start": 11, "i_end": 11}, "action": {"text": "performance", "start": 163, "end": 174, "i_start": 23, "i_end": 23}}, {"character": {"text": "performance", "start": 163, "end": 174, "i_start": 23, "i_end": 23}, "action": {"text": "impressive", "start": 152, "end": 162, "i_start": 22, "i_end": 22}}], "id": 3573}, {"sent": "in the sinr model with opportunistic links , slightly weaker task of local broadcasting in ad hoc setting , in which nodes have to inform only their neighbors in the corresponding communication graph , was studied in .", "tokens": ["in", "the", "sinr", "model", "with", "opportunistic", "links", ",", "slightly", "weaker", "task", "of", "local", "broadcasting", "in", "ad", "hoc", "setting", ",", "in", "which", "nodes", "have", "to", "inform", "only", "their", "neighbors", "in", "the", "corresponding", "communication", "graph", ",", "was", "studied", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "nodes", "start": 117, "end": 122, "i_start": 21, "i_end": 21}, "action": {"text": "inform", "start": 131, "end": 137, "i_start": 24, "i_end": 24}}], "id": 3574}, {"sent": "the electric charge is the sum of the third component of isospin t3 and the hypercharge y .", "tokens": ["the", "electric", "charge", "is", "the", "sum", "of", "the", "third", "component", "of", "isospin", "t3", "and", "the", "hypercharge", "y", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electric charge", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 3575}, {"sent": "this problem was intially addressed by wyner in the context of wiretap channels .", "tokens": ["this", "problem", "was", "intially", "addressed", "by", "wyner", "in", "the", "context", "of", "wiretap", "channels", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this problem", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "addressed", "start": 26, "end": 35, "i_start": 4, "i_end": 4}}, {"subject": {"text": "this problem", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "was", "start": 13, "end": 16, "i_start": 2, "i_end": 2}}], "id": 3576}, {"sent": "the exchangecorrelation energy was evaluated with the help of the perdew-burke-erzenhof approach within the generalized gradient approximation .", "tokens": ["the", "exchangecorrelation", "energy", "was", "evaluated", "with", "the", "help", "of", "the", "perdew", "-", "burke", "-", "erzenhof", "approach", "within", "the", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchangecorrelation energy", "start": 0, "end": 30, "i_start": 0, "i_end": 2}, "verb": {"text": "was evaluated", "start": 31, "end": 44, "i_start": 3, "i_end": 4}}, {"character": {"text": "approach", "start": 88, "end": 96, "i_start": 15, "i_end": 15}, "action": {"text": "help", "start": 54, "end": 58, "i_start": 7, "i_end": 7}}], "id": 3577}, {"sent": "burslem , centralizers of partially hyperboli di eomorphisms .", "tokens": ["burslem", ",", "centralizers", "of", "partially", "hyperboli", "di", "eomorphisms", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3578}, {"sent": "deep neural networks have contributed to notable performance improvements in fields such as image processing .", "tokens": ["deep", "neural", "networks", "have", "contributed", "to", "notable", "performance", "improvements", "in", "fields", "such", "as", "image", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have contributed", "start": 21, "end": 37, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "contributed", "start": 26, "end": 37, "i_start": 4, "i_end": 4}}], "id": 3579}, {"sent": "the exchange-correlation potential was calculated using the generalized gradient approximation as proposed by pedrew , burke , and ernzerhof .", "tokens": ["the", "exchange", "-", "correlation", "potential", "was", "calculated", "using", "the", "generalized", "gradient", "approximation", "as", "proposed", "by", "pedrew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange-correlation potential", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "was calculated", "start": 35, "end": 49, "i_start": 5, "i_end": 6}}, {"character": {"text": "pedrew", "start": 110, "end": 116, "i_start": 15, "i_end": 15}, "action": {"text": "proposed", "start": 98, "end": 106, "i_start": 13, "i_end": 13}}, {"character": {"text": "burke", "start": 119, "end": 124, "i_start": 17, "i_end": 17}, "action": {"text": "proposed", "start": 98, "end": 106, "i_start": 13, "i_end": 13}}, {"character": {"text": "ernzerhof", "start": 131, "end": 140, "i_start": 20, "i_end": 20}, "action": {"text": "proposed", "start": 98, "end": 106, "i_start": 13, "i_end": 13}}], "id": 3580}, {"sent": "deep learning and deep convolutional neural networks in particular , have recently shown impressive performance on a number of multimedia information retrieval tasks .", "tokens": ["deep", "learning", "and", "deep", "convolutional", "neural", "networks", "in", "particular", ",", "have", "recently", "shown", "impressive", "performance", "on", "a", "number", "of", "multimedia", "information", "retrieval", "tasks", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "deep learning and deep convolutional neural networks in particular", "start": 0, "end": 66, "i_start": 0, "i_end": 8}, "verb": {"text": "shown", "start": 83, "end": 88, "i_start": 12, "i_end": 12}}, {"subject": {"text": "deep learning and deep convolutional neural networks in particular", "start": 0, "end": 66, "i_start": 0, "i_end": 8}, "verb": {"text": "have", "start": 69, "end": 73, "i_start": 10, "i_end": 10}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "shown", "start": 83, "end": 88, "i_start": 12, "i_end": 12}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "shown", "start": 83, "end": 88, "i_start": 12, "i_end": 12}}, {"character": {"text": "convolutional", "start": 23, "end": 36, "i_start": 4, "i_end": 4}, "action": {"text": "shown", "start": 83, "end": 88, "i_start": 12, "i_end": 12}}, {"character": {"text": "deep", "start": 18, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 83, "end": 88, "i_start": 12, "i_end": 12}}, {"character": {"text": "particular", "start": 56, "end": 66, "i_start": 8, "i_end": 8}, "action": {"text": "shown", "start": 83, "end": 88, "i_start": 12, "i_end": 12}}], "id": 3581}, {"sent": "while the ising model is a classical model , it has become the basis for understanding magnetic phase transitions in quan chapter 3 .", "tokens": ["while", "the", "ising", "model", "is", "a", "classical", "model", ",", "it", "has", "become", "the", "basis", "for", "understanding", "magnetic", "phase", "transitions", "in", "quan", "chapter", "3", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 45, "end": 47, "i_start": 9, "i_end": 9}, "verb": {"text": "has become", "start": 48, "end": 58, "i_start": 10, "i_end": 11}}], "id": 3582}, {"sent": "this is clear if am is homogeneous for every m .", "tokens": ["this", "is", "clear", "if", "am", "is", "homogeneous", "for", "every", "m", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3583}, {"sent": "generative adversarial networks , a type of generative model , help us mitigate the issue of data unavailability by synthesizing new realistic samples .", "tokens": ["generative", "adversarial", "networks", ",", "a", "type", "of", "generative", "model", ",", "help", "us", "mitigate", "the", "issue", "of", "data", "unavailability", "by", "synthesizing", "new", "realistic", "samples", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "help", "start": 63, "end": 67, "i_start": 10, "i_end": 10}}, {"subject": {"text": "us", "start": 68, "end": 70, "i_start": 11, "i_end": 11}, "verb": {"text": "mitigate", "start": 71, "end": 79, "i_start": 12, "i_end": 12}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "help", "start": 63, "end": 67, "i_start": 10, "i_end": 10}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "mitigate", "start": 71, "end": 79, "i_start": 12, "i_end": 12}}, {"character": {"text": "unavailability", "start": 98, "end": 112, "i_start": 17, "i_end": 17}, "action": {"text": "issue", "start": 84, "end": 89, "i_start": 14, "i_end": 14}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "synthesizing", "start": 116, "end": 128, "i_start": 19, "i_end": 19}}], "id": 3584}, {"sent": "free energy is the fundamental object in statistical mechanics .", "tokens": ["free", "energy", "is", "the", "fundamental", "object", "in", "statistical", "mechanics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "free energy", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 3585}, {"sent": "universal fault-tolerant quantum computation on decoherence-free subspaces .", "tokens": ["universal", "fault", "-", "tolerant", "quantum", "computation", "on", "decoherence", "-", "free", "subspaces", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "computation", "start": 33, "end": 44, "i_start": 5, "i_end": 5}, "action": {"text": "tolerant", "start": 16, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3586}, {"sent": "on the uniqueness of solutions of stochastic differential equations .", "tokens": ["on", "the", "uniqueness", "of", "solutions", "of", "stochastic", "differential", "equations", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3587}, {"sent": "the resistance increases linear with the sample lengths apart from the fluctuations .", "tokens": ["the", "resistance", "increases", "linear", "with", "the", "sample", "lengths", "apart", "from", "the", "fluctuations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the resistance", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "increases", "start": 15, "end": 24, "i_start": 2, "i_end": 2}}], "id": 3588}, {"sent": "generative adversarial networks are unsupervised generative models that learn to produce realistic samples of a given dataset from low-dimensional , random latent vectors .", "tokens": ["generative", "adversarial", "networks", "are", "unsupervised", "generative", "models", "that", "learn", "to", "produce", "realistic", "samples", "of", "a", "given", "dataset", "from", "low", "-", "dimensional", ",", "random", "latent", "vectors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are unsupervised", "start": 32, "end": 48, "i_start": 3, "i_end": 4}}, {"character": {"text": "models", "start": 60, "end": 66, "i_start": 6, "i_end": 6}, "action": {"text": "learn", "start": 72, "end": 77, "i_start": 8, "i_end": 8}}, {"character": {"text": "models", "start": 60, "end": 66, "i_start": 6, "i_end": 6}, "action": {"text": "produce", "start": 81, "end": 88, "i_start": 10, "i_end": 10}}], "id": 3589}, {"sent": "these correlators are calculated for the ulrarelativistic electronpositron plasma .", "tokens": ["these", "correlators", "are", "calculated", "for", "the", "ulrarelativistic", "electronpositron", "plasma", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these correlators", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "are calculated", "start": 18, "end": 32, "i_start": 2, "i_end": 3}}], "id": 3590}, {"sent": "in doing so , although we follow the arguments of refs , some of our derivations are original .", "tokens": ["in", "doing", "so", ",", "although", "we", "follow", "the", "arguments", "of", "refs", ",", "some", "of", "our", "derivations", "are", "original", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "some of our derivations", "start": 57, "end": 80, "i_start": 12, "i_end": 15}, "verb": {"text": "are", "start": 81, "end": 84, "i_start": 16, "i_end": 16}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "action": {"text": "derivations", "start": 69, "end": 80, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "action": {"text": "follow", "start": 26, "end": 32, "i_start": 6, "i_end": 6}}], "id": 3591}, {"sent": "the saturation 0 ) is a finite union of linear subspaces of w .", "tokens": ["the", "saturation", "0", ")", "is", "a", "finite", "union", "of", "linear", "subspaces", "of", "w", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the saturation 0 )", "start": 0, "end": 18, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 4, "i_end": 4}}], "id": 3592}, {"sent": "algorithms for concurrently coupling quantum mechanics and classical molecular mechanics are widely used to perform simulations of large systems in materials science and biochemistry .", "tokens": ["algorithms", "for", "concurrently", "coupling", "quantum", "mechanics", "and", "classical", "molecular", "mechanics", "are", "widely", "used", "to", "perform", "simulations", "of", "large", "systems", "in", "materials", "science", "and", "biochemistry", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "algorithms for concurrently coupling quantum mechanics and classical molecular mechanics", "start": 0, "end": 88, "i_start": 0, "i_end": 9}, "verb": {"text": "used", "start": 100, "end": 104, "i_start": 12, "i_end": 12}}, {"subject": {"text": "algorithms for concurrently coupling quantum mechanics and classical molecular mechanics", "start": 0, "end": 88, "i_start": 0, "i_end": 9}, "verb": {"text": "are", "start": 89, "end": 92, "i_start": 10, "i_end": 10}}], "id": 3593}, {"sent": "convolutional neural networks have powerful pattern-recognition capabilities that have recently given dramatic improvements in important tasks such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "powerful", "pattern", "-", "recognition", "capabilities", "that", "have", "recently", "given", "dramatic", "improvements", "in", "important", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "recognition", "start": 52, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "capabilities", "start": 64, "end": 76, "i_start": 8, "i_end": 8}, "action": {"text": "improvements", "start": 111, "end": 123, "i_start": 14, "i_end": 14}}], "id": 3594}, {"sent": "reinforcement learning in markovian and non-markovian environments .", "tokens": ["reinforcement", "learning", "in", "markovian", "and", "non", "-", "markovian", "environments", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3595}, {"sent": "use a sum of normal densities to estimate the probability distributions and can approximate any probability density function .", "tokens": ["use", "a", "sum", "of", "normal", "densities", "to", "estimate", "the", "probability", "distributions", "and", "can", "approximate", "any", "probability", "density", "function", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3596}, {"sent": "massive multiple-input multiple-output is an essential technology for future fifth generation wireless communication systems .", "tokens": ["massive", "multiple", "-", "input", "multiple", "-", "output", "is", "an", "essential", "technology", "for", "future", "fifth", "generation", "wireless", "communication", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "massive multiple-input multiple-output", "start": 0, "end": 38, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 7, "i_end": 7}}], "id": 3597}, {"sent": "convolutional neural networks have surpassed many traditional machine learning approaches in solving several computer vision tasks such as classification and others .", "tokens": ["convolutional", "neural", "networks", "have", "surpassed", "many", "traditional", "machine", "learning", "approaches", "in", "solving", "several", "computer", "vision", "tasks", "such", "as", "classification", "and", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have surpassed", "start": 30, "end": 44, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "surpassed", "start": 35, "end": 44, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "solving", "start": 93, "end": 100, "i_start": 11, "i_end": 11}}], "id": 3598}, {"sent": "consequently , this means that the difference discrete multisymplectic structure preserving law holds in the function space with the closed discrete euler-lagrange condition in general rather than in the solution space only .", "tokens": ["consequently", ",", "this", "means", "that", "the", "difference", "discrete", "multisymplectic", "structure", "preserving", "law", "holds", "in", "the", "function", "space", "with", "the", "closed", "discrete", "euler", "-", "lagrange", "condition", "in", "general", "rather", "than", "in", "the", "solution", "space", "only", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 15, "end": 19, "i_start": 2, "i_end": 2}, "verb": {"text": "means", "start": 20, "end": 25, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the difference discrete multisymplectic structure preserving law", "start": 31, "end": 95, "i_start": 5, "i_end": 11}, "verb": {"text": "holds", "start": 96, "end": 101, "i_start": 12, "i_end": 12}}, {"character": {"text": "law", "start": 92, "end": 95, "i_start": 11, "i_end": 11}, "action": {"text": "holds", "start": 96, "end": 101, "i_start": 12, "i_end": 12}}, {"character": {"text": "law", "start": 92, "end": 95, "i_start": 11, "i_end": 11}, "action": {"text": "preserving", "start": 81, "end": 91, "i_start": 10, "i_end": 10}}], "id": 3599}, {"sent": "there has been active research on developing efficient algorithms for convex-concave saddle point problems min x max y l , eg , .", "tokens": ["there", "has", "been", "active", "research", "on", "developing", "efficient", "algorithms", "for", "convex", "-", "concave", "saddle", "point", "problems", "min", "x", "max", "y", "l", ",", "eg", ",", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "has been", "start": 6, "end": 14, "i_start": 1, "i_end": 2}}], "id": 3600}, {"sent": "velten et al solved this system using a backprojection algorithm .", "tokens": ["velten", "et", "al", "solved", "this", "system", "using", "a", "backprojection", "algorithm", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 7, "end": 12, "i_start": 1, "i_end": 2}, "verb": {"text": "solved", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "velten", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "solved", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "velten", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 32, "end": 37, "i_start": 6, "i_end": 6}}], "id": 3601}, {"sent": "in particular , it was shown in the seminal paper that the noncommutative theory can be naturally embedded into the string theory .", "tokens": ["in", "particular", ",", "it", "was", "shown", "in", "the", "seminal", "paper", "that", "the", "noncommutative", "theory", "can", "be", "naturally", "embedded", "into", "the", "string", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "was shown", "start": 19, "end": 28, "i_start": 4, "i_end": 5}}, {"subject": {"text": "the noncommutative theory", "start": 55, "end": 80, "i_start": 11, "i_end": 13}, "verb": {"text": "embedded", "start": 98, "end": 106, "i_start": 17, "i_end": 17}}], "id": 3602}, {"sent": "the calculations are performed within density-functional theory using the projector augmented wave method encoded in the vienna ab initio simulation package .", "tokens": ["the", "calculations", "are", "performed", "within", "density", "-", "functional", "theory", "using", "the", "projector", "augmented", "wave", "method", "encoded", "in", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the calculations", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "are performed", "start": 17, "end": 30, "i_start": 2, "i_end": 3}}, {"character": {"text": "density", "start": 38, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "functional", "start": 46, "end": 56, "i_start": 7, "i_end": 7}}], "id": 3603}, {"sent": "a temporal logic for reasoning about timed concurrent constraint programs .", "tokens": ["a", "temporal", "logic", "for", "reasoning", "about", "timed", "concurrent", "constraint", "programs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "programs", "start": 65, "end": 73, "i_start": 9, "i_end": 9}, "action": {"text": "constraint", "start": 54, "end": 64, "i_start": 8, "i_end": 8}}], "id": 3604}, {"sent": "the data were calibrated using the reduction package common astronomy software applications .", "tokens": ["the", "data", "were", "calibrated", "using", "the", "reduction", "package", "common", "astronomy", "software", "applications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "were calibrated", "start": 9, "end": 24, "i_start": 2, "i_end": 3}}, {"character": {"text": "package", "start": 45, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "reduction", "start": 35, "end": 44, "i_start": 6, "i_end": 6}}], "id": 3605}, {"sent": "batch normalization is introduced following each convolutional layer .", "tokens": ["batch", "normalization", "is", "introduced", "following", "each", "convolutional", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "batch normalization", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is introduced", "start": 20, "end": 33, "i_start": 2, "i_end": 3}}], "id": 3606}, {"sent": "noise thresholds for optical cluster-state quantum computation .", "tokens": ["noise", "thresholds", "for", "optical", "cluster", "-", "state", "quantum", "computation", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3607}, {"sent": "furthermore , we also rely on recent generative models , namely generative adversarial networks , to build image descriptors .", "tokens": ["furthermore", ",", "we", "also", "rely", "on", "recent", "generative", "models", ",", "namely", "generative", "adversarial", "networks", ",", "to", "build", "image", "descriptors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "rely", "start": 22, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "rely", "start": 22, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "models", "start": 48, "end": 54, "i_start": 8, "i_end": 8}, "action": {"text": "build", "start": 101, "end": 106, "i_start": 16, "i_end": 16}}], "id": 3608}, {"sent": "the average of this probability over the whole network is called clustering coefficient .", "tokens": ["the", "average", "of", "this", "probability", "over", "the", "whole", "network", "is", "called", "clustering", "coefficient", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the average of this probability over the whole network", "start": 0, "end": 54, "i_start": 0, "i_end": 8}, "verb": {"text": "is called", "start": 55, "end": 64, "i_start": 9, "i_end": 10}}], "id": 3609}, {"sent": "an alternative approach to attain an interior point for multiple access channels is rate splitting .", "tokens": ["an", "alternative", "approach", "to", "attain", "an", "interior", "point", "for", "multiple", "access", "channels", "is", "rate", "splitting", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "an alternative approach to attain an interior point for multiple access channels", "start": 0, "end": 80, "i_start": 0, "i_end": 11}, "verb": {"text": "is", "start": 81, "end": 83, "i_start": 12, "i_end": 12}}], "id": 3610}, {"sent": "for image classification models we use the pretrained vgg16 networks with imagenet .", "tokens": ["for", "image", "classification", "models", "we", "use", "the", "pretrained", "vgg16", "networks", "with", "imagenet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 32, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 35, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "models", "start": 25, "end": 31, "i_start": 3, "i_end": 3}, "action": {"text": "classification", "start": 10, "end": 24, "i_start": 2, "i_end": 2}}], "id": 3611}, {"sent": "this capacitance comprises the input capacitance of the preamplifier and the parasitic capacitance associated to the depfet source line .", "tokens": ["this", "capacitance", "comprises", "the", "input", "capacitance", "of", "the", "preamplifier", "and", "the", "parasitic", "capacitance", "associated", "to", "the", "depfet", "source", "line", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this capacitance", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "comprises", "start": 17, "end": 26, "i_start": 2, "i_end": 2}}], "id": 3612}, {"sent": "photoacoustic imaging is a recent hybrid imaging modality that couples electromagnetic waves with acoustic waves to achieve high-resolution imaging of optical properties of heterogeneous media such as biological tissues .", "tokens": ["photoacoustic", "imaging", "is", "a", "recent", "hybrid", "imaging", "modality", "that", "couples", "electromagnetic", "waves", "with", "acoustic", "waves", "to", "achieve", "high", "-", "resolution", "imaging", "of", "optical", "properties", "of", "heterogeneous", "media", "such", "as", "biological", "tissues", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "photoacoustic imaging", "start": 0, "end": 21, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "modality", "start": 49, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "couples", "start": 63, "end": 70, "i_start": 9, "i_end": 9}}, {"character": {"text": "waves", "start": 87, "end": 92, "i_start": 11, "i_end": 11}, "action": {"text": "achieve", "start": 116, "end": 123, "i_start": 16, "i_end": 16}}], "id": 3613}, {"sent": "the fermionic case follows by the jw-transformation .", "tokens": ["the", "fermionic", "case", "follows", "by", "the", "jw", "-", "transformation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the fermionic case", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "follows", "start": 19, "end": 26, "i_start": 3, "i_end": 3}}], "id": 3614}, {"sent": "another work designed by the authors is a very deep end-to-end persistent memory network for image restoration task , which tackles the long-term dependency problem in the previous cnn architectures .", "tokens": ["another", "work", "designed", "by", "the", "authors", "is", "a", "very", "deep", "end", "-", "to", "-", "end", "persistent", "memory", "network", "for", "image", "restoration", "task", ",", "which", "tackles", "the", "long", "-", "term", "dependency", "problem", "in", "the", "previous", "cnn", "architectures", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another work designed by the authors", "start": 0, "end": 36, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 37, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "persistent", "start": 63, "end": 73, "i_start": 15, "i_end": 15}, "action": {"text": "authors", "start": 29, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "network", "start": 81, "end": 88, "i_start": 17, "i_end": 17}, "action": {"text": "tackles", "start": 124, "end": 131, "i_start": 24, "i_end": 24}}], "id": 3615}, {"sent": "indeed , the theoretical structure of the model is very similar to the adm formalism of general relativity .", "tokens": ["indeed", ",", "the", "theoretical", "structure", "of", "the", "model", "is", "very", "similar", "to", "the", "adm", "formalism", "of", "general", "relativity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the theoretical structure of the model", "start": 9, "end": 47, "i_start": 2, "i_end": 7}, "verb": {"text": "is", "start": 48, "end": 50, "i_start": 8, "i_end": 8}}], "id": 3616}, {"sent": "although string theory is a strong candidate of it , the dynamics of the fermion states in string theories has not yet been extensively studied .", "tokens": ["although", "string", "theory", "is", "a", "strong", "candidate", "of", "it", ",", "the", "dynamics", "of", "the", "fermion", "states", "in", "string", "theories", "has", "not", "yet", "been", "extensively", "studied", "."], "score": [1, 1, 1, 1, 1], "labels": [{"subject": {"text": "the dynamics of the fermion states in string theories", "start": 53, "end": 106, "i_start": 10, "i_end": 18}, "verb": {"text": "studied", "start": 136, "end": 143, "i_start": 24, "i_end": 24}}, {"subject": {"text": "the dynamics of the fermion states in string theories", "start": 53, "end": 106, "i_start": 10, "i_end": 18}, "verb": {"text": "has not", "start": 107, "end": 114, "i_start": 19, "i_end": 20}}, {"subject": {"text": "the dynamics of the fermion states in string theories", "start": 53, "end": 106, "i_start": 10, "i_end": 18}, "verb": {"text": "been", "start": 119, "end": 123, "i_start": 22, "i_end": 22}}], "id": 3617}, {"sent": "in this work , we utilize resnet as the backbone of the offset-guided network .", "tokens": ["in", "this", "work", ",", "we", "utilize", "resnet", "as", "the", "backbone", "of", "the", "offset", "-", "guided", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "utilize", "start": 18, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "utilize", "start": 18, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "offset", "start": 56, "end": 62, "i_start": 12, "i_end": 12}, "action": {"text": "guided", "start": 63, "end": 69, "i_start": 14, "i_end": 14}}], "id": 3618}, {"sent": "asterisks denote experimental realizations .", "tokens": ["asterisks", "denote", "experimental", "realizations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "asterisks", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "denote", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "asterisks", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}], "id": 3619}, {"sent": "this approximation was introduced by chorin , in order to deal with the difficulty induced by the incompressibility constraints in the numerical approximations to the navier stokes equation .", "tokens": ["this", "approximation", "was", "introduced", "by", "chorin", ",", "in", "order", "to", "deal", "with", "the", "difficulty", "induced", "by", "the", "incompressibility", "constraints", "in", "the", "numerical", "approximations", "to", "the", "navier", "stokes", "equation", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this approximation", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "was introduced", "start": 19, "end": 33, "i_start": 2, "i_end": 3}}, {"character": {"text": "chorin", "start": 37, "end": 43, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 23, "end": 33, "i_start": 3, "i_end": 3}}, {"character": {"text": "chorin", "start": 37, "end": 43, "i_start": 5, "i_end": 5}, "action": {"text": "deal", "start": 58, "end": 62, "i_start": 10, "i_end": 10}}, {"character": {"text": "constraints", "start": 116, "end": 127, "i_start": 18, "i_end": 18}, "action": {"text": "induced", "start": 83, "end": 90, "i_start": 14, "i_end": 14}}], "id": 3620}, {"sent": "its association with the bal outflow is unclear .", "tokens": ["its", "association", "with", "the", "bal", "outflow", "is", "unclear", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "its association with the bal outflow", "start": 0, "end": 36, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 37, "end": 39, "i_start": 6, "i_end": 6}}], "id": 3621}, {"sent": "let fj be the unique edge towards the loop emanating from pj .", "tokens": ["let", "fj", "be", "the", "unique", "edge", "towards", "the", "loop", "emanating", "from", "pj", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "pj", "start": 58, "end": 60, "i_start": 11, "i_end": 11}, "action": {"text": "emanating", "start": 43, "end": 52, "i_start": 9, "i_end": 9}}], "id": 3622}, {"sent": "in recent years , a multi-task learning approach has been successfully applied in combination with neural networks for a variety of nlp tasks .", "tokens": ["in", "recent", "years", ",", "a", "multi", "-", "task", "learning", "approach", "has", "been", "successfully", "applied", "in", "combination", "with", "neural", "networks", "for", "a", "variety", "of", "nlp", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a multi-task learning approach", "start": 18, "end": 48, "i_start": 4, "i_end": 9}, "verb": {"text": "applied", "start": 71, "end": 78, "i_start": 13, "i_end": 13}}, {"subject": {"text": "a multi-task learning approach", "start": 18, "end": 48, "i_start": 4, "i_end": 9}, "verb": {"text": "has been", "start": 49, "end": 57, "i_start": 10, "i_end": 11}}], "id": 3623}, {"sent": "we used stochastic gradient descent with adam updates for optimization .", "tokens": ["we", "used", "stochastic", "gradient", "descent", "with", "adam", "updates", "for", "optimization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimization", "start": 58, "end": 70, "i_start": 9, "i_end": 9}}], "id": 3624}, {"sent": "we use the pascal voc 2011 action classification dataset for our experiments .", "tokens": ["we", "use", "the", "pascal", "voc", "2011", "action", "classification", "dataset", "for", "our", "experiments", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "experiments", "start": 65, "end": 76, "i_start": 11, "i_end": 11}}], "id": 3625}, {"sent": "beta-ray activities were measured following chemical separation .", "tokens": ["beta", "-", "ray", "activities", "were", "measured", "following", "chemical", "separation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "beta-ray activities", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "were measured", "start": 20, "end": 33, "i_start": 4, "i_end": 5}}], "id": 3626}, {"sent": "we used adam as our training optimizer with reference parameters .", "tokens": ["we", "used", "adam", "as", "our", "training", "optimizer", "with", "reference", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3627}, {"sent": "accurate measurement of the forces affecting the needle tip is of particular interest , eg , to keep track of the needle-tissue interaction and to detect potential tissue ruptures , or to generate haptic and visual feedback .", "tokens": ["accurate", "measurement", "of", "the", "forces", "affecting", "the", "needle", "tip", "is", "of", "particular", "interest", ",", "eg", ",", "to", "keep", "track", "of", "the", "needle", "-", "tissue", "interaction", "and", "to", "detect", "potential", "tissue", "ruptures", ",", "or", "to", "generate", "haptic", "and", "visual", "feedback", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "accurate measurement of the forces affecting the needle tip", "start": 0, "end": 59, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 60, "end": 62, "i_start": 9, "i_end": 9}}, {"character": {"text": "forces", "start": 28, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "affecting", "start": 35, "end": 44, "i_start": 5, "i_end": 5}}, {"character": {"text": "needle", "start": 49, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "interaction", "start": 128, "end": 139, "i_start": 24, "i_end": 24}}], "id": 3628}, {"sent": "deep neural networks have achieved impressive performance on tasks across a variety of domains , including vision .", "tokens": ["deep", "neural", "networks", "have", "achieved", "impressive", "performance", "on", "tasks", "across", "a", "variety", "of", "domains", ",", "including", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 46, "end": 57, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 46, "end": 57, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 35, "end": 45, "i_start": 5, "i_end": 5}}], "id": 3629}, {"sent": "in , zheng and huang have already shown that any bounded above , resp .", "tokens": ["in", ",", "zheng", "and", "huang", "have", "already", "shown", "that", "any", "bounded", "above", ",", "resp", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zheng and huang", "start": 5, "end": 20, "i_start": 2, "i_end": 4}, "verb": {"text": "shown", "start": 34, "end": 39, "i_start": 7, "i_end": 7}}, {"subject": {"text": "zheng and huang", "start": 5, "end": 20, "i_start": 2, "i_end": 4}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 5, "i_end": 5}}, {"subject": {"text": "zheng and huang", "start": 5, "end": 20, "i_start": 2, "i_end": 4}, "verb": {"text": "bounded", "start": 49, "end": 56, "i_start": 10, "i_end": 10}}, {"character": {"text": "zheng", "start": 5, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 34, "end": 39, "i_start": 7, "i_end": 7}}, {"character": {"text": "huang", "start": 15, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "shown", "start": 34, "end": 39, "i_start": 7, "i_end": 7}}, {"character": {"text": "resp", "start": 65, "end": 69, "i_start": 13, "i_end": 13}, "action": {"text": "shown", "start": 34, "end": 39, "i_start": 7, "i_end": 7}}], "id": 3630}, {"sent": "we evaluated the quality of summaries from different systems automatically using rouge .", "tokens": ["we", "evaluated", "the", "quality", "of", "summaries", "from", "different", "systems", "automatically", "using", "rouge", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluated", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluated", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "systems", "start": 53, "end": 60, "i_start": 8, "i_end": 8}, "action": {"text": "summaries", "start": 28, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 75, "end": 80, "i_start": 10, "i_end": 10}}], "id": 3631}, {"sent": "within this setting , there exist algorithms that recover s 1 , s 2 , along with convergence rates for estimating f in the limit of large n .", "tokens": ["within", "this", "setting", ",", "there", "exist", "algorithms", "that", "recover", "s", "1", ",", "s", "2", ",", "along", "with", "convergence", "rates", "for", "estimating", "f", "in", "the", "limit", "of", "large", "n", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 22, "end": 27, "i_start": 4, "i_end": 4}, "verb": {"text": "exist", "start": 28, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "algorithms", "start": 34, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "recover", "start": 50, "end": 57, "i_start": 8, "i_end": 8}}], "id": 3632}, {"sent": "variable-speed-of-light cosmologies were proposed as possible solutions to the initial value problems in the standard big bang model .", "tokens": ["variable", "-", "speed", "-", "of", "-", "light", "cosmologies", "were", "proposed", "as", "possible", "solutions", "to", "the", "initial", "value", "problems", "in", "the", "standard", "big", "bang", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "variable-speed-of-light cosmologies", "start": 0, "end": 35, "i_start": 0, "i_end": 7}, "verb": {"text": "were proposed", "start": 36, "end": 49, "i_start": 8, "i_end": 9}}], "id": 3633}, {"sent": "phase synchronization of chaotic oscilla tors .", "tokens": ["phase", "synchronization", "of", "chaotic", "oscilla", "tors", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3634}, {"sent": "nondemolition measurement and control in quantum dynamical systems .", "tokens": ["nondemolition", "measurement", "and", "control", "in", "quantum", "dynamical", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3635}, {"sent": "the perdew-burke-ernzerhof functional within the generalized gradient approximation is used for the exchange-correlation interaction between valence electrons .", "tokens": ["the", "perdew", "-", "burke", "-", "ernzerhof", "functional", "within", "the", "generalized", "gradient", "approximation", "is", "used", "for", "the", "exchange", "-", "correlation", "interaction", "between", "valence", "electrons", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the perdew-burke-ernzerhof functional within the generalized gradient approximation", "start": 0, "end": 83, "i_start": 0, "i_end": 11}, "verb": {"text": "is used", "start": 84, "end": 91, "i_start": 12, "i_end": 13}}, {"character": {"text": "electrons", "start": 149, "end": 158, "i_start": 22, "i_end": 22}, "action": {"text": "interaction", "start": 121, "end": 132, "i_start": 19, "i_end": 19}}], "id": 3636}, {"sent": "next is an integration by parts formula for the left young and right young integrals .", "tokens": ["next", "is", "an", "integration", "by", "parts", "formula", "for", "the", "left", "young", "and", "right", "young", "integrals", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "an integration by parts formula for the left young and right young integrals", "start": 8, "end": 84, "i_start": 2, "i_end": 14}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3637}, {"sent": "each of these blocks consists of a 3x3 convolution with 64 filters , batch normalization , a relu activation , and 2x2 max-pooling .", "tokens": ["each", "of", "these", "blocks", "consists", "of", "a", "3x3", "convolution", "with", "64", "filters", ",", "batch", "normalization", ",", "a", "relu", "activation", ",", "and", "2x2", "max", "-", "pooling", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each of these blocks", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "consists", "start": 21, "end": 29, "i_start": 4, "i_end": 4}}], "id": 3638}, {"sent": "the tm waves are derived from the vector potential whose only nonzero component is az .", "tokens": ["the", "tm", "waves", "are", "derived", "from", "the", "vector", "potential", "whose", "only", "nonzero", "component", "is", "az", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the tm waves", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "are derived", "start": 13, "end": 24, "i_start": 3, "i_end": 4}}], "id": 3639}, {"sent": "this task was computationally performed using the software uspex combined with vienna ab initio simulation package .", "tokens": ["this", "task", "was", "computationally", "performed", "using", "the", "software", "uspex", "combined", "with", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this task", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "performed", "start": 30, "end": 39, "i_start": 4, "i_end": 4}}, {"subject": {"text": "this task", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "was", "start": 10, "end": 13, "i_start": 2, "i_end": 2}}], "id": 3640}, {"sent": "the dynamics of the model consists of two steps .", "tokens": ["the", "dynamics", "of", "the", "model", "consists", "of", "two", "steps", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dynamics of the model", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "consists", "start": 26, "end": 34, "i_start": 5, "i_end": 5}}], "id": 3641}, {"sent": "as the orbit of y is connected then so is the closure of such orbit which , by minimality , is all of y .", "tokens": ["as", "the", "orbit", "of", "y", "is", "connected", "then", "so", "is", "the", "closure", "of", "such", "orbit", "which", ",", "by", "minimality", ",", "is", "all", "of", "y", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the closure of such orbit which", "start": 42, "end": 73, "i_start": 10, "i_end": 15}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 9, "i_end": 9}}], "id": 3642}, {"sent": "deep reinforcement learning with neural network policies and value functions has had enormous success in recent years across a wide range of domains .", "tokens": ["deep", "reinforcement", "learning", "with", "neural", "network", "policies", "and", "value", "functions", "has", "had", "enormous", "success", "in", "recent", "years", "across", "a", "wide", "range", "of", "domains", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "deep reinforcement learning with neural network policies and value functions", "start": 0, "end": 76, "i_start": 0, "i_end": 9}, "verb": {"text": "has had", "start": 77, "end": 84, "i_start": 10, "i_end": 11}}, {"character": {"text": "learning", "start": 19, "end": 27, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 94, "end": 101, "i_start": 13, "i_end": 13}}, {"character": {"text": "network", "start": 40, "end": 47, "i_start": 5, "i_end": 5}, "action": {"text": "policies", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}], "id": 3643}, {"sent": "recent development of deep convolutional neural networks has led to great success in a variety of tasks including image classfication and others .", "tokens": ["recent", "development", "of", "deep", "convolutional", "neural", "networks", "has", "led", "to", "great", "success", "in", "a", "variety", "of", "tasks", "including", "image", "classfication", "and", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent development of deep convolutional neural networks", "start": 0, "end": 56, "i_start": 0, "i_end": 6}, "verb": {"text": "has led", "start": 57, "end": 64, "i_start": 7, "i_end": 8}}, {"character": {"text": "development", "start": 7, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 61, "end": 64, "i_start": 8, "i_end": 8}}], "id": 3644}, {"sent": "liao et al also find dense correspondence between two images based on deep features , yielding results that are more similar to ours .", "tokens": ["liao", "et", "al", "also", "find", "dense", "correspondence", "between", "two", "images", "based", "on", "deep", "features", ",", "yielding", "results", "that", "are", "more", "similar", "to", "ours", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "liao et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "find", "start": 16, "end": 20, "i_start": 4, "i_end": 4}}, {"character": {"text": "liao", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 16, "end": 20, "i_start": 4, "i_end": 4}}, {"character": {"text": "two images", "start": 50, "end": 60, "i_start": 8, "i_end": 9}, "action": {"text": "correspondence", "start": 27, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "correspondence", "start": 27, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "yielding", "start": 86, "end": 94, "i_start": 15, "i_end": 15}}], "id": 3645}, {"sent": "recent years have yielded rapid advances in the field of deep learning , largely due to the unparalleled effectiveness of convolutional neural networks on a variety of difficult problems .", "tokens": ["recent", "years", "have", "yielded", "rapid", "advances", "in", "the", "field", "of", "deep", "learning", ",", "largely", "due", "to", "the", "unparalleled", "effectiveness", "of", "convolutional", "neural", "networks", "on", "a", "variety", "of", "difficult", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent years", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "have yielded", "start": 13, "end": 25, "i_start": 2, "i_end": 3}}, {"character": {"text": "years", "start": 7, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "yielded", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 143, "end": 151, "i_start": 22, "i_end": 22}, "action": {"text": "effectiveness", "start": 105, "end": 118, "i_start": 18, "i_end": 18}}], "id": 3646}, {"sent": "the weyl tensor is a 4-rank tensor that contains the independent components of the riemann tensor not captured by the ricci tensor .", "tokens": ["the", "weyl", "tensor", "is", "a", "4", "-", "rank", "tensor", "that", "contains", "the", "independent", "components", "of", "the", "riemann", "tensor", "not", "captured", "by", "the", "ricci", "tensor", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the weyl tensor", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "components", "start": 65, "end": 75, "i_start": 13, "i_end": 13}, "action": {"text": "-rank tensor that contains the independent", "start": 22, "end": 64, "i_start": 6, "i_end": 12}}], "id": 3647}, {"sent": "the kagome lattice is a representative frustrated magnet suitable for learning more general lessons on the twodimensional systems .", "tokens": ["the", "kagome", "lattice", "is", "a", "representative", "frustrated", "magnet", "suitable", "for", "learning", "more", "general", "lessons", "on", "the", "twodimensional", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the kagome lattice", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "magnet", "start": 50, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "representative", "start": 24, "end": 38, "i_start": 5, "i_end": 5}}], "id": 3648}, {"sent": "to analyze data streams in this way , in we developed an approach to ultrametric embedding of timevarying signals , including biomedical , meteorological , financial and other .", "tokens": ["to", "analyze", "data", "streams", "in", "this", "way", ",", "in", "we", "developed", "an", "approach", "to", "ultrametric", "embedding", "of", "timevarying", "signals", ",", "including", "biomedical", ",", "meteorological", ",", "financial", "and", "other", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 41, "end": 43, "i_start": 9, "i_end": 9}, "verb": {"text": "developed", "start": 44, "end": 53, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 41, "end": 43, "i_start": 9, "i_end": 9}, "action": {"text": "developed", "start": 44, "end": 53, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 41, "end": 43, "i_start": 9, "i_end": 9}, "action": {"text": "approach", "start": 57, "end": 65, "i_start": 12, "i_end": 12}}], "id": 3649}, {"sent": "in recent years , deep learning techniques have achieved profound breakthroughs in many computer vision applications , including the classification of natural and medical images .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "techniques", "have", "achieved", "profound", "breakthroughs", "in", "many", "computer", "vision", "applications", ",", "including", "the", "classification", "of", "natural", "and", "medical", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning techniques", "start": 18, "end": 42, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 43, "end": 56, "i_start": 7, "i_end": 8}}, {"character": {"text": "techniques", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 48, "end": 56, "i_start": 8, "i_end": 8}}, {"character": {"text": "techniques", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "breakthroughs", "start": 66, "end": 79, "i_start": 10, "i_end": 10}}], "id": 3650}, {"sent": "a naked singularity is a singularity which is visible to a far away observer , ie outgoing light rays starting from the singularity terminate on the singularity in the past .", "tokens": ["a", "naked", "singularity", "is", "a", "singularity", "which", "is", "visible", "to", "a", "far", "away", "observer", ",", "ie", "outgoing", "light", "rays", "starting", "from", "the", "singularity", "terminate", "on", "the", "singularity", "in", "the", "past", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a naked singularity", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 3651}, {"sent": "we adopted batch normalization for all networks , because it was also effective for block-wise training .", "tokens": ["we", "adopted", "batch", "normalization", "for", "all", "networks", ",", "because", "it", "was", "also", "effective", "for", "block", "-", "wise", "training", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "adopted", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adopted", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "effective", "start": 70, "end": 79, "i_start": 12, "i_end": 12}, "action": {"text": "because", "start": 50, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "normalization", "start": 17, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "effective", "start": 70, "end": 79, "i_start": 12, "i_end": 12}}], "id": 3652}, {"sent": "in recent years , convolutional neural networks has achieved remarkable results in a wide range of computer vision applications .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "has", "achieved", "remarkable", "results", "in", "a", "wide", "range", "of", "computer", "vision", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "has achieved", "start": 48, "end": 60, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 52, "end": 60, "i_start": 8, "i_end": 8}}], "id": 3653}, {"sent": "then , if the inflaton is a free field , the slice of constant \u03c6 will coincide with the flat slice and with the constant energy density slice even at the end of inflation , i .", "tokens": ["then", ",", "if", "the", "inflaton", "is", "a", "free", "field", ",", "the", "slice", "of", "constant", "\u03c6", "will", "coincide", "with", "the", "flat", "slice", "and", "with", "the", "constant", "energy", "density", "slice", "even", "at", "the", "end", "of", "inflation", ",", "i", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the slice of constant \u03c6", "start": 41, "end": 64, "i_start": 10, "i_end": 14}, "verb": {"text": "will coincide", "start": 65, "end": 78, "i_start": 15, "i_end": 16}}], "id": 3654}, {"sent": "in the next section the mathematical operators of the pso algorithm are presented .", "tokens": ["in", "the", "next", "section", "the", "mathematical", "operators", "of", "the", "pso", "algorithm", "are", "presented", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the mathematical operators of the pso algorithm", "start": 20, "end": 67, "i_start": 4, "i_end": 10}, "verb": {"text": "are presented", "start": 68, "end": 81, "i_start": 11, "i_end": 12}}], "id": 3655}, {"sent": "the surviving properties appear in figure 1 , where an arrow denotes implication .", "tokens": ["the", "surviving", "properties", "appear", "in", "figure", "1", ",", "where", "an", "arrow", "denotes", "implication", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the surviving properties", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "appear", "start": 25, "end": 31, "i_start": 3, "i_end": 3}}, {"character": {"text": "properties", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "surviving", "start": 4, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "arrow", "start": 55, "end": 60, "i_start": 10, "i_end": 10}, "action": {"text": "denotes", "start": 61, "end": 68, "i_start": 11, "i_end": 11}}], "id": 3656}, {"sent": "reconstructing wimp properties in direct detection experiments including galactic dark matter distribution uncertainties .", "tokens": ["reconstructing", "wimp", "properties", "in", "direct", "detection", "experiments", "including", "galactic", "dark", "matter", "distribution", "uncertainties", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3657}, {"sent": "is smaller than the lower limit obtained by the cleo .", "tokens": ["is", "smaller", "than", "the", "lower", "limit", "obtained", "by", "the", "cleo", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3658}, {"sent": "the em algorithm is often used for maximum likelihood estimation in the presence of missing data .", "tokens": ["the", "em", "algorithm", "is", "often", "used", "for", "maximum", "likelihood", "estimation", "in", "the", "presence", "of", "missing", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the em algorithm", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 26, "end": 30, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the em algorithm", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 3659}, {"sent": "zwanziger , covariant quantization of gauge fields without gribov ambiguity , nucl .", "tokens": ["zwanziger", ",", "covariant", "quantization", "of", "gauge", "fields", "without", "gribov", "ambiguity", ",", "nucl", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3660}, {"sent": "the third key technique is to use level sets of the plurisubharmonic measure .", "tokens": ["the", "third", "key", "technique", "is", "to", "use", "level", "sets", "of", "the", "plurisubharmonic", "measure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the third key technique", "start": 0, "end": 23, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 4, "i_end": 4}}], "id": 3661}, {"sent": "on longitudinal and lateral moment hierarchy in turbulence .", "tokens": ["on", "longitudinal", "and", "lateral", "moment", "hierarchy", "in", "turbulence", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3662}, {"sent": "if the mass of the particle is the planck mass , then this into it compton scale becomes the planck scale .", "tokens": ["if", "the", "mass", "of", "the", "particle", "is", "the", "planck", "mass", ",", "then", "this", "into", "it", "compton", "scale", "becomes", "the", "planck", "scale", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "then this into it compton scale", "start": 49, "end": 80, "i_start": 11, "i_end": 16}, "verb": {"text": "becomes", "start": 81, "end": 88, "i_start": 17, "i_end": 17}}], "id": 3663}, {"sent": "the result of these calculations are presented in the following theorem .", "tokens": ["the", "result", "of", "these", "calculations", "are", "presented", "in", "the", "following", "theorem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the result of these calculations", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "are presented", "start": 33, "end": 46, "i_start": 5, "i_end": 6}}], "id": 3664}, {"sent": "imputation is a term that denotes the procedure to replace the missing values by the considering observations .", "tokens": ["imputation", "is", "a", "term", "that", "denotes", "the", "procedure", "to", "replace", "the", "missing", "values", "by", "the", "considering", "observations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "imputation", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "term", "start": 16, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "denotes", "start": 26, "end": 33, "i_start": 5, "i_end": 5}}], "id": 3665}, {"sent": "moreover , if the orbit is a solution to the equation of motion under homogeneous potential , the orbit has a new constant involving momenta .", "tokens": ["moreover", ",", "if", "the", "orbit", "is", "a", "solution", "to", "the", "equation", "of", "motion", "under", "homogeneous", "potential", ",", "the", "orbit", "has", "a", "new", "constant", "involving", "momenta", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "the orbit", "start": 94, "end": 103, "i_start": 17, "i_end": 18}, "verb": {"text": "has", "start": 104, "end": 107, "i_start": 19, "i_end": 19}}, {"character": {"text": "orbit", "start": 18, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "has", "start": 104, "end": 107, "i_start": 19, "i_end": 19}}], "id": 3666}, {"sent": "the data were calibrated using the reduction package common astronomy software applications .", "tokens": ["the", "data", "were", "calibrated", "using", "the", "reduction", "package", "common", "astronomy", "software", "applications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "were calibrated", "start": 9, "end": 24, "i_start": 2, "i_end": 3}}, {"character": {"text": "package", "start": 45, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "reduction", "start": 35, "end": 44, "i_start": 6, "i_end": 6}}], "id": 3667}, {"sent": "for an orbifold , there is a notion of an orbifold embedding , which is more general than the one of sub-orbifolds .", "tokens": ["for", "an", "orbifold", ",", "there", "is", "a", "notion", "of", "an", "orbifold", "embedding", ",", "which", "is", "more", "general", "than", "the", "one", "of", "sub", "-", "orbifolds", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 18, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 5, "i_end": 5}}], "id": 3668}, {"sent": "in this section we present a comparison with the cosserat model for plates proposed and investigated by the second author in .", "tokens": ["in", "this", "section", "we", "present", "a", "comparison", "with", "the", "cosserat", "model", "for", "plates", "proposed", "and", "investigated", "by", "the", "second", "author", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "present", "start": 19, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "present", "start": 19, "end": 26, "i_start": 4, "i_end": 4}}], "id": 3669}, {"sent": "in particular , macroscopic models derived by closing the mass conservation equation with suitable relations for the velocity follow the ideas outlined above , see eg , .", "tokens": ["in", "particular", ",", "macroscopic", "models", "derived", "by", "closing", "the", "mass", "conservation", "equation", "with", "suitable", "relations", "for", "the", "velocity", "follow", "the", "ideas", "outlined", "above", ",", "see", "eg", ",", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "macroscopic models derived by closing the mass conservation equation with suitable relations for the velocity", "start": 16, "end": 125, "i_start": 3, "i_end": 17}, "verb": {"text": "follow", "start": 126, "end": 132, "i_start": 18, "i_end": 18}}, {"character": {"text": "models", "start": 28, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "follow", "start": 126, "end": 132, "i_start": 18, "i_end": 18}}], "id": 3670}, {"sent": "likewise , convolutional neural networks are significantly more efficient at modeling spatial structures , such as on images .", "tokens": ["likewise", ",", "convolutional", "neural", "networks", "are", "significantly", "more", "efficient", "at", "modeling", "spatial", "structures", ",", "such", "as", "on", "images", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 11, "end": 40, "i_start": 2, "i_end": 4}, "verb": {"text": "are", "start": 41, "end": 44, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "modeling", "start": 77, "end": 85, "i_start": 10, "i_end": 10}}], "id": 3671}, {"sent": "in recent years , convolutional neural networkshave demonstrated great efficacy on computer vision tasks such as classification .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networkshave", "demonstrated", "great", "efficacy", "on", "computer", "vision", "tasks", "such", "as", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networkshave", "start": 18, "end": 51, "i_start": 4, "i_end": 6}, "verb": {"text": "demonstrated", "start": 52, "end": 64, "i_start": 7, "i_end": 7}}, {"character": {"text": "networkshave", "start": 39, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "demonstrated", "start": 52, "end": 64, "i_start": 7, "i_end": 7}}], "id": 3672}, {"sent": "let us notice here that , by this point , we have examined all the proper subsets of and the second identity only on p .", "tokens": ["let", "us", "notice", "here", "that", ",", "by", "this", "point", ",", "we", "have", "examined", "all", "the", "proper", "subsets", "of", "and", "the", "second", "identity", "only", "on", "p", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "notice", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "notice", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "examined", "start": 50, "end": 58, "i_start": 12, "i_end": 12}}], "id": 3673}, {"sent": "currently the most prominent approaches include autoregressive models , variational autoencoders , and generative adversarial networks .", "tokens": ["currently", "the", "most", "prominent", "approaches", "include", "autoregressive", "models", ",", "variational", "autoencoders", ",", "and", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most prominent approaches", "start": 10, "end": 39, "i_start": 1, "i_end": 4}, "verb": {"text": "include", "start": 40, "end": 47, "i_start": 5, "i_end": 5}}], "id": 3674}, {"sent": "if degeneracy is a problem , we may simply use a complete set of commuting physical operators that we simultaneously diagonalize .", "tokens": ["if", "degeneracy", "is", "a", "problem", ",", "we", "may", "simply", "use", "a", "complete", "set", "of", "commuting", "physical", "operators", "that", "we", "simultaneously", "diagonalize", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 99, "end": 101, "i_start": 18, "i_end": 18}, "verb": {"text": "use", "start": 43, "end": 46, "i_start": 9, "i_end": 9}}, {"subject": {"text": "we", "start": 29, "end": 31, "i_start": 6, "i_end": 6}, "verb": {"text": "may", "start": 32, "end": 35, "i_start": 7, "i_end": 7}}, {"subject": {"text": "we", "start": 29, "end": 31, "i_start": 6, "i_end": 6}, "verb": {"text": "diagonalize", "start": 117, "end": 128, "i_start": 20, "i_end": 20}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 6, "i_end": 6}, "action": {"text": "use", "start": 43, "end": 46, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 6, "i_end": 6}, "action": {"text": "diagonalize", "start": 117, "end": 128, "i_start": 20, "i_end": 20}}], "id": 3675}, {"sent": "the only prerequisite is a comparison criterion during the training phase by which the success of candidate policies can be evaluated .", "tokens": ["the", "only", "prerequisite", "is", "a", "comparison", "criterion", "during", "the", "training", "phase", "by", "which", "the", "success", "of", "candidate", "policies", "can", "be", "evaluated", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the only prerequisite", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "policies", "start": 108, "end": 116, "i_start": 17, "i_end": 17}, "action": {"text": "success", "start": 87, "end": 94, "i_start": 14, "i_end": 14}}, {"character": {"text": "candidate", "start": 98, "end": 107, "i_start": 16, "i_end": 16}, "action": {"text": "policies", "start": 108, "end": 116, "i_start": 17, "i_end": 17}}], "id": 3676}, {"sent": "if the higgs boson is a composite particle , a proton collider with very high energies may be a unique instrument to search for its constituents .", "tokens": ["if", "the", "higgs", "boson", "is", "a", "composite", "particle", ",", "a", "proton", "collider", "with", "very", "high", "energies", "may", "be", "a", "unique", "instrument", "to", "search", "for", "its", "constituents", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a proton collider with very high energies", "start": 45, "end": 86, "i_start": 9, "i_end": 15}, "verb": {"text": "may be", "start": 87, "end": 93, "i_start": 16, "i_end": 17}}, {"character": {"text": "collider", "start": 54, "end": 62, "i_start": 11, "i_end": 11}, "action": {"text": "search", "start": 117, "end": 123, "i_start": 22, "i_end": 22}}], "id": 3677}, {"sent": "henceforth , there is a need to extend the current areas of quantum chemistry to the realm of , for instance , finite temperature .", "tokens": ["henceforth", ",", "there", "is", "a", "need", "to", "extend", "the", "current", "areas", "of", "quantum", "chemistry", "to", "the", "realm", "of", ",", "for", "instance", ",", "finite", "temperature", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 13, "end": 18, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 3678}, {"sent": "the coefficient 2kf is a decent approximation to the true adjoint is applicable only for string tension .", "tokens": ["the", "coefficient", "2kf", "is", "a", "decent", "approximation", "to", "the", "true", "adjoint", "is", "applicable", "only", "for", "string", "tension", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the coefficient 2kf", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 3679}, {"sent": "similar plots are obtained for other proton angles and clas sectors .", "tokens": ["similar", "plots", "are", "obtained", "for", "other", "proton", "angles", "and", "clas", "sectors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "similar plots", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "are obtained", "start": 14, "end": 26, "i_start": 2, "i_end": 3}}], "id": 3680}, {"sent": "therefore , the crystal consists of weakly coupled chains with strong intrachain bonding .", "tokens": ["therefore", ",", "the", "crystal", "consists", "of", "weakly", "coupled", "chains", "with", "strong", "intrachain", "bonding", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the crystal", "start": 12, "end": 23, "i_start": 2, "i_end": 3}, "verb": {"text": "consists", "start": 24, "end": 32, "i_start": 4, "i_end": 4}}], "id": 3681}, {"sent": "the top-level package scheduler is primarily based on the jobrequestgenerator interface which defines methods for the generation of mjr .", "tokens": ["the", "top", "-", "level", "package", "scheduler", "is", "primarily", "based", "on", "the", "jobrequestgenerator", "interface", "which", "defines", "methods", "for", "the", "generation", "of", "mjr", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the top-level package scheduler", "start": 0, "end": 31, "i_start": 0, "i_end": 5}, "verb": {"text": "based", "start": 45, "end": 50, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the top-level package scheduler", "start": 0, "end": 31, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "interface", "start": 78, "end": 87, "i_start": 12, "i_end": 12}, "action": {"text": "defines", "start": 94, "end": 101, "i_start": 14, "i_end": 14}}], "id": 3682}, {"sent": "deep neural networks have achieved remarkable success in computer vision , speech recognition , and natural language processing systems .", "tokens": ["deep", "neural", "networks", "have", "achieved", "remarkable", "success", "in", "computer", "vision", ",", "speech", "recognition", ",", "and", "natural", "language", "processing", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 46, "end": 53, "i_start": 6, "i_end": 6}}], "id": 3683}, {"sent": "deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification among many others .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "already", "achieved", "tremendous", "success", "on", "a", "variety", "of", "computer", "vision", "tasks", "such", "as", "image", "classification", "among", "many", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "achieved", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 68, "end": 75, "i_start": 8, "i_end": 8}}], "id": 3684}, {"sent": "the mechanism responsible for the formation of the dip at zero momentum is closely related to the one that governs the electron capture into rydberg states .", "tokens": ["the", "mechanism", "responsible", "for", "the", "formation", "of", "the", "dip", "at", "zero", "momentum", "is", "closely", "related", "to", "the", "one", "that", "governs", "the", "electron", "capture", "into", "rydberg", "states", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the mechanism responsible for the formation of the dip at zero momentum", "start": 0, "end": 71, "i_start": 0, "i_end": 11}, "verb": {"text": "related", "start": 83, "end": 90, "i_start": 14, "i_end": 14}}, {"subject": {"text": "the mechanism responsible for the formation of the dip at zero momentum", "start": 0, "end": 71, "i_start": 0, "i_end": 11}, "verb": {"text": "is", "start": 72, "end": 74, "i_start": 12, "i_end": 12}}, {"character": {"text": "mechanism", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "responsible", "start": 14, "end": 25, "i_start": 2, "i_end": 2}}], "id": 3685}, {"sent": "recent advances in deep learning have revolutionized the application of machine learning in areas such as computer vision , speech recognition and natural language processing .", "tokens": ["recent", "advances", "in", "deep", "learning", "have", "revolutionized", "the", "application", "of", "machine", "learning", "in", "areas", "such", "as", "computer", "vision", ",", "speech", "recognition", "and", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent advances in deep learning", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "have revolutionized", "start": 33, "end": 52, "i_start": 5, "i_end": 6}}, {"character": {"text": "advances", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "revolutionized", "start": 38, "end": 52, "i_start": 6, "i_end": 6}}], "id": 3686}, {"sent": "according to a recent study , 390 million dengue infections occur per year worldwide , of which 96 million with clinical symptoms .", "tokens": ["according", "to", "a", "recent", "study", ",", "390", "million", "dengue", "infections", "occur", "per", "year", "worldwide", ",", "of", "which", "96", "million", "with", "clinical", "symptoms", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "390 million dengue infections", "start": 30, "end": 59, "i_start": 6, "i_end": 9}, "verb": {"text": "occur", "start": 60, "end": 65, "i_start": 10, "i_end": 10}}], "id": 3687}, {"sent": "all calculations have been carried out using the projected augmented-wave formalism as implemented in the vienna ab initio simulation package .", "tokens": ["all", "calculations", "have", "been", "carried", "out", "using", "the", "projected", "augmented", "-", "wave", "formalism", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all calculations", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "have been carried out", "start": 17, "end": 38, "i_start": 2, "i_end": 5}}], "id": 3688}, {"sent": "maiorca et al employed this strategy to generate exe embedding attacks .", "tokens": ["maiorca", "et", "al", "employed", "this", "strategy", "to", "generate", "exe", "embedding", "attacks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 8, "end": 13, "i_start": 1, "i_end": 2}, "verb": {"text": "employed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "maiorca", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "employed", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "maiorca", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "generate", "start": 40, "end": 48, "i_start": 7, "i_end": 7}}], "id": 3689}, {"sent": "quantum computing is believed to solve several problems faster than classical computing .", "tokens": ["quantum", "computing", "is", "believed", "to", "solve", "several", "problems", "faster", "than", "classical", "computing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum computing", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is believed", "start": 18, "end": 29, "i_start": 2, "i_end": 3}}, {"character": {"text": "computing", "start": 8, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "solve", "start": 33, "end": 38, "i_start": 5, "i_end": 5}}], "id": 3690}, {"sent": "this thermal state is the well-known unruh effect felt by a uniformly accelerated observer .", "tokens": ["this", "thermal", "state", "is", "the", "well", "-", "known", "unruh", "effect", "felt", "by", "a", "uniformly", "accelerated", "observer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this thermal state", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 3691}, {"sent": "in fact , the analysis of the quantization process has gained a lot of attention in academic research .", "tokens": ["in", "fact", ",", "the", "analysis", "of", "the", "quantization", "process", "has", "gained", "a", "lot", "of", "attention", "in", "academic", "research", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the analysis of the quantization process", "start": 10, "end": 50, "i_start": 3, "i_end": 8}, "verb": {"text": "has gained", "start": 51, "end": 61, "i_start": 9, "i_end": 10}}, {"character": {"text": "analysis", "start": 14, "end": 22, "i_start": 4, "i_end": 4}, "action": {"text": "gained", "start": 55, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "research", "start": 93, "end": 101, "i_start": 17, "i_end": 17}, "action": {"text": "attention", "start": 71, "end": 80, "i_start": 14, "i_end": 14}}], "id": 3692}, {"sent": "the design of compact gks based on the cell averaged and cell interface values has been conducted .", "tokens": ["the", "design", "of", "compact", "gks", "based", "on", "the", "cell", "averaged", "and", "cell", "interface", "values", "has", "been", "conducted", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the design of compact gks based on the cell", "start": 0, "end": 43, "i_start": 0, "i_end": 8}, "verb": {"text": "averaged", "start": 44, "end": 52, "i_start": 9, "i_end": 9}}, {"subject": {"text": "cell interface values", "start": 57, "end": 78, "i_start": 11, "i_end": 13}, "verb": {"text": "conducted", "start": 88, "end": 97, "i_start": 16, "i_end": 16}}], "id": 3693}, {"sent": "replacing the anti-quark by the diquark , pentaquarks can be related to dibaryons composed of three diquarks .", "tokens": ["replacing", "the", "anti", "-", "quark", "by", "the", "diquark", ",", "pentaquarks", "can", "be", "related", "to", "dibaryons", "composed", "of", "three", "diquarks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "pentaquarks", "start": 42, "end": 53, "i_start": 9, "i_end": 9}, "verb": {"text": "can be related", "start": 54, "end": 68, "i_start": 10, "i_end": 12}}], "id": 3694}, {"sent": "neutrino oscillations in cosmological plasma .", "tokens": ["neutrino", "oscillations", "in", "cosmological", "plasma", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3695}, {"sent": "for the ls estimator and its derivative , we also derive the pointwise asymptotic distribution .", "tokens": ["for", "the", "ls", "estimator", "and", "its", "derivative", ",", "we", "also", "derive", "the", "pointwise", "asymptotic", "distribution", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 42, "end": 44, "i_start": 8, "i_end": 8}, "verb": {"text": "derive", "start": 50, "end": 56, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 42, "end": 44, "i_start": 8, "i_end": 8}, "action": {"text": "derive", "start": 50, "end": 56, "i_start": 10, "i_end": 10}}], "id": 3696}, {"sent": "any associative algebra is right-symmetric .", "tokens": ["any", "associative", "algebra", "is", "right", "-", "symmetric", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "any associative algebra", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "algebra", "start": 16, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "associative", "start": 4, "end": 15, "i_start": 1, "i_end": 1}}], "id": 3697}, {"sent": "a possibility that has not been considered before is that the repulsion is eliminated through the presence in the interior of the q-ball of fermions with charge opposite to that of the scalar condensate .", "tokens": ["a", "possibility", "that", "has", "not", "been", "considered", "before", "is", "that", "the", "repulsion", "is", "eliminated", "through", "the", "presence", "in", "the", "interior", "of", "the", "q", "-", "ball", "of", "fermions", "with", "charge", "opposite", "to", "that", "of", "the", "scalar", "condensate", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a possibility that has not been considered before", "start": 0, "end": 49, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 50, "end": 52, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the repulsion", "start": 58, "end": 71, "i_start": 10, "i_end": 11}, "verb": {"text": "eliminated", "start": 75, "end": 85, "i_start": 13, "i_end": 13}}], "id": 3698}, {"sent": "zur nedden , for the hera-b collaboration , these proceedings .", "tokens": ["zur", "nedden", ",", "for", "the", "hera", "-", "b", "collaboration", ",", "these", "proceedings", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3699}, {"sent": "which is the general term of the sequence a000108 in the on-line encyclopedia of integer sequences .", "tokens": ["which", "is", "the", "general", "term", "of", "the", "sequence", "a000108", "in", "the", "on", "-", "line", "encyclopedia", "of", "integer", "sequences", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "which", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}], "id": 3700}, {"sent": "gravity is the driving force that at the end of the life of massive stars overcomes the pressure forces and causes the collapse of the stellar core .", "tokens": ["gravity", "is", "the", "driving", "force", "that", "at", "the", "end", "of", "the", "life", "of", "massive", "stars", "overcomes", "the", "pressure", "forces", "and", "causes", "the", "collapse", "of", "the", "stellar", "core", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "gravity", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "force", "start": 23, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "driving", "start": 15, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "force", "start": 23, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "overcomes", "start": 74, "end": 83, "i_start": 15, "i_end": 15}}, {"character": {"text": "force", "start": 23, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "causes", "start": 108, "end": 114, "i_start": 20, "i_end": 20}}], "id": 3701}, {"sent": "convolutional neural networks have achieved state-of-the-art accuracy in computer vision tasks such as image recognition .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "accuracy", "in", "computer", "vision", "tasks", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}], "id": 3702}, {"sent": "however , these methodologies are an interpolation procedure .", "tokens": ["however", ",", "these", "methodologies", "are", "an", "interpolation", "procedure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these methodologies", "start": 10, "end": 29, "i_start": 2, "i_end": 3}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 4, "i_end": 4}}], "id": 3703}, {"sent": "the projector-augmented wave method was employed in this study , and for the exchange-correlation potential , the generalized gradient approximation with the perdew , burke , and ernzerhof functional was used .", "tokens": ["the", "projector", "-", "augmented", "wave", "method", "was", "employed", "in", "this", "study", ",", "and", "for", "the", "exchange", "-", "correlation", "potential", ",", "the", "generalized", "gradient", "approximation", "with", "the", "perdew", ",", "burke", ",", "and", "ernzerhof", "functional", "was", "used", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the projector-augmented wave method", "start": 0, "end": 35, "i_start": 0, "i_end": 5}, "verb": {"text": "was employed", "start": 36, "end": 48, "i_start": 6, "i_end": 7}}, {"subject": {"text": "the generalized gradient approximation with the perdew", "start": 110, "end": 164, "i_start": 20, "i_end": 26}, "verb": {"text": "used", "start": 204, "end": 208, "i_start": 34, "i_end": 34}}, {"character": {"text": "projector", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "augmented", "start": 14, "end": 23, "i_start": 3, "i_end": 3}}], "id": 3704}, {"sent": "an operad consists of operations shaped like with many inputs and one output .", "tokens": ["an", "operad", "consists", "of", "operations", "shaped", "like", "with", "many", "inputs", "and", "one", "output", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an operad", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 10, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3705}, {"sent": "recently , deep neural networks have attracted enormous research attentions , due to their prominent performance comparing to various state of the art approaches in pattern recognition , computer vision , and speech recognition .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "attracted", "enormous", "research", "attentions", ",", "due", "to", "their", "prominent", "performance", "comparing", "to", "various", "state", "of", "the", "art", "approaches", "in", "pattern", "recognition", ",", "computer", "vision", ",", "and", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have attracted", "start": 32, "end": 46, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "attracted", "start": 37, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "performance", "start": 101, "end": 112, "i_start": 15, "i_end": 15}}], "id": 3706}, {"sent": "duality is a mapping between two different mathematical descriptions of a same physical phenomenon .", "tokens": ["duality", "is", "a", "mapping", "between", "two", "different", "mathematical", "descriptions", "of", "a", "same", "physical", "phenomenon", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "duality", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}], "id": 3707}, {"sent": "now we give the definition of non-associative biseminear-rings .", "tokens": ["now", "we", "give", "the", "definition", "of", "non", "-", "associative", "biseminear", "-", "rings", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "give", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "definition", "start": 16, "end": 26, "i_start": 4, "i_end": 4}}], "id": 3708}, {"sent": "thermodynamics is the discipline that describes the exchange processes of energy and matter that occur at the molecular and cellular level .", "tokens": ["thermodynamics", "is", "the", "discipline", "that", "describes", "the", "exchange", "processes", "of", "energy", "and", "matter", "that", "occur", "at", "the", "molecular", "and", "cellular", "level", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "thermodynamics", "start": 0, "end": 14, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 1, "i_end": 1}}, {"character": {"text": "discipline", "start": 22, "end": 32, "i_start": 3, "i_end": 3}, "action": {"text": "describes", "start": 38, "end": 47, "i_start": 5, "i_end": 5}}], "id": 3709}, {"sent": "deep convolutional neural networks have recently played a transformative role in advancing artificial intelligence .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "recently", "played", "a", "transformative", "role", "in", "advancing", "artificial", "intelligence", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "played", "start": 49, "end": 55, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "role", "start": 73, "end": 77, "i_start": 9, "i_end": 9}, "action": {"text": "transformative", "start": 58, "end": 72, "i_start": 8, "i_end": 8}}], "id": 3710}, {"sent": "the difference between the maximum and the minimum energy is called a torsional barrier .", "tokens": ["the", "difference", "between", "the", "maximum", "and", "the", "minimum", "energy", "is", "called", "a", "torsional", "barrier", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the difference between the maximum and the minimum energy", "start": 0, "end": 57, "i_start": 0, "i_end": 8}, "verb": {"text": "is called", "start": 58, "end": 67, "i_start": 9, "i_end": 10}}], "id": 3711}, {"sent": "in figure 6 we apply the dft cca technique on the imagenet resnet .", "tokens": ["in", "figure", "6", "we", "apply", "the", "dft", "cca", "technique", "on", "the", "imagenet", "resnet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 12, "end": 14, "i_start": 3, "i_end": 3}, "verb": {"text": "apply", "start": 15, "end": 20, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 12, "end": 14, "i_start": 3, "i_end": 3}, "action": {"text": "apply", "start": 15, "end": 20, "i_start": 4, "i_end": 4}}], "id": 3712}, {"sent": "we follow similar experimental protocols as dhn is an image recognition , segmentation , and captioning dataset .", "tokens": ["we", "follow", "similar", "experimental", "protocols", "as", "dhn", "is", "an", "image", "recognition", ",", "segmentation", ",", "and", "captioning", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "dataset", "start": 104, "end": 111, "i_start": 16, "i_end": 16}, "action": {"text": "recognition", "start": 60, "end": 71, "i_start": 10, "i_end": 10}}], "id": 3713}, {"sent": "machine learning models , such as deep neural networks , have been remarkably successful in performing many tasks .", "tokens": ["machine", "learning", "models", ",", "such", "as", "deep", "neural", "networks", ",", "have", "been", "remarkably", "successful", "in", "performing", "many", "tasks", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "machine learning models", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 57, "end": 66, "i_start": 10, "i_end": 11}}, {"character": {"text": "models", "start": 17, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 78, "end": 88, "i_start": 13, "i_end": 13}}, {"character": {"text": "models", "start": 17, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "learning", "start": 8, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "models", "start": 17, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "performing", "start": 92, "end": 102, "i_start": 15, "i_end": 15}}], "id": 3714}, {"sent": "then allen gave a simpler proof for large n without using the regularity lemma .", "tokens": ["then", "allen", "gave", "a", "simpler", "proof", "for", "large", "n", "without", "using", "the", "regularity", "lemma", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "allen", "start": 5, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "gave", "start": 11, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "allen", "start": 5, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "gave", "start": 11, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "allen", "start": 5, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "using", "start": 52, "end": 57, "i_start": 10, "i_end": 10}}], "id": 3715}, {"sent": "convolutional neural networks can be used to better model the spatial relationships between voxels .", "tokens": ["convolutional", "neural", "networks", "can", "be", "used", "to", "better", "model", "the", "spatial", "relationships", "between", "voxels", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "can be used", "start": 30, "end": 41, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "model", "start": 52, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "voxels", "start": 92, "end": 98, "i_start": 13, "i_end": 13}, "action": {"text": "relationships", "start": 70, "end": 83, "i_start": 11, "i_end": 11}}], "id": 3716}, {"sent": "in , the authors studied the resource allocation algorithm design for energy-efficient communication in multi-cell orthogonal frequency division multiple access systems .", "tokens": ["in", ",", "the", "authors", "studied", "the", "resource", "allocation", "algorithm", "design", "for", "energy", "-", "efficient", "communication", "in", "multi", "-", "cell", "orthogonal", "frequency", "division", "multiple", "access", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 5, "end": 16, "i_start": 2, "i_end": 3}, "verb": {"text": "studied", "start": 17, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "systems", "start": 161, "end": 168, "i_start": 24, "i_end": 24}, "action": {"text": "communication", "start": 87, "end": 100, "i_start": 14, "i_end": 14}}], "id": 3717}, {"sent": "as a common property , the node degree of many real-world large networks including social networks follows a power-law distribution .", "tokens": ["as", "a", "common", "property", ",", "the", "node", "degree", "of", "many", "real", "-", "world", "large", "networks", "including", "social", "networks", "follows", "a", "power", "-", "law", "distribution", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the node degree of many real-world large networks including social networks", "start": 23, "end": 98, "i_start": 5, "i_end": 17}, "verb": {"text": "follows", "start": 99, "end": 106, "i_start": 18, "i_end": 18}}], "id": 3718}, {"sent": "recently , deep convolutional neural networks have achieved great successes in computer vision topics such as image classification .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "achieved", "great", "successes", "in", "computer", "vision", "topics", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "successes", "start": 66, "end": 75, "i_start": 9, "i_end": 9}}], "id": 3719}, {"sent": "the quantum dot is a small cylindrical structure located in the i layer between n and p semiconductors .", "tokens": ["the", "quantum", "dot", "is", "a", "small", "cylindrical", "structure", "located", "in", "the", "i", "layer", "between", "n", "and", "p", "semiconductors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quantum dot", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 3720}, {"sent": "current-driven magnetic switching in manganite trilayer junctions .", "tokens": ["current", "-", "driven", "magnetic", "switching", "in", "manganite", "trilayer", "junctions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "current", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "driven", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}], "id": 3721}, {"sent": "time frequency analysis based on different principals has attracted a lot of attention in the field and many variations are available .", "tokens": ["time", "frequency", "analysis", "based", "on", "different", "principals", "has", "attracted", "a", "lot", "of", "attention", "in", "the", "field", "and", "many", "variations", "are", "available", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "time frequency analysis based on different principals", "start": 0, "end": 53, "i_start": 0, "i_end": 6}, "verb": {"text": "has attracted", "start": 54, "end": 67, "i_start": 7, "i_end": 8}}, {"character": {"text": "analysis", "start": 15, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "attracted", "start": 58, "end": 67, "i_start": 8, "i_end": 8}}], "id": 3722}, {"sent": "deep neural networks are widely used for many applications including object recognition .", "tokens": ["deep", "neural", "networks", "are", "widely", "used", "for", "many", "applications", "including", "object", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 32, "end": 36, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3723}, {"sent": "the first one has the two settings on and off and is the standard type for all simple switches .", "tokens": ["the", "first", "one", "has", "the", "two", "settings", "on", "and", "off", "and", "is", "the", "standard", "type", "for", "all", "simple", "switches", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the first one", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "has", "start": 14, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "one", "start": 10, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "has", "start": 14, "end": 17, "i_start": 3, "i_end": 3}}], "id": 3724}, {"sent": "whilst this is a useful approximation for studying cosmological dynamics at late-time , it is impossible to extrapolate these simple forms of wde to early times , unless some ad hoc mechanisms are invoked .", "tokens": ["whilst", "this", "is", "a", "useful", "approximation", "for", "studying", "cosmological", "dynamics", "at", "late", "-", "time", ",", "it", "is", "impossible", "to", "extrapolate", "these", "simple", "forms", "of", "wde", "to", "early", "times", ",", "unless", "some", "ad", "hoc", "mechanisms", "are", "invoked", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 88, "end": 90, "i_start": 15, "i_end": 15}, "verb": {"text": "is", "start": 91, "end": 93, "i_start": 16, "i_end": 16}}], "id": 3725}, {"sent": "deep neural networks have been shown useful for many computer vision tasks , but they are still limited by requiring large-scale well-annotated datasets for network training .", "tokens": ["deep", "neural", "networks", "have", "been", "shown", "useful", "for", "many", "computer", "vision", "tasks", ",", "but", "they", "are", "still", "limited", "by", "requiring", "large", "-", "scale", "well", "-", "annotated", "datasets", "for", "network", "training", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been shown", "start": 21, "end": 36, "i_start": 3, "i_end": 5}}, {"subject": {"text": "they", "start": 81, "end": 85, "i_start": 14, "i_end": 14}, "verb": {"text": "limited", "start": 96, "end": 103, "i_start": 17, "i_end": 17}}], "id": 3726}, {"sent": "path loss was calculated based on the free space path loss model , with a tr separation distance equal to the total propagated ray length .", "tokens": ["path", "loss", "was", "calculated", "based", "on", "the", "free", "space", "path", "loss", "model", ",", "with", "a", "tr", "separation", "distance", "equal", "to", "the", "total", "propagated", "ray", "length", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "path loss", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "was calculated", "start": 10, "end": 24, "i_start": 2, "i_end": 3}}, {"character": {"text": "ray", "start": 127, "end": 130, "i_start": 23, "i_end": 23}, "action": {"text": "propagated", "start": 116, "end": 126, "i_start": 22, "i_end": 22}}], "id": 3727}, {"sent": "roughly , a quantum network consists of a set of machines .", "tokens": ["roughly", ",", "a", "quantum", "network", "consists", "of", "a", "set", "of", "machines", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a quantum network", "start": 10, "end": 27, "i_start": 2, "i_end": 4}, "verb": {"text": "consists", "start": 28, "end": 36, "i_start": 5, "i_end": 5}}], "id": 3728}, {"sent": "sbft is deterministic so lacks liveness in the asynchronous mode , flp .", "tokens": ["sbft", "is", "deterministic", "so", "lacks", "liveness", "in", "the", "asynchronous", "mode", ",", "flp", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "sbft", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3729}, {"sent": "the size of each patch we have compared the proposed method based image cs recovery against four other competing approaches including bm3d method .", "tokens": ["the", "size", "of", "each", "patch", "we", "have", "compared", "the", "proposed", "method", "based", "image", "cs", "recovery", "against", "four", "other", "competing", "approaches", "including", "bm3d", "method", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "action": {"text": "compared", "start": 31, "end": 39, "i_start": 7, "i_end": 7}}, {"character": {"text": "four other competing approaches", "start": 92, "end": 123, "i_start": 16, "i_end": 19}, "action": {"text": "competing", "start": 103, "end": 112, "i_start": 18, "i_end": 18}}], "id": 3730}, {"sent": "as shown in , the sources and sinks in the species momentum equations that arise from ionization and recombination reactions can be evaluated by taking the first moments of the relevant collision operators .", "tokens": ["as", "shown", "in", ",", "the", "sources", "and", "sinks", "in", "the", "species", "momentum", "equations", "that", "arise", "from", "ionization", "and", "recombination", "reactions", "can", "be", "evaluated", "by", "taking", "the", "first", "moments", "of", "the", "relevant", "collision", "operators", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the sources and sinks in the species momentum equations that arise from ionization and recombination reactions", "start": 14, "end": 124, "i_start": 4, "i_end": 19}, "verb": {"text": "can be evaluated", "start": 125, "end": 141, "i_start": 20, "i_end": 22}}, {"character": {"text": "reactions", "start": 115, "end": 124, "i_start": 19, "i_end": 19}, "action": {"text": "arise", "start": 75, "end": 80, "i_start": 14, "i_end": 14}}], "id": 3731}, {"sent": "the blockchain and smart contract enabled security mechanism for applications has been a hot research topic and some efforts have been reported recently , for example , smart surveillance system .", "tokens": ["the", "blockchain", "and", "smart", "contract", "enabled", "security", "mechanism", "for", "applications", "has", "been", "a", "hot", "research", "topic", "and", "some", "efforts", "have", "been", "reported", "recently", ",", "for", "example", ",", "smart", "surveillance", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the blockchain and smart contract", "start": 0, "end": 33, "i_start": 0, "i_end": 4}, "verb": {"text": "enabled", "start": 34, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "blockchain", "start": 4, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "enabled", "start": 34, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "contract", "start": 25, "end": 33, "i_start": 4, "i_end": 4}, "action": {"text": "enabled", "start": 34, "end": 41, "i_start": 5, "i_end": 5}}], "id": 3732}, {"sent": "deep learning is currently the state of the art machine learning technique in many application areas such as computer vision or natural language processing .", "tokens": ["deep", "learning", "is", "currently", "the", "state", "of", "the", "art", "machine", "learning", "technique", "in", "many", "application", "areas", "such", "as", "computer", "vision", "or", "natural", "language", "processing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 3733}, {"sent": "this confluence has enabled the development of api mining methods , so far api mining tools have not yet gained wide-spread adoption in development environments such as eclipse and visual studio .", "tokens": ["this", "confluence", "has", "enabled", "the", "development", "of", "api", "mining", "methods", ",", "so", "far", "api", "mining", "tools", "have", "not", "yet", "gained", "wide", "-", "spread", "adoption", "in", "development", "environments", "such", "as", "eclipse", "and", "visual", "studio", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this confluence", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "has enabled", "start": 16, "end": 27, "i_start": 2, "i_end": 3}}, {"subject": {"text": "api mining tools", "start": 75, "end": 91, "i_start": 13, "i_end": 15}, "verb": {"text": "gained", "start": 105, "end": 111, "i_start": 19, "i_end": 19}}, {"character": {"text": "confluence", "start": 5, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "enabled", "start": 20, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "tools", "start": 86, "end": 91, "i_start": 15, "i_end": 15}, "action": {"text": "not yet gained", "start": 97, "end": 111, "i_start": 17, "i_end": 19}}, {"character": {"text": "environments", "start": 148, "end": 160, "i_start": 26, "i_end": 26}, "action": {"text": "adoption", "start": 124, "end": 132, "i_start": 23, "i_end": 23}}], "id": 3734}, {"sent": "a three-step resource allocation strategy for maximizing the network throughput has been proposed in , which guarantees the qos requirements of the cellular users as well as d2d users , along with optimal power control .", "tokens": ["a", "three", "-", "step", "resource", "allocation", "strategy", "for", "maximizing", "the", "network", "throughput", "has", "been", "proposed", "in", ",", "which", "guarantees", "the", "qos", "requirements", "of", "the", "cellular", "users", "as", "well", "as", "d2d", "users", ",", "along", "with", "optimal", "power", "control", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "a three-step resource allocation strategy for maximizing the network throughput has been proposed in , which guarantees the qos requirements of the cellular users as well as", "start": 0, "end": 173, "i_start": 0, "i_end": 28}, "verb": {"text": "has been proposed", "start": 80, "end": 97, "i_start": 12, "i_end": 14}}, {"character": {"text": "strategy", "start": 33, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "guarantees", "start": 109, "end": 119, "i_start": 18, "i_end": 18}}, {"character": {"text": "d2d", "start": 174, "end": 177, "i_start": 29, "i_end": 29}, "action": {"text": "requirements", "start": 128, "end": 140, "i_start": 21, "i_end": 21}}], "id": 3735}, {"sent": "deep neural networks have shown great success in computer vision and natural language processing tasks .", "tokens": ["deep", "neural", "networks", "have", "shown", "great", "success", "in", "computer", "vision", "and", "natural", "language", "processing", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 38, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "processing", "start": 86, "end": 96, "i_start": 13, "i_end": 13}}], "id": 3736}, {"sent": "a uav based mobile cloud computing system is proposed in , where uavs , using noma transmission , offer computation offloading opportunities to mobile stations with limited local processing capabilities .", "tokens": ["a", "uav", "based", "mobile", "cloud", "computing", "system", "is", "proposed", "in", ",", "where", "uavs", ",", "using", "noma", "transmission", ",", "offer", "computation", "offloading", "opportunities", "to", "mobile", "stations", "with", "limited", "local", "processing", "capabilities", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a uav based mobile cloud computing system", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "is proposed", "start": 42, "end": 53, "i_start": 7, "i_end": 8}}, {"subject": {"text": "uavs", "start": 65, "end": 69, "i_start": 12, "i_end": 12}, "verb": {"text": "offer", "start": 98, "end": 103, "i_start": 18, "i_end": 18}}], "id": 3737}, {"sent": "the higgs is a pgb of a spontaneously broken global symmetry , and it is protected against divergent quantum corrections at one loop , including logarithmic divergences .", "tokens": ["the", "higgs", "is", "a", "pgb", "of", "a", "spontaneously", "broken", "global", "symmetry", ",", "and", "it", "is", "protected", "against", "divergent", "quantum", "corrections", "at", "one", "loop", ",", "including", "logarithmic", "divergences", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the higgs", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}, {"subject": {"text": "it", "start": 67, "end": 69, "i_start": 13, "i_end": 13}, "verb": {"text": "protected", "start": 73, "end": 82, "i_start": 15, "i_end": 15}}], "id": 3738}, {"sent": "component-wise powers of codes are also studied in the context of secure multi-party computation .", "tokens": ["component", "-", "wise", "powers", "of", "codes", "are", "also", "studied", "in", "the", "context", "of", "secure", "multi", "-", "party", "computation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "component-wise powers of codes", "start": 0, "end": 30, "i_start": 0, "i_end": 5}, "verb": {"text": "studied", "start": 40, "end": 47, "i_start": 8, "i_end": 8}}, {"subject": {"text": "component-wise powers of codes", "start": 0, "end": 30, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 31, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "party", "start": 79, "end": 84, "i_start": 16, "i_end": 16}, "action": {"text": "computation", "start": 85, "end": 96, "i_start": 17, "i_end": 17}}], "id": 3739}, {"sent": "we note that signatures of lifshitz transitions were recently found in tetralayer graphene at zero magnetic field , but that no direct compressibility measurements of lifshitz transitions have been reported .", "tokens": ["we", "note", "that", "signatures", "of", "lifshitz", "transitions", "were", "recently", "found", "in", "tetralayer", "graphene", "at", "zero", "magnetic", "field", ",", "but", "that", "no", "direct", "compressibility", "measurements", "of", "lifshitz", "transitions", "have", "been", "reported", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "note", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "signatures of lifshitz transitions", "start": 13, "end": 47, "i_start": 3, "i_end": 6}, "verb": {"text": "found", "start": 62, "end": 67, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "note", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3740}, {"sent": "in recent years , deep learning methods have shown great success with many computer vision tasks such as image classification .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "methods", "have", "shown", "great", "success", "with", "many", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning methods", "start": 18, "end": 39, "i_start": 4, "i_end": 6}, "verb": {"text": "have shown", "start": 40, "end": 50, "i_start": 7, "i_end": 8}}, {"character": {"text": "methods", "start": 32, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "shown", "start": 45, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "methods", "start": 32, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 57, "end": 64, "i_start": 10, "i_end": 10}}], "id": 3741}, {"sent": "after the pivotal work of krizhevsky et al , deep convolutional neural networks quickly became the dominant tool in computer vision , establishing new state-ofthe-art results for a large variety of tasks , such as human pose estimation .", "tokens": ["after", "the", "pivotal", "work", "of", "krizhevsky", "et", "al", ",", "deep", "convolutional", "neural", "networks", "quickly", "became", "the", "dominant", "tool", "in", "computer", "vision", ",", "establishing", "new", "state", "-", "ofthe", "-", "art", "results", "for", "a", "large", "variety", "of", "tasks", ",", "such", "as", "human", "pose", "estimation", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 45, "end": 79, "i_start": 9, "i_end": 12}, "verb": {"text": "became", "start": 88, "end": 94, "i_start": 14, "i_end": 14}}, {"character": {"text": "tool", "start": 108, "end": 112, "i_start": 17, "i_end": 17}, "action": {"text": "dominant", "start": 99, "end": 107, "i_start": 16, "i_end": 16}}, {"character": {"text": "networks", "start": 71, "end": 79, "i_start": 12, "i_end": 12}, "action": {"text": "establishing", "start": 134, "end": 146, "i_start": 22, "i_end": 22}}, {"character": {"text": "krizhevsky", "start": 26, "end": 36, "i_start": 5, "i_end": 5}, "action": {"text": "work", "start": 18, "end": 22, "i_start": 3, "i_end": 3}}], "id": 3742}, {"sent": "we also exploit dropout on the output of the last layer for further regularization .", "tokens": ["we", "also", "exploit", "dropout", "on", "the", "output", "of", "the", "last", "layer", "for", "further", "regularization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "exploit", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "exploit", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}], "id": 3743}, {"sent": "the field equations are evolved in the generalized harmonic formulation , using the code described in .", "tokens": ["the", "field", "equations", "are", "evolved", "in", "the", "generalized", "harmonic", "formulation", ",", "using", "the", "code", "described", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the field equations", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "are evolved", "start": 20, "end": 31, "i_start": 3, "i_end": 4}}], "id": 3744}, {"sent": "exploiting channel reciprocity in the adopted time-division duplex mode , we can divide each coherence block of \u03c4 seconds into two phases , namely ce and information transfer .", "tokens": ["exploiting", "channel", "reciprocity", "in", "the", "adopted", "time", "-", "division", "duplex", "mode", ",", "we", "can", "divide", "each", "coherence", "block", "of", "\u03c4", "seconds", "into", "two", "phases", ",", "namely", "ce", "and", "information", "transfer", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 74, "end": 76, "i_start": 12, "i_end": 12}, "verb": {"text": "can divide", "start": 77, "end": 87, "i_start": 13, "i_end": 14}}, {"character": {"text": "we", "start": 74, "end": 76, "i_start": 12, "i_end": 12}, "action": {"text": "divide", "start": 81, "end": 87, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 74, "end": 76, "i_start": 12, "i_end": 12}, "action": {"text": "exploiting", "start": 0, "end": 10, "i_start": 0, "i_end": 0}}], "id": 3745}, {"sent": "mania et al proposed a perturbed iterate framework to analyze the asynchronous parallel algorithms of sgd , scd and sparse svrg .", "tokens": ["mania", "et", "al", "proposed", "a", "perturbed", "iterate", "framework", "to", "analyze", "the", "asynchronous", "parallel", "algorithms", "of", "sgd", ",", "scd", "and", "sparse", "svrg", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "mania et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "mania", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}], "id": 3746}, {"sent": "tissue microarray technology was first described by wan , fortuna and furmanski and substantially improved by kononen et al as a high-throughput technology for the assessment of protein expression in tissue samples .", "tokens": ["tissue", "microarray", "technology", "was", "first", "described", "by", "wan", ",", "fortuna", "and", "furmanski", "and", "substantially", "improved", "by", "kononen", "et", "al", "as", "a", "high", "-", "throughput", "technology", "for", "the", "assessment", "of", "protein", "expression", "in", "tissue", "samples", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "tissue microarray technology", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "described", "start": 39, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "tissue microarray technology", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "was", "start": 29, "end": 32, "i_start": 3, "i_end": 3}}, {"subject": {"text": "tissue microarray technology", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "improved", "start": 98, "end": 106, "i_start": 14, "i_end": 14}}, {"character": {"text": "wan", "start": 52, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "described", "start": 39, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "fortuna", "start": 58, "end": 65, "i_start": 9, "i_end": 9}, "action": {"text": "described", "start": 39, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "furmanski", "start": 70, "end": 79, "i_start": 11, "i_end": 11}, "action": {"text": "described", "start": 39, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "kononen", "start": 110, "end": 117, "i_start": 16, "i_end": 16}, "action": {"text": "improved", "start": 98, "end": 106, "i_start": 14, "i_end": 14}}], "id": 3747}, {"sent": "dropout is employed on both word embedding and latent variable layers , with rates selected from on the validation set .", "tokens": ["dropout", "is", "employed", "on", "both", "word", "embedding", "and", "latent", "variable", "layers", ",", "with", "rates", "selected", "from", "on", "the", "validation", "set", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dropout", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is employed", "start": 8, "end": 19, "i_start": 1, "i_end": 2}}], "id": 3748}, {"sent": "we know that corson compact spaces are characterized as compact spaces with a full r-skeleton .", "tokens": ["we", "know", "that", "corson", "compact", "spaces", "are", "characterized", "as", "compact", "spaces", "with", "a", "full", "r", "-", "skeleton", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "know", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "corson compact spaces", "start": 13, "end": 34, "i_start": 3, "i_end": 5}, "verb": {"text": "characterized", "start": 39, "end": 52, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "know", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3749}, {"sent": "solecki proved , building on work of herwig and lascar , the following result .", "tokens": ["solecki", "proved", ",", "building", "on", "work", "of", "herwig", "and", "lascar", ",", "the", "following", "result", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "solecki", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "proved", "start": 8, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "solecki", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "proved", "start": 8, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "herwig", "start": 37, "end": 43, "i_start": 7, "i_end": 7}, "action": {"text": "work", "start": 29, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "lascar", "start": 48, "end": 54, "i_start": 9, "i_end": 9}, "action": {"text": "work", "start": 29, "end": 33, "i_start": 5, "i_end": 5}}], "id": 3750}, {"sent": "comparing with the original sat theorem , the homomorphism version of sat works on a more abstract level .", "tokens": ["comparing", "with", "the", "original", "sat", "theorem", ",", "the", "homomorphism", "version", "of", "sat", "works", "on", "a", "more", "abstract", "level", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the homomorphism version of sat", "start": 42, "end": 73, "i_start": 7, "i_end": 11}, "verb": {"text": "works", "start": 74, "end": 79, "i_start": 12, "i_end": 12}}, {"character": {"text": "theorem", "start": 32, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "works", "start": 74, "end": 79, "i_start": 12, "i_end": 12}}], "id": 3751}, {"sent": "there are many weakly supervised object detection methods proposed in literature , among which cnn based methods show great promise recently .", "tokens": ["there", "are", "many", "weakly", "supervised", "object", "detection", "methods", "proposed", "in", "literature", ",", "among", "which", "cnn", "based", "methods", "show", "great", "promise", "recently", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 6, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "methods", "start": 105, "end": 112, "i_start": 16, "i_end": 16}, "action": {"text": "show", "start": 113, "end": 117, "i_start": 17, "i_end": 17}}], "id": 3752}, {"sent": "the complexity level for ilfs and eifs is based on the number of rets and dets .", "tokens": ["the", "complexity", "level", "for", "ilfs", "and", "eifs", "is", "based", "on", "the", "number", "of", "rets", "and", "dets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the complexity level for ilfs and eifs", "start": 0, "end": 38, "i_start": 0, "i_end": 6}, "verb": {"text": "is based", "start": 39, "end": 47, "i_start": 7, "i_end": 8}}], "id": 3753}, {"sent": "show that \u00b5 is quasi-invariant iff the collection of null sets is h-invariant .", "tokens": ["show", "that", "\u00b5", "is", "quasi", "-", "invariant", "iff", "the", "collection", "of", "null", "sets", "is", "h", "-", "invariant", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3754}, {"sent": "in contrast to the conventional mimo systems employing a small number of antennas , pilot overhead required for channel estimation in massive mimo systems can be overwhelming .", "tokens": ["in", "contrast", "to", "the", "conventional", "mimo", "systems", "employing", "a", "small", "number", "of", "antennas", ",", "pilot", "overhead", "required", "for", "channel", "estimation", "in", "massive", "mimo", "systems", "can", "be", "overwhelming", "."], "score": [0, 1, 1, 1, 0], "labels": [{"subject": {"text": "pilot overhead required for channel estimation in massive mimo systems", "start": 84, "end": 154, "i_start": 14, "i_end": 23}, "verb": {"text": "can be", "start": 155, "end": 161, "i_start": 24, "i_end": 25}}, {"character": {"text": "overhead", "start": 90, "end": 98, "i_start": 15, "i_end": 15}, "action": {"text": "overwhelming", "start": 162, "end": 174, "i_start": 26, "i_end": 26}}, {"character": {"text": "estimation", "start": 120, "end": 130, "i_start": 19, "i_end": 19}, "action": {"text": "required", "start": 99, "end": 107, "i_start": 16, "i_end": 16}}, {"character": {"text": "systems", "start": 147, "end": 154, "i_start": 23, "i_end": 23}, "action": {"text": "employing", "start": 45, "end": 54, "i_start": 7, "i_end": 7}}], "id": 3755}, {"sent": "perhaps it might be interesting to refer where the authors argue that instead of the pure-tetrad formalism for the f -gravity , if in addition , the spin connection is allowed , then the problem with local lorentz invariance might be resolved .", "tokens": ["perhaps", "it", "might", "be", "interesting", "to", "refer", "where", "the", "authors", "argue", "that", "instead", "of", "the", "pure", "-", "tetrad", "formalism", "for", "the", "f", "-gravity", ",", "if", "in", "addition", ",", "the", "spin", "connection", "is", "allowed", ",", "then", "the", "problem", "with", "local", "lorentz", "invariance", "might", "be", "resolved", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the problem with local lorentz invariance", "start": 183, "end": 224, "i_start": 35, "i_end": 40}, "verb": {"text": "might be resolved", "start": 225, "end": 242, "i_start": 41, "i_end": 43}}, {"subject": {"text": "the problem with local lorentz invariance", "start": 183, "end": 224, "i_start": 35, "i_end": 40}, "verb": {"text": "be", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 3756}, {"sent": "this problem has proved important in a vast number of applications , such as computational biology .", "tokens": ["this", "problem", "has", "proved", "important", "in", "a", "vast", "number", "of", "applications", ",", "such", "as", "computational", "biology", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this problem", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "has proved", "start": 13, "end": 23, "i_start": 2, "i_end": 3}}], "id": 3757}, {"sent": "following the pioneering work of that the k-nn classifier is strongly bayes consistent in r d .", "tokens": ["following", "the", "pioneering", "work", "of", "that", "the", "k", "-", "nn", "classifier", "is", "strongly", "bayes", "consistent", "in", "r", "d", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the k-nn classifier", "start": 38, "end": 57, "i_start": 6, "i_end": 10}, "verb": {"text": "is", "start": 58, "end": 60, "i_start": 11, "i_end": 11}}, {"character": {"text": "that", "start": 33, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "work", "start": 25, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "work", "start": 25, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "pioneering", "start": 14, "end": 24, "i_start": 2, "i_end": 2}}], "id": 3758}, {"sent": "circles mark out the assumed parameter values characteristic of four different p .", "tokens": ["circles", "mark", "out", "the", "assumed", "parameter", "values", "characteristic", "of", "four", "different", "p", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "circles", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "mark out", "start": 8, "end": 16, "i_start": 1, "i_end": 2}}, {"character": {"text": "circles", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "mark", "start": 8, "end": 12, "i_start": 1, "i_end": 1}}], "id": 3759}, {"sent": "an operad a is a en-operad if there is a chain of equivalences connecting a to dn .", "tokens": ["an", "operad", "a", "is", "a", "en", "-", "operad", "if", "there", "is", "a", "chain", "of", "equivalences", "connecting", "a", "to", "dn", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3760}, {"sent": "for that purpose , we present a natural extension of the skip-gram model that simultaneously learns word and phrase embeddings , which are then mapped to a cross-lingual space through selflearning .", "tokens": ["for", "that", "purpose", ",", "we", "present", "a", "natural", "extension", "of", "the", "skip", "-", "gram", "model", "that", "simultaneously", "learns", "word", "and", "phrase", "embeddings", ",", "which", "are", "then", "mapped", "to", "a", "cross", "-", "lingual", "space", "through", "selflearning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "verb": {"text": "present", "start": 22, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "present", "start": 22, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "model", "start": 67, "end": 72, "i_start": 14, "i_end": 14}, "action": {"text": "learns", "start": 93, "end": 99, "i_start": 17, "i_end": 17}}], "id": 3761}, {"sent": "electric charge is a technological challenge .", "tokens": ["electric", "charge", "is", "a", "technological", "challenge", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "electric charge", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 3762}, {"sent": "in , venugopalan et al present a lstm based model to generate video descriptions with the mean pooling representation over all frames .", "tokens": ["in", ",", "venugopalan", "et", "al", "present", "a", "lstm", "based", "model", "to", "generate", "video", "descriptions", "with", "the", "mean", "pooling", "representation", "over", "all", "frames", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "venugopalan et al", "start": 5, "end": 22, "i_start": 2, "i_end": 4}, "verb": {"text": "present", "start": 23, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "venugopalan", "start": 5, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "present", "start": 23, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "venugopalan", "start": 5, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "generate", "start": 53, "end": 61, "i_start": 11, "i_end": 11}}], "id": 3763}, {"sent": "we first evaluate menet on the ilsvrc 2012 classification dataset and compare menet with other state-of-the-art networks .", "tokens": ["we", "first", "evaluate", "menet", "on", "the", "ilsvrc", "2012", "classification", "dataset", "and", "compare", "menet", "with", "other", "state", "-", "of", "-", "the", "-", "art", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 9, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 70, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 9, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 70, "end": 77, "i_start": 11, "i_end": 11}}], "id": 3764}, {"sent": "this approach is known as dynamical compactification .", "tokens": ["this", "approach", "is", "known", "as", "dynamical", "compactification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this approach", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is known", "start": 14, "end": 22, "i_start": 2, "i_end": 3}}], "id": 3765}, {"sent": "the semantics integrate change propagation with the classic idea of memoization to enable reuse of computations under mutation to memory .", "tokens": ["the", "semantics", "integrate", "change", "propagation", "with", "the", "classic", "idea", "of", "memoization", "to", "enable", "reuse", "of", "computations", "under", "mutation", "to", "memory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the semantics", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "integrate", "start": 14, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "semantics", "start": 4, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "integrate", "start": 14, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "integrate", "start": 14, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "enable", "start": 83, "end": 89, "i_start": 12, "i_end": 12}}], "id": 3766}, {"sent": "recently , kontsevich provided a deformation quantization of the algebra of functions on an arbitrary poisson manifold .", "tokens": ["recently", ",", "kontsevich", "provided", "a", "deformation", "quantization", "of", "the", "algebra", "of", "functions", "on", "an", "arbitrary", "poisson", "manifold", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "kontsevich", "start": 11, "end": 21, "i_start": 2, "i_end": 2}, "verb": {"text": "provided", "start": 22, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "kontsevich", "start": 11, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "provided", "start": 22, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "kontsevich", "start": 11, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "quantization", "start": 45, "end": 57, "i_start": 6, "i_end": 6}}], "id": 3767}, {"sent": "for a given number of features p , the preferential attachment algorithm is employed to generate a scale-free network as the underlying true feature graph .", "tokens": ["for", "a", "given", "number", "of", "features", "p", ",", "the", "preferential", "attachment", "algorithm", "is", "employed", "to", "generate", "a", "scale", "-", "free", "network", "as", "the", "underlying", "true", "feature", "graph", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the preferential attachment algorithm", "start": 35, "end": 72, "i_start": 8, "i_end": 11}, "verb": {"text": "is employed", "start": 73, "end": 84, "i_start": 12, "i_end": 13}}, {"character": {"text": "algorithm", "start": 63, "end": 72, "i_start": 11, "i_end": 11}, "action": {"text": "generate", "start": 88, "end": 96, "i_start": 15, "i_end": 15}}, {"character": {"text": "network", "start": 110, "end": 117, "i_start": 20, "i_end": 20}, "action": {"text": "underlying", "start": 125, "end": 135, "i_start": 23, "i_end": 23}}], "id": 3768}, {"sent": "the network weights are randomly initialized using the method of .", "tokens": ["the", "network", "weights", "are", "randomly", "initialized", "using", "the", "method", "of", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the network weights", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "initialized", "start": 33, "end": 44, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the network weights", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 20, "end": 23, "i_start": 3, "i_end": 3}}], "id": 3769}, {"sent": "data are represented by spatial configurations of attractants and repellents , and results of computation by structures of a protoplasmic network formed by the plasmodium on the data sets .", "tokens": ["data", "are", "represented", "by", "spatial", "configurations", "of", "attractants", "and", "repellents", ",", "and", "results", "of", "computation", "by", "structures", "of", "a", "protoplasmic", "network", "formed", "by", "the", "plasmodium", "on", "the", "data", "sets", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "data", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "are represented", "start": 5, "end": 20, "i_start": 1, "i_end": 2}}, {"character": {"text": "configurations", "start": 32, "end": 46, "i_start": 5, "i_end": 5}, "action": {"text": "represented", "start": 9, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "and", "start": 79, "end": 82, "i_start": 11, "i_end": 11}, "action": {"text": "represented", "start": 9, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "plasmodium", "start": 160, "end": 170, "i_start": 24, "i_end": 24}, "action": {"text": "formed", "start": 146, "end": 152, "i_start": 21, "i_end": 21}}], "id": 3770}, {"sent": "deep neural networks have demonstrated impressive performance on many machine-learning tasks such as image recognition .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "impressive", "performance", "on", "many", "machine", "-", "learning", "tasks", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 50, "end": 61, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 50, "end": 61, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 39, "end": 49, "i_start": 5, "i_end": 5}}], "id": 3771}, {"sent": "specifically , in the discussions of piston theory , we should mention the modern engineering references .", "tokens": ["specifically", ",", "in", "the", "discussions", "of", "piston", "theory", ",", "we", "should", "mention", "the", "modern", "engineering", "references", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 53, "end": 55, "i_start": 9, "i_end": 9}, "verb": {"text": "should mention", "start": 56, "end": 70, "i_start": 10, "i_end": 11}}, {"character": {"text": "we", "start": 53, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "mention", "start": 63, "end": 70, "i_start": 11, "i_end": 11}}], "id": 3772}, {"sent": "the advent of deep learning has seen a resurgence in the use of neural networks .", "tokens": ["the", "advent", "of", "deep", "learning", "has", "seen", "a", "resurgence", "in", "the", "use", "of", "neural", "networks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the advent of deep learning", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "has seen", "start": 28, "end": 36, "i_start": 5, "i_end": 6}}, {"character": {"text": "advent", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "resurgence", "start": 39, "end": 49, "i_start": 8, "i_end": 8}}], "id": 3773}, {"sent": "cognitive radio , with its capability to flexibly configure its transmission parameters , has emerged in recent years as a promising paradigm to enable more efficient spectrum utilization .", "tokens": ["cognitive", "radio", ",", "with", "its", "capability", "to", "flexibly", "configure", "its", "transmission", "parameters", ",", "has", "emerged", "in", "recent", "years", "as", "a", "promising", "paradigm", "to", "enable", "more", "efficient", "spectrum", "utilization", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "cognitive radio", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "has emerged", "start": 90, "end": 101, "i_start": 13, "i_end": 14}}, {"character": {"text": "radio", "start": 10, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "emerged", "start": 94, "end": 101, "i_start": 14, "i_end": 14}}, {"character": {"text": "radio", "start": 10, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "has", "start": 90, "end": 93, "i_start": 13, "i_end": 13}}, {"character": {"text": "radio", "start": 10, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "configure", "start": 50, "end": 59, "i_start": 8, "i_end": 8}}], "id": 3774}, {"sent": "recent progress in deep convolutional neural networks has led to substantial performance improvements in a broad range of computer vision tasks .", "tokens": ["recent", "progress", "in", "deep", "convolutional", "neural", "networks", "has", "led", "to", "substantial", "performance", "improvements", "in", "a", "broad", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent progress in deep convolutional neural networks", "start": 0, "end": 53, "i_start": 0, "i_end": 6}, "verb": {"text": "has led", "start": 54, "end": 61, "i_start": 7, "i_end": 8}}, {"character": {"text": "progress", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 58, "end": 61, "i_start": 8, "i_end": 8}}], "id": 3775}, {"sent": "dust extinction is a function of the metallicity and gasfraction of the merging system , and has the strongest effect on g .", "tokens": ["dust", "extinction", "is", "a", "function", "of", "the", "metallicity", "and", "gasfraction", "of", "the", "merging", "system", ",", "and", "has", "the", "strongest", "effect", "on", "g", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dust extinction", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"subject": {"text": "dust extinction", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "has", "start": 93, "end": 96, "i_start": 16, "i_end": 16}}, {"character": {"text": "metallicity", "start": 37, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "function", "start": 21, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "system", "start": 80, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "function", "start": 21, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "gasfraction", "start": 53, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "function", "start": 21, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "system", "start": 80, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "function", "start": 21, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "system", "start": 80, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "merging", "start": 72, "end": 79, "i_start": 12, "i_end": 12}}], "id": 3776}, {"sent": "a stochastic multi-period opf model is presented in which contains an offshore wind farm connected to the grid by a lcc-hvdc link .", "tokens": ["a", "stochastic", "multi", "-", "period", "opf", "model", "is", "presented", "in", "which", "contains", "an", "offshore", "wind", "farm", "connected", "to", "the", "grid", "by", "a", "lcc", "-", "hvdc", "link", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a stochastic multi-period opf model", "start": 0, "end": 35, "i_start": 0, "i_end": 6}, "verb": {"text": "is presented", "start": 36, "end": 48, "i_start": 7, "i_end": 8}}, {"character": {"text": "model", "start": 30, "end": 35, "i_start": 6, "i_end": 6}, "action": {"text": "contains", "start": 58, "end": 66, "i_start": 11, "i_end": 11}}], "id": 3777}, {"sent": "we leverage object detection module with pretrained resnet-101 to produce the region-level representation .", "tokens": ["we", "leverage", "object", "detection", "module", "with", "pretrained", "resnet-101", "to", "produce", "the", "region", "-", "level", "representation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "leverage", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "leverage", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "module", "start": 29, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "detection", "start": 19, "end": 28, "i_start": 3, "i_end": 3}}], "id": 3778}, {"sent": "diamonds denote the location of co detections by engargiola et al , as well as the co detection diamonds .", "tokens": ["diamonds", "denote", "the", "location", "of", "co", "detections", "by", "engargiola", "et", "al", ",", "as", "well", "as", "the", "co", "detection", "diamonds", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "diamonds", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "denote", "start": 9, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "diamonds", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 9, "end": 15, "i_start": 1, "i_end": 1}}, {"character": {"text": "engargiola", "start": 49, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "detections", "start": 35, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "diamonds", "start": 96, "end": 104, "i_start": 18, "i_end": 18}, "action": {"text": "detection", "start": 86, "end": 95, "i_start": 17, "i_end": 17}}], "id": 3779}, {"sent": "each convolution is followed by batch normalization and a relu activation function .", "tokens": ["each", "convolution", "is", "followed", "by", "batch", "normalization", "and", "a", "relu", "activation", "function", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each convolution", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is followed", "start": 17, "end": 28, "i_start": 2, "i_end": 3}}], "id": 3780}, {"sent": "reinforcement learning is a field of machine learning that addresses the problems of how to behave in an environment by performing certain actions and observing the reward from those actions .", "tokens": ["reinforcement", "learning", "is", "a", "field", "of", "machine", "learning", "that", "addresses", "the", "problems", "of", "how", "to", "behave", "in", "an", "environment", "by", "performing", "certain", "actions", "and", "observing", "the", "reward", "from", "those", "actions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "field", "start": 28, "end": 33, "i_start": 4, "i_end": 4}, "action": {"text": "addresses", "start": 59, "end": 68, "i_start": 9, "i_end": 9}}], "id": 3781}, {"sent": "generalized gradient approximation was used for the exchangecorrelation energy , within the perdew-burke-ernzerhof functional form .", "tokens": ["generalized", "gradient", "approximation", "was", "used", "for", "the", "exchangecorrelation", "energy", ",", "within", "the", "perdew", "-", "burke", "-", "ernzerhof", "functional", "form", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generalized gradient approximation", "start": 0, "end": 34, "i_start": 0, "i_end": 2}, "verb": {"text": "was used", "start": 35, "end": 43, "i_start": 3, "i_end": 4}}], "id": 3782}, {"sent": "for more recent work on the structure of graph inverse semigroups , we refer to .", "tokens": ["for", "more", "recent", "work", "on", "the", "structure", "of", "graph", "inverse", "semigroups", ",", "we", "refer", "to", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 68, "end": 70, "i_start": 12, "i_end": 12}, "verb": {"text": "refer", "start": 71, "end": 76, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 68, "end": 70, "i_start": 12, "i_end": 12}, "action": {"text": "refer", "start": 71, "end": 76, "i_start": 13, "i_end": 13}}], "id": 3783}, {"sent": "one class of generative models that has been applied to representation learning is generative adversarial networks .", "tokens": ["one", "class", "of", "generative", "models", "that", "has", "been", "applied", "to", "representation", "learning", "is", "generative", "adversarial", "networks", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "one class of generative models that has been applied to representation learning", "start": 0, "end": 79, "i_start": 0, "i_end": 11}, "verb": {"text": "is", "start": 80, "end": 82, "i_start": 12, "i_end": 12}}], "id": 3784}, {"sent": "following the feature pyramid network setting , we add extra layers and form top-down connections .", "tokens": ["following", "the", "feature", "pyramid", "network", "setting", ",", "we", "add", "extra", "layers", "and", "form", "top", "-", "down", "connections", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 48, "end": 50, "i_start": 7, "i_end": 7}, "verb": {"text": "add", "start": 51, "end": 54, "i_start": 8, "i_end": 8}}, {"subject": {"text": "we", "start": 48, "end": 50, "i_start": 7, "i_end": 7}, "verb": {"text": "form", "start": 72, "end": 76, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 48, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "add", "start": 51, "end": 54, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 48, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "form", "start": 72, "end": 76, "i_start": 12, "i_end": 12}}], "id": 3785}, {"sent": "we establish new criteria that are helpful in interpreting and analyzing quantum and classical spin transport phenomena .", "tokens": ["we", "establish", "new", "criteria", "that", "are", "helpful", "in", "interpreting", "and", "analyzing", "quantum", "and", "classical", "spin", "transport", "phenomena", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "establish", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "establish", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "criteria", "start": 17, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "helpful", "start": 35, "end": 42, "i_start": 6, "i_end": 6}}], "id": 3786}, {"sent": "chekanov et al measurement of deeply virtual compton scattering at hera .", "tokens": ["chekanov", "et", "al", "measurement", "of", "deeply", "virtual", "compton", "scattering", "at", "hera", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "chekanov", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "measurement", "start": 15, "end": 26, "i_start": 3, "i_end": 3}}], "id": 3787}, {"sent": "deep convolutional neural networks have led to a series of breakthrough for visual tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "led", "to", "a", "series", "of", "breakthrough", "for", "visual", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have led", "start": 35, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "led", "start": 40, "end": 43, "i_start": 5, "i_end": 5}}], "id": 3788}, {"sent": "we provide inner and outer bounds for the capacity region of the degraded discrete memoryless multi-receiver wiretap channel .", "tokens": ["we", "provide", "inner", "and", "outer", "bounds", "for", "the", "capacity", "region", "of", "the", "degraded", "discrete", "memoryless", "multi", "-", "receiver", "wiretap", "channel", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "provide", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "provide", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "channel", "start": 117, "end": 124, "i_start": 19, "i_end": 19}, "action": {"text": "-", "start": 99, "end": 100, "i_start": 16, "i_end": 16}}], "id": 3789}, {"sent": "moreover , we investigated the image quality by calculating the peak signal-to-noise ratio and the structural similarity index .", "tokens": ["moreover", ",", "we", "investigated", "the", "image", "quality", "by", "calculating", "the", "peak", "signal", "-", "to", "-", "noise", "ratio", "and", "the", "structural", "similarity", "index", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "verb": {"text": "investigated", "start": 14, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "investigated", "start": 14, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "calculating", "start": 48, "end": 59, "i_start": 8, "i_end": 8}}], "id": 3790}, {"sent": "our approach is evaluated on the large-scale imagenet vid dataset .", "tokens": ["our", "approach", "is", "evaluated", "on", "the", "large", "-", "scale", "imagenet", "vid", "dataset", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our approach", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is evaluated", "start": 13, "end": 25, "i_start": 2, "i_end": 3}}], "id": 3791}, {"sent": "overlaid is the expectation for the previous best-fit mix nca with .", "tokens": ["overlaid", "is", "the", "expectation", "for", "the", "previous", "best", "-", "fit", "mix", "nca", "with", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3792}, {"sent": "end if end if end if else end if end if end if message bridgeinform over port l .", "tokens": ["end", "if", "end", "if", "end", "if", "else", "end", "if", "end", "if", "end", "if", "message", "bridgeinform", "over", "port", "l", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3793}, {"sent": "the neutrino is the only known stable particle immune to the gzk degradation .", "tokens": ["the", "neutrino", "is", "the", "only", "known", "stable", "particle", "immune", "to", "the", "gzk", "degradation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the neutrino", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 3794}, {"sent": "more recently , convolutional neural networks have achieved unprecedented performance in a wide range of image classification problems .", "tokens": ["more", "recently", ",", "convolutional", "neural", "networks", "have", "achieved", "unprecedented", "performance", "in", "a", "wide", "range", "of", "image", "classification", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 74, "end": 85, "i_start": 9, "i_end": 9}}], "id": 3795}, {"sent": "recently deep neural networks have made a great success in many real-world applications , such as image classification .", "tokens": ["recently", "deep", "neural", "networks", "have", "made", "a", "great", "success", "in", "many", "real", "-", "world", "applications", ",", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 9, "end": 29, "i_start": 1, "i_end": 3}, "verb": {"text": "have made", "start": 30, "end": 39, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 48, "end": 55, "i_start": 8, "i_end": 8}}], "id": 3796}, {"sent": "to this end , diks et al and gneiting and ranjan consider the use of proper weighted scoring rules that emphasize specific regions of interest .", "tokens": ["to", "this", "end", ",", "diks", "et", "al", "and", "gneiting", "and", "ranjan", "consider", "the", "use", "of", "proper", "weighted", "scoring", "rules", "that", "emphasize", "specific", "regions", "of", "interest", "."], "score": [1, 0, 0, 0, 1], "labels": [{"subject": {"text": "to this end", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "consider", "start": 49, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "and", "start": 38, "end": 41, "i_start": 9, "i_end": 9}, "action": {"text": "consider", "start": 49, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "diks", "start": 14, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "consider", "start": 49, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "gneiting", "start": 29, "end": 37, "i_start": 8, "i_end": 8}, "action": {"text": "consider", "start": 49, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "ranjan", "start": 42, "end": 48, "i_start": 10, "i_end": 10}, "action": {"text": "consider", "start": 49, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "rules", "start": 93, "end": 98, "i_start": 18, "i_end": 18}, "action": {"text": "emphasize", "start": 104, "end": 113, "i_start": 20, "i_end": 20}}], "id": 3797}, {"sent": "very recently the weakly supervised segmentation results have been significantly improved by deep convolutional neural network-based models .", "tokens": ["very", "recently", "the", "weakly", "supervised", "segmentation", "results", "have", "been", "significantly", "improved", "by", "deep", "convolutional", "neural", "network", "-", "based", "models", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the weakly supervised segmentation results", "start": 14, "end": 56, "i_start": 2, "i_end": 6}, "verb": {"text": "improved", "start": 81, "end": 89, "i_start": 10, "i_end": 10}}, {"subject": {"text": "the weakly supervised segmentation results", "start": 14, "end": 56, "i_start": 2, "i_end": 6}, "verb": {"text": "have been", "start": 57, "end": 66, "i_start": 7, "i_end": 8}}, {"character": {"text": "models", "start": 133, "end": 139, "i_start": 18, "i_end": 18}, "action": {"text": "improved", "start": 81, "end": 89, "i_start": 10, "i_end": 10}}], "id": 3798}, {"sent": "random forests or randomized decision trees , are a popular ensemble predictive model suitable for many machine learning tasks .", "tokens": ["random", "forests", "or", "randomized", "decision", "trees", ",", "are", "a", "popular", "ensemble", "predictive", "model", "suitable", "for", "many", "machine", "learning", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "random forests or randomized decision trees", "start": 0, "end": 43, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 46, "end": 49, "i_start": 7, "i_end": 7}}, {"character": {"text": "model", "start": 80, "end": 85, "i_start": 12, "i_end": 12}, "action": {"text": "predictive", "start": 69, "end": 79, "i_start": 11, "i_end": 11}}], "id": 3799}, {"sent": "one should also note that the toffoli and hadamard gates comprise the simplest quantum universal set of gates .", "tokens": ["one", "should", "also", "note", "that", "the", "toffoli", "and", "hadamard", "gates", "comprise", "the", "simplest", "quantum", "universal", "set", "of", "gates", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the toffoli and hadamard gates", "start": 26, "end": 56, "i_start": 5, "i_end": 9}, "verb": {"text": "note", "start": 16, "end": 20, "i_start": 3, "i_end": 3}}, {"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "should", "start": 4, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "comprise", "start": 57, "end": 65, "i_start": 10, "i_end": 10}}, {"character": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "note", "start": 16, "end": 20, "i_start": 3, "i_end": 3}}], "id": 3800}, {"sent": "deep neural network is a significant technique in machine learning , which has been developed to manage tasks like humans do .", "tokens": ["deep", "neural", "network", "is", "a", "significant", "technique", "in", "machine", "learning", ",", "which", "has", "been", "developed", "to", "manage", "tasks", "like", "humans", "do", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural network", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "network", "start": 12, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "manage", "start": 97, "end": 103, "i_start": 16, "i_end": 16}}], "id": 3801}, {"sent": "low-density parity-check block codes , invented by gallager , have been shown to achieve excellent performance on a wide class of channels .", "tokens": ["low", "-", "density", "parity", "-", "check", "block", "codes", ",", "invented", "by", "gallager", ",", "have", "been", "shown", "to", "achieve", "excellent", "performance", "on", "a", "wide", "class", "of", "channels", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "low-density parity-check block codes", "start": 0, "end": 36, "i_start": 0, "i_end": 7}, "verb": {"text": "have been shown", "start": 62, "end": 77, "i_start": 13, "i_end": 15}}, {"character": {"text": "codes", "start": 31, "end": 36, "i_start": 7, "i_end": 7}, "action": {"text": "achieve", "start": 81, "end": 88, "i_start": 17, "i_end": 17}}, {"character": {"text": "codes", "start": 31, "end": 36, "i_start": 7, "i_end": 7}, "action": {"text": "check", "start": 19, "end": 24, "i_start": 5, "i_end": 5}}, {"character": {"text": "gallager", "start": 51, "end": 59, "i_start": 11, "i_end": 11}, "action": {"text": "invented", "start": 39, "end": 47, "i_start": 9, "i_end": 9}}], "id": 3802}, {"sent": "it assures that the physics remains independent of the observer , and it is therefore also called observer invariance .", "tokens": ["it", "assures", "that", "the", "physics", "remains", "independent", "of", "the", "observer", ",", "and", "it", "is", "therefore", "also", "called", "observer", "invariance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assures", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the physics", "start": 16, "end": 27, "i_start": 3, "i_end": 4}, "verb": {"text": "remains", "start": 28, "end": 35, "i_start": 5, "i_end": 5}}, {"subject": {"text": "it", "start": 70, "end": 72, "i_start": 12, "i_end": 12}, "verb": {"text": "called", "start": 91, "end": 97, "i_start": 16, "i_end": 16}}, {"character": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assures", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "physics", "start": 20, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "independent", "start": 36, "end": 47, "i_start": 6, "i_end": 6}}], "id": 3803}, {"sent": "if string theory is the correct quantum theory of gravity , then whatever it computes presumably are the observables .", "tokens": ["if", "string", "theory", "is", "the", "correct", "quantum", "theory", "of", "gravity", ",", "then", "whatever", "it", "computes", "presumably", "are", "the", "observables", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "whatever it computes", "start": 65, "end": 85, "i_start": 12, "i_end": 14}, "verb": {"text": "are", "start": 97, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "theory", "start": 10, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "computes", "start": 77, "end": 85, "i_start": 14, "i_end": 14}}], "id": 3804}, {"sent": "as an example , the exchange of robots 4 and 9 can be carried out using a 2-switch sequence , of which each individual pair is an adjacent one after the previous 2-switch is completed .", "tokens": ["as", "an", "example", ",", "the", "exchange", "of", "robots", "4", "and", "9", "can", "be", "carried", "out", "using", "a", "2", "-", "switch", "sequence", ",", "of", "which", "each", "individual", "pair", "is", "an", "adjacent", "one", "after", "the", "previous", "2", "-", "switch", "is", "completed", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange of robots 4 and 9", "start": 16, "end": 46, "i_start": 4, "i_end": 10}, "verb": {"text": "can be carried out", "start": 47, "end": 65, "i_start": 11, "i_end": 14}}], "id": 3805}, {"sent": "metasurfaces are thin arrays of artificial scattering particles engineered to control the propagation of light in ways that are unachievable with conventional matters .", "tokens": ["metasurfaces", "are", "thin", "arrays", "of", "artificial", "scattering", "particles", "engineered", "to", "control", "the", "propagation", "of", "light", "in", "ways", "that", "are", "unachievable", "with", "conventional", "matters", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "metasurfaces", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 13, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "particles", "start": 54, "end": 63, "i_start": 7, "i_end": 7}, "action": {"text": "scattering", "start": 43, "end": 53, "i_start": 6, "i_end": 6}}, {"character": {"text": "metasurfaces", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "action": {"text": "control", "start": 78, "end": 85, "i_start": 10, "i_end": 10}}], "id": 3806}, {"sent": "this string theory can be thought of as the gravity dual of a gauge theory living in a stack of d3 branes placed at the conical singularity of y 6 , the cone over x 5 .", "tokens": ["this", "string", "theory", "can", "be", "thought", "of", "as", "the", "gravity", "dual", "of", "a", "gauge", "theory", "living", "in", "a", "stack", "of", "d3", "branes", "placed", "at", "the", "conical", "singularity", "of", "y", "6", ",", "the", "cone", "over", "x", "5", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this string theory", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "can be thought", "start": 19, "end": 33, "i_start": 3, "i_end": 5}}, {"character": {"text": "theory", "start": 68, "end": 74, "i_start": 14, "i_end": 14}, "action": {"text": "living", "start": 75, "end": 81, "i_start": 15, "i_end": 15}}], "id": 3807}, {"sent": "we note that these approaches are also closely related to hashing approaches .", "tokens": ["we", "note", "that", "these", "approaches", "are", "also", "closely", "related", "to", "hashing", "approaches", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "note", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "note", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3808}, {"sent": "now we want to compute correlators containing the field \u03c8 .", "tokens": ["now", "we", "want", "to", "compute", "correlators", "containing", "the", "field", "\u03c8", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "want", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "want", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "compute", "start": 15, "end": 22, "i_start": 4, "i_end": 4}}], "id": 3809}, {"sent": "each of these invariants is a refinement of the slice genus of a knot .", "tokens": ["each", "of", "these", "invariants", "is", "a", "refinement", "of", "the", "slice", "genus", "of", "a", "knot", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each of these invariants", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 4, "i_end": 4}}], "id": 3810}, {"sent": "in , egc was studied by approximating the moment generating function of the output snr , where the moments are determined exactly only for exponentially correlated nakagami-m channels in terms of multi-fold infinite series .", "tokens": ["in", ",", "egc", "was", "studied", "by", "approximating", "the", "moment", "generating", "function", "of", "the", "output", "snr", ",", "where", "the", "moments", "are", "determined", "exactly", "only", "for", "exponentially", "correlated", "nakagami", "-", "m", "channels", "in", "terms", "of", "multi", "-", "fold", "infinite", "series", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "egc", "start": 5, "end": 8, "i_start": 2, "i_end": 2}, "verb": {"text": "was studied", "start": 9, "end": 20, "i_start": 3, "i_end": 4}}], "id": 3811}, {"sent": "it follows form that qcspreduces to the verification of a polynomial number of instances of csp , each of which is in nl by .", "tokens": ["it", "follows", "form", "that", "qcspreduces", "to", "the", "verification", "of", "a", "polynomial", "number", "of", "instances", "of", "csp", ",", "each", "of", "which", "is", "in", "nl", "by", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follows", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 3812}, {"sent": "this is the contribution of the tube track to the total combined resolution measured at the fibre plane .", "tokens": ["this", "is", "the", "contribution", "of", "the", "tube", "track", "to", "the", "total", "combined", "resolution", "measured", "at", "the", "fibre", "plane", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "track", "start": 37, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "contribution", "start": 12, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3813}, {"sent": "belinkov and bisk show that nmt systems can be fooled via synthetic and natural character level noises .", "tokens": ["belinkov", "and", "bisk", "show", "that", "nmt", "systems", "can", "be", "fooled", "via", "synthetic", "and", "natural", "character", "level", "noises", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "belinkov and bisk", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "show", "start": 18, "end": 22, "i_start": 3, "i_end": 3}}, {"subject": {"text": "nmt systems", "start": 28, "end": 39, "i_start": 5, "i_end": 6}, "verb": {"text": "fooled", "start": 47, "end": 53, "i_start": 9, "i_end": 9}}, {"character": {"text": "belinkov", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 18, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "bisk", "start": 13, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 18, "end": 22, "i_start": 3, "i_end": 3}}], "id": 3814}, {"sent": "fluid flow through a porous medium is an important problem for many technological applications ranging from oil recovery to chemical reactors .", "tokens": ["fluid", "flow", "through", "a", "porous", "medium", "is", "an", "important", "problem", "for", "many", "technological", "applications", "ranging", "from", "oil", "recovery", "to", "chemical", "reactors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "fluid flow through a porous medium", "start": 0, "end": 34, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 6, "i_end": 6}}], "id": 3815}, {"sent": "it is shown also that dmi leads to the helical spin fluctuations which may be observed by the polarized neutron scattering .", "tokens": ["it", "is", "shown", "also", "that", "dmi", "leads", "to", "the", "helical", "spin", "fluctuations", "which", "may", "be", "observed", "by", "the", "polarized", "neutron", "scattering", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is shown", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"subject": {"text": "dmi", "start": 22, "end": 25, "i_start": 5, "i_end": 5}, "verb": {"text": "leads", "start": 26, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "scattering", "start": 112, "end": 122, "i_start": 20, "i_end": 20}, "action": {"text": "observed", "start": 78, "end": 86, "i_start": 15, "i_end": 15}}], "id": 3816}, {"sent": "recently quantum field theories on a noncommutative space-time have received a lot of attention , see for example and references there .", "tokens": ["recently", "quantum", "field", "theories", "on", "a", "noncommutative", "space", "-", "time", "have", "received", "a", "lot", "of", "attention", ",", "see", "for", "example", "and", "references", "there", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "recently quantum field theories on a noncommutative space-time", "start": 0, "end": 62, "i_start": 0, "i_end": 9}, "verb": {"text": "have received", "start": 63, "end": 76, "i_start": 10, "i_end": 11}}, {"subject": {"text": "recently quantum field theories on a noncommutative space-time", "start": 0, "end": 62, "i_start": 0, "i_end": 9}, "verb": {"text": "see", "start": 98, "end": 101, "i_start": 17, "i_end": 17}}], "id": 3817}, {"sent": "deep convolutional neural networks trained using backpropagation are thus achieving record performance in a variety of large-scale machine vision tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "trained", "using", "backpropagation", "are", "thus", "achieving", "record", "performance", "in", "a", "variety", "of", "large", "-", "scale", "machine", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks trained using backpropagation", "start": 0, "end": 64, "i_start": 0, "i_end": 6}, "verb": {"text": "achieving", "start": 74, "end": 83, "i_start": 9, "i_end": 9}}, {"subject": {"text": "deep convolutional neural networks trained using backpropagation", "start": 0, "end": 64, "i_start": 0, "i_end": 6}, "verb": {"text": "are", "start": 65, "end": 68, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieving", "start": 74, "end": 83, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "using", "start": 43, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 91, "end": 102, "i_start": 11, "i_end": 11}}], "id": 3818}, {"sent": "quantum mechanics is a non-commutative version of classical phase space .", "tokens": ["quantum", "mechanics", "is", "a", "non", "-", "commutative", "version", "of", "classical", "phase", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum mechanics", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}], "id": 3819}, {"sent": "in recent years , learning systems based on neural networks have gained tremendous popularity in a variety of application domains such as machine vision , natural language processing , biomedical analysis or financial data analysis .", "tokens": ["in", "recent", "years", ",", "learning", "systems", "based", "on", "neural", "networks", "have", "gained", "tremendous", "popularity", "in", "a", "variety", "of", "application", "domains", "such", "as", "machine", "vision", ",", "natural", "language", "processing", ",", "biomedical", "analysis", "or", "financial", "data", "analysis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "learning systems based on neural networks", "start": 18, "end": 59, "i_start": 4, "i_end": 9}, "verb": {"text": "have gained", "start": 60, "end": 71, "i_start": 10, "i_end": 11}}, {"character": {"text": "systems", "start": 27, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "gained", "start": 65, "end": 71, "i_start": 11, "i_end": 11}}], "id": 3820}, {"sent": "shahroudy et al introduced a part-aware lstm to learn the long-term dynamics of a long skeleton sequence from multimodal inputs extracted from human body parts .", "tokens": ["shahroudy", "et", "al", "introduced", "a", "part", "-", "aware", "lstm", "to", "learn", "the", "long", "-", "term", "dynamics", "of", "a", "long", "skeleton", "sequence", "from", "multimodal", "inputs", "extracted", "from", "human", "body", "parts", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 10, "end": 15, "i_start": 1, "i_end": 2}, "verb": {"text": "introduced", "start": 16, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "shahroudy", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 16, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "shahroudy", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "learn", "start": 48, "end": 53, "i_start": 10, "i_end": 10}}], "id": 3821}, {"sent": "deep learning models have achieved great success in visual recognition tasks .", "tokens": ["deep", "learning", "models", "have", "achieved", "great", "success", "in", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning models", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "models", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "models", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "models", "start": 14, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 41, "end": 48, "i_start": 6, "i_end": 6}}], "id": 3822}, {"sent": "modern detection methods , such as , based on convolutional neural networks have achieved state-ofthe-art results on benchmarks such as pascal voc .", "tokens": ["modern", "detection", "methods", ",", "such", "as", ",", "based", "on", "convolutional", "neural", "networks", "have", "achieved", "state", "-", "ofthe", "-", "art", "results", "on", "benchmarks", "such", "as", "pascal", "voc", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "modern detection methods", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 76, "end": 89, "i_start": 12, "i_end": 13}}, {"character": {"text": "methods", "start": 17, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 81, "end": 89, "i_start": 13, "i_end": 13}}], "id": 3823}, {"sent": "the aim of this paper has been to solve the geodesic equation exactly and present the complete set of solutions to the geodesic equation .", "tokens": ["the", "aim", "of", "this", "paper", "has", "been", "to", "solve", "the", "geodesic", "equation", "exactly", "and", "present", "the", "complete", "set", "of", "solutions", "to", "the", "geodesic", "equation", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the aim of this paper", "start": 0, "end": 21, "i_start": 0, "i_end": 4}, "verb": {"text": "has been", "start": 22, "end": 30, "i_start": 5, "i_end": 6}}, {"character": {"text": "paper", "start": 16, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "aim", "start": 4, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3824}, {"sent": "baryogenesis through leptogenesis is a simple and attractive mechanism to explain the mysterious excess of matter over antimatter in the universe .", "tokens": ["baryogenesis", "through", "leptogenesis", "is", "a", "simple", "and", "attractive", "mechanism", "to", "explain", "the", "mysterious", "excess", "of", "matter", "over", "antimatter", "in", "the", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "baryogenesis through leptogenesis", "start": 0, "end": 33, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 3, "i_end": 3}}, {"character": {"text": "mechanism", "start": 61, "end": 70, "i_start": 8, "i_end": 8}, "action": {"text": "attractive", "start": 50, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "mechanism", "start": 61, "end": 70, "i_start": 8, "i_end": 8}, "action": {"text": "explain", "start": 74, "end": 81, "i_start": 10, "i_end": 10}}], "id": 3825}, {"sent": "also , for the standard galerkin method , although with constants depending on inverse powers on \u03bd , we get a rate of convergence for the method in space one unit larger than the method in .", "tokens": ["also", ",", "for", "the", "standard", "galerkin", "method", ",", "although", "with", "constants", "depending", "on", "inverse", "powers", "on", "\u03bd", ",", "we", "get", "a", "rate", "of", "convergence", "for", "the", "method", "in", "space", "one", "unit", "larger", "than", "the", "method", "in", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 101, "end": 103, "i_start": 18, "i_end": 18}, "verb": {"text": "get", "start": 104, "end": 107, "i_start": 19, "i_end": 19}}, {"character": {"text": "we", "start": 101, "end": 103, "i_start": 18, "i_end": 18}, "action": {"text": "get", "start": 104, "end": 107, "i_start": 19, "i_end": 19}}, {"character": {"text": "constants", "start": 56, "end": 65, "i_start": 10, "i_end": 10}, "action": {"text": "depending", "start": 66, "end": 75, "i_start": 11, "i_end": 11}}], "id": 3826}, {"sent": "the word embeddings produced by the cbow and sg models have been shown to be surprisingly effective at capturing detailed semantics useful for various natural language processing and reasoning tasks , including word analogies .", "tokens": ["the", "word", "embeddings", "produced", "by", "the", "cbow", "and", "sg", "models", "have", "been", "shown", "to", "be", "surprisingly", "effective", "at", "capturing", "detailed", "semantics", "useful", "for", "various", "natural", "language", "processing", "and", "reasoning", "tasks", ",", "including", "word", "analogies", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the word embeddings produced by the cbow and sg models", "start": 0, "end": 54, "i_start": 0, "i_end": 9}, "verb": {"text": "have been shown", "start": 55, "end": 70, "i_start": 10, "i_end": 12}}, {"character": {"text": "embeddings", "start": 9, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "effective", "start": 90, "end": 99, "i_start": 16, "i_end": 16}}, {"character": {"text": "models", "start": 48, "end": 54, "i_start": 9, "i_end": 9}, "action": {"text": "produced", "start": 20, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "cbow", "start": 36, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "produced", "start": 20, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "sg", "start": 45, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "produced", "start": 20, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "embeddings", "start": 9, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "capturing", "start": 103, "end": 112, "i_start": 18, "i_end": 18}}, {"character": {"text": "shown", "start": 65, "end": 70, "i_start": 12, "i_end": 12}, "action": {"text": "surprisingly", "start": 77, "end": 89, "i_start": 15, "i_end": 15}}], "id": 3827}, {"sent": "convolutional neural networks are good at capturing scale-invariant features based on the spectral information .", "tokens": ["convolutional", "neural", "networks", "are", "good", "at", "capturing", "scale", "-", "invariant", "features", "based", "on", "the", "spectral", "information", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 30, "end": 33, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "capturing", "start": 42, "end": 51, "i_start": 6, "i_end": 6}}], "id": 3828}, {"sent": "we now describe a more general sperner lemma-type of result for polytopes , following .", "tokens": ["we", "now", "describe", "a", "more", "general", "sperner", "lemma", "-", "type", "of", "result", "for", "polytopes", ",", "following", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "describe", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "describe", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}], "id": 3829}, {"sent": "in it is shown that matrix theory compactifications on morita equivalent noncommutative tori are physically equivalent , in that the associated quantum theories are dual .", "tokens": ["in", "it", "is", "shown", "that", "matrix", "theory", "compactifications", "on", "morita", "equivalent", "noncommutative", "tori", "are", "physically", "equivalent", ",", "in", "that", "the", "associated", "quantum", "theories", "are", "dual", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 3, "end": 5, "i_start": 1, "i_end": 1}, "verb": {"text": "is shown", "start": 6, "end": 14, "i_start": 2, "i_end": 3}}, {"subject": {"text": "it", "start": 3, "end": 5, "i_start": 1, "i_end": 1}, "verb": {"text": "are", "start": 93, "end": 96, "i_start": 13, "i_end": 13}}], "id": 3830}, {"sent": "the element resolution of lemt is shown in detail by reames .", "tokens": ["the", "element", "resolution", "of", "lemt", "is", "shown", "in", "detail", "by", "reames", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the element resolution of lemt", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "is shown", "start": 31, "end": 39, "i_start": 5, "i_end": 6}}], "id": 3831}, {"sent": "one natural generalization consists of the case when t is assumed to be a principal direction but the corresponding principal curvature is different from 0 .", "tokens": ["one", "natural", "generalization", "consists", "of", "the", "case", "when", "t", "is", "assumed", "to", "be", "a", "principal", "direction", "but", "the", "corresponding", "principal", "curvature", "is", "different", "from", "0", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one natural generalization", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 27, "end": 35, "i_start": 3, "i_end": 3}}], "id": 3832}, {"sent": "as is well known , there is a maximal temperature of a gas of weakly coupled strings in thermal equilibrium , the hagedorn temperature t h .", "tokens": ["as", "is", "well", "known", ",", "there", "is", "a", "maximal", "temperature", "of", "a", "gas", "of", "weakly", "coupled", "strings", "in", "thermal", "equilibrium", ",", "the", "hagedorn", "temperature", "t", "h", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 19, "end": 24, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 6, "i_end": 6}}], "id": 3833}, {"sent": "we further follow paulus et al to use the self-critical policy gradient training algorithm .", "tokens": ["we", "further", "follow", "paulus", "et", "al", "to", "use", "the", "self", "-", "critical", "policy", "gradient", "training", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follow", "start": 11, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "follow", "start": 11, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "paulus", "start": 18, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 34, "end": 37, "i_start": 7, "i_end": 7}}], "id": 3834}, {"sent": "the line bundle l is called the normal bundle of the foliation .", "tokens": ["the", "line", "bundle", "l", "is", "called", "the", "normal", "bundle", "of", "the", "foliation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the line bundle l", "start": 0, "end": 17, "i_start": 0, "i_end": 3}, "verb": {"text": "is called", "start": 18, "end": 27, "i_start": 4, "i_end": 5}}], "id": 3835}, {"sent": "for euclidean signature spherical spaces , we explained that the non-associative gauge theory can be related to con structions in matrix theory via fuzzy spheres .", "tokens": ["for", "euclidean", "signature", "spherical", "spaces", ",", "we", "explained", "that", "the", "non", "-", "associative", "gauge", "theory", "can", "be", "related", "to", "con", "structions", "in", "matrix", "theory", "via", "fuzzy", "spheres", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 43, "end": 45, "i_start": 6, "i_end": 6}, "verb": {"text": "explained", "start": 46, "end": 55, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the non-associative gauge theory", "start": 61, "end": 93, "i_start": 9, "i_end": 14}, "verb": {"text": "related", "start": 101, "end": 108, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 43, "end": 45, "i_start": 6, "i_end": 6}, "action": {"text": "explained", "start": 46, "end": 55, "i_start": 7, "i_end": 7}}], "id": 3836}, {"sent": "ding et al used faster r-cnn to generate candidate nodules , followed by 3d convolutional networks to remove false positive nodules .", "tokens": ["ding", "et", "al", "used", "faster", "r", "-", "cnn", "to", "generate", "candidate", "nodules", ",", "followed", "by", "3d", "convolutional", "networks", "to", "remove", "false", "positive", "nodules", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "ding", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "ding", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "generate", "start": 32, "end": 40, "i_start": 9, "i_end": 9}}], "id": 3837}, {"sent": "recent developments in deep learning have led to significant progress in supervised learning tasks on complex image datasets .", "tokens": ["recent", "developments", "in", "deep", "learning", "have", "led", "to", "significant", "progress", "in", "supervised", "learning", "tasks", "on", "complex", "image", "datasets", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent developments in deep learning", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "have led", "start": 37, "end": 45, "i_start": 5, "i_end": 6}}, {"character": {"text": "developments", "start": 7, "end": 19, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 42, "end": 45, "i_start": 6, "i_end": 6}}], "id": 3838}, {"sent": "in the next section , we will explain the equivalent perturbation method in the probabilistic framework .", "tokens": ["in", "the", "next", "section", ",", "we", "will", "explain", "the", "equivalent", "perturbation", "method", "in", "the", "probabilistic", "framework", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 22, "end": 24, "i_start": 5, "i_end": 5}, "verb": {"text": "will explain", "start": 25, "end": 37, "i_start": 6, "i_end": 7}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 5, "i_end": 5}, "action": {"text": "explain", "start": 30, "end": 37, "i_start": 7, "i_end": 7}}], "id": 3839}, {"sent": "symbol-level cooperation between neighboring wireless nodes is known to have the potential for large data-rate gains in wireless fading channels .", "tokens": ["symbol", "-", "level", "cooperation", "between", "neighboring", "wireless", "nodes", "is", "known", "to", "have", "the", "potential", "for", "large", "data", "-", "rate", "gains", "in", "wireless", "fading", "channels", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "symbol-level cooperation between neighboring wireless nodes", "start": 0, "end": 59, "i_start": 0, "i_end": 7}, "verb": {"text": "is known", "start": 60, "end": 68, "i_start": 8, "i_end": 9}}, {"character": {"text": "channels", "start": 136, "end": 144, "i_start": 23, "i_end": 23}, "action": {"text": "fading", "start": 129, "end": 135, "i_start": 22, "i_end": 22}}, {"character": {"text": "nodes", "start": 54, "end": 59, "i_start": 7, "i_end": 7}, "action": {"text": "cooperation", "start": 13, "end": 24, "i_start": 3, "i_end": 3}}], "id": 3840}, {"sent": "the model is trained with the adam optimizer using default parameters and learning-rate of 2e-4 .", "tokens": ["the", "model", "is", "trained", "with", "the", "adam", "optimizer", "using", "default", "parameters", "and", "learning", "-", "rate", "of", "2e-4", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is trained", "start": 10, "end": 20, "i_start": 2, "i_end": 3}}, {"character": {"text": "model", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "using", "start": 45, "end": 50, "i_start": 8, "i_end": 8}}], "id": 3841}, {"sent": "mcdaniel and mclaughlin discuss privacy concerns due to energy-usage profiling , which smart grids could potentially enable .", "tokens": ["mcdaniel", "and", "mclaughlin", "discuss", "privacy", "concerns", "due", "to", "energy", "-", "usage", "profiling", ",", "which", "smart", "grids", "could", "potentially", "enable", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "mcdaniel and mclaughlin", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "discuss", "start": 24, "end": 31, "i_start": 3, "i_end": 3}}, {"character": {"text": "mcdaniel", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "discuss", "start": 24, "end": 31, "i_start": 3, "i_end": 3}}, {"character": {"text": "mclaughlin", "start": 13, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "discuss", "start": 24, "end": 31, "i_start": 3, "i_end": 3}}, {"character": {"text": "profiling", "start": 69, "end": 78, "i_start": 11, "i_end": 11}, "action": {"text": "concerns", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "grids", "start": 93, "end": 98, "i_start": 15, "i_end": 15}, "action": {"text": "enable", "start": 117, "end": 123, "i_start": 18, "i_end": 18}}], "id": 3842}, {"sent": "we compare the proposed scheme with the full-rank with d coefficients provides an estimate of the desired symbol for the desired used using the bit error rate .", "tokens": ["we", "compare", "the", "proposed", "scheme", "with", "the", "full", "-", "rank", "with", "d", "coefficients", "provides", "an", "estimate", "of", "the", "desired", "symbol", "for", "the", "desired", "used", "using", "the", "bit", "error", "rate", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "provides", "start": 70, "end": 78, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "compare", "start": 3, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "provides", "start": 70, "end": 78, "i_start": 13, "i_end": 13}}], "id": 3843}, {"sent": "deep neural networks have been widely adopted in many applications such as computer vision .", "tokens": ["deep", "neural", "networks", "have", "been", "widely", "adopted", "in", "many", "applications", "such", "as", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "adopted", "start": 38, "end": 45, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}], "id": 3844}, {"sent": "the modification essentially consists of discarding objects whose stalks carry a nonsemisimple action of frobenius .", "tokens": ["the", "modification", "essentially", "consists", "of", "discarding", "objects", "whose", "stalks", "carry", "a", "nonsemisimple", "action", "of", "frobenius", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the modification", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 29, "end": 37, "i_start": 3, "i_end": 3}}, {"character": {"text": "objects", "start": 52, "end": 59, "i_start": 6, "i_end": 6}, "action": {"text": "stalks", "start": 66, "end": 72, "i_start": 8, "i_end": 8}}], "id": 3845}, {"sent": "deep convolutional neural networks have gained tremendous attention recently due to their great success in boosting the performance of image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "gained", "tremendous", "attention", "recently", "due", "to", "their", "great", "success", "in", "boosting", "the", "performance", "of", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have gained", "start": 35, "end": 46, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "gained", "start": 40, "end": 46, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 96, "end": 103, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "boosting", "start": 107, "end": 115, "i_start": 15, "i_end": 15}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 120, "end": 131, "i_start": 17, "i_end": 17}}], "id": 3846}, {"sent": "in 1987 , affleck , kennedy , lieb and tasaki constructed the exact valence-bond ground state of a particular nextnearest-neighbour spin chain .", "tokens": ["in", "1987", ",", "affleck", ",", "kennedy", ",", "lieb", "and", "tasaki", "constructed", "the", "exact", "valence", "-", "bond", "ground", "state", "of", "a", "particular", "nextnearest", "-", "neighbour", "spin", "chain", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "affleck", "start": 10, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "constructed", "start": 46, "end": 57, "i_start": 10, "i_end": 10}}, {"character": {"text": "affleck", "start": 10, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "constructed", "start": 46, "end": 57, "i_start": 10, "i_end": 10}}, {"character": {"text": "kennedy", "start": 20, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "constructed", "start": 46, "end": 57, "i_start": 10, "i_end": 10}}, {"character": {"text": "lieb", "start": 30, "end": 34, "i_start": 7, "i_end": 7}, "action": {"text": "constructed", "start": 46, "end": 57, "i_start": 10, "i_end": 10}}, {"character": {"text": "tasaki", "start": 39, "end": 45, "i_start": 9, "i_end": 9}, "action": {"text": "constructed", "start": 46, "end": 57, "i_start": 10, "i_end": 10}}], "id": 3847}, {"sent": "the space spanned by ideal boson-fermion states that are selected with the aid of the above particle number considerations is called the ideal subspace .", "tokens": ["the", "space", "spanned", "by", "ideal", "boson", "-", "fermion", "states", "that", "are", "selected", "with", "the", "aid", "of", "the", "above", "particle", "number", "considerations", "is", "called", "the", "ideal", "subspace", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the space spanned by ideal boson-fermion states that are selected with the aid of the above particle number considerations", "start": 0, "end": 122, "i_start": 0, "i_end": 20}, "verb": {"text": "is called", "start": 123, "end": 132, "i_start": 21, "i_end": 22}}, {"character": {"text": "states", "start": 41, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "spanned", "start": 10, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "considerations", "start": 108, "end": 122, "i_start": 20, "i_end": 20}, "action": {"text": "aid", "start": 75, "end": 78, "i_start": 14, "i_end": 14}}], "id": 3848}, {"sent": "meeting our students where they are means building upon the resources for thinking about free energy and spontaneity that ipls students bring from their experiences in those classes .", "tokens": ["meeting", "our", "students", "where", "they", "are", "means", "building", "upon", "the", "resources", "for", "thinking", "about", "free", "energy", "and", "spontaneity", "that", "ipls", "students", "bring", "from", "their", "experiences", "in", "those", "classes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "experiences", "start": 153, "end": 164, "i_start": 24, "i_end": 24}, "action": {"text": "bring", "start": 136, "end": 141, "i_start": 21, "i_end": 21}}], "id": 3849}, {"sent": "set-valued young tableaux were introduced by buch in his study of the littlewood-richardson rule for stable grothendieck polynomials .", "tokens": ["set", "-", "valued", "young", "tableaux", "were", "introduced", "by", "buch", "in", "his", "study", "of", "the", "littlewood", "-", "richardson", "rule", "for", "stable", "grothendieck", "polynomials", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "set-valued young tableaux", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "were introduced", "start": 26, "end": 41, "i_start": 5, "i_end": 6}}, {"character": {"text": "buch", "start": 45, "end": 49, "i_start": 8, "i_end": 8}, "action": {"text": "introduced", "start": 31, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "buch", "start": 45, "end": 49, "i_start": 8, "i_end": 8}, "action": {"text": "study", "start": 57, "end": 62, "i_start": 11, "i_end": 11}}, {"character": {"text": "littlewood", "start": 70, "end": 80, "i_start": 14, "i_end": 14}, "action": {"text": "rule", "start": 92, "end": 96, "i_start": 17, "i_end": 17}}], "id": 3850}, {"sent": "in this way , a given density velocity field is represented by a set of particles .", "tokens": ["in", "this", "way", ",", "a", "given", "density", "velocity", "field", "is", "represented", "by", "a", "set", "of", "particles", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "a given density velocity field", "start": 14, "end": 44, "i_start": 4, "i_end": 8}, "verb": {"text": "is represented", "start": 45, "end": 59, "i_start": 9, "i_end": 10}}, {"character": {"text": "set", "start": 65, "end": 68, "i_start": 13, "i_end": 13}, "action": {"text": "represented", "start": 48, "end": 59, "i_start": 10, "i_end": 10}}], "id": 3851}, {"sent": "this is different from the standard practice in literature where chance constraints are placed on every bus of the network .", "tokens": ["this", "is", "different", "from", "the", "standard", "practice", "in", "literature", "where", "chance", "constraints", "are", "placed", "on", "every", "bus", "of", "the", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 3852}, {"sent": "a unified approach for face detection , pose estimation and landmark localization using the dpm framework was recently proposed in .", "tokens": ["a", "unified", "approach", "for", "face", "detection", ",", "pose", "estimation", "and", "landmark", "localization", "using", "the", "dpm", "framework", "was", "recently", "proposed", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a unified approach for face detection", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "pose", "start": 40, "end": 44, "i_start": 7, "i_end": 7}}, {"subject": {"text": "a unified approach for face detection", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "proposed", "start": 119, "end": 127, "i_start": 18, "i_end": 18}}], "id": 3853}, {"sent": "discrete breathers are time periodic and spatially localized nonlinear excitations in nonlinear systems .", "tokens": ["discrete", "breathers", "are", "time", "periodic", "and", "spatially", "localized", "nonlinear", "excitations", "in", "nonlinear", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "discrete breathers", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 19, "end": 22, "i_start": 2, "i_end": 2}}], "id": 3854}, {"sent": "all weights in these models are initialized randomly using the suggestion of glorot and bengio .", "tokens": ["all", "weights", "in", "these", "models", "are", "initialized", "randomly", "using", "the", "suggestion", "of", "glorot", "and", "bengio", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all weights in these models", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "are initialized", "start": 28, "end": 43, "i_start": 5, "i_end": 6}}, {"character": {"text": "glorot", "start": 77, "end": 83, "i_start": 12, "i_end": 12}, "action": {"text": "suggestion", "start": 63, "end": 73, "i_start": 10, "i_end": 10}}, {"character": {"text": "bengio", "start": 88, "end": 94, "i_start": 14, "i_end": 14}, "action": {"text": "suggestion", "start": 63, "end": 73, "i_start": 10, "i_end": 10}}], "id": 3855}, {"sent": "it has been found that the number of feedback bits per user has to increase with the transmit snr so as to bound the throughput loss caused by feedback quantization .", "tokens": ["it", "has", "been", "found", "that", "the", "number", "of", "feedback", "bits", "per", "user", "has", "to", "increase", "with", "the", "transmit", "snr", "so", "as", "to", "bound", "the", "throughput", "loss", "caused", "by", "feedback", "quantization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has been found", "start": 3, "end": 17, "i_start": 1, "i_end": 3}}, {"subject": {"text": "the number of feedback bits per user", "start": 23, "end": 59, "i_start": 5, "i_end": 11}, "verb": {"text": "has", "start": 60, "end": 63, "i_start": 12, "i_end": 12}}], "id": 3856}, {"sent": "we use adam as the meta-optimizer , and standard batch gradient descent with a fixed learning rate to update the model during fast adaptation .", "tokens": ["we", "use", "adam", "as", "the", "meta", "-", "optimizer", ",", "and", "standard", "batch", "gradient", "descent", "with", "a", "fixed", "learning", "rate", "to", "update", "the", "model", "during", "fast", "adaptation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "adam", "start": 7, "end": 11, "i_start": 2, "i_end": 2}, "action": {"text": "update", "start": 102, "end": 108, "i_start": 20, "i_end": 20}}, {"character": {"text": "adam", "start": 7, "end": 11, "i_start": 2, "i_end": 2}, "action": {"text": "optimizer", "start": 24, "end": 33, "i_start": 7, "i_end": 7}}], "id": 3857}, {"sent": "designing deeper and wider convolutional neural networks has led to significant breakthroughs in many machine learning tasks , such as image classification .", "tokens": ["designing", "deeper", "and", "wider", "convolutional", "neural", "networks", "has", "led", "to", "significant", "breakthroughs", "in", "many", "machine", "learning", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "designing deeper and wider convolutional neural networks", "start": 0, "end": 56, "i_start": 0, "i_end": 6}, "verb": {"text": "has led", "start": 57, "end": 64, "i_start": 7, "i_end": 8}}, {"character": {"text": "designing", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "led", "start": 61, "end": 64, "i_start": 8, "i_end": 8}}], "id": 3858}, {"sent": "reinforcement learning is learning by trial and error to map situations to actions , which aims to maximize a numerical reward signal .", "tokens": ["reinforcement", "learning", "is", "learning", "by", "trial", "and", "error", "to", "map", "situations", "to", "actions", ",", "which", "aims", "to", "maximize", "a", "numerical", "reward", "signal", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is learning", "start": 23, "end": 34, "i_start": 2, "i_end": 3}}, {"character": {"text": "map", "start": 57, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "aims", "start": 91, "end": 95, "i_start": 15, "i_end": 15}}], "id": 3859}, {"sent": "the study indicates that the quality of night-sky in hong kong is strongly associated with the human presence and human activities .", "tokens": ["the", "study", "indicates", "that", "the", "quality", "of", "night", "-", "sky", "in", "hong", "kong", "is", "strongly", "associated", "with", "the", "human", "presence", "and", "human", "activities", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the study", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "indicates", "start": 10, "end": 19, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the quality of night-sky in hong kong", "start": 25, "end": 62, "i_start": 4, "i_end": 12}, "verb": {"text": "associated", "start": 75, "end": 85, "i_start": 15, "i_end": 15}}, {"character": {"text": "study", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "indicates", "start": 10, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "human", "start": 95, "end": 100, "i_start": 18, "i_end": 18}, "action": {"text": "activities", "start": 120, "end": 130, "i_start": 22, "i_end": 22}}], "id": 3860}, {"sent": "in , the focus was on channel conditions where interference alignment is required .", "tokens": ["in", ",", "the", "focus", "was", "on", "channel", "conditions", "where", "interference", "alignment", "is", "required", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the focus", "start": 5, "end": 14, "i_start": 2, "i_end": 3}, "verb": {"text": "was", "start": 15, "end": 18, "i_start": 4, "i_end": 4}}], "id": 3861}, {"sent": "find the s-units in zs over the ring of integers z .", "tokens": ["find", "the", "s", "-", "units", "in", "zs", "over", "the", "ring", "of", "integers", "z", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3862}, {"sent": "cosmic strings are linear defects that could be formed at a symmetry breaking phase transition in the early universe .", "tokens": ["cosmic", "strings", "are", "linear", "defects", "that", "could", "be", "formed", "at", "a", "symmetry", "breaking", "phase", "transition", "in", "the", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "transition", "start": 84, "end": 94, "i_start": 14, "i_end": 14}, "action": {"text": "breaking", "start": 69, "end": 77, "i_start": 12, "i_end": 12}}], "id": 3863}, {"sent": "in the context of poisson inverse problems , this approach was originally proposed by mcclure for tomographic image reconstruction and later studied and extended by saquib , bouman and sauer , but has received little attention since then .", "tokens": ["in", "the", "context", "of", "poisson", "inverse", "problems", ",", "this", "approach", "was", "originally", "proposed", "by", "mcclure", "for", "tomographic", "image", "reconstruction", "and", "later", "studied", "and", "extended", "by", "saquib", ",", "bouman", "and", "sauer", ",", "but", "has", "received", "little", "attention", "since", "then", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this approach", "start": 45, "end": 58, "i_start": 8, "i_end": 9}, "verb": {"text": "proposed", "start": 74, "end": 82, "i_start": 12, "i_end": 12}}, {"subject": {"text": "this approach", "start": 45, "end": 58, "i_start": 8, "i_end": 9}, "verb": {"text": "was", "start": 59, "end": 62, "i_start": 10, "i_end": 10}}, {"subject": {"text": "this approach", "start": 45, "end": 58, "i_start": 8, "i_end": 9}, "verb": {"text": "studied", "start": 141, "end": 148, "i_start": 21, "i_end": 21}}, {"subject": {"text": "this approach", "start": 45, "end": 58, "i_start": 8, "i_end": 9}, "verb": {"text": "received", "start": 201, "end": 209, "i_start": 33, "i_end": 33}}, {"character": {"text": "saquib", "start": 165, "end": 171, "i_start": 25, "i_end": 25}, "action": {"text": "studied", "start": 141, "end": 148, "i_start": 21, "i_end": 21}}, {"character": {"text": "bouman", "start": 174, "end": 180, "i_start": 27, "i_end": 27}, "action": {"text": "studied", "start": 141, "end": 148, "i_start": 21, "i_end": 21}}, {"character": {"text": "sauer", "start": 185, "end": 190, "i_start": 29, "i_end": 29}, "action": {"text": "studied", "start": 141, "end": 148, "i_start": 21, "i_end": 21}}, {"character": {"text": "saquib", "start": 165, "end": 171, "i_start": 25, "i_end": 25}, "action": {"text": "extended", "start": 153, "end": 161, "i_start": 23, "i_end": 23}}, {"character": {"text": "bouman", "start": 174, "end": 180, "i_start": 27, "i_end": 27}, "action": {"text": "extended", "start": 153, "end": 161, "i_start": 23, "i_end": 23}}, {"character": {"text": "sauer", "start": 185, "end": 190, "i_start": 29, "i_end": 29}, "action": {"text": "extended", "start": 153, "end": 161, "i_start": 23, "i_end": 23}}], "id": 3864}, {"sent": "all convolutional layers are followed by batch normalization and a relu activation layer except for the last convolutional layer in each decoder .", "tokens": ["all", "convolutional", "layers", "are", "followed", "by", "batch", "normalization", "and", "a", "relu", "activation", "layer", "except", "for", "the", "last", "convolutional", "layer", "in", "each", "decoder", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "all convolutional layers", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "are followed", "start": 25, "end": 37, "i_start": 3, "i_end": 4}}, {"character": {"text": "layers", "start": 18, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "activation", "start": 72, "end": 82, "i_start": 11, "i_end": 11}}], "id": 3865}, {"sent": "with the tremendous success of deep learning , neural networks have found profound applications in cf tasks .", "tokens": ["with", "the", "tremendous", "success", "of", "deep", "learning", ",", "neural", "networks", "have", "found", "profound", "applications", "in", "cf", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 47, "end": 62, "i_start": 8, "i_end": 9}, "verb": {"text": "have found", "start": 63, "end": 73, "i_start": 10, "i_end": 11}}, {"character": {"text": "networks", "start": 54, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "found", "start": 68, "end": 73, "i_start": 11, "i_end": 11}}, {"character": {"text": "learning", "start": 36, "end": 44, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 20, "end": 27, "i_start": 3, "i_end": 3}}], "id": 3866}, {"sent": "deep convolutional neural networks have led to major breakthroughs in many computer vision tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "led", "to", "major", "breakthroughs", "in", "many", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have led", "start": 35, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "led", "start": 40, "end": 43, "i_start": 5, "i_end": 5}}], "id": 3867}, {"sent": "this scheme is called adaptive quantum computation .", "tokens": ["this", "scheme", "is", "called", "adaptive", "quantum", "computation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this scheme", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is called", "start": 12, "end": 21, "i_start": 2, "i_end": 3}}], "id": 3868}, {"sent": "the rest of the argument is the same as the proof of the lemma 3 point 6 .", "tokens": ["the", "rest", "of", "the", "argument", "is", "the", "same", "as", "the", "proof", "of", "the", "lemma", "3", "point", "6", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the rest of the argument", "start": 0, "end": 24, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 5, "i_end": 5}}], "id": 3869}, {"sent": "based on these ideas , jiang et al suggested to use the rank modulation scheme for errorcorrecting coding of data in flash memories .", "tokens": ["based", "on", "these", "ideas", ",", "jiang", "et", "al", "suggested", "to", "use", "the", "rank", "modulation", "scheme", "for", "errorcorrecting", "coding", "of", "data", "in", "flash", "memories", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "jiang et al", "start": 23, "end": 34, "i_start": 5, "i_end": 7}, "verb": {"text": "suggested", "start": 35, "end": 44, "i_start": 8, "i_end": 8}}, {"character": {"text": "jiang", "start": 23, "end": 28, "i_start": 5, "i_end": 5}, "action": {"text": "suggested", "start": 35, "end": 44, "i_start": 8, "i_end": 8}}], "id": 3870}, {"sent": "obviously , gravity is a destabilizing effect since the heavy fluid is above the light one .", "tokens": ["obviously", ",", "gravity", "is", "a", "destabilizing", "effect", "since", "the", "heavy", "fluid", "is", "above", "the", "light", "one", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "gravity", "start": 12, "end": 19, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "gravity", "start": 12, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "destabilizing", "start": 25, "end": 38, "i_start": 5, "i_end": 5}}], "id": 3871}, {"sent": "the catenoid is the unique \u03c3 with finite total curvature and two ends .", "tokens": ["the", "catenoid", "is", "the", "unique", "\u03c3", "with", "finite", "total", "curvature", "and", "two", "ends", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the catenoid", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 3872}, {"sent": "since the matrix v is symmetric and positive definite , we can employ a conjugate gradient method to solve the linear system .", "tokens": ["since", "the", "matrix", "v", "is", "symmetric", "and", "positive", "definite", ",", "we", "can", "employ", "a", "conjugate", "gradient", "method", "to", "solve", "the", "linear", "system", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 56, "end": 58, "i_start": 10, "i_end": 10}, "verb": {"text": "can employ", "start": 59, "end": 69, "i_start": 11, "i_end": 12}}, {"character": {"text": "we", "start": 56, "end": 58, "i_start": 10, "i_end": 10}, "action": {"text": "employ", "start": 63, "end": 69, "i_start": 12, "i_end": 12}}, {"character": {"text": "method", "start": 91, "end": 97, "i_start": 16, "i_end": 16}, "action": {"text": "solve", "start": 101, "end": 106, "i_start": 18, "i_end": 18}}], "id": 3873}, {"sent": "a more detailed description of the cms detector , together with a definition of the coordinate system used and all relevant kinematic variables , can be found in ref .", "tokens": ["a", "more", "detailed", "description", "of", "the", "cms", "detector", ",", "together", "with", "a", "definition", "of", "the", "coordinate", "system", "used", "and", "all", "relevant", "kinematic", "variables", ",", "can", "be", "found", "in", "ref", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "a more detailed description of the cms detector", "start": 0, "end": 47, "i_start": 0, "i_end": 7}, "verb": {"text": "can be found", "start": 146, "end": 158, "i_start": 24, "i_end": 26}}], "id": 3874}, {"sent": "deep neural networks have demonstrated impressive performance on many hard perception problems .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "impressive", "performance", "on", "many", "hard", "perception", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 50, "end": 61, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 50, "end": 61, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 39, "end": 49, "i_start": 5, "i_end": 5}}], "id": 3875}, {"sent": "convolutional neural networks have achieved great success in grid structure data such as image and video .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "grid", "structure", "data", "such", "as", "image", "and", "video", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}], "id": 3876}, {"sent": "it is well known that feedback can not increase the capacity of memoryless point-to-point channels .", "tokens": ["it", "is", "well", "known", "that", "feedback", "can", "not", "increase", "the", "capacity", "of", "memoryless", "point", "-", "to", "-", "point", "channels", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "feedback", "start": 22, "end": 30, "i_start": 5, "i_end": 5}, "verb": {"text": "increase", "start": 39, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "feedback", "start": 22, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "increase", "start": 39, "end": 47, "i_start": 8, "i_end": 8}}], "id": 3877}, {"sent": "quasi-metrics and the semantics of logic programs .", "tokens": ["quasi", "-", "metrics", "and", "the", "semantics", "of", "logic", "programs", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3878}, {"sent": "stability of the planetary three-body problem .", "tokens": ["stability", "of", "the", "planetary", "three", "-", "body", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3879}, {"sent": "we use the pbe exchange-correlation functional of the generalized gradient approximation to obtain adequate structures .", "tokens": ["we", "use", "the", "pbe", "exchange", "-", "correlation", "functional", "of", "the", "generalized", "gradient", "approximation", "to", "obtain", "adequate", "structures", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "approximation", "start": 75, "end": 88, "i_start": 12, "i_end": 12}, "action": {"text": "functional", "start": 36, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "obtain", "start": 92, "end": 98, "i_start": 14, "i_end": 14}}], "id": 3880}, {"sent": "another straightforward approach is to design a compact network directly , eg , resnext .", "tokens": ["another", "straightforward", "approach", "is", "to", "design", "a", "compact", "network", "directly", ",", "eg", ",", "resnext", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "another straightforward approach", "start": 0, "end": 32, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 3, "i_end": 3}}], "id": 3881}, {"sent": "the data were calibrated , continuum subtracted , and imaged using the miriad software package .", "tokens": ["the", "data", "were", "calibrated", ",", "continuum", "subtracted", ",", "and", "imaged", "using", "the", "miriad", "software", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "were calibrated", "start": 9, "end": 24, "i_start": 2, "i_end": 3}}], "id": 3882}, {"sent": "in , wang et al present a fully convolutional neural network tracking algorithm by transferring pre-trained cnn features to improve tracking accuracy .", "tokens": ["in", ",", "wang", "et", "al", "present", "a", "fully", "convolutional", "neural", "network", "tracking", "algorithm", "by", "transferring", "pre", "-", "trained", "cnn", "features", "to", "improve", "tracking", "accuracy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "wang et al", "start": 5, "end": 15, "i_start": 2, "i_end": 4}, "verb": {"text": "present", "start": 16, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "wang", "start": 5, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "present", "start": 16, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "algorithm", "start": 70, "end": 79, "i_start": 12, "i_end": 12}, "action": {"text": "tracking", "start": 61, "end": 69, "i_start": 11, "i_end": 11}}, {"character": {"text": "wang", "start": 5, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "transferring", "start": 83, "end": 95, "i_start": 14, "i_end": 14}}, {"character": {"text": "wang", "start": 5, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "improve", "start": 124, "end": 131, "i_start": 21, "i_end": 21}}], "id": 3883}, {"sent": "powell , honore et al , hong and tamer , lee and lee , blundell and powell , and frandsen .", "tokens": ["powell", ",", "honore", "et", "al", ",", "hong", "and", "tamer", ",", "lee", "and", "lee", ",", "blundell", "and", "powell", ",", "and", "frandsen", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3884}, {"sent": "among others , the two dimensional case arises in pat with so called integrating line detectors .", "tokens": ["among", "others", ",", "the", "two", "dimensional", "case", "arises", "in", "pat", "with", "so", "called", "integrating", "line", "detectors", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the two dimensional case", "start": 15, "end": 39, "i_start": 3, "i_end": 6}, "verb": {"text": "arises", "start": 40, "end": 46, "i_start": 7, "i_end": 7}}, {"character": {"text": "integrating", "start": 69, "end": 80, "i_start": 13, "i_end": 13}, "action": {"text": "arises", "start": 40, "end": 46, "i_start": 7, "i_end": 7}}], "id": 3885}, {"sent": "for example , socher et al introduced recursive neural tensor network over parse trees to compute sentence embedding for sentiment analysis .", "tokens": ["for", "example", ",", "socher", "et", "al", "introduced", "recursive", "neural", "tensor", "network", "over", "parse", "trees", "to", "compute", "sentence", "embedding", "for", "sentiment", "analysis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "socher et al", "start": 14, "end": 26, "i_start": 3, "i_end": 5}, "verb": {"text": "introduced", "start": 27, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "socher", "start": 14, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "introduced", "start": 27, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "socher", "start": 14, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "compute", "start": 90, "end": 97, "i_start": 15, "i_end": 15}}], "id": 3886}, {"sent": "finally we outline how the incorporation of additional flux superpotentials can be used to stabilize the remaining moduli .", "tokens": ["finally", "we", "outline", "how", "the", "incorporation", "of", "additional", "flux", "superpotentials", "can", "be", "used", "to", "stabilize", "the", "remaining", "moduli", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "outline", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the incorporation of additional flux superpotentials", "start": 23, "end": 75, "i_start": 4, "i_end": 9}, "verb": {"text": "used", "start": 83, "end": 87, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "outline", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "incorporation", "start": 27, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "stabilize", "start": 91, "end": 100, "i_start": 14, "i_end": 14}}], "id": 3887}, {"sent": "we imaged the data using the polyhedron method to minimise effects of non-coplanar baselines .", "tokens": ["we", "imaged", "the", "data", "using", "the", "polyhedron", "method", "to", "minimise", "effects", "of", "non", "-", "coplanar", "baselines", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "imaged", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "imaged", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 19, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "minimise", "start": 50, "end": 58, "i_start": 9, "i_end": 9}}], "id": 3888}, {"sent": "this fundamental problem has a long history in statistics and has been well-studied in a classical setting .", "tokens": ["this", "fundamental", "problem", "has", "a", "long", "history", "in", "statistics", "and", "has", "been", "well", "-", "studied", "in", "a", "classical", "setting", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this fundamental problem", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "has", "start": 25, "end": 28, "i_start": 3, "i_end": 3}}, {"subject": {"text": "this fundamental problem", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "studied", "start": 76, "end": 83, "i_start": 14, "i_end": 14}}, {"character": {"text": "problem", "start": 17, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "has", "start": 25, "end": 28, "i_start": 3, "i_end": 3}}], "id": 3889}, {"sent": "a priori there is a reason to suspect that the coherent state is not adequate to describe this component of the wave function of the system .", "tokens": ["a", "priori", "there", "is", "a", "reason", "to", "suspect", "that", "the", "coherent", "state", "is", "not", "adequate", "to", "describe", "this", "component", "of", "the", "wave", "function", "of", "the", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 9, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "state", "start": 56, "end": 61, "i_start": 11, "i_end": 11}, "action": {"text": "describe", "start": 81, "end": 89, "i_start": 16, "i_end": 16}}, {"character": {"text": "system", "start": 133, "end": 139, "i_start": 25, "i_end": 25}, "action": {"text": "function", "start": 117, "end": 125, "i_start": 22, "i_end": 22}}], "id": 3890}, {"sent": "recently a new method has become known , namely the multiparticle effective field method was put forward and developed by one of the authors .", "tokens": ["recently", "a", "new", "method", "has", "become", "known", ",", "namely", "the", "multiparticle", "effective", "field", "method", "was", "put", "forward", "and", "developed", "by", "one", "of", "the", "authors", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "namely the multiparticle effective field method", "start": 41, "end": 88, "i_start": 8, "i_end": 13}, "verb": {"text": "was put", "start": 89, "end": 96, "i_start": 14, "i_end": 15}}, {"subject": {"text": "namely the multiparticle effective field method", "start": 41, "end": 88, "i_start": 8, "i_end": 13}, "verb": {"text": "developed", "start": 109, "end": 118, "i_start": 18, "i_end": 18}}, {"character": {"text": "method", "start": 82, "end": 88, "i_start": 13, "i_end": 13}, "action": {"text": "effective", "start": 66, "end": 75, "i_start": 11, "i_end": 11}}], "id": 3891}, {"sent": "the colornet model is implemented using the pytorch deep learning library .", "tokens": ["the", "colornet", "model", "is", "implemented", "using", "the", "pytorch", "deep", "learning", "library", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the colornet model", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is implemented", "start": 19, "end": 33, "i_start": 3, "i_end": 4}}], "id": 3892}, {"sent": "we will return these problems in future work .", "tokens": ["we", "will", "return", "these", "problems", "in", "future", "work", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will return", "start": 3, "end": 14, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "return", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "work", "start": 40, "end": 44, "i_start": 7, "i_end": 7}}], "id": 3893}, {"sent": "first , we apply sscnet without the flipped tsdf as input feature .", "tokens": ["first", ",", "we", "apply", "sscnet", "without", "the", "flipped", "tsdf", "as", "input", "feature", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "apply", "start": 11, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "apply", "start": 11, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "feature", "start": 58, "end": 65, "i_start": 11, "i_end": 11}}], "id": 3894}, {"sent": "we employed several different exchange-correlation functionals , namely pbe for gete models .", "tokens": ["we", "employed", "several", "different", "exchange", "-", "correlation", "functionals", ",", "namely", "pbe", "for", "gete", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employed", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employed", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 3895}, {"sent": "deep convolutional neural networks have achieved great success in image classification and many others .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "image", "classification", "and", "many", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}], "id": 3896}, {"sent": "deep neural networks have shown remarkable success in many domains , such as computer vision .", "tokens": ["deep", "neural", "networks", "have", "shown", "remarkable", "success", "in", "many", "domains", ",", "such", "as", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}], "id": 3897}, {"sent": "a theory of thermoelastic materials with voids .", "tokens": ["a", "theory", "of", "thermoelastic", "materials", "with", "voids", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3898}, {"sent": "convolutional neural networks have witnessed great improvement on a series of vision tasks such as object classification .", "tokens": ["convolutional", "neural", "networks", "have", "witnessed", "great", "improvement", "on", "a", "series", "of", "vision", "tasks", "such", "as", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have witnessed", "start": 30, "end": 44, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "witnessed", "start": 35, "end": 44, "i_start": 4, "i_end": 4}}], "id": 3899}, {"sent": "quantum entanglement is a type of correlation , but special because it can be shared only among quantum it has been the focus of foundational discussystems .", "tokens": ["quantum", "entanglement", "is", "a", "type", "of", "correlation", ",", "but", "special", "because", "it", "can", "be", "shared", "only", "among", "quantum", "it", "has", "been", "the", "focus", "of", "foundational", "discussystems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum entanglement", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "discussystems", "start": 142, "end": 155, "i_start": 25, "i_end": 25}, "action": {"text": "shared", "start": 78, "end": 84, "i_start": 14, "i_end": 14}}], "id": 3900}, {"sent": "hydrogen is a convenient , safe , versatile fuel source that can be easily converted .", "tokens": ["hydrogen", "is", "a", "convenient", ",", "safe", ",", "versatile", "fuel", "source", "that", "can", "be", "easily", "converted", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "hydrogen", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "source", "start": 49, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "safe", "start": 27, "end": 31, "i_start": 5, "i_end": 5}}], "id": 3901}, {"sent": "the convergence of the eigen-decomposition of the matrices to that of the laplace-beltrami and other differential operators on the manifold is discussed , for example , in .", "tokens": ["the", "convergence", "of", "the", "eigen", "-", "decomposition", "of", "the", "matrices", "to", "that", "of", "the", "laplace", "-", "beltrami", "and", "other", "differential", "operators", "on", "the", "manifold", "is", "discussed", ",", "for", "example", ",", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the convergence of the eigen-decomposition of the matrices to that of the laplace-beltrami and other differential operators on the manifold", "start": 0, "end": 139, "i_start": 0, "i_end": 23}, "verb": {"text": "is discussed", "start": 140, "end": 152, "i_start": 24, "i_end": 25}}], "id": 3902}, {"sent": "moreover , if the orbit is a solution to the equation of motion under homogeneous potential , the orbit has a new constant involving momenta .", "tokens": ["moreover", ",", "if", "the", "orbit", "is", "a", "solution", "to", "the", "equation", "of", "motion", "under", "homogeneous", "potential", ",", "the", "orbit", "has", "a", "new", "constant", "involving", "momenta", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "the orbit", "start": 94, "end": 103, "i_start": 17, "i_end": 18}, "verb": {"text": "has", "start": 104, "end": 107, "i_start": 19, "i_end": 19}}, {"character": {"text": "orbit", "start": 18, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "has", "start": 104, "end": 107, "i_start": 19, "i_end": 19}}], "id": 3903}, {"sent": "convolutional neural networks have shown outstanding performance in many fundamental areas in computer vision , enabled by the availability of large-scale annotated datasets .", "tokens": ["convolutional", "neural", "networks", "have", "shown", "outstanding", "performance", "in", "many", "fundamental", "areas", "in", "computer", "vision", ",", "enabled", "by", "the", "availability", "of", "large", "-", "scale", "annotated", "datasets", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 35, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 6, "i_end": 6}}, {"character": {"text": "availability", "start": 127, "end": 139, "i_start": 18, "i_end": 18}, "action": {"text": "enabled", "start": 112, "end": 119, "i_start": 15, "i_end": 15}}], "id": 3904}, {"sent": "for example , lorentz violation could imply that neutrino oscillation will occur even if the neutrino mass is zero .", "tokens": ["for", "example", ",", "lorentz", "violation", "could", "imply", "that", "neutrino", "oscillation", "will", "occur", "even", "if", "the", "neutrino", "mass", "is", "zero", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "lorentz violation", "start": 14, "end": 31, "i_start": 3, "i_end": 4}, "verb": {"text": "could imply", "start": 32, "end": 43, "i_start": 5, "i_end": 6}}, {"subject": {"text": "neutrino oscillation", "start": 49, "end": 69, "i_start": 8, "i_end": 9}, "verb": {"text": "occur", "start": 75, "end": 80, "i_start": 11, "i_end": 11}}, {"character": {"text": "violation", "start": 22, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "imply", "start": 38, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "neutrino", "start": 49, "end": 57, "i_start": 8, "i_end": 8}, "action": {"text": "oscillation", "start": 58, "end": 69, "i_start": 9, "i_end": 9}}], "id": 3905}, {"sent": "we will prove this conjecture in this paper .", "tokens": ["we", "will", "prove", "this", "conjecture", "in", "this", "paper", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will prove", "start": 3, "end": 13, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "prove", "start": 8, "end": 13, "i_start": 2, "i_end": 2}}], "id": 3906}, {"sent": "our approach shares similar high level spirit with spatial transform networks .", "tokens": ["our", "approach", "shares", "similar", "high", "level", "spirit", "with", "spatial", "transform", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "approach", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "shares", "start": 13, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "networks", "start": 69, "end": 77, "i_start": 10, "i_end": 10}, "action": {"text": "transform", "start": 59, "end": 68, "i_start": 9, "i_end": 9}}], "id": 3907}, {"sent": "some methods used , such as cryptographic authentication and other mechanisms , do not entirely solve the problem .", "tokens": ["some", "methods", "used", ",", "such", "as", "cryptographic", "authentication", "and", "other", "mechanisms", ",", "do", "not", "entirely", "solve", "the", "problem", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "some methods used", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "solve", "start": 96, "end": 101, "i_start": 15, "i_end": 15}}, {"subject": {"text": "some methods used", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "do not", "start": 80, "end": 86, "i_start": 12, "i_end": 13}}, {"character": {"text": "methods", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "not entirely solve", "start": 83, "end": 101, "i_start": 13, "i_end": 15}}], "id": 3908}, {"sent": "because the misalignment it is a lorentz is between locally inertial transformation .", "tokens": ["because", "the", "misalignment", "it", "is", "a", "lorentz", "is", "between", "locally", "inertial", "transformation", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the misalignment it is a lorentz", "start": 8, "end": 40, "i_start": 1, "i_end": 6}, "verb": {"text": "is", "start": 41, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "misalignment", "start": 12, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "because", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}], "id": 3909}, {"sent": "queen utilizes recursive dns queries to measure the packet loss between a pair of dns servers , and extrapolates from this to estimate the packet loss rate between arbitrary hosts .", "tokens": ["queen", "utilizes", "recursive", "dns", "queries", "to", "measure", "the", "packet", "loss", "between", "a", "pair", "of", "dns", "servers", ",", "and", "extrapolates", "from", "this", "to", "estimate", "the", "packet", "loss", "rate", "between", "arbitrary", "hosts", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "queen", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "utilizes", "start": 6, "end": 14, "i_start": 1, "i_end": 1}}, {"subject": {"text": "queen", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "extrapolates", "start": 100, "end": 112, "i_start": 18, "i_end": 18}}, {"character": {"text": "queen", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "utilizes", "start": 6, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "queen", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "measure", "start": 40, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "queen", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "extrapolates", "start": 100, "end": 112, "i_start": 18, "i_end": 18}}, {"character": {"text": "queen", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "estimate", "start": 126, "end": 134, "i_start": 22, "i_end": 22}}], "id": 3910}, {"sent": "for low energy jets , resolutions are limited by the intrinsic calorimeter resolutions .", "tokens": ["for", "low", "energy", "jets", ",", "resolutions", "are", "limited", "by", "the", "intrinsic", "calorimeter", "resolutions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "resolutions", "start": 22, "end": 33, "i_start": 5, "i_end": 5}, "verb": {"text": "are limited", "start": 34, "end": 45, "i_start": 6, "i_end": 7}}, {"character": {"text": "resolutions", "start": 22, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "limited", "start": 38, "end": 45, "i_start": 7, "i_end": 7}}], "id": 3911}, {"sent": "peer to peer networks will become an increasingly important distribution channel for consumer .", "tokens": ["peer", "to", "peer", "networks", "will", "become", "an", "increasingly", "important", "distribution", "channel", "for", "consumer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "peer to peer networks", "start": 0, "end": 21, "i_start": 0, "i_end": 3}, "verb": {"text": "will become", "start": 22, "end": 33, "i_start": 4, "i_end": 5}}], "id": 3912}, {"sent": "the phase space is the cotangent bundle over it with conjugate momenta denoted by pi .", "tokens": ["the", "phase", "space", "is", "the", "cotangent", "bundle", "over", "it", "with", "conjugate", "momenta", "denoted", "by", "pi", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the phase space", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 3913}, {"sent": "schweigert , conformal correlation functions , frobenius algebras and triangulations , nucl .", "tokens": ["schweigert", ",", "conformal", "correlation", "functions", ",", "frobenius", "algebras", "and", "triangulations", ",", "nucl", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "frobenius", "start": 47, "end": 56, "i_start": 6, "i_end": 6}, "action": {"text": "triangulations", "start": 70, "end": 84, "i_start": 9, "i_end": 9}}], "id": 3914}, {"sent": "quantum phases of dipolar bosons in optical lattices .", "tokens": ["quantum", "phases", "of", "dipolar", "bosons", "in", "optical", "lattices", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3915}, {"sent": "if x admits a torus action and the fixed point set is compact , we can define torus-equivariant orbifold gromovwitten invariants using the atiyah-bott style localization on the moduli space of stable maps .", "tokens": ["if", "x", "admits", "a", "torus", "action", "and", "the", "fixed", "point", "set", "is", "compact", ",", "we", "can", "define", "torus", "-", "equivariant", "orbifold", "gromovwitten", "invariants", "using", "the", "atiyah", "-", "bott", "style", "localization", "on", "the", "moduli", "space", "of", "stable", "maps", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 64, "end": 66, "i_start": 14, "i_end": 14}, "verb": {"text": "can define", "start": 67, "end": 77, "i_start": 15, "i_end": 16}}, {"subject": {"text": "we", "start": 64, "end": 66, "i_start": 14, "i_end": 14}, "verb": {"text": "is", "start": 51, "end": 53, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 14, "i_end": 14}, "action": {"text": "define", "start": 71, "end": 77, "i_start": 16, "i_end": 16}}], "id": 3916}, {"sent": "even determining if a stationary point is a local minimum is np-hard .", "tokens": ["even", "determining", "if", "a", "stationary", "point", "is", "a", "local", "minimum", "is", "np", "-", "hard", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3917}, {"sent": "in both figures , t is a terminal leaf node and marked arcs are crossed by a line .", "tokens": ["in", "both", "figures", ",", "t", "is", "a", "terminal", "leaf", "node", "and", "marked", "arcs", "are", "crossed", "by", "a", "line", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "t", "start": 18, "end": 19, "i_start": 4, "i_end": 4}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 5, "i_end": 5}}, {"subject": {"text": "t", "start": 18, "end": 19, "i_start": 4, "i_end": 4}, "verb": {"text": "crossed", "start": 64, "end": 71, "i_start": 14, "i_end": 14}}, {"character": {"text": "line", "start": 77, "end": 81, "i_start": 17, "i_end": 17}, "action": {"text": "crossed", "start": 64, "end": 71, "i_start": 14, "i_end": 14}}], "id": 3918}, {"sent": "to increase cellular network capacity , the deployment of small cells has been proposed and is currently taking place .", "tokens": ["to", "increase", "cellular", "network", "capacity", ",", "the", "deployment", "of", "small", "cells", "has", "been", "proposed", "and", "is", "currently", "taking", "place", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the deployment of small cells", "start": 40, "end": 69, "i_start": 6, "i_end": 10}, "verb": {"text": "has been proposed", "start": 70, "end": 87, "i_start": 11, "i_end": 13}}, {"subject": {"text": "the deployment of small cells", "start": 40, "end": 69, "i_start": 6, "i_end": 10}, "verb": {"text": "taking", "start": 105, "end": 111, "i_start": 17, "i_end": 17}}], "id": 3919}, {"sent": "srivastava and salakhutdinov extend deep boltzman machines to multimodal data for learning joint representations of images and text .", "tokens": ["srivastava", "and", "salakhutdinov", "extend", "deep", "boltzman", "machines", "to", "multimodal", "data", "for", "learning", "joint", "representations", "of", "images", "and", "text", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "srivastava and salakhutdinov", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "extend", "start": 29, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "srivastava", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "extend", "start": 29, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "salakhutdinov", "start": 15, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "extend", "start": 29, "end": 35, "i_start": 3, "i_end": 3}}], "id": 3920}, {"sent": "the gpru component and the rpru are initialized with the xavier initialization .", "tokens": ["the", "gpru", "component", "and", "the", "rpru", "are", "initialized", "with", "the", "xavier", "initialization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the gpru component and the rpru", "start": 0, "end": 31, "i_start": 0, "i_end": 5}, "verb": {"text": "are initialized", "start": 32, "end": 47, "i_start": 6, "i_end": 7}}], "id": 3921}, {"sent": "the term multiple instance learning was first developed by dietterich et al in 1997 for drug activity detection .", "tokens": ["the", "term", "multiple", "instance", "learning", "was", "first", "developed", "by", "dietterich", "et", "al", "in", "1997", "for", "drug", "activity", "detection", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the term multiple instance learning", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "developed", "start": 46, "end": 55, "i_start": 7, "i_end": 7}}, {"subject": {"text": "the term multiple instance learning", "start": 0, "end": 35, "i_start": 0, "i_end": 4}, "verb": {"text": "was", "start": 36, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "dietterich", "start": 59, "end": 69, "i_start": 9, "i_end": 9}, "action": {"text": "developed", "start": 46, "end": 55, "i_start": 7, "i_end": 7}}], "id": 3922}, {"sent": "ac field is applied parallel to the ab plane .", "tokens": ["ac", "field", "is", "applied", "parallel", "to", "the", "ab", "plane", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "ac field", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "is applied", "start": 9, "end": 19, "i_start": 2, "i_end": 3}}], "id": 3923}, {"sent": "though gravity is the oldest known one , it is still the less well understood .", "tokens": ["though", "gravity", "is", "the", "oldest", "known", "one", ",", "it", "is", "still", "the", "less", "well", "understood", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 41, "end": 43, "i_start": 8, "i_end": 8}, "verb": {"text": "is", "start": 44, "end": 46, "i_start": 9, "i_end": 9}}], "id": 3924}, {"sent": "the generalizedgradient approximation of perdew-burke-ernzerhof is employed as the exchange-correlation functional .", "tokens": ["the", "generalizedgradient", "approximation", "of", "perdew", "-", "burke", "-", "ernzerhof", "is", "employed", "as", "the", "exchange", "-", "correlation", "functional", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalizedgradient approximation of perdew-burke-ernzerhof", "start": 0, "end": 63, "i_start": 0, "i_end": 8}, "verb": {"text": "is employed", "start": 64, "end": 75, "i_start": 9, "i_end": 10}}], "id": 3925}, {"sent": "the propagator is a smooth function of its arguments and the time entries , ii .", "tokens": ["the", "propagator", "is", "a", "smooth", "function", "of", "its", "arguments", "and", "the", "time", "entries", ",", "ii", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the propagator", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "arguments", "start": 43, "end": 52, "i_start": 8, "i_end": 8}, "action": {"text": "function of its arguments and the time entries , ii", "start": 27, "end": 78, "i_start": 5, "i_end": 14}}], "id": 3926}, {"sent": "using this model , the authors of propose an estimator for the tree topology to estimate the pass rate of a path connecting the source to a node .", "tokens": ["using", "this", "model", ",", "the", "authors", "of", "propose", "an", "estimator", "for", "the", "tree", "topology", "to", "estimate", "the", "pass", "rate", "of", "a", "path", "connecting", "the", "source", "to", "a", "node", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 19, "end": 30, "i_start": 4, "i_end": 5}, "verb": {"text": "of propose", "start": 31, "end": 41, "i_start": 6, "i_end": 7}}, {"character": {"text": "path", "start": 108, "end": 112, "i_start": 21, "i_end": 21}, "action": {"text": "connecting", "start": 113, "end": 123, "i_start": 22, "i_end": 22}}], "id": 3927}, {"sent": "the abscissa and ordinate denote the frequency in hz and the flux density in mjy , respectively .", "tokens": ["the", "abscissa", "and", "ordinate", "denote", "the", "frequency", "in", "hz", "and", "the", "flux", "density", "in", "mjy", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the abscissa and ordinate", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "denote", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "abscissa", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "ordinate", "start": 17, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "denote", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}], "id": 3928}, {"sent": "the matching has applications in a variety of different fields such as computational biology .", "tokens": ["the", "matching", "has", "applications", "in", "a", "variety", "of", "different", "fields", "such", "as", "computational", "biology", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the matching", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "has", "start": 13, "end": 16, "i_start": 2, "i_end": 2}}], "id": 3929}, {"sent": "we extract a 4096- dimensional feature vector from each image using the caffe .", "tokens": ["we", "extract", "a", "4096-", "dimensional", "feature", "vector", "from", "each", "image", "using", "the", "caffe", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "extract", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extract", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 62, "end": 67, "i_start": 10, "i_end": 10}}], "id": 3930}, {"sent": "the solid line is obtained from the dashed line after including the absorption corrections .", "tokens": ["the", "solid", "line", "is", "obtained", "from", "the", "dashed", "line", "after", "including", "the", "absorption", "corrections", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the solid line", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is obtained", "start": 15, "end": 26, "i_start": 3, "i_end": 4}}], "id": 3931}, {"sent": "thus , their cancellation is a necessary consistency check for any such open string vacuum .", "tokens": ["thus", ",", "their", "cancellation", "is", "a", "necessary", "consistency", "check", "for", "any", "such", "open", "string", "vacuum", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "their cancellation", "start": 7, "end": 25, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "cancellation", "start": 13, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "check", "start": 53, "end": 58, "i_start": 8, "i_end": 8}}], "id": 3932}, {"sent": "whilst , chen et al , adopts tdma for scheduling transmissions within a wban and carrier sensing mechanism to deal with inter-wban interference .", "tokens": ["whilst", ",", "chen", "et", "al", ",", "adopts", "tdma", "for", "scheduling", "transmissions", "within", "a", "wban", "and", "carrier", "sensing", "mechanism", "to", "deal", "with", "inter", "-", "wban", "interference", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "chen et al", "start": 9, "end": 19, "i_start": 2, "i_end": 4}, "verb": {"text": "adopts", "start": 22, "end": 28, "i_start": 6, "i_end": 6}}, {"character": {"text": "chen", "start": 9, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "adopts", "start": 22, "end": 28, "i_start": 6, "i_end": 6}}, {"character": {"text": "chen", "start": 9, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "deal", "start": 110, "end": 114, "i_start": 19, "i_end": 19}}], "id": 3933}, {"sent": "to fulfil this requirement , we use density-based spatial clustering of applications with noise , which groups together points that are in a neighborhood .", "tokens": ["to", "fulfil", "this", "requirement", ",", "we", "use", "density", "-", "based", "spatial", "clustering", "of", "applications", "with", "noise", ",", "which", "groups", "together", "points", "that", "are", "in", "a", "neighborhood", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 32, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 32, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "clustering", "start": 58, "end": 68, "i_start": 11, "i_end": 11}, "action": {"text": "groups", "start": 104, "end": 110, "i_start": 18, "i_end": 18}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "fulfil", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 3934}, {"sent": "the origins of pairwise comparisons date back to the thirteenth century .", "tokens": ["the", "origins", "of", "pairwise", "comparisons", "date", "back", "to", "the", "thirteenth", "century", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3935}, {"sent": "convolutional neural networks have made great progress in various fields , such as object classification , detection and character recognition .", "tokens": ["convolutional", "neural", "networks", "have", "made", "great", "progress", "in", "various", "fields", ",", "such", "as", "object", "classification", ",", "detection", "and", "character", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have made", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}], "id": 3936}, {"sent": "finally , we need to determine the relation between tips and tifs .", "tokens": ["finally", ",", "we", "need", "to", "determine", "the", "relation", "between", "tips", "and", "tifs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "need", "start": 13, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "need", "start": 13, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "determine", "start": 21, "end": 30, "i_start": 5, "i_end": 5}}], "id": 3937}, {"sent": "the network is initialized with the weights from the pretrained resnet-101 model on imagenet .", "tokens": ["the", "network", "is", "initialized", "with", "the", "weights", "from", "the", "pretrained", "resnet-101", "model", "on", "imagenet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the network", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is initialized", "start": 12, "end": 26, "i_start": 2, "i_end": 3}}], "id": 3938}, {"sent": "equivalently , the algorithm is applicable to networks with arbitrary in-degree , but also arbitrary computation time and memory .", "tokens": ["equivalently", ",", "the", "algorithm", "is", "applicable", "to", "networks", "with", "arbitrary", "in", "-", "degree", ",", "but", "also", "arbitrary", "computation", "time", "and", "memory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the algorithm", "start": 15, "end": 28, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 4, "i_end": 4}}], "id": 3939}, {"sent": "convolutional neural networks have been proven to achieve astonishing results in different research areas such as face recognition .", "tokens": ["convolutional", "neural", "networks", "have", "been", "proven", "to", "achieve", "astonishing", "results", "in", "different", "research", "areas", "such", "as", "face", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been proven", "start": 30, "end": 46, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 50, "end": 57, "i_start": 7, "i_end": 7}}, {"character": {"text": "results", "start": 70, "end": 77, "i_start": 9, "i_end": 9}, "action": {"text": "astonishing", "start": 58, "end": 69, "i_start": 8, "i_end": 8}}], "id": 3940}, {"sent": "a set of pss is generated by using a shift register guided by a galois field gf , that satisfies orthogonal , closure and balance properties .", "tokens": ["a", "set", "of", "pss", "is", "generated", "by", "using", "a", "shift", "register", "guided", "by", "a", "galois", "field", "gf", ",", "that", "satisfies", "orthogonal", ",", "closure", "and", "balance", "properties", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a set of pss", "start": 0, "end": 12, "i_start": 0, "i_end": 3}, "verb": {"text": "is generated", "start": 13, "end": 25, "i_start": 4, "i_end": 5}}, {"character": {"text": "gf", "start": 77, "end": 79, "i_start": 16, "i_end": 16}, "action": {"text": "guided", "start": 52, "end": 58, "i_start": 11, "i_end": 11}}, {"character": {"text": "register", "start": 43, "end": 51, "i_start": 10, "i_end": 10}, "action": {"text": "satisfies", "start": 87, "end": 96, "i_start": 19, "i_end": 19}}], "id": 3941}, {"sent": "recently , millimeter-wave communication has gained considerable attention as a candidate technology for 5g mobile communication systems and beyond .", "tokens": ["recently", ",", "millimeter", "-", "wave", "communication", "has", "gained", "considerable", "attention", "as", "a", "candidate", "technology", "for", "5", "g", "mobile", "communication", "systems", "and", "beyond", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "millimeter-wave communication", "start": 11, "end": 40, "i_start": 2, "i_end": 5}, "verb": {"text": "has gained", "start": 41, "end": 51, "i_start": 6, "i_end": 7}}, {"character": {"text": "communication", "start": 27, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "gained", "start": 45, "end": 51, "i_start": 7, "i_end": 7}}], "id": 3942}, {"sent": "deep neural networks have gained popularity in recent years thanks to their achievements in many applications including computer vision , signal and image processing , speech recognition .", "tokens": ["deep", "neural", "networks", "have", "gained", "popularity", "in", "recent", "years", "thanks", "to", "their", "achievements", "in", "many", "applications", "including", "computer", "vision", ",", "signal", "and", "image", "processing", ",", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have gained", "start": 21, "end": 32, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "gained", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achievements", "start": 76, "end": 88, "i_start": 12, "i_end": 12}}], "id": 3943}, {"sent": "this strategy in turn gives an interesting generalization of the classical oconvergence rate of the conditional gradient algorithm .", "tokens": ["this", "strategy", "in", "turn", "gives", "an", "interesting", "generalization", "of", "the", "classical", "oconvergence", "rate", "of", "the", "conditional", "gradient", "algorithm", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this strategy", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "gives", "start": 22, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "strategy", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "generalization", "start": 43, "end": 57, "i_start": 7, "i_end": 7}}], "id": 3944}, {"sent": "in section 2 , we review subsurface projections and tight geodesics defined by masur-minsky .", "tokens": ["in", "section", "2", ",", "we", "review", "subsurface", "projections", "and", "tight", "geodesics", "defined", "by", "masur", "-", "minsky", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "review", "start": 18, "end": 24, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "review", "start": 18, "end": 24, "i_start": 5, "i_end": 5}}, {"character": {"text": "masur", "start": 79, "end": 84, "i_start": 13, "i_end": 13}, "action": {"text": "defined", "start": 68, "end": 75, "i_start": 11, "i_end": 11}}], "id": 3945}, {"sent": "on the positive side , bonsma et al proved that it can be decided in polynomial time in claw-free graphs .", "tokens": ["on", "the", "positive", "side", ",", "bonsma", "et", "al", "proved", "that", "it", "can", "be", "decided", "in", "polynomial", "time", "in", "claw", "-", "free", "graphs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bonsma et al", "start": 23, "end": 35, "i_start": 5, "i_end": 7}, "verb": {"text": "proved", "start": 36, "end": 42, "i_start": 8, "i_end": 8}}, {"subject": {"text": "it", "start": 48, "end": 50, "i_start": 10, "i_end": 10}, "verb": {"text": "decided", "start": 58, "end": 65, "i_start": 13, "i_end": 13}}, {"character": {"text": "bonsma", "start": 23, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "proved", "start": 36, "end": 42, "i_start": 8, "i_end": 8}}], "id": 3946}, {"sent": "in particular , the kuramoto model , which assumes sinusoidal coupling , has been extensively studied and is related to synchronization phenomena in power grids .", "tokens": ["in", "particular", ",", "the", "kuramoto", "model", ",", "which", "assumes", "sinusoidal", "coupling", ",", "has", "been", "extensively", "studied", "and", "is", "related", "to", "synchronization", "phenomena", "in", "power", "grids", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "the kuramoto model", "start": 16, "end": 34, "i_start": 3, "i_end": 5}, "verb": {"text": "studied", "start": 94, "end": 101, "i_start": 15, "i_end": 15}}, {"subject": {"text": "the kuramoto model", "start": 16, "end": 34, "i_start": 3, "i_end": 5}, "verb": {"text": "has been", "start": 73, "end": 81, "i_start": 12, "i_end": 13}}, {"subject": {"text": "the kuramoto model", "start": 16, "end": 34, "i_start": 3, "i_end": 5}, "verb": {"text": "related", "start": 109, "end": 116, "i_start": 18, "i_end": 18}}, {"character": {"text": "model", "start": 29, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "assumes", "start": 43, "end": 50, "i_start": 8, "i_end": 8}}], "id": 3947}, {"sent": "generative adversarial networks are a related class of deep generative models that have successfully modelled complex nonlinear distributions .", "tokens": ["generative", "adversarial", "networks", "are", "a", "related", "class", "of", "deep", "generative", "models", "that", "have", "successfully", "modelled", "complex", "nonlinear", "distributions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 71, "end": 77, "i_start": 10, "i_end": 10}, "action": {"text": "modelled", "start": 101, "end": 109, "i_start": 14, "i_end": 14}}], "id": 3948}, {"sent": "recently deep neural networks have made a great success in many real-world applications , such as image classification .", "tokens": ["recently", "deep", "neural", "networks", "have", "made", "a", "great", "success", "in", "many", "real", "-", "world", "applications", ",", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 9, "end": 29, "i_start": 1, "i_end": 3}, "verb": {"text": "have made", "start": 30, "end": 39, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 48, "end": 55, "i_start": 8, "i_end": 8}}], "id": 3949}, {"sent": "ternary matrices are an important subject of study in some fields of coding theory .", "tokens": ["ternary", "matrices", "are", "an", "important", "subject", "of", "study", "in", "some", "fields", "of", "coding", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "ternary matrices", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 17, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "fields", "start": 59, "end": 65, "i_start": 10, "i_end": 10}, "action": {"text": "study", "start": 45, "end": 50, "i_start": 7, "i_end": 7}}], "id": 3950}, {"sent": "quantum mechanics is a one dimensional field theory .", "tokens": ["quantum", "mechanics", "is", "a", "one", "dimensional", "field", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum mechanics", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}], "id": 3951}, {"sent": "deep convolutional neural networks have made significant breakthroughs in many visual understanding tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "significant", "breakthroughs", "in", "many", "visual", "understanding", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "breakthroughs", "start": 57, "end": 70, "i_start": 7, "i_end": 7}}], "id": 3952}, {"sent": "deep neural networks have achieved state-of-the-art performance on many machine learning tasks such as speech recognition .", "tokens": ["deep", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "many", "machine", "learning", "tasks", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 52, "end": 63, "i_start": 12, "i_end": 12}}], "id": 3953}, {"sent": "the belle detector is a large-solid-angle magnetic spectrometer that consists of a threelayer silicon vertex detector .", "tokens": ["the", "belle", "detector", "is", "a", "large", "-", "solid", "-", "angle", "magnetic", "spectrometer", "that", "consists", "of", "a", "threelayer", "silicon", "vertex", "detector", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the belle detector", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 3954}, {"sent": "the four panels correspond to the configurations and , respectively .", "tokens": ["the", "four", "panels", "correspond", "to", "the", "configurations", "and", ",", "respectively", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the four panels", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "correspond", "start": 16, "end": 26, "i_start": 3, "i_end": 3}}], "id": 3955}, {"sent": "we employ an architecture derived from alexnet and train multiple networks on the imagenet dataset .", "tokens": ["we", "employ", "an", "architecture", "derived", "from", "alexnet", "and", "train", "multiple", "networks", "on", "the", "imagenet", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 51, "end": 56, "i_start": 8, "i_end": 8}}], "id": 3956}, {"sent": "in recent years , deep reinforcement learning has made significant progress in many domains , such as video games , the game of go and continuous control tasks .", "tokens": ["in", "recent", "years", ",", "deep", "reinforcement", "learning", "has", "made", "significant", "progress", "in", "many", "domains", ",", "such", "as", "video", "games", ",", "the", "game", "of", "go", "and", "continuous", "control", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep reinforcement learning", "start": 18, "end": 45, "i_start": 4, "i_end": 6}, "verb": {"text": "has made", "start": 46, "end": 54, "i_start": 7, "i_end": 8}}], "id": 3957}, {"sent": "polar codes were originally proposed by arikan in to achieve the symmetric capacity of binary-input discrete memoryless channels .", "tokens": ["polar", "codes", "were", "originally", "proposed", "by", "arikan", "in", "to", "achieve", "the", "symmetric", "capacity", "of", "binary", "-", "input", "discrete", "memoryless", "channels", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "polar codes", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "proposed", "start": 28, "end": 36, "i_start": 4, "i_end": 4}}, {"subject": {"text": "polar codes", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "were", "start": 12, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "arikan", "start": 40, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "proposed", "start": 28, "end": 36, "i_start": 4, "i_end": 4}}, {"character": {"text": "codes", "start": 6, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "achieve", "start": 53, "end": 60, "i_start": 9, "i_end": 9}}, {"character": {"text": "channels", "start": 120, "end": 128, "i_start": 19, "i_end": 19}, "action": {"text": "-", "start": 93, "end": 94, "i_start": 15, "i_end": 15}}], "id": 3958}, {"sent": "for definitions and terms in the theory of vertex tensor categories , we refer the reader to .", "tokens": ["for", "definitions", "and", "terms", "in", "the", "theory", "of", "vertex", "tensor", "categories", ",", "we", "refer", "the", "reader", "to", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 70, "end": 72, "i_start": 12, "i_end": 12}, "verb": {"text": "refer", "start": 73, "end": 78, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 70, "end": 72, "i_start": 12, "i_end": 12}, "action": {"text": "refer", "start": 73, "end": 78, "i_start": 13, "i_end": 13}}], "id": 3959}, {"sent": "these are indicated by full circles in the plot .", "tokens": ["these", "are", "indicated", "by", "full", "circles", "in", "the", "plot", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "these", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "are indicated", "start": 6, "end": 19, "i_start": 1, "i_end": 2}}, {"character": {"text": "circles", "start": 28, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "indicated", "start": 10, "end": 19, "i_start": 2, "i_end": 2}}], "id": 3960}, {"sent": "finally , we show that the studied system allows for a violation of the svetlichny inequality , revealing genuine tripartite nonlocality in a broad parameter range .", "tokens": ["finally", ",", "we", "show", "that", "the", "studied", "system", "allows", "for", "a", "violation", "of", "the", "svetlichny", "inequality", ",", "revealing", "genuine", "tripartite", "nonlocality", "in", "a", "broad", "parameter", "range", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "show", "start": 13, "end": 17, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the studied system", "start": 23, "end": 41, "i_start": 5, "i_end": 7}, "verb": {"text": "allows", "start": 42, "end": 48, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 13, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "system", "start": 35, "end": 41, "i_start": 7, "i_end": 7}, "action": {"text": "allows", "start": 42, "end": 48, "i_start": 8, "i_end": 8}}], "id": 3961}, {"sent": "in recent years , a variety of novel approaches to the glass transition , both theoretical and phenomenological , stimulated new experimental investigations especially of the high-frequency dynamics of glass-forming liquids .", "tokens": ["in", "recent", "years", ",", "a", "variety", "of", "novel", "approaches", "to", "the", "glass", "transition", ",", "both", "theoretical", "and", "phenomenological", ",", "stimulated", "new", "experimental", "investigations", "especially", "of", "the", "high", "-", "frequency", "dynamics", "of", "glass", "-", "forming", "liquids", "."], "score": [0, 0, 1, 0, 1], "labels": [{"subject": {"text": "a variety of novel approaches to the glass transition", "start": 18, "end": 71, "i_start": 4, "i_end": 12}, "verb": {"text": "stimulated", "start": 114, "end": 124, "i_start": 19, "i_end": 19}}, {"character": {"text": "approaches", "start": 37, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "stimulated", "start": 114, "end": 124, "i_start": 19, "i_end": 19}}], "id": 3962}, {"sent": "ebert , kg klimenko , av tyukov and vc zhukovsky , eur .", "tokens": ["ebert", ",", "kg", "klimenko", ",", "av", "tyukov", "and", "vc", "zhukovsky", ",", "eur", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3963}, {"sent": "secondly , the ratio of the local length scale to the velocity at this scale .", "tokens": ["secondly", ",", "the", "ratio", "of", "the", "local", "length", "scale", "to", "the", "velocity", "at", "this", "scale", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3964}, {"sent": "c oded caching is a communication method invented in that exploits receiver-side caches in broadcast-type communications , to achieve substantial throughput gains by delivering independent content to many users at a time .", "tokens": ["c", "oded", "caching", "is", "a", "communication", "method", "invented", "in", "that", "exploits", "receiver", "-", "side", "caches", "in", "broadcast", "-", "type", "communications", ",", "to", "achieve", "substantial", "throughput", "gains", "by", "delivering", "independent", "content", "to", "many", "users", "at", "a", "time", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "c oded caching", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "method", "start": 34, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "exploits", "start": 58, "end": 66, "i_start": 10, "i_end": 10}}, {"character": {"text": "method", "start": 34, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "achieve", "start": 126, "end": 133, "i_start": 22, "i_end": 22}}, {"character": {"text": "method", "start": 34, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "gains", "start": 157, "end": 162, "i_start": 25, "i_end": 25}}, {"character": {"text": "method", "start": 34, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "delivering", "start": 166, "end": 176, "i_start": 27, "i_end": 27}}, {"character": {"text": "content", "start": 189, "end": 196, "i_start": 29, "i_end": 29}, "action": {"text": "-side caches in broadcast-type communications , to achieve substantial throughput gains by delivering independent", "start": 75, "end": 188, "i_start": 12, "i_end": 28}}], "id": 3965}, {"sent": "however , for the multivariate case these properties have been proven to be incompatible with guaranteeing nonnegativity , by using some counterexamples .", "tokens": ["however", ",", "for", "the", "multivariate", "case", "these", "properties", "have", "been", "proven", "to", "be", "incompatible", "with", "guaranteeing", "nonnegativity", ",", "by", "using", "some", "counterexamples", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "these properties", "start": 36, "end": 52, "i_start": 6, "i_end": 7}, "verb": {"text": "have been proven", "start": 53, "end": 69, "i_start": 8, "i_end": 10}}, {"character": {"text": "properties", "start": 42, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "guaranteeing", "start": 94, "end": 106, "i_start": 15, "i_end": 15}}], "id": 3966}, {"sent": "deep convolutional neural networks have shown tremendous success in a variety of computer vision tasks , such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "shown", "tremendous", "success", "in", "a", "variety", "of", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have shown", "start": 35, "end": 45, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 57, "end": 64, "i_start": 7, "i_end": 7}}], "id": 3967}, {"sent": "in order to provide performance numbers that are comparable to the proposed multiworld approach in malinowski and fritz , we also run our method on the reduced set with 37 object classes and only 25 images with 297 question-answer pairs at test time .", "tokens": ["in", "order", "to", "provide", "performance", "numbers", "that", "are", "comparable", "to", "the", "proposed", "multiworld", "approach", "in", "malinowski", "and", "fritz", ",", "we", "also", "run", "our", "method", "on", "the", "reduced", "set", "with", "37", "object", "classes", "and", "only", "25", "images", "with", "297", "question", "-", "answer", "pairs", "at", "test", "time", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 122, "end": 124, "i_start": 19, "i_end": 19}, "verb": {"text": "run", "start": 130, "end": 133, "i_start": 21, "i_end": 21}}, {"character": {"text": "we", "start": 122, "end": 124, "i_start": 19, "i_end": 19}, "action": {"text": "run", "start": 130, "end": 133, "i_start": 21, "i_end": 21}}], "id": 3968}, {"sent": "deep neural networks have made great strides in many computer vision tasks such as image classification .", "tokens": ["deep", "neural", "networks", "have", "made", "great", "strides", "in", "many", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have made", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "strides", "start": 37, "end": 44, "i_start": 6, "i_end": 6}}], "id": 3969}, {"sent": "using these iteration identities , several parseval goldstein type theorems for these transforms are given .", "tokens": ["using", "these", "iteration", "identities", ",", "several", "parseval", "goldstein", "type", "theorems", "for", "these", "transforms", "are", "given", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "several parseval goldstein type theorems for these transforms", "start": 35, "end": 96, "i_start": 5, "i_end": 12}, "verb": {"text": "are given", "start": 97, "end": 106, "i_start": 13, "i_end": 14}}], "id": 3970}, {"sent": "these calculations consist of computing single-nucleon loops leading to a linear dependence on the density of the parameters .", "tokens": ["these", "calculations", "consist", "of", "computing", "single", "-", "nucleon", "loops", "leading", "to", "a", "linear", "dependence", "on", "the", "density", "of", "the", "parameters", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these calculations", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "consist", "start": 19, "end": 26, "i_start": 2, "i_end": 2}}], "id": 3971}, {"sent": "evolution of the azimuthally averaged surface density of the viscous ring at three different times , applying only artificial bulk viscosity .", "tokens": ["evolution", "of", "the", "azimuthally", "averaged", "surface", "density", "of", "the", "viscous", "ring", "at", "three", "different", "times", ",", "applying", "only", "artificial", "bulk", "viscosity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "evolution", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "applying", "start": 101, "end": 109, "i_start": 16, "i_end": 16}}], "id": 3972}, {"sent": "the block keys , bk , is an b-element array which encodes the keys of the tree block .", "tokens": ["the", "block", "keys", ",", "bk", ",", "is", "an", "b", "-", "element", "array", "which", "encodes", "the", "keys", "of", "the", "tree", "block", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the block keys , bk", "start": 0, "end": 19, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 6, "i_end": 6}}, {"character": {"text": "array", "start": 38, "end": 43, "i_start": 11, "i_end": 11}, "action": {"text": "encodes", "start": 50, "end": 57, "i_start": 13, "i_end": 13}}], "id": 3973}, {"sent": "many researchers have focused on developing deep neural network models .", "tokens": ["many", "researchers", "have", "focused", "on", "developing", "deep", "neural", "network", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "many researchers", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "have focused", "start": 17, "end": 29, "i_start": 2, "i_end": 3}}, {"character": {"text": "many", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "focused", "start": 22, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "many", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "developing", "start": 33, "end": 43, "i_start": 5, "i_end": 5}}], "id": 3974}, {"sent": "we now apply the expectation-maximisation algorithm to optimise our objective l .", "tokens": ["we", "now", "apply", "the", "expectation", "-", "maximisation", "algorithm", "to", "optimise", "our", "objective", "l", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "apply", "start": 7, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "apply", "start": 7, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimise", "start": 55, "end": 63, "i_start": 9, "i_end": 9}}], "id": 3975}, {"sent": "the pbe form of the generalized gradient approximation was used as exchange and correlation functional .", "tokens": ["the", "pbe", "form", "of", "the", "generalized", "gradient", "approximation", "was", "used", "as", "exchange", "and", "correlation", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the pbe form of the generalized gradient approximation", "start": 0, "end": 54, "i_start": 0, "i_end": 7}, "verb": {"text": "was used", "start": 55, "end": 63, "i_start": 8, "i_end": 9}}], "id": 3976}, {"sent": "asterisk denotes the classes for which we were not able to find examples .", "tokens": ["asterisk", "denotes", "the", "classes", "for", "which", "we", "were", "not", "able", "to", "find", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "asterisk", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "denotes", "start": 9, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "asterisk", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "denotes", "start": 9, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 39, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "find", "start": 59, "end": 63, "i_start": 11, "i_end": 11}}], "id": 3977}, {"sent": "of the nine entries in table 4 of , four are hyperelliptic , four are cyclic trigonal , and one is general trigonal .", "tokens": ["of", "the", "nine", "entries", "in", "table", "4", "of", ",", "four", "are", "hyperelliptic", ",", "four", "are", "cyclic", "trigonal", ",", "and", "one", "is", "general", "trigonal", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "four", "start": 61, "end": 65, "i_start": 13, "i_end": 13}, "verb": {"text": "are", "start": 66, "end": 69, "i_start": 14, "i_end": 14}}, {"subject": {"text": "four", "start": 61, "end": 65, "i_start": 13, "i_end": 13}, "verb": {"text": "are", "start": 41, "end": 44, "i_start": 10, "i_end": 10}}], "id": 3978}, {"sent": "a curve is self-transversal if and only if its chart is straight .", "tokens": ["a", "curve", "is", "self", "-", "transversal", "if", "and", "only", "if", "its", "chart", "is", "straight", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a curve", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 2, "i_end": 2}}, {"character": {"text": "curve", "start": 2, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "transversal", "start": 16, "end": 27, "i_start": 5, "i_end": 5}}], "id": 3979}, {"sent": "the fakelepton control samples in data are used to determine starting values for the final full fit to all data samples .", "tokens": ["the", "fakelepton", "control", "samples", "in", "data", "are", "used", "to", "determine", "starting", "values", "for", "the", "final", "full", "fit", "to", "all", "data", "samples", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the fakelepton control samples in data", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "are used", "start": 39, "end": 47, "i_start": 6, "i_end": 7}}], "id": 3980}, {"sent": "the splitting theorem for riemannian manifolds have been investigated in .", "tokens": ["the", "splitting", "theorem", "for", "riemannian", "manifolds", "have", "been", "investigated", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the splitting theorem for riemannian manifolds", "start": 0, "end": 46, "i_start": 0, "i_end": 5}, "verb": {"text": "have been investigated", "start": 47, "end": 69, "i_start": 6, "i_end": 8}}], "id": 3981}, {"sent": "ultracold atomic gases have attracted considerable interest since the successful realization of bose-einstein condensation in a bosonic 87 rb system .", "tokens": ["ultracold", "atomic", "gases", "have", "attracted", "considerable", "interest", "since", "the", "successful", "realization", "of", "bose", "-", "einstein", "condensation", "in", "a", "bosonic", "87", "rb", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "ultracold atomic gases", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "have attracted", "start": 23, "end": 37, "i_start": 3, "i_end": 4}}, {"character": {"text": "gases", "start": 17, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "attracted", "start": 28, "end": 37, "i_start": 4, "i_end": 4}}], "id": 3982}, {"sent": "the exponentials are calculated with the star-product .", "tokens": ["the", "exponentials", "are", "calculated", "with", "the", "star", "-", "product", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exponentials", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "are calculated", "start": 17, "end": 31, "i_start": 2, "i_end": 3}}], "id": 3983}, {"sent": "such a policy is called an optimal policy .", "tokens": ["such", "a", "policy", "is", "called", "an", "optimal", "policy", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such a policy", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 14, "end": 23, "i_start": 3, "i_end": 4}}], "id": 3984}, {"sent": "the part which describes the strong nuclear force is called quantum chromodynamics .", "tokens": ["the", "part", "which", "describes", "the", "strong", "nuclear", "force", "is", "called", "quantum", "chromodynamics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the part which describes the strong nuclear force", "start": 0, "end": 49, "i_start": 0, "i_end": 7}, "verb": {"text": "is called", "start": 50, "end": 59, "i_start": 8, "i_end": 9}}], "id": 3985}, {"sent": "the pulsar is the brightest point source in four 12h observations at 8 4 ghz made with atca , at 0 1 arcsec resolution .", "tokens": ["the", "pulsar", "is", "the", "brightest", "point", "source", "in", "four", "12h", "observations", "at", "8", "4", "ghz", "made", "with", "atca", ",", "at", "0", "1", "arcsec", "resolution", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the pulsar", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}], "id": 3986}, {"sent": "let us to obtain the lagrangian version of this system .", "tokens": ["let", "us", "to", "obtain", "the", "lagrangian", "version", "of", "this", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "obtain", "start": 10, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "obtain", "start": 10, "end": 16, "i_start": 3, "i_end": 3}}], "id": 3987}, {"sent": "the mwa data were calibrated with the common astronomy software applications , using observations of a calibrator source .", "tokens": ["the", "mwa", "data", "were", "calibrated", "with", "the", "common", "astronomy", "software", "applications", ",", "using", "observations", "of", "a", "calibrator", "source", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the mwa data", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "were calibrated", "start": 13, "end": 28, "i_start": 3, "i_end": 4}}, {"character": {"text": "source", "start": 114, "end": 120, "i_start": 17, "i_end": 17}, "action": {"text": "observations", "start": 85, "end": 97, "i_start": 13, "i_end": 13}}], "id": 3988}, {"sent": "the readers who are interested in this topic can see , chartrand et al generalized the concept of rainbow connection to rainbow index .", "tokens": ["the", "readers", "who", "are", "interested", "in", "this", "topic", "can", "see", ",", "chartrand", "et", "al", "generalized", "the", "concept", "of", "rainbow", "connection", "to", "rainbow", "index", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "chartrand et al", "start": 55, "end": 70, "i_start": 11, "i_end": 13}, "verb": {"text": "generalized", "start": 71, "end": 82, "i_start": 14, "i_end": 14}}, {"subject": {"text": "the readers who are interested in this topic", "start": 0, "end": 44, "i_start": 0, "i_end": 7}, "verb": {"text": "see", "start": 49, "end": 52, "i_start": 9, "i_end": 9}}, {"character": {"text": "this", "start": 34, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "see", "start": 49, "end": 52, "i_start": 9, "i_end": 9}}, {"character": {"text": "chartrand", "start": 55, "end": 64, "i_start": 11, "i_end": 11}, "action": {"text": "generalized", "start": 71, "end": 82, "i_start": 14, "i_end": 14}}], "id": 3989}, {"sent": "a cell cycle consists of four distinct and separate phases named g1 , s , g2 and m .", "tokens": ["a", "cell", "cycle", "consists", "of", "four", "distinct", "and", "separate", "phases", "named", "g1", ",", "s", ",", "g2", "and", "m", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a cell cycle", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}], "id": 3990}, {"sent": "such an eigenvalue is called the principal eigenvalue .", "tokens": ["such", "an", "eigenvalue", "is", "called", "the", "principal", "eigenvalue", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such an eigenvalue", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 19, "end": 28, "i_start": 3, "i_end": 4}}], "id": 3991}, {"sent": "in this section we explain the particulars of the model and review the main results obtained in .", "tokens": ["in", "this", "section", "we", "explain", "the", "particulars", "of", "the", "model", "and", "review", "the", "main", "results", "obtained", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "explain", "start": 19, "end": 26, "i_start": 4, "i_end": 4}}, {"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "review", "start": 60, "end": 66, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "explain", "start": 19, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "review", "start": 60, "end": 66, "i_start": 11, "i_end": 11}}], "id": 3992}, {"sent": "loop quantum cosmology is a mathematically consistent theory of quantum cosmological space-times .", "tokens": ["loop", "quantum", "cosmology", "is", "a", "mathematically", "consistent", "theory", "of", "quantum", "cosmological", "space", "-", "times", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "loop quantum cosmology", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}], "id": 3993}, {"sent": "mechanical properties of internal human soft tissues .", "tokens": ["mechanical", "properties", "of", "internal", "human", "soft", "tissues", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 3994}, {"sent": "we employ the gated recurrent units to implement the rnn model in this work .", "tokens": ["we", "employ", "the", "gated", "recurrent", "units", "to", "implement", "the", "rnn", "model", "in", "this", "work", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "units", "start": 30, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "implement", "start": 39, "end": 48, "i_start": 7, "i_end": 7}}], "id": 3995}, {"sent": "convolutional networks have recently demonstrated impressive progress in a variety of image classification and recognition tasks .", "tokens": ["convolutional", "networks", "have", "recently", "demonstrated", "impressive", "progress", "in", "a", "variety", "of", "image", "classification", "and", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional networks", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "demonstrated", "start": 37, "end": 49, "i_start": 4, "i_end": 4}}, {"subject": {"text": "convolutional networks", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "have", "start": 23, "end": 27, "i_start": 2, "i_end": 2}}, {"character": {"text": "networks", "start": 14, "end": 22, "i_start": 1, "i_end": 1}, "action": {"text": "demonstrated", "start": 37, "end": 49, "i_start": 4, "i_end": 4}}, {"character": {"text": "progress", "start": 61, "end": 69, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 50, "end": 60, "i_start": 5, "i_end": 5}}], "id": 3996}, {"sent": "large deep neural networks have enabled breakthroughs in fields such as computer vision , speech recognition , and reinforcement learning .", "tokens": ["large", "deep", "neural", "networks", "have", "enabled", "breakthroughs", "in", "fields", "such", "as", "computer", "vision", ",", "speech", "recognition", ",", "and", "reinforcement", "learning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "large deep neural networks", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "have enabled", "start": 27, "end": 39, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 18, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "enabled", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}], "id": 3997}, {"sent": "thus , one might expect that the cantilever measures the spin component along the effective magnetic field in the rotating reference frame .", "tokens": ["thus", ",", "one", "might", "expect", "that", "the", "cantilever", "measures", "the", "spin", "component", "along", "the", "effective", "magnetic", "field", "in", "the", "rotating", "reference", "frame", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 7, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "might expect", "start": 11, "end": 23, "i_start": 3, "i_end": 4}}, {"subject": {"text": "the cantilever", "start": 29, "end": 43, "i_start": 6, "i_end": 7}, "verb": {"text": "measures", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "one", "start": 7, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "expect", "start": 17, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "cantilever", "start": 33, "end": 43, "i_start": 7, "i_end": 7}, "action": {"text": "measures", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "field", "start": 101, "end": 106, "i_start": 16, "i_end": 16}, "action": {"text": "effective", "start": 82, "end": 91, "i_start": 14, "i_end": 14}}], "id": 3998}, {"sent": "a perdew-burke-ernzerhof form of generalized gradient approximation was employed as the exchange-correlation functional .", "tokens": ["a", "perdew", "-", "burke", "-", "ernzerhof", "form", "of", "generalized", "gradient", "approximation", "was", "employed", "as", "the", "exchange", "-", "correlation", "functional", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a perdew-burke-ernzerhof form of generalized gradient approximation", "start": 0, "end": 67, "i_start": 0, "i_end": 10}, "verb": {"text": "was employed", "start": 68, "end": 80, "i_start": 11, "i_end": 12}}], "id": 3999}, {"sent": "this can be seen by applying the seiberg-witten map to the above configuration .", "tokens": ["this", "can", "be", "seen", "by", "applying", "the", "seiberg", "-", "witten", "map", "to", "the", "above", "configuration", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "can be seen", "start": 5, "end": 16, "i_start": 1, "i_end": 3}}], "id": 4000}, {"sent": "such within-view neighborhood preservation constraints have been extensively explored in the metric learning literature .", "tokens": ["such", "within", "-", "view", "neighborhood", "preservation", "constraints", "have", "been", "extensively", "explored", "in", "the", "metric", "learning", "literature", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such within-view neighborhood preservation constraints", "start": 0, "end": 54, "i_start": 0, "i_end": 6}, "verb": {"text": "explored", "start": 77, "end": 85, "i_start": 10, "i_end": 10}}, {"subject": {"text": "such within-view neighborhood preservation constraints", "start": 0, "end": 54, "i_start": 0, "i_end": 6}, "verb": {"text": "have been", "start": 55, "end": 64, "i_start": 7, "i_end": 8}}], "id": 4001}, {"sent": "quantum mechanics is a good example of this where dirac invented his own mathematics in his formulation of quantum mechanics .", "tokens": ["quantum", "mechanics", "is", "a", "good", "example", "of", "this", "where", "dirac", "invented", "his", "own", "mathematics", "in", "his", "formulation", "of", "quantum", "mechanics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quantum mechanics", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "dirac", "start": 50, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "invented", "start": 56, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "dirac", "start": 50, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "formulation", "start": 92, "end": 103, "i_start": 16, "i_end": 16}}], "id": 4002}, {"sent": "the neutrosophy is a new branch of philosophy , introduced by florentin smarandache in .", "tokens": ["the", "neutrosophy", "is", "a", "new", "branch", "of", "philosophy", ",", "introduced", "by", "florentin", "smarandache", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the neutrosophy", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "florentin smarandache", "start": 62, "end": 83, "i_start": 11, "i_end": 12}, "action": {"text": "introduced", "start": 48, "end": 58, "i_start": 9, "i_end": 9}}], "id": 4003}, {"sent": "the t -duality is a symmetry of the string theory .", "tokens": ["the", "t", "-duality", "is", "a", "symmetry", "of", "the", "string", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the t -duality", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}], "id": 4004}, {"sent": "in this work we review some recent development in the mathematical modeling of quantitative sociology by means of statistical mechanics .", "tokens": ["in", "this", "work", "we", "review", "some", "recent", "development", "in", "the", "mathematical", "modeling", "of", "quantitative", "sociology", "by", "means", "of", "statistical", "mechanics", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "review", "start": 16, "end": 22, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "review", "start": 16, "end": 22, "i_start": 4, "i_end": 4}}], "id": 4005}, {"sent": "in this paper we propose to use object proposals methods , which are designed to directly provide a segmentation of the object , for the computation of context-based saliency .", "tokens": ["in", "this", "paper", "we", "propose", "to", "use", "object", "proposals", "methods", ",", "which", "are", "designed", "to", "directly", "provide", "a", "segmentation", "of", "the", "object", ",", "for", "the", "computation", "of", "context", "-", "based", "saliency", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "propose", "start": 17, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "propose", "start": 17, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 28, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "methods", "start": 49, "end": 56, "i_start": 9, "i_end": 9}, "action": {"text": "provide", "start": 90, "end": 97, "i_start": 16, "i_end": 16}}], "id": 4006}, {"sent": "spin-dependent conductance quantization in nickel point contacts .", "tokens": ["spin", "-", "dependent", "conductance", "quantization", "in", "nickel", "point", "contacts", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "spin", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "dependent", "start": 5, "end": 14, "i_start": 2, "i_end": 2}}], "id": 4007}, {"sent": "calculations are done for the neutron-rich oxygen isotopes .", "tokens": ["calculations", "are", "done", "for", "the", "neutron", "-", "rich", "oxygen", "isotopes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "calculations", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "are done", "start": 13, "end": 21, "i_start": 1, "i_end": 2}}], "id": 4008}, {"sent": "when two voas are the same , such a linear isomorphism is called an automorphism .", "tokens": ["when", "two", "voas", "are", "the", "same", ",", "such", "a", "linear", "isomorphism", "is", "called", "an", "automorphism", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such a linear isomorphism", "start": 29, "end": 54, "i_start": 7, "i_end": 10}, "verb": {"text": "is called", "start": 55, "end": 64, "i_start": 11, "i_end": 12}}], "id": 4009}, {"sent": "multi-layer convolutional neural networks pioneered by lecun et al have led to breakthrough results , constituting the state-of-the art technology for many challenges such as imagenet .", "tokens": ["multi", "-", "layer", "convolutional", "neural", "networks", "pioneered", "by", "lecun", "et", "al", "have", "led", "to", "breakthrough", "results", ",", "constituting", "the", "state", "-", "of", "-", "the", "art", "technology", "for", "many", "challenges", "such", "as", "imagenet", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "multi-layer convolutional neural networks pioneered by lecun et al", "start": 0, "end": 66, "i_start": 0, "i_end": 10}, "verb": {"text": "have led", "start": 67, "end": 75, "i_start": 11, "i_end": 12}}, {"character": {"text": "networks", "start": 33, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "led", "start": 72, "end": 75, "i_start": 12, "i_end": 12}}, {"character": {"text": "lecun", "start": 55, "end": 60, "i_start": 8, "i_end": 8}, "action": {"text": "pioneered", "start": 42, "end": 51, "i_start": 6, "i_end": 6}}], "id": 4010}, {"sent": "convolutional neural networks have shown promise for classification tasks in computer vision .", "tokens": ["convolutional", "neural", "networks", "have", "shown", "promise", "for", "classification", "tasks", "in", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "promise", "start": 41, "end": 48, "i_start": 5, "i_end": 5}}], "id": 4011}, {"sent": "belle is a general-purpose detector with a silicon vertex detector .", "tokens": ["belle", "is", "a", "general", "-", "purpose", "detector", "with", "a", "silicon", "vertex", "detector", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "belle", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 1, "i_end": 1}}], "id": 4012}, {"sent": "all these parameters are detailed in table xviii .", "tokens": ["all", "these", "parameters", "are", "detailed", "in", "table", "xviii", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all these parameters", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are detailed", "start": 21, "end": 33, "i_start": 3, "i_end": 4}}], "id": 4013}, {"sent": "all calculations have been carried out using the projected augmented-wave formalism as implemented in the vienna ab initio simulation package .", "tokens": ["all", "calculations", "have", "been", "carried", "out", "using", "the", "projected", "augmented", "-", "wave", "formalism", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all calculations", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "have been carried out", "start": 17, "end": 38, "i_start": 2, "i_end": 5}}], "id": 4014}, {"sent": "plots of amplitude versus redshift and absolute magnitude for the most variable quasars in the sample .", "tokens": ["plots", "of", "amplitude", "versus", "redshift", "and", "absolute", "magnitude", "for", "the", "most", "variable", "quasars", "in", "the", "sample", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4015}, {"sent": "we further evaluate our approach on scannet dataset , which contains 1513 real-world scans .", "tokens": ["we", "further", "evaluate", "our", "approach", "on", "scannet", "dataset", ",", "which", "contains", "1513", "real", "-", "world", "scans", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "approach", "start": 24, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "dataset", "start": 44, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "contains", "start": 60, "end": 68, "i_start": 10, "i_end": 10}}], "id": 4016}, {"sent": "so what emerges is a semantic network , with a directed flow of meaning , determined by the direction of the links .", "tokens": ["so", "what", "emerges", "is", "a", "semantic", "network", ",", "with", "a", "directed", "flow", "of", "meaning", ",", "determined", "by", "the", "direction", "of", "the", "links", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "what emerges", "start": 3, "end": 15, "i_start": 1, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "network", "start": 30, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "emerges", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "network", "start": 30, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "flow", "start": 56, "end": 60, "i_start": 11, "i_end": 11}}, {"character": {"text": "direction", "start": 92, "end": 101, "i_start": 18, "i_end": 18}, "action": {"text": "determined", "start": 74, "end": 84, "i_start": 15, "i_end": 15}}], "id": 4017}, {"sent": "isola et al presented a unified pix2pix framework for learning image-to-image translation from paired data .", "tokens": ["isola", "et", "al", "presented", "a", "unified", "pix2pix", "framework", "for", "learning", "image", "-", "to", "-", "image", "translation", "from", "paired", "data", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 6, "end": 11, "i_start": 1, "i_end": 2}, "verb": {"text": "presented", "start": 12, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "isola", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "presented", "start": 12, "end": 21, "i_start": 3, "i_end": 3}}], "id": 4018}, {"sent": "recently , approaches that extract features with deep learning structures , the deep cnns in particular , have shown great potential in various computer vision tasks , including image classification .", "tokens": ["recently", ",", "approaches", "that", "extract", "features", "with", "deep", "learning", "structures", ",", "the", "deep", "cnns", "in", "particular", ",", "have", "shown", "great", "potential", "in", "various", "computer", "vision", "tasks", ",", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "approaches that extract features with deep learning structures", "start": 11, "end": 73, "i_start": 2, "i_end": 9}, "verb": {"text": "have shown", "start": 106, "end": 116, "i_start": 17, "i_end": 18}}, {"character": {"text": "approaches", "start": 11, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 111, "end": 116, "i_start": 18, "i_end": 18}}, {"character": {"text": "approaches", "start": 11, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "extract", "start": 27, "end": 34, "i_start": 4, "i_end": 4}}], "id": 4019}, {"sent": "we will illustrate this situation by some simple examples .", "tokens": ["we", "will", "illustrate", "this", "situation", "by", "some", "simple", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will illustrate", "start": 3, "end": 18, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "illustrate", "start": 8, "end": 18, "i_start": 2, "i_end": 2}}], "id": 4020}, {"sent": "despite their successful application to several machine learning tasks , deep neural networks have been shown to be vulnerable .", "tokens": ["despite", "their", "successful", "application", "to", "several", "machine", "learning", "tasks", ",", "deep", "neural", "networks", "have", "been", "shown", "to", "be", "vulnerable", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 73, "end": 93, "i_start": 10, "i_end": 12}, "verb": {"text": "have been shown", "start": 94, "end": 109, "i_start": 13, "i_end": 15}}, {"character": {"text": "networks", "start": 85, "end": 93, "i_start": 12, "i_end": 12}, "action": {"text": "successful", "start": 14, "end": 24, "i_start": 2, "i_end": 2}}], "id": 4021}, {"sent": "laboratory astrophysics comprises both theoretical and experimental studies of the underlying physics that produce the observed astrophysical processes .", "tokens": ["laboratory", "astrophysics", "comprises", "both", "theoretical", "and", "experimental", "studies", "of", "the", "underlying", "physics", "that", "produce", "the", "observed", "astrophysical", "processes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "laboratory astrophysics", "start": 0, "end": 23, "i_start": 0, "i_end": 1}, "verb": {"text": "comprises", "start": 24, "end": 33, "i_start": 2, "i_end": 2}}, {"character": {"text": "physics", "start": 94, "end": 101, "i_start": 11, "i_end": 11}, "action": {"text": "underlying", "start": 83, "end": 93, "i_start": 10, "i_end": 10}}, {"character": {"text": "physics", "start": 94, "end": 101, "i_start": 11, "i_end": 11}, "action": {"text": "produce", "start": 107, "end": 114, "i_start": 13, "i_end": 13}}], "id": 4022}, {"sent": "a consensus has been reached that a reasonable observer will observe a local expansion rate .", "tokens": ["a", "consensus", "has", "been", "reached", "that", "a", "reasonable", "observer", "will", "observe", "a", "local", "expansion", "rate", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a consensus has been reached that a reasonable observer will observe a local expansion rate", "start": 0, "end": 91, "i_start": 0, "i_end": 14}, "verb": {"text": "has been reached", "start": 12, "end": 28, "i_start": 2, "i_end": 4}}], "id": 4023}, {"sent": "more recently , chudnovsky and seymour published a series of excellent papers in journal of combinatorial theory series b on this topic .", "tokens": ["more", "recently", ",", "chudnovsky", "and", "seymour", "published", "a", "series", "of", "excellent", "papers", "in", "journal", "of", "combinatorial", "theory", "series", "b", "on", "this", "topic", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "chudnovsky", "start": 16, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "published", "start": 39, "end": 48, "i_start": 6, "i_end": 6}}, {"character": {"text": "seymour", "start": 31, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "published", "start": 39, "end": 48, "i_start": 6, "i_end": 6}}], "id": 4024}, {"sent": "further investigation of the geometry of requires the solution of the field equations .", "tokens": ["further", "investigation", "of", "the", "geometry", "of", "requires", "the", "solution", "of", "the", "field", "equations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "further investigation of the geometry of", "start": 0, "end": 40, "i_start": 0, "i_end": 5}, "verb": {"text": "requires", "start": 41, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "investigation", "start": 8, "end": 21, "i_start": 1, "i_end": 1}, "action": {"text": "requires", "start": 41, "end": 49, "i_start": 6, "i_end": 6}}], "id": 4025}, {"sent": "artemov developed the first justification logic , the logic of proofs , to provide intuitionistic logic with a classical provability semantics .", "tokens": ["artemov", "developed", "the", "first", "justification", "logic", ",", "the", "logic", "of", "proofs", ",", "to", "provide", "intuitionistic", "logic", "with", "a", "classical", "provability", "semantics", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "artemov", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "developed", "start": 8, "end": 17, "i_start": 1, "i_end": 1}}, {"character": {"text": "artemov", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "developed", "start": 8, "end": 17, "i_start": 1, "i_end": 1}}, {"character": {"text": "logic", "start": 42, "end": 47, "i_start": 5, "i_end": 5}, "action": {"text": "justification", "start": 28, "end": 41, "i_start": 4, "i_end": 4}}], "id": 4026}, {"sent": "neural networks have been shown to be adept at discerning patterns in diverse data sets , and are being applied successfully to problems in image and video recognition , as well as many other challenging tasks .", "tokens": ["neural", "networks", "have", "been", "shown", "to", "be", "adept", "at", "discerning", "patterns", "in", "diverse", "data", "sets", ",", "and", "are", "being", "applied", "successfully", "to", "problems", "in", "image", "and", "video", "recognition", ",", "as", "well", "as", "many", "other", "challenging", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have been shown", "start": 16, "end": 31, "i_start": 2, "i_end": 4}}, {"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "applied", "start": 104, "end": 111, "i_start": 19, "i_end": 19}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "discerning", "start": 47, "end": 57, "i_start": 9, "i_end": 9}}], "id": 4027}, {"sent": "all models were trained using the adam optimizer , with a 1-cycle learning rate policy and dropout regularization .", "tokens": ["all", "models", "were", "trained", "using", "the", "adam", "optimizer", ",", "with", "a", "1", "-", "cycle", "learning", "rate", "policy", "and", "dropout", "regularization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all models", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "were trained", "start": 11, "end": 23, "i_start": 2, "i_end": 3}}], "id": 4028}, {"sent": "we conduct experiments on two challenging video datasets with human actions , namely hmdb51 .", "tokens": ["we", "conduct", "experiments", "on", "two", "challenging", "video", "datasets", "with", "human", "actions", ",", "namely", "hmdb51", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "conduct", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "conduct", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "experiments", "start": 11, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "two challenging video datasets", "start": 26, "end": 56, "i_start": 4, "i_end": 7}, "action": {"text": "challenging", "start": 30, "end": 41, "i_start": 5, "i_end": 5}}], "id": 4029}, {"sent": "in spite of the efforts made during the last years in order to investigate the phase structure of qcd , the behavior of quark matter in many regions of the mentioned above extended phase diagram is not known .", "tokens": ["in", "spite", "of", "the", "efforts", "made", "during", "the", "last", "years", "in", "order", "to", "investigate", "the", "phase", "structure", "of", "qcd", ",", "the", "behavior", "of", "quark", "matter", "in", "many", "regions", "of", "the", "mentioned", "above", "extended", "phase", "diagram", "is", "not", "known", "."], "score": [1, 1, 0, 1, 1], "labels": [{"subject": {"text": "the phase structure of qcd", "start": 75, "end": 101, "i_start": 14, "i_end": 18}, "verb": {"text": "is not known", "start": 195, "end": 207, "i_start": 35, "i_end": 37}}, {"character": {"text": "matter", "start": 126, "end": 132, "i_start": 24, "i_end": 24}, "action": {"text": "behavior", "start": 108, "end": 116, "i_start": 21, "i_end": 21}}], "id": 4030}, {"sent": "finally , we provide an alternative formula for the mhv amplitude based on bcfw recursion in twistor space .", "tokens": ["finally", ",", "we", "provide", "an", "alternative", "formula", "for", "the", "mhv", "amplitude", "based", "on", "bcfw", "recursion", "in", "twistor", "space", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "provide", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "provide", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}], "id": 4031}, {"sent": "with their high mobility and reducing cost , unmanned aerial vehicles have found applications in wireless communication systems .", "tokens": ["with", "their", "high", "mobility", "and", "reducing", "cost", ",", "unmanned", "aerial", "vehicles", "have", "found", "applications", "in", "wireless", "communication", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "unmanned aerial vehicles", "start": 45, "end": 69, "i_start": 8, "i_end": 10}, "verb": {"text": "have found", "start": 70, "end": 80, "i_start": 11, "i_end": 12}}, {"character": {"text": "vehicles", "start": 61, "end": 69, "i_start": 10, "i_end": 10}, "action": {"text": "found", "start": 75, "end": 80, "i_start": 12, "i_end": 12}}, {"character": {"text": "vehicles", "start": 61, "end": 69, "i_start": 10, "i_end": 10}, "action": {"text": "reducing", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}], "id": 4032}, {"sent": "having discussed the evolution of the underlying homogeneous base state we now turn to the linearised dynamics of the heterogeneous perturbations .", "tokens": ["having", "discussed", "the", "evolution", "of", "the", "underlying", "homogeneous", "base", "state", "we", "now", "turn", "to", "the", "linearised", "dynamics", "of", "the", "heterogeneous", "perturbations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 72, "end": 74, "i_start": 10, "i_end": 10}, "action": {"text": "discussed", "start": 7, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "state", "start": 66, "end": 71, "i_start": 9, "i_end": 9}, "action": {"text": "underlying", "start": 38, "end": 48, "i_start": 6, "i_end": 6}}], "id": 4033}, {"sent": "a particle-flow algorithm is used to reconstruct and identify each individual particle in an event using an optimized combination of information from the various elements of the cms detector .", "tokens": ["a", "particle", "-", "flow", "algorithm", "is", "used", "to", "reconstruct", "and", "identify", "each", "individual", "particle", "in", "an", "event", "using", "an", "optimized", "combination", "of", "information", "from", "the", "various", "elements", "of", "the", "cms", "detector", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a particle-flow algorithm", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "is used", "start": 26, "end": 33, "i_start": 5, "i_end": 6}}], "id": 4034}, {"sent": "deep learning has been widely applied to various computer vision tasks such as image classification , etc .", "tokens": ["deep", "learning", "has", "been", "widely", "applied", "to", "various", "computer", "vision", "tasks", "such", "as", "image", "classification", ",", "etc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "applied", "start": 30, "end": 37, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has been", "start": 14, "end": 22, "i_start": 2, "i_end": 3}}], "id": 4035}, {"sent": "in the next section we analyze the relevant length scales for structure formation in the mirror photon-baryonic sector .", "tokens": ["in", "the", "next", "section", "we", "analyze", "the", "relevant", "length", "scales", "for", "structure", "formation", "in", "the", "mirror", "photon", "-", "baryonic", "sector", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 20, "end": 22, "i_start": 4, "i_end": 4}, "verb": {"text": "analyze", "start": 23, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 20, "end": 22, "i_start": 4, "i_end": 4}, "action": {"text": "analyze", "start": 23, "end": 30, "i_start": 5, "i_end": 5}}], "id": 4036}, {"sent": "we employ vgg-16 layer net as our encoder f enc , and the feature descriptor a is obtained from the last convolutional layer to retain spatial information in input image .", "tokens": ["we", "employ", "vgg-16", "layer", "net", "as", "our", "encoder", "f", "enc", ",", "and", "the", "feature", "descriptor", "a", "is", "obtained", "from", "the", "last", "convolutional", "layer", "to", "retain", "spatial", "information", "in", "input", "image", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the feature descriptor a", "start": 54, "end": 78, "i_start": 12, "i_end": 15}, "verb": {"text": "obtained", "start": 82, "end": 90, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "layer", "start": 119, "end": 124, "i_start": 22, "i_end": 22}, "action": {"text": "retain", "start": 128, "end": 134, "i_start": 24, "i_end": 24}}], "id": 4037}, {"sent": "generative adversarial networks provide an important approach for learning a generative model which generates samples from the real-world data distribution .", "tokens": ["generative", "adversarial", "networks", "provide", "an", "important", "approach", "for", "learning", "a", "generative", "model", "which", "generates", "samples", "from", "the", "real", "-", "world", "data", "distribution", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "provide", "start": 32, "end": 39, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "provide", "start": 32, "end": 39, "i_start": 3, "i_end": 3}}, {"character": {"text": "model", "start": 88, "end": 93, "i_start": 11, "i_end": 11}, "action": {"text": "generates", "start": 100, "end": 109, "i_start": 13, "i_end": 13}}], "id": 4038}, {"sent": "we then consider the asymptotical sf networks generated with the static model .", "tokens": ["we", "then", "consider", "the", "asymptotical", "sf", "networks", "generated", "with", "the", "static", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "consider", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "consider", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}], "id": 4039}, {"sent": "multi-task learning aims to boost the generalization performance by learning multiple related tasks simultaneously .", "tokens": ["multi", "-", "task", "learning", "aims", "to", "boost", "the", "generalization", "performance", "by", "learning", "multiple", "related", "tasks", "simultaneously", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "multi-task learning", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "aims", "start": 20, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 68, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "aims", "start": 20, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 68, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "boost", "start": 28, "end": 33, "i_start": 6, "i_end": 6}}], "id": 4040}, {"sent": "when the orbit is a collection of line segments , such an unfolding will be a straight line .", "tokens": ["when", "the", "orbit", "is", "a", "collection", "of", "line", "segments", ",", "such", "an", "unfolding", "will", "be", "a", "straight", "line", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "such an unfolding", "start": 50, "end": 67, "i_start": 10, "i_end": 12}, "verb": {"text": "will be", "start": 68, "end": 75, "i_start": 13, "i_end": 14}}], "id": 4041}, {"sent": "to solve the problem , we adopt the reinforce algorithm .", "tokens": ["to", "solve", "the", "problem", ",", "we", "adopt", "the", "reinforce", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "verb": {"text": "adopt", "start": 26, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "action": {"text": "adopt", "start": 26, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "algorithm", "start": 46, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "reinforce", "start": 36, "end": 45, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 5, "i_end": 5}, "action": {"text": "solve", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 4042}, {"sent": "the class of lenticular galaxies was introduced by hubble as a more-or-less speculative means of bridging the morphological chasm between elliptical and spiral galaxies .", "tokens": ["the", "class", "of", "lenticular", "galaxies", "was", "introduced", "by", "hubble", "as", "a", "more", "-", "or", "-", "less", "speculative", "means", "of", "bridging", "the", "morphological", "chasm", "between", "elliptical", "and", "spiral", "galaxies", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the class of lenticular galaxies", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "was introduced", "start": 33, "end": 47, "i_start": 5, "i_end": 6}}, {"character": {"text": "hubble", "start": 51, "end": 57, "i_start": 8, "i_end": 8}, "action": {"text": "introduced", "start": 37, "end": 47, "i_start": 6, "i_end": 6}}], "id": 4043}, {"sent": "the efficiency of the method is phenomenal and the validity of the method has been checked by various tree level calculations .", "tokens": ["the", "efficiency", "of", "the", "method", "is", "phenomenal", "and", "the", "validity", "of", "the", "method", "has", "been", "checked", "by", "various", "tree", "level", "calculations", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the efficiency of the method", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the validity of the method", "start": 47, "end": 73, "i_start": 8, "i_end": 12}, "verb": {"text": "checked", "start": 83, "end": 90, "i_start": 15, "i_end": 15}}, {"character": {"text": "calculations", "start": 113, "end": 125, "i_start": 20, "i_end": 20}, "action": {"text": "checked", "start": 83, "end": 90, "i_start": 15, "i_end": 15}}], "id": 4044}, {"sent": "in , the authors presented a simple and practical data structure for the approximate polytope membership problem , called splitreduce .", "tokens": ["in", ",", "the", "authors", "presented", "a", "simple", "and", "practical", "data", "structure", "for", "the", "approximate", "polytope", "membership", "problem", ",", "called", "splitreduce", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 5, "end": 16, "i_start": 2, "i_end": 3}, "verb": {"text": "presented", "start": 17, "end": 26, "i_start": 4, "i_end": 4}}], "id": 4045}, {"sent": "asterisks denote the ratio of the normal self-energy terms n0\u03c3 e at .", "tokens": ["asterisks", "denote", "the", "ratio", "of", "the", "normal", "self", "-", "energy", "terms", "n0\u03c3", "e", "at", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "asterisks", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "denote", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "asterisks", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 10, "end": 16, "i_start": 1, "i_end": 1}}], "id": 4046}, {"sent": "in this work , we consider a standard b-spline discretization with interpolative boundaries .", "tokens": ["in", "this", "work", ",", "we", "consider", "a", "standard", "b", "-", "spline", "discretization", "with", "interpolative", "boundaries", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "consider", "start": 18, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "consider", "start": 18, "end": 26, "i_start": 5, "i_end": 5}}], "id": 4047}, {"sent": "in the framework of the generalized model considered in this paper , the scalar functions \u03bbi remain free functional parameters .", "tokens": ["in", "the", "framework", "of", "the", "generalized", "model", "considered", "in", "this", "paper", ",", "the", "scalar", "functions", "\u03bb"], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4048}, {"sent": "the restriction of the classes \u03c4p to fixed points .", "tokens": ["the", "restriction", "of", "the", "classes", "\u03c4p", "to", "fixed", "points", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4049}, {"sent": "in addition , we use batch normalization on the results of the convolutional layers .", "tokens": ["in", "addition", ",", "we", "use", "batch", "normalization", "on", "the", "results", "of", "the", "convolutional", "layers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "use", "start": 17, "end": 20, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 17, "end": 20, "i_start": 4, "i_end": 4}}], "id": 4050}, {"sent": "the cosmological constant problem is the most intriguing problem in theoretical physics .", "tokens": ["the", "cosmological", "constant", "problem", "is", "the", "most", "intriguing", "problem", "in", "theoretical", "physics", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the cosmological constant problem", "start": 0, "end": 33, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 4, "i_end": 4}}, {"character": {"text": "problem", "start": 26, "end": 33, "i_start": 3, "i_end": 3}, "action": {"text": "intriguing", "start": 46, "end": 56, "i_start": 7, "i_end": 7}}], "id": 4051}, {"sent": "these problems are good candidates for finding efficient quantum algorithms .", "tokens": ["these", "problems", "are", "good", "candidates", "for", "finding", "efficient", "quantum", "algorithms", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these problems", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}], "id": 4052}, {"sent": "this means that larger values of quantum noise influence the game weakly .", "tokens": ["this", "means", "that", "larger", "values", "of", "quantum", "noise", "influence", "the", "game", "weakly", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "means", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "weakly", "start": 66, "end": 72, "i_start": 11, "i_end": 11}}, {"character": {"text": "values", "start": 23, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "influence", "start": 47, "end": 56, "i_start": 8, "i_end": 8}}], "id": 4053}, {"sent": "recently , attention mechanism has demonstrated the effectiveness in various machine learning tasks such as image captioning .", "tokens": ["recently", ",", "attention", "mechanism", "has", "demonstrated", "the", "effectiveness", "in", "various", "machine", "learning", "tasks", "such", "as", "image", "captioning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "attention mechanism", "start": 11, "end": 30, "i_start": 2, "i_end": 3}, "verb": {"text": "has demonstrated", "start": 31, "end": 47, "i_start": 4, "i_end": 5}}, {"character": {"text": "mechanism", "start": 21, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "demonstrated", "start": 35, "end": 47, "i_start": 5, "i_end": 5}}, {"character": {"text": "mechanism", "start": 21, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "attention", "start": 11, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "mechanism", "start": 21, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "effectiveness", "start": 52, "end": 65, "i_start": 7, "i_end": 7}}], "id": 4054}, {"sent": "the kuramoto model is a generic model that can predict the behavior of multiple types of oscillators .", "tokens": ["the", "kuramoto", "model", "is", "a", "generic", "model", "that", "can", "predict", "the", "behavior", "of", "multiple", "types", "of", "oscillators", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the kuramoto model", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "model", "start": 13, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "predict", "start": 47, "end": 54, "i_start": 9, "i_end": 9}}, {"character": {"text": "types", "start": 80, "end": 85, "i_start": 14, "i_end": 14}, "action": {"text": "behavior", "start": 59, "end": 67, "i_start": 11, "i_end": 11}}], "id": 4055}, {"sent": "teleportation is a clear example where the aim is to end up with a quantum state , and where classical communication is necessary .", "tokens": ["teleportation", "is", "a", "clear", "example", "where", "the", "aim", "is", "to", "end", "up", "with", "a", "quantum", "state", ",", "and", "where", "classical", "communication", "is", "necessary", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "teleportation", "start": 0, "end": 13, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 1, "i_end": 1}}], "id": 4056}, {"sent": "we used the levenbergmarquardt algorithm as gradient-based optimiser .", "tokens": ["we", "used", "the", "levenbergmarquardt", "algorithm", "as", "gradient", "-", "based", "optimiser", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 4057}, {"sent": "deep neural networks show dramatically accurate results on challenging tasks such as computer vision .", "tokens": ["deep", "neural", "networks", "show", "dramatically", "accurate", "results", "on", "challenging", "tasks", "such", "as", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "show", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}], "id": 4058}, {"sent": "we evaluate our method on the pascal voc 2012 image segmentation benchmark , which has 21 semantic classes , including background .", "tokens": ["we", "evaluate", "our", "method", "on", "the", "pascal", "voc", "2012", "image", "segmentation", "benchmark", ",", "which", "has", "21", "semantic", "classes", ",", "including", "background", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "benchmark", "start": 65, "end": 74, "i_start": 11, "i_end": 11}, "action": {"text": "has", "start": 83, "end": 86, "i_start": 14, "i_end": 14}}], "id": 4059}, {"sent": "lenet-5 is a seven-layer version of cnns which has three convolutional layers , two pooling layers , and two fully connected layers .", "tokens": ["lenet-5", "is", "a", "seven", "-", "layer", "version", "of", "cnns", "which", "has", "three", "convolutional", "layers", ",", "two", "pooling", "layers", ",", "and", "two", "fully", "connected", "layers", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "lenet-5", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "version", "start": 25, "end": 32, "i_start": 6, "i_end": 6}, "action": {"text": "has", "start": 47, "end": 50, "i_start": 10, "i_end": 10}}, {"character": {"text": "two pooling layers", "start": 80, "end": 98, "i_start": 15, "i_end": 17}, "action": {"text": "pooling", "start": 84, "end": 91, "i_start": 16, "i_end": 16}}], "id": 4060}, {"sent": "the electronic structures of these materials were calculated using the vienna ab-initio simulation package within the generalized gradient approximation .", "tokens": ["the", "electronic", "structures", "of", "these", "materials", "were", "calculated", "using", "the", "vienna", "ab", "-", "initio", "simulation", "package", "within", "the", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electronic structures of these materials", "start": 0, "end": 44, "i_start": 0, "i_end": 5}, "verb": {"text": "were calculated", "start": 45, "end": 60, "i_start": 6, "i_end": 7}}], "id": 4061}, {"sent": "the left panel shows the results for the dwarfs , the right the spirals .", "tokens": ["the", "left", "panel", "shows", "the", "results", "for", "the", "dwarfs", ",", "the", "right", "the", "spirals", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the left panel", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "shows", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "panel", "start": 9, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "shows", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}], "id": 4062}, {"sent": "a space-time is a collection of events , ie points in space and time .", "tokens": ["a", "space", "-", "time", "is", "a", "collection", "of", "events", ",", "ie", "points", "in", "space", "and", "time", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a space-time", "start": 0, "end": 12, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 4, "i_end": 4}}, {"subject": {"text": "a space-time", "start": 0, "end": 12, "i_start": 0, "i_end": 3}, "verb": {"text": "points", "start": 44, "end": 50, "i_start": 11, "i_end": 11}}], "id": 4063}, {"sent": "ab initio calculations were performed within the density-functional theory framework as implemented in the vasp code .", "tokens": ["ab", "initio", "calculations", "were", "performed", "within", "the", "density", "-", "functional", "theory", "framework", "as", "implemented", "in", "the", "vasp", "code", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "ab initio calculations", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "were performed", "start": 23, "end": 37, "i_start": 3, "i_end": 4}}], "id": 4064}, {"sent": "it is easy to see that the resulting diagram is realizable .", "tokens": ["it", "is", "easy", "to", "see", "that", "the", "resulting", "diagram", "is", "realizable", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}], "id": 4065}, {"sent": "the muons for mice came from the decay of pions produced by an internal target dipping directly into the circulating proton beam of the isis synchrotron at the rutherford appleton laboratory .", "tokens": ["the", "muons", "for", "mice", "came", "from", "the", "decay", "of", "pions", "produced", "by", "an", "internal", "target", "dipping", "directly", "into", "the", "circulating", "proton", "beam", "of", "the", "isis", "synchrotron", "at", "the", "rutherford", "appleton", "laboratory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the muons for mice", "start": 0, "end": 18, "i_start": 0, "i_end": 3}, "verb": {"text": "came", "start": 19, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "dipping", "start": 79, "end": 86, "i_start": 15, "i_end": 15}, "action": {"text": "produced", "start": 48, "end": 56, "i_start": 10, "i_end": 10}}], "id": 4066}, {"sent": "for example , both dncnn have been evaluated on all the three tasks .", "tokens": ["for", "example", ",", "both", "dncnn", "have", "been", "evaluated", "on", "all", "the", "three", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "both dncnn", "start": 14, "end": 24, "i_start": 3, "i_end": 4}, "verb": {"text": "have been evaluated", "start": 25, "end": 44, "i_start": 5, "i_end": 7}}], "id": 4067}, {"sent": "now we need to consider the internal property of erasure zones .", "tokens": ["now", "we", "need", "to", "consider", "the", "internal", "property", "of", "erasure", "zones", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "need", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "need", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "consider", "start": 15, "end": 23, "i_start": 4, "i_end": 4}}], "id": 4068}, {"sent": "all networks were trained for 50 epochs using the adam optimizer .", "tokens": ["all", "networks", "were", "trained", "for", "50", "epochs", "using", "the", "adam", "optimizer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all networks", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "were trained", "start": 13, "end": 25, "i_start": 2, "i_end": 3}}], "id": 4069}, {"sent": "black and gray regions stand for chaotic trajectories .", "tokens": ["black", "and", "gray", "regions", "stand", "for", "chaotic", "trajectories", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "black and gray regions", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "stand", "start": 23, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "regions", "start": 15, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "stand", "start": 23, "end": 28, "i_start": 4, "i_end": 4}}], "id": 4070}, {"sent": "however , the degeneracy can be broken by the measurement of the speed of cosmological propagation of gravitational waves .", "tokens": ["however", ",", "the", "degeneracy", "can", "be", "broken", "by", "the", "measurement", "of", "the", "speed", "of", "cosmological", "propagation", "of", "gravitational", "waves", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the degeneracy", "start": 10, "end": 24, "i_start": 2, "i_end": 3}, "verb": {"text": "can be broken", "start": 25, "end": 38, "i_start": 4, "i_end": 6}}, {"character": {"text": "measurement", "start": 46, "end": 57, "i_start": 9, "i_end": 9}, "action": {"text": "broken", "start": 32, "end": 38, "i_start": 6, "i_end": 6}}], "id": 4071}, {"sent": "models based on convolutional neural networks and recurrent neural networks have achieved remarkable performance in many tasks , such as image classification .", "tokens": ["models", "based", "on", "convolutional", "neural", "networks", "and", "recurrent", "neural", "networks", "have", "achieved", "remarkable", "performance", "in", "many", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "models based on convolutional neural networks and recurrent neural networks", "start": 0, "end": 75, "i_start": 0, "i_end": 9}, "verb": {"text": "have achieved", "start": 76, "end": 89, "i_start": 10, "i_end": 11}}, {"character": {"text": "models", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "achieved", "start": 81, "end": 89, "i_start": 11, "i_end": 11}}], "id": 4072}, {"sent": "following , covert communications have been studied in a few scenarios .", "tokens": ["following", ",", "covert", "communications", "have", "been", "studied", "in", "a", "few", "scenarios", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "covert communications", "start": 12, "end": 33, "i_start": 2, "i_end": 3}, "verb": {"text": "have been studied", "start": 34, "end": 51, "i_start": 4, "i_end": 6}}], "id": 4073}, {"sent": "the attention mechanism is a general framework for neural network learning , and has been since used in many areas such as speech recognition , computer vision and healthcare .", "tokens": ["the", "attention", "mechanism", "is", "a", "general", "framework", "for", "neural", "network", "learning", ",", "and", "has", "been", "since", "used", "in", "many", "areas", "such", "as", "speech", "recognition", ",", "computer", "vision", "and", "healthcare", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the attention mechanism", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the attention mechanism", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 96, "end": 100, "i_start": 16, "i_end": 16}}], "id": 4074}, {"sent": "this formalization dates back to the work of valiant that in 1984 introduced the probably approximately correct learning model .", "tokens": ["this", "formalization", "dates", "back", "to", "the", "work", "of", "valiant", "that", "in", "1984", "introduced", "the", "probably", "approximately", "correct", "learning", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this formalization", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "dates", "start": 19, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "valiant", "start": 45, "end": 52, "i_start": 8, "i_end": 8}, "action": {"text": "work", "start": 37, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "valiant", "start": 45, "end": 52, "i_start": 8, "i_end": 8}, "action": {"text": "introduced", "start": 66, "end": 76, "i_start": 12, "i_end": 12}}], "id": 4075}, {"sent": "we use slot error rate that includes the intent as slot to evaluate the overall predictive performance of the nlu models .", "tokens": ["we", "use", "slot", "error", "rate", "that", "includes", "the", "intent", "as", "slot", "to", "evaluate", "the", "overall", "predictive", "performance", "of", "the", "nlu", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 59, "end": 67, "i_start": 12, "i_end": 12}}, {"character": {"text": "models", "start": 114, "end": 120, "i_start": 20, "i_end": 20}, "action": {"text": "performance", "start": 91, "end": 102, "i_start": 16, "i_end": 16}}], "id": 4076}, {"sent": "early data stream management systems were motivated by sensor network applications , that have similarities to iot .", "tokens": ["early", "data", "stream", "management", "systems", "were", "motivated", "by", "sensor", "network", "applications", ",", "that", "have", "similarities", "to", "iot", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "early data stream management systems", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "were motivated", "start": 37, "end": 51, "i_start": 5, "i_end": 6}}, {"subject": {"text": "that", "start": 85, "end": 89, "i_start": 12, "i_end": 12}, "verb": {"text": "have", "start": 90, "end": 94, "i_start": 13, "i_end": 13}}, {"character": {"text": "applications", "start": 70, "end": 82, "i_start": 10, "i_end": 10}, "action": {"text": "motivated", "start": 42, "end": 51, "i_start": 6, "i_end": 6}}], "id": 4077}, {"sent": "bremsstrahlung is the only radiation loss mechanism considered .", "tokens": ["bremsstrahlung", "is", "the", "only", "radiation", "loss", "mechanism", "considered", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "bremsstrahlung", "start": 0, "end": 14, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 1, "i_end": 1}}], "id": 4078}, {"sent": "the high-speed particles are blown upward from the holes in the layer .", "tokens": ["the", "high", "-", "speed", "particles", "are", "blown", "upward", "from", "the", "holes", "in", "the", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the high-speed particles", "start": 0, "end": 24, "i_start": 0, "i_end": 4}, "verb": {"text": "are blown", "start": 25, "end": 34, "i_start": 5, "i_end": 6}}], "id": 4079}, {"sent": "it has been showed that it is possible to partially solve this problem by including a correction to the unwrapped measured phase using partial kramers-kronig relations .", "tokens": ["it", "has", "been", "showed", "that", "it", "is", "possible", "to", "partially", "solve", "this", "problem", "by", "including", "a", "correction", "to", "the", "unwrapped", "measured", "phase", "using", "partial", "kramers", "-", "kronig", "relations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has been showed", "start": 3, "end": 18, "i_start": 1, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 6, "i_end": 6}}], "id": 4080}, {"sent": "in this work , we consider content delivery using coded caching in a wireless network where a server is connected to k users each equipped with a cache of finite memory .", "tokens": ["in", "this", "work", ",", "we", "consider", "content", "delivery", "using", "coded", "caching", "in", "a", "wireless", "network", "where", "a", "server", "is", "connected", "to", "k", "users", "each", "equipped", "with", "a", "cache", "of", "finite", "memory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "consider", "start": 18, "end": 26, "i_start": 5, "i_end": 5}}, {"subject": {"text": "content delivery", "start": 27, "end": 43, "i_start": 6, "i_end": 7}, "verb": {"text": "using", "start": 44, "end": 49, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "consider", "start": 18, "end": 26, "i_start": 5, "i_end": 5}}], "id": 4081}, {"sent": "tompson et al implemented the multi-resolution deep model and markov random field within an end-to-end joint training framework .", "tokens": ["tompson", "et", "al", "implemented", "the", "multi", "-", "resolution", "deep", "model", "and", "markov", "random", "field", "within", "an", "end", "-", "to", "-", "end", "joint", "training", "framework", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 8, "end": 13, "i_start": 1, "i_end": 2}, "verb": {"text": "implemented", "start": 14, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "tompson", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "implemented", "start": 14, "end": 25, "i_start": 3, "i_end": 3}}], "id": 4082}, {"sent": "to reduce the annotation cost in object detection , weakly supervised detection methods attempt to learn object detectors using only image category labels .", "tokens": ["to", "reduce", "the", "annotation", "cost", "in", "object", "detection", ",", "weakly", "supervised", "detection", "methods", "attempt", "to", "learn", "object", "detectors", "using", "only", "image", "category", "labels", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "weakly supervised detection methods", "start": 52, "end": 87, "i_start": 9, "i_end": 12}, "verb": {"text": "attempt", "start": 88, "end": 95, "i_start": 13, "i_end": 13}}, {"character": {"text": "methods", "start": 80, "end": 87, "i_start": 12, "i_end": 12}, "action": {"text": "attempt", "start": 88, "end": 95, "i_start": 13, "i_end": 13}}, {"character": {"text": "methods", "start": 80, "end": 87, "i_start": 12, "i_end": 12}, "action": {"text": "learn", "start": 99, "end": 104, "i_start": 15, "i_end": 15}}, {"character": {"text": "methods", "start": 80, "end": 87, "i_start": 12, "i_end": 12}, "action": {"text": "reduce", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 4083}, {"sent": "then the only possible case is that the tromino covering and covers and the tromino covering and covers .", "tokens": ["then", "the", "only", "possible", "case", "is", "that", "the", "tromino", "covering", "and", "covers", "and", "the", "tromino", "covering", "and", "covers", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the only possible case is that", "start": 5, "end": 35, "i_start": 1, "i_end": 6}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 5, "i_end": 5}}], "id": 4084}, {"sent": "the pcal response function puts the detector sensitivities lower than the conventional coil actuator response function .", "tokens": ["the", "pcal", "response", "function", "puts", "the", "detector", "sensitivities", "lower", "than", "the", "conventional", "coil", "actuator", "response", "function", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the pcal response function", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "puts", "start": 27, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "function", "start": 18, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "puts", "start": 27, "end": 31, "i_start": 4, "i_end": 4}}], "id": 4085}, {"sent": "hence s is a homomorphism and therefore a0 is a right indicator .", "tokens": ["hence", "s", "is", "a", "homomorphism", "and", "therefore", "a0", "is", "a", "right", "indicator", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "s", "start": 6, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 2, "i_end": 2}}], "id": 4086}, {"sent": "richardson , conjugacy classes of involutions in coxeter groups .", "tokens": ["richardson", ",", "conjugacy", "classes", "of", "involutions", "in", "coxeter", "groups", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4087}, {"sent": "one missing ingredient is the three loop anomalous dimension for c1 , for which only partial results are known .", "tokens": ["one", "missing", "ingredient", "is", "the", "three", "loop", "anomalous", "dimension", "for", "c1", ",", "for", "which", "only", "partial", "results", "are", "known", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one missing ingredient", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}], "id": 4088}, {"sent": "evolutionary game theory provides a powerful mathematical framework for studying the emergence and stability of cooperation in social , economic and biological systems .", "tokens": ["evolutionary", "game", "theory", "provides", "a", "powerful", "mathematical", "framework", "for", "studying", "the", "emergence", "and", "stability", "of", "cooperation", "in", "social", ",", "economic", "and", "biological", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "evolutionary game theory", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "provides", "start": 25, "end": 33, "i_start": 3, "i_end": 3}}, {"character": {"text": "theory", "start": 18, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "provides", "start": 25, "end": 33, "i_start": 3, "i_end": 3}}, {"character": {"text": "cooperation", "start": 112, "end": 123, "i_start": 15, "i_end": 15}, "action": {"text": "emergence", "start": 85, "end": 94, "i_start": 11, "i_end": 11}}, {"character": {"text": "systems", "start": 160, "end": 167, "i_start": 22, "i_end": 22}, "action": {"text": "cooperation", "start": 112, "end": 123, "i_start": 15, "i_end": 15}}, {"character": {"text": "social", "start": 127, "end": 133, "i_start": 17, "i_end": 17}, "action": {"text": "cooperation", "start": 112, "end": 123, "i_start": 15, "i_end": 15}}, {"character": {"text": "economic", "start": 136, "end": 144, "i_start": 19, "i_end": 19}, "action": {"text": "cooperation", "start": 112, "end": 123, "i_start": 15, "i_end": 15}}, {"character": {"text": "biological", "start": 149, "end": 159, "i_start": 21, "i_end": 21}, "action": {"text": "cooperation", "start": 112, "end": 123, "i_start": 15, "i_end": 15}}], "id": 4089}, {"sent": "note that the simple motion of these particles is due to the exact solubility of our model .", "tokens": ["note", "that", "the", "simple", "motion", "of", "these", "particles", "is", "due", "to", "the", "exact", "solubility", "of", "our", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4090}, {"sent": "shown are the raw simulation data as well as the critical power laws of table i .", "tokens": ["shown", "are", "the", "raw", "simulation", "data", "as", "well", "as", "the", "critical", "power", "laws", "of", "table", "i", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4091}, {"sent": "it was later proved in that a local weyl module is a fusion product of fundamental local weyl modules .", "tokens": ["it", "was", "later", "proved", "in", "that", "a", "local", "weyl", "module", "is", "a", "fusion", "product", "of", "fundamental", "local", "weyl", "modules", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "proved", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "was", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 48, "end": 50, "i_start": 10, "i_end": 10}}, {"character": {"text": "module", "start": 41, "end": 47, "i_start": 9, "i_end": 9}, "action": {"text": "product", "start": 60, "end": 67, "i_start": 13, "i_end": 13}}], "id": 4092}, {"sent": "the canonicalization method in use is the one implemented by openbabel which is based in the widely used morgan algorithm .", "tokens": ["the", "canonicalization", "method", "in", "use", "is", "the", "one", "implemented", "by", "openbabel", "which", "is", "based", "in", "the", "widely", "used", "morgan", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the canonicalization method in use", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 5, "i_end": 5}}], "id": 4093}, {"sent": "inflation is one of the most motivated scenarios for explaining the origin of structure formation in the universe .", "tokens": ["inflation", "is", "one", "of", "the", "most", "motivated", "scenarios", "for", "explaining", "the", "origin", "of", "structure", "formation", "in", "the", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "inflation", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 1, "i_end": 1}}], "id": 4094}, {"sent": "the latent dirichlet allocation adopts a probabilistic approach to cluster highly semantically-related terms in a text corpus .", "tokens": ["the", "latent", "dirichlet", "allocation", "adopts", "a", "probabilistic", "approach", "to", "cluster", "highly", "semantically", "-", "related", "terms", "in", "a", "text", "corpus", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the latent dirichlet allocation", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "adopts", "start": 32, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "allocation", "start": 21, "end": 31, "i_start": 3, "i_end": 3}, "action": {"text": "adopts", "start": 32, "end": 38, "i_start": 4, "i_end": 4}}], "id": 4095}, {"sent": "graphene is a two-dimensional honeycomb lattice of carbon atoms , with two nonequivalent sublattices .", "tokens": ["graphene", "is", "a", "two", "-", "dimensional", "honeycomb", "lattice", "of", "carbon", "atoms", ",", "with", "two", "nonequivalent", "sublattices", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "graphene", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}], "id": 4096}, {"sent": "this behavior is expected because the dissipation mechanism in ppm operates on smaller and smaller scales as the resolution is increased .", "tokens": ["this", "behavior", "is", "expected", "because", "the", "dissipation", "mechanism", "in", "ppm", "operates", "on", "smaller", "and", "smaller", "scales", "as", "the", "resolution", "is", "increased", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this behavior", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is expected", "start": 14, "end": 25, "i_start": 2, "i_end": 3}}, {"character": {"text": "operates", "start": 67, "end": 75, "i_start": 10, "i_end": 10}, "action": {"text": "because", "start": 26, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "mechanism", "start": 50, "end": 59, "i_start": 7, "i_end": 7}, "action": {"text": "dissipation", "start": 38, "end": 49, "i_start": 6, "i_end": 6}}], "id": 4097}, {"sent": "deep convolutional neural networks have been successfully applied to several pattern recognition tasks such as image recognition .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successfully", "applied", "to", "several", "pattern", "recognition", "tasks", "such", "as", "image", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "applied", "start": 58, "end": 65, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}], "id": 4098}, {"sent": "the value-based methods estimate future expected total rewards through a state , such as sarsa and deep q network .", "tokens": ["the", "value", "-", "based", "methods", "estimate", "future", "expected", "total", "rewards", "through", "a", "state", ",", "such", "as", "sarsa", "and", "deep", "q", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the value-based methods", "start": 0, "end": 23, "i_start": 0, "i_end": 4}, "verb": {"text": "estimate", "start": 24, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "methods", "start": 16, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "estimate", "start": 24, "end": 32, "i_start": 5, "i_end": 5}}], "id": 4099}, {"sent": "the convolution and full-connected layers use rectified linear units as the activation function , while the output layer uses linear activation .", "tokens": ["the", "convolution", "and", "full", "-", "connected", "layers", "use", "rectified", "linear", "units", "as", "the", "activation", "function", ",", "while", "the", "output", "layer", "uses", "linear", "activation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the convolution and full-connected layers", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "use", "start": 42, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "convolution", "start": 4, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "use", "start": 42, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "layers", "start": 35, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "use", "start": 42, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "full", "start": 20, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 42, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "convolution", "start": 4, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "function", "start": 87, "end": 95, "i_start": 14, "i_end": 14}}, {"character": {"text": "layers", "start": 35, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "function", "start": 87, "end": 95, "i_start": 14, "i_end": 14}}, {"character": {"text": "full", "start": 20, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "function", "start": 87, "end": 95, "i_start": 14, "i_end": 14}}], "id": 4100}, {"sent": "these results in fact apply for any spectrally localized forcing , not just for monoscale-like forcing .", "tokens": ["these", "results", "in", "fact", "apply", "for", "any", "spectrally", "localized", "forcing", ",", "not", "just", "for", "monoscale", "-", "like", "forcing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these results", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "apply", "start": 22, "end": 27, "i_start": 4, "i_end": 4}}], "id": 4101}, {"sent": "deep convolutional neural networks have achieved significant success in a wide range of studies .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "significant", "success", "in", "a", "wide", "range", "of", "studies", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}], "id": 4102}, {"sent": "in tree parallelization one mcts tree is shared among several threads that are performing simultaneous searches .", "tokens": ["in", "tree", "parallelization", "one", "mcts", "tree", "is", "shared", "among", "several", "threads", "that", "are", "performing", "simultaneous", "searches", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "one mcts tree", "start": 24, "end": 37, "i_start": 3, "i_end": 5}, "verb": {"text": "is shared", "start": 38, "end": 47, "i_start": 6, "i_end": 7}}, {"character": {"text": "threads", "start": 62, "end": 69, "i_start": 10, "i_end": 10}, "action": {"text": "shared", "start": 41, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "threads", "start": 62, "end": 69, "i_start": 10, "i_end": 10}, "action": {"text": "searches", "start": 103, "end": 111, "i_start": 15, "i_end": 15}}], "id": 4103}, {"sent": "for example , gruber et al found that irregular blood flow can lead to hypoplastic left heart syndrome , where the ventricle is too small or absent during the remainder of cardiogenesis .", "tokens": ["for", "example", ",", "gruber", "et", "al", "found", "that", "irregular", "blood", "flow", "can", "lead", "to", "hypoplastic", "left", "heart", "syndrome", ",", "where", "the", "ventricle", "is", "too", "small", "or", "absent", "during", "the", "remainder", "of", "cardiogenesis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "gruber et al", "start": 14, "end": 26, "i_start": 3, "i_end": 5}, "verb": {"text": "found", "start": 27, "end": 32, "i_start": 6, "i_end": 6}}, {"subject": {"text": "irregular blood flow", "start": 38, "end": 58, "i_start": 8, "i_end": 10}, "verb": {"text": "lead", "start": 63, "end": 67, "i_start": 12, "i_end": 12}}, {"character": {"text": "gruber", "start": 14, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "found", "start": 27, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "flow", "start": 54, "end": 58, "i_start": 10, "i_end": 10}, "action": {"text": "lead", "start": 63, "end": 67, "i_start": 12, "i_end": 12}}], "id": 4104}, {"sent": "let us restrict ourselves to the case of lie algebras corresponding to classical lie groups .", "tokens": ["let", "us", "restrict", "ourselves", "to", "the", "case", "of", "lie", "algebras", "corresponding", "to", "classical", "lie", "groups", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "restrict", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "restrict", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "groups", "start": 85, "end": 91, "i_start": 14, "i_end": 14}, "action": {"text": "lie", "start": 81, "end": 84, "i_start": 13, "i_end": 13}}], "id": 4105}, {"sent": "the lower plots in each set show the corresponding pedestal shifts from reconstruction and the derived analysing powers , both for non-colliding and colliding bunches .", "tokens": ["the", "lower", "plots", "in", "each", "set", "show", "the", "corresponding", "pedestal", "shifts", "from", "reconstruction", "and", "the", "derived", "analysing", "powers", ",", "both", "for", "non", "-", "colliding", "and", "colliding", "bunches", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the lower plots in each set", "start": 0, "end": 27, "i_start": 0, "i_end": 5}, "verb": {"text": "show", "start": 28, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "plots", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "show", "start": 28, "end": 32, "i_start": 6, "i_end": 6}}], "id": 4106}, {"sent": "the present models reproduce the main trends of observed methane-dwarfs in near-ir color-magnitude diagrams .", "tokens": ["the", "present", "models", "reproduce", "the", "main", "trends", "of", "observed", "methane", "-", "dwarfs", "in", "near", "-", "ir", "color", "-", "magnitude", "diagrams", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the present models", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "reproduce", "start": 19, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 12, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "reproduce", "start": 19, "end": 28, "i_start": 3, "i_end": 3}}], "id": 4107}, {"sent": "convolutional neural networks have shown excellent performance in various visual recognition problems such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "shown", "excellent", "performance", "in", "various", "visual", "recognition", "problems", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 35, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 51, "end": 62, "i_start": 6, "i_end": 6}}], "id": 4108}, {"sent": "we also show the number of diagrams both at tree-level and at the one-loop level .", "tokens": ["we", "also", "show", "the", "number", "of", "diagrams", "both", "at", "tree", "-", "level", "and", "at", "the", "one", "-", "loop", "level", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}], "id": 4109}, {"sent": "for observers with large \u03b8obs the polarization degree significantly decreases with \u03b3j .", "tokens": ["for", "observers", "with", "large", "\u03b8obs", "the", "polarization", "degree", "significantly", "decreases", "with", "\u03b3j", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the polarization degree", "start": 30, "end": 53, "i_start": 5, "i_end": 7}, "verb": {"text": "decreases", "start": 68, "end": 77, "i_start": 9, "i_end": 9}}], "id": 4110}, {"sent": "our lagrangian is the minimal extension which allows to incorporate the full momentum dependence of the quark propagator , through its mass and wave function renormalization .", "tokens": ["our", "lagrangian", "is", "the", "minimal", "extension", "which", "allows", "to", "incorporate", "the", "full", "momentum", "dependence", "of", "the", "quark", "propagator", ",", "through", "its", "mass", "and", "wave", "function", "renormalization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our lagrangian", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "extension", "start": 30, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "allows", "start": 46, "end": 52, "i_start": 7, "i_end": 7}}], "id": 4111}, {"sent": "another dominant noma category is code-domain multiplexing , including multiple access lowdensity spreading cdma , sparse-code multiple access , multi-users shared access , and so on .", "tokens": ["another", "dominant", "noma", "category", "is", "code", "-", "domain", "multiplexing", ",", "including", "multiple", "access", "lowdensity", "spreading", "cdma", ",", "sparse", "-", "code", "multiple", "access", ",", "multi", "-", "users", "shared", "access", ",", "and", "so", "on", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "multi-users", "start": 145, "end": 156, "i_start": 23, "i_end": 25}, "verb": {"text": "shared", "start": 157, "end": 163, "i_start": 26, "i_end": 26}}, {"subject": {"text": "multi-users", "start": 145, "end": 156, "i_start": 23, "i_end": 25}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "multiplexing", "start": 46, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "dominant", "start": 8, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "multiple", "start": 127, "end": 135, "i_start": 20, "i_end": 20}, "action": {"text": "shared", "start": 157, "end": 163, "i_start": 26, "i_end": 26}}], "id": 4112}, {"sent": "welty , the velocity distribution of the nearest interstellar gas , astrophys .", "tokens": ["welty", ",", "the", "velocity", "distribution", "of", "the", "nearest", "interstellar", "gas", ",", "astrophys", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4113}, {"sent": "deep learning has greatly improved pattern classification performance by leaps and bounds in computer vision .", "tokens": ["deep", "learning", "has", "greatly", "improved", "pattern", "classification", "performance", "by", "leaps", "and", "bounds", "in", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "improved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has", "start": 14, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "improved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}], "id": 4114}, {"sent": "cosmic strings are one-dimensional topological defects that can form during phase transitions in the early universe .", "tokens": ["cosmic", "strings", "are", "one", "-", "dimensional", "topological", "defects", "that", "can", "form", "during", "phase", "transitions", "in", "the", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}], "id": 4115}, {"sent": "theobald et al design specialized maxsat algorithms that efficiently solve a family of mln programs .", "tokens": ["theobald", "et", "al", "design", "specialized", "maxsat", "algorithms", "that", "efficiently", "solve", "a", "family", "of", "mln", "programs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "theobald", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "design", "start": 15, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithms", "start": 41, "end": 51, "i_start": 6, "i_end": 6}, "action": {"text": "solve", "start": 69, "end": 74, "i_start": 9, "i_end": 9}}], "id": 4116}, {"sent": "non-empty products are shown on the left , and empty products on the right .", "tokens": ["non", "-", "empty", "products", "are", "shown", "on", "the", "left", ",", "and", "empty", "products", "on", "the", "right", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "non-empty products", "start": 0, "end": 18, "i_start": 0, "i_end": 3}, "verb": {"text": "are shown", "start": 19, "end": 28, "i_start": 4, "i_end": 5}}], "id": 4117}, {"sent": "for fully converged results better computational facilities may be required .", "tokens": ["for", "fully", "converged", "results", "better", "computational", "facilities", "may", "be", "required", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "better computational facilities", "start": 28, "end": 59, "i_start": 4, "i_end": 6}, "verb": {"text": "may be required", "start": 60, "end": 75, "i_start": 7, "i_end": 9}}], "id": 4118}, {"sent": "now we move onto the detection of spin polarization .", "tokens": ["now", "we", "move", "onto", "the", "detection", "of", "spin", "polarization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "move", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "move", "start": 7, "end": 11, "i_start": 2, "i_end": 2}}], "id": 4119}, {"sent": "this partition function can be also obtained from the refined topological vertex of .", "tokens": ["this", "partition", "function", "can", "be", "also", "obtained", "from", "the", "refined", "topological", "vertex", "of", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this partition function", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "obtained", "start": 36, "end": 44, "i_start": 6, "i_end": 6}}, {"subject": {"text": "this partition function", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "can be", "start": 24, "end": 30, "i_start": 3, "i_end": 4}}], "id": 4120}, {"sent": "here , we introduce the product-operators used in the calculations shown in the proceeding sections .", "tokens": ["here", ",", "we", "introduce", "the", "product", "-", "operators", "used", "in", "the", "calculations", "shown", "in", "the", "proceeding", "sections", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "verb": {"text": "introduce", "start": 10, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 7, "end": 9, "i_start": 2, "i_end": 2}, "action": {"text": "introduce", "start": 10, "end": 19, "i_start": 3, "i_end": 3}}], "id": 4121}, {"sent": "contrary , if the scale of electric taxi fleet decreases , the passenger average waiting time will increase .", "tokens": ["contrary", ",", "if", "the", "scale", "of", "electric", "taxi", "fleet", "decreases", ",", "the", "passenger", "average", "waiting", "time", "will", "increase", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the passenger average waiting time", "start": 59, "end": 93, "i_start": 11, "i_end": 15}, "verb": {"text": "will increase", "start": 94, "end": 107, "i_start": 16, "i_end": 17}}], "id": 4122}, {"sent": "we explicitly resolve the respective classical equations of motion via the projection method and quantize the system .", "tokens": ["we", "explicitly", "resolve", "the", "respective", "classical", "equations", "of", "motion", "via", "the", "projection", "method", "and", "quantize", "the", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "resolve", "start": 14, "end": 21, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "quantize", "start": 97, "end": 105, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "resolve", "start": 14, "end": 21, "i_start": 2, "i_end": 2}}], "id": 4123}, {"sent": "this is consistent with the explicit calculation in which shows that the one-loop correction vanishes at the orientifold point .", "tokens": ["this", "is", "consistent", "with", "the", "explicit", "calculation", "in", "which", "shows", "that", "the", "one", "-", "loop", "correction", "vanishes", "at", "the", "orientifold", "point", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "calculation", "start": 37, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "shows", "start": 58, "end": 63, "i_start": 9, "i_end": 9}}], "id": 4124}, {"sent": "replacing the generators by their holomorphic limits we can extract the ooguri-vafa invariants from the partition functions .", "tokens": ["replacing", "the", "generators", "by", "their", "holomorphic", "limits", "we", "can", "extract", "the", "ooguri", "-", "vafa", "invariants", "from", "the", "partition", "functions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 53, "end": 55, "i_start": 7, "i_end": 7}, "verb": {"text": "can extract", "start": 56, "end": 67, "i_start": 8, "i_end": 9}}, {"character": {"text": "we", "start": 53, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "extract", "start": 60, "end": 67, "i_start": 9, "i_end": 9}}], "id": 4125}, {"sent": "in , a stacked hourglass network is proposed to introduce bottom-up , top-down inference across multiple scales .", "tokens": ["in", ",", "a", "stacked", "hourglass", "network", "is", "proposed", "to", "introduce", "bottom", "-", "up", ",", "top", "-", "down", "inference", "across", "multiple", "scales", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a stacked hourglass network", "start": 5, "end": 32, "i_start": 2, "i_end": 5}, "verb": {"text": "is proposed", "start": 33, "end": 44, "i_start": 6, "i_end": 7}}, {"character": {"text": "network", "start": 25, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "introduce", "start": 48, "end": 57, "i_start": 9, "i_end": 9}}], "id": 4126}, {"sent": "in recent years , deep learning techniques have demonstrated outstanding performance on numerous tasks ranging from object recognition to natural language processing .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "techniques", "have", "demonstrated", "outstanding", "performance", "on", "numerous", "tasks", "ranging", "from", "object", "recognition", "to", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning techniques", "start": 18, "end": 42, "i_start": 4, "i_end": 6}, "verb": {"text": "have demonstrated", "start": 43, "end": 60, "i_start": 7, "i_end": 8}}, {"character": {"text": "techniques", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "demonstrated", "start": 48, "end": 60, "i_start": 8, "i_end": 8}}, {"character": {"text": "techniques", "start": 32, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 73, "end": 84, "i_start": 10, "i_end": 10}}], "id": 4127}, {"sent": "moreover we study the construction of codes in this case and relate them to completely reducible cyclic orbit codes .", "tokens": ["moreover", "we", "study", "the", "construction", "of", "codes", "in", "this", "case", "and", "relate", "them", "to", "completely", "reducible", "cyclic", "orbit", "codes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 9, "end": 11, "i_start": 1, "i_end": 1}, "verb": {"text": "study", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 9, "end": 11, "i_start": 1, "i_end": 1}, "verb": {"text": "relate", "start": 61, "end": 67, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 9, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "study", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 9, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "relate", "start": 61, "end": 67, "i_start": 11, "i_end": 11}}], "id": 4128}, {"sent": "functions whose ranges have star geometry are known as star functions while those whose ranges have convex geometry are called convex .", "tokens": ["functions", "whose", "ranges", "have", "star", "geometry", "are", "known", "as", "star", "functions", "while", "those", "whose", "ranges", "have", "convex", "geometry", "are", "called", "convex", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "functions whose ranges have star geometry", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "are known", "start": 42, "end": 51, "i_start": 6, "i_end": 7}}], "id": 4129}, {"sent": "hinton et al developed the idea of distillation to learn a student model with simpler network structure to replace the teacher model with a cumbersome ensemble of models .", "tokens": ["hinton", "et", "al", "developed", "the", "idea", "of", "distillation", "to", "learn", "a", "student", "model", "with", "simpler", "network", "structure", "to", "replace", "the", "teacher", "model", "with", "a", "cumbersome", "ensemble", "of", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hinton et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "developed", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "hinton", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "developed", "start": 13, "end": 22, "i_start": 3, "i_end": 3}}], "id": 4130}, {"sent": "here the ellipsis denotes the term including derivatives of y ijk by the fields \u03c6a .", "tokens": ["here", "the", "ellipsis", "denotes", "the", "term", "including", "derivatives", "of", "y", "ijk", "by", "the", "fields", "\u03c6a", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ellipsis", "start": 5, "end": 17, "i_start": 1, "i_end": 2}, "verb": {"text": "denotes", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "ellipsis", "start": 9, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "denotes", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}], "id": 4131}, {"sent": "specifically , we utilize a c3d model pre-trained on the sports-1m video dataset , and extract features form the fc7 fully-connected layer as the representation f for an input clip c .", "tokens": ["specifically", ",", "we", "utilize", "a", "c3d", "model", "pre", "-", "trained", "on", "the", "sports-1", "m", "video", "dataset", ",", "and", "extract", "features", "form", "the", "fc7", "fully", "-", "connected", "layer", "as", "the", "representation", "f", "for", "an", "input", "clip", "c", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "utilize", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"subject": {"text": "extract features", "start": 87, "end": 103, "i_start": 18, "i_end": 19}, "verb": {"text": "form", "start": 104, "end": 108, "i_start": 20, "i_end": 20}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "utilize", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "extract", "start": 87, "end": 94, "i_start": 18, "i_end": 18}}, {"character": {"text": "layer", "start": 133, "end": 138, "i_start": 26, "i_end": 26}, "action": {"text": "representation", "start": 146, "end": 160, "i_start": 29, "i_end": 29}}], "id": 4132}, {"sent": "it is found that the divergent parts of the radial and azimuthal electric field components , as well as the electric potential , are determined by the local charge density while the axial component is determined by the local dipole density .", "tokens": ["it", "is", "found", "that", "the", "divergent", "parts", "of", "the", "radial", "and", "azimuthal", "electric", "field", "components", ",", "as", "well", "as", "the", "electric", "potential", ",", "are", "determined", "by", "the", "local", "charge", "density", "while", "the", "axial", "component", "is", "determined", "by", "the", "local", "dipole", "density", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is found", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"subject": {"text": "the divergent parts of the radial and azimuthal electric field components", "start": 17, "end": 90, "i_start": 4, "i_end": 14}, "verb": {"text": "determined", "start": 133, "end": 143, "i_start": 24, "i_end": 24}}, {"character": {"text": "density", "start": 164, "end": 171, "i_start": 29, "i_end": 29}, "action": {"text": "determined", "start": 133, "end": 143, "i_start": 24, "i_end": 24}}, {"character": {"text": "density", "start": 232, "end": 239, "i_start": 40, "i_end": 40}, "action": {"text": "determined", "start": 201, "end": 211, "i_start": 35, "i_end": 35}}], "id": 4133}, {"sent": "we now calculate the eigenvalues of an important matrix , called the keeping with the method of asymptotic splittings , we proceed to construct series expansions which are local solutions around movable singularities .", "tokens": ["we", "now", "calculate", "the", "eigenvalues", "of", "an", "important", "matrix", ",", "called", "the", "keeping", "with", "the", "method", "of", "asymptotic", "splittings", ",", "we", "proceed", "to", "construct", "series", "expansions", "which", "are", "local", "solutions", "around", "movable", "singularities", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "calculate", "start": 7, "end": 16, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 120, "end": 122, "i_start": 20, "i_end": 20}, "verb": {"text": "proceed", "start": 123, "end": 130, "i_start": 21, "i_end": 21}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proceed", "start": 123, "end": 130, "i_start": 21, "i_end": 21}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "construct", "start": 134, "end": 143, "i_start": 23, "i_end": 23}}], "id": 4134}, {"sent": "in recent years , deep convolutional neural networks have achieved impressive results in a number of computer vision tasks such as image classification .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "achieved", "impressive", "results", "in", "a", "number", "of", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have achieved", "start": 53, "end": 66, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 58, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "results", "start": 78, "end": 85, "i_start": 11, "i_end": 11}, "action": {"text": "impressive", "start": 67, "end": 77, "i_start": 10, "i_end": 10}}], "id": 4135}, {"sent": "we use batch normalization between each convolutional layer and which is followed by relu non-linearity .", "tokens": ["we", "use", "batch", "normalization", "between", "each", "convolutional", "layer", "and", "which", "is", "followed", "by", "relu", "non", "-", "linearity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "which", "start": 64, "end": 69, "i_start": 9, "i_end": 9}, "verb": {"text": "followed", "start": 73, "end": 81, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 4136}, {"sent": "our achievability scheme is a combination of the superposition of gaussian codes and randomization within the layers .", "tokens": ["our", "achievability", "scheme", "is", "a", "combination", "of", "the", "superposition", "of", "gaussian", "codes", "and", "randomization", "within", "the", "layers", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our achievability scheme", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 3, "i_end": 3}}], "id": 4137}, {"sent": "overlaid is the exclusion result published in ref .", "tokens": ["overlaid", "is", "the", "exclusion", "result", "published", "in", "ref", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4138}, {"sent": "a soliton is the extremely robust , nonlinear excitation localized in space , which has particlelike properties .", "tokens": ["a", "soliton", "is", "the", "extremely", "robust", ",", "nonlinear", "excitation", "localized", "in", "space", ",", "which", "has", "particlelike", "properties", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a soliton", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}], "id": 4139}, {"sent": "the ordinate provides a measure of the amount of dust obscuration , while the abscissa provides a measure of the total star formation rate .", "tokens": ["the", "ordinate", "provides", "a", "measure", "of", "the", "amount", "of", "dust", "obscuration", ",", "while", "the", "abscissa", "provides", "a", "measure", "of", "the", "total", "star", "formation", "rate", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ordinate", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "provides", "start": 13, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "ordinate", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "provides", "start": 13, "end": 21, "i_start": 2, "i_end": 2}}], "id": 4140}, {"sent": "deep neural networks have achieved state-of-the-art performance on tasks such as image recognition in the last few years .", "tokens": ["deep", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "tasks", "such", "as", "image", "recognition", "in", "the", "last", "few", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 52, "end": 63, "i_start": 12, "i_end": 12}}], "id": 4141}, {"sent": "the symbols designate the energy well which is activated at each gauss point of the mesh .", "tokens": ["the", "symbols", "designate", "the", "energy", "well", "which", "is", "activated", "at", "each", "gauss", "point", "of", "the", "mesh", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the symbols", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "designate", "start": 12, "end": 21, "i_start": 2, "i_end": 2}}], "id": 4142}, {"sent": "the fact that chat rooms are open to abuse does not mean they should of necessity be closed .", "tokens": ["the", "fact", "that", "chat", "rooms", "are", "open", "to", "abuse", "does", "not", "mean", "they", "should", "of", "necessity", "be", "closed", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the fact that chat rooms are open to abuse", "start": 0, "end": 42, "i_start": 0, "i_end": 8}, "verb": {"text": "does not mean", "start": 43, "end": 56, "i_start": 9, "i_end": 11}}, {"subject": {"text": "the fact that chat rooms are open to abuse", "start": 0, "end": 42, "i_start": 0, "i_end": 8}, "verb": {"text": "closed", "start": 85, "end": 91, "i_start": 17, "i_end": 17}}], "id": 4143}, {"sent": "meanwhile the hot-electron effect tends to soften the hf term through the increase of the electron temperature and the scattering rate .", "tokens": ["meanwhile", "the", "hot", "-", "electron", "effect", "tends", "to", "soften", "the", "hf", "term", "through", "the", "increase", "of", "the", "electron", "temperature", "and", "the", "scattering", "rate", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the hot-electron effect", "start": 10, "end": 33, "i_start": 1, "i_end": 5}, "verb": {"text": "tends", "start": 34, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "electron", "start": 18, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "effect", "start": 27, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "effect", "start": 27, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "soften", "start": 43, "end": 49, "i_start": 8, "i_end": 8}}], "id": 4144}, {"sent": "these states correspond to de sitter-invariant pure states in the global fock space , traced over the modes behind the horizon .", "tokens": ["these", "states", "correspond", "to", "de", "sitter", "-", "invariant", "pure", "states", "in", "the", "global", "fock", "space", ",", "traced", "over", "the", "modes", "behind", "the", "horizon", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these states", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "correspond", "start": 13, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "states", "start": 52, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "invariant", "start": 37, "end": 46, "i_start": 7, "i_end": 7}}], "id": 4145}, {"sent": "we will use the language of vertex operator algebras , .", "tokens": ["we", "will", "use", "the", "language", "of", "vertex", "operator", "algebras", ",", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will use", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "algebras", "start": 44, "end": 52, "i_start": 8, "i_end": 8}, "action": {"text": "operator", "start": 35, "end": 43, "i_start": 7, "i_end": 7}}], "id": 4146}, {"sent": "in recent years , many centralized power and spectrum allocation schemes have been extensively studied in cellular and multihop wireless networks .", "tokens": ["in", "recent", "years", ",", "many", "centralized", "power", "and", "spectrum", "allocation", "schemes", "have", "been", "extensively", "studied", "in", "cellular", "and", "multihop", "wireless", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many centralized power and spectrum allocation schemes", "start": 18, "end": 72, "i_start": 4, "i_end": 10}, "verb": {"text": "studied", "start": 95, "end": 102, "i_start": 14, "i_end": 14}}, {"subject": {"text": "many centralized power and spectrum allocation schemes", "start": 18, "end": 72, "i_start": 4, "i_end": 10}, "verb": {"text": "have been", "start": 73, "end": 82, "i_start": 11, "i_end": 12}}], "id": 4147}, {"sent": "a g-space is a topological space x with a fixed continuous right action of g .", "tokens": ["a", "g", "-", "space", "is", "a", "topological", "space", "x", "with", "a", "fixed", "continuous", "right", "action", "of", "g", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "g-space", "start": 2, "end": 9, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 4, "i_end": 4}}], "id": 4148}, {"sent": "deep learning based techniques have enabled a significant rise in the performance of various tasks such as object detection and recognition .", "tokens": ["deep", "learning", "based", "techniques", "have", "enabled", "a", "significant", "rise", "in", "the", "performance", "of", "various", "tasks", "such", "as", "object", "detection", "and", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning based techniques", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "have enabled", "start": 31, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "techniques", "start": 20, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "enabled", "start": 36, "end": 43, "i_start": 5, "i_end": 5}}], "id": 4149}, {"sent": "in proceedings of the ninth international joint conference on arti cial intel ligence , pp .", "tokens": ["in", "proceedings", "of", "the", "ninth", "international", "joint", "conference", "on", "arti", "cial", "intel", "ligence", ",", "pp", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4150}, {"sent": "the training procedures is carried out using the adam stochastic optimizer with default settings and mini-batches of size 1000 .", "tokens": ["the", "training", "procedures", "is", "carried", "out", "using", "the", "adam", "stochastic", "optimizer", "with", "default", "settings", "and", "mini", "-", "batches", "of", "size", "1000", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the training procedures", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is carried out", "start": 24, "end": 38, "i_start": 3, "i_end": 5}}], "id": 4151}, {"sent": "we assume that the cocoon stays overpressured with respect to the surrounding medium .", "tokens": ["we", "assume", "that", "the", "cocoon", "stays", "overpressured", "with", "respect", "to", "the", "surrounding", "medium", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the cocoon", "start": 15, "end": 25, "i_start": 3, "i_end": 4}, "verb": {"text": "stays", "start": 26, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 4152}, {"sent": "therefore , one can not impose ingoing boundary conditions for the wave functions .", "tokens": ["therefore", ",", "one", "can", "not", "impose", "ingoing", "boundary", "conditions", "for", "the", "wave", "functions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 12, "end": 15, "i_start": 2, "i_end": 2}, "verb": {"text": "can not impose", "start": 16, "end": 30, "i_start": 3, "i_end": 5}}, {"character": {"text": "one", "start": 12, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "impose", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}], "id": 4153}, {"sent": "for more on the theory of time scales we refer to the gentle books .", "tokens": ["for", "more", "on", "the", "theory", "of", "time", "scales", "we", "refer", "to", "the", "gentle", "books", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 38, "end": 40, "i_start": 8, "i_end": 8}, "action": {"text": "refer", "start": 41, "end": 46, "i_start": 9, "i_end": 9}}], "id": 4154}, {"sent": "deep convolutional neural networks have enabled unparalleled breakthroughs in a variety of visual tasks , such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "enabled", "unparalleled", "breakthroughs", "in", "a", "variety", "of", "visual", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have enabled", "start": 35, "end": 47, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "enabled", "start": 40, "end": 47, "i_start": 5, "i_end": 5}}], "id": 4155}, {"sent": "the result extends to all complex hyperbolic cocompact lattices of any dimension .", "tokens": ["the", "result", "extends", "to", "all", "complex", "hyperbolic", "cocompact", "lattices", "of", "any", "dimension", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the result", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "extends", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}], "id": 4156}, {"sent": "taylor has shown in that the strongest locally convex topology agreeing with the strict topology on norm-bounded sets is actually the strict topology itself .", "tokens": ["taylor", "has", "shown", "in", "that", "the", "strongest", "locally", "convex", "topology", "agreeing", "with", "the", "strict", "topology", "on", "norm", "-", "bounded", "sets", "is", "actually", "the", "strict", "topology", "itself", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "taylor", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "has shown", "start": 7, "end": 16, "i_start": 1, "i_end": 2}}, {"subject": {"text": "taylor", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 118, "end": 120, "i_start": 20, "i_end": 20}}, {"character": {"text": "taylor", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "shown", "start": 11, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "topology", "start": 88, "end": 96, "i_start": 14, "i_end": 14}, "action": {"text": "agreeing", "start": 63, "end": 71, "i_start": 10, "i_end": 10}}], "id": 4157}, {"sent": "as we mentioned earlier , a viable approach for this is to use the adaptive aggregations based on a posteriori error estimates as proposed in .", "tokens": ["as", "we", "mentioned", "earlier", ",", "a", "viable", "approach", "for", "this", "is", "to", "use", "the", "adaptive", "aggregations", "based", "on", "a", "posteriori", "error", "estimates", "as", "proposed", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a viable approach for this", "start": 26, "end": 52, "i_start": 5, "i_end": 9}, "verb": {"text": "is", "start": 53, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 3, "end": 5, "i_start": 1, "i_end": 1}, "action": {"text": "approach", "start": 35, "end": 43, "i_start": 7, "i_end": 7}}], "id": 4158}, {"sent": "in contrast , specialized deep learning accelerators such as the tpu usually favor leaner control with a decoupled access-execute architecture and offload the problem of finegrained synchronization to software .", "tokens": ["in", "contrast", ",", "specialized", "deep", "learning", "accelerators", "such", "as", "the", "tpu", "usually", "favor", "leaner", "control", "with", "a", "decoupled", "access", "-", "execute", "architecture", "and", "offload", "the", "problem", "of", "finegrained", "synchronization", "to", "software", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "specialized deep learning accelerators such as the tpu", "start": 14, "end": 68, "i_start": 3, "i_end": 10}, "verb": {"text": "favor", "start": 77, "end": 82, "i_start": 12, "i_end": 12}}], "id": 4159}, {"sent": "now we proceed on to define super vector space .", "tokens": ["now", "we", "proceed", "on", "to", "define", "super", "vector", "space", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "proceed on", "start": 7, "end": 17, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 4160}, {"sent": "in the past two decades , the lattice boltzmann method has been developed into an efficient mesoscopic numerical method for simulating fluid flows and heat transfer .", "tokens": ["in", "the", "past", "two", "decades", ",", "the", "lattice", "boltzmann", "method", "has", "been", "developed", "into", "an", "efficient", "mesoscopic", "numerical", "method", "for", "simulating", "fluid", "flows", "and", "heat", "transfer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lattice boltzmann method", "start": 26, "end": 54, "i_start": 6, "i_end": 9}, "verb": {"text": "has been developed", "start": 55, "end": 73, "i_start": 10, "i_end": 12}}], "id": 4161}, {"sent": "the eikonal approximation gives excellent results for nuclear-dominated reactions .", "tokens": ["the", "eikonal", "approximation", "gives", "excellent", "results", "for", "nuclear", "-", "dominated", "reactions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the eikonal approximation", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "gives", "start": 26, "end": 31, "i_start": 3, "i_end": 3}}, {"character": {"text": "nuclear", "start": 54, "end": 61, "i_start": 7, "i_end": 7}, "action": {"text": "dominated", "start": 62, "end": 71, "i_start": 9, "i_end": 9}}], "id": 4162}, {"sent": "however , at the quantum level , it appears explicitly in the spectra of geometric operators .", "tokens": ["however", ",", "at", "the", "quantum", "level", ",", "it", "appears", "explicitly", "in", "the", "spectra", "of", "geometric", "operators", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 33, "end": 35, "i_start": 7, "i_end": 7}, "verb": {"text": "appears", "start": 36, "end": 43, "i_start": 8, "i_end": 8}}], "id": 4163}, {"sent": "the notation above is the same as the notation used in .", "tokens": ["the", "notation", "above", "is", "the", "same", "as", "the", "notation", "used", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the notation above", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 4164}, {"sent": "this dynamical system has an r n -action and is defined analogously to tiling dynamical systems , for which see .", "tokens": ["this", "dynamical", "system", "has", "an", "r", "n", "-action", "and", "is", "defined", "analogously", "to", "tiling", "dynamical", "systems", ",", "for", "which", "see", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this dynamical system", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "has", "start": 22, "end": 25, "i_start": 3, "i_end": 3}}, {"subject": {"text": "this dynamical system", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "defined", "start": 48, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "system", "start": 15, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "has", "start": 22, "end": 25, "i_start": 3, "i_end": 3}}], "id": 4165}, {"sent": "unfortunately , such convergent solutions of chaos have never been reported .", "tokens": ["unfortunately", ",", "such", "convergent", "solutions", "of", "chaos", "have", "never", "been", "reported", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such convergent solutions of chaos", "start": 16, "end": 50, "i_start": 2, "i_end": 6}, "verb": {"text": "have never been reported", "start": 51, "end": 75, "i_start": 7, "i_end": 10}}], "id": 4166}, {"sent": "in the literature , numerous attempts to protect privacy have followed the traditional method of pseudonymization and anonymization , which are essentially based on the assumptions of soft privacy .", "tokens": ["in", "the", "literature", ",", "numerous", "attempts", "to", "protect", "privacy", "have", "followed", "the", "traditional", "method", "of", "pseudonymization", "and", "anonymization", ",", "which", "are", "essentially", "based", "on", "the", "assumptions", "of", "soft", "privacy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "numerous attempts to protect privacy", "start": 20, "end": 56, "i_start": 4, "i_end": 8}, "verb": {"text": "have followed", "start": 57, "end": 70, "i_start": 9, "i_end": 10}}, {"character": {"text": "attempts", "start": 29, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "followed", "start": 62, "end": 70, "i_start": 10, "i_end": 10}}], "id": 4167}, {"sent": "compared to standard nns , these new models are often computationally slower to train and harder to implement , creating tremendous difficulty for practical uses .", "tokens": ["compared", "to", "standard", "nns", ",", "these", "new", "models", "are", "often", "computationally", "slower", "to", "train", "and", "harder", "to", "implement", ",", "creating", "tremendous", "difficulty", "for", "practical", "uses", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these new models", "start": 27, "end": 43, "i_start": 5, "i_end": 7}, "verb": {"text": "are", "start": 44, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "and", "start": 86, "end": 89, "i_start": 14, "i_end": 14}, "action": {"text": "creating", "start": 112, "end": 120, "i_start": 19, "i_end": 19}}], "id": 4168}, {"sent": "moreover , the sets are the only one-dimensional orbits .", "tokens": ["moreover", ",", "the", "sets", "are", "the", "only", "one", "-", "dimensional", "orbits", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the sets", "start": 11, "end": 19, "i_start": 2, "i_end": 3}, "verb": {"text": "are", "start": 20, "end": 23, "i_start": 4, "i_end": 4}}], "id": 4169}, {"sent": "in addition , the wightman function determines the response of the particle detector of unruhdewitt type , moving through the vacuum under consideration .", "tokens": ["in", "addition", ",", "the", "wightman", "function", "determines", "the", "response", "of", "the", "particle", "detector", "of", "unruhdewitt", "type", ",", "moving", "through", "the", "vacuum", "under", "consideration", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the wightman function", "start": 14, "end": 35, "i_start": 3, "i_end": 5}, "verb": {"text": "determines", "start": 36, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "function", "start": 27, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "determines", "start": 36, "end": 46, "i_start": 6, "i_end": 6}}], "id": 4170}, {"sent": "deep convolutional neural networks have performed impressively on very large-scale image recognition problems .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "performed", "impressively", "on", "very", "large", "-", "scale", "image", "recognition", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have performed", "start": 35, "end": 49, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performed", "start": 40, "end": 49, "i_start": 5, "i_end": 5}}, {"character": {"text": "performed", "start": 40, "end": 49, "i_start": 5, "i_end": 5}, "action": {"text": "impressively", "start": 50, "end": 62, "i_start": 6, "i_end": 6}}], "id": 4171}, {"sent": "latin indices here denote anholonomic components , that is , components that are not derivable from a coordinate basis .", "tokens": ["latin", "indices", "here", "denote", "anholonomic", "components", ",", "that", "is", ",", "components", "that", "are", "not", "derivable", "from", "a", "coordinate", "basis", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "indices", "start": 6, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 19, "end": 25, "i_start": 3, "i_end": 3}}], "id": 4172}, {"sent": "this mechanism has gained recent popularity in the form of the preferential attachment mechanism in the formation of scale-free networks .", "tokens": ["this", "mechanism", "has", "gained", "recent", "popularity", "in", "the", "form", "of", "the", "preferential", "attachment", "mechanism", "in", "the", "formation", "of", "scale", "-", "free", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this mechanism", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "has gained", "start": 15, "end": 25, "i_start": 2, "i_end": 3}}, {"character": {"text": "mechanism", "start": 5, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "gained", "start": 19, "end": 25, "i_start": 3, "i_end": 3}}], "id": 4173}, {"sent": "neural networks have been proven effective in several domains such as image classification .", "tokens": ["neural", "networks", "have", "been", "proven", "effective", "in", "several", "domains", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have been proven", "start": 16, "end": 32, "i_start": 2, "i_end": 4}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "effective", "start": 33, "end": 42, "i_start": 5, "i_end": 5}}], "id": 4174}, {"sent": "a general framework for proving convergence of a finite-difference scheme to the viscosity solution of a non-linear second order pde was developed by barles and souganidis .", "tokens": ["a", "general", "framework", "for", "proving", "convergence", "of", "a", "finite", "-", "difference", "scheme", "to", "the", "viscosity", "solution", "of", "a", "non", "-", "linear", "second", "order", "pde", "was", "developed", "by", "barles", "and", "souganidis", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "a general framework for proving convergence of a finite-difference scheme to the viscosity solution of a non-linear second order pde", "start": 0, "end": 132, "i_start": 0, "i_end": 23}, "verb": {"text": "was developed", "start": 133, "end": 146, "i_start": 24, "i_end": 25}}, {"character": {"text": "barles", "start": 150, "end": 156, "i_start": 27, "i_end": 27}, "action": {"text": "developed", "start": 137, "end": 146, "i_start": 25, "i_end": 25}}, {"character": {"text": "souganidis", "start": 161, "end": 171, "i_start": 29, "i_end": 29}, "action": {"text": "developed", "start": 137, "end": 146, "i_start": 25, "i_end": 25}}], "id": 4175}, {"sent": "recurrent neural networks have recently shown great promise in tackling various sequence modeling tasks in machine learning , such as automatic speech recognition .", "tokens": ["recurrent", "neural", "networks", "have", "recently", "shown", "great", "promise", "in", "tackling", "various", "sequence", "modeling", "tasks", "in", "machine", "learning", ",", "such", "as", "automatic", "speech", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "recurrent neural networks", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "shown", "start": 40, "end": 45, "i_start": 5, "i_end": 5}}, {"subject": {"text": "recurrent neural networks", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 26, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 17, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "promise", "start": 52, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 17, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "tackling", "start": 63, "end": 71, "i_start": 9, "i_end": 9}}], "id": 4176}, {"sent": "oxygen is the most easily displaced of the elements initially present in the olivine .", "tokens": ["oxygen", "is", "the", "most", "easily", "displaced", "of", "the", "elements", "initially", "present", "in", "the", "olivine", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "oxygen", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "displaced", "start": 26, "end": 35, "i_start": 5, "i_end": 5}}], "id": 4177}, {"sent": "deep neural networks have demonstrated their success in many machine learning and computer vision applications , including image classification .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "their", "success", "in", "many", "machine", "learning", "and", "computer", "vision", "applications", ",", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 45, "end": 52, "i_start": 6, "i_end": 6}}], "id": 4178}, {"sent": "our construction relies heavily on the existence results for formal models of derived k-analytic spaces obtained by the first author in .", "tokens": ["our", "construction", "relies", "heavily", "on", "the", "existence", "results", "for", "formal", "models", "of", "derived", "k", "-", "analytic", "spaces", "obtained", "by", "the", "first", "author", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our construction", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "relies", "start": 17, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "construction", "start": 4, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "relies", "start": 17, "end": 23, "i_start": 2, "i_end": 2}}], "id": 4179}, {"sent": "the median values of the variables are given in the frames .", "tokens": ["the", "median", "values", "of", "the", "variables", "are", "given", "in", "the", "frames", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the median values of the variables", "start": 0, "end": 34, "i_start": 0, "i_end": 5}, "verb": {"text": "are given", "start": 35, "end": 44, "i_start": 6, "i_end": 7}}], "id": 4180}, {"sent": "what emerges is the prolate spheroidal function , \u03c6 , is the apodizer .", "tokens": ["what", "emerges", "is", "the", "prolate", "spheroidal", "function", ",", "\u03c6", ",", "is", "the", "apodizer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "\u03c6", "start": 50, "end": 51, "i_start": 8, "i_end": 8}, "verb": {"text": "is", "start": 54, "end": 56, "i_start": 10, "i_end": 10}}, {"subject": {"text": "\u03c6", "start": 50, "end": 51, "i_start": 8, "i_end": 8}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 4181}, {"sent": "deep learning has revolutionised research in automatic speech recognition as well as many other fields of application of machine learning .", "tokens": ["deep", "learning", "has", "revolutionised", "research", "in", "automatic", "speech", "recognition", "as", "well", "as", "many", "other", "fields", "of", "application", "of", "machine", "learning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has revolutionised", "start": 14, "end": 32, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "revolutionised", "start": 18, "end": 32, "i_start": 3, "i_end": 3}}], "id": 4182}, {"sent": "deep convolutional neural networks have shown tremendous success in a variety of computer vision tasks , such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "shown", "tremendous", "success", "in", "a", "variety", "of", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have shown", "start": 35, "end": 45, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 57, "end": 64, "i_start": 7, "i_end": 7}}], "id": 4183}, {"sent": "convolutional neural networks have become a standard tool for machine learning in euclidean domains , such as images .", "tokens": ["convolutional", "neural", "networks", "have", "become", "a", "standard", "tool", "for", "machine", "learning", "in", "euclidean", "domains", ",", "such", "as", "images", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have become", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}], "id": 4184}, {"sent": "its geometry is a geometry of non-traversable wormhole .", "tokens": ["its", "geometry", "is", "a", "geometry", "of", "non", "-", "traversable", "wormhole", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "its geometry", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 4185}, {"sent": "the inflaton is the moduli for the brane distance .", "tokens": ["the", "inflaton", "is", "the", "moduli", "for", "the", "brane", "distance", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the inflaton", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 4186}, {"sent": "then the lightest neutralino is the lsp and ends all superparticle decay chains .", "tokens": ["then", "the", "lightest", "neutralino", "is", "the", "lsp", "and", "ends", "all", "superparticle", "decay", "chains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the lightest neutralino", "start": 5, "end": 28, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the lightest neutralino", "start": 5, "end": 28, "i_start": 1, "i_end": 3}, "verb": {"text": "ends", "start": 44, "end": 48, "i_start": 8, "i_end": 8}}, {"character": {"text": "neutralino", "start": 18, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "ends", "start": 44, "end": 48, "i_start": 8, "i_end": 8}}], "id": 4187}, {"sent": "the reader is assumed to be familiar with the standard definitions for deterministic and probabilistic turing machines .", "tokens": ["the", "reader", "is", "assumed", "to", "be", "familiar", "with", "the", "standard", "definitions", "for", "deterministic", "and", "probabilistic", "turing", "machines", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the reader", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is assumed", "start": 11, "end": 21, "i_start": 2, "i_end": 3}}, {"character": {"text": "machines", "start": 110, "end": 118, "i_start": 16, "i_end": 16}, "action": {"text": "turing", "start": 103, "end": 109, "i_start": 15, "i_end": 15}}], "id": 4188}, {"sent": "deep neural network models have recently demonstrated impressive learning results in many visual and speech classification problems .", "tokens": ["deep", "neural", "network", "models", "have", "recently", "demonstrated", "impressive", "learning", "results", "in", "many", "visual", "and", "speech", "classification", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural network models", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "demonstrated", "start": 41, "end": 53, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep neural network models", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 27, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "models", "start": 20, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "demonstrated", "start": 41, "end": 53, "i_start": 6, "i_end": 6}}, {"character": {"text": "results", "start": 74, "end": 81, "i_start": 9, "i_end": 9}, "action": {"text": "impressive", "start": 54, "end": 64, "i_start": 7, "i_end": 7}}], "id": 4189}, {"sent": "it was shown that an even order symmetric tensor is positive definite if and only if all of its h-eigenvalues or z-eigenvalues are positive .", "tokens": ["it", "was", "shown", "that", "an", "even", "order", "symmetric", "tensor", "is", "positive", "definite", "if", "and", "only", "if", "all", "of", "its", "h", "-", "eigenvalues", "or", "z", "-", "eigenvalues", "are", "positive", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "was shown", "start": 3, "end": 12, "i_start": 1, "i_end": 2}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 49, "end": 51, "i_start": 9, "i_end": 9}}], "id": 4190}, {"sent": "algebraically , the set of equivalence classes is the first cohomology of the null foliation f h 1 up to the ambient hamiltonian isotopies .", "tokens": ["algebraically", ",", "the", "set", "of", "equivalence", "classes", "is", "the", "first", "cohomology", "of", "the", "null", "foliation", "f", "h", "1", "up", "to", "the", "ambient", "hamiltonian", "isotopies", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the set of equivalence classes", "start": 16, "end": 46, "i_start": 2, "i_end": 6}, "verb": {"text": "is", "start": 47, "end": 49, "i_start": 7, "i_end": 7}}], "id": 4191}, {"sent": "deep convolutional neural networks have been successful in many computer vision tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successful", "in", "many", "computer", "vision", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "successful", "start": 45, "end": 55, "i_start": 6, "i_end": 6}}], "id": 4192}, {"sent": "the millimeter-wave spectrum , roughly defined as the frequencies between 10 and 300 ghz , is a new and promising frontier for cellular wireless communications .", "tokens": ["the", "millimeter", "-", "wave", "spectrum", ",", "roughly", "defined", "as", "the", "frequencies", "between", "10", "and", "300", "ghz", ",", "is", "a", "new", "and", "promising", "frontier", "for", "cellular", "wireless", "communications", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the millimeter-wave spectrum", "start": 0, "end": 28, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 91, "end": 93, "i_start": 17, "i_end": 17}}, {"character": {"text": "frontier", "start": 114, "end": 122, "i_start": 22, "i_end": 22}, "action": {"text": "promising", "start": 104, "end": 113, "i_start": 21, "i_end": 21}}], "id": 4193}, {"sent": "cluster algebras were introduced by fomin and zelevinsky in order to give a combinatorial framework for understanding total positivity in algebraic groups and dual canonical bases in quantum groups .", "tokens": ["cluster", "algebras", "were", "introduced", "by", "fomin", "and", "zelevinsky", "in", "order", "to", "give", "a", "combinatorial", "framework", "for", "understanding", "total", "positivity", "in", "algebraic", "groups", "and", "dual", "canonical", "bases", "in", "quantum", "groups", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were introduced", "start": 17, "end": 32, "i_start": 2, "i_end": 3}}, {"character": {"text": "fomin", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "zelevinsky", "start": 46, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "fomin", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "give", "start": 69, "end": 73, "i_start": 11, "i_end": 11}}, {"character": {"text": "zelevinsky", "start": 46, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "give", "start": 69, "end": 73, "i_start": 11, "i_end": 11}}], "id": 4194}, {"sent": "this theory has the color-flavor locked center symmetry z n , and it is called z n -qcd .", "tokens": ["this", "theory", "has", "the", "color", "-", "flavor", "locked", "center", "symmetry", "z", "n", ",", "and", "it", "is", "called", "z", "n", "-qcd", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this theory", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "has", "start": 12, "end": 15, "i_start": 2, "i_end": 2}}, {"subject": {"text": "it", "start": 66, "end": 68, "i_start": 14, "i_end": 14}, "verb": {"text": "called", "start": 72, "end": 78, "i_start": 16, "i_end": 16}}], "id": 4195}, {"sent": "we shall provide some insights into this issue .", "tokens": ["we", "shall", "provide", "some", "insights", "into", "this", "issue", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "shall provide", "start": 3, "end": 16, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "provide", "start": 9, "end": 16, "i_start": 2, "i_end": 2}}], "id": 4196}, {"sent": "for the problem of estimating the parameters of generative models , the expectation-maximization algorithm is particularly effective .", "tokens": ["for", "the", "problem", "of", "estimating", "the", "parameters", "of", "generative", "models", ",", "the", "expectation", "-", "maximization", "algorithm", "is", "particularly", "effective", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "the expectation-maximization algorithm", "start": 68, "end": 106, "i_start": 11, "i_end": 15}, "verb": {"text": "is", "start": 107, "end": 109, "i_start": 16, "i_end": 16}}, {"character": {"text": "algorithm", "start": 97, "end": 106, "i_start": 15, "i_end": 15}, "action": {"text": "effective", "start": 123, "end": 132, "i_start": 18, "i_end": 18}}], "id": 4197}, {"sent": "we employed density functional theory within the generalized gradient approximation of the exchange and correlation functional , as parameterized by perdew , burke and ernzerhof .", "tokens": ["we", "employed", "density", "functional", "theory", "within", "the", "generalized", "gradient", "approximation", "of", "the", "exchange", "and", "correlation", "functional", ",", "as", "parameterized", "by", "perdew", ",", "burke", "and", "ernzerhof", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "employed", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "employed", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "perdew", "start": 149, "end": 155, "i_start": 20, "i_end": 20}, "action": {"text": "parameterized", "start": 132, "end": 145, "i_start": 18, "i_end": 18}}, {"character": {"text": "burke", "start": 158, "end": 163, "i_start": 22, "i_end": 22}, "action": {"text": "parameterized", "start": 132, "end": 145, "i_start": 18, "i_end": 18}}, {"character": {"text": "ernzerhof", "start": 168, "end": 177, "i_start": 24, "i_end": 24}, "action": {"text": "parameterized", "start": 132, "end": 145, "i_start": 18, "i_end": 18}}], "id": 4198}, {"sent": "quantum cluster algebras were introduced by berenstein and zelevinsky in , to lay the groundwork for a study of the canonical basis .", "tokens": ["quantum", "cluster", "algebras", "were", "introduced", "by", "berenstein", "and", "zelevinsky", "in", ",", "to", "lay", "the", "groundwork", "for", "a", "study", "of", "the", "canonical", "basis", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "quantum cluster algebras", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "were introduced", "start": 25, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "berenstein", "start": 44, "end": 54, "i_start": 6, "i_end": 6}, "action": {"text": "introduced", "start": 30, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "zelevinsky", "start": 59, "end": 69, "i_start": 8, "i_end": 8}, "action": {"text": "introduced", "start": 30, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "berenstein", "start": 44, "end": 54, "i_start": 6, "i_end": 6}, "action": {"text": "lay", "start": 78, "end": 81, "i_start": 12, "i_end": 12}}, {"character": {"text": "zelevinsky", "start": 59, "end": 69, "i_start": 8, "i_end": 8}, "action": {"text": "lay", "start": 78, "end": 81, "i_start": 12, "i_end": 12}}], "id": 4199}, {"sent": "thus , successive dual packings will reduce the numbers of remaining clockwise and counterclockwise flows by at least one alternately .", "tokens": ["thus", ",", "successive", "dual", "packings", "will", "reduce", "the", "numbers", "of", "remaining", "clockwise", "and", "counterclockwise", "flows", "by", "at", "least", "one", "alternately", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "successive dual packings", "start": 7, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "will reduce", "start": 32, "end": 43, "i_start": 5, "i_end": 6}}, {"subject": {"text": "counterclockwise", "start": 83, "end": 99, "i_start": 13, "i_end": 13}, "verb": {"text": "flows", "start": 100, "end": 105, "i_start": 14, "i_end": 14}}, {"character": {"text": "packings", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "reduce", "start": 37, "end": 43, "i_start": 6, "i_end": 6}}], "id": 4200}, {"sent": "the inflaton itself is a coherent field , and as we have shown , other fields such as supersymmetric flat directions may be made coherent through the process of inflation .", "tokens": ["the", "inflaton", "itself", "is", "a", "coherent", "field", ",", "and", "as", "we", "have", "shown", ",", "other", "fields", "such", "as", "supersymmetric", "flat", "directions", "may", "be", "made", "coherent", "through", "the", "process", "of", "inflation", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the inflaton itself", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}, {"subject": {"text": "other fields such as supersymmetric flat directions", "start": 65, "end": 116, "i_start": 14, "i_end": 20}, "verb": {"text": "made", "start": 124, "end": 128, "i_start": 23, "i_end": 23}}, {"character": {"text": "process", "start": 150, "end": 157, "i_start": 27, "i_end": 27}, "action": {"text": "made", "start": 124, "end": 128, "i_start": 23, "i_end": 23}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 10, "i_end": 10}, "action": {"text": "shown", "start": 57, "end": 62, "i_start": 12, "i_end": 12}}], "id": 4201}, {"sent": "in the next section , from the analytical expression of the solution of the ladder sd equation , we identify the form of the leading correction to the hyperscaling relation .", "tokens": ["in", "the", "next", "section", ",", "from", "the", "analytical", "expression", "of", "the", "solution", "of", "the", "ladder", "sd", "equation", ",", "we", "identify", "the", "form", "of", "the", "leading", "correction", "to", "the", "hyperscaling", "relation", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 97, "end": 99, "i_start": 18, "i_end": 18}, "verb": {"text": "identify", "start": 100, "end": 108, "i_start": 19, "i_end": 19}}, {"character": {"text": "we", "start": 97, "end": 99, "i_start": 18, "i_end": 18}, "action": {"text": "identify", "start": 100, "end": 108, "i_start": 19, "i_end": 19}}, {"character": {"text": "correction", "start": 133, "end": 143, "i_start": 25, "i_end": 25}, "action": {"text": "leading", "start": 125, "end": 132, "i_start": 24, "i_end": 24}}], "id": 4202}, {"sent": "our network f is an imagenet-pretrained resnet-50 and remains fixed during training .", "tokens": ["our", "network", "f", "is", "an", "imagenet", "-", "pretrained", "resnet-50", "and", "remains", "fixed", "during", "training", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our network f", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 3, "i_end": 3}}, {"subject": {"text": "our network f", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "fixed", "start": 62, "end": 67, "i_start": 11, "i_end": 11}}], "id": 4203}, {"sent": "until now we have considered only the two-point correlation function of eq .", "tokens": ["until", "now", "we", "have", "considered", "only", "the", "two", "-", "point", "correlation", "function", "of", "eq", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "have considered", "start": 13, "end": 28, "i_start": 3, "i_end": 4}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "considered", "start": 18, "end": 28, "i_start": 4, "i_end": 4}}], "id": 4204}, {"sent": "deep neural networks , together with large scale accurately annotated datasets , have achieved remarkable performance in a great many classification tasks in recent years .", "tokens": ["deep", "neural", "networks", ",", "together", "with", "large", "scale", "accurately", "annotated", "datasets", ",", "have", "achieved", "remarkable", "performance", "in", "a", "great", "many", "classification", "tasks", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "annotated", "start": 60, "end": 69, "i_start": 9, "i_end": 9}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 86, "end": 94, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 86, "end": 94, "i_start": 13, "i_end": 13}}, {"character": {"text": "deep", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "achieved", "start": 86, "end": 94, "i_start": 13, "i_end": 13}}, {"character": {"text": "datasets", "start": 70, "end": 78, "i_start": 10, "i_end": 10}, "action": {"text": "achieved", "start": 86, "end": 94, "i_start": 13, "i_end": 13}}, {"character": {"text": "accurately", "start": 49, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "achieved", "start": 86, "end": 94, "i_start": 13, "i_end": 13}}, {"character": {"text": "large", "start": 37, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 86, "end": 94, "i_start": 13, "i_end": 13}}], "id": 4205}, {"sent": "deep learning has shown its effectiveness in many computer vision tasks , such as object detection .", "tokens": ["deep", "learning", "has", "shown", "its", "effectiveness", "in", "many", "computer", "vision", "tasks", ",", "such", "as", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has shown", "start": 14, "end": 23, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "shown", "start": 18, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "effectiveness", "start": 28, "end": 41, "i_start": 5, "i_end": 5}}], "id": 4206}, {"sent": "the performance of a wiretap channel was first introduced by wyner in which a source is trying to communicate with the destination in the presence of an external eavesdropper .", "tokens": ["the", "performance", "of", "a", "wiretap", "channel", "was", "first", "introduced", "by", "wyner", "in", "which", "a", "source", "is", "trying", "to", "communicate", "with", "the", "destination", "in", "the", "presence", "of", "an", "external", "eavesdropper", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the performance of a wiretap channel", "start": 0, "end": 36, "i_start": 0, "i_end": 5}, "verb": {"text": "introduced", "start": 47, "end": 57, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the performance of a wiretap channel", "start": 0, "end": 36, "i_start": 0, "i_end": 5}, "verb": {"text": "was", "start": 37, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "wyner", "start": 61, "end": 66, "i_start": 10, "i_end": 10}, "action": {"text": "introduced", "start": 47, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "source", "start": 78, "end": 84, "i_start": 14, "i_end": 14}, "action": {"text": "trying", "start": 88, "end": 94, "i_start": 16, "i_end": 16}}, {"character": {"text": "source", "start": 78, "end": 84, "i_start": 14, "i_end": 14}, "action": {"text": "communicate", "start": 98, "end": 109, "i_start": 18, "i_end": 18}}], "id": 4207}, {"sent": "the value of k\u03c1 can be assumed to increase between subsequent appearances .", "tokens": ["the", "value", "of", "k\u03c1", "can", "be", "assumed", "to", "increase", "between", "subsequent", "appearances", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the value of k\u03c1", "start": 0, "end": 15, "i_start": 0, "i_end": 3}, "verb": {"text": "can be assumed", "start": 16, "end": 30, "i_start": 4, "i_end": 6}}], "id": 4208}, {"sent": "mykland et al and rosenthal give prescriptions that are often useful for establishing in general spaces .", "tokens": ["mykland", "et", "al", "and", "rosenthal", "give", "prescriptions", "that", "are", "often", "useful", "for", "establishing", "in", "general", "spaces", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "mykland et al and rosenthal", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "give", "start": 28, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "mykland", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "prescriptions", "start": 33, "end": 46, "i_start": 6, "i_end": 6}}], "id": 4209}, {"sent": "it is seen that the calculated ground-state energies are less bound than the experimental value .", "tokens": ["it", "is", "seen", "that", "the", "calculated", "ground", "-", "state", "energies", "are", "less", "bound", "than", "the", "experimental", "value", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is seen", "start": 3, "end": 10, "i_start": 1, "i_end": 2}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 53, "end": 56, "i_start": 10, "i_end": 10}}], "id": 4210}, {"sent": "it is well known that the worldvolume theory on d-branes becomes non-commutative when the non-zero b-field is threading the cycle on which the d-branes are wrapped .", "tokens": ["it", "is", "well", "known", "that", "the", "worldvolume", "theory", "on", "d", "-", "branes", "becomes", "non", "-", "commutative", "when", "the", "non", "-", "zero", "b", "-", "field", "is", "threading", "the", "cycle", "on", "which", "the", "d", "-", "branes", "are", "wrapped", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"character": {"text": "field", "start": 101, "end": 106, "i_start": 23, "i_end": 23}, "action": {"text": "threading", "start": 110, "end": 119, "i_start": 25, "i_end": 25}}], "id": 4211}, {"sent": "furthermore , we have computed the inner and outer bounds of the deterministic and stochastic secrecy capacities and have determined the deterministic secrecy capacity for the class of reversely degraded relay channels .", "tokens": ["furthermore", ",", "we", "have", "computed", "the", "inner", "and", "outer", "bounds", "of", "the", "deterministic", "and", "stochastic", "secrecy", "capacities", "and", "have", "determined", "the", "deterministic", "secrecy", "capacity", "for", "the", "class", "of", "reversely", "degraded", "relay", "channels", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "have computed", "start": 17, "end": 30, "i_start": 3, "i_end": 4}}, {"subject": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "verb": {"text": "determined", "start": 122, "end": 132, "i_start": 19, "i_end": 19}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "computed", "start": 22, "end": 30, "i_start": 4, "i_end": 4}}], "id": 4212}, {"sent": "large-scale deep convolutional neural networks have been successfully applied to a wide variety of applications such as image classification .", "tokens": ["large", "-", "scale", "deep", "convolutional", "neural", "networks", "have", "been", "successfully", "applied", "to", "a", "wide", "variety", "of", "applications", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "large-scale deep convolutional neural networks", "start": 0, "end": 46, "i_start": 0, "i_end": 6}, "verb": {"text": "applied", "start": 70, "end": 77, "i_start": 10, "i_end": 10}}, {"subject": {"text": "large-scale deep convolutional neural networks", "start": 0, "end": 46, "i_start": 0, "i_end": 6}, "verb": {"text": "have been", "start": 47, "end": 56, "i_start": 7, "i_end": 8}}], "id": 4213}, {"sent": "eigen et al use a multi-scale cnn for predicting depths , surface normals and semantic labels from a single image .", "tokens": ["eigen", "et", "al", "use", "a", "multi", "-", "scale", "cnn", "for", "predicting", "depths", ",", "surface", "normals", "and", "semantic", "labels", "from", "a", "single", "image", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "eigen et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "use", "start": 12, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "eigen", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 12, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "eigen", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "predicting", "start": 38, "end": 48, "i_start": 10, "i_end": 10}}], "id": 4214}, {"sent": "graphene , a carbon-based 2d material with extraordinary in-plane charge mobility .", "tokens": ["graphene", ",", "a", "carbon", "-", "based", "2d", "material", "with", "extraordinary", "in", "-", "plane", "charge", "mobility", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4215}, {"sent": "zarubin petersburg nuclear physics institute , gatchina , russia n .", "tokens": ["zarubin", "petersburg", "nuclear", "physics", "institute", ",", "gatchina", ",", "russia", "n", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4216}, {"sent": "our initial network is a v gg16 network pre-trained on the imagenet dataset .", "tokens": ["our", "initial", "network", "is", "a", "v", "gg16", "network", "pre", "-", "trained", "on", "the", "imagenet", "dataset", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our initial network", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 4217}, {"sent": "the first of them was established by kifer and provides a sufficient condition for the validity of ldp for a family of random probability measures .", "tokens": ["the", "first", "of", "them", "was", "established", "by", "kifer", "and", "provides", "a", "sufficient", "condition", "for", "the", "validity", "of", "ldp", "for", "a", "family", "of", "random", "probability", "measures", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the first of them", "start": 0, "end": 17, "i_start": 0, "i_end": 3}, "verb": {"text": "was established", "start": 18, "end": 33, "i_start": 4, "i_end": 5}}, {"subject": {"text": "the first of them", "start": 0, "end": 17, "i_start": 0, "i_end": 3}, "verb": {"text": "provides", "start": 47, "end": 55, "i_start": 9, "i_end": 9}}, {"character": {"text": "kifer", "start": 37, "end": 42, "i_start": 7, "i_end": 7}, "action": {"text": "established", "start": 22, "end": 33, "i_start": 5, "i_end": 5}}], "id": 4218}, {"sent": "shifted forms of these higher order approximations diminish the order to one , making them unusable as chen and deng noted .", "tokens": ["shifted", "forms", "of", "these", "higher", "order", "approximations", "diminish", "the", "order", "to", "one", ",", "making", "them", "unusable", "as", "chen", "and", "deng", "noted", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "shifted forms of these higher order approximations", "start": 0, "end": 50, "i_start": 0, "i_end": 6}, "verb": {"text": "diminish", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "forms", "start": 8, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "diminish", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "diminish", "start": 51, "end": 59, "i_start": 7, "i_end": 7}, "action": {"text": "making", "start": 79, "end": 85, "i_start": 13, "i_end": 13}}, {"character": {"text": "chen", "start": 103, "end": 107, "i_start": 17, "i_end": 17}, "action": {"text": "noted", "start": 117, "end": 122, "i_start": 20, "i_end": 20}}, {"character": {"text": "deng", "start": 112, "end": 116, "i_start": 19, "i_end": 19}, "action": {"text": "noted", "start": 117, "end": 122, "i_start": 20, "i_end": 20}}], "id": 4219}, {"sent": "therefore , it is almost impossible to detect the gws from q-ball formation even by the future detectors in this case .", "tokens": ["therefore", ",", "it", "is", "almost", "impossible", "to", "detect", "the", "gws", "from", "q", "-", "ball", "formation", "even", "by", "the", "future", "detectors", "in", "this", "case", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "future", "start": 88, "end": 94, "i_start": 18, "i_end": 18}, "action": {"text": "detect", "start": 39, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "even", "start": 76, "end": 80, "i_start": 15, "i_end": 15}, "action": {"text": "detect", "start": 39, "end": 45, "i_start": 7, "i_end": 7}}], "id": 4220}, {"sent": "i n recent years , deep convolutional neural networks have demonstrated an outstanding capability in various computer vision tasks , such as image classification .", "tokens": ["i", "n", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "demonstrated", "an", "outstanding", "capability", "in", "various", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 19, "end": 53, "i_start": 5, "i_end": 8}, "verb": {"text": "have demonstrated", "start": 54, "end": 71, "i_start": 9, "i_end": 10}}, {"character": {"text": "networks", "start": 45, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "demonstrated", "start": 59, "end": 71, "i_start": 10, "i_end": 10}}], "id": 4221}, {"sent": "zero-shot learning aims to recognize objects whose instances may not have been seen during training .", "tokens": ["zero", "-", "shot", "learning", "aims", "to", "recognize", "objects", "whose", "instances", "may", "not", "have", "been", "seen", "during", "training", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zero-shot learning", "start": 0, "end": 18, "i_start": 0, "i_end": 3}, "verb": {"text": "aims", "start": 19, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 10, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "aims", "start": 19, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "learning", "start": 10, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "recognize", "start": 27, "end": 36, "i_start": 6, "i_end": 6}}], "id": 4222}, {"sent": "2an orbifold is a space which looks locally like the quotient of rn by a finite group .", "tokens": ["2an", "orbifold", "is", "a", "space", "which", "looks", "locally", "like", "the", "quotient", "of", "rn", "by", "a", "finite", "group", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "2an orbifold", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "space", "start": 18, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "looks", "start": 30, "end": 35, "i_start": 6, "i_end": 6}}], "id": 4223}, {"sent": "its phase space is a cylinder to a mixed regime with a large chaotic domain .", "tokens": ["its", "phase", "space", "is", "a", "cylinder", "to", "a", "mixed", "regime", "with", "a", "large", "chaotic", "domain", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "its phase space", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 4224}, {"sent": "to evaluate the proposed approach and demonstrate the effectiveness of the key components , we conduct an ablation study on the kitti benchmark .", "tokens": ["to", "evaluate", "the", "proposed", "approach", "and", "demonstrate", "the", "effectiveness", "of", "the", "key", "components", ",", "we", "conduct", "an", "ablation", "study", "on", "the", "kitti", "benchmark", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 92, "end": 94, "i_start": 14, "i_end": 14}, "verb": {"text": "conduct", "start": 95, "end": 102, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 92, "end": 94, "i_start": 14, "i_end": 14}, "action": {"text": "conduct", "start": 95, "end": 102, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 92, "end": 94, "i_start": 14, "i_end": 14}, "action": {"text": "study", "start": 115, "end": 120, "i_start": 18, "i_end": 18}}, {"character": {"text": "we", "start": 92, "end": 94, "i_start": 14, "i_end": 14}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 92, "end": 94, "i_start": 14, "i_end": 14}, "action": {"text": "demonstrate", "start": 38, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "components", "start": 79, "end": 89, "i_start": 12, "i_end": 12}, "action": {"text": "effectiveness", "start": 54, "end": 67, "i_start": 8, "i_end": 8}}], "id": 4225}, {"sent": "our implementation is based on the theano library in python .", "tokens": ["our", "implementation", "is", "based", "on", "the", "theano", "library", "in", "python", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our implementation", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is based", "start": 19, "end": 27, "i_start": 2, "i_end": 3}}], "id": 4226}, {"sent": "to deal with this issue , partiallyconnected hybrid mimo architectures were proposed in the literature where the output of each rf chain is connected to only a subset of the antennas .", "tokens": ["to", "deal", "with", "this", "issue", ",", "partiallyconnected", "hybrid", "mimo", "architectures", "were", "proposed", "in", "the", "literature", "where", "the", "output", "of", "each", "rf", "chain", "is", "connected", "to", "only", "a", "subset", "of", "the", "antennas", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "partiallyconnected hybrid mimo architectures", "start": 26, "end": 70, "i_start": 6, "i_end": 9}, "verb": {"text": "were proposed", "start": 71, "end": 84, "i_start": 10, "i_end": 11}}], "id": 4227}, {"sent": "algorithms like stochastic variance reduced gradient method and related approaches mix sgd-like steps with some batch computations to control the stochastic noise .", "tokens": ["algorithms", "like", "stochastic", "variance", "reduced", "gradient", "method", "and", "related", "approaches", "mix", "sgd", "-", "like", "steps", "with", "some", "batch", "computations", "to", "control", "the", "stochastic", "noise", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "algorithms like stochastic variance", "start": 0, "end": 35, "i_start": 0, "i_end": 3}, "verb": {"text": "reduced", "start": 36, "end": 43, "i_start": 4, "i_end": 4}}, {"subject": {"text": "related approaches", "start": 64, "end": 82, "i_start": 8, "i_end": 9}, "verb": {"text": "mix", "start": 83, "end": 86, "i_start": 10, "i_end": 10}}, {"character": {"text": "algorithms", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "mix", "start": 83, "end": 86, "i_start": 10, "i_end": 10}}, {"character": {"text": "method", "start": 53, "end": 59, "i_start": 6, "i_end": 6}, "action": {"text": "reduced", "start": 36, "end": 43, "i_start": 4, "i_end": 4}}], "id": 4228}, {"sent": "following the procedure hinted to in , it can be shown that the only globally coupled variables are the face unknowns for the velocity and the mean value of the pressure in each mesh element .", "tokens": ["following", "the", "procedure", "hinted", "to", "in", ",", "it", "can", "be", "shown", "that", "the", "only", "globally", "coupled", "variables", "are", "the", "face", "unknowns", "for", "the", "velocity", "and", "the", "mean", "value", "of", "the", "pressure", "in", "each", "mesh", "element", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 39, "end": 41, "i_start": 7, "i_end": 7}, "verb": {"text": "can be shown", "start": 42, "end": 54, "i_start": 8, "i_end": 10}}, {"subject": {"text": "it", "start": 39, "end": 41, "i_start": 7, "i_end": 7}, "verb": {"text": "are", "start": 96, "end": 99, "i_start": 17, "i_end": 17}}], "id": 4229}, {"sent": "generative adversarial networks have been introduced as the state of the art in generative models .", "tokens": ["generative", "adversarial", "networks", "have", "been", "introduced", "as", "the", "state", "of", "the", "art", "in", "generative", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "have been introduced", "start": 32, "end": 52, "i_start": 3, "i_end": 5}}], "id": 4230}, {"sent": "he et al proposed neural collaborative filtering , which uses neural network to model interaction between users and items .", "tokens": ["he", "et", "al", "proposed", "neural", "collaborative", "filtering", ",", "which", "uses", "neural", "network", "to", "model", "interaction", "between", "users", "and", "items", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "he", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "he", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "filtering", "start": 39, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "uses", "start": 57, "end": 61, "i_start": 9, "i_end": 9}}, {"character": {"text": "network", "start": 69, "end": 76, "i_start": 11, "i_end": 11}, "action": {"text": "model", "start": 80, "end": 85, "i_start": 13, "i_end": 13}}], "id": 4231}, {"sent": "for the shared encoder , we use the resnet-50 to produce rich and contextual features .", "tokens": ["for", "the", "shared", "encoder", ",", "we", "use", "the", "resnet-50", "to", "produce", "rich", "and", "contextual", "features", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 28, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 28, "end": 31, "i_start": 6, "i_end": 6}}], "id": 4232}, {"sent": "since teleportation is a linear process it may also be used for entanglement swapping .", "tokens": ["since", "teleportation", "is", "a", "linear", "process", "it", "may", "also", "be", "used", "for", "entanglement", "swapping", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "teleportation", "start": 6, "end": 19, "i_start": 1, "i_end": 1}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 2, "i_end": 2}}], "id": 4233}, {"sent": "when the dc voltage is increased further , the temperature diverges as in the ohmic case .", "tokens": ["when", "the", "dc", "voltage", "is", "increased", "further", ",", "the", "temperature", "diverges", "as", "in", "the", "ohmic", "case", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the temperature", "start": 43, "end": 58, "i_start": 8, "i_end": 9}, "verb": {"text": "diverges", "start": 59, "end": 67, "i_start": 10, "i_end": 10}}, {"character": {"text": "temperature", "start": 47, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "diverges", "start": 59, "end": 67, "i_start": 10, "i_end": 10}}], "id": 4234}, {"sent": "this is analogous to the claim of , that the mixed anomalies are canceled by the coupling of the non-commutative gauge bosons to closed string axion-type fields , which cancel the anomaly by the green-schwarz mechanism .", "tokens": ["this", "is", "analogous", "to", "the", "claim", "of", ",", "that", "the", "mixed", "anomalies", "are", "canceled", "by", "the", "coupling", "of", "the", "non", "-", "commutative", "gauge", "bosons", "to", "closed", "string", "axion", "-", "type", "fields", ",", "which", "cancel", "the", "anomaly", "by", "the", "green", "-", "schwarz", "mechanism", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the mixed anomalies", "start": 41, "end": 60, "i_start": 9, "i_end": 11}, "verb": {"text": "canceled", "start": 65, "end": 73, "i_start": 13, "i_end": 13}}, {"character": {"text": "coupling", "start": 81, "end": 89, "i_start": 16, "i_end": 16}, "action": {"text": "canceled", "start": 65, "end": 73, "i_start": 13, "i_end": 13}}, {"character": {"text": "coupling", "start": 81, "end": 89, "i_start": 16, "i_end": 16}, "action": {"text": "cancel", "start": 169, "end": 175, "i_start": 33, "i_end": 33}}], "id": 4235}, {"sent": "dong and lapata introduce a sequenceto-sequence approach to converting text to logical forms .", "tokens": ["dong", "and", "lapata", "introduce", "a", "sequenceto", "-", "sequence", "approach", "to", "converting", "text", "to", "logical", "forms", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "dong and lapata", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "introduce", "start": 16, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "dong", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "introduce", "start": 16, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "lapata", "start": 9, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "introduce", "start": 16, "end": 25, "i_start": 3, "i_end": 3}}], "id": 4236}, {"sent": "carma consists of six 10 m and nine 6 m antennas located at 2200 meters elevation at cedar flat in the inyo mountains of california .", "tokens": ["carma", "consists", "of", "six", "10", "m", "and", "nine", "6", "m", "antennas", "located", "at", "2200", "meters", "elevation", "at", "cedar", "flat", "in", "the", "inyo", "mountains", "of", "california", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "carma", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "consists", "start": 6, "end": 14, "i_start": 1, "i_end": 1}}], "id": 4237}, {"sent": "here and throughout , overdots denote derivatives with respect to conformal time , and a is the scale factor normalised to unity today .", "tokens": ["here", "and", "throughout", ",", "overdots", "denote", "derivatives", "with", "respect", "to", "conformal", "time", ",", "and", "a", "is", "the", "scale", "factor", "normalised", "to", "unity", "today", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "overdots denote derivatives with respect to conformal time , and a", "start": 22, "end": 88, "i_start": 4, "i_end": 14}, "verb": {"text": "is", "start": 89, "end": 91, "i_start": 15, "i_end": 15}}, {"character": {"text": "overdots", "start": 22, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "denote", "start": 31, "end": 37, "i_start": 5, "i_end": 5}}], "id": 4238}, {"sent": "a bloom filter is an efficient data structure that encodes an approximate set .", "tokens": ["a", "bloom", "filter", "is", "an", "efficient", "data", "structure", "that", "encodes", "an", "approximate", "set", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a bloom filter", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "structure", "start": 36, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "encodes", "start": 51, "end": 58, "i_start": 9, "i_end": 9}}], "id": 4239}, {"sent": "specifically , mud algorithms based on the algorithms of jacobi , gs and sor were investigated .", "tokens": ["specifically", ",", "mud", "algorithms", "based", "on", "the", "algorithms", "of", "jacobi", ",", "gs", "and", "sor", "were", "investigated", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "gs and sor", "start": 66, "end": 76, "i_start": 11, "i_end": 13}, "verb": {"text": "were investigated", "start": 77, "end": 94, "i_start": 14, "i_end": 15}}], "id": 4240}, {"sent": "evolution towards an equilibrium state after a global quantum quench is an example of the thermalization .", "tokens": ["evolution", "towards", "an", "equilibrium", "state", "after", "a", "global", "quantum", "quench", "is", "an", "example", "of", "the", "thermalization", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "evolution towards an equilibrium state after a global quantum quench", "start": 0, "end": 68, "i_start": 0, "i_end": 9}, "verb": {"text": "is", "start": 69, "end": 71, "i_start": 10, "i_end": 10}}], "id": 4241}, {"sent": "now , we will recall briefly the combinatorial construction for link heegaardfloer homology given in .", "tokens": ["now", ",", "we", "will", "recall", "briefly", "the", "combinatorial", "construction", "for", "link", "heegaardfloer", "homology", "given", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "verb": {"text": "will recall", "start": 9, "end": 20, "i_start": 3, "i_end": 4}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "recall", "start": 14, "end": 20, "i_start": 4, "i_end": 4}}], "id": 4242}, {"sent": "this saturation is a signature of statistics dominated by front-like structures , the cliffs .", "tokens": ["this", "saturation", "is", "a", "signature", "of", "statistics", "dominated", "by", "front", "-", "like", "structures", ",", "the", "cliffs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this saturation", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "structures", "start": 69, "end": 79, "i_start": 12, "i_end": 12}, "action": {"text": "dominated", "start": 45, "end": 54, "i_start": 7, "i_end": 7}}], "id": 4243}, {"sent": "we derive these complexity measures by combining the technique of chaining mutual information , with the multilevel architecture of neural nets .", "tokens": ["we", "derive", "these", "complexity", "measures", "by", "combining", "the", "technique", "of", "chaining", "mutual", "information", ",", "with", "the", "multilevel", "architecture", "of", "neural", "nets", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "derive", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "derive", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "combining", "start": 39, "end": 48, "i_start": 6, "i_end": 6}}], "id": 4244}, {"sent": "we will show that this series expansion is convergent , under the assumption of bounded potentials .", "tokens": ["we", "will", "show", "that", "this", "series", "expansion", "is", "convergent", ",", "under", "the", "assumption", "of", "bounded", "potentials", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will show", "start": 3, "end": 12, "i_start": 1, "i_end": 2}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 40, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}], "id": 4245}, {"sent": "further , we give an explicit criterion on the singular parameters for bn over an arbitrary field .", "tokens": ["further", ",", "we", "give", "an", "explicit", "criterion", "on", "the", "singular", "parameters", "for", "bn", "over", "an", "arbitrary", "field", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "give", "start": 13, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "give", "start": 13, "end": 17, "i_start": 3, "i_end": 3}}], "id": 4246}, {"sent": "deep neural networks have been significantly successful in many artificial intelligence tasks such as im- age classification .", "tokens": ["deep", "neural", "networks", "have", "been", "significantly", "successful", "in", "many", "artificial", "intelligence", "tasks", "such", "as", "im-", "age", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 45, "end": 55, "i_start": 6, "i_end": 6}}], "id": 4247}, {"sent": "using an efficient implementation of the pseudoinverse by means of the lsqr algorithm , we observed a running time that was only half or even less than half that of omp , and a performance that was only slightly poorer than that of omp .", "tokens": ["using", "an", "efficient", "implementation", "of", "the", "pseudoinverse", "by", "means", "of", "the", "lsqr", "algorithm", ",", "we", "observed", "a", "running", "time", "that", "was", "only", "half", "or", "even", "less", "than", "half", "that", "of", "omp", ",", "and", "a", "performance", "that", "was", "only", "slightly", "poorer", "than", "that", "of", "omp", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 88, "end": 90, "i_start": 14, "i_end": 14}, "verb": {"text": "observed", "start": 91, "end": 99, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 88, "end": 90, "i_start": 14, "i_end": 14}, "action": {"text": "observed", "start": 91, "end": 99, "i_start": 15, "i_end": 15}}], "id": 4248}, {"sent": "on the other hand , the classification scheme regards each identity as a unique class and train the network as a n -way classification problem , such as the softmax .", "tokens": ["on", "the", "other", "hand", ",", "the", "classification", "scheme", "regards", "each", "identity", "as", "a", "unique", "class", "and", "train", "the", "network", "as", "a", "n", "-way", "classification", "problem", ",", "such", "as", "the", "softmax", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the classification scheme", "start": 20, "end": 45, "i_start": 5, "i_end": 7}, "verb": {"text": "regards", "start": 46, "end": 53, "i_start": 8, "i_end": 8}}, {"subject": {"text": "the classification scheme", "start": 20, "end": 45, "i_start": 5, "i_end": 7}, "verb": {"text": "train", "start": 90, "end": 95, "i_start": 16, "i_end": 16}}, {"character": {"text": "scheme", "start": 39, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "regards", "start": 46, "end": 53, "i_start": 8, "i_end": 8}}, {"character": {"text": "scheme", "start": 39, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "classification", "start": 24, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "scheme", "start": 39, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "train", "start": 90, "end": 95, "i_start": 16, "i_end": 16}}], "id": 4249}, {"sent": "exchange and correlation effects were treated in the generalized gradient approximation in the formulation of perdew , burke , and ernzerhof .", "tokens": ["exchange", "and", "correlation", "effects", "were", "treated", "in", "the", "generalized", "gradient", "approximation", "in", "the", "formulation", "of", "perdew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "exchange and correlation effects", "start": 0, "end": 32, "i_start": 0, "i_end": 3}, "verb": {"text": "were treated", "start": 33, "end": 45, "i_start": 4, "i_end": 5}}], "id": 4250}, {"sent": "capasso , enhancing acceleration radiation from ground-state atoms via cavity quantum electrodynamics , phys .", "tokens": ["capasso", ",", "enhancing", "acceleration", "radiation", "from", "ground", "-", "state", "atoms", "via", "cavity", "quantum", "electrodynamics", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "capasso", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "enhancing", "start": 10, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "atoms", "start": 61, "end": 66, "i_start": 9, "i_end": 9}, "action": {"text": "radiation", "start": 33, "end": 42, "i_start": 4, "i_end": 4}}], "id": 4251}, {"sent": "bose-einstein condensates represent an ideal platform for the investigation of weak to strongly correlated quantum many-body systems , and are especially appealing due to their exquisite experimental control .", "tokens": ["bose", "-", "einstein", "condensates", "represent", "an", "ideal", "platform", "for", "the", "investigation", "of", "weak", "to", "strongly", "correlated", "quantum", "many", "-", "body", "systems", ",", "and", "are", "especially", "appealing", "due", "to", "their", "exquisite", "experimental", "control", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bose-einstein condensates", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "represent", "start": 26, "end": 35, "i_start": 4, "i_end": 4}}, {"subject": {"text": "bose-einstein condensates", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "appealing", "start": 154, "end": 163, "i_start": 25, "i_end": 25}}, {"character": {"text": "condensates", "start": 14, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "represent", "start": 26, "end": 35, "i_start": 4, "i_end": 4}}], "id": 4252}, {"sent": "the third axiom transcribes the reverse oriented reidemeister move .", "tokens": ["the", "third", "axiom", "transcribes", "the", "reverse", "oriented", "reidemeister", "move", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the third axiom", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "transcribes", "start": 16, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "axiom", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "transcribes", "start": 16, "end": 27, "i_start": 3, "i_end": 3}}], "id": 4253}, {"sent": "recently , deep convolutional neural networks showed outstanding performance in automatic feature extraction , leading to a dramatic breakthrough in a range of fields associated with computer vision .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "showed", "outstanding", "performance", "in", "automatic", "feature", "extraction", ",", "leading", "to", "a", "dramatic", "breakthrough", "in", "a", "range", "of", "fields", "associated", "with", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "showed", "start": 46, "end": 52, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "showed", "start": 46, "end": 52, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 65, "end": 76, "i_start": 8, "i_end": 8}}, {"character": {"text": "showed", "start": 46, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "leading", "start": 111, "end": 118, "i_start": 14, "i_end": 14}}], "id": 4254}, {"sent": "logistic regression is a widely used discriminative model for two-class classification 2 .", "tokens": ["logistic", "regression", "is", "a", "widely", "used", "discriminative", "model", "for", "two", "-", "class", "classification", "2", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "logistic regression", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "model", "start": 52, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "discriminative", "start": 37, "end": 51, "i_start": 6, "i_end": 6}}], "id": 4255}, {"sent": "to support discrete communication messages , we use the gumbelsoftmax estimator .", "tokens": ["to", "support", "discrete", "communication", "messages", ",", "we", "use", "the", "gumbelsoftmax", "estimator", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 45, "end": 47, "i_start": 6, "i_end": 6}, "verb": {"text": "use", "start": 48, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 45, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "use", "start": 48, "end": 51, "i_start": 7, "i_end": 7}}], "id": 4256}, {"sent": "jaderberg et al use synthetic data to train cnn models for natural scene text recognition .", "tokens": ["jaderberg", "et", "al", "use", "synthetic", "data", "to", "train", "cnn", "models", "for", "natural", "scene", "text", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "jaderberg et al", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "use", "start": 16, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "jaderberg", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 16, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "jaderberg", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 38, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "models", "start": 48, "end": 54, "i_start": 9, "i_end": 9}, "action": {"text": "recognition", "start": 78, "end": 89, "i_start": 14, "i_end": 14}}], "id": 4257}, {"sent": "a self-organization of complex systems that reflects economical and power rules in societies .", "tokens": ["a", "self", "-", "organization", "of", "complex", "systems", "that", "reflects", "economical", "and", "power", "rules", "in", "societies", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4258}, {"sent": "it is well known how the noncommutativity appears in d-branes , when the open string dynamics is analyzed in the presence of constant b-field .", "tokens": ["it", "is", "well", "known", "how", "the", "noncommutativity", "appears", "in", "d", "-", "branes", ",", "when", "the", "open", "string", "dynamics", "is", "analyzed", "in", "the", "presence", "of", "constant", "b", "-", "field", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the noncommutativity", "start": 21, "end": 41, "i_start": 5, "i_end": 6}, "verb": {"text": "appears", "start": 42, "end": 49, "i_start": 7, "i_end": 7}}], "id": 4259}, {"sent": "on the other hand , in it is shown that any simple cubic graph admits a normal 7-edge-coloring .", "tokens": ["on", "the", "other", "hand", ",", "in", "it", "is", "shown", "that", "any", "simple", "cubic", "graph", "admits", "a", "normal", "7", "-", "edge", "-", "coloring", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 23, "end": 25, "i_start": 6, "i_end": 6}, "verb": {"text": "is shown", "start": 26, "end": 34, "i_start": 7, "i_end": 8}}, {"subject": {"text": "any simple cubic graph", "start": 40, "end": 62, "i_start": 10, "i_end": 13}, "verb": {"text": "admits", "start": 63, "end": 69, "i_start": 14, "i_end": 14}}, {"character": {"text": "graph", "start": 57, "end": 62, "i_start": 13, "i_end": 13}, "action": {"text": "admits", "start": 63, "end": 69, "i_start": 14, "i_end": 14}}], "id": 4260}, {"sent": "each t -junction consists of two horizontal channels a and b .", "tokens": ["each", "t", "-junction", "consists", "of", "two", "horizontal", "channels", "a", "and", "b", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each t -junction", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}], "id": 4261}, {"sent": "in the current era , deep learning techniques have made significant development in fields such as artificial intelligence .", "tokens": ["in", "the", "current", "era", ",", "deep", "learning", "techniques", "have", "made", "significant", "development", "in", "fields", "such", "as", "artificial", "intelligence", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning techniques", "start": 21, "end": 45, "i_start": 5, "i_end": 7}, "verb": {"text": "have made", "start": 46, "end": 55, "i_start": 8, "i_end": 9}}], "id": 4262}, {"sent": "as the pulsar is a relatively bright source , short exposure times were used .", "tokens": ["as", "the", "pulsar", "is", "a", "relatively", "bright", "source", ",", "short", "exposure", "times", "were", "used", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "short exposure times", "start": 46, "end": 66, "i_start": 9, "i_end": 11}, "verb": {"text": "were used", "start": 67, "end": 76, "i_start": 12, "i_end": 13}}], "id": 4263}, {"sent": "li et al utilize a proposal network to estimate the score maps and bounding boxes using two branches , which provides more accurate object scales than the traditional multi-resolution scale estimation .", "tokens": ["li", "et", "al", "utilize", "a", "proposal", "network", "to", "estimate", "the", "score", "maps", "and", "bounding", "boxes", "using", "two", "branches", ",", "which", "provides", "more", "accurate", "object", "scales", "than", "the", "traditional", "multi", "-", "resolution", "scale", "estimation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "li et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "utilize", "start": 9, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "li", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "utilize", "start": 9, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "network", "start": 28, "end": 35, "i_start": 6, "i_end": 6}, "action": {"text": "proposal", "start": 19, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "li", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "estimate", "start": 39, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "estimate", "start": 39, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "provides", "start": 109, "end": 117, "i_start": 20, "i_end": 20}}], "id": 4264}, {"sent": "we refer to for the definition of standard and good determinantal schemes .", "tokens": ["we", "refer", "to", "for", "the", "definition", "of", "standard", "and", "good", "determinantal", "schemes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 4265}, {"sent": "a standard fifth-order weno method is applied in the direction perpendicular to the cell interface to determine the line-averaged values of the variables on both sides of it .", "tokens": ["a", "standard", "fifth", "-", "order", "weno", "method", "is", "applied", "in", "the", "direction", "perpendicular", "to", "the", "cell", "interface", "to", "determine", "the", "line", "-", "averaged", "values", "of", "the", "variables", "on", "both", "sides", "of", "it", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a standard fifth-order weno method", "start": 0, "end": 34, "i_start": 0, "i_end": 6}, "verb": {"text": "is applied", "start": 35, "end": 45, "i_start": 7, "i_end": 8}}, {"character": {"text": "method", "start": 28, "end": 34, "i_start": 6, "i_end": 6}, "action": {"text": "determine", "start": 102, "end": 111, "i_start": 18, "i_end": 18}}, {"character": {"text": "variables", "start": 144, "end": 153, "i_start": 26, "i_end": 26}, "action": {"text": "averaged", "start": 121, "end": 129, "i_start": 22, "i_end": 22}}], "id": 4266}, {"sent": "the exchange-correlation energy was evaluated with the help of the perdew-burke-erzenhof approach , within the generalised gradient approximation .", "tokens": ["the", "exchange", "-", "correlation", "energy", "was", "evaluated", "with", "the", "help", "of", "the", "perdew", "-", "burke", "-", "erzenhof", "approach", ",", "within", "the", "generalised", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange-correlation energy", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "was evaluated", "start": 32, "end": 45, "i_start": 5, "i_end": 6}}, {"character": {"text": "approach", "start": 89, "end": 97, "i_start": 17, "i_end": 17}, "action": {"text": "help", "start": 55, "end": 59, "i_start": 9, "i_end": 9}}], "id": 4267}, {"sent": "in , a dynamic bandwidth algorithm based on local storage vod delivery in pons was proposed and achievable throughput levels have been improved when a local storage is used to assist vod delivery .", "tokens": ["in", ",", "a", "dynamic", "bandwidth", "algorithm", "based", "on", "local", "storage", "vod", "delivery", "in", "pons", "was", "proposed", "and", "achievable", "throughput", "levels", "have", "been", "improved", "when", "a", "local", "storage", "is", "used", "to", "assist", "vod", "delivery", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a dynamic bandwidth algorithm based on local storage vod delivery in pons", "start": 5, "end": 78, "i_start": 2, "i_end": 13}, "verb": {"text": "was proposed", "start": 79, "end": 91, "i_start": 14, "i_end": 15}}, {"subject": {"text": "achievable throughput levels", "start": 96, "end": 124, "i_start": 17, "i_end": 19}, "verb": {"text": "improved", "start": 135, "end": 143, "i_start": 22, "i_end": 22}}], "id": 4268}, {"sent": "the ellipses denotes terms that are subleading in r relative to the terms written above .", "tokens": ["the", "ellipses", "denotes", "terms", "that", "are", "subleading", "in", "r", "relative", "to", "the", "terms", "written", "above", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ellipses", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "denotes", "start": 13, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "ellipses", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denotes", "start": 13, "end": 20, "i_start": 2, "i_end": 2}}], "id": 4269}, {"sent": "deep neural networks have achieved impressive performance on tasks across a variety of domains , including vision .", "tokens": ["deep", "neural", "networks", "have", "achieved", "impressive", "performance", "on", "tasks", "across", "a", "variety", "of", "domains", ",", "including", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 46, "end": 57, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 46, "end": 57, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 35, "end": 45, "i_start": 5, "i_end": 5}}], "id": 4270}, {"sent": "the geometrical relaxations are carried out within the framework of density-functional theory , as implemented in the vienna ab initio simulation package code .", "tokens": ["the", "geometrical", "relaxations", "are", "carried", "out", "within", "the", "framework", "of", "density", "-", "functional", "theory", ",", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "code", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the geometrical relaxations", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "are carried out", "start": 28, "end": 43, "i_start": 3, "i_end": 5}}], "id": 4271}, {"sent": "the first-principles density functional theory calculations in this work were carried out using the vienna ab-initio simulation package .", "tokens": ["the", "first", "-", "principles", "density", "functional", "theory", "calculations", "in", "this", "work", "were", "carried", "out", "using", "the", "vienna", "ab", "-", "initio", "simulation", "package", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the first-principles density functional theory calculations in this work", "start": 0, "end": 72, "i_start": 0, "i_end": 10}, "verb": {"text": "were carried out", "start": 73, "end": 89, "i_start": 11, "i_end": 13}}], "id": 4272}, {"sent": "a spreading activation theory of semantic processing .", "tokens": ["a", "spreading", "activation", "theory", "of", "semantic", "processing", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4273}, {"sent": "an n-best em variant is employed to reestimate the model parameters such that the ppl on training data is decreasedthe likelihood of the training data under our model is increased .", "tokens": ["an", "n", "-", "best", "em", "variant", "is", "employed", "to", "reestimate", "the", "model", "parameters", "such", "that", "the", "ppl", "on", "training", "data", "is", "decreasedthe", "likelihood", "of", "the", "training", "data", "under", "our", "model", "is", "increased", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "an n-best em variant", "start": 0, "end": 20, "i_start": 0, "i_end": 5}, "verb": {"text": "is employed", "start": 21, "end": 32, "i_start": 6, "i_end": 7}}, {"subject": {"text": "an n-best em variant", "start": 0, "end": 20, "i_start": 0, "i_end": 5}, "verb": {"text": "increased", "start": 170, "end": 179, "i_start": 31, "i_end": 31}}, {"character": {"text": "variant", "start": 13, "end": 20, "i_start": 5, "i_end": 5}, "action": {"text": "reestimate", "start": 36, "end": 46, "i_start": 9, "i_end": 9}}], "id": 4274}, {"sent": "our models are trained using stochastic gradient descent with adam .", "tokens": ["our", "models", "are", "trained", "using", "stochastic", "gradient", "descent", "with", "adam", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our models", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "are trained", "start": 11, "end": 22, "i_start": 2, "i_end": 3}}], "id": 4275}, {"sent": "the original dynamo was one of the pioneers in the eventual consistency movement and served as the basis for voldemort key-value store .", "tokens": ["the", "original", "dynamo", "was", "one", "of", "the", "pioneers", "in", "the", "eventual", "consistency", "movement", "and", "served", "as", "the", "basis", "for", "voldemort", "key", "-", "value", "store", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the original dynamo", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "was", "start": 20, "end": 23, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the original dynamo", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "served", "start": 85, "end": 91, "i_start": 14, "i_end": 14}}], "id": 4276}, {"sent": "for this purpose , we use a markov-chain monte-carlo approach to explore the available parameter space using a modified version of the widely used package cosmomc .", "tokens": ["for", "this", "purpose", ",", "we", "use", "a", "markov", "-", "chain", "monte", "-", "carlo", "approach", "to", "explore", "the", "available", "parameter", "space", "using", "a", "modified", "version", "of", "the", "widely", "used", "package", "cosmomc", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 22, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 22, "end": 25, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "explore", "start": 65, "end": 72, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "using", "start": 103, "end": 108, "i_start": 20, "i_end": 20}}], "id": 4277}, {"sent": "appear as sequence a000139 in the online encyclopedia of integer sequences .", "tokens": ["appear", "as", "sequence", "a000139", "in", "the", "online", "encyclopedia", "of", "integer", "sequences", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4278}, {"sent": "last column show the velocity dispersion measured in the different stacked spectra .", "tokens": ["last", "column", "show", "the", "velocity", "dispersion", "measured", "in", "the", "different", "stacked", "spectra", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "last column", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "show", "start": 12, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "column", "start": 5, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 12, "end": 16, "i_start": 2, "i_end": 2}}], "id": 4279}, {"sent": "large mimo is believed to be one of the key technologies for 5g wireless systems .", "tokens": ["large", "mimo", "is", "believed", "to", "be", "one", "of", "the", "key", "technologies", "for", "5", "g", "wireless", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "large mimo", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is believed", "start": 11, "end": 22, "i_start": 2, "i_end": 3}}], "id": 4280}, {"sent": "deep neural networks are powerful methods for solving large scale real world problems such as automated image classification .", "tokens": ["deep", "neural", "networks", "are", "powerful", "methods", "for", "solving", "large", "scale", "real", "world", "problems", "such", "as", "automated", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}], "id": 4281}, {"sent": "these simulations were performed using the lammps code with the reactive force field .", "tokens": ["these", "simulations", "were", "performed", "using", "the", "lammps", "code", "with", "the", "reactive", "force", "field", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these simulations", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "were performed", "start": 18, "end": 32, "i_start": 2, "i_end": 3}}, {"character": {"text": "force", "start": 73, "end": 78, "i_start": 11, "i_end": 11}, "action": {"text": "reactive", "start": 64, "end": 72, "i_start": 10, "i_end": 10}}], "id": 4282}, {"sent": "recently , deep learning has made breakthroughs in computer vision and natural language processing , presented new opportunities to recommender systems .", "tokens": ["recently", ",", "deep", "learning", "has", "made", "breakthroughs", "in", "computer", "vision", "and", "natural", "language", "processing", ",", "presented", "new", "opportunities", "to", "recommender", "systems", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 11, "end": 24, "i_start": 2, "i_end": 3}, "verb": {"text": "has made", "start": 25, "end": 33, "i_start": 4, "i_end": 5}}, {"subject": {"text": "deep learning", "start": 11, "end": 24, "i_start": 2, "i_end": 3}, "verb": {"text": "presented", "start": 101, "end": 110, "i_start": 15, "i_end": 15}}, {"character": {"text": "learning", "start": 16, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "breakthroughs", "start": 34, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "systems", "start": 144, "end": 151, "i_start": 20, "i_end": 20}, "action": {"text": "recommender", "start": 132, "end": 143, "i_start": 19, "i_end": 19}}], "id": 4283}, {"sent": "more generally , it has been realized that noncommutative gauge theory arises as the worldvolume theory on d-branes in the presence of a constant background b field in string theory .", "tokens": ["more", "generally", ",", "it", "has", "been", "realized", "that", "noncommutative", "gauge", "theory", "arises", "as", "the", "worldvolume", "theory", "on", "d", "-", "branes", "in", "the", "presence", "of", "a", "constant", "background", "b", "field", "in", "string", "theory", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 17, "end": 19, "i_start": 3, "i_end": 3}, "verb": {"text": "has been realized", "start": 20, "end": 37, "i_start": 4, "i_end": 6}}, {"subject": {"text": "noncommutative gauge theory", "start": 43, "end": 70, "i_start": 8, "i_end": 10}, "verb": {"text": "arises", "start": 71, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "presence", "start": 123, "end": 131, "i_start": 22, "i_end": 22}, "action": {"text": "arises", "start": 71, "end": 77, "i_start": 11, "i_end": 11}}], "id": 4284}, {"sent": "we will proceed onto give examples of them .", "tokens": ["we", "will", "proceed", "onto", "give", "examples", "of", "them", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will proceed", "start": 3, "end": 15, "i_start": 1, "i_end": 2}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "give", "start": 21, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proceed", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "give", "start": 21, "end": 25, "i_start": 4, "i_end": 4}}], "id": 4285}, {"sent": "at this point it has been suggested that the neutral nambu-goldstone boson , being odd under cp , might condense and spontaneously break cp .", "tokens": ["at", "this", "point", "it", "has", "been", "suggested", "that", "the", "neutral", "nambu", "-", "goldstone", "boson", ",", "being", "odd", "under", "cp", ",", "might", "condense", "and", "spontaneously", "break", "cp", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "has been suggested", "start": 17, "end": 35, "i_start": 4, "i_end": 6}}, {"subject": {"text": "the neutral nambu-goldstone boson", "start": 41, "end": 74, "i_start": 8, "i_end": 13}, "verb": {"text": "condense", "start": 104, "end": 112, "i_start": 21, "i_end": 21}}, {"character": {"text": "boson", "start": 69, "end": 74, "i_start": 13, "i_end": 13}, "action": {"text": "neutral", "start": 45, "end": 52, "i_start": 9, "i_end": 9}}, {"character": {"text": "boson", "start": 69, "end": 74, "i_start": 13, "i_end": 13}, "action": {"text": "break", "start": 131, "end": 136, "i_start": 24, "i_end": 24}}], "id": 4286}, {"sent": "this bound is close to the bugey upper bound in the schemes .", "tokens": ["this", "bound", "is", "close", "to", "the", "bugey", "upper", "bound", "in", "the", "schemes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this bound", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}], "id": 4287}, {"sent": "postman m , lubin lm , gunn je , oke jb , hoessel jg , schneider dp , christensen ja .", "tokens": ["postman", "m", ",", "lubin", "lm", ",", "gunn", "je", ",", "oke", "jb", ",", "hoessel", "jg", ",", "schneider", "dp", ",", "christensen", "ja", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4288}, {"sent": "facebook , ibm , google , microsoft , pushing towards deploying services based on brain-inspired machinelearning to their customers .", "tokens": ["facebook", ",", "ibm", ",", "google", ",", "microsoft", ",", "pushing", "towards", "deploying", "services", "based", "on", "brain", "-", "inspired", "machinelearning", "to", "their", "customers", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "facebook", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "pushing", "start": 38, "end": 45, "i_start": 8, "i_end": 8}}, {"character": {"text": "ibm", "start": 11, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "pushing", "start": 38, "end": 45, "i_start": 8, "i_end": 8}}, {"character": {"text": "google", "start": 17, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "pushing", "start": 38, "end": 45, "i_start": 8, "i_end": 8}}, {"character": {"text": "microsoft", "start": 26, "end": 35, "i_start": 6, "i_end": 6}, "action": {"text": "pushing", "start": 38, "end": 45, "i_start": 8, "i_end": 8}}], "id": 4289}, {"sent": "this phenomenon was identified from the first reports of this gradient up to the most recent study .", "tokens": ["this", "phenomenon", "was", "identified", "from", "the", "first", "reports", "of", "this", "gradient", "up", "to", "the", "most", "recent", "study", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this phenomenon", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "was identified", "start": 16, "end": 30, "i_start": 2, "i_end": 3}}, {"subject": {"text": "this phenomenon", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "up", "start": 71, "end": 73, "i_start": 11, "i_end": 11}}], "id": 4290}, {"sent": "a smaller number of disorder realizations has been sampled for smaller lattices .", "tokens": ["a", "smaller", "number", "of", "disorder", "realizations", "has", "been", "sampled", "for", "smaller", "lattices", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a smaller number of disorder realizations", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "has been sampled", "start": 42, "end": 58, "i_start": 6, "i_end": 8}}], "id": 4291}, {"sent": "we also compare the first-order and the second-order lagrangian approximations to examine the validity of the approximation scheme .", "tokens": ["we", "also", "compare", "the", "first", "-", "order", "and", "the", "second", "-", "order", "lagrangian", "approximations", "to", "examine", "the", "validity", "of", "the", "approximation", "scheme", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "compare", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compare", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "examine", "start": 82, "end": 89, "i_start": 15, "i_end": 15}}], "id": 4292}, {"sent": "the work in attacks this problem and formulates the outlier detection as a lasso problem based on sparse approximations of the cyclic ranking projection of paired comparison data in hodge decomposition .", "tokens": ["the", "work", "in", "attacks", "this", "problem", "and", "formulates", "the", "outlier", "detection", "as", "a", "lasso", "problem", "based", "on", "sparse", "approximations", "of", "the", "cyclic", "ranking", "projection", "of", "paired", "comparison", "data", "in", "hodge", "decomposition", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4293}, {"sent": "deep neural networks have achieved state-of-the-art performance in many application areas , such as computer vision and natural language processing .", "tokens": ["deep", "neural", "networks", "have", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "many", "application", "areas", ",", "such", "as", "computer", "vision", "and", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 52, "end": 63, "i_start": 12, "i_end": 12}}], "id": 4294}, {"sent": "zurada describes a method called rule extraction from function approximating neural networks for extracting rules from trained neural networks for nonlinear regression .", "tokens": ["zurada", "describes", "a", "method", "called", "rule", "extraction", "from", "function", "approximating", "neural", "networks", "for", "extracting", "rules", "from", "trained", "neural", "networks", "for", "nonlinear", "regression", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zurada", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "describes", "start": 7, "end": 16, "i_start": 1, "i_end": 1}}, {"character": {"text": "zurada", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "describes", "start": 7, "end": 16, "i_start": 1, "i_end": 1}}], "id": 4295}, {"sent": "with the vast amount of data and powerful hardware resources , deep learning algorithms have obtained high performance across many applications , such as computer vision .", "tokens": ["with", "the", "vast", "amount", "of", "data", "and", "powerful", "hardware", "resources", ",", "deep", "learning", "algorithms", "have", "obtained", "high", "performance", "across", "many", "applications", ",", "such", "as", "computer", "vision", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "deep learning algorithms", "start": 63, "end": 87, "i_start": 11, "i_end": 13}, "verb": {"text": "have obtained", "start": 88, "end": 101, "i_start": 14, "i_end": 15}}, {"character": {"text": "algorithms", "start": 77, "end": 87, "i_start": 13, "i_end": 13}, "action": {"text": "obtained", "start": 93, "end": 101, "i_start": 15, "i_end": 15}}, {"character": {"text": "algorithms", "start": 77, "end": 87, "i_start": 13, "i_end": 13}, "action": {"text": "learning", "start": 68, "end": 76, "i_start": 12, "i_end": 12}}], "id": 4296}, {"sent": "let us consider the propagation of soliton in the inhomogeneous chain with random sequence of bases .", "tokens": ["let", "us", "consider", "the", "propagation", "of", "soliton", "in", "the", "inhomogeneous", "chain", "with", "random", "sequence", "of", "bases", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "consider", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "consider", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}], "id": 4297}, {"sent": "a foliation by c k leaves which is tranversely c k is called simply a c k foliation .", "tokens": ["a", "foliation", "by", "c", "k", "leaves", "which", "is", "tranversely", "c", "k", "is", "called", "simply", "a", "c", "k", "foliation", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "c k", "start": 47, "end": 50, "i_start": 9, "i_end": 10}, "verb": {"text": "is called", "start": 51, "end": 60, "i_start": 11, "i_end": 12}}, {"subject": {"text": "a foliation by c k", "start": 0, "end": 18, "i_start": 0, "i_end": 4}, "verb": {"text": "leaves", "start": 19, "end": 25, "i_start": 5, "i_end": 5}}], "id": 4298}, {"sent": "sen , continuous cohomology and p-adic galois representations , invent .", "tokens": ["sen", ",", "continuous", "cohomology", "and", "p", "-", "adic", "galois", "representations", ",", "invent", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "sen", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "invent", "start": 64, "end": 70, "i_start": 11, "i_end": 11}}, {"character": {"text": "representations", "start": 46, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "invent", "start": 64, "end": 70, "i_start": 11, "i_end": 11}}, {"character": {"text": "cohomology", "start": 17, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "invent", "start": 64, "end": 70, "i_start": 11, "i_end": 11}}, {"character": {"text": "galois", "start": 39, "end": 45, "i_start": 8, "i_end": 8}, "action": {"text": "invent", "start": 64, "end": 70, "i_start": 11, "i_end": 11}}], "id": 4299}, {"sent": "in , wendl shows that minimal strong filling of is unique up to symplectic deformation .", "tokens": ["in", ",", "wendl", "shows", "that", "minimal", "strong", "filling", "of", "is", "unique", "up", "to", "symplectic", "deformation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "wendl", "start": 5, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "shows", "start": 11, "end": 16, "i_start": 3, "i_end": 3}}, {"subject": {"text": "wendl", "start": 5, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 48, "end": 50, "i_start": 9, "i_end": 9}}, {"character": {"text": "wendl", "start": 5, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "shows", "start": 11, "end": 16, "i_start": 3, "i_end": 3}}], "id": 4300}, {"sent": "the structural and statistical properties of evolving and dynamical networks have been studied intensively over the last decade .", "tokens": ["the", "structural", "and", "statistical", "properties", "of", "evolving", "and", "dynamical", "networks", "have", "been", "studied", "intensively", "over", "the", "last", "decade", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the structural and statistical properties of evolving and dynamical networks", "start": 0, "end": 76, "i_start": 0, "i_end": 9}, "verb": {"text": "have been studied", "start": 77, "end": 94, "i_start": 10, "i_end": 12}}], "id": 4301}, {"sent": "residual connections were first introduced and later refined by he et al for the effective training of deep networks .", "tokens": ["residual", "connections", "were", "first", "introduced", "and", "later", "refined", "by", "he", "et", "al", "for", "the", "effective", "training", "of", "deep", "networks", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "residual connections", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "introduced", "start": 32, "end": 42, "i_start": 4, "i_end": 4}}, {"subject": {"text": "residual connections", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "were", "start": 21, "end": 25, "i_start": 2, "i_end": 2}}, {"subject": {"text": "residual connections", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "refined", "start": 53, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "he", "start": 64, "end": 66, "i_start": 9, "i_end": 9}, "action": {"text": "introduced", "start": 32, "end": 42, "i_start": 4, "i_end": 4}}, {"character": {"text": "he", "start": 64, "end": 66, "i_start": 9, "i_end": 9}, "action": {"text": "refined", "start": 53, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 108, "end": 116, "i_start": 18, "i_end": 18}, "action": {"text": "effective", "start": 81, "end": 90, "i_start": 14, "i_end": 14}}], "id": 4302}, {"sent": "high-quality sources of single photons are a critical resource for developing photonic quantum technologies for information processing , communications , and metrology .", "tokens": ["high", "-", "quality", "sources", "of", "single", "photons", "are", "a", "critical", "resource", "for", "developing", "photonic", "quantum", "technologies", "for", "information", "processing", ",", "communications", ",", "and", "metrology", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "high-quality sources of single photons", "start": 0, "end": 38, "i_start": 0, "i_end": 6}, "verb": {"text": "are", "start": 39, "end": 42, "i_start": 7, "i_end": 7}}], "id": 4303}, {"sent": "convolutional neural networks have shown extraordinary success in a large variety of computer vision tasks , such as image recognition .", "tokens": ["convolutional", "neural", "networks", "have", "shown", "extraordinary", "success", "in", "a", "large", "variety", "of", "computer", "vision", "tasks", ",", "such", "as", "image", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 6, "i_end": 6}}], "id": 4304}, {"sent": "the exchangecorrelation potential was calculated using the generalized gradient approximation as proposed by perdew , burke , and ernzerhof .", "tokens": ["the", "exchangecorrelation", "potential", "was", "calculated", "using", "the", "generalized", "gradient", "approximation", "as", "proposed", "by", "perdew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchangecorrelation potential", "start": 0, "end": 33, "i_start": 0, "i_end": 2}, "verb": {"text": "was calculated", "start": 34, "end": 48, "i_start": 3, "i_end": 4}}, {"character": {"text": "perdew", "start": 109, "end": 115, "i_start": 13, "i_end": 13}, "action": {"text": "proposed", "start": 97, "end": 105, "i_start": 11, "i_end": 11}}, {"character": {"text": "burke", "start": 118, "end": 123, "i_start": 15, "i_end": 15}, "action": {"text": "proposed", "start": 97, "end": 105, "i_start": 11, "i_end": 11}}, {"character": {"text": "ernzerhof", "start": 130, "end": 139, "i_start": 18, "i_end": 18}, "action": {"text": "proposed", "start": 97, "end": 105, "i_start": 11, "i_end": 11}}], "id": 4305}, {"sent": "we primarily use a multi-layer multi-head transformer to extract evidence sentences .", "tokens": ["we", "primarily", "use", "a", "multi", "-", "layer", "multi", "-", "head", "transformer", "to", "extract", "evidence", "sentences", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 13, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 13, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "transformer", "start": 42, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "extract", "start": 57, "end": 64, "i_start": 12, "i_end": 12}}, {"character": {"text": "sentences", "start": 74, "end": 83, "i_start": 14, "i_end": 14}, "action": {"text": "evidence", "start": 65, "end": 73, "i_start": 13, "i_end": 13}}], "id": 4306}, {"sent": "convolutional neural networks have recently exhibited great performance in various fields such as computer vision .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "exhibited", "great", "performance", "in", "various", "fields", "such", "as", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "exhibited", "start": 44, "end": 53, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "exhibited", "start": 44, "end": 53, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 60, "end": 71, "i_start": 7, "i_end": 7}}], "id": 4307}, {"sent": "non-commutative field theories have recently received a great deal of attention .", "tokens": ["non", "-", "commutative", "field", "theories", "have", "recently", "received", "a", "great", "deal", "of", "attention", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "non-commutative field theories", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "received", "start": 45, "end": 53, "i_start": 7, "i_end": 7}}, {"subject": {"text": "non-commutative field theories", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "have", "start": 31, "end": 35, "i_start": 5, "i_end": 5}}], "id": 4308}, {"sent": "for exchange and correlation we applied the gradient corrected approach using the generalized gradient approximation functional following the approach suggested by perdew-burke-ernzerhof .", "tokens": ["for", "exchange", "and", "correlation", "we", "applied", "the", "gradient", "corrected", "approach", "using", "the", "generalized", "gradient", "approximation", "functional", "following", "the", "approach", "suggested", "by", "perdew", "-", "burke", "-", "ernzerhof", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 29, "end": 31, "i_start": 4, "i_end": 4}, "verb": {"text": "applied", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "applied", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "using", "start": 72, "end": 77, "i_start": 10, "i_end": 10}}, {"character": {"text": "perdew", "start": 164, "end": 170, "i_start": 21, "i_end": 21}, "action": {"text": "suggested", "start": 151, "end": 160, "i_start": 19, "i_end": 19}}], "id": 4309}, {"sent": "in recent years , deep neural networks have revolutionized machine-learning tasks such as image classification , speech recognition and language translation .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "revolutionized", "machine", "-", "learning", "tasks", "such", "as", "image", "classification", ",", "speech", "recognition", "and", "language", "translation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have revolutionized", "start": 39, "end": 58, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "revolutionized", "start": 44, "end": 58, "i_start": 8, "i_end": 8}}], "id": 4310}, {"sent": "deep convolutional neural networks have improved performance of many tasks in computer vision , such as image recognition .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "improved", "performance", "of", "many", "tasks", "in", "computer", "vision", ",", "such", "as", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have improved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performance", "start": 49, "end": 60, "i_start": 6, "i_end": 6}}], "id": 4311}, {"sent": "nevertheless , it was observed in that , in typical indoor environments the main received energy at the photodetector comes from the los component .", "tokens": ["nevertheless", ",", "it", "was", "observed", "in", "that", ",", "in", "typical", "indoor", "environments", "the", "main", "received", "energy", "at", "the", "photodetector", "comes", "from", "the", "los", "component", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the main received energy at the photodetector", "start": 72, "end": 117, "i_start": 12, "i_end": 18}, "verb": {"text": "comes", "start": 118, "end": 123, "i_start": 19, "i_end": 19}}, {"subject": {"text": "it", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "observed", "start": 22, "end": 30, "i_start": 4, "i_end": 4}}], "id": 4312}, {"sent": "of course , these two operads have the same homotopy type .", "tokens": ["of", "course", ",", "these", "two", "operads", "have", "the", "same", "homotopy", "type", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "these two operads", "start": 12, "end": 29, "i_start": 3, "i_end": 5}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "two", "start": 18, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "have", "start": 30, "end": 34, "i_start": 6, "i_end": 6}}], "id": 4313}, {"sent": "machine learning approaches , especially deep neural networks , are transforming a wide range of application domains , such as computer vision .", "tokens": ["machine", "learning", "approaches", ",", "especially", "deep", "neural", "networks", ",", "are", "transforming", "a", "wide", "range", "of", "application", "domains", ",", "such", "as", "computer", "vision", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "machine learning approaches", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "are transforming", "start": 64, "end": 80, "i_start": 9, "i_end": 10}}, {"character": {"text": "approaches", "start": 17, "end": 27, "i_start": 2, "i_end": 2}, "action": {"text": "transforming", "start": 68, "end": 80, "i_start": 10, "i_end": 10}}], "id": 4314}, {"sent": "additionally , the use of an augmented dataset with adversarial samples is perhaps one of the most successful approaches to construct robust neural networks .", "tokens": ["additionally", ",", "the", "use", "of", "an", "augmented", "dataset", "with", "adversarial", "samples", "is", "perhaps", "one", "of", "the", "most", "successful", "approaches", "to", "construct", "robust", "neural", "networks", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the use of an augmented dataset with adversarial samples", "start": 15, "end": 71, "i_start": 2, "i_end": 10}, "verb": {"text": "is", "start": 72, "end": 74, "i_start": 11, "i_end": 11}}], "id": 4315}, {"sent": "the forces were calculated in the vasp code within the projector-augmented wave method using the perdew-burke-ernzerhof flavor of the exchange-correlation potential .", "tokens": ["the", "forces", "were", "calculated", "in", "the", "vasp", "code", "within", "the", "projector", "-", "augmented", "wave", "method", "using", "the", "perdew", "-", "burke", "-", "ernzerhof", "flavor", "of", "the", "exchange", "-", "correlation", "potential", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the forces", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "were calculated", "start": 11, "end": 26, "i_start": 2, "i_end": 3}}, {"character": {"text": "projector", "start": 55, "end": 64, "i_start": 10, "i_end": 10}, "action": {"text": "augmented", "start": 65, "end": 74, "i_start": 12, "i_end": 12}}], "id": 4316}, {"sent": "as alluded to above , for weighted flow-time on unrelated machines , the best clairvoyant result is a -speed o-competitive algorithm .", "tokens": ["as", "alluded", "to", "above", ",", "for", "weighted", "flow", "-", "time", "on", "unrelated", "machines", ",", "the", "best", "clairvoyant", "result", "is", "a", "-speed", "o", "-", "competitive", "algorithm", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the best clairvoyant result", "start": 69, "end": 96, "i_start": 14, "i_end": 17}, "verb": {"text": "is", "start": 97, "end": 99, "i_start": 18, "i_end": 18}}], "id": 4317}, {"sent": "this new parameter allows us to get a pp-wave background that includes as special cases the bmn pp-wave background .", "tokens": ["this", "new", "parameter", "allows", "us", "to", "get", "a", "pp", "-", "wave", "background", "that", "includes", "as", "special", "cases", "the", "bmn", "pp", "-", "wave", "background", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this new parameter", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "allows", "start": 19, "end": 25, "i_start": 3, "i_end": 3}}, {"subject": {"text": "us", "start": 26, "end": 28, "i_start": 4, "i_end": 4}, "verb": {"text": "get", "start": 32, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "parameter", "start": 9, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "allows", "start": 19, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 26, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "get", "start": 32, "end": 35, "i_start": 6, "i_end": 6}}], "id": 4318}, {"sent": "the exchange correlation between electrons was treated with generalized gradient approximation in the perdewburke-ernzerhof form .", "tokens": ["the", "exchange", "correlation", "between", "electrons", "was", "treated", "with", "generalized", "gradient", "approximation", "in", "the", "perdewburke", "-", "ernzerhof", "form", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange correlation between electrons", "start": 0, "end": 42, "i_start": 0, "i_end": 4}, "verb": {"text": "was treated", "start": 43, "end": 54, "i_start": 5, "i_end": 6}}], "id": 4319}, {"sent": "recently , deep learning based algorithms have shown great success in object detection and classification tasks .", "tokens": ["recently", ",", "deep", "learning", "based", "algorithms", "have", "shown", "great", "success", "in", "object", "detection", "and", "classification", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning based algorithms", "start": 11, "end": 41, "i_start": 2, "i_end": 5}, "verb": {"text": "have shown", "start": 42, "end": 52, "i_start": 6, "i_end": 7}}, {"character": {"text": "algorithms", "start": 31, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 9, "i_end": 9}}], "id": 4320}, {"sent": "requiring correct relic abundance , we restrict the parameter space of the scalar mixing angle and mass of the heavy scalar boson of this model .", "tokens": ["requiring", "correct", "relic", "abundance", ",", "we", "restrict", "the", "parameter", "space", "of", "the", "scalar", "mixing", "angle", "and", "mass", "of", "the", "heavy", "scalar", "boson", "of", "this", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 36, "end": 38, "i_start": 5, "i_end": 5}, "verb": {"text": "restrict", "start": 39, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 36, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "restrict", "start": 39, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "abundance", "start": 24, "end": 33, "i_start": 3, "i_end": 3}, "action": {"text": "requiring", "start": 0, "end": 9, "i_start": 0, "i_end": 0}}], "id": 4321}, {"sent": "note also that the code of st-cgan is not publicly available , and we can only report their results on the datasets used in their published papers .", "tokens": ["note", "also", "that", "the", "code", "of", "st", "-", "cgan", "is", "not", "publicly", "available", ",", "and", "we", "can", "only", "report", "their", "results", "on", "the", "datasets", "used", "in", "their", "published", "papers", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 67, "end": 69, "i_start": 15, "i_end": 15}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "we", "start": 67, "end": 69, "i_start": 15, "i_end": 15}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 9, "i_end": 9}}, {"subject": {"text": "we", "start": 67, "end": 69, "i_start": 15, "i_end": 15}, "verb": {"text": "report", "start": 79, "end": 85, "i_start": 18, "i_end": 18}}, {"character": {"text": "we", "start": 67, "end": 69, "i_start": 15, "i_end": 15}, "action": {"text": "report", "start": 79, "end": 85, "i_start": 18, "i_end": 18}}], "id": 4322}, {"sent": "the suffix tree is a data storage and fast search technique which has been used in fields such as computational biology for applications such as string matching applied to dna sequences .", "tokens": ["the", "suffix", "tree", "is", "a", "data", "storage", "and", "fast", "search", "technique", "which", "has", "been", "used", "in", "fields", "such", "as", "computational", "biology", "for", "applications", "such", "as", "string", "matching", "applied", "to", "dna", "sequences", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the suffix tree", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 4323}, {"sent": "convolutional neural networks have recently achieved great success on various visual recognition tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "achieved", "great", "success", "on", "various", "visual", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 7, "i_end": 7}}], "id": 4324}, {"sent": "however , although functional connectivity correlates well with anatomical connectivity , there are studies showing that strong functional connections may exist between nodes with no direct physical connection .", "tokens": ["however", ",", "although", "functional", "connectivity", "correlates", "well", "with", "anatomical", "connectivity", ",", "there", "are", "studies", "showing", "that", "strong", "functional", "connections", "may", "exist", "between", "nodes", "with", "no", "direct", "physical", "connection", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "there", "start": 90, "end": 95, "i_start": 11, "i_end": 11}, "verb": {"text": "are", "start": 96, "end": 99, "i_start": 12, "i_end": 12}}, {"character": {"text": "studies", "start": 100, "end": 107, "i_start": 13, "i_end": 13}, "action": {"text": "showing", "start": 108, "end": 115, "i_start": 14, "i_end": 14}}, {"character": {"text": "nodes", "start": 169, "end": 174, "i_start": 22, "i_end": 22}, "action": {"text": "no", "start": 180, "end": 182, "i_start": 24, "i_end": 24}}], "id": 4325}, {"sent": "besides , their pruning based on the greedy algorithm in has a bound looser than ours .", "tokens": ["besides", ",", "their", "pruning", "based", "on", "the", "greedy", "algorithm", "in", "has", "a", "bound", "looser", "than", "ours", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "their pruning", "start": 10, "end": 23, "i_start": 2, "i_end": 3}, "verb": {"text": "based", "start": 24, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "pruning", "start": 16, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "has", "start": 57, "end": 60, "i_start": 10, "i_end": 10}}], "id": 4326}, {"sent": "in the case that the fermion mass hierarchy is realized by the wavefunction localiza tion in the extra dimension , the experimental bounds on the flavor-changing processes can provide stronger constraints on mrad and \u03bbr .", "tokens": ["in", "the", "case", "that", "the", "fermion", "mass", "hierarchy", "is", "realized", "by", "the", "wavefunction", "localiza", "tion", "in", "the", "extra", "dimension", ",", "the", "experimental", "bounds", "on", "the", "flavor", "-", "changing", "processes", "can", "provide", "stronger", "constraints", "on", "mrad", "and", "\u03bbr", "."], "score": [0, 0, 1, 1, 0], "labels": [{"subject": {"text": "the experimental bounds on the flavor-changing processes", "start": 115, "end": 171, "i_start": 20, "i_end": 28}, "verb": {"text": "can provide", "start": 172, "end": 183, "i_start": 29, "i_end": 30}}, {"character": {"text": "bounds", "start": 132, "end": 138, "i_start": 22, "i_end": 22}, "action": {"text": "provide", "start": 176, "end": 183, "i_start": 30, "i_end": 30}}, {"character": {"text": "experimental", "start": 119, "end": 131, "i_start": 21, "i_end": 21}, "action": {"text": "bounds", "start": 132, "end": 138, "i_start": 22, "i_end": 22}}], "id": 4327}, {"sent": "cluster algebras were introduced by fomin and zelevinsky in in order to study total positivity and canonical bases in semisimple groups .", "tokens": ["cluster", "algebras", "were", "introduced", "by", "fomin", "and", "zelevinsky", "in", "in", "order", "to", "study", "total", "positivity", "and", "canonical", "bases", "in", "semisimple", "groups", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were introduced", "start": 17, "end": 32, "i_start": 2, "i_end": 3}}, {"character": {"text": "fomin", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "zelevinsky", "start": 46, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "fomin", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "study", "start": 72, "end": 77, "i_start": 12, "i_end": 12}}, {"character": {"text": "zelevinsky", "start": 46, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "study", "start": 72, "end": 77, "i_start": 12, "i_end": 12}}], "id": 4328}, {"sent": "we use the standard terminology and notation from commutative algebra and algebraic geometry see .", "tokens": ["we", "use", "the", "standard", "terminology", "and", "notation", "from", "commutative", "algebra", "and", "algebraic", "geometry", "see", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 4329}, {"sent": "in recent years , convolutional neural networks has achieved remarkable results in a wide range of computer vision applications .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "has", "achieved", "remarkable", "results", "in", "a", "wide", "range", "of", "computer", "vision", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "has achieved", "start": 48, "end": 60, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 52, "end": 60, "i_start": 8, "i_end": 8}}], "id": 4330}, {"sent": "heterogeneity is the rule not the exception and many activities such as periodicities are often left out of simulations .", "tokens": ["heterogeneity", "is", "the", "rule", "not", "the", "exception", "and", "many", "activities", "such", "as", "periodicities", "are", "often", "left", "out", "of", "simulations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "heterogeneity", "start": 0, "end": 13, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 1, "i_end": 1}}, {"subject": {"text": "many activities such as periodicities", "start": 48, "end": 85, "i_start": 8, "i_end": 12}, "verb": {"text": "left", "start": 96, "end": 100, "i_start": 15, "i_end": 15}}], "id": 4331}, {"sent": "deep convolutional neural networks have achieved remarkable accuracy for tasks in a wide range of application domains including image processing , machine translation , and speech recognition .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "remarkable", "accuracy", "for", "tasks", "in", "a", "wide", "range", "of", "application", "domains", "including", "image", "processing", ",", "machine", "translation", ",", "and", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}], "id": 4332}, {"sent": "quadratic systems of size larger than 15 equations are very difficult .", "tokens": ["quadratic", "systems", "of", "size", "larger", "than", "15", "equations", "are", "very", "difficult", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "quadratic systems of size larger than 15 equations", "start": 0, "end": 50, "i_start": 0, "i_end": 7}, "verb": {"text": "are", "start": 51, "end": 54, "i_start": 8, "i_end": 8}}], "id": 4333}, {"sent": "deep learning has brought significant breakthroughs in many computer vision tasks , including object detection .", "tokens": ["deep", "learning", "has", "brought", "significant", "breakthroughs", "in", "many", "computer", "vision", "tasks", ",", "including", "object", "detection", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has brought", "start": 14, "end": 25, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "breakthroughs", "start": 38, "end": 51, "i_start": 5, "i_end": 5}}], "id": 4334}, {"sent": "edge-on view of the late stage of the shock passage in the model wssb .", "tokens": ["edge", "-", "on", "view", "of", "the", "late", "stage", "of", "the", "shock", "passage", "in", "the", "model", "wssb", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4335}, {"sent": "detecting communities is a task of great importance in many disciplines , namely sociology , biology and computer science , where systems are often represented as graphs .", "tokens": ["detecting", "communities", "is", "a", "task", "of", "great", "importance", "in", "many", "disciplines", ",", "namely", "sociology", ",", "biology", "and", "computer", "science", ",", "where", "systems", "are", "often", "represented", "as", "graphs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "detecting communities", "start": 0, "end": 21, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 2, "i_end": 2}}], "id": 4336}, {"sent": "xu et al leverage the neural network to encode cfgs of binary code into vectors .", "tokens": ["xu", "et", "al", "leverage", "the", "neural", "network", "to", "encode", "cfgs", "of", "binary", "code", "into", "vectors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "xu et al", "start": 0, "end": 8, "i_start": 0, "i_end": 2}, "verb": {"text": "leverage", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "xu", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "leverage", "start": 9, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "xu", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "encode", "start": 40, "end": 46, "i_start": 8, "i_end": 8}}], "id": 4337}, {"sent": "deep convolutional neural networks have been successfully used in various computer vision applications such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successfully", "used", "in", "various", "computer", "vision", "applications", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "used", "start": 58, "end": 62, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}], "id": 4338}, {"sent": "proximal methods and its accelerated variants generalize gradient descent to nonsmooth problems when the proximal operator of the nondifferentiable term in the objective function is readily available .", "tokens": ["proximal", "methods", "and", "its", "accelerated", "variants", "generalize", "gradient", "descent", "to", "nonsmooth", "problems", "when", "the", "proximal", "operator", "of", "the", "nondifferentiable", "term", "in", "the", "objective", "function", "is", "readily", "available", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "proximal methods and its accelerated variants", "start": 0, "end": 45, "i_start": 0, "i_end": 5}, "verb": {"text": "generalize", "start": 46, "end": 56, "i_start": 6, "i_end": 6}}, {"character": {"text": "methods", "start": 9, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "generalize", "start": 46, "end": 56, "i_start": 6, "i_end": 6}}, {"character": {"text": "proximal", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "generalize", "start": 46, "end": 56, "i_start": 6, "i_end": 6}}, {"character": {"text": "variants", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "generalize", "start": 46, "end": 56, "i_start": 6, "i_end": 6}}, {"character": {"text": "methods", "start": 9, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "generalize", "start": 46, "end": 56, "i_start": 6, "i_end": 6}}, {"character": {"text": "proximal", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "generalize", "start": 46, "end": 56, "i_start": 6, "i_end": 6}}], "id": 4339}, {"sent": "in and , a cox regressionbased model was used to develop a sepsis shock severity score that can handle data streams that are censored due to interventions .", "tokens": ["in", "and", ",", "a", "cox", "regressionbased", "model", "was", "used", "to", "develop", "a", "sepsis", "shock", "severity", "score", "that", "can", "handle", "data", "streams", "that", "are", "censored", "due", "to", "interventions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a cox regressionbased model", "start": 9, "end": 36, "i_start": 3, "i_end": 6}, "verb": {"text": "was used", "start": 37, "end": 45, "i_start": 7, "i_end": 8}}, {"character": {"text": "sepsis", "start": 59, "end": 65, "i_start": 12, "i_end": 12}, "action": {"text": "shock", "start": 66, "end": 71, "i_start": 13, "i_end": 13}}, {"character": {"text": "score", "start": 81, "end": 86, "i_start": 15, "i_end": 15}, "action": {"text": "handle", "start": 96, "end": 102, "i_start": 18, "i_end": 18}}], "id": 4340}, {"sent": "although the tlb invalidation itself is fast , the process of context switches , transferring ipis across all possible cores , and waiting for all acknowledgements may be time-consuming .", "tokens": ["although", "the", "tlb", "invalidation", "itself", "is", "fast", ",", "the", "process", "of", "context", "switches", ",", "transferring", "ipis", "across", "all", "possible", "cores", ",", "and", "waiting", "for", "all", "acknowledgements", "may", "be", "time", "-", "consuming", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "the process of context switches", "start": 47, "end": 78, "i_start": 8, "i_end": 12}, "verb": {"text": "may be", "start": 164, "end": 170, "i_start": 26, "i_end": 27}}, {"character": {"text": "process", "start": 51, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "consuming", "start": 176, "end": 185, "i_start": 30, "i_end": 30}}], "id": 4341}, {"sent": "learning to generate creative point cloudsusing deep learning to generate new objects has been studied in different data types , such as music .", "tokens": ["learning", "to", "generate", "creative", "point", "cloudsusing", "deep", "learning", "to", "generate", "new", "objects", "has", "been", "studied", "in", "different", "data", "types", ",", "such", "as", "music", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4342}, {"sent": "we also study dynamics of shear-band structures in wormlike micellar solutions under the condition of fixed stress .", "tokens": ["we", "also", "study", "dynamics", "of", "shear", "-", "band", "structures", "in", "wormlike", "micellar", "solutions", "under", "the", "condition", "of", "fixed", "stress", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "study", "start": 8, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "study", "start": 8, "end": 13, "i_start": 2, "i_end": 2}}], "id": 4343}, {"sent": "this case is also known as multiantenna broadcast channel precoding and the precoder design depends on the channels of the individual users .", "tokens": ["this", "case", "is", "also", "known", "as", "multiantenna", "broadcast", "channel", "precoding", "and", "the", "precoder", "design", "depends", "on", "the", "channels", "of", "the", "individual", "users", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this case", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "known", "start": 18, "end": 23, "i_start": 4, "i_end": 4}}, {"subject": {"text": "this case", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}, {"subject": {"text": "this case", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "depends", "start": 92, "end": 99, "i_start": 14, "i_end": 14}}, {"character": {"text": "design", "start": 85, "end": 91, "i_start": 13, "i_end": 13}, "action": {"text": "depends", "start": 92, "end": 99, "i_start": 14, "i_end": 14}}], "id": 4344}, {"sent": "in this section , we first evaluate slimmable networks on imagenet classification .", "tokens": ["in", "this", "section", ",", "we", "first", "evaluate", "slimmable", "networks", "on", "imagenet", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "evaluate", "start": 27, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "evaluate", "start": 27, "end": 35, "i_start": 6, "i_end": 6}}], "id": 4345}, {"sent": "recent success of deep convolutional networks has been coupled with increased requirement of computation resources .", "tokens": ["recent", "success", "of", "deep", "convolutional", "networks", "has", "been", "coupled", "with", "increased", "requirement", "of", "computation", "resources", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "recent success of deep convolutional networks", "start": 0, "end": 45, "i_start": 0, "i_end": 5}, "verb": {"text": "has been coupled", "start": 46, "end": 62, "i_start": 6, "i_end": 8}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "success", "start": 7, "end": 14, "i_start": 1, "i_end": 1}}], "id": 4346}, {"sent": "nevertheless , algorithms exist that can compute a closest lattice point in reasonable time if the dimension is small .", "tokens": ["nevertheless", ",", "algorithms", "exist", "that", "can", "compute", "a", "closest", "lattice", "point", "in", "reasonable", "time", "if", "the", "dimension", "is", "small", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "algorithms exist that can compute a closest lattice point in reasonable time if the dimension is small", "start": 15, "end": 117, "i_start": 2, "i_end": 18}, "verb": {"text": "exist", "start": 26, "end": 31, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithms", "start": 15, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "compute", "start": 41, "end": 48, "i_start": 6, "i_end": 6}}], "id": 4347}, {"sent": "rtkdsm monitors many kernel objects to achieve vmi .", "tokens": ["rtkdsm", "monitors", "many", "kernel", "objects", "to", "achieve", "vmi", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "rtkdsm", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "monitors", "start": 7, "end": 15, "i_start": 1, "i_end": 1}}], "id": 4348}, {"sent": "dropout is a regularization technique to prevent coadaptation of feature detectors by randomly and temporarily omitting nodes of a neural network .", "tokens": ["dropout", "is", "a", "regularization", "technique", "to", "prevent", "coadaptation", "of", "feature", "detectors", "by", "randomly", "and", "temporarily", "omitting", "nodes", "of", "a", "neural", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dropout", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}], "id": 4349}, {"sent": "differential privacy is a privacy model that has received significant attention in machine-learning and datamining applications .", "tokens": ["differential", "privacy", "is", "a", "privacy", "model", "that", "has", "received", "significant", "attention", "in", "machine", "-", "learning", "and", "datamining", "applications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "differential privacy", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "model", "start": 34, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "received", "start": 49, "end": 57, "i_start": 8, "i_end": 8}}], "id": 4350}, {"sent": "recently , the study of complex networks has revealed the true structure of real-world networks .", "tokens": ["recently", ",", "the", "study", "of", "complex", "networks", "has", "revealed", "the", "true", "structure", "of", "real", "-", "world", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the study of complex networks", "start": 11, "end": 40, "i_start": 2, "i_end": 6}, "verb": {"text": "has revealed", "start": 41, "end": 53, "i_start": 7, "i_end": 8}}, {"character": {"text": "study", "start": 15, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "revealed", "start": 45, "end": 53, "i_start": 8, "i_end": 8}}], "id": 4351}, {"sent": "this portion of the algebra is given the notation hn , and is isomorphic to the hecke algebra .", "tokens": ["this", "portion", "of", "the", "algebra", "is", "given", "the", "notation", "hn", ",", "and", "is", "isomorphic", "to", "the", "hecke", "algebra", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this portion of the algebra", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "is given", "start": 28, "end": 36, "i_start": 5, "i_end": 6}}], "id": 4352}, {"sent": "motivated by this , singh and manilal defined the strong power graphs as a generalization of the power graphs .", "tokens": ["motivated", "by", "this", ",", "singh", "and", "manilal", "defined", "the", "strong", "power", "graphs", "as", "a", "generalization", "of", "the", "power", "graphs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "singh and manilal", "start": 20, "end": 37, "i_start": 4, "i_end": 6}, "verb": {"text": "defined", "start": 38, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "singh", "start": 20, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "defined", "start": 38, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "manilal", "start": 30, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "defined", "start": 38, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "this", "start": 13, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "motivated", "start": 0, "end": 9, "i_start": 0, "i_end": 0}}], "id": 4353}, {"sent": "to circumvent the binary resolution of devices , compound memristive synapse with multiple bistable devices in parallel was recently proposed to emulate analog weights on average .", "tokens": ["to", "circumvent", "the", "binary", "resolution", "of", "devices", ",", "compound", "memristive", "synapse", "with", "multiple", "bistable", "devices", "in", "parallel", "was", "recently", "proposed", "to", "emulate", "analog", "weights", "on", "average", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "compound memristive synapse with multiple bistable devices in parallel", "start": 49, "end": 119, "i_start": 8, "i_end": 16}, "verb": {"text": "proposed", "start": 133, "end": 141, "i_start": 19, "i_end": 19}}, {"subject": {"text": "compound memristive synapse with multiple bistable devices in parallel", "start": 49, "end": 119, "i_start": 8, "i_end": 16}, "verb": {"text": "was", "start": 120, "end": 123, "i_start": 17, "i_end": 17}}], "id": 4354}, {"sent": "generative adversarial networks are one of the main approaches to learning such models in a fully unsupervised fashion .", "tokens": ["generative", "adversarial", "networks", "are", "one", "of", "the", "main", "approaches", "to", "learning", "such", "models", "in", "a", "fully", "unsupervised", "fashion", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}], "id": 4355}, {"sent": "deep learning based methods have achieved great success on the image inpainting task .", "tokens": ["deep", "learning", "based", "methods", "have", "achieved", "great", "success", "on", "the", "image", "inpainting", "task", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning based methods", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 28, "end": 41, "i_start": 4, "i_end": 5}}, {"character": {"text": "methods", "start": 20, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 33, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "methods", "start": 20, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 48, "end": 55, "i_start": 7, "i_end": 7}}], "id": 4356}, {"sent": "generalized linear model is a generalization of classical linear regression model .", "tokens": ["generalized", "linear", "model", "is", "a", "generalization", "of", "classical", "linear", "regression", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generalized linear model", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 3, "i_end": 3}}], "id": 4357}, {"sent": "this work implements a flexible ecc accelerator which supports arbitrary primes up to 256 bits , in contrast with only supports binary field modular arithmetic in hardware .", "tokens": ["this", "work", "implements", "a", "flexible", "ecc", "accelerator", "which", "supports", "arbitrary", "primes", "up", "to", "256", "bits", ",", "in", "contrast", "with", "only", "supports", "binary", "field", "modular", "arithmetic", "in", "hardware", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this work", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "implements", "start": 10, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "work", "start": 5, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "implements", "start": 10, "end": 20, "i_start": 2, "i_end": 2}}], "id": 4358}, {"sent": "deep neural networks are widely used in various fields of machine learning and achieve huge success in all these applications .", "tokens": ["deep", "neural", "networks", "are", "widely", "used", "in", "various", "fields", "of", "machine", "learning", "and", "achieve", "huge", "success", "in", "all", "these", "applications", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 32, "end": 36, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "achieve", "start": 79, "end": 86, "i_start": 13, "i_end": 13}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 92, "end": 99, "i_start": 15, "i_end": 15}}], "id": 4359}, {"sent": "recently , neural networks have achieved very impressive success on a wide range of fields like computer vision .", "tokens": ["recently", ",", "neural", "networks", "have", "achieved", "very", "impressive", "success", "on", "a", "wide", "range", "of", "fields", "like", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 11, "end": 26, "i_start": 2, "i_end": 3}, "verb": {"text": "have achieved", "start": 27, "end": 40, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 18, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 32, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 18, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 57, "end": 64, "i_start": 8, "i_end": 8}}, {"character": {"text": "success", "start": 57, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "impressive", "start": 46, "end": 56, "i_start": 7, "i_end": 7}}], "id": 4360}, {"sent": "let us obtain further constraints on other bare parameters of the hls through the wilsonian matching for the currents correlators .", "tokens": ["let", "us", "obtain", "further", "constraints", "on", "other", "bare", "parameters", "of", "the", "hls", "through", "the", "wilsonian", "matching", "for", "the", "currents", "correlators", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "obtain", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}, {"subject": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "correlators", "start": 118, "end": 129, "i_start": 19, "i_end": 19}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "let", "start": 0, "end": 3, "i_start": 0, "i_end": 0}}, {"character": {"text": "us", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "obtain", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}], "id": 4361}, {"sent": "the main aim would be to systematically discuss the set of equations which are crucial in understanding the process highlighting the major physical processes and assumptions .", "tokens": ["the", "main", "aim", "would", "be", "to", "systematically", "discuss", "the", "set", "of", "equations", "which", "are", "crucial", "in", "understanding", "the", "process", "highlighting", "the", "major", "physical", "processes", "and", "assumptions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the main aim", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "would be", "start": 13, "end": 21, "i_start": 3, "i_end": 4}}, {"character": {"text": "equations", "start": 59, "end": 68, "i_start": 11, "i_end": 11}, "action": {"text": "highlighting", "start": 116, "end": 128, "i_start": 19, "i_end": 19}}], "id": 4362}, {"sent": "the bulge is a predominantly pressure-supported spheroidal component containing old stellar populations .", "tokens": ["the", "bulge", "is", "a", "predominantly", "pressure", "-", "supported", "spheroidal", "component", "containing", "old", "stellar", "populations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the bulge", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "component", "start": 59, "end": 68, "i_start": 9, "i_end": 9}, "action": {"text": "containing", "start": 69, "end": 79, "i_start": 10, "i_end": 10}}, {"character": {"text": "pressure", "start": 29, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "supported", "start": 38, "end": 47, "i_start": 7, "i_end": 7}}], "id": 4363}, {"sent": "generative adversarial networks are a variation of deep neural network that are believed to learn a generative model given a bunch of real data points .", "tokens": ["generative", "adversarial", "networks", "are", "a", "variation", "of", "deep", "neural", "network", "that", "are", "believed", "to", "learn", "a", "generative", "model", "given", "a", "bunch", "of", "real", "data", "points", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}, {"character": {"text": "network", "start": 63, "end": 70, "i_start": 9, "i_end": 9}, "action": {"text": "learn", "start": 92, "end": 97, "i_start": 14, "i_end": 14}}], "id": 4364}, {"sent": "the em algorithm is often used for maximum likelihood estimation in the presence of missing data .", "tokens": ["the", "em", "algorithm", "is", "often", "used", "for", "maximum", "likelihood", "estimation", "in", "the", "presence", "of", "missing", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the em algorithm", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 26, "end": 30, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the em algorithm", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}], "id": 4365}, {"sent": "the grey shaded region indicates the error margin , which is estimated as described in the supplement .", "tokens": ["the", "grey", "shaded", "region", "indicates", "the", "error", "margin", ",", "which", "is", "estimated", "as", "described", "in", "the", "supplement", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the grey shaded region", "start": 0, "end": 22, "i_start": 0, "i_end": 3}, "verb": {"text": "indicates", "start": 23, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "region", "start": 16, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "indicates", "start": 23, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "supplement", "start": 91, "end": 101, "i_start": 16, "i_end": 16}, "action": {"text": "described", "start": 74, "end": 83, "i_start": 13, "i_end": 13}}], "id": 4366}, {"sent": "any almost hermitian manifold of type g 1 admits a unique characteristic connection .", "tokens": ["any", "almost", "hermitian", "manifold", "of", "type", "g", "1", "admits", "a", "unique", "characteristic", "connection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "any almost hermitian manifold of type g 1", "start": 0, "end": 41, "i_start": 0, "i_end": 7}, "verb": {"text": "admits", "start": 42, "end": 48, "i_start": 8, "i_end": 8}}, {"character": {"text": "manifold", "start": 21, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "admits", "start": 42, "end": 48, "i_start": 8, "i_end": 8}}], "id": 4367}, {"sent": "in recent years , convolutional neural networks have achieved superior performance in many visual tasks , such as object classification and detection .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "classification", "and", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 48, "end": 61, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 53, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 71, "end": 82, "i_start": 10, "i_end": 10}}], "id": 4368}, {"sent": "in recent years , convolutional neural networks methods have demonstrated highly accurate and reliable performance across a variety of computer-vision related tasks , including image classification .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "methods", "have", "demonstrated", "highly", "accurate", "and", "reliable", "performance", "across", "a", "variety", "of", "computer", "-", "vision", "related", "tasks", ",", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks methods", "start": 18, "end": 55, "i_start": 4, "i_end": 7}, "verb": {"text": "have demonstrated", "start": 56, "end": 73, "i_start": 8, "i_end": 9}}, {"character": {"text": "methods", "start": 48, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "demonstrated", "start": 61, "end": 73, "i_start": 9, "i_end": 9}}, {"character": {"text": "methods", "start": 48, "end": 55, "i_start": 7, "i_end": 7}, "action": {"text": "performance", "start": 103, "end": 114, "i_start": 14, "i_end": 14}}], "id": 4369}, {"sent": "in recent years , the focus has shifted towards determining explicit dependence of the estimation performance on the communication constraint .", "tokens": ["in", "recent", "years", ",", "the", "focus", "has", "shifted", "towards", "determining", "explicit", "dependence", "of", "the", "estimation", "performance", "on", "the", "communication", "constraint", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the focus", "start": 18, "end": 27, "i_start": 4, "i_end": 5}, "verb": {"text": "has shifted", "start": 28, "end": 39, "i_start": 6, "i_end": 7}}, {"character": {"text": "performance", "start": 98, "end": 109, "i_start": 15, "i_end": 15}, "action": {"text": "dependence", "start": 69, "end": 79, "i_start": 11, "i_end": 11}}], "id": 4370}, {"sent": "however , existing deep models are not suitable to solve our problem because they assume similar learning difficulties and convergence rates across all tasks .", "tokens": ["however", ",", "existing", "deep", "models", "are", "not", "suitable", "to", "solve", "our", "problem", "because", "they", "assume", "similar", "learning", "difficulties", "and", "convergence", "rates", "across", "all", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "existing deep models", "start": 10, "end": 30, "i_start": 2, "i_end": 4}, "verb": {"text": "are not", "start": 31, "end": 38, "i_start": 5, "i_end": 6}}, {"character": {"text": "models", "start": 24, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "solve", "start": 51, "end": 56, "i_start": 9, "i_end": 9}}, {"character": {"text": "assume", "start": 82, "end": 88, "i_start": 14, "i_end": 14}, "action": {"text": "because", "start": 69, "end": 76, "i_start": 12, "i_end": 12}}, {"character": {"text": "models", "start": 24, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "assume", "start": 82, "end": 88, "i_start": 14, "i_end": 14}}], "id": 4371}, {"sent": "we assume that the nucleon is a thermodynamic system of quarks and gluons .", "tokens": ["we", "assume", "that", "the", "nucleon", "is", "a", "thermodynamic", "system", "of", "quarks", "and", "gluons", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "assume", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 4372}, {"sent": "millimeter wave communication is deemed as a promising technique for meeting the ever-increasing traffic demand in next generation wireless communication systems .", "tokens": ["millimeter", "wave", "communication", "is", "deemed", "as", "a", "promising", "technique", "for", "meeting", "the", "ever", "-", "increasing", "traffic", "demand", "in", "next", "generation", "wireless", "communication", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "millimeter wave communication", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "is deemed", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "technique", "start": 55, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "promising", "start": 45, "end": 54, "i_start": 7, "i_end": 7}}, {"character": {"text": "systems", "start": 154, "end": 161, "i_start": 22, "i_end": 22}, "action": {"text": "demand", "start": 105, "end": 111, "i_start": 16, "i_end": 16}}], "id": 4373}, {"sent": "the eigenvalue is the outcome of the measurement and it is a real value , meaning that the result of the ideal measurement is exact .", "tokens": ["the", "eigenvalue", "is", "the", "outcome", "of", "the", "measurement", "and", "it", "is", "a", "real", "value", ",", "meaning", "that", "the", "result", "of", "the", "ideal", "measurement", "is", "exact", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the eigenvalue", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 4374}, {"sent": "characterize those groupoid rings rg which are never essential or s-essential .", "tokens": ["characterize", "those", "groupoid", "rings", "rg", "which", "are", "never", "essential", "or", "s", "-", "essential", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4375}, {"sent": "optimal approximation of sobolev functions in the sup-norm .", "tokens": ["optimal", "approximation", "of", "sobolev", "functions", "in", "the", "sup", "-", "norm", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4376}, {"sent": "these scaling factors are tabulated in table iv .", "tokens": ["these", "scaling", "factors", "are", "tabulated", "in", "table", "iv", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these scaling factors", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "are tabulated", "start": 22, "end": 35, "i_start": 3, "i_end": 4}}], "id": 4377}, {"sent": "some of these graph generators mechanistically model network growth , .", "tokens": ["some", "of", "these", "graph", "generators", "mechanistically", "model", "network", "growth", ",", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "some of these graph generators", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "model", "start": 47, "end": 52, "i_start": 6, "i_end": 6}}, {"character": {"text": "some", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "model", "start": 47, "end": 52, "i_start": 6, "i_end": 6}}], "id": 4378}, {"sent": "this asymmetry is a pure direct-cp-violating observable .", "tokens": ["this", "asymmetry", "is", "a", "pure", "direct", "-", "cp", "-", "violating", "observable", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this asymmetry", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "-", "start": 31, "end": 32, "i_start": 6, "i_end": 6}, "action": {"text": "violating", "start": 35, "end": 44, "i_start": 9, "i_end": 9}}], "id": 4379}, {"sent": "deep neural networks have gained a lot interests in recent years as it has demonstrated success for many classification and regression tasks , including image recognition .", "tokens": ["deep", "neural", "networks", "have", "gained", "a", "lot", "interests", "in", "recent", "years", "as", "it", "has", "demonstrated", "success", "for", "many", "classification", "and", "regression", "tasks", ",", "including", "image", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have gained", "start": 21, "end": 32, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "gained", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 75, "end": 87, "i_start": 14, "i_end": 14}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 88, "end": 95, "i_start": 15, "i_end": 15}}], "id": 4380}, {"sent": "the coefficient d is the decay rate for the predator y , and f , the efficiency of its predation .", "tokens": ["the", "coefficient", "d", "is", "the", "decay", "rate", "for", "the", "predator", "y", ",", "and", "f", ",", "the", "efficiency", "of", "its", "predation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the coefficient d", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "predator", "start": 44, "end": 52, "i_start": 9, "i_end": 9}, "action": {"text": "decay", "start": 25, "end": 30, "i_start": 5, "i_end": 5}}], "id": 4381}, {"sent": "we will use an internal probabilistic turing machine to simulate time independent -polynomial time .", "tokens": ["we", "will", "use", "an", "internal", "probabilistic", "turing", "machine", "to", "simulate", "time", "independent", "-polynomial", "time", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will use", "start": 3, "end": 11, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "machine", "start": 45, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "simulate", "start": 56, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "time", "start": 65, "end": 69, "i_start": 10, "i_end": 10}, "action": {"text": "independent", "start": 70, "end": 81, "i_start": 11, "i_end": 11}}], "id": 4382}, {"sent": "micrornas are small non-coding rna molecules that can control the function of their target messenger rnas by downregulating the expression of the targets .", "tokens": ["micrornas", "are", "small", "non", "-", "coding", "rna", "molecules", "that", "can", "control", "the", "function", "of", "their", "target", "messenger", "rnas", "by", "downregulating", "the", "expression", "of", "the", "targets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "micrornas", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 10, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "molecules", "start": 35, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "control", "start": 54, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "messenger", "start": 91, "end": 100, "i_start": 16, "i_end": 16}, "action": {"text": "function", "start": 66, "end": 74, "i_start": 12, "i_end": 12}}, {"character": {"text": "molecules", "start": 35, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "target", "start": 84, "end": 90, "i_start": 15, "i_end": 15}}, {"character": {"text": "molecules", "start": 35, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "downregulating", "start": 109, "end": 123, "i_start": 19, "i_end": 19}}], "id": 4383}, {"sent": "we obtain posterior samples using the blocked gibbs sampler and working with the latent parameters of the bivariate beta distribution .", "tokens": ["we", "obtain", "posterior", "samples", "using", "the", "blocked", "gibbs", "sampler", "and", "working", "with", "the", "latent", "parameters", "of", "the", "bivariate", "beta", "distribution", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "obtain", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "obtain", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 28, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "working", "start": 64, "end": 71, "i_start": 10, "i_end": 10}}], "id": 4384}, {"sent": "zehnder , the dynamics on threedimensional strictly convex energy surfaces .", "tokens": ["zehnder", ",", "the", "dynamics", "on", "threedimensional", "strictly", "convex", "energy", "surfaces", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4385}, {"sent": "convolutional neural networks have witnessed great improvement on a series of vision tasks such as object classification .", "tokens": ["convolutional", "neural", "networks", "have", "witnessed", "great", "improvement", "on", "a", "series", "of", "vision", "tasks", "such", "as", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have witnessed", "start": 30, "end": 44, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "witnessed", "start": 35, "end": 44, "i_start": 4, "i_end": 4}}], "id": 4386}, {"sent": "fire management agencies in australia and the usa have initiated extensive fuel management programs to lessen the possibility of large wildfires in fire-prone areas .", "tokens": ["fire", "management", "agencies", "in", "australia", "and", "the", "usa", "have", "initiated", "extensive", "fuel", "management", "programs", "to", "lessen", "the", "possibility", "of", "large", "wildfires", "in", "fire", "-", "prone", "areas", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "fire management agencies in australia and the usa", "start": 0, "end": 49, "i_start": 0, "i_end": 7}, "verb": {"text": "have initiated", "start": 50, "end": 64, "i_start": 8, "i_end": 9}}, {"character": {"text": "agencies", "start": 16, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "initiated", "start": 55, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "usa", "start": 46, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "initiated", "start": 55, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "australia", "start": 28, "end": 37, "i_start": 4, "i_end": 4}, "action": {"text": "initiated", "start": 55, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "usa", "start": 46, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "initiated", "start": 55, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "agencies", "start": 16, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "management", "start": 5, "end": 15, "i_start": 1, "i_end": 1}}], "id": 4387}, {"sent": "deep neural networks trained with millions of parameters have achieved tremendous success in various machine learning tasks including speech , natural language and image processing .", "tokens": ["deep", "neural", "networks", "trained", "with", "millions", "of", "parameters", "have", "achieved", "tremendous", "success", "in", "various", "machine", "learning", "tasks", "including", "speech", ",", "natural", "language", "and", "image", "processing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks trained with millions of parameters", "start": 0, "end": 56, "i_start": 0, "i_end": 7}, "verb": {"text": "have achieved", "start": 57, "end": 70, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 82, "end": 89, "i_start": 11, "i_end": 11}}], "id": 4388}, {"sent": "spin foam models of riemannian quantum gravity .", "tokens": ["spin", "foam", "models", "of", "riemannian", "quantum", "gravity", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4389}, {"sent": "kipf and welling propose a first order approximation scheme to reduce the computational costs the graph filter spectrum .", "tokens": ["kipf", "and", "welling", "propose", "a", "first", "order", "approximation", "scheme", "to", "reduce", "the", "computational", "costs", "the", "graph", "filter", "spectrum", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "kipf", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "welling", "start": 9, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "propose", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "spectrum", "start": 111, "end": 119, "i_start": 17, "i_end": 17}, "action": {"text": "filter", "start": 104, "end": 110, "i_start": 16, "i_end": 16}}], "id": 4390}, {"sent": "rage uses atomic opacities compiled from the los alamos oplib database 7 and can evolve multimaterial flows with several types of equation of state .", "tokens": ["rage", "uses", "atomic", "opacities", "compiled", "from", "the", "los", "alamos", "oplib", "database", "7", "and", "can", "evolve", "multimaterial", "flows", "with", "several", "types", "of", "equation", "of", "state", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "rage", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "uses", "start": 5, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "rage", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "evolve", "start": 81, "end": 87, "i_start": 14, "i_end": 14}}, {"character": {"text": "rage", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "uses", "start": 5, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "rage", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "evolve", "start": 81, "end": 87, "i_start": 14, "i_end": 14}}], "id": 4391}, {"sent": "at tree level , this dual conformal symmetry can be extended to a dual super-conformal symmetry .", "tokens": ["at", "tree", "level", ",", "this", "dual", "conformal", "symmetry", "can", "be", "extended", "to", "a", "dual", "super", "-", "conformal", "symmetry", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this dual conformal symmetry", "start": 16, "end": 44, "i_start": 4, "i_end": 7}, "verb": {"text": "can be extended", "start": 45, "end": 60, "i_start": 8, "i_end": 10}}], "id": 4392}, {"sent": "a deterministic eh model for the gaussian relay channel was considered in , where delay and nondelay constrained traffic were studied .", "tokens": ["a", "deterministic", "eh", "model", "for", "the", "gaussian", "relay", "channel", "was", "considered", "in", ",", "where", "delay", "and", "nondelay", "constrained", "traffic", "were", "studied", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a deterministic eh model for the gaussian relay channel", "start": 0, "end": 55, "i_start": 0, "i_end": 8}, "verb": {"text": "was considered", "start": 56, "end": 70, "i_start": 9, "i_end": 10}}], "id": 4393}, {"sent": "dataset dmostly contains images with centered and clutter-free single objects , unlike the challenging pascal voc 2012 .", "tokens": ["dataset", "dmostly", "contains", "images", "with", "centered", "and", "clutter", "-", "free", "single", "objects", ",", "unlike", "the", "challenging", "pascal", "voc", "2012", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "dataset", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "contains", "start": 16, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "dataset", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "contains", "start": 16, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "pascal voc 2012", "start": 103, "end": 118, "i_start": 16, "i_end": 18}, "action": {"text": "challenging", "start": 91, "end": 102, "i_start": 15, "i_end": 15}}], "id": 4394}, {"sent": "the power spectrum is a two point statistic , which depends on the square of the bias .", "tokens": ["the", "power", "spectrum", "is", "a", "two", "point", "statistic", ",", "which", "depends", "on", "the", "square", "of", "the", "bias", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the power spectrum", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "statistic", "start": 34, "end": 43, "i_start": 7, "i_end": 7}, "action": {"text": "depends", "start": 52, "end": 59, "i_start": 10, "i_end": 10}}], "id": 4395}, {"sent": "the flux of hard x-ray emission measured by the rxte and osse telescopes .", "tokens": ["the", "flux", "of", "hard", "x", "-", "ray", "emission", "measured", "by", "the", "rxte", "and", "osse", "telescopes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "telescopes", "start": 62, "end": 72, "i_start": 14, "i_end": 14}, "action": {"text": "measured", "start": 32, "end": 40, "i_start": 8, "i_end": 8}}, {"character": {"text": "rxte", "start": 48, "end": 52, "i_start": 11, "i_end": 11}, "action": {"text": "measured", "start": 32, "end": 40, "i_start": 8, "i_end": 8}}, {"character": {"text": "osse", "start": 57, "end": 61, "i_start": 13, "i_end": 13}, "action": {"text": "measured", "start": 32, "end": 40, "i_start": 8, "i_end": 8}}], "id": 4396}, {"sent": "these are known as generalized cp symmetries , or gcp symmetries .", "tokens": ["these", "are", "known", "as", "generalized", "cp", "symmetries", ",", "or", "gcp", "symmetries", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "are known", "start": 6, "end": 15, "i_start": 1, "i_end": 2}}], "id": 4397}, {"sent": "in , power allocation to maximize the throughput is studied when the amount of harvested energy and channel states are modeled as markov and static processes , respectively .", "tokens": ["in", ",", "power", "allocation", "to", "maximize", "the", "throughput", "is", "studied", "when", "the", "amount", "of", "harvested", "energy", "and", "channel", "states", "are", "modeled", "as", "markov", "and", "static", "processes", ",", "respectively", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "power allocation to maximize the throughput", "start": 5, "end": 48, "i_start": 2, "i_end": 7}, "verb": {"text": "is studied", "start": 49, "end": 59, "i_start": 8, "i_end": 9}}], "id": 4398}, {"sent": "convolutional neural networks have achieved great success in visual recognition in recent years .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "visual", "recognition", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "recognition", "start": 68, "end": 79, "i_start": 9, "i_end": 9}}], "id": 4399}, {"sent": "we adopt scaled exponential linear units as the activation function of the first 3 layers and the softmax function for the last layer .", "tokens": ["we", "adopt", "scaled", "exponential", "linear", "units", "as", "the", "activation", "function", "of", "the", "first", "3", "layers", "and", "the", "softmax", "function", "for", "the", "last", "layer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "3 layers", "start": 81, "end": 89, "i_start": 13, "i_end": 14}, "action": {"text": "function", "start": 59, "end": 67, "i_start": 9, "i_end": 9}}, {"character": {"text": "layer", "start": 128, "end": 133, "i_start": 22, "i_end": 22}, "action": {"text": "function", "start": 106, "end": 114, "i_start": 18, "i_end": 18}}], "id": 4400}, {"sent": "now we will proceed onto define interval loop interval semiring .", "tokens": ["now", "we", "will", "proceed", "onto", "define", "interval", "loop", "interval", "semiring", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "will proceed", "start": 7, "end": 19, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "proceed", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 25, "end": 31, "i_start": 5, "i_end": 5}}], "id": 4401}, {"sent": "bolme et al learn a minimum output sum of squared error filter over the luminance channel for fast visual tracking .", "tokens": ["bolme", "et", "al", "learn", "a", "minimum", "output", "sum", "of", "squared", "error", "filter", "over", "the", "luminance", "channel", "for", "fast", "visual", "tracking", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "bolme et al", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "learn", "start": 12, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "bolme", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "learn", "start": 12, "end": 17, "i_start": 3, "i_end": 3}}], "id": 4402}, {"sent": "order in the concordance group and heegaard floer homology .", "tokens": ["order", "in", "the", "concordance", "group", "and", "heegaard", "floer", "homology", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4403}, {"sent": "an adm charge corresponding to an asymptotic symmetry of a spacetime is defined via hamiltonian perturbation theory .", "tokens": ["an", "adm", "charge", "corresponding", "to", "an", "asymptotic", "symmetry", "of", "a", "spacetime", "is", "defined", "via", "hamiltonian", "perturbation", "theory", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "an adm charge corresponding to an asymptotic symmetry of a spacetime", "start": 0, "end": 68, "i_start": 0, "i_end": 10}, "verb": {"text": "is defined", "start": 69, "end": 79, "i_start": 11, "i_end": 12}}, {"character": {"text": "theory", "start": 109, "end": 115, "i_start": 16, "i_end": 16}, "action": {"text": "defined", "start": 72, "end": 79, "i_start": 12, "i_end": 12}}], "id": 4404}, {"sent": "can cauchy schwarz super inequality for super vector spaces .", "tokens": ["can", "cauchy", "schwarz", "super", "inequality", "for", "super", "vector", "spaces", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4405}, {"sent": "generative adversarial networks are one of the most popular generative models .", "tokens": ["generative", "adversarial", "networks", "are", "one", "of", "the", "most", "popular", "generative", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 3, "i_end": 3}}], "id": 4406}, {"sent": "for mlc , we use ms-coco , a recognition task covering 80 object classes .", "tokens": ["for", "mlc", ",", "we", "use", "ms", "-", "coco", ",", "a", "recognition", "task", "covering", "80", "object", "classes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 3, "i_end": 3}, "verb": {"text": "use", "start": 13, "end": 16, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 13, "end": 16, "i_start": 4, "i_end": 4}}, {"character": {"text": "task", "start": 41, "end": 45, "i_start": 11, "i_end": 11}, "action": {"text": "covering", "start": 46, "end": 54, "i_start": 12, "i_end": 12}}], "id": 4407}, {"sent": "a laser system is standard to calibrate timing and energy response for particle detectors .", "tokens": ["a", "laser", "system", "is", "standard", "to", "calibrate", "timing", "and", "energy", "response", "for", "particle", "detectors", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a laser system", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "system", "start": 8, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "calibrate", "start": 30, "end": 39, "i_start": 6, "i_end": 6}}], "id": 4408}, {"sent": "the perdew-burke-ernzerhof exchange-correlation potential was used , including semi-empirical dispersion corrections .", "tokens": ["the", "perdew", "-", "burke", "-", "ernzerhof", "exchange", "-", "correlation", "potential", "was", "used", ",", "including", "semi", "-", "empirical", "dispersion", "corrections", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the perdew-burke-ernzerhof exchange-correlation potential was used , including semi-empirical dispersion corrections", "start": 0, "end": 116, "i_start": 0, "i_end": 18}, "verb": {"text": "was used", "start": 58, "end": 66, "i_start": 10, "i_end": 11}}], "id": 4409}, {"sent": "in , non-singular solutions for screw and edge dislocations were found .", "tokens": ["in", ",", "non", "-", "singular", "solutions", "for", "screw", "and", "edge", "dislocations", "were", "found", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "non-singular solutions for screw and edge dislocations", "start": 5, "end": 59, "i_start": 2, "i_end": 10}, "verb": {"text": "were found", "start": 60, "end": 70, "i_start": 11, "i_end": 12}}], "id": 4410}, {"sent": "another important observed feature of complex networks is the presence of a community structure .", "tokens": ["another", "important", "observed", "feature", "of", "complex", "networks", "is", "the", "presence", "of", "a", "community", "structure", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "another important observed feature of complex networks", "start": 0, "end": 54, "i_start": 0, "i_end": 6}, "verb": {"text": "is", "start": 55, "end": 57, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 46, "end": 54, "i_start": 6, "i_end": 6}, "action": {"text": "feature", "start": 27, "end": 34, "i_start": 3, "i_end": 3}}], "id": 4411}, {"sent": "however , previous studies have shown that focus anisoplanatism can be solved for instance by using several lgs per object in order to sense the whole cylinder turbulence path .", "tokens": ["however", ",", "previous", "studies", "have", "shown", "that", "focus", "anisoplanatism", "can", "be", "solved", "for", "instance", "by", "using", "several", "lgs", "per", "object", "in", "order", "to", "sense", "the", "whole", "cylinder", "turbulence", "path", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "previous studies", "start": 10, "end": 26, "i_start": 2, "i_end": 3}, "verb": {"text": "have shown", "start": 27, "end": 37, "i_start": 4, "i_end": 5}}, {"subject": {"text": "that focus anisoplanatism", "start": 38, "end": 63, "i_start": 6, "i_end": 8}, "verb": {"text": "solved", "start": 71, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "studies", "start": 19, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 32, "end": 37, "i_start": 5, "i_end": 5}}], "id": 4412}, {"sent": "in the following , we denote the distance function of by dn .", "tokens": ["in", "the", "following", ",", "we", "denote", "the", "distance", "function", "of", "by", "dn", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "verb": {"text": "denote", "start": 22, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "denote", "start": 22, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "by dn", "start": 54, "end": 59, "i_start": 10, "i_end": 11}, "action": {"text": "function", "start": 42, "end": 50, "i_start": 8, "i_end": 8}}], "id": 4413}, {"sent": "in recent years , the accuracy of object detection has been dramatically improved thanks to the advance of deep convolutional neural network .", "tokens": ["in", "recent", "years", ",", "the", "accuracy", "of", "object", "detection", "has", "been", "dramatically", "improved", "thanks", "to", "the", "advance", "of", "deep", "convolutional", "neural", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the accuracy of object detection", "start": 18, "end": 50, "i_start": 4, "i_end": 8}, "verb": {"text": "improved", "start": 73, "end": 81, "i_start": 12, "i_end": 12}}, {"subject": {"text": "the accuracy of object detection", "start": 18, "end": 50, "i_start": 4, "i_end": 8}, "verb": {"text": "has been", "start": 51, "end": 59, "i_start": 9, "i_end": 10}}], "id": 4414}, {"sent": "we leverage object detection module with pretrained resnet-101 to produce the region-level representation .", "tokens": ["we", "leverage", "object", "detection", "module", "with", "pretrained", "resnet-101", "to", "produce", "the", "region", "-", "level", "representation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "leverage", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "leverage", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "module", "start": 29, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "detection", "start": 19, "end": 28, "i_start": 3, "i_end": 3}}], "id": 4415}, {"sent": "recent advances in deep neural networks have resulted in powerful models that demonstrate high predictive capabilities on a wide variety of tasks from image classification and other tasks .", "tokens": ["recent", "advances", "in", "deep", "neural", "networks", "have", "resulted", "in", "powerful", "models", "that", "demonstrate", "high", "predictive", "capabilities", "on", "a", "wide", "variety", "of", "tasks", "from", "image", "classification", "and", "other", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "recent advances in deep neural networks", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "have resulted", "start": 40, "end": 53, "i_start": 6, "i_end": 7}}, {"character": {"text": "models", "start": 66, "end": 72, "i_start": 10, "i_end": 10}, "action": {"text": "demonstrate", "start": 78, "end": 89, "i_start": 12, "i_end": 12}}], "id": 4416}, {"sent": "convolutional neural networks have broken many records of computer vision tasks , such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "broken", "many", "records", "of", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have broken", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "broken", "start": 35, "end": 41, "i_start": 4, "i_end": 4}}], "id": 4417}, {"sent": "besides the spqn regularizer , there are some other popular nonconvex regularizers for producing a sparse solution of a system or a vector optimization problem .", "tokens": ["besides", "the", "spqn", "regularizer", ",", "there", "are", "some", "other", "popular", "nonconvex", "regularizers", "for", "producing", "a", "sparse", "solution", "of", "a", "system", "or", "a", "vector", "optimization", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 31, "end": 36, "i_start": 5, "i_end": 5}, "verb": {"text": "are", "start": 37, "end": 40, "i_start": 6, "i_end": 6}}], "id": 4418}, {"sent": "correlations between count fluence hardness ratios and pulse peak time within bursts .", "tokens": ["correlations", "between", "count", "fluence", "hardness", "ratios", "and", "pulse", "peak", "time", "within", "bursts", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4419}, {"sent": "convolutional neural networks have witnessed great improvement on a series of vision tasks such as object classification .", "tokens": ["convolutional", "neural", "networks", "have", "witnessed", "great", "improvement", "on", "a", "series", "of", "vision", "tasks", "such", "as", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have witnessed", "start": 30, "end": 44, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "witnessed", "start": 35, "end": 44, "i_start": 4, "i_end": 4}}], "id": 4420}, {"sent": "for more details and applications on this subject we refer the interested reader to .", "tokens": ["for", "more", "details", "and", "applications", "on", "this", "subject", "we", "refer", "the", "interested", "reader", "to", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 50, "end": 52, "i_start": 8, "i_end": 8}, "verb": {"text": "refer", "start": 53, "end": 58, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 50, "end": 52, "i_start": 8, "i_end": 8}, "action": {"text": "refer", "start": 53, "end": 58, "i_start": 9, "i_end": 9}}], "id": 4421}, {"sent": "deep convolutional neural networks have achieved great success in computer vision related tasks such as image classification , and so on .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "computer", "vision", "related", "tasks", "such", "as", "image", "classification", ",", "and", "so", "on", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}], "id": 4422}, {"sent": "if hydrogen is the dominant collision partner , we can determine the density of h i necessary to collisionally excite the observed rotational levels of co .", "tokens": ["if", "hydrogen", "is", "the", "dominant", "collision", "partner", ",", "we", "can", "determine", "the", "density", "of", "h", "i", "necessary", "to", "collisionally", "excite", "the", "observed", "rotational", "levels", "of", "co", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 48, "end": 50, "i_start": 8, "i_end": 8}, "verb": {"text": "can determine", "start": 51, "end": 64, "i_start": 9, "i_end": 10}}, {"character": {"text": "we", "start": 48, "end": 50, "i_start": 8, "i_end": 8}, "action": {"text": "determine", "start": 55, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "density", "start": 69, "end": 76, "i_start": 12, "i_end": 12}, "action": {"text": "excite", "start": 111, "end": 117, "i_start": 19, "i_end": 19}}], "id": 4423}, {"sent": "we use the resnet-18 network pre-trained on imagenet as the image encoder .", "tokens": ["we", "use", "the", "resnet-18", "network", "pre", "-", "trained", "on", "imagenet", "as", "the", "image", "encoder", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 4424}, {"sent": "the gravitational field is a metric tensor on spacetime to which is naturally associated a metric-connection in the tangent bundle , and the gauge symmetries arise from diffeomorphisms acting on the spacetime manifold .", "tokens": ["the", "gravitational", "field", "is", "a", "metric", "tensor", "on", "spacetime", "to", "which", "is", "naturally", "associated", "a", "metric", "-", "connection", "in", "the", "tangent", "bundle", ",", "and", "the", "gauge", "symmetries", "arise", "from", "diffeomorphisms", "acting", "on", "the", "spacetime", "manifold", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the gravitational field", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the gauge symmetries", "start": 137, "end": 157, "i_start": 24, "i_end": 26}, "verb": {"text": "arise", "start": 158, "end": 163, "i_start": 27, "i_end": 27}}, {"character": {"text": "diffeomorphisms", "start": 169, "end": 184, "i_start": 29, "i_end": 29}, "action": {"text": "arise", "start": 158, "end": 163, "i_start": 27, "i_end": 27}}, {"character": {"text": "diffeomorphisms", "start": 169, "end": 184, "i_start": 29, "i_end": 29}, "action": {"text": "acting", "start": 185, "end": 191, "i_start": 30, "i_end": 30}}], "id": 4425}, {"sent": "sometimes , randomization has to be employed to achieve feasible beamforming vectors .", "tokens": ["sometimes", ",", "randomization", "has", "to", "be", "employed", "to", "achieve", "feasible", "beamforming", "vectors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "randomization", "start": 12, "end": 25, "i_start": 2, "i_end": 2}, "verb": {"text": "has", "start": 26, "end": 29, "i_start": 3, "i_end": 3}}], "id": 4426}, {"sent": "specialized networks for 3d recently , there has been a serious effort to have alternative ways of applying cnns in 3d data such as octnet .", "tokens": ["specialized", "networks", "for", "3d", "recently", ",", "there", "has", "been", "a", "serious", "effort", "to", "have", "alternative", "ways", "of", "applying", "cnns", "in", "3d", "data", "such", "as", "octnet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "specialized networks for 3d recently , there", "start": 0, "end": 44, "i_start": 0, "i_end": 6}, "verb": {"text": "has been", "start": 45, "end": 53, "i_start": 7, "i_end": 8}}], "id": 4427}, {"sent": "convolutional neural networks have proved their dominating spot in various machine learning tasks , such as speech recognition .", "tokens": ["convolutional", "neural", "networks", "have", "proved", "their", "dominating", "spot", "in", "various", "machine", "learning", "tasks", ",", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have proved", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "proved", "start": 35, "end": 41, "i_start": 4, "i_end": 4}}, {"character": {"text": "spot", "start": 59, "end": 63, "i_start": 7, "i_end": 7}, "action": {"text": "dominating", "start": 48, "end": 58, "i_start": 6, "i_end": 6}}], "id": 4428}, {"sent": "the most significant difference is the choice of the momentum range of the correlated particles .", "tokens": ["the", "most", "significant", "difference", "is", "the", "choice", "of", "the", "momentum", "range", "of", "the", "correlated", "particles", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most significant difference", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 4, "i_end": 4}}], "id": 4429}, {"sent": "using this technique in , it has been shown that under rayleigh flat-fading an oarray gain can be achieved .", "tokens": ["using", "this", "technique", "in", ",", "it", "has", "been", "shown", "that", "under", "rayleigh", "flat", "-", "fading", "an", "oarray", "gain", "can", "be", "achieved", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "verb": {"text": "has been shown", "start": 29, "end": 43, "i_start": 6, "i_end": 8}}, {"subject": {"text": "it", "start": 26, "end": 28, "i_start": 5, "i_end": 5}, "verb": {"text": "achieved", "start": 98, "end": 106, "i_start": 20, "i_end": 20}}], "id": 4430}, {"sent": "recently convolutional neural networks have performed very well on image classification tasks and are pervasive in machine learning and computer vision .", "tokens": ["recently", "convolutional", "neural", "networks", "have", "performed", "very", "well", "on", "image", "classification", "tasks", "and", "are", "pervasive", "in", "machine", "learning", "and", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 9, "end": 38, "i_start": 1, "i_end": 3}, "verb": {"text": "have performed", "start": 39, "end": 53, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "performed", "start": 44, "end": 53, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "pervasive", "start": 102, "end": 111, "i_start": 14, "i_end": 14}}], "id": 4431}, {"sent": "as the potential between correlated cooper pairs is attractive , the bcs state is also called a condensate .", "tokens": ["as", "the", "potential", "between", "correlated", "cooper", "pairs", "is", "attractive", ",", "the", "bcs", "state", "is", "also", "called", "a", "condensate", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the bcs state", "start": 65, "end": 78, "i_start": 10, "i_end": 12}, "verb": {"text": "called", "start": 87, "end": 93, "i_start": 15, "i_end": 15}}, {"subject": {"text": "the bcs state", "start": 65, "end": 78, "i_start": 10, "i_end": 12}, "verb": {"text": "is", "start": 79, "end": 81, "i_start": 13, "i_end": 13}}, {"character": {"text": "potential", "start": 7, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "attractive", "start": 52, "end": 62, "i_start": 8, "i_end": 8}}], "id": 4432}, {"sent": "deep convolutional neural networks have led to a series of breakthrough for visual tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "led", "to", "a", "series", "of", "breakthrough", "for", "visual", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have led", "start": 35, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "led", "start": 40, "end": 43, "i_start": 5, "i_end": 5}}], "id": 4433}, {"sent": "in recent years , deep neural networks have led to many breakthrough results in machine learning and computer vision , and are now widely deployed in industry .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "led", "to", "many", "breakthrough", "results", "in", "machine", "learning", "and", "computer", "vision", ",", "and", "are", "now", "widely", "deployed", "in", "industry", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have led", "start": 39, "end": 47, "i_start": 7, "i_end": 8}}, {"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "deployed", "start": 138, "end": 146, "i_start": 24, "i_end": 24}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "led", "start": 44, "end": 47, "i_start": 8, "i_end": 8}}], "id": 4434}, {"sent": "in recent years , deep convolutional networks have achieved remarkable results in many computer vision tasks .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "networks", "have", "achieved", "remarkable", "results", "in", "many", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional networks", "start": 18, "end": 45, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 8, "i_end": 8}}], "id": 4435}, {"sent": "we derive mode-coupling expressions for the tagged particle friction tensor and for an effective , shear-rate dependent temperature .", "tokens": ["we", "derive", "mode", "-", "coupling", "expressions", "for", "the", "tagged", "particle", "friction", "tensor", "and", "for", "an", "effective", ",", "shear", "-", "rate", "dependent", "temperature", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "derive", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "derive", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "temperature", "start": 120, "end": 131, "i_start": 21, "i_end": 21}, "action": {"text": "effective", "start": 87, "end": 96, "i_start": 15, "i_end": 15}}, {"character": {"text": "temperature", "start": 120, "end": 131, "i_start": 21, "i_end": 21}, "action": {"text": "dependent", "start": 110, "end": 119, "i_start": 20, "i_end": 20}}], "id": 4436}, {"sent": "so one expects that this problem will be easier to handle in the case of loop quantum cosmology .", "tokens": ["so", "one", "expects", "that", "this", "problem", "will", "be", "easier", "to", "handle", "in", "the", "case", "of", "loop", "quantum", "cosmology", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 3, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "expects", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"subject": {"text": "one", "start": 3, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "be", "start": 38, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "one", "start": 3, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "expects", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}], "id": 4437}, {"sent": "traditional machine learning algorithms are known to be vulnerable to adversarial examples .", "tokens": ["traditional", "machine", "learning", "algorithms", "are", "known", "to", "be", "vulnerable", "to", "adversarial", "examples", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "traditional machine learning algorithms", "start": 0, "end": 39, "i_start": 0, "i_end": 3}, "verb": {"text": "are known", "start": 40, "end": 49, "i_start": 4, "i_end": 5}}, {"character": {"text": "algorithms", "start": 29, "end": 39, "i_start": 3, "i_end": 3}, "action": {"text": "learning", "start": 20, "end": 28, "i_start": 2, "i_end": 2}}], "id": 4438}, {"sent": "management strategies for information technology .", "tokens": ["management", "strategies", "for", "information", "technology", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4439}, {"sent": "the baseline is the state-of-the-art architecture retinanet as backbone feature extractors .", "tokens": ["the", "baseline", "is", "the", "state", "-", "of", "-", "the", "-", "art", "architecture", "retinanet", "as", "backbone", "feature", "extractors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the baseline", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 4440}, {"sent": "to perform the calculations we employed the vienna ab-initio simulation package .", "tokens": ["to", "perform", "the", "calculations", "we", "employed", "the", "vienna", "ab", "-", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 28, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "employed", "start": 31, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 28, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "perform", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 4441}, {"sent": "in this context , deep neural networks have set benchmarks in various fields of research , such as computer vision , speech recognition and image classification .", "tokens": ["in", "this", "context", ",", "deep", "neural", "networks", "have", "set", "benchmarks", "in", "various", "fields", "of", "research", ",", "such", "as", "computer", "vision", ",", "speech", "recognition", "and", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have set", "start": 39, "end": 47, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "benchmarks", "start": 48, "end": 58, "i_start": 9, "i_end": 9}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "recognition", "start": 124, "end": 135, "i_start": 22, "i_end": 22}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "classification", "start": 146, "end": 160, "i_start": 25, "i_end": 25}}], "id": 4442}, {"sent": "the exchange-correlation of electrons was treated within the generalized gradient approximation as implemented by perdew-berke-enzelhof .", "tokens": ["the", "exchange", "-", "correlation", "of", "electrons", "was", "treated", "within", "the", "generalized", "gradient", "approximation", "as", "implemented", "by", "perdew", "-", "berke", "-", "enzelhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange-correlation of electrons", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "was treated", "start": 38, "end": 49, "i_start": 6, "i_end": 7}}, {"character": {"text": "perdew", "start": 114, "end": 120, "i_start": 16, "i_end": 16}, "action": {"text": "implemented", "start": 99, "end": 110, "i_start": 14, "i_end": 14}}], "id": 4443}, {"sent": "we use adam optimizer as the gradient descent to optimize network weights .", "tokens": ["we", "use", "adam", "optimizer", "as", "the", "gradient", "descent", "to", "optimize", "network", "weights", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimizer", "start": 12, "end": 21, "i_start": 3, "i_end": 3}}], "id": 4444}, {"sent": "deep neural networks , particularly convolutional neural networks have become exceptionally successful in a wide variety of visual object recognition and classification tasks .", "tokens": ["deep", "neural", "networks", ",", "particularly", "convolutional", "neural", "networks", "have", "become", "exceptionally", "successful", "in", "a", "wide", "variety", "of", "visual", "object", "recognition", "and", "classification", "tasks", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have become", "start": 66, "end": 77, "i_start": 8, "i_end": 9}}], "id": 4445}, {"sent": "a central extension and an extension by a derivation of a polynomial loop algebra over a finite-dimensional simple lie algebra give a lie algebra which is isomorphic with a nontwisted affine kac-moody algebra .", "tokens": ["a", "central", "extension", "and", "an", "extension", "by", "a", "derivation", "of", "a", "polynomial", "loop", "algebra", "over", "a", "finite", "-", "dimensional", "simple", "lie", "algebra", "give", "a", "lie", "algebra", "which", "is", "isomorphic", "with", "a", "nontwisted", "affine", "kac", "-", "moody", "algebra", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "a central extension and an extension by a derivation of a polynomial loop algebra over a finite-dimensional simple lie algebra", "start": 0, "end": 126, "i_start": 0, "i_end": 21}, "verb": {"text": "give", "start": 127, "end": 131, "i_start": 22, "i_end": 22}}, {"character": {"text": "extension", "start": 10, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "give", "start": 127, "end": 131, "i_start": 22, "i_end": 22}}, {"character": {"text": "central", "start": 2, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "give", "start": 127, "end": 131, "i_start": 22, "i_end": 22}}, {"character": {"text": "extension", "start": 27, "end": 36, "i_start": 5, "i_end": 5}, "action": {"text": "give", "start": 127, "end": 131, "i_start": 22, "i_end": 22}}, {"character": {"text": "derivation", "start": 42, "end": 52, "i_start": 8, "i_end": 8}, "action": {"text": "give", "start": 127, "end": 131, "i_start": 22, "i_end": 22}}, {"character": {"text": "loop", "start": 69, "end": 73, "i_start": 12, "i_end": 12}, "action": {"text": "give", "start": 127, "end": 131, "i_start": 22, "i_end": 22}}, {"character": {"text": "polynomial", "start": 58, "end": 68, "i_start": 11, "i_end": 11}, "action": {"text": "give", "start": 127, "end": 131, "i_start": 22, "i_end": 22}}, {"character": {"text": "lie", "start": 115, "end": 118, "i_start": 20, "i_end": 20}, "action": {"text": "give", "start": 127, "end": 131, "i_start": 22, "i_end": 22}}, {"character": {"text": "dimensional", "start": 96, "end": 107, "i_start": 18, "i_end": 18}, "action": {"text": "give", "start": 127, "end": 131, "i_start": 22, "i_end": 22}}, {"character": {"text": "finite", "start": 89, "end": 95, "i_start": 16, "i_end": 16}, "action": {"text": "give", "start": 127, "end": 131, "i_start": 22, "i_end": 22}}], "id": 4446}, {"sent": "in order to establish the adaptability of our proposed method , we train our model on a very different dataset than the places365 dataset zhou et al .", "tokens": ["in", "order", "to", "establish", "the", "adaptability", "of", "our", "proposed", "method", ",", "we", "train", "our", "model", "on", "a", "very", "different", "dataset", "than", "the", "places365", "dataset", "zhou", "et", "al", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 64, "end": 66, "i_start": 11, "i_end": 11}, "verb": {"text": "train", "start": 67, "end": 72, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "train", "start": 67, "end": 72, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "establish", "start": 12, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 64, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "proposed", "start": 46, "end": 54, "i_start": 8, "i_end": 8}}], "id": 4447}, {"sent": "we show further how one can use these networks to transfer entangled quantum states and to generate entanglement between distant sites in the network .", "tokens": ["we", "show", "further", "how", "one", "can", "use", "these", "networks", "to", "transfer", "entangled", "quantum", "states", "and", "to", "generate", "entanglement", "between", "distant", "sites", "in", "the", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "one", "start": 20, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 28, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "one", "start": 20, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 28, "end": 31, "i_start": 6, "i_end": 6}}, {"character": {"text": "one", "start": 20, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "transfer", "start": 50, "end": 58, "i_start": 10, "i_end": 10}}, {"character": {"text": "one", "start": 20, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "generate", "start": 91, "end": 99, "i_start": 16, "i_end": 16}}], "id": 4448}, {"sent": "recently , deep learning architectures have led to remarkable progress in problems like speech recognition and many others .", "tokens": ["recently", ",", "deep", "learning", "architectures", "have", "led", "to", "remarkable", "progress", "in", "problems", "like", "speech", "recognition", "and", "many", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning architectures", "start": 11, "end": 38, "i_start": 2, "i_end": 4}, "verb": {"text": "have led", "start": 39, "end": 47, "i_start": 5, "i_end": 6}}, {"character": {"text": "architectures", "start": 25, "end": 38, "i_start": 4, "i_end": 4}, "action": {"text": "led", "start": 44, "end": 47, "i_start": 6, "i_end": 6}}], "id": 4449}, {"sent": "in , resource allocation algorithms for multicast transmissions and tcp protocol performance were analyzed in a long term evolution -based geo system , providing valuable solutions .", "tokens": ["in", ",", "resource", "allocation", "algorithms", "for", "multicast", "transmissions", "and", "tcp", "protocol", "performance", "were", "analyzed", "in", "a", "long", "term", "evolution", "-based", "geo", "system", ",", "providing", "valuable", "solutions", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "resource allocation algorithms for multicast transmissions and tcp protocol performance", "start": 5, "end": 92, "i_start": 2, "i_end": 11}, "verb": {"text": "were analyzed", "start": 93, "end": 106, "i_start": 12, "i_end": 13}}, {"character": {"text": "algorithms", "start": 25, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "allocation", "start": 14, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "protocol", "start": 72, "end": 80, "i_start": 10, "i_end": 10}, "action": {"text": "performance", "start": 81, "end": 92, "i_start": 11, "i_end": 11}}], "id": 4450}, {"sent": "further it has been found that the low energy behavior of the d-branes are well described by supersymmetric yang-mills theory .", "tokens": ["further", "it", "has", "been", "found", "that", "the", "low", "energy", "behavior", "of", "the", "d", "-", "branes", "are", "well", "described", "by", "supersymmetric", "yang", "-", "mills", "theory", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "has been found", "start": 11, "end": 25, "i_start": 2, "i_end": 4}}, {"subject": {"text": "the low energy behavior of the d-branes", "start": 31, "end": 70, "i_start": 6, "i_end": 14}, "verb": {"text": "described", "start": 80, "end": 89, "i_start": 17, "i_end": 17}}, {"character": {"text": "theory", "start": 119, "end": 125, "i_start": 23, "i_end": 23}, "action": {"text": "described", "start": 80, "end": 89, "i_start": 17, "i_end": 17}}], "id": 4451}, {"sent": "random linear network coding and more recently , random affine network coding , are powerful means for distributing information in networks .", "tokens": ["random", "linear", "network", "coding", "and", "more", "recently", ",", "random", "affine", "network", "coding", ",", "are", "powerful", "means", "for", "distributing", "information", "in", "networks", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "random linear network coding and more recently", "start": 0, "end": 46, "i_start": 0, "i_end": 6}, "verb": {"text": "are", "start": 80, "end": 83, "i_start": 13, "i_end": 13}}], "id": 4452}, {"sent": "we adopt the region proposal network from faster rcnn for the object localization .", "tokens": ["we", "adopt", "the", "region", "proposal", "network", "from", "faster", "rcnn", "for", "the", "object", "localization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 4453}, {"sent": "yang et al rank similarity of image regions with foreground or background cues using a graph-based manifold ranking .", "tokens": ["yang", "et", "al", "rank", "similarity", "of", "image", "regions", "with", "foreground", "or", "background", "cues", "using", "a", "graph", "-", "based", "manifold", "ranking", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "yang", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "rank", "start": 11, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "yang", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 79, "end": 84, "i_start": 13, "i_end": 13}}], "id": 4454}, {"sent": "here and below , the symbol tr denotes the contraction with respect to all repeated indices , which will not be shown explicitly .", "tokens": ["here", "and", "below", ",", "the", "symbol", "tr", "denotes", "the", "contraction", "with", "respect", "to", "all", "repeated", "indices", ",", "which", "will", "not", "be", "shown", "explicitly", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the symbol tr", "start": 17, "end": 30, "i_start": 4, "i_end": 6}, "verb": {"text": "denotes", "start": 31, "end": 38, "i_start": 7, "i_end": 7}}, {"character": {"text": "tr", "start": 28, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "denotes", "start": 31, "end": 38, "i_start": 7, "i_end": 7}}], "id": 4455}, {"sent": "collell et al introduce a multi-modal recurrent neural network to generate image descriptions .", "tokens": ["collell", "et", "al", "introduce", "a", "multi", "-", "modal", "recurrent", "neural", "network", "to", "generate", "image", "descriptions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "collell et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "introduce", "start": 14, "end": 23, "i_start": 3, "i_end": 3}}], "id": 4456}, {"sent": "in fact , the iterative algorithm in can significant improve the secrecy rate by directly optimizing the precoder matrix .", "tokens": ["in", "fact", ",", "the", "iterative", "algorithm", "in", "can", "significant", "improve", "the", "secrecy", "rate", "by", "directly", "optimizing", "the", "precoder", "matrix", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the iterative algorithm in", "start": 10, "end": 36, "i_start": 3, "i_end": 6}, "verb": {"text": "improve", "start": 53, "end": 60, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the iterative algorithm in", "start": 10, "end": 36, "i_start": 3, "i_end": 6}, "verb": {"text": "can", "start": 37, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "algorithm", "start": 24, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "improve", "start": 53, "end": 60, "i_start": 9, "i_end": 9}}, {"character": {"text": "algorithm", "start": 24, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "optimizing", "start": 90, "end": 100, "i_start": 15, "i_end": 15}}], "id": 4457}, {"sent": "the discrepancy is a consequence of the changes made to the collision step , as the exchange of momentum between the mpcd particles and the colloid , via vp , changes the effective number of local brownian collisions .", "tokens": ["the", "discrepancy", "is", "a", "consequence", "of", "the", "changes", "made", "to", "the", "collision", "step", ",", "as", "the", "exchange", "of", "momentum", "between", "the", "mpcd", "particles", "and", "the", "colloid", ",", "via", "vp", ",", "changes", "the", "effective", "number", "of", "local", "brownian", "collisions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the discrepancy", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "exchange", "start": 84, "end": 92, "i_start": 16, "i_end": 16}, "action": {"text": "changes", "start": 159, "end": 166, "i_start": 30, "i_end": 30}}, {"character": {"text": "particles", "start": 122, "end": 131, "i_start": 22, "i_end": 22}, "action": {"text": "exchange", "start": 84, "end": 92, "i_start": 16, "i_end": 16}}, {"character": {"text": "number", "start": 181, "end": 187, "i_start": 33, "i_end": 33}, "action": {"text": "effective", "start": 171, "end": 180, "i_start": 32, "i_end": 32}}], "id": 4458}, {"sent": "deep convolutional neural networks have successfully revolutionized various challenging tasks , eg , image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "successfully", "revolutionized", "various", "challenging", "tasks", ",", "eg", ",", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "revolutionized", "start": 53, "end": 67, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "revolutionized", "start": 53, "end": 67, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "successfully", "start": 40, "end": 52, "i_start": 5, "i_end": 5}}], "id": 4459}, {"sent": "differential privacy is the most well-known technique to use this approach .", "tokens": ["differential", "privacy", "is", "the", "most", "well", "-", "known", "technique", "to", "use", "this", "approach", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "differential privacy", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 2, "i_end": 2}}], "id": 4460}, {"sent": "goodfellow et al propose the fast gradient sign method for generating adversarial examples .", "tokens": ["goodfellow", "et", "al", "propose", "the", "fast", "gradient", "sign", "method", "for", "generating", "adversarial", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "goodfellow", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 17, "end": 24, "i_start": 3, "i_end": 3}}], "id": 4461}, {"sent": "a quiver a is a finite oriented graph with no oriented cycles .", "tokens": ["a", "quiver", "a", "is", "a", "finite", "oriented", "graph", "with", "no", "oriented", "cycles", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "graph", "start": 32, "end": 37, "i_start": 7, "i_end": 7}, "action": {"text": "no", "start": 43, "end": 45, "i_start": 9, "i_end": 9}}], "id": 4462}, {"sent": "convolutional neural networks have achieved notable successes in a variety of visual recognition tasks , such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "notable", "successes", "in", "a", "variety", "of", "visual", "recognition", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successes", "start": 52, "end": 61, "i_start": 6, "i_end": 6}}], "id": 4463}, {"sent": "iac scripts are susceptible to human errors and bad coding practices , which make scripts susceptible to defects .", "tokens": ["iac", "scripts", "are", "susceptible", "to", "human", "errors", "and", "bad", "coding", "practices", ",", "which", "make", "scripts", "susceptible", "to", "defects", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "iac scripts", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 12, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "and", "start": 44, "end": 47, "i_start": 7, "i_end": 7}, "action": {"text": "make", "start": 77, "end": 81, "i_start": 13, "i_end": 13}}], "id": 4464}, {"sent": "recent deep learning models trained on large-scale datasets have significantly advanced the task of image classification and related applications in computer vision , such as object detection .", "tokens": ["recent", "deep", "learning", "models", "trained", "on", "large", "-", "scale", "datasets", "have", "significantly", "advanced", "the", "task", "of", "image", "classification", "and", "related", "applications", "in", "computer", "vision", ",", "such", "as", "object", "detection", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "recent deep learning models trained on large-scale datasets", "start": 0, "end": 59, "i_start": 0, "i_end": 9}, "verb": {"text": "advanced", "start": 79, "end": 87, "i_start": 12, "i_end": 12}}, {"subject": {"text": "recent deep learning models trained on large-scale datasets", "start": 0, "end": 59, "i_start": 0, "i_end": 9}, "verb": {"text": "have", "start": 60, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "models", "start": 21, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "advanced", "start": 79, "end": 87, "i_start": 12, "i_end": 12}}], "id": 4465}, {"sent": "the linear gauge field term in the perturbative expansion is universal .", "tokens": ["the", "linear", "gauge", "field", "term", "in", "the", "perturbative", "expansion", "is", "universal", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the linear gauge field term in the perturbative expansion", "start": 0, "end": 57, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 58, "end": 60, "i_start": 9, "i_end": 9}}], "id": 4466}, {"sent": "umetsu , gauge theory on noncommutative supersphere from supermatrix model , phys .", "tokens": ["umetsu", ",", "gauge", "theory", "on", "noncommutative", "supersphere", "from", "supermatrix", "model", ",", "phys", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4467}, {"sent": "classical quantities are conveniently represented as moments of some joint distribution functions connected to measurements .", "tokens": ["classical", "quantities", "are", "conveniently", "represented", "as", "moments", "of", "some", "joint", "distribution", "functions", "connected", "to", "measurements", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "classical quantities", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "represented", "start": 38, "end": 49, "i_start": 4, "i_end": 4}}, {"subject": {"text": "classical quantities", "start": 0, "end": 20, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 2, "i_end": 2}}], "id": 4468}, {"sent": "ijb-a is a face verif ication and identif ication dataset , containing images captured from unconstrained environments with wide variations of pose and imaging conditions .", "tokens": ["ijb", "-", "a", "is", "a", "face", "verif", "ication", "and", "identif", "ication", "dataset", ",", "containing", "images", "captured", "from", "unconstrained", "environments", "with", "wide", "variations", "of", "pose", "and", "imaging", "conditions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "ijb-a", "start": 0, "end": 5, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 6, "end": 8, "i_start": 3, "i_end": 3}}, {"character": {"text": "dataset", "start": 50, "end": 57, "i_start": 11, "i_end": 11}, "action": {"text": "containing", "start": 60, "end": 70, "i_start": 13, "i_end": 13}}], "id": 4469}, {"sent": "along the way discuss the basic methods for finding asymptotics of sums of arithmetic functions , and we also compute the arithmetic factor in the standard conjectures for moments of the zeta-function .", "tokens": ["along", "the", "way", "discuss", "the", "basic", "methods", "for", "finding", "asymptotics", "of", "sums", "of", "arithmetic", "functions", ",", "and", "we", "also", "compute", "the", "arithmetic", "factor", "in", "the", "standard", "conjectures", "for", "moments", "of", "the", "zeta", "-", "function", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 102, "end": 104, "i_start": 17, "i_end": 17}, "verb": {"text": "discuss", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 102, "end": 104, "i_start": 17, "i_end": 17}, "verb": {"text": "compute", "start": 110, "end": 117, "i_start": 19, "i_end": 19}}, {"character": {"text": "we", "start": 102, "end": 104, "i_start": 17, "i_end": 17}, "action": {"text": "discuss", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}], "id": 4470}, {"sent": "avalanche analysis of nlfps in the awake cat .", "tokens": ["avalanche", "analysis", "of", "nlfps", "in", "the", "awake", "cat", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "cat", "start": 41, "end": 44, "i_start": 7, "i_end": 7}, "action": {"text": "awake", "start": 35, "end": 40, "i_start": 6, "i_end": 6}}], "id": 4471}, {"sent": "onvolutional neural networks have achieved remarkable performance on vision problems such as image classification .", "tokens": ["onvolutional", "neural", "networks", "have", "achieved", "remarkable", "performance", "on", "vision", "problems", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "onvolutional neural networks", "start": 0, "end": 28, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 29, "end": 42, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 20, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 34, "end": 42, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 20, "end": 28, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 54, "end": 65, "i_start": 6, "i_end": 6}}], "id": 4472}, {"sent": "second order symmetries of the laplacian on r 3 were classified by boyer , kalnins , and miller .", "tokens": ["second", "order", "symmetries", "of", "the", "laplacian", "on", "r", "3", "were", "classified", "by", "boyer", ",", "kalnins", ",", "and", "miller", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "second order symmetries of the laplacian on r 3", "start": 0, "end": 47, "i_start": 0, "i_end": 8}, "verb": {"text": "were classified", "start": 48, "end": 63, "i_start": 9, "i_end": 10}}, {"character": {"text": "boyer", "start": 67, "end": 72, "i_start": 12, "i_end": 12}, "action": {"text": "classified", "start": 53, "end": 63, "i_start": 10, "i_end": 10}}, {"character": {"text": "kalnins", "start": 75, "end": 82, "i_start": 14, "i_end": 14}, "action": {"text": "classified", "start": 53, "end": 63, "i_start": 10, "i_end": 10}}, {"character": {"text": "miller", "start": 89, "end": 95, "i_start": 17, "i_end": 17}, "action": {"text": "classified", "start": 53, "end": 63, "i_start": 10, "i_end": 10}}], "id": 4473}, {"sent": "in recent years , deep neural networks have been applied to many areas and have achieved huge success in different domains such as image classification .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "been", "applied", "to", "many", "areas", "and", "have", "achieved", "huge", "success", "in", "different", "domains", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have been applied", "start": 39, "end": 56, "i_start": 7, "i_end": 9}}, {"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "achieved", "start": 80, "end": 88, "i_start": 15, "i_end": 15}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 80, "end": 88, "i_start": 15, "i_end": 15}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 94, "end": 101, "i_start": 17, "i_end": 17}}], "id": 4474}, {"sent": "finfet is one of the options which provides excellent scalability due to its non-planar structure .", "tokens": ["finfet", "is", "one", "of", "the", "options", "which", "provides", "excellent", "scalability", "due", "to", "its", "non", "-", "planar", "structure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "finfet", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 7, "end": 9, "i_start": 1, "i_end": 1}}], "id": 4475}, {"sent": "convolutional neural networks have shown their efficiency for a wide range of tasks .", "tokens": ["convolutional", "neural", "networks", "have", "shown", "their", "efficiency", "for", "a", "wide", "range", "of", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 35, "end": 40, "i_start": 4, "i_end": 4}}], "id": 4476}, {"sent": "the scattering of quantum fields around a classical gravitational background has had an important impact in the study of quantum fields in curved spaces .", "tokens": ["the", "scattering", "of", "quantum", "fields", "around", "a", "classical", "gravitational", "background", "has", "had", "an", "important", "impact", "in", "the", "study", "of", "quantum", "fields", "in", "curved", "spaces", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the scattering of quantum fields around a classical gravitational background", "start": 0, "end": 76, "i_start": 0, "i_end": 9}, "verb": {"text": "has had", "start": 77, "end": 84, "i_start": 10, "i_end": 11}}, {"character": {"text": "scattering", "start": 4, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "impact", "start": 98, "end": 104, "i_start": 14, "i_end": 14}}], "id": 4477}, {"sent": "isola et al proposed a framework called pix2pix , which used generative adversarial networks for image-to-image translation .", "tokens": ["isola", "et", "al", "proposed", "a", "framework", "called", "pix2pix", ",", "which", "used", "generative", "adversarial", "networks", "for", "image", "-", "to", "-", "image", "translation", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 6, "end": 11, "i_start": 1, "i_end": 2}, "verb": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "isola", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "framework", "start": 23, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "used", "start": 56, "end": 60, "i_start": 10, "i_end": 10}}], "id": 4478}, {"sent": "generalized gradient approximation by perdew , burke , and ernzerhof parametrization is employed for the exchange-correlation potential .", "tokens": ["generalized", "gradient", "approximation", "by", "perdew", ",", "burke", ",", "and", "ernzerhof", "parametrization", "is", "employed", "for", "the", "exchange", "-", "correlation", "potential", "."], "score": [0, 1, 0, 0, 1], "labels": [{"subject": {"text": "generalized gradient approximation by perdew", "start": 0, "end": 44, "i_start": 0, "i_end": 4}, "verb": {"text": "is employed", "start": 85, "end": 96, "i_start": 11, "i_end": 12}}, {"character": {"text": "perdew", "start": 38, "end": 44, "i_start": 4, "i_end": 4}, "action": {"text": "approximation", "start": 21, "end": 34, "i_start": 2, "i_end": 2}}, {"character": {"text": "burke", "start": 47, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "approximation", "start": 21, "end": 34, "i_start": 2, "i_end": 2}}, {"character": {"text": "ernzerhof", "start": 59, "end": 68, "i_start": 9, "i_end": 9}, "action": {"text": "approximation", "start": 21, "end": 34, "i_start": 2, "i_end": 2}}], "id": 4479}, {"sent": "loading rydberg atoms into deep optical lattices has been achieved recently , allowing the realization of spin-lattice models and observation of spatial ordering due to long-range interaction .", "tokens": ["loading", "rydberg", "atoms", "into", "deep", "optical", "lattices", "has", "been", "achieved", "recently", ",", "allowing", "the", "realization", "of", "spin", "-", "lattice", "models", "and", "observation", "of", "spatial", "ordering", "due", "to", "long", "-", "range", "interaction", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "loading rydberg atoms into deep optical lattices", "start": 0, "end": 48, "i_start": 0, "i_end": 6}, "verb": {"text": "has been achieved", "start": 49, "end": 66, "i_start": 7, "i_end": 9}}, {"character": {"text": "achieved", "start": 58, "end": 66, "i_start": 9, "i_end": 9}, "action": {"text": "allowing", "start": 78, "end": 86, "i_start": 12, "i_end": 12}}], "id": 4480}, {"sent": "the following result already appears in , but we include the proof for completeness .", "tokens": ["the", "following", "result", "already", "appears", "in", ",", "but", "we", "include", "the", "proof", "for", "completeness", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the following result", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "appears", "start": 29, "end": 36, "i_start": 4, "i_end": 4}}, {"subject": {"text": "we", "start": 46, "end": 48, "i_start": 8, "i_end": 8}, "verb": {"text": "include", "start": 49, "end": 56, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 46, "end": 48, "i_start": 8, "i_end": 8}, "action": {"text": "include", "start": 49, "end": 56, "i_start": 9, "i_end": 9}}], "id": 4481}, {"sent": "finally , our work can be seen as an instance of the transfer learning paradigm , which has been successful in both linguistic and visual processing .", "tokens": ["finally", ",", "our", "work", "can", "be", "seen", "as", "an", "instance", "of", "the", "transfer", "learning", "paradigm", ",", "which", "has", "been", "successful", "in", "both", "linguistic", "and", "visual", "processing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our work", "start": 10, "end": 18, "i_start": 2, "i_end": 3}, "verb": {"text": "can be seen", "start": 19, "end": 30, "i_start": 4, "i_end": 6}}, {"character": {"text": "paradigm", "start": 71, "end": 79, "i_start": 14, "i_end": 14}, "action": {"text": "successful", "start": 97, "end": 107, "i_start": 19, "i_end": 19}}], "id": 4482}, {"sent": "in superconductors this is the ginzburg-landau method1 .", "tokens": ["in", "superconductors", "this", "is", "the", "ginzburg", "-", "landau", "method1", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 19, "end": 23, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}], "id": 4483}, {"sent": "cosmic strings are linear topological defects generated in symmetry breaking phase transitions in the early universe due to the kibble mechanism .", "tokens": ["cosmic", "strings", "are", "linear", "topological", "defects", "generated", "in", "symmetry", "breaking", "phase", "transitions", "in", "the", "early", "universe", "due", "to", "the", "kibble", "mechanism", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "cosmic strings", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 15, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "transitions", "start": 83, "end": 94, "i_start": 11, "i_end": 11}, "action": {"text": "generated", "start": 46, "end": 55, "i_start": 6, "i_end": 6}}, {"character": {"text": "transitions", "start": 83, "end": 94, "i_start": 11, "i_end": 11}, "action": {"text": "breaking", "start": 68, "end": 76, "i_start": 9, "i_end": 9}}], "id": 4484}, {"sent": "we use the pascal 2012 segmentation data set to evaluate the proposed methods on natural image semantic segmentation task .", "tokens": ["we", "use", "the", "pascal", "2012", "segmentation", "data", "set", "to", "evaluate", "the", "proposed", "methods", "on", "natural", "image", "semantic", "segmentation", "task", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 48, "end": 56, "i_start": 9, "i_end": 9}}], "id": 4485}, {"sent": "the agreement with the available data is fairly good .", "tokens": ["the", "agreement", "with", "the", "available", "data", "is", "fairly", "good", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the agreement with the available data", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 6, "i_end": 6}}], "id": 4486}, {"sent": "among others , the two-dimensional case arises in pat with integrating line detectors , which is very time consuming .", "tokens": ["among", "others", ",", "the", "two", "-", "dimensional", "case", "arises", "in", "pat", "with", "integrating", "line", "detectors", ",", "which", "is", "very", "time", "consuming", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the two-dimensional case", "start": 15, "end": 39, "i_start": 3, "i_end": 7}, "verb": {"text": "arises", "start": 40, "end": 46, "i_start": 8, "i_end": 8}}, {"character": {"text": "integrating", "start": 59, "end": 70, "i_start": 12, "i_end": 12}, "action": {"text": "arises", "start": 40, "end": 46, "i_start": 8, "i_end": 8}}, {"character": {"text": "integrating", "start": 59, "end": 70, "i_start": 12, "i_end": 12}, "action": {"text": "consuming", "start": 107, "end": 116, "i_start": 20, "i_end": 20}}], "id": 4487}, {"sent": "a detailed description of the cms detector , together with a definition of the coordinate system and the relevant kinematic variables , can be found in ref .", "tokens": ["a", "detailed", "description", "of", "the", "cms", "detector", ",", "together", "with", "a", "definition", "of", "the", "coordinate", "system", "and", "the", "relevant", "kinematic", "variables", ",", "can", "be", "found", "in", "ref", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "a detailed description of the cms detector", "start": 0, "end": 42, "i_start": 0, "i_end": 6}, "verb": {"text": "can be found", "start": 136, "end": 148, "i_start": 22, "i_end": 24}}], "id": 4488}, {"sent": "if an orbit contains a critical point of f then , by invariance , all points of this orbit are critical points and the orbit itself is called a critical orbit of f .", "tokens": ["if", "an", "orbit", "contains", "a", "critical", "point", "of", "f", "then", ",", "by", "invariance", ",", "all", "points", "of", "this", "orbit", "are", "critical", "points", "and", "the", "orbit", "itself", "is", "called", "a", "critical", "orbit", "of", "f", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "all points of this orbit", "start": 66, "end": 90, "i_start": 14, "i_end": 18}, "verb": {"text": "are", "start": 91, "end": 94, "i_start": 19, "i_end": 19}}, {"subject": {"text": "the orbit itself", "start": 115, "end": 131, "i_start": 23, "i_end": 25}, "verb": {"text": "called", "start": 135, "end": 141, "i_start": 27, "i_end": 27}}, {"character": {"text": "orbit", "start": 6, "end": 11, "i_start": 2, "i_end": 2}, "action": {"text": "contains", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}], "id": 4489}, {"sent": "the grayscale is the digital sky survey image and the contour image is the h i from the vla .", "tokens": ["the", "grayscale", "is", "the", "digital", "sky", "survey", "image", "and", "the", "contour", "image", "is", "the", "h", "i", "from", "the", "vla", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the grayscale", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the grayscale", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 68, "end": 70, "i_start": 12, "i_end": 12}}], "id": 4490}, {"sent": "in recent years , the deep convolutional neural networks have made great breakthroughs in computer vision .", "tokens": ["in", "recent", "years", ",", "the", "deep", "convolutional", "neural", "networks", "have", "made", "great", "breakthroughs", "in", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the deep convolutional neural networks", "start": 18, "end": 56, "i_start": 4, "i_end": 8}, "verb": {"text": "have made", "start": 57, "end": 66, "i_start": 9, "i_end": 10}}, {"character": {"text": "networks", "start": 48, "end": 56, "i_start": 8, "i_end": 8}, "action": {"text": "breakthroughs", "start": 73, "end": 86, "i_start": 12, "i_end": 12}}], "id": 4491}, {"sent": "as larger scale experiments , we trained resnet-50 on imagenet .", "tokens": ["as", "larger", "scale", "experiments", ",", "we", "trained", "resnet-50", "on", "imagenet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "verb": {"text": "trained", "start": 33, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "trained", "start": 33, "end": 40, "i_start": 6, "i_end": 6}}], "id": 4492}, {"sent": "dynamic modeling of constrained flexible robot arms for controller design .", "tokens": ["dynamic", "modeling", "of", "constrained", "flexible", "robot", "arms", "for", "controller", "design", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4493}, {"sent": "consequently , stochastic gradient descent has been a typical alternation .", "tokens": ["consequently", ",", "stochastic", "gradient", "descent", "has", "been", "a", "typical", "alternation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "stochastic gradient descent", "start": 15, "end": 42, "i_start": 2, "i_end": 4}, "verb": {"text": "has been", "start": 43, "end": 51, "i_start": 5, "i_end": 6}}], "id": 4494}, {"sent": "convolutional neural networks have been demonstrated to have state-of-the-art performances in many computer vision tasks such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "been", "demonstrated", "to", "have", "state", "-", "of", "-", "the", "-", "art", "performances", "in", "many", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been demonstrated", "start": 30, "end": 52, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performances", "start": 78, "end": 90, "i_start": 15, "i_end": 15}}], "id": 4495}, {"sent": "the proof follows from continuity of the floquet multipliers .", "tokens": ["the", "proof", "follows", "from", "continuity", "of", "the", "floquet", "multipliers", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the proof", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "follows", "start": 10, "end": 17, "i_start": 2, "i_end": 2}}], "id": 4496}, {"sent": "based on recursive neural network , luong et al utilized the weighted morpheme part and basic part of an english word to improve the representation of it .", "tokens": ["based", "on", "recursive", "neural", "network", ",", "luong", "et", "al", "utilized", "the", "weighted", "morpheme", "part", "and", "basic", "part", "of", "an", "english", "word", "to", "improve", "the", "representation", "of", "it", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 42, "end": 47, "i_start": 7, "i_end": 8}, "verb": {"text": "utilized", "start": 48, "end": 56, "i_start": 9, "i_end": 9}}, {"character": {"text": "luong", "start": 36, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "utilized", "start": 48, "end": 56, "i_start": 9, "i_end": 9}}, {"character": {"text": "luong", "start": 36, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "improve", "start": 121, "end": 128, "i_start": 22, "i_end": 22}}], "id": 4497}, {"sent": "if and only if this is the case , there exists an g-invariant infinitesimal causal structure on m .", "tokens": ["if", "and", "only", "if", "this", "is", "the", "case", ",", "there", "exists", "an", "g", "-", "invariant", "infinitesimal", "causal", "structure", "on", "m", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 34, "end": 39, "i_start": 9, "i_end": 9}, "verb": {"text": "exists", "start": 40, "end": 46, "i_start": 10, "i_end": 10}}, {"character": {"text": "structure", "start": 83, "end": 92, "i_start": 17, "i_end": 17}, "action": {"text": "if", "start": 0, "end": 2, "i_start": 0, "i_end": 0}}], "id": 4498}, {"sent": "the works of gave algorithms to solve various approximate numerical linear algebra problems given small memory and a only one or few passes over an input matrix .", "tokens": ["the", "works", "of", "gave", "algorithms", "to", "solve", "various", "approximate", "numerical", "linear", "algebra", "problems", "given", "small", "memory", "and", "a", "only", "one", "or", "few", "passes", "over", "an", "input", "matrix", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the works of", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "gave", "start": 13, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithms", "start": 18, "end": 28, "i_start": 4, "i_end": 4}, "action": {"text": "solve", "start": 32, "end": 37, "i_start": 6, "i_end": 6}}], "id": 4499}, {"sent": "in addition , we use batch normalization to accelerate the training stage .", "tokens": ["in", "addition", ",", "we", "use", "batch", "normalization", "to", "accelerate", "the", "training", "stage", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "use", "start": 17, "end": 20, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "use", "start": 17, "end": 20, "i_start": 4, "i_end": 4}}, {"character": {"text": "normalization", "start": 27, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "accelerate", "start": 44, "end": 54, "i_start": 8, "i_end": 8}}], "id": 4500}, {"sent": "cloaking via change of variables was introduced by greenleaf , lassas , uhlmann in the geometric optics setting .", "tokens": ["cloaking", "via", "change", "of", "variables", "was", "introduced", "by", "greenleaf", ",", "lassas", ",", "uhlmann", "in", "the", "geometric", "optics", "setting", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cloaking via change of variables", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "was introduced", "start": 33, "end": 47, "i_start": 5, "i_end": 6}}, {"character": {"text": "greenleaf", "start": 51, "end": 60, "i_start": 8, "i_end": 8}, "action": {"text": "introduced", "start": 37, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "lassas", "start": 63, "end": 69, "i_start": 10, "i_end": 10}, "action": {"text": "introduced", "start": 37, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "uhlmann", "start": 72, "end": 79, "i_start": 12, "i_end": 12}, "action": {"text": "introduced", "start": 37, "end": 47, "i_start": 6, "i_end": 6}}], "id": 4501}, {"sent": "where the tilde denotes a reversed film , which corresponds to interchange of the diagonal elements of transfer matrix .", "tokens": ["where", "the", "tilde", "denotes", "a", "reversed", "film", ",", "which", "corresponds", "to", "interchange", "of", "the", "diagonal", "elements", "of", "transfer", "matrix", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the tilde", "start": 6, "end": 15, "i_start": 1, "i_end": 2}, "verb": {"text": "denotes", "start": 16, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "tilde", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "denotes", "start": 16, "end": 23, "i_start": 3, "i_end": 3}}], "id": 4502}, {"sent": "so , as in , \u03c6can be isotoped across the curves bi , j in b without affecting the isotopy class of s in n .", "tokens": ["so", ",", "as", "in", ",", "\u03c6can", "be", "isotoped", "across", "the", "curves", "b"], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "\u03c6can", "start": 13, "end": 17, "i_start": 5, "i_end": 5}, "verb": {"text": "be isotoped", "start": 18, "end": 29, "i_start": 6, "i_end": 7}}], "id": 4503}, {"sent": "visibility is the probability of detecting a vortex over several shots .", "tokens": ["visibility", "is", "the", "probability", "of", "detecting", "a", "vortex", "over", "several", "shots", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "visibility", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 1, "i_end": 1}}], "id": 4504}, {"sent": "recent successes of deep neural networks have spanned many domains , from computer vision and many other tasks .", "tokens": ["recent", "successes", "of", "deep", "neural", "networks", "have", "spanned", "many", "domains", ",", "from", "computer", "vision", "and", "many", "other", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent successes of deep neural networks", "start": 0, "end": 40, "i_start": 0, "i_end": 5}, "verb": {"text": "have spanned", "start": 41, "end": 53, "i_start": 6, "i_end": 7}}, {"character": {"text": "successes", "start": 7, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "spanned", "start": 46, "end": 53, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "successes", "start": 7, "end": 16, "i_start": 1, "i_end": 1}}], "id": 4505}, {"sent": "micro-algae growth in a photobioreactor is often modelled through one of two models , the monod model .", "tokens": ["micro", "-", "algae", "growth", "in", "a", "photobioreactor", "is", "often", "modelled", "through", "one", "of", "two", "models", ",", "the", "monod", "model", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "micro-algae growth in a photobioreactor is often modelled through one of two models , the monod model", "start": 0, "end": 101, "i_start": 0, "i_end": 18}, "verb": {"text": "modelled", "start": 49, "end": 57, "i_start": 9, "i_end": 9}}, {"subject": {"text": "micro-algae growth in a photobioreactor is often modelled through one of two models , the monod model", "start": 0, "end": 101, "i_start": 0, "i_end": 18}, "verb": {"text": "is", "start": 40, "end": 42, "i_start": 7, "i_end": 7}}], "id": 4506}, {"sent": "several materials hosting both nontrivial band topology and superconductivity have been discovered and synthesized experimentally .", "tokens": ["several", "materials", "hosting", "both", "nontrivial", "band", "topology", "and", "superconductivity", "have", "been", "discovered", "and", "synthesized", "experimentally", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "several materials hosting both nontrivial band topology and superconductivity", "start": 0, "end": 77, "i_start": 0, "i_end": 8}, "verb": {"text": "have been discovered", "start": 78, "end": 98, "i_start": 9, "i_end": 11}}, {"subject": {"text": "several materials hosting both nontrivial band topology and superconductivity", "start": 0, "end": 77, "i_start": 0, "i_end": 8}, "verb": {"text": "synthesized", "start": 103, "end": 114, "i_start": 13, "i_end": 13}}, {"character": {"text": "materials", "start": 8, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "hosting", "start": 18, "end": 25, "i_start": 2, "i_end": 2}}], "id": 4507}, {"sent": "printout the most suitable printer is a laser printer .", "tokens": ["printout", "the", "most", "suitable", "printer", "is", "a", "laser", "printer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "printout the most suitable printer", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 5, "i_end": 5}}], "id": 4508}, {"sent": "for more information on the blow-up criteria of compressible flows , we refer to and the references therein .", "tokens": ["for", "more", "information", "on", "the", "blow", "-", "up", "criteria", "of", "compressible", "flows", ",", "we", "refer", "to", "and", "the", "references", "therein", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 69, "end": 71, "i_start": 13, "i_end": 13}, "verb": {"text": "refer", "start": 72, "end": 77, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 69, "end": 71, "i_start": 13, "i_end": 13}, "action": {"text": "refer", "start": 72, "end": 77, "i_start": 14, "i_end": 14}}], "id": 4509}, {"sent": "here interior means the complement of the toric divisors .", "tokens": ["here", "interior", "means", "the", "complement", "of", "the", "toric", "divisors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "interior", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "verb": {"text": "means", "start": 14, "end": 19, "i_start": 2, "i_end": 2}}], "id": 4510}, {"sent": "goodfellow et al proposed generative adversarial networks that contain a generative model and discriminative model .", "tokens": ["goodfellow", "et", "al", "proposed", "generative", "adversarial", "networks", "that", "contain", "a", "generative", "model", "and", "discriminative", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "goodfellow", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 49, "end": 57, "i_start": 6, "i_end": 6}, "action": {"text": "contain", "start": 63, "end": 70, "i_start": 8, "i_end": 8}}, {"character": {"text": "model", "start": 109, "end": 114, "i_start": 14, "i_end": 14}, "action": {"text": "discriminative", "start": 94, "end": 108, "i_start": 13, "i_end": 13}}], "id": 4511}, {"sent": "our goal is to establish lower bounds on the maximum of the ratio of the minimum energy required by routing and network coding solutions , where the maximum is over all configurations .", "tokens": ["our", "goal", "is", "to", "establish", "lower", "bounds", "on", "the", "maximum", "of", "the", "ratio", "of", "the", "minimum", "energy", "required", "by", "routing", "and", "network", "coding", "solutions", ",", "where", "the", "maximum", "is", "over", "all", "configurations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our goal", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 2, "i_end": 2}}], "id": 4512}, {"sent": "we develop the inference based on the expectation-maximization algorithm , which also allows us to handle missing data .", "tokens": ["we", "develop", "the", "inference", "based", "on", "the", "expectation", "-", "maximization", "algorithm", ",", "which", "also", "allows", "us", "to", "handle", "missing", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "develop", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "develop", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "algorithm", "start": 63, "end": 72, "i_start": 10, "i_end": 10}, "action": {"text": "allows", "start": 86, "end": 92, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "handle", "start": 99, "end": 105, "i_start": 17, "i_end": 17}}], "id": 4513}, {"sent": "we obtain an analytical expression for the baryon binding energy .", "tokens": ["we", "obtain", "an", "analytical", "expression", "for", "the", "baryon", "binding", "energy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "obtain", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "obtain", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "energy", "start": 58, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "binding", "start": 50, "end": 57, "i_start": 8, "i_end": 8}}], "id": 4514}, {"sent": "this shell is a circle , it contributes to 1 generator .", "tokens": ["this", "shell", "is", "a", "circle", ",", "it", "contributes", "to", "1", "generator", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 25, "end": 27, "i_start": 6, "i_end": 6}, "verb": {"text": "contributes", "start": 28, "end": 39, "i_start": 7, "i_end": 7}}, {"subject": {"text": "it", "start": 25, "end": 27, "i_start": 6, "i_end": 6}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "shell", "start": 5, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "contributes", "start": 28, "end": 39, "i_start": 7, "i_end": 7}}], "id": 4515}, {"sent": "in recent years , many models based on convolutional neural networks have been proposed and used for various computer vision tasks such as image classification .", "tokens": ["in", "recent", "years", ",", "many", "models", "based", "on", "convolutional", "neural", "networks", "have", "been", "proposed", "and", "used", "for", "various", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many models based on convolutional neural networks", "start": 18, "end": 68, "i_start": 4, "i_end": 10}, "verb": {"text": "have been proposed", "start": 69, "end": 87, "i_start": 11, "i_end": 13}}, {"subject": {"text": "many models based on convolutional neural networks", "start": 18, "end": 68, "i_start": 4, "i_end": 10}, "verb": {"text": "used", "start": 92, "end": 96, "i_start": 15, "i_end": 15}}], "id": 4516}, {"sent": "there has been a huge amount of research on graph partitioning so that we refer the reader to for most of the material .", "tokens": ["there", "has", "been", "a", "huge", "amount", "of", "research", "on", "graph", "partitioning", "so", "that", "we", "refer", "the", "reader", "to", "for", "most", "of", "the", "material", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "has been", "start": 6, "end": 14, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 71, "end": 73, "i_start": 13, "i_end": 13}, "action": {"text": "refer", "start": 74, "end": 79, "i_start": 14, "i_end": 14}}], "id": 4517}, {"sent": "we also estimated the energy release rates based on the magnetic reconnection model .", "tokens": ["we", "also", "estimated", "the", "energy", "release", "rates", "based", "on", "the", "magnetic", "reconnection", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "estimated", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "estimated", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}], "id": 4518}, {"sent": "the markov blanket of a variable of interest t , denoted as b , is the minimal set of variables conditioned on which all other variables in the model are probabilistically independent of the target t .", "tokens": ["the", "markov", "blanket", "of", "a", "variable", "of", "interest", "t", ",", "denoted", "as", "b", ",", "is", "the", "minimal", "set", "of", "variables", "conditioned", "on", "which", "all", "other", "variables", "in", "the", "model", "are", "probabilistically", "independent", "of", "the", "target", "t", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the markov blanket of a variable of interest t", "start": 0, "end": 46, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 64, "end": 66, "i_start": 14, "i_end": 14}}, {"character": {"text": "variables", "start": 86, "end": 95, "i_start": 19, "i_end": 19}, "action": {"text": "independent", "start": 172, "end": 183, "i_start": 31, "i_end": 31}}], "id": 4519}, {"sent": "the lightest neutralino , if it is the lsp , is the plausible candidate for the cdm .", "tokens": ["the", "lightest", "neutralino", ",", "if", "it", "is", "the", "lsp", ",", "is", "the", "plausible", "candidate", "for", "the", "cdm", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the lightest neutralino", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 45, "end": 47, "i_start": 10, "i_end": 10}}], "id": 4520}, {"sent": "applications range from statistics on the optimal trajectories in the context of traveling salesman problem on a random set of cities , and going to partial self-avoiding deterministic tourist walk .", "tokens": ["applications", "range", "from", "statistics", "on", "the", "optimal", "trajectories", "in", "the", "context", "of", "traveling", "salesman", "problem", "on", "a", "random", "set", "of", "cities", ",", "and", "going", "to", "partial", "self", "-", "avoiding", "deterministic", "tourist", "walk", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "applications", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "range", "start": 13, "end": 18, "i_start": 1, "i_end": 1}}, {"subject": {"text": "applications", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "going", "start": 140, "end": 145, "i_start": 23, "i_end": 23}}, {"character": {"text": "walk", "start": 193, "end": 197, "i_start": 31, "i_end": 31}, "action": {"text": "avoiding", "start": 162, "end": 170, "i_start": 28, "i_end": 28}}], "id": 4521}, {"sent": "remarkably , these non-standard solitons result from the same dual wrapping rule that leads to the standard solitons .", "tokens": ["remarkably", ",", "these", "non", "-", "standard", "solitons", "result", "from", "the", "same", "dual", "wrapping", "rule", "that", "leads", "to", "the", "standard", "solitons", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these non-standard solitons", "start": 13, "end": 40, "i_start": 2, "i_end": 6}, "verb": {"text": "result", "start": 41, "end": 47, "i_start": 7, "i_end": 7}}, {"character": {"text": "rule", "start": 76, "end": 80, "i_start": 13, "i_end": 13}, "action": {"text": "leads", "start": 86, "end": 91, "i_start": 15, "i_end": 15}}], "id": 4522}, {"sent": "in recent years , convolutional neural networks are driving advances in computer vision , such as image classification .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "are", "driving", "advances", "in", "computer", "vision", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "are driving", "start": 48, "end": 59, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "driving", "start": 52, "end": 59, "i_start": 8, "i_end": 8}}], "id": 4523}, {"sent": "therefore , we can regard the contributions of the non-planar diagrams in the supermatrix model as that of these fields .", "tokens": ["therefore", ",", "we", "can", "regard", "the", "contributions", "of", "the", "non", "-", "planar", "diagrams", "in", "the", "supermatrix", "model", "as", "that", "of", "these", "fields", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "verb": {"text": "can regard", "start": 15, "end": 25, "i_start": 3, "i_end": 4}}, {"character": {"text": "we", "start": 12, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "regard", "start": 19, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "diagrams", "start": 62, "end": 70, "i_start": 12, "i_end": 12}, "action": {"text": "contributions", "start": 30, "end": 43, "i_start": 6, "i_end": 6}}], "id": 4524}, {"sent": "it has a simple architecture inspired by the vgg network , consisting of 17 convolutional layers .", "tokens": ["it", "has", "a", "simple", "architecture", "inspired", "by", "the", "vgg", "network", ",", "consisting", "of", "17", "convolutional", "layers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "has", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "network", "start": 49, "end": 56, "i_start": 9, "i_end": 9}, "action": {"text": "inspired", "start": 29, "end": 37, "i_start": 5, "i_end": 5}}], "id": 4525}, {"sent": "in turn , the knowledge of these nichols algebras is important for example for the lifting method of andruskiewitsch and schneider to classify pointed hopf algebras .", "tokens": ["in", "turn", ",", "the", "knowledge", "of", "these", "nichols", "algebras", "is", "important", "for", "example", "for", "the", "lifting", "method", "of", "andruskiewitsch", "and", "schneider", "to", "classify", "pointed", "hopf", "algebras", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the knowledge of these nichols algebras", "start": 10, "end": 49, "i_start": 3, "i_end": 8}, "verb": {"text": "is", "start": 50, "end": 52, "i_start": 9, "i_end": 9}}, {"character": {"text": "method", "start": 91, "end": 97, "i_start": 16, "i_end": 16}, "action": {"text": "classify", "start": 134, "end": 142, "i_start": 22, "i_end": 22}}], "id": 4526}, {"sent": "the functor dmb is an equivalence of triangulated monoidal categories .", "tokens": ["the", "functor", "dmb", "is", "an", "equivalence", "of", "triangulated", "monoidal", "categories", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the functor dmb", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 4527}, {"sent": "the property of entanglement lies at the heart of quantum information processing and quantum mechanics in general .", "tokens": ["the", "property", "of", "entanglement", "lies", "at", "the", "heart", "of", "quantum", "information", "processing", "and", "quantum", "mechanics", "in", "general", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4528}, {"sent": "with rgb images viola and jones face detector is often exploited , eg .", "tokens": ["with", "rgb", "images", "viola", "and", "jones", "face", "detector", "is", "often", "exploited", ",", "eg", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "rgb images viola and jones face detector", "start": 5, "end": 45, "i_start": 1, "i_end": 7}, "verb": {"text": "exploited", "start": 55, "end": 64, "i_start": 10, "i_end": 10}}, {"subject": {"text": "rgb images viola and jones face detector", "start": 5, "end": 45, "i_start": 1, "i_end": 7}, "verb": {"text": "is", "start": 46, "end": 48, "i_start": 8, "i_end": 8}}], "id": 4529}, {"sent": "to learn the true data distribution p data in a nonparametric way , goodfellow et al proposed the generative adversarial network .", "tokens": ["to", "learn", "the", "true", "data", "distribution", "p", "data", "in", "a", "nonparametric", "way", ",", "goodfellow", "et", "al", "proposed", "the", "generative", "adversarial", "network", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 68, "end": 84, "i_start": 13, "i_end": 15}, "verb": {"text": "proposed", "start": 85, "end": 93, "i_start": 16, "i_end": 16}}, {"character": {"text": "goodfellow", "start": 68, "end": 78, "i_start": 13, "i_end": 13}, "action": {"text": "proposed", "start": 85, "end": 93, "i_start": 16, "i_end": 16}}, {"character": {"text": "goodfellow", "start": 68, "end": 78, "i_start": 13, "i_end": 13}, "action": {"text": "learn", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 4530}, {"sent": "qdi asynchronous circuits are generally categorized as strong-indication types .", "tokens": ["qdi", "asynchronous", "circuits", "are", "generally", "categorized", "as", "strong", "-", "indication", "types", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "qdi asynchronous circuits", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "categorized", "start": 40, "end": 51, "i_start": 5, "i_end": 5}}, {"subject": {"text": "qdi asynchronous circuits", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 26, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "types", "start": 73, "end": 78, "i_start": 10, "i_end": 10}, "action": {"text": "indication", "start": 62, "end": 72, "i_start": 9, "i_end": 9}}], "id": 4531}, {"sent": "using the more advanced permutation blocking pimc and configuration pimc methods is not yet possible .", "tokens": ["using", "the", "more", "advanced", "permutation", "blocking", "pimc", "and", "configuration", "pimc", "methods", "is", "not", "yet", "possible", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "using the more advanced permutation blocking pimc and configuration pimc methods", "start": 0, "end": 80, "i_start": 0, "i_end": 10}, "verb": {"text": "is not", "start": 81, "end": 87, "i_start": 11, "i_end": 12}}, {"character": {"text": "methods", "start": 73, "end": 80, "i_start": 10, "i_end": 10}, "action": {"text": "blocking", "start": 36, "end": 44, "i_start": 5, "i_end": 5}}], "id": 4532}, {"sent": "in \u03b3\u03b3 interactions both photons are vmd-like .", "tokens": ["in", "\u03b3\u03b3", "interactions", "both", "photons", "are", "vmd", "-", "like", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "both photons", "start": 19, "end": 31, "i_start": 3, "i_end": 4}, "verb": {"text": "are", "start": 32, "end": 35, "i_start": 5, "i_end": 5}}], "id": 4533}, {"sent": "by continuity , the invariant disk can not move from the upper to the lower half plane .", "tokens": ["by", "continuity", ",", "the", "invariant", "disk", "can", "not", "move", "from", "the", "upper", "to", "the", "lower", "half", "plane", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the invariant disk", "start": 16, "end": 34, "i_start": 3, "i_end": 5}, "verb": {"text": "can not move", "start": 35, "end": 47, "i_start": 6, "i_end": 8}}], "id": 4534}, {"sent": "it has also been proved for certain special classes of graphs , including powers of cycles and their complements .", "tokens": ["it", "has", "also", "been", "proved", "for", "certain", "special", "classes", "of", "graphs", ",", "including", "powers", "of", "cycles", "and", "their", "complements", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "been proved", "start": 12, "end": 23, "i_start": 3, "i_end": 4}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 4535}, {"sent": "cluster algebras were introduced by fomin and zelevinsky in in the context of canonical bases and total positivity .", "tokens": ["cluster", "algebras", "were", "introduced", "by", "fomin", "and", "zelevinsky", "in", "in", "the", "context", "of", "canonical", "bases", "and", "total", "positivity", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "cluster algebras", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were introduced", "start": 17, "end": 32, "i_start": 2, "i_end": 3}}, {"character": {"text": "fomin", "start": 36, "end": 41, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "zelevinsky", "start": 46, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "introduced", "start": 22, "end": 32, "i_start": 3, "i_end": 3}}], "id": 4536}, {"sent": "the flux in different parts of the profiles , are well correlated with each other , and with the continuum flux as well .", "tokens": ["the", "flux", "in", "different", "parts", "of", "the", "profiles", ",", "are", "well", "correlated", "with", "each", "other", ",", "and", "with", "the", "continuum", "flux", "as", "well", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the flux in different parts of the profiles", "start": 0, "end": 43, "i_start": 0, "i_end": 7}, "verb": {"text": "correlated", "start": 55, "end": 65, "i_start": 11, "i_end": 11}}, {"subject": {"text": "the flux in different parts of the profiles", "start": 0, "end": 43, "i_start": 0, "i_end": 7}, "verb": {"text": "are", "start": 46, "end": 49, "i_start": 9, "i_end": 9}}], "id": 4537}, {"sent": "deep learning has led to significant improvements in many computer vision tasks such as image classification .", "tokens": ["deep", "learning", "has", "led", "to", "significant", "improvements", "in", "many", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has led", "start": 14, "end": 21, "i_start": 2, "i_end": 3}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 18, "end": 21, "i_start": 3, "i_end": 3}}], "id": 4538}, {"sent": "deep neural networks are the basis for some of the most accurate speech recognition systems in research and production .", "tokens": ["deep", "neural", "networks", "are", "the", "basis", "for", "some", "of", "the", "most", "accurate", "speech", "recognition", "systems", "in", "research", "and", "production", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "systems", "start": 84, "end": 91, "i_start": 14, "i_end": 14}, "action": {"text": "recognition", "start": 72, "end": 83, "i_start": 13, "i_end": 13}}], "id": 4539}, {"sent": "fomin and zelevinsky proved that the cluster algebras of finite type are parametrized by the finite root systems .", "tokens": ["fomin", "and", "zelevinsky", "proved", "that", "the", "cluster", "algebras", "of", "finite", "type", "are", "parametrized", "by", "the", "finite", "root", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "fomin and zelevinsky", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "proved", "start": 21, "end": 27, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the cluster algebras of finite type", "start": 33, "end": 68, "i_start": 5, "i_end": 10}, "verb": {"text": "parametrized", "start": 73, "end": 85, "i_start": 12, "i_end": 12}}, {"character": {"text": "fomin", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proved", "start": 21, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "zelevinsky", "start": 10, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "proved", "start": 21, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "systems", "start": 105, "end": 112, "i_start": 17, "i_end": 17}, "action": {"text": "parametrized", "start": 73, "end": 85, "i_start": 12, "i_end": 12}}], "id": 4540}, {"sent": "a perturbation based approach was proposed by agrawal and srikant which built a decision-tree classifier from training data .", "tokens": ["a", "perturbation", "based", "approach", "was", "proposed", "by", "agrawal", "and", "srikant", "which", "built", "a", "decision", "-", "tree", "classifier", "from", "training", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a perturbation based approach", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "was proposed", "start": 30, "end": 42, "i_start": 4, "i_end": 5}}, {"character": {"text": "agrawal", "start": 46, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "proposed", "start": 34, "end": 42, "i_start": 5, "i_end": 5}}, {"character": {"text": "srikant", "start": 58, "end": 65, "i_start": 9, "i_end": 9}, "action": {"text": "proposed", "start": 34, "end": 42, "i_start": 5, "i_end": 5}}, {"character": {"text": "approach", "start": 21, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "built", "start": 72, "end": 77, "i_start": 11, "i_end": 11}}], "id": 4541}, {"sent": "we refer to for the definition of g-convergence and more details of the homogenization problems .", "tokens": ["we", "refer", "to", "for", "the", "definition", "of", "g", "-", "convergence", "and", "more", "details", "of", "the", "homogenization", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 4542}, {"sent": "every finite dimensional a-module is completely reducible .", "tokens": ["every", "finite", "dimensional", "a", "-", "module", "is", "completely", "reducible", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "every finite dimensional a-module", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 6, "i_end": 6}}], "id": 4543}, {"sent": "virtual knot theory was introduced by kauffman and can be viewed as a generalization of the classical study of embeddings of circles into r 3 .", "tokens": ["virtual", "knot", "theory", "was", "introduced", "by", "kauffman", "and", "can", "be", "viewed", "as", "a", "generalization", "of", "the", "classical", "study", "of", "embeddings", "of", "circles", "into", "r", "3", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "virtual knot theory", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "was introduced", "start": 20, "end": 34, "i_start": 3, "i_end": 4}}, {"subject": {"text": "virtual knot theory", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "viewed", "start": 58, "end": 64, "i_start": 10, "i_end": 10}}, {"character": {"text": "kauffman", "start": 38, "end": 46, "i_start": 6, "i_end": 6}, "action": {"text": "introduced", "start": 24, "end": 34, "i_start": 4, "i_end": 4}}], "id": 4544}, {"sent": "the achievable scheme that we present here is based on , but we further allow a common message at both relaying nodes .", "tokens": ["the", "achievable", "scheme", "that", "we", "present", "here", "is", "based", "on", ",", "but", "we", "further", "allow", "a", "common", "message", "at", "both", "relaying", "nodes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the achievable scheme that we present here", "start": 0, "end": 42, "i_start": 0, "i_end": 6}, "verb": {"text": "is based", "start": 43, "end": 51, "i_start": 7, "i_end": 8}}, {"subject": {"text": "we", "start": 61, "end": 63, "i_start": 12, "i_end": 12}, "verb": {"text": "allow", "start": 72, "end": 77, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 27, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "present", "start": 30, "end": 37, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 27, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "allow", "start": 72, "end": 77, "i_start": 14, "i_end": 14}}, {"character": {"text": "nodes", "start": 112, "end": 117, "i_start": 21, "i_end": 21}, "action": {"text": "relaying", "start": 103, "end": 111, "i_start": 20, "i_end": 20}}], "id": 4545}, {"sent": "a nucleon is a common name for both neutrons and protons , emphasizing the approximated symmetry of their response to the strong force , and their similar mass .", "tokens": ["a", "nucleon", "is", "a", "common", "name", "for", "both", "neutrons", "and", "protons", ",", "emphasizing", "the", "approximated", "symmetry", "of", "their", "response", "to", "the", "strong", "force", ",", "and", "their", "similar", "mass", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a nucleon", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "name", "start": 22, "end": 26, "i_start": 5, "i_end": 5}, "action": {"text": "emphasizing", "start": 59, "end": 70, "i_start": 12, "i_end": 12}}, {"character": {"text": "nucleon", "start": 2, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "response", "start": 106, "end": 114, "i_start": 18, "i_end": 18}}], "id": 4546}, {"sent": "deep convolutional neural networks have recently shown immense success for various image recognition tasks , such as object recognition .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "recently", "shown", "immense", "success", "for", "various", "image", "recognition", "tasks", ",", "such", "as", "object", "recognition", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "shown", "start": 49, "end": 54, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 63, "end": 70, "i_start": 8, "i_end": 8}}], "id": 4547}, {"sent": "the filters on the collimator were used to control the light intensity .", "tokens": ["the", "filters", "on", "the", "collimator", "were", "used", "to", "control", "the", "light", "intensity", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the filters on the collimator", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "were used", "start": 30, "end": 39, "i_start": 5, "i_end": 6}}, {"character": {"text": "filters", "start": 4, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "control", "start": 43, "end": 50, "i_start": 8, "i_end": 8}}], "id": 4548}, {"sent": "we would also like to extend gratitude to kamal barley for his graphic enhancements and to ben morin for the personalized lectures .", "tokens": ["we", "would", "also", "like", "to", "extend", "gratitude", "to", "kamal", "barley", "for", "his", "graphic", "enhancements", "and", "to", "ben", "morin", "for", "the", "personalized", "lectures", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "like", "start": 14, "end": 18, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "would", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "like", "start": 14, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extend", "start": 22, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "kamal barley", "start": 42, "end": 54, "i_start": 8, "i_end": 9}, "action": {"text": "enhancements", "start": 71, "end": 83, "i_start": 13, "i_end": 13}}, {"character": {"text": "ben morin", "start": 91, "end": 100, "i_start": 16, "i_end": 17}, "action": {"text": "lectures", "start": 122, "end": 130, "i_start": 21, "i_end": 21}}], "id": 4549}, {"sent": "the property of compositionality was a main motivation for hierarchical models of visual cortex such as hmax which can be regarded as a pyramid of and and or layers , that is a sequence of conjunctions and disjunctions .", "tokens": ["the", "property", "of", "compositionality", "was", "a", "main", "motivation", "for", "hierarchical", "models", "of", "visual", "cortex", "such", "as", "hmax", "which", "can", "be", "regarded", "as", "a", "pyramid", "of", "and", "and", "or", "layers", ",", "that", "is", "a", "sequence", "of", "conjunctions", "and", "disjunctions", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "that", "start": 167, "end": 171, "i_start": 30, "i_end": 30}, "verb": {"text": "is", "start": 172, "end": 174, "i_start": 31, "i_end": 31}}, {"subject": {"text": "that", "start": 167, "end": 171, "i_start": 30, "i_end": 30}, "verb": {"text": "was", "start": 33, "end": 36, "i_start": 4, "i_end": 4}}, {"character": {"text": "property", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "motivation", "start": 44, "end": 54, "i_start": 7, "i_end": 7}}], "id": 4550}, {"sent": "by compactness of t , there is a lower bound t .", "tokens": ["by", "compactness", "of", "t", ",", "there", "is", "a", "lower", "bound", "t", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 22, "end": 27, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 6, "i_end": 6}}], "id": 4551}, {"sent": "improved approximation algorithms for the uncapacitated facility location problem .", "tokens": ["improved", "approximation", "algorithms", "for", "the", "uncapacitated", "facility", "location", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4552}, {"sent": "since this coefficient is a short distance property , we may work directly at the critical point .", "tokens": ["since", "this", "coefficient", "is", "a", "short", "distance", "property", ",", "we", "may", "work", "directly", "at", "the", "critical", "point", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 54, "end": 56, "i_start": 9, "i_end": 9}, "verb": {"text": "may work", "start": 57, "end": 65, "i_start": 10, "i_end": 11}}, {"character": {"text": "we", "start": 54, "end": 56, "i_start": 9, "i_end": 9}, "action": {"text": "work", "start": 61, "end": 65, "i_start": 11, "i_end": 11}}], "id": 4553}, {"sent": "backpressure based algorithms may not provide good delay performance , especially in lightly loaded conditions .", "tokens": ["backpressure", "based", "algorithms", "may", "not", "provide", "good", "delay", "performance", ",", "especially", "in", "lightly", "loaded", "conditions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "backpressure based algorithms", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "may not provide", "start": 30, "end": 45, "i_start": 3, "i_end": 5}}, {"character": {"text": "algorithms", "start": 19, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "not provide", "start": 34, "end": 45, "i_start": 4, "i_end": 5}}], "id": 4554}, {"sent": "however it is more plausible to say that there is a small range in parameter space where the lc is not unique .", "tokens": ["however", "it", "is", "more", "plausible", "to", "say", "that", "there", "is", "a", "small", "range", "in", "parameter", "space", "where", "the", "lc", "is", "not", "unique", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}], "id": 4555}, {"sent": "in the following section when we will understand better .", "tokens": ["in", "the", "following", "section", "when", "we", "will", "understand", "better", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 30, "end": 32, "i_start": 5, "i_end": 5}, "action": {"text": "understand", "start": 38, "end": 48, "i_start": 7, "i_end": 7}}], "id": 4556}, {"sent": "convolutional neural networks have achieved superior performance in many visual tasks , such as object classification and detection .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "superior", "performance", "in", "many", "visual", "tasks", ",", "such", "as", "object", "classification", "and", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 6, "i_end": 6}}], "id": 4557}, {"sent": "in lower abscissa , the logarithm of the pulsar mass over the sun mass is shown .", "tokens": ["in", "lower", "abscissa", ",", "the", "logarithm", "of", "the", "pulsar", "mass", "over", "the", "sun", "mass", "is", "shown", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the logarithm of the pulsar mass over the sun mass", "start": 20, "end": 70, "i_start": 4, "i_end": 13}, "verb": {"text": "is shown", "start": 71, "end": 79, "i_start": 14, "i_end": 15}}], "id": 4558}, {"sent": "in addition , we explore the potential of photonic structures based on aperiodic order for the engineering of radiative rates and emission patterns in erbium-doped silicon-rich nitride photonic structures .", "tokens": ["in", "addition", ",", "we", "explore", "the", "potential", "of", "photonic", "structures", "based", "on", "aperiodic", "order", "for", "the", "engineering", "of", "radiative", "rates", "and", "emission", "patterns", "in", "erbium", "-", "doped", "silicon", "-", "rich", "nitride", "photonic", "structures", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "verb": {"text": "explore", "start": 17, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "explore", "start": 17, "end": 24, "i_start": 4, "i_end": 4}}], "id": 4559}, {"sent": "rapid developments in advanced machine learning , especially in the area of deep learning techniques-such as deep cnns-has increased the use of these techniques in a wide range of computer vision research areas .", "tokens": ["rapid", "developments", "in", "advanced", "machine", "learning", ",", "especially", "in", "the", "area", "of", "deep", "learning", "techniques", "-", "such", "as", "deep", "cnns", "-", "has", "increased", "the", "use", "of", "these", "techniques", "in", "a", "wide", "range", "of", "computer", "vision", "research", "areas", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "rapid developments in advanced machine learning", "start": 0, "end": 47, "i_start": 0, "i_end": 5}, "verb": {"text": "has increased", "start": 119, "end": 132, "i_start": 21, "i_end": 22}}, {"character": {"text": "developments", "start": 6, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "increased", "start": 123, "end": 132, "i_start": 22, "i_end": 22}}], "id": 4560}, {"sent": "thus 1 spacetime only consists of elements of language constrained by quantum theory .", "tokens": ["thus", "1", "spacetime", "only", "consists", "of", "elements", "of", "language", "constrained", "by", "quantum", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "1 spacetime", "start": 5, "end": 16, "i_start": 1, "i_end": 2}, "verb": {"text": "consists", "start": 22, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "theory", "start": 78, "end": 84, "i_start": 12, "i_end": 12}, "action": {"text": "constrained", "start": 55, "end": 66, "i_start": 9, "i_end": 9}}], "id": 4561}, {"sent": "for the generation of the scale-free network , we implement the standard growth and preferential attachment algorithm .", "tokens": ["for", "the", "generation", "of", "the", "scale", "-", "free", "network", ",", "we", "implement", "the", "standard", "growth", "and", "preferential", "attachment", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 47, "end": 49, "i_start": 10, "i_end": 10}, "verb": {"text": "implement", "start": 50, "end": 59, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 47, "end": 49, "i_start": 10, "i_end": 10}, "action": {"text": "implement", "start": 50, "end": 59, "i_start": 11, "i_end": 11}}], "id": 4562}, {"sent": "finally , we compare our rds network with other state-of-the-art methods on five public sod datasets , hku-is .", "tokens": ["finally", ",", "we", "compare", "our", "rds", "network", "with", "other", "state", "-", "of", "-", "the", "-", "art", "methods", "on", "five", "public", "sod", "datasets", ",", "hku", "-", "is", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "hku", "start": 103, "end": 106, "i_start": 23, "i_end": 23}, "verb": {"text": "is", "start": 107, "end": 109, "i_start": 25, "i_end": 25}}, {"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "compare", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "compare", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}], "id": 4563}, {"sent": "we trained 5-gram language models with kneser-ney smoothing using kenlm .", "tokens": ["we", "trained", "5", "-", "gram", "language", "models", "with", "kneser", "-", "ney", "smoothing", "using", "kenlm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "trained", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "trained", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 4564}, {"sent": "thus the surjectivity is a lifting problem .", "tokens": ["thus", "the", "surjectivity", "is", "a", "lifting", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the surjectivity", "start": 5, "end": 21, "i_start": 1, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 4565}, {"sent": "a grothendieck-riemann-roch formula for maps of complex manifolds .", "tokens": ["a", "grothendieck", "-", "riemann", "-", "roch", "formula", "for", "maps", "of", "complex", "manifolds", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4566}, {"sent": "the calorimeter is a mineral oil based scintillator segmented 4 into 512 independent modules .", "tokens": ["the", "calorimeter", "is", "a", "mineral", "oil", "based", "scintillator", "segmented", "4", "into", "512", "independent", "modules", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the calorimeter", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "512", "start": 69, "end": 72, "i_start": 11, "i_end": 11}, "action": {"text": "independent", "start": 73, "end": 84, "i_start": 12, "i_end": 12}}], "id": 4567}, {"sent": "one potential approach is measurement-based quantum computation , where universal quantum computation is achieved by means of non-entangling operations on an already entangled resource state .", "tokens": ["one", "potential", "approach", "is", "measurement", "-", "based", "quantum", "computation", ",", "where", "universal", "quantum", "computation", "is", "achieved", "by", "means", "of", "non", "-", "entangling", "operations", "on", "an", "already", "entangled", "resource", "state", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one potential approach", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 3, "i_end": 3}}], "id": 4568}, {"sent": "deep neural networks have significantly improved the performance of diverse data mining and computer vision applications .", "tokens": ["deep", "neural", "networks", "have", "significantly", "improved", "the", "performance", "of", "diverse", "data", "mining", "and", "computer", "vision", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "applications", "start": 108, "end": 120, "i_start": 15, "i_end": 15}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 7, "i_end": 7}}, {"character": {"text": "diverse", "start": 68, "end": 75, "i_start": 9, "i_end": 9}, "action": {"text": "performance", "start": 53, "end": 64, "i_start": 7, "i_end": 7}}], "id": 4569}, {"sent": "such central charges are a common occurrence in surface symmetry algebras that include surface translations .", "tokens": ["such", "central", "charges", "are", "a", "common", "occurrence", "in", "surface", "symmetry", "algebras", "that", "include", "surface", "translations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such central charges", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}], "id": 4570}, {"sent": "however , for most of the molecular species in the network , little knowledge , if any , could be deduced about their regulatory mechanisms , for instance in the gene transcription networks in yeast and e .", "tokens": ["however", ",", "for", "most", "of", "the", "molecular", "species", "in", "the", "network", ",", "little", "knowledge", ",", "if", "any", ",", "could", "be", "deduced", "about", "their", "regulatory", "mechanisms", ",", "for", "instance", "in", "the", "gene", "transcription", "networks", "in", "yeast", "and", "e", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "little knowledge , if any", "start": 61, "end": 86, "i_start": 12, "i_end": 16}, "verb": {"text": "could be deduced", "start": 89, "end": 105, "i_start": 18, "i_end": 20}}, {"character": {"text": "mechanisms", "start": 129, "end": 139, "i_start": 24, "i_end": 24}, "action": {"text": "regulatory", "start": 118, "end": 128, "i_start": 23, "i_end": 23}}], "id": 4571}, {"sent": "in order to automatically learn the alignments between speech frames and label sequences , the connectionist temporal classification objective was adopted .", "tokens": ["in", "order", "to", "automatically", "learn", "the", "alignments", "between", "speech", "frames", "and", "label", "sequences", ",", "the", "connectionist", "temporal", "classification", "objective", "was", "adopted", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the connectionist temporal classification objective", "start": 91, "end": 142, "i_start": 14, "i_end": 18}, "verb": {"text": "was adopted", "start": 143, "end": 154, "i_start": 19, "i_end": 20}}], "id": 4572}, {"sent": "the instrumented detector volume is a cubic kilometer of dark , transparent and sterile antarctic ice .", "tokens": ["the", "instrumented", "detector", "volume", "is", "a", "cubic", "kilometer", "of", "dark", ",", "transparent", "and", "sterile", "antarctic", "ice", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the instrumented detector volume", "start": 0, "end": 32, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 33, "end": 35, "i_start": 4, "i_end": 4}}], "id": 4573}, {"sent": "polar codes proposed by arikan , are the first explicit construction of a family of codes that provably achieve the channel capacity for any binary-input , symmetric , memoryless channel .", "tokens": ["polar", "codes", "proposed", "by", "arikan", ",", "are", "the", "first", "explicit", "construction", "of", "a", "family", "of", "codes", "that", "provably", "achieve", "the", "channel", "capacity", "for", "any", "binary", "-", "input", ",", "symmetric", ",", "memoryless", "channel", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "polar codes proposed by arikan", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "are", "start": 33, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "arikan", "start": 24, "end": 30, "i_start": 4, "i_end": 4}, "action": {"text": "proposed", "start": 12, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "codes", "start": 84, "end": 89, "i_start": 15, "i_end": 15}, "action": {"text": "achieve", "start": 104, "end": 111, "i_start": 18, "i_end": 18}}], "id": 4574}, {"sent": "for further information on the natural functions of dcs please refer to lutz and schuler .", "tokens": ["for", "further", "information", "on", "the", "natural", "functions", "of", "dcs", "please", "refer", "to", "lutz", "and", "schuler", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4575}, {"sent": "indeed , the neoplasm develops several strategies to circumvent the action of the immune system .", "tokens": ["indeed", ",", "the", "neoplasm", "develops", "several", "strategies", "to", "circumvent", "the", "action", "of", "the", "immune", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the neoplasm", "start": 9, "end": 21, "i_start": 2, "i_end": 3}, "verb": {"text": "develops", "start": 22, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "neoplasm", "start": 13, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "develops", "start": 22, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "neoplasm", "start": 13, "end": 21, "i_start": 3, "i_end": 3}, "action": {"text": "circumvent", "start": 53, "end": 63, "i_start": 8, "i_end": 8}}, {"character": {"text": "system", "start": 89, "end": 95, "i_start": 14, "i_end": 14}, "action": {"text": "immune", "start": 82, "end": 88, "i_start": 13, "i_end": 13}}], "id": 4576}, {"sent": "for the exchange-correlation potential , within the general gradient approximation , the parametrization of perdew-burke-ernzerhof was chosen .", "tokens": ["for", "the", "exchange", "-", "correlation", "potential", ",", "within", "the", "general", "gradient", "approximation", ",", "the", "parametrization", "of", "perdew", "-", "burke", "-", "ernzerhof", "was", "chosen", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the parametrization of perdew-burke-ernzerhof", "start": 85, "end": 130, "i_start": 13, "i_end": 20}, "verb": {"text": "was chosen", "start": 131, "end": 141, "i_start": 21, "i_end": 22}}], "id": 4577}, {"sent": "as a potential photocatalytic material , go-sno 2 has been used in the decolorization of methylene blue .", "tokens": ["as", "a", "potential", "photocatalytic", "material", ",", "go", "-", "sno", "2", "has", "been", "used", "in", "the", "decolorization", "of", "methylene", "blue", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "go-sno 2", "start": 41, "end": 49, "i_start": 6, "i_end": 9}, "verb": {"text": "has been used", "start": 50, "end": 63, "i_start": 10, "i_end": 12}}, {"character": {"text": "material", "start": 30, "end": 38, "i_start": 4, "i_end": 4}, "action": {"text": "photocatalytic", "start": 15, "end": 29, "i_start": 3, "i_end": 3}}], "id": 4578}, {"sent": "this invariance is a simple corollary of lemma 5 3 and theorem 5 point 5 .", "tokens": ["this", "invariance", "is", "a", "simple", "corollary", "of", "lemma", "5", "3", "and", "theorem", "5", "point", "5", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this invariance", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"subject": {"text": "this invariance", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "theorem", "start": 55, "end": 62, "i_start": 11, "i_end": 11}}], "id": 4579}, {"sent": "the lagrangian is the curvature scalar of 3d time .", "tokens": ["the", "lagrangian", "is", "the", "curvature", "scalar", "of", "3d", "time", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the lagrangian", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 4580}, {"sent": "firstly , we are going to prove the closure of our algorithm under these assumptions .", "tokens": ["firstly", ",", "we", "are", "going", "to", "prove", "the", "closure", "of", "our", "algorithm", "under", "these", "assumptions", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "are going", "start": 13, "end": 22, "i_start": 3, "i_end": 4}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "prove", "start": 26, "end": 31, "i_start": 6, "i_end": 6}}], "id": 4581}, {"sent": "the residual module is a convolutional neural network with a similar architecture as resnet .", "tokens": ["the", "residual", "module", "is", "a", "convolutional", "neural", "network", "with", "a", "similar", "architecture", "as", "resnet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the residual module", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 4582}, {"sent": "vehicle trajectories with gps data have also been widely used for driver behavior pattern analysis and prediction .", "tokens": ["vehicle", "trajectories", "with", "gps", "data", "have", "also", "been", "widely", "used", "for", "driver", "behavior", "pattern", "analysis", "and", "prediction", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "vehicle trajectories with gps data", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "used", "start": 57, "end": 61, "i_start": 9, "i_end": 9}}, {"subject": {"text": "vehicle trajectories with gps data", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 5, "i_end": 5}}, {"subject": {"text": "vehicle trajectories with gps data", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "been", "start": 45, "end": 49, "i_start": 7, "i_end": 7}}], "id": 4583}, {"sent": "then this isomorphism is the identity map .", "tokens": ["then", "this", "isomorphism", "is", "the", "identity", "map", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this isomorphism", "start": 5, "end": 21, "i_start": 1, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 4584}, {"sent": "hyperbolic transformations without fixed points .", "tokens": ["hyperbolic", "transformations", "without", "fixed", "points", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4585}, {"sent": "we adopt the 56-layer resnet as the feature extractor network where the dimension is 64 .", "tokens": ["we", "adopt", "the", "56", "-", "layer", "resnet", "as", "the", "feature", "extractor", "network", "where", "the", "dimension", "is", "64", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "network", "start": 54, "end": 61, "i_start": 11, "i_end": 11}, "action": {"text": "extractor", "start": 44, "end": 53, "i_start": 10, "i_end": 10}}], "id": 4586}, {"sent": "nevertheless , we believe that the package can be well adequate for some feasibility studies of the high pt physics at lhc and in future , after some adjustments , of other detectors as well .", "tokens": ["nevertheless", ",", "we", "believe", "that", "the", "package", "can", "be", "well", "adequate", "for", "some", "feasibility", "studies", "of", "the", "high", "pt", "physics", "at", "lhc", "and", "in", "future", ",", "after", "some", "adjustments", ",", "of", "other", "detectors", "as", "well", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "believe", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "be", "start": 47, "end": 49, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "believe", "start": 18, "end": 25, "i_start": 3, "i_end": 3}}], "id": 4587}, {"sent": "combining the results of this subsection we obtain the following theorem .", "tokens": ["combining", "the", "results", "of", "this", "subsection", "we", "obtain", "the", "following", "theorem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 41, "end": 43, "i_start": 6, "i_end": 6}, "verb": {"text": "obtain", "start": 44, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 41, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "obtain", "start": 44, "end": 50, "i_start": 7, "i_end": 7}}], "id": 4588}, {"sent": "then one quantises the spacetime following the strategy of deformation quantisation the algebra of functions in the pseudo-euclidean space to a noncommutative associate algebra known as the moyal algebra .", "tokens": ["then", "one", "quantises", "the", "spacetime", "following", "the", "strategy", "of", "deformation", "quantisation", "the", "algebra", "of", "functions", "in", "the", "pseudo", "-", "euclidean", "space", "to", "a", "noncommutative", "associate", "algebra", "known", "as", "the", "moyal", "algebra", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 5, "end": 8, "i_start": 1, "i_end": 1}, "verb": {"text": "quantises", "start": 9, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "one", "start": 5, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "quantises", "start": 9, "end": 18, "i_start": 2, "i_end": 2}}], "id": 4589}, {"sent": "topological defects could be produced at a phase transition in the early universe .", "tokens": ["topological", "defects", "could", "be", "produced", "at", "a", "phase", "transition", "in", "the", "early", "universe", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "topological defects", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "could be produced", "start": 20, "end": 37, "i_start": 2, "i_end": 4}}], "id": 4590}, {"sent": "characteristic polynomials of random matrices .", "tokens": ["characteristic", "polynomials", "of", "random", "matrices", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4591}, {"sent": "later , levine and pandharipande found a geometric presentation of the cobordism groups .", "tokens": ["later", ",", "levine", "and", "pandharipande", "found", "a", "geometric", "presentation", "of", "the", "cobordism", "groups", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "levine and pandharipande", "start": 8, "end": 32, "i_start": 2, "i_end": 4}, "verb": {"text": "found", "start": 33, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "levine", "start": 8, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "found", "start": 33, "end": 38, "i_start": 5, "i_end": 5}}, {"character": {"text": "pandharipande", "start": 19, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "found", "start": 33, "end": 38, "i_start": 5, "i_end": 5}}], "id": 4592}, {"sent": "for two-sided ideals we show that all three concepts coincide .", "tokens": ["for", "two", "-", "sided", "ideals", "we", "show", "that", "all", "three", "concepts", "coincide", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 5, "i_end": 5}, "verb": {"text": "show", "start": 24, "end": 28, "i_start": 6, "i_end": 6}}, {"subject": {"text": "all three concepts", "start": 34, "end": 52, "i_start": 8, "i_end": 10}, "verb": {"text": "coincide", "start": 53, "end": 61, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 5, "i_end": 5}, "action": {"text": "show", "start": 24, "end": 28, "i_start": 6, "i_end": 6}}], "id": 4593}, {"sent": "deep model-free reinforcement learning has had great successes in recent years , notably in playing video games .", "tokens": ["deep", "model", "-", "free", "reinforcement", "learning", "has", "had", "great", "successes", "in", "recent", "years", ",", "notably", "in", "playing", "video", "games", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep model-free reinforcement learning", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "has had", "start": 39, "end": 46, "i_start": 6, "i_end": 7}}, {"character": {"text": "learning", "start": 30, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "successes", "start": 53, "end": 62, "i_start": 9, "i_end": 9}}], "id": 4594}, {"sent": "in general , the symplectic quotient is a symplectic stratified space .", "tokens": ["in", "general", ",", "the", "symplectic", "quotient", "is", "a", "symplectic", "stratified", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the symplectic quotient", "start": 13, "end": 36, "i_start": 3, "i_end": 5}, "verb": {"text": "is", "start": 37, "end": 39, "i_start": 6, "i_end": 6}}], "id": 4595}, {"sent": "gao et al conduct a rigorous and extensive study on detecting spam campaigns in facebook wall posts .", "tokens": ["gao", "et", "al", "conduct", "a", "rigorous", "and", "extensive", "study", "on", "detecting", "spam", "campaigns", "in", "facebook", "wall", "posts", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "gao et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "conduct", "start": 10, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "gao", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "conduct", "start": 10, "end": 17, "i_start": 3, "i_end": 3}}], "id": 4596}, {"sent": "the string tension is the coefficient of the linearly rising potential energy as a quark-antiquark pair are separated .", "tokens": ["the", "string", "tension", "is", "the", "coefficient", "of", "the", "linearly", "rising", "potential", "energy", "as", "a", "quark", "-", "antiquark", "pair", "are", "separated", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the string tension", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the coefficient of the linearly rising potential energy as a quark-antiquark pair", "start": 22, "end": 103, "i_start": 4, "i_end": 17}, "verb": {"text": "separated", "start": 108, "end": 117, "i_start": 19, "i_end": 19}}], "id": 4597}, {"sent": "we used dft as implemented in vasp with the projector augmented waves basis .", "tokens": ["we", "used", "dft", "as", "implemented", "in", "vasp", "with", "the", "projector", "augmented", "waves", "basis", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 4598}, {"sent": "despite the fundamental breakthroughs in various tasks , deep neural networks have been shown to be utterly vulnerable to adversarial attacks .", "tokens": ["despite", "the", "fundamental", "breakthroughs", "in", "various", "tasks", ",", "deep", "neural", "networks", "have", "been", "shown", "to", "be", "utterly", "vulnerable", "to", "adversarial", "attacks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 57, "end": 77, "i_start": 8, "i_end": 10}, "verb": {"text": "have been shown", "start": 78, "end": 93, "i_start": 11, "i_end": 13}}, {"character": {"text": "adversarial", "start": 122, "end": 133, "i_start": 19, "i_end": 19}, "action": {"text": "attacks", "start": 134, "end": 141, "i_start": 20, "i_end": 20}}], "id": 4599}, {"sent": "as a result , one can achieve the same peak photocurrent densities as in the previously reported dense arrays but with a much lower density of nanoparticles .", "tokens": ["as", "a", "result", ",", "one", "can", "achieve", "the", "same", "peak", "photocurrent", "densities", "as", "in", "the", "previously", "reported", "dense", "arrays", "but", "with", "a", "much", "lower", "density", "of", "nanoparticles", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 14, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "can achieve", "start": 18, "end": 29, "i_start": 5, "i_end": 6}}, {"character": {"text": "one", "start": 14, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "achieve", "start": 22, "end": 29, "i_start": 6, "i_end": 6}}], "id": 4600}, {"sent": "visual context can be obtained in a very local manner such as pixel context or in a global manner by image descriptors like the gist of a scene .", "tokens": ["visual", "context", "can", "be", "obtained", "in", "a", "very", "local", "manner", "such", "as", "pixel", "context", "or", "in", "a", "global", "manner", "by", "image", "descriptors", "like", "the", "gist", "of", "a", "scene", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "visual context", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "can be obtained", "start": 15, "end": 30, "i_start": 2, "i_end": 4}}], "id": 4601}, {"sent": "the weak phases and the amplitudes are determined by comparing this parametrization with available measurements .", "tokens": ["the", "weak", "phases", "and", "the", "amplitudes", "are", "determined", "by", "comparing", "this", "parametrization", "with", "available", "measurements", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the weak phases and the amplitudes", "start": 0, "end": 34, "i_start": 0, "i_end": 5}, "verb": {"text": "are determined", "start": 35, "end": 49, "i_start": 6, "i_end": 7}}, {"character": {"text": "comparing", "start": 53, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "determined", "start": 39, "end": 49, "i_start": 7, "i_end": 7}}], "id": 4602}, {"sent": "neutrinoless double beta decay is a lepton number violating process whose observation would also establish that neutrinos are their own anti-particles .", "tokens": ["neutrinoless", "double", "beta", "decay", "is", "a", "lepton", "number", "violating", "process", "whose", "observation", "would", "also", "establish", "that", "neutrinos", "are", "their", "own", "anti", "-", "particles", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neutrinoless double beta decay", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "process", "start": 60, "end": 67, "i_start": 9, "i_end": 9}, "action": {"text": "violating", "start": 50, "end": 59, "i_start": 8, "i_end": 8}}, {"character": {"text": "process", "start": 60, "end": 67, "i_start": 9, "i_end": 9}, "action": {"text": "observation", "start": 74, "end": 85, "i_start": 11, "i_end": 11}}, {"character": {"text": "observation", "start": 74, "end": 85, "i_start": 11, "i_end": 11}, "action": {"text": "establish", "start": 97, "end": 106, "i_start": 14, "i_end": 14}}, {"character": {"text": "neutrinos", "start": 112, "end": 121, "i_start": 16, "i_end": 16}, "action": {"text": "anti", "start": 136, "end": 140, "i_start": 20, "i_end": 20}}], "id": 4603}, {"sent": "this search with multiple conditions based objective statement comparison proves that the required effort needed to search multi conditional information is very little in .", "tokens": ["this", "search", "with", "multiple", "conditions", "based", "objective", "statement", "comparison", "proves", "that", "the", "required", "effort", "needed", "to", "search", "multi", "conditional", "information", "is", "very", "little", "in", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "this search with multiple conditions based objective statement comparison", "start": 0, "end": 73, "i_start": 0, "i_end": 8}, "verb": {"text": "proves", "start": 74, "end": 80, "i_start": 9, "i_end": 9}}, {"subject": {"text": "this search with multiple conditions based objective statement comparison", "start": 0, "end": 73, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 153, "end": 155, "i_start": 20, "i_end": 20}}, {"character": {"text": "search", "start": 5, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "proves", "start": 74, "end": 80, "i_start": 9, "i_end": 9}}], "id": 4604}, {"sent": "these integrals can be approximated with high accuracy by monte carlo integration , .", "tokens": ["these", "integrals", "can", "be", "approximated", "with", "high", "accuracy", "by", "monte", "carlo", "integration", ",", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these integrals", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "can be approximated", "start": 16, "end": 35, "i_start": 2, "i_end": 4}}], "id": 4605}, {"sent": "in the authors used lexicons with 50k , 12k and 95k words for respectively iam , rimes and openhart database , but none of this lexicon is fully covering the evaluation set .", "tokens": ["in", "the", "authors", "used", "lexicons", "with", "50k", ",", "12k", "and", "95k", "words", "for", "respectively", "iam", ",", "rimes", "and", "openhart", "database", ",", "but", "none", "of", "this", "lexicon", "is", "fully", "covering", "the", "evaluation", "set", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "none of this lexicon", "start": 115, "end": 135, "i_start": 22, "i_end": 25}, "verb": {"text": "used", "start": 15, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "none of this lexicon", "start": 115, "end": 135, "i_start": 22, "i_end": 25}, "verb": {"text": "covering", "start": 145, "end": 153, "i_start": 28, "i_end": 28}}], "id": 4606}, {"sent": "recently , recurrent neural network based approaches have achieved promising performance in video captioning .", "tokens": ["recently", ",", "recurrent", "neural", "network", "based", "approaches", "have", "achieved", "promising", "performance", "in", "video", "captioning", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recurrent neural network based approaches", "start": 11, "end": 52, "i_start": 2, "i_end": 6}, "verb": {"text": "have achieved", "start": 53, "end": 66, "i_start": 7, "i_end": 8}}, {"character": {"text": "approaches", "start": 42, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 58, "end": 66, "i_start": 8, "i_end": 8}}, {"character": {"text": "approaches", "start": 42, "end": 52, "i_start": 6, "i_end": 6}, "action": {"text": "performance", "start": 77, "end": 88, "i_start": 10, "i_end": 10}}, {"character": {"text": "performance", "start": 77, "end": 88, "i_start": 10, "i_end": 10}, "action": {"text": "promising", "start": 67, "end": 76, "i_start": 9, "i_end": 9}}], "id": 4607}, {"sent": "this semicircle law was first derived by wigner for large random matrices .", "tokens": ["this", "semicircle", "law", "was", "first", "derived", "by", "wigner", "for", "large", "random", "matrices", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this semicircle law", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "derived", "start": 30, "end": 37, "i_start": 5, "i_end": 5}}, {"subject": {"text": "this semicircle law", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "was", "start": 20, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "wigner", "start": 41, "end": 47, "i_start": 7, "i_end": 7}, "action": {"text": "derived", "start": 30, "end": 37, "i_start": 5, "i_end": 5}}], "id": 4608}, {"sent": "a client is a user who submits a job to the system .", "tokens": ["a", "client", "is", "a", "user", "who", "submits", "a", "job", "to", "the", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a client", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 2, "i_end": 2}}], "id": 4609}, {"sent": "the non-antenna-part is the core of the graph .", "tokens": ["the", "non", "-", "antenna", "-", "part", "is", "the", "core", "of", "the", "graph", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the non-antenna-part", "start": 0, "end": 20, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 6, "i_end": 6}}], "id": 4610}, {"sent": "for example , the alexnet in contains more than 60 million parameters .", "tokens": ["for", "example", ",", "the", "alexnet", "in", "contains", "more", "than", "60", "million", "parameters", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the alexnet in", "start": 14, "end": 28, "i_start": 3, "i_end": 5}, "verb": {"text": "contains", "start": 29, "end": 37, "i_start": 6, "i_end": 6}}], "id": 4611}, {"sent": "one mc step consists of single-spin flips , followed by loop flips with either flip xyz , flip parallel , or rotate .", "tokens": ["one", "mc", "step", "consists", "of", "single", "-", "spin", "flips", ",", "followed", "by", "loop", "flips", "with", "either", "flip", "xyz", ",", "flip", "parallel", ",", "or", "rotate", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one mc step", "start": 0, "end": 11, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 12, "end": 20, "i_start": 3, "i_end": 3}}], "id": 4612}, {"sent": "spades for adaptive nonparametric density estimation .", "tokens": ["spades", "for", "adaptive", "nonparametric", "density", "estimation", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4613}, {"sent": "in recent years , deep convolutional neural networks have achieved impressive results in a number of computer vision tasks such as image classification .", "tokens": ["in", "recent", "years", ",", "deep", "convolutional", "neural", "networks", "have", "achieved", "impressive", "results", "in", "a", "number", "of", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 18, "end": 52, "i_start": 4, "i_end": 7}, "verb": {"text": "have achieved", "start": 53, "end": 66, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 44, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 58, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "results", "start": 78, "end": 85, "i_start": 11, "i_end": 11}, "action": {"text": "impressive", "start": 67, "end": 77, "i_start": 10, "i_end": 10}}], "id": 4614}, {"sent": "subspace segmentation is an important data clustering problem and arises in numerous research areas , including computer vision .", "tokens": ["subspace", "segmentation", "is", "an", "important", "data", "clustering", "problem", "and", "arises", "in", "numerous", "research", "areas", ",", "including", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "subspace segmentation", "start": 0, "end": 21, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 2, "i_end": 2}}, {"subject": {"text": "subspace segmentation", "start": 0, "end": 21, "i_start": 0, "i_end": 1}, "verb": {"text": "arises", "start": 66, "end": 72, "i_start": 9, "i_end": 9}}], "id": 4615}, {"sent": "within the experimental resolution , as reflected in the data points , these inner cuts appear to overlay exactly .", "tokens": ["within", "the", "experimental", "resolution", ",", "as", "reflected", "in", "the", "data", "points", ",", "these", "inner", "cuts", "appear", "to", "overlay", "exactly", "."], "score": [0, 1, 0, 1, 0], "labels": [{"subject": {"text": "these inner cuts", "start": 71, "end": 87, "i_start": 12, "i_end": 14}, "verb": {"text": "appear", "start": 88, "end": 94, "i_start": 15, "i_end": 15}}, {"character": {"text": "cuts", "start": 83, "end": 87, "i_start": 14, "i_end": 14}, "action": {"text": "overlay", "start": 98, "end": 105, "i_start": 17, "i_end": 17}}], "id": 4616}, {"sent": "let be the time-average values for the radial component .", "tokens": ["let", "be", "the", "time", "-", "average", "values", "for", "the", "radial", "component", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the time-average values for the radial component", "start": 7, "end": 55, "i_start": 2, "i_end": 10}, "verb": {"text": "let be", "start": 0, "end": 6, "i_start": 0, "i_end": 1}}], "id": 4617}, {"sent": "it is a concave lower semicontinuous function on the set staking values in .", "tokens": ["it", "is", "a", "concave", "lower", "semicontinuous", "function", "on", "the", "set", "staking", "values", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"character": {"text": "set", "start": 53, "end": 56, "i_start": 9, "i_end": 9}, "action": {"text": "function", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}], "id": 4618}, {"sent": "the metallicity is the log of the ratio of the amount of iron to hydrogen in the stars relative to the sun .", "tokens": ["the", "metallicity", "is", "the", "log", "of", "the", "ratio", "of", "the", "amount", "of", "iron", "to", "hydrogen", "in", "the", "stars", "relative", "to", "the", "sun", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the metallicity", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 4619}, {"sent": "in , the authors proposed to mimic the gl instability with the rayleigh-plateau instability , based on the suggestive appearance of the second law of black hole mechanics which endows the horizon with an effective surface tension .", "tokens": ["in", ",", "the", "authors", "proposed", "to", "mimic", "the", "gl", "instability", "with", "the", "rayleigh", "-", "plateau", "instability", ",", "based", "on", "the", "suggestive", "appearance", "of", "the", "second", "law", "of", "black", "hole", "mechanics", "which", "endows", "the", "horizon", "with", "an", "effective", "surface", "tension", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 5, "end": 16, "i_start": 2, "i_end": 3}, "verb": {"text": "proposed", "start": 17, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "law", "start": 143, "end": 146, "i_start": 25, "i_end": 25}, "action": {"text": "endows", "start": 177, "end": 183, "i_start": 31, "i_end": 31}}, {"character": {"text": "tension", "start": 222, "end": 229, "i_start": 38, "i_end": 38}, "action": {"text": "effective", "start": 204, "end": 213, "i_start": 36, "i_end": 36}}, {"character": {"text": "appearance", "start": 118, "end": 128, "i_start": 21, "i_end": 21}, "action": {"text": "suggestive", "start": 107, "end": 117, "i_start": 20, "i_end": 20}}], "id": 4620}, {"sent": "deep neural networks have been widely adopted in many applications such as computer vision , speech recognition , and natural language processing .", "tokens": ["deep", "neural", "networks", "have", "been", "widely", "adopted", "in", "many", "applications", "such", "as", "computer", "vision", ",", "speech", "recognition", ",", "and", "natural", "language", "processing", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "adopted", "start": 38, "end": 45, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}], "id": 4621}, {"sent": "its lagrangian consists of all possible terms involving standard-model fields that are observer lorentz scalars , including terms having coupling coefficients with lorentz indices .", "tokens": ["its", "lagrangian", "consists", "of", "all", "possible", "terms", "involving", "standard", "-", "model", "fields", "that", "are", "observer", "lorentz", "scalars", ",", "including", "terms", "having", "coupling", "coefficients", "with", "lorentz", "indices", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "its lagrangian", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 15, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "fields", "start": 71, "end": 77, "i_start": 11, "i_end": 11}, "action": {"text": "observer", "start": 87, "end": 95, "i_start": 14, "i_end": 14}}, {"character": {"text": "terms", "start": 124, "end": 129, "i_start": 19, "i_end": 19}, "action": {"text": "having", "start": 130, "end": 136, "i_start": 20, "i_end": 20}}], "id": 4622}, {"sent": "in particular , a variety of graph convolutional networks have been developed , including networks with prescribed parameters .", "tokens": ["in", "particular", ",", "a", "variety", "of", "graph", "convolutional", "networks", "have", "been", "developed", ",", "including", "networks", "with", "prescribed", "parameters", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "a variety of graph convolutional networks", "start": 16, "end": 57, "i_start": 3, "i_end": 8}, "verb": {"text": "have been developed", "start": 58, "end": 77, "i_start": 9, "i_end": 11}}, {"character": {"text": "networks", "start": 90, "end": 98, "i_start": 14, "i_end": 14}, "action": {"text": "have", "start": 58, "end": 62, "i_start": 9, "i_end": 9}}], "id": 4623}, {"sent": "deep neural networks have achieved considerable improvements in learning tasks with voluminous labeled data .", "tokens": ["deep", "neural", "networks", "have", "achieved", "considerable", "improvements", "in", "learning", "tasks", "with", "voluminous", "labeled", "data", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improvements", "start": 48, "end": 60, "i_start": 6, "i_end": 6}}], "id": 4624}, {"sent": "the state of polarization is described by stokes parameter .", "tokens": ["the", "state", "of", "polarization", "is", "described", "by", "stokes", "parameter", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the state of polarization", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "is described", "start": 26, "end": 38, "i_start": 4, "i_end": 5}}, {"character": {"text": "parameter", "start": 49, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "described", "start": 29, "end": 38, "i_start": 5, "i_end": 5}}], "id": 4625}, {"sent": "the ordinate is the ratio of the bh mass as obtained from ground-based data to that obtained with hst kinematic data included .", "tokens": ["the", "ordinate", "is", "the", "ratio", "of", "the", "bh", "mass", "as", "obtained", "from", "ground", "-", "based", "data", "to", "that", "obtained", "with", "hst", "kinematic", "data", "included", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ordinate", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 4626}, {"sent": "events are reconstructed using the particle flow , pf , algorithm , which reconstructs and identifies each individual particle with an optimized combination of information from the various elements of the cms detector .", "tokens": ["events", "are", "reconstructed", "using", "the", "particle", "flow", ",", "pf", ",", "algorithm", ",", "which", "reconstructs", "and", "identifies", "each", "individual", "particle", "with", "an", "optimized", "combination", "of", "information", "from", "the", "various", "elements", "of", "the", "cms", "detector", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "events", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "are reconstructed", "start": 7, "end": 24, "i_start": 1, "i_end": 2}}, {"character": {"text": "algorithm", "start": 56, "end": 65, "i_start": 10, "i_end": 10}, "action": {"text": "reconstructs", "start": 74, "end": 86, "i_start": 13, "i_end": 13}}, {"character": {"text": "algorithm", "start": 56, "end": 65, "i_start": 10, "i_end": 10}, "action": {"text": "identifies", "start": 91, "end": 101, "i_start": 15, "i_end": 15}}], "id": 4627}, {"sent": "this model has been of considerable interest in the physics literature .", "tokens": ["this", "model", "has", "been", "of", "considerable", "interest", "in", "the", "physics", "literature", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this model", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "has been", "start": 11, "end": 19, "i_start": 2, "i_end": 3}}], "id": 4628}, {"sent": "density functional theory based calculations were performed using the vasp ab-initio simulation package .", "tokens": ["density", "functional", "theory", "based", "calculations", "were", "performed", "using", "the", "vasp", "ab", "-", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "density functional theory based calculations", "start": 0, "end": 44, "i_start": 0, "i_end": 4}, "verb": {"text": "were performed", "start": 45, "end": 59, "i_start": 5, "i_end": 6}}], "id": 4629}, {"sent": "it is well-known that linear network codes achieve the min-cut capacity of networks for unicast applications .", "tokens": ["it", "is", "well", "-", "known", "that", "linear", "network", "codes", "achieve", "the", "min", "-", "cut", "capacity", "of", "networks", "for", "unicast", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "linear network codes", "start": 22, "end": 42, "i_start": 6, "i_end": 8}, "verb": {"text": "achieve", "start": 43, "end": 50, "i_start": 9, "i_end": 9}}, {"character": {"text": "codes", "start": 37, "end": 42, "i_start": 8, "i_end": 8}, "action": {"text": "achieve", "start": 43, "end": 50, "i_start": 9, "i_end": 9}}], "id": 4630}, {"sent": "several methods exploit the self-similarity property in natural images and construct lr-hr patch pairs based on the scale-space pyramid of the low-resolution input image .", "tokens": ["several", "methods", "exploit", "the", "self", "-", "similarity", "property", "in", "natural", "images", "and", "construct", "lr", "-", "hr", "patch", "pairs", "based", "on", "the", "scale", "-", "space", "pyramid", "of", "the", "low", "-", "resolution", "input", "image", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "several methods", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "exploit", "start": 16, "end": 23, "i_start": 2, "i_end": 2}}, {"subject": {"text": "several methods", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "construct", "start": 75, "end": 84, "i_start": 12, "i_end": 12}}, {"character": {"text": "methods", "start": 8, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "exploit", "start": 16, "end": 23, "i_start": 2, "i_end": 2}}, {"character": {"text": "methods", "start": 8, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "construct", "start": 75, "end": 84, "i_start": 12, "i_end": 12}}], "id": 4631}, {"sent": "garg et al proposed an unsupervised framework for single view depth estimation with a photometric reconstruction loss between stereo pairs .", "tokens": ["garg", "et", "al", "proposed", "an", "unsupervised", "framework", "for", "single", "view", "depth", "estimation", "with", "a", "photometric", "reconstruction", "loss", "between", "stereo", "pairs", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 5, "end": 10, "i_start": 1, "i_end": 2}, "verb": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "garg", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}], "id": 4632}, {"sent": "deep neural networks have been shown to be very efficient in image processing tasks such as content classification .", "tokens": ["deep", "neural", "networks", "have", "been", "shown", "to", "be", "very", "efficient", "in", "image", "processing", "tasks", "such", "as", "content", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been shown", "start": 21, "end": 36, "i_start": 3, "i_end": 5}}], "id": 4633}, {"sent": "deep learning models have been widely applied to many vision tasks such as classification , leading to state-of-theart performance .", "tokens": ["deep", "learning", "models", "have", "been", "widely", "applied", "to", "many", "vision", "tasks", "such", "as", "classification", ",", "leading", "to", "state", "-", "of", "-", "theart", "performance", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning models", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "applied", "start": 38, "end": 45, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep learning models", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}, {"character": {"text": "applied", "start": 38, "end": 45, "i_start": 6, "i_end": 6}, "action": {"text": "leading", "start": 92, "end": 99, "i_start": 15, "i_end": 15}}], "id": 4634}, {"sent": "after every convolutional layer , batch normalization are applied to the output .", "tokens": ["after", "every", "convolutional", "layer", ",", "batch", "normalization", "are", "applied", "to", "the", "output", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "batch normalization", "start": 34, "end": 53, "i_start": 5, "i_end": 6}, "verb": {"text": "are applied", "start": 54, "end": 65, "i_start": 7, "i_end": 8}}], "id": 4635}, {"sent": "second , roughgarden showed that poa bounds for smooth games also apply to bayesian extensions of the game as long as types are drawn independently .", "tokens": ["second", ",", "roughgarden", "showed", "that", "poa", "bounds", "for", "smooth", "games", "also", "apply", "to", "bayesian", "extensions", "of", "the", "game", "as", "long", "as", "types", "are", "drawn", "independently", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "roughgarden", "start": 9, "end": 20, "i_start": 2, "i_end": 2}, "verb": {"text": "showed", "start": 21, "end": 27, "i_start": 3, "i_end": 3}}, {"subject": {"text": "poa bounds for smooth games", "start": 33, "end": 60, "i_start": 5, "i_end": 9}, "verb": {"text": "apply", "start": 66, "end": 71, "i_start": 11, "i_end": 11}}, {"character": {"text": "roughgarden", "start": 9, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "showed", "start": 21, "end": 27, "i_start": 3, "i_end": 3}}], "id": 4636}, {"sent": "since the cohomology consists of cosets of \u03b3-closed expressions modulo \u03b3-exact ones , the undifferentiated fields clearly do not belong to it .", "tokens": ["since", "the", "cohomology", "consists", "of", "cosets", "of", "\u03b3", "-", "closed", "expressions", "modulo", "\u03b3", "-", "exact", "ones", ",", "the", "undifferentiated", "fields", "clearly", "do", "not", "belong", "to", "it", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "the undifferentiated fields", "start": 86, "end": 113, "i_start": 17, "i_end": 19}, "verb": {"text": "do not belong", "start": 122, "end": 135, "i_start": 21, "i_end": 23}}, {"character": {"text": "fields", "start": 107, "end": 113, "i_start": 19, "i_end": 19}, "action": {"text": "-closed expressions modulo \u03b3-exact ones , the undifferentiated fields clearly do not belong", "start": 44, "end": 135, "i_start": 8, "i_end": 23}}], "id": 4637}, {"sent": "there are an increasing number of providers offering cloud infrastructures and services with different terminology , definitions , and goals .", "tokens": ["there", "are", "an", "increasing", "number", "of", "providers", "offering", "cloud", "infrastructures", "and", "services", "with", "different", "terminology", ",", "definitions", ",", "and", "goals", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 6, "end": 9, "i_start": 1, "i_end": 1}}], "id": 4638}, {"sent": "neural networks have been widely adopted in many scenarios , achieving state-of-the-art results in numerous tasks .", "tokens": ["neural", "networks", "have", "been", "widely", "adopted", "in", "many", "scenarios", ",", "achieving", "state", "-", "of", "-", "the", "-", "art", "results", "in", "numerous", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "adopted", "start": 33, "end": 40, "i_start": 5, "i_end": 5}}, {"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have been", "start": 16, "end": 25, "i_start": 2, "i_end": 3}}], "id": 4639}, {"sent": "the pieri formula shows these coefficients are certain intersection numbers , recovering a result of kirillov and maeno , which are not geometric .", "tokens": ["the", "pieri", "formula", "shows", "these", "coefficients", "are", "certain", "intersection", "numbers", ",", "recovering", "a", "result", "of", "kirillov", "and", "maeno", ",", "which", "are", "not", "geometric", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the pieri formula", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "shows", "start": 18, "end": 23, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the pieri formula", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 43, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "formula", "start": 10, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "shows", "start": 18, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "shows", "start": 18, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "recovering", "start": 78, "end": 88, "i_start": 11, "i_end": 11}}], "id": 4640}, {"sent": "there are several popular frameworks of deep generative models , including generative adversarial networks .", "tokens": ["there", "are", "several", "popular", "frameworks", "of", "deep", "generative", "models", ",", "including", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 6, "end": 9, "i_start": 1, "i_end": 1}}], "id": 4641}, {"sent": "banerjee et al generalized this idea by developing a k-means-like algorithm with various distortion functions based on bregman divergences .", "tokens": ["banerjee", "et", "al", "generalized", "this", "idea", "by", "developing", "a", "k", "-", "means", "-", "like", "algorithm", "with", "various", "distortion", "functions", "based", "on", "bregman", "divergences", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "banerjee et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "generalized", "start": 15, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "banerjee", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "generalized", "start": 15, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "banerjee", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "developing", "start": 40, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "bregman", "start": 119, "end": 126, "i_start": 21, "i_end": 21}, "action": {"text": "divergences", "start": 127, "end": 138, "i_start": 22, "i_end": 22}}], "id": 4642}, {"sent": "this superpotential consists of four pieces .", "tokens": ["this", "superpotential", "consists", "of", "four", "pieces", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4643}, {"sent": "we also show that loop amplitudes with fewer than four points vanish .", "tokens": ["we", "also", "show", "that", "loop", "amplitudes", "with", "fewer", "than", "four", "points", "vanish", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"subject": {"text": "loop amplitudes with fewer than four points", "start": 18, "end": 61, "i_start": 4, "i_end": 10}, "verb": {"text": "vanish", "start": 62, "end": 68, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}], "id": 4644}, {"sent": "the cdos method can be easily transformed into an effective mixed optimizer that can .", "tokens": ["the", "cdos", "method", "can", "be", "easily", "transformed", "into", "an", "effective", "mixed", "optimizer", "that", "can", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the cdos method", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "transformed", "start": 30, "end": 41, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the cdos method", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "can be", "start": 16, "end": 22, "i_start": 3, "i_end": 4}}, {"character": {"text": "optimizer", "start": 66, "end": 75, "i_start": 11, "i_end": 11}, "action": {"text": "effective", "start": 50, "end": 59, "i_start": 9, "i_end": 9}}], "id": 4645}, {"sent": "to represent the image , we leverage the feature representations of a pre-trained vgg-19 network .", "tokens": ["to", "represent", "the", "image", ",", "we", "leverage", "the", "feature", "representations", "of", "a", "pre", "-", "trained", "vgg-19", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "verb": {"text": "leverage", "start": 28, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "leverage", "start": 28, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 25, "end": 27, "i_start": 5, "i_end": 5}, "action": {"text": "represent", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}], "id": 4646}, {"sent": "the pb nanoparticles are higly reactive material and they can be easily oxidized .", "tokens": ["the", "pb", "nanoparticles", "are", "higly", "reactive", "material", "and", "they", "can", "be", "easily", "oxidized", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the pb nanoparticles", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}, {"subject": {"text": "they", "start": 53, "end": 57, "i_start": 8, "i_end": 8}, "verb": {"text": "oxidized", "start": 72, "end": 80, "i_start": 12, "i_end": 12}}, {"character": {"text": "material", "start": 40, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "reactive", "start": 31, "end": 39, "i_start": 5, "i_end": 5}}], "id": 4647}, {"sent": "meanwhile , the vertices connected to in qare , and , and the variable attached to them are equal tox 1 , x 1 , x 1 , andx 3 , respectively .", "tokens": ["meanwhile", ",", "the", "vertices", "connected", "to", "in", "qare", ",", "and", ",", "and", "the", "variable", "attached", "to", "them", "are", "equal", "tox", "1", ",", "x", "1", ",", "x", "1", ",", "andx", "3", ",", "respectively", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the vertices connected to in qare , and , and the variable attached to them", "start": 12, "end": 87, "i_start": 2, "i_end": 16}, "verb": {"text": "are", "start": 88, "end": 91, "i_start": 17, "i_end": 17}}], "id": 4648}, {"sent": "these methods originate from cdma multiuser detection problems in .", "tokens": ["these", "methods", "originate", "from", "cdma", "multiuser", "detection", "problems", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these methods", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "originate", "start": 14, "end": 23, "i_start": 2, "i_end": 2}}], "id": 4649}, {"sent": "on square-free vertex colorings of graphs .", "tokens": ["on", "square", "-", "free", "vertex", "colorings", "of", "graphs", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4650}, {"sent": "a batch normalization layer is added to the output of every convolutional layer .", "tokens": ["a", "batch", "normalization", "layer", "is", "added", "to", "the", "output", "of", "every", "convolutional", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a batch normalization layer", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "is added", "start": 28, "end": 36, "i_start": 4, "i_end": 5}}], "id": 4651}, {"sent": "transmit power can be further reduced by perturbing the transmitted vector , as in , where the optimum perturbation vector is found using the sphere encoder .", "tokens": ["transmit", "power", "can", "be", "further", "reduced", "by", "perturbing", "the", "transmitted", "vector", ",", "as", "in", ",", "where", "the", "optimum", "perturbation", "vector", "is", "found", "using", "the", "sphere", "encoder", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "transmit power", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "reduced", "start": 30, "end": 37, "i_start": 5, "i_end": 5}}, {"subject": {"text": "transmit power", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "can be", "start": 15, "end": 21, "i_start": 2, "i_end": 3}}, {"character": {"text": "vector", "start": 116, "end": 122, "i_start": 19, "i_end": 19}, "action": {"text": "perturbation", "start": 103, "end": 115, "i_start": 18, "i_end": 18}}], "id": 4652}, {"sent": "since every a-module is a quotient of a map of free a-modules , it suffices to show that fan is an isomorphism .", "tokens": ["since", "every", "a", "-", "module", "is", "a", "quotient", "of", "a", "map", "of", "free", "a", "-", "modules", ",", "it", "suffices", "to", "show", "that", "fan", "is", "an", "isomorphism", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 64, "end": 66, "i_start": 17, "i_end": 17}, "verb": {"text": "suffices", "start": 67, "end": 75, "i_start": 18, "i_end": 18}}, {"character": {"text": "show", "start": 79, "end": 83, "i_start": 20, "i_end": 20}, "action": {"text": "suffices", "start": 67, "end": 75, "i_start": 18, "i_end": 18}}], "id": 4653}, {"sent": "unfortunately , their approach also suffered from low f-measure when filler size is small .", "tokens": ["unfortunately", ",", "their", "approach", "also", "suffered", "from", "low", "f", "-", "measure", "when", "filler", "size", "is", "small", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "their approach", "start": 16, "end": 30, "i_start": 2, "i_end": 3}, "verb": {"text": "suffered", "start": 36, "end": 44, "i_start": 5, "i_end": 5}}, {"character": {"text": "approach", "start": 22, "end": 30, "i_start": 3, "i_end": 3}, "action": {"text": "suffered", "start": 36, "end": 44, "i_start": 5, "i_end": 5}}], "id": 4654}, {"sent": "this result motivated the work by wyner who introduced the notion of wiretap channel .", "tokens": ["this", "result", "motivated", "the", "work", "by", "wyner", "who", "introduced", "the", "notion", "of", "wiretap", "channel", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this result", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "motivated", "start": 12, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "result", "start": 5, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "motivated", "start": 12, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "channel", "start": 77, "end": 84, "i_start": 13, "i_end": 13}, "action": {"text": "work", "start": 26, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "wiretap", "start": 69, "end": 76, "i_start": 12, "i_end": 12}, "action": {"text": "work", "start": 26, "end": 30, "i_start": 4, "i_end": 4}}], "id": 4655}, {"sent": "the inverse process takes place occasionally .", "tokens": ["the", "inverse", "process", "takes", "place", "occasionally", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the inverse process", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "takes", "start": 20, "end": 25, "i_start": 3, "i_end": 3}}], "id": 4656}, {"sent": "superscripts d or b denote only dressed or bare vertices , respectively , whereas no superscript refers to both .", "tokens": ["superscripts", "d", "or", "b", "denote", "only", "dressed", "or", "bare", "vertices", ",", "respectively", ",", "whereas", "no", "superscript", "refers", "to", "both", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "superscripts", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "action": {"text": "denote", "start": 20, "end": 26, "i_start": 4, "i_end": 4}}], "id": 4657}, {"sent": "in fact , information theory is a fundamental theory for data compression and transmission .", "tokens": ["in", "fact", ",", "information", "theory", "is", "a", "fundamental", "theory", "for", "data", "compression", "and", "transmission", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "information theory", "start": 10, "end": 28, "i_start": 3, "i_end": 4}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 5, "i_end": 5}}], "id": 4658}, {"sent": "the conjugate gradient method is an iterative method which is often well suited to solve these systems .", "tokens": ["the", "conjugate", "gradient", "method", "is", "an", "iterative", "method", "which", "is", "often", "well", "suited", "to", "solve", "these", "systems", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the conjugate gradient method", "start": 0, "end": 29, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "method", "start": 23, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "solve", "start": 83, "end": 88, "i_start": 14, "i_end": 14}}], "id": 4659}, {"sent": "we check in this part that our results coincide with the ones obtained directly from the 1-matrix model in .", "tokens": ["we", "check", "in", "this", "part", "that", "our", "results", "coincide", "with", "the", "ones", "obtained", "directly", "from", "the", "1", "-", "matrix", "model", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "check", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "our results", "start": 27, "end": 38, "i_start": 6, "i_end": 7}, "verb": {"text": "coincide", "start": 39, "end": 47, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "check", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 4660}, {"sent": "the numerator is the length of the reconnected strings .", "tokens": ["the", "numerator", "is", "the", "length", "of", "the", "reconnected", "strings", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the numerator", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 4661}, {"sent": "especially , many approaches based on convolutional neural networks made significant advances in large-scale image classification .", "tokens": ["especially", ",", "many", "approaches", "based", "on", "convolutional", "neural", "networks", "made", "significant", "advances", "in", "large", "-", "scale", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "many approaches based on convolutional neural networks", "start": 13, "end": 67, "i_start": 2, "i_end": 8}, "verb": {"text": "made", "start": 68, "end": 72, "i_start": 9, "i_end": 9}}, {"character": {"text": "approaches", "start": 18, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "advances", "start": 85, "end": 93, "i_start": 11, "i_end": 11}}], "id": 4662}, {"sent": "this has various interesting properties which were not seen in the monopole cases .", "tokens": ["this", "has", "various", "interesting", "properties", "which", "were", "not", "seen", "in", "the", "monopole", "cases", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "has", "start": 5, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "has", "start": 5, "end": 8, "i_start": 1, "i_end": 1}}], "id": 4663}, {"sent": "the forward tracker consists of five silicon microstrip disks similar to those in the l and sd detectors .", "tokens": ["the", "forward", "tracker", "consists", "of", "five", "silicon", "microstrip", "disks", "similar", "to", "those", "in", "the", "l", "and", "sd", "detectors", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the forward tracker", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 20, "end": 28, "i_start": 3, "i_end": 3}}], "id": 4664}, {"sent": "proof of this theorem will be stated in section v .", "tokens": ["proof", "of", "this", "theorem", "will", "be", "stated", "in", "section", "v", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "proof of this theorem", "start": 0, "end": 21, "i_start": 0, "i_end": 3}, "verb": {"text": "will be stated", "start": 22, "end": 36, "i_start": 4, "i_end": 6}}], "id": 4665}, {"sent": "this leads us to consider generalized gradient flows in metric spaces .", "tokens": ["this", "leads", "us", "to", "consider", "generalized", "gradient", "flows", "in", "metric", "spaces", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "leads", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "leads", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "us", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "action": {"text": "consider", "start": 17, "end": 25, "i_start": 4, "i_end": 4}}], "id": 4666}, {"sent": "deep neural networks recently have shown successful results on image-based recognition tasks .", "tokens": ["deep", "neural", "networks", "recently", "have", "shown", "successful", "results", "on", "image", "-", "based", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 35, "end": 40, "i_start": 5, "i_end": 5}}], "id": 4667}, {"sent": "the cofibration is called closed , if a is a closed subspace .", "tokens": ["the", "cofibration", "is", "called", "closed", ",", "if", "a", "is", "a", "closed", "subspace", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the cofibration", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is called", "start": 16, "end": 25, "i_start": 2, "i_end": 3}}], "id": 4668}, {"sent": "the networks are trained using stochastic gradient descent .", "tokens": ["the", "networks", "are", "trained", "using", "stochastic", "gradient", "descent", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the networks", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "are trained", "start": 13, "end": 24, "i_start": 2, "i_end": 3}}], "id": 4669}, {"sent": "to improve the learning performance , the mixture correntropy was proposed in a recent paper by using a linear combination of several zero-mean gaussian kernels as the kernel function .", "tokens": ["to", "improve", "the", "learning", "performance", ",", "the", "mixture", "correntropy", "was", "proposed", "in", "a", "recent", "paper", "by", "using", "a", "linear", "combination", "of", "several", "zero", "-", "mean", "gaussian", "kernels", "as", "the", "kernel", "function", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the mixture correntropy", "start": 38, "end": 61, "i_start": 6, "i_end": 8}, "verb": {"text": "was proposed", "start": 62, "end": 74, "i_start": 9, "i_end": 10}}, {"character": {"text": "combination", "start": 111, "end": 122, "i_start": 19, "i_end": 19}, "action": {"text": "function", "start": 175, "end": 183, "i_start": 30, "i_end": 30}}], "id": 4670}, {"sent": "thank you for helping me through twenty years of school .", "tokens": ["thank", "you", "for", "helping", "me", "through", "twenty", "years", "of", "school", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "me", "start": 22, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "thank", "start": 0, "end": 5, "i_start": 0, "i_end": 0}}, {"character": {"text": "you", "start": 6, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "helping", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}], "id": 4671}, {"sent": "goodfellow et al describe the fast gradient sign method of generating adversarial perturbations in a white-box setting .", "tokens": ["goodfellow", "et", "al", "describe", "the", "fast", "gradient", "sign", "method", "of", "generating", "adversarial", "perturbations", "in", "a", "white", "-", "box", "setting", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "describe", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "goodfellow", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "describe", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}], "id": 4672}, {"sent": "convolutional neural networks have been largely responsible for the significant progress achieved on visual recognition tasks in recent years .", "tokens": ["convolutional", "neural", "networks", "have", "been", "largely", "responsible", "for", "the", "significant", "progress", "achieved", "on", "visual", "recognition", "tasks", "in", "recent", "years", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 30, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "responsible", "start": 48, "end": 59, "i_start": 6, "i_end": 6}}], "id": 4673}, {"sent": "the panels is the large scale eddy turnover time .", "tokens": ["the", "panels", "is", "the", "large", "scale", "eddy", "turnover", "time", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the panels", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}], "id": 4674}, {"sent": "here we consider a gene clustering example using a gene expression dataset from a small round blue-cell tumors microarray experiment to further evaluate the compared methods .", "tokens": ["here", "we", "consider", "a", "gene", "clustering", "example", "using", "a", "gene", "expression", "dataset", "from", "a", "small", "round", "blue", "-", "cell", "tumors", "microarray", "experiment", "to", "further", "evaluate", "the", "compared", "methods", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "consider", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}, {"subject": {"text": "a gene", "start": 17, "end": 23, "i_start": 3, "i_end": 4}, "verb": {"text": "clustering", "start": 24, "end": 34, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "microarray", "start": 111, "end": 121, "i_start": 20, "i_end": 20}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "consider", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "using", "start": 43, "end": 48, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "evaluate", "start": 144, "end": 152, "i_start": 24, "i_end": 24}}], "id": 4675}, {"sent": "in these conditions , the persistence of the present instantaneous beat signal between the two resonators would represent an unambiguous evidence for the type of random vacuum we have been considering .", "tokens": ["in", "these", "conditions", ",", "the", "persistence", "of", "the", "present", "instantaneous", "beat", "signal", "between", "the", "two", "resonators", "would", "represent", "an", "unambiguous", "evidence", "for", "the", "type", "of", "random", "vacuum", "we", "have", "been", "considering", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the persistence of the present instantaneous beat signal between the two resonators", "start": 22, "end": 105, "i_start": 4, "i_end": 15}, "verb": {"text": "would represent", "start": 106, "end": 121, "i_start": 16, "i_end": 17}}, {"character": {"text": "persistence", "start": 26, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "represent", "start": 112, "end": 121, "i_start": 17, "i_end": 17}}, {"character": {"text": "two", "start": 91, "end": 94, "i_start": 14, "i_end": 14}, "action": {"text": "resonators", "start": 95, "end": 105, "i_start": 15, "i_end": 15}}, {"character": {"text": "persistence", "start": 26, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "evidence", "start": 137, "end": 145, "i_start": 20, "i_end": 20}}, {"character": {"text": "we", "start": 176, "end": 178, "i_start": 27, "i_end": 27}, "action": {"text": "considering", "start": 189, "end": 200, "i_start": 30, "i_end": 30}}], "id": 4676}, {"sent": "again the similarities are both in terms of infinite series formulas and in terms of formulas via iterated integrals over membranes .", "tokens": ["again", "the", "similarities", "are", "both", "in", "terms", "of", "infinite", "series", "formulas", "and", "in", "terms", "of", "formulas", "via", "iterated", "integrals", "over", "membranes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the similarities", "start": 6, "end": 22, "i_start": 1, "i_end": 2}, "verb": {"text": "are", "start": 23, "end": 26, "i_start": 3, "i_end": 3}}], "id": 4677}, {"sent": "it suffices to show there is a polynomial time reduction of the satisfiability problem to this factoring problem , where m is of magnitude some constant positive root of n .", "tokens": ["it", "suffices", "to", "show", "there", "is", "a", "polynomial", "time", "reduction", "of", "the", "satisfiability", "problem", "to", "this", "factoring", "problem", ",", "where", "m", "is", "of", "magnitude", "some", "constant", "positive", "root", "of", "n", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "suffices", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "show", "start": 15, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "suffices", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 4678}, {"sent": "this condensate is a very important characteristics of qcd vacuum , since it is directly related to the vacuum energy density .", "tokens": ["this", "condensate", "is", "a", "very", "important", "characteristics", "of", "qcd", "vacuum", ",", "since", "it", "is", "directly", "related", "to", "the", "vacuum", "energy", "density", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this condensate", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"subject": {"text": "this condensate", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "related", "start": 89, "end": 96, "i_start": 15, "i_end": 15}}], "id": 4679}, {"sent": "recently , deep convolutional neural networks show promising performances in various computer vision tasks such as object classification , localization .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "show", "promising", "performances", "in", "various", "computer", "vision", "tasks", "such", "as", "object", "classification", ",", "localization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "show", "start": 46, "end": 50, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "show", "start": 46, "end": 50, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performances", "start": 61, "end": 73, "i_start": 8, "i_end": 8}}, {"character": {"text": "performances", "start": 61, "end": 73, "i_start": 8, "i_end": 8}, "action": {"text": "promising", "start": 51, "end": 60, "i_start": 7, "i_end": 7}}], "id": 4680}, {"sent": "most previous experiments have employed monodisperse spheres to form coulomb crystals .", "tokens": ["most", "previous", "experiments", "have", "employed", "monodisperse", "spheres", "to", "form", "coulomb", "crystals", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "most previous experiments", "start": 0, "end": 25, "i_start": 0, "i_end": 2}, "verb": {"text": "have employed", "start": 26, "end": 39, "i_start": 3, "i_end": 4}}, {"character": {"text": "experiments", "start": 14, "end": 25, "i_start": 2, "i_end": 2}, "action": {"text": "employed", "start": 31, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "spheres", "start": 53, "end": 60, "i_start": 6, "i_end": 6}, "action": {"text": "form", "start": 64, "end": 68, "i_start": 8, "i_end": 8}}], "id": 4681}, {"sent": "we shall refer to the decomposition of the space of link variables as the geometric .", "tokens": ["we", "shall", "refer", "to", "the", "decomposition", "of", "the", "space", "of", "link", "variables", "as", "the", "geometric", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "shall refer", "start": 3, "end": 14, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 9, "end": 14, "i_start": 2, "i_end": 2}}], "id": 4682}, {"sent": "show that every open siegel set is an open subset of g .", "tokens": ["show", "that", "every", "open", "siegel", "set", "is", "an", "open", "subset", "of", "g", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4683}, {"sent": "this postulate is a new addition to the traditional principles of general relativity , although it is a familiar principle in high energy physics .", "tokens": ["this", "postulate", "is", "a", "new", "addition", "to", "the", "traditional", "principles", "of", "general", "relativity", ",", "although", "it", "is", "a", "familiar", "principle", "in", "high", "energy", "physics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this postulate", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 4684}, {"sent": "however , despite all these advantages , face recognition systems are the ones that most suffer from spoofing attacks since they can be easily fooled even with common printed photographs .", "tokens": ["however", ",", "despite", "all", "these", "advantages", ",", "face", "recognition", "systems", "are", "the", "ones", "that", "most", "suffer", "from", "spoofing", "attacks", "since", "they", "can", "be", "easily", "fooled", "even", "with", "common", "printed", "photographs", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "face recognition systems", "start": 41, "end": 65, "i_start": 7, "i_end": 9}, "verb": {"text": "are", "start": 66, "end": 69, "i_start": 10, "i_end": 10}}, {"character": {"text": "systems", "start": 58, "end": 65, "i_start": 9, "i_end": 9}, "action": {"text": "suffer", "start": 89, "end": 95, "i_start": 15, "i_end": 15}}, {"character": {"text": "systems", "start": 58, "end": 65, "i_start": 9, "i_end": 9}, "action": {"text": "recognition", "start": 46, "end": 57, "i_start": 8, "i_end": 8}}], "id": 4685}, {"sent": "encouraged by the benefits of transfer learning , we adapt 2d refinenet for 3d segmentation of plant root mri images in super-resolution .", "tokens": ["encouraged", "by", "the", "benefits", "of", "transfer", "learning", ",", "we", "adapt", "2d", "refinenet", "for", "3d", "segmentation", "of", "plant", "root", "mri", "images", "in", "super", "-", "resolution", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 50, "end": 52, "i_start": 8, "i_end": 8}, "verb": {"text": "adapt", "start": 53, "end": 58, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 50, "end": 52, "i_start": 8, "i_end": 8}, "action": {"text": "adapt", "start": 53, "end": 58, "i_start": 9, "i_end": 9}}, {"character": {"text": "benefits", "start": 18, "end": 26, "i_start": 3, "i_end": 3}, "action": {"text": "encouraged", "start": 0, "end": 10, "i_start": 0, "i_end": 0}}, {"character": {"text": "learning", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "benefits", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}], "id": 4686}, {"sent": "central extensions of the vector field algebra .", "tokens": ["central", "extensions", "of", "the", "vector", "field", "algebra", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4687}, {"sent": "the values are marked on the corresponding diffraction peaks .", "tokens": ["the", "values", "are", "marked", "on", "the", "corresponding", "diffraction", "peaks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the values", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "are marked", "start": 11, "end": 21, "i_start": 2, "i_end": 3}}], "id": 4688}, {"sent": "we solve the dual of the master problem using the fista algorithm .", "tokens": ["we", "solve", "the", "dual", "of", "the", "master", "problem", "using", "the", "fista", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "solve", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "solve", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 4689}, {"sent": "in the context of error-correcting codes , we have previously classified the lc orbits of all graphs on up to 12 vertices .", "tokens": ["in", "the", "context", "of", "error", "-", "correcting", "codes", ",", "we", "have", "previously", "classified", "the", "lc", "orbits", "of", "all", "graphs", "on", "up", "to", "12", "vertices", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 43, "end": 45, "i_start": 9, "i_end": 9}, "verb": {"text": "classified", "start": 62, "end": 72, "i_start": 12, "i_end": 12}}, {"subject": {"text": "we", "start": 43, "end": 45, "i_start": 9, "i_end": 9}, "verb": {"text": "have", "start": 46, "end": 50, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 43, "end": 45, "i_start": 9, "i_end": 9}, "action": {"text": "classified", "start": 62, "end": 72, "i_start": 12, "i_end": 12}}, {"character": {"text": "codes", "start": 35, "end": 40, "i_start": 7, "i_end": 7}, "action": {"text": "correcting", "start": 24, "end": 34, "i_start": 6, "i_end": 6}}], "id": 4690}, {"sent": "if neutrino is a majorana particle then by definition it is identical to its charge conjugate .", "tokens": ["if", "neutrino", "is", "a", "majorana", "particle", "then", "by", "definition", "it", "is", "identical", "to", "its", "charge", "conjugate", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 54, "end": 56, "i_start": 9, "i_end": 9}, "verb": {"text": "is", "start": 57, "end": 59, "i_start": 10, "i_end": 10}}], "id": 4691}, {"sent": "radio loudness of the nuclei for the three samples of local agn .", "tokens": ["radio", "loudness", "of", "the", "nuclei", "for", "the", "three", "samples", "of", "local", "agn", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4692}, {"sent": "the network coding approach introduced in generalizes routing by allowing intermediate nodes to forward coded combinations of all received data packets .", "tokens": ["the", "network", "coding", "approach", "introduced", "in", "generalizes", "routing", "by", "allowing", "intermediate", "nodes", "to", "forward", "coded", "combinations", "of", "all", "received", "data", "packets", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the network coding approach introduced in generalizes routing by allowing intermediate nodes to forward coded combinations of all", "start": 0, "end": 129, "i_start": 0, "i_end": 17}, "verb": {"text": "received", "start": 130, "end": 138, "i_start": 18, "i_end": 18}}, {"character": {"text": "approach", "start": 19, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "generalizes", "start": 42, "end": 53, "i_start": 6, "i_end": 6}}, {"character": {"text": "approach", "start": 19, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "allowing", "start": 65, "end": 73, "i_start": 9, "i_end": 9}}, {"character": {"text": "nodes", "start": 87, "end": 92, "i_start": 11, "i_end": 11}, "action": {"text": "forward", "start": 96, "end": 103, "i_start": 13, "i_end": 13}}], "id": 4693}, {"sent": "some researchers have proposed basic mobility models such as random walk , random waypoint , etc .", "tokens": ["some", "researchers", "have", "proposed", "basic", "mobility", "models", "such", "as", "random", "walk", ",", "random", "waypoint", ",", "etc", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "some researchers", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "have proposed", "start": 17, "end": 30, "i_start": 2, "i_end": 3}}, {"character": {"text": "some", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 22, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "some", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "models", "start": 46, "end": 52, "i_start": 6, "i_end": 6}}], "id": 4694}, {"sent": "this can by the photoionization temperature further suppress star formation in low mass haloes and is known as radiative feedback .", "tokens": ["this", "can", "by", "the", "photoionization", "temperature", "further", "suppress", "star", "formation", "in", "low", "mass", "haloes", "and", "is", "known", "as", "radiative", "feedback", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "suppress", "start": 52, "end": 60, "i_start": 7, "i_end": 7}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "can", "start": 5, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "known", "start": 102, "end": 107, "i_start": 16, "i_end": 16}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "suppress", "start": 52, "end": 60, "i_start": 7, "i_end": 7}}], "id": 4695}, {"sent": "currently the strongest bounds on the spin-independent wimp-proton scattering cross section , \u03c3 si p , have been achieved in the xenon-based underground detector lux .", "tokens": ["currently", "the", "strongest", "bounds", "on", "the", "spin", "-", "independent", "wimp", "-", "proton", "scattering", "cross", "section", ",", "\u03c3", "si", "p", ",", "have", "been", "achieved", "in", "the", "xenon", "-", "based", "underground", "detector", "lux", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the strongest bounds on the spin-independent wimp-proton scattering cross section", "start": 10, "end": 91, "i_start": 1, "i_end": 14}, "verb": {"text": "have been achieved", "start": 103, "end": 121, "i_start": 20, "i_end": 22}}, {"character": {"text": "cross", "start": 78, "end": 83, "i_start": 13, "i_end": 13}, "action": {"text": "-independent", "start": 42, "end": 54, "i_start": 7, "i_end": 8}}], "id": 4696}, {"sent": "deep neural networks have been extensively applied in many fields , such as image recognition .", "tokens": ["deep", "neural", "networks", "have", "been", "extensively", "applied", "in", "many", "fields", ",", "such", "as", "image", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "applied", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}], "id": 4697}, {"sent": "the exchange-correlation effects are treated with the functional proposed by perdew , burke , and ernzerhof .", "tokens": ["the", "exchange", "-", "correlation", "effects", "are", "treated", "with", "the", "functional", "proposed", "by", "perdew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange-correlation effects", "start": 0, "end": 32, "i_start": 0, "i_end": 4}, "verb": {"text": "are treated", "start": 33, "end": 44, "i_start": 5, "i_end": 6}}, {"character": {"text": "perdew", "start": 77, "end": 83, "i_start": 12, "i_end": 12}, "action": {"text": "proposed", "start": 65, "end": 73, "i_start": 10, "i_end": 10}}, {"character": {"text": "burke", "start": 86, "end": 91, "i_start": 14, "i_end": 14}, "action": {"text": "proposed", "start": 65, "end": 73, "i_start": 10, "i_end": 10}}, {"character": {"text": "ernzerhof", "start": 98, "end": 107, "i_start": 17, "i_end": 17}, "action": {"text": "proposed", "start": 65, "end": 73, "i_start": 10, "i_end": 10}}], "id": 4698}, {"sent": "massive mimo has been identified as one of the promising air interface technologies to address the massive capacity requirement required demanded by 5g networks .", "tokens": ["massive", "mimo", "has", "been", "identified", "as", "one", "of", "the", "promising", "air", "interface", "technologies", "to", "address", "the", "massive", "capacity", "requirement", "required", "demanded", "by", "5", "g", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "massive mimo", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "has been identified", "start": 13, "end": 32, "i_start": 2, "i_end": 4}}], "id": 4699}, {"sent": "the event calculus is a deductive kr formalism for temporal reasoning about the effects of events .", "tokens": ["the", "event", "calculus", "is", "a", "deductive", "kr", "formalism", "for", "temporal", "reasoning", "about", "the", "effects", "of", "events", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the event calculus", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "formalism", "start": 37, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "deductive", "start": 24, "end": 33, "i_start": 5, "i_end": 5}}], "id": 4700}, {"sent": "deep convolutional neural networks have shown promising performances on various computer vision problems such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "shown", "promising", "performances", "on", "various", "computer", "vision", "problems", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have shown", "start": 35, "end": 45, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "shown", "start": 40, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "performances", "start": 56, "end": 68, "i_start": 7, "i_end": 7}}, {"character": {"text": "performances", "start": 56, "end": 68, "i_start": 7, "i_end": 7}, "action": {"text": "promising", "start": 46, "end": 55, "i_start": 6, "i_end": 6}}], "id": 4701}, {"sent": "we use the definition in of the supergroup of isometries of a riemannian supermanifold .", "tokens": ["we", "use", "the", "definition", "in", "of", "the", "supergroup", "of", "isometries", "of", "a", "riemannian", "supermanifold", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 4702}, {"sent": "morphisms of towers , that are isomorphisms in this category , are called pro isomorphisms .", "tokens": ["morphisms", "of", "towers", ",", "that", "are", "isomorphisms", "in", "this", "category", ",", "are", "called", "pro", "isomorphisms", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "morphisms of towers", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "are called", "start": 63, "end": 73, "i_start": 11, "i_end": 12}}], "id": 4703}, {"sent": "the chandrasekhar limit is a stability criterion for compact objects like white dwarfs or the iron core of a massive star .", "tokens": ["the", "chandrasekhar", "limit", "is", "a", "stability", "criterion", "for", "compact", "objects", "like", "white", "dwarfs", "or", "the", "iron", "core", "of", "a", "massive", "star", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the chandrasekhar limit", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "chandrasekhar", "start": 4, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "limit", "start": 18, "end": 23, "i_start": 2, "i_end": 2}}], "id": 4704}, {"sent": "the dot-dashed line is the upper bound from curvaton dominance .", "tokens": ["the", "dot", "-", "dashed", "line", "is", "the", "upper", "bound", "from", "curvaton", "dominance", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dot-dashed line", "start": 0, "end": 19, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 5, "i_end": 5}}, {"character": {"text": "curvaton", "start": 44, "end": 52, "i_start": 10, "i_end": 10}, "action": {"text": "dominance", "start": 53, "end": 62, "i_start": 11, "i_end": 11}}], "id": 4705}, {"sent": "for a fixed number of components k , the model is usually estimated using the em algorithm .", "tokens": ["for", "a", "fixed", "number", "of", "components", "k", ",", "the", "model", "is", "usually", "estimated", "using", "the", "em", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 37, "end": 46, "i_start": 8, "i_end": 9}, "verb": {"text": "estimated", "start": 58, "end": 67, "i_start": 12, "i_end": 12}}, {"subject": {"text": "the model", "start": 37, "end": 46, "i_start": 8, "i_end": 9}, "verb": {"text": "is", "start": 47, "end": 49, "i_start": 10, "i_end": 10}}], "id": 4706}, {"sent": "a junction is a point in space formed where edges intersect .", "tokens": ["a", "junction", "is", "a", "point", "in", "space", "formed", "where", "edges", "intersect", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a junction", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "edges", "start": 44, "end": 49, "i_start": 9, "i_end": 9}, "action": {"text": "intersect", "start": 50, "end": 59, "i_start": 10, "i_end": 10}}], "id": 4707}, {"sent": "deep convolutional neural networks have led to a series of breakthrough for visual tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "led", "to", "a", "series", "of", "breakthrough", "for", "visual", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have led", "start": 35, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "led", "start": 40, "end": 43, "i_start": 5, "i_end": 5}}], "id": 4708}, {"sent": "we also use a threelayer bi-directional lstm with bayesian dropout as the encoder .", "tokens": ["we", "also", "use", "a", "threelayer", "bi", "-", "directional", "lstm", "with", "bayesian", "dropout", "as", "the", "encoder", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}], "id": 4709}, {"sent": "for further results , we refer the reader to and references therein .", "tokens": ["for", "further", "results", ",", "we", "refer", "the", "reader", "to", "and", "references", "therein", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 22, "end": 24, "i_start": 4, "i_end": 4}, "verb": {"text": "refer", "start": 25, "end": 30, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 22, "end": 24, "i_start": 4, "i_end": 4}, "verb": {"text": "references", "start": 49, "end": 59, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "refer", "start": 25, "end": 30, "i_start": 5, "i_end": 5}}], "id": 4710}, {"sent": "considering swipt , the authors in study mimo broadcast systems , where the users either demand information or energy .", "tokens": ["considering", "swipt", ",", "the", "authors", "in", "study", "mimo", "broadcast", "systems", ",", "where", "the", "users", "either", "demand", "information", "or", "energy", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4711}, {"sent": "in recent years , deep neural networks have achieved great success in a variety of machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "achieved", "great", "success", "in", "a", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}], "id": 4712}, {"sent": "in these figures , each datapoint is the average of the effort spent by buyers for the corresponding loyalty level and includes at least 400 instances .", "tokens": ["in", "these", "figures", ",", "each", "datapoint", "is", "the", "average", "of", "the", "effort", "spent", "by", "buyers", "for", "the", "corresponding", "loyalty", "level", "and", "includes", "at", "least", "400", "instances", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each datapoint", "start": 19, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 6, "i_end": 6}}, {"subject": {"text": "each datapoint", "start": 19, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "includes", "start": 119, "end": 127, "i_start": 21, "i_end": 21}}], "id": 4713}, {"sent": "the phase boundary is the location of the sonic horizon .", "tokens": ["the", "phase", "boundary", "is", "the", "location", "of", "the", "sonic", "horizon", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the phase boundary", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 4714}, {"sent": "according to the general theory of singular systems , variables with ambiguous dynamics do not represent observable quantities .", "tokens": ["according", "to", "the", "general", "theory", "of", "singular", "systems", ",", "variables", "with", "ambiguous", "dynamics", "do", "not", "represent", "observable", "quantities", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "variables with ambiguous dynamics", "start": 54, "end": 87, "i_start": 9, "i_end": 12}, "verb": {"text": "do not represent", "start": 88, "end": 104, "i_start": 13, "i_end": 15}}, {"character": {"text": "variables", "start": 54, "end": 63, "i_start": 9, "i_end": 9}, "action": {"text": "not represent", "start": 91, "end": 104, "i_start": 14, "i_end": 15}}], "id": 4715}, {"sent": "we train the model using the first-order stochastic gradient descent method adam .", "tokens": ["we", "train", "the", "model", "using", "the", "first", "-", "order", "stochastic", "gradient", "descent", "method", "adam", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 4716}, {"sent": "the perdew-burke-ernzerhof exchange-correlation functional in the generalized gradient approximation was employed .", "tokens": ["the", "perdew", "-", "burke", "-", "ernzerhof", "exchange", "-", "correlation", "functional", "in", "the", "generalized", "gradient", "approximation", "was", "employed", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the perdew-burke-ernzerhof exchange-correlation functional in the generalized gradient approximation", "start": 0, "end": 100, "i_start": 0, "i_end": 14}, "verb": {"text": "was employed", "start": 101, "end": 113, "i_start": 15, "i_end": 16}}], "id": 4717}, {"sent": "moreover , the elliptic degeneracy and geometry of the problem makes it difficult to apply the hodograph transform approach in kinderlehrer-nirenberg to a partially modified equation .", "tokens": ["moreover", ",", "the", "elliptic", "degeneracy", "and", "geometry", "of", "the", "problem", "makes", "it", "difficult", "to", "apply", "the", "hodograph", "transform", "approach", "in", "kinderlehrer", "-", "nirenberg", "to", "a", "partially", "modified", "equation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the elliptic degeneracy and geometry of the problem", "start": 11, "end": 62, "i_start": 2, "i_end": 9}, "verb": {"text": "makes", "start": 63, "end": 68, "i_start": 10, "i_end": 10}}, {"subject": {"text": "the elliptic degeneracy and geometry of the problem", "start": 11, "end": 62, "i_start": 2, "i_end": 9}, "verb": {"text": "difficult", "start": 72, "end": 81, "i_start": 12, "i_end": 12}}, {"character": {"text": "degeneracy", "start": 24, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "makes", "start": 63, "end": 68, "i_start": 10, "i_end": 10}}, {"character": {"text": "elliptic", "start": 15, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "makes", "start": 63, "end": 68, "i_start": 10, "i_end": 10}}, {"character": {"text": "geometry", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "makes", "start": 63, "end": 68, "i_start": 10, "i_end": 10}}, {"character": {"text": "problem", "start": 55, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "makes", "start": 63, "end": 68, "i_start": 10, "i_end": 10}}], "id": 4718}, {"sent": "millimeter wave communications have emerged as a promising technology for 5g communications .", "tokens": ["millimeter", "wave", "communications", "have", "emerged", "as", "a", "promising", "technology", "for", "5", "g", "communications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "millimeter wave communications", "start": 0, "end": 30, "i_start": 0, "i_end": 2}, "verb": {"text": "have emerged", "start": 31, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "communications", "start": 16, "end": 30, "i_start": 2, "i_end": 2}, "action": {"text": "emerged", "start": 36, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "technology", "start": 59, "end": 69, "i_start": 8, "i_end": 8}, "action": {"text": "promising", "start": 49, "end": 58, "i_start": 7, "i_end": 7}}], "id": 4719}, {"sent": "else , choose a leaf , associated to a step by step leaf removal process is called an history .", "tokens": ["else", ",", "choose", "a", "leaf", ",", "associated", "to", "a", "step", "by", "step", "leaf", "removal", "process", "is", "called", "an", "history", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4720}, {"sent": "we use the fermilab prescription for the charm quarks , which suppresses heavy-quark discretization effects in mass splittings .", "tokens": ["we", "use", "the", "fermilab", "prescription", "for", "the", "charm", "quarks", ",", "which", "suppresses", "heavy", "-", "quark", "discretization", "effects", "in", "mass", "splittings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "quarks", "start": 47, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "suppresses", "start": 62, "end": 72, "i_start": 11, "i_end": 11}}, {"character": {"text": "quark", "start": 79, "end": 84, "i_start": 14, "i_end": 14}, "action": {"text": "discretization", "start": 85, "end": 99, "i_start": 15, "i_end": 15}}], "id": 4721}, {"sent": "a classification of the projective lines over small rings .", "tokens": ["a", "classification", "of", "the", "projective", "lines", "over", "small", "rings", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4722}, {"sent": "convolutional neural networks have had great success in in various computer vision tasks .", "tokens": ["convolutional", "neural", "networks", "have", "had", "great", "success", "in", "in", "various", "computer", "vision", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have had", "start": 30, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 45, "end": 52, "i_start": 6, "i_end": 6}}], "id": 4723}, {"sent": "in the standard scenario of thermal leptogenesis , a lepton asymmetry is generated by decays of heavy right-handed majorana neutrinos into standard model leptons at temperatures much above the electroweak scale .", "tokens": ["in", "the", "standard", "scenario", "of", "thermal", "leptogenesis", ",", "a", "lepton", "asymmetry", "is", "generated", "by", "decays", "of", "heavy", "right", "-", "handed", "majorana", "neutrinos", "into", "standard", "model", "leptons", "at", "temperatures", "much", "above", "the", "electroweak", "scale", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "a lepton asymmetry", "start": 51, "end": 69, "i_start": 8, "i_end": 10}, "verb": {"text": "is generated", "start": 70, "end": 82, "i_start": 11, "i_end": 12}}, {"character": {"text": "decays", "start": 86, "end": 92, "i_start": 14, "i_end": 14}, "action": {"text": "generated", "start": 73, "end": 82, "i_start": 12, "i_end": 12}}, {"character": {"text": "neutrinos", "start": 124, "end": 133, "i_start": 21, "i_end": 21}, "action": {"text": "decays", "start": 86, "end": 92, "i_start": 14, "i_end": 14}}], "id": 4724}, {"sent": "strang northeastern university , boston , usa g .", "tokens": ["strang", "northeastern", "university", ",", "boston", ",", "usa", "g", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4725}, {"sent": "also for the warm phase of the ism we could demonstrate that the numerical scheme is appropriate for simulations of this phase .", "tokens": ["also", "for", "the", "warm", "phase", "of", "the", "ism", "we", "could", "demonstrate", "that", "the", "numerical", "scheme", "is", "appropriate", "for", "simulations", "of", "this", "phase", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 35, "end": 37, "i_start": 8, "i_end": 8}, "verb": {"text": "could demonstrate", "start": 38, "end": 55, "i_start": 9, "i_end": 10}}, {"subject": {"text": "we", "start": 35, "end": 37, "i_start": 8, "i_end": 8}, "verb": {"text": "is", "start": 82, "end": 84, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 35, "end": 37, "i_start": 8, "i_end": 8}, "action": {"text": "demonstrate", "start": 44, "end": 55, "i_start": 10, "i_end": 10}}], "id": 4726}, {"sent": "in , an alternating projection method was adopted to implement svd-based analog combiners .", "tokens": ["in", ",", "an", "alternating", "projection", "method", "was", "adopted", "to", "implement", "svd", "-", "based", "analog", "combiners", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an alternating projection method", "start": 5, "end": 37, "i_start": 2, "i_end": 5}, "verb": {"text": "was adopted", "start": 38, "end": 49, "i_start": 6, "i_end": 7}}], "id": 4727}, {"sent": "hou et al introduced short connections into the skiplayer structures within the holisitcally-nested edge detector architecture to achieve image saliency detection , which combines the low-level and high-level features at multiple scales .", "tokens": ["hou", "et", "al", "introduced", "short", "connections", "into", "the", "skiplayer", "structures", "within", "the", "holisitcally", "-", "nested", "edge", "detector", "architecture", "to", "achieve", "image", "saliency", "detection", ",", "which", "combines", "the", "low", "-", "level", "and", "high", "-", "level", "features", "at", "multiple", "scales", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hou et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "introduced", "start": 10, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "hou", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 10, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "hou", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "achieve", "start": 130, "end": 137, "i_start": 19, "i_end": 19}}, {"character": {"text": "detection", "start": 153, "end": 162, "i_start": 22, "i_end": 22}, "action": {"text": "combines", "start": 171, "end": 179, "i_start": 25, "i_end": 25}}], "id": 4728}, {"sent": "unfortunately , the no-go theorem for the rule on lattice has been proved in our previous papers .", "tokens": ["unfortunately", ",", "the", "no", "-", "go", "theorem", "for", "the", "rule", "on", "lattice", "has", "been", "proved", "in", "our", "previous", "papers", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the no-go theorem for the rule on lattice", "start": 16, "end": 57, "i_start": 2, "i_end": 11}, "verb": {"text": "has been proved", "start": 58, "end": 73, "i_start": 12, "i_end": 14}}], "id": 4729}, {"sent": "the electron exchange correlation potential is treated with the generalized gradient of the perdew-bruke-ernzerhof functional .", "tokens": ["the", "electron", "exchange", "correlation", "potential", "is", "treated", "with", "the", "generalized", "gradient", "of", "the", "perdew", "-", "bruke", "-", "ernzerhof", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electron exchange correlation potential", "start": 0, "end": 43, "i_start": 0, "i_end": 4}, "verb": {"text": "is treated", "start": 44, "end": 54, "i_start": 5, "i_end": 6}}], "id": 4730}, {"sent": "we use the googlenet model trained on imagenet for extracting frame-level features .", "tokens": ["we", "use", "the", "googlenet", "model", "trained", "on", "imagenet", "for", "extracting", "frame", "-", "level", "features", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "extracting", "start": 51, "end": 61, "i_start": 9, "i_end": 9}}], "id": 4731}, {"sent": "we also see that the ring solution has lower energy then that of the sphere solution .", "tokens": ["we", "also", "see", "that", "the", "ring", "solution", "has", "lower", "energy", "then", "that", "of", "the", "sphere", "solution", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "see", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the ring solution", "start": 17, "end": 34, "i_start": 4, "i_end": 6}, "verb": {"text": "has", "start": 35, "end": 38, "i_start": 7, "i_end": 7}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "that", "start": 57, "end": 61, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "see", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "solution", "start": 26, "end": 34, "i_start": 6, "i_end": 6}, "action": {"text": "has", "start": 35, "end": 38, "i_start": 7, "i_end": 7}}], "id": 4732}, {"sent": "deep convolutional neural networks have been prevailed in various computer vision tasks , such as objection classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "prevailed", "in", "various", "computer", "vision", "tasks", ",", "such", "as", "objection", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been prevailed", "start": 35, "end": 54, "i_start": 4, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "prevailed", "start": 45, "end": 54, "i_start": 6, "i_end": 6}}], "id": 4733}, {"sent": "in this section , we introduce the weight formulas for the original turaev-viro invariants tv r , q defined in .", "tokens": ["in", "this", "section", ",", "we", "introduce", "the", "weight", "formulas", "for", "the", "original", "turaev", "-", "viro", "invariants", "tv", "r", ",", "q", "defined", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "introduce", "start": 21, "end": 30, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "invariants", "start": 80, "end": 90, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "introduce", "start": 21, "end": 30, "i_start": 5, "i_end": 5}}], "id": 4734}, {"sent": "the model is trained using mini-batches and the adam optimisation algorithm .", "tokens": ["the", "model", "is", "trained", "using", "mini", "-", "batches", "and", "the", "adam", "optimisation", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is trained", "start": 10, "end": 20, "i_start": 2, "i_end": 3}}], "id": 4735}, {"sent": "the physics objects are the jets , clustered using the anti-k t jet finding algorithm with the tracks assigned to the vertex as inputs , and the associated missing transverse momentum , taken as the negative vector sum of the p t of those jets .", "tokens": ["the", "physics", "objects", "are", "the", "jets", ",", "clustered", "using", "the", "anti", "-", "k", "t", "jet", "finding", "algorithm", "with", "the", "tracks", "assigned", "to", "the", "vertex", "as", "inputs", ",", "and", "the", "associated", "missing", "transverse", "momentum", ",", "taken", "as", "the", "negative", "vector", "sum", "of", "the", "p", "t", "of", "those", "jets", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the physics objects", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 20, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithm", "start": 76, "end": 85, "i_start": 16, "i_end": 16}, "action": {"text": "finding", "start": 68, "end": 75, "i_start": 15, "i_end": 15}}, {"character": {"text": "jet", "start": 64, "end": 67, "i_start": 14, "i_end": 14}, "action": {"text": "anti", "start": 55, "end": 59, "i_start": 10, "i_end": 10}}], "id": 4736}, {"sent": "polar codes are the first capacity-achieving channel codes with low-complexity successive cancellation decoding .", "tokens": ["polar", "codes", "are", "the", "first", "capacity", "-", "achieving", "channel", "codes", "with", "low", "-", "complexity", "successive", "cancellation", "decoding", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "polar codes", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 12, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "codes", "start": 6, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "achieving", "start": 35, "end": 44, "i_start": 7, "i_end": 7}}, {"character": {"text": "codes", "start": 6, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "decoding", "start": 103, "end": 111, "i_start": 16, "i_end": 16}}], "id": 4737}, {"sent": "one of these algebras is the quotient of the polynomial ring modulo certain monomial ideal , while the other is the quotient of the polynomial ring modulo certain powers of linear forms .", "tokens": ["one", "of", "these", "algebras", "is", "the", "quotient", "of", "the", "polynomial", "ring", "modulo", "certain", "monomial", "ideal", ",", "while", "the", "other", "is", "the", "quotient", "of", "the", "polynomial", "ring", "modulo", "certain", "powers", "of", "linear", "forms", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one of these algebras", "start": 0, "end": 21, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}], "id": 4738}, {"sent": "each profile is a sum of approximately twenty unblended line profiles .", "tokens": ["each", "profile", "is", "a", "sum", "of", "approximately", "twenty", "unblended", "line", "profiles", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each profile", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 4739}, {"sent": "a stochastic homogeneous hyperelastic model is defined by a stochastic strain-energy function , for which the model parameters are random variables , drawn from probability distributions .", "tokens": ["a", "stochastic", "homogeneous", "hyperelastic", "model", "is", "defined", "by", "a", "stochastic", "strain", "-", "energy", "function", ",", "for", "which", "the", "model", "parameters", "are", "random", "variables", ",", "drawn", "from", "probability", "distributions", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "a stochastic homogeneous hyperelastic model", "start": 0, "end": 43, "i_start": 0, "i_end": 4}, "verb": {"text": "is defined", "start": 44, "end": 54, "i_start": 5, "i_end": 6}}, {"character": {"text": "function", "start": 85, "end": 93, "i_start": 13, "i_end": 13}, "action": {"text": "defined", "start": 47, "end": 54, "i_start": 6, "i_end": 6}}], "id": 4740}, {"sent": "then the einstein-maxwell horizon geometry consists of the quadruplet .", "tokens": ["then", "the", "einstein", "-", "maxwell", "horizon", "geometry", "consists", "of", "the", "quadruplet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the einstein-maxwell horizon geometry", "start": 5, "end": 42, "i_start": 1, "i_end": 6}, "verb": {"text": "consists", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}], "id": 4741}, {"sent": "the calculations were performed using first-principles density functional theory as implemented in the vienna ab initio simulation package .", "tokens": ["the", "calculations", "were", "performed", "using", "first", "-", "principles", "density", "functional", "theory", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the calculations", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were performed", "start": 17, "end": 31, "i_start": 2, "i_end": 3}}], "id": 4742}, {"sent": "in this section we experiment with resnet-110 and a 164-layer bottleneck architecture .", "tokens": ["in", "this", "section", "we", "experiment", "with", "resnet-110", "and", "a", "164", "-", "layer", "bottleneck", "architecture", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "experiment", "start": 19, "end": 29, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "experiment", "start": 19, "end": 29, "i_start": 4, "i_end": 4}}], "id": 4743}, {"sent": "the only modification is a reduction in the size if the resulting electric field compared to a precisely shaped hyperbolic electrode of the same characteristic size .", "tokens": ["the", "only", "modification", "is", "a", "reduction", "in", "the", "size", "if", "the", "resulting", "electric", "field", "compared", "to", "a", "precisely", "shaped", "hyperbolic", "electrode", "of", "the", "same", "characteristic", "size", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the only modification", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 3, "i_end": 3}}], "id": 4744}, {"sent": "we want to examine this action and work out the mass eigenstates .", "tokens": ["we", "want", "to", "examine", "this", "action", "and", "work", "out", "the", "mass", "eigenstates", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "want", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "want", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "examine", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "work", "start": 35, "end": 39, "i_start": 7, "i_end": 7}}], "id": 4745}, {"sent": "the size of the star-forming region relative to the scale of the galaxy increases with galaxy mass as well .", "tokens": ["the", "size", "of", "the", "star", "-", "forming", "region", "relative", "to", "the", "scale", "of", "the", "galaxy", "increases", "with", "galaxy", "mass", "as", "well", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the size of the star-forming region relative to the scale of the galaxy", "start": 0, "end": 71, "i_start": 0, "i_end": 14}, "verb": {"text": "increases", "start": 72, "end": 81, "i_start": 15, "i_end": 15}}, {"character": {"text": "region", "start": 29, "end": 35, "i_start": 7, "i_end": 7}, "action": {"text": "forming", "start": 21, "end": 28, "i_start": 6, "i_end": 6}}], "id": 4746}, {"sent": "the result is consistent with the consideration of the total number of possible microstates of the system .", "tokens": ["the", "result", "is", "consistent", "with", "the", "consideration", "of", "the", "total", "number", "of", "possible", "microstates", "of", "the", "system", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the result", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 2, "i_end": 2}}], "id": 4747}, {"sent": "deep neural networks have contributed to notable performance improvements in fields such as image processing .", "tokens": ["deep", "neural", "networks", "have", "contributed", "to", "notable", "performance", "improvements", "in", "fields", "such", "as", "image", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have contributed", "start": 21, "end": 37, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "contributed", "start": 26, "end": 37, "i_start": 4, "i_end": 4}}], "id": 4748}, {"sent": "the perdew-burkeernzerhof generalized-gradient approximation is employed to describe the exchange and correlation functional .", "tokens": ["the", "perdew", "-", "burkeernzerhof", "generalized", "-", "gradient", "approximation", "is", "employed", "to", "describe", "the", "exchange", "and", "correlation", "functional", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the perdew-burkeernzerhof generalized-gradient approximation", "start": 0, "end": 60, "i_start": 0, "i_end": 7}, "verb": {"text": "is employed", "start": 61, "end": 72, "i_start": 8, "i_end": 9}}, {"character": {"text": "approximation", "start": 47, "end": 60, "i_start": 7, "i_end": 7}, "action": {"text": "describe", "start": 76, "end": 84, "i_start": 11, "i_end": 11}}], "id": 4749}, {"sent": "recent development of deep convolutional neural networks has led to great success in a variety of tasks including image classfication and others .", "tokens": ["recent", "development", "of", "deep", "convolutional", "neural", "networks", "has", "led", "to", "great", "success", "in", "a", "variety", "of", "tasks", "including", "image", "classfication", "and", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent development of deep convolutional neural networks", "start": 0, "end": 56, "i_start": 0, "i_end": 6}, "verb": {"text": "has led", "start": 57, "end": 64, "i_start": 7, "i_end": 8}}, {"character": {"text": "development", "start": 7, "end": 18, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 61, "end": 64, "i_start": 8, "i_end": 8}}], "id": 4750}, {"sent": "although great effort has been devoted to the study of the tcp , it has been shown to be polynomial-time solvable only for a couple of very restricted subclasses of stable networks , namely , tree-child networks .", "tokens": ["although", "great", "effort", "has", "been", "devoted", "to", "the", "study", "of", "the", "tcp", ",", "it", "has", "been", "shown", "to", "be", "polynomial", "-", "time", "solvable", "only", "for", "a", "couple", "of", "very", "restricted", "subclasses", "of", "stable", "networks", ",", "namely", ",", "tree", "-", "child", "networks", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 65, "end": 67, "i_start": 13, "i_end": 13}, "verb": {"text": "has been shown", "start": 68, "end": 82, "i_start": 14, "i_end": 16}}, {"character": {"text": "subclasses", "start": 151, "end": 161, "i_start": 30, "i_end": 30}, "action": {"text": "solvable", "start": 105, "end": 113, "i_start": 22, "i_end": 22}}], "id": 4751}, {"sent": "the calculations have been performed using density functional theory .", "tokens": ["the", "calculations", "have", "been", "performed", "using", "density", "functional", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the calculations", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "have been performed", "start": 17, "end": 36, "i_start": 2, "i_end": 4}}], "id": 4752}, {"sent": "nice expositions of the theory of strongly regular graphs may be found in eg , .", "tokens": ["nice", "expositions", "of", "the", "theory", "of", "strongly", "regular", "graphs", "may", "be", "found", "in", "eg", ",", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "nice expositions of the theory of strongly regular graphs", "start": 0, "end": 57, "i_start": 0, "i_end": 8}, "verb": {"text": "may be found", "start": 58, "end": 70, "i_start": 9, "i_end": 11}}], "id": 4753}, {"sent": "our models are trained using stochastic gradient descent with adam .", "tokens": ["our", "models", "are", "trained", "using", "stochastic", "gradient", "descent", "with", "adam", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our models", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "are trained", "start": 11, "end": 22, "i_start": 2, "i_end": 3}}], "id": 4754}, {"sent": "deep convolutional neural networks have demonstrated significant improvements over traditional approaches in many pattern recognition tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "demonstrated", "significant", "improvements", "over", "traditional", "approaches", "in", "many", "pattern", "recognition", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have demonstrated", "start": 35, "end": 52, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "demonstrated", "start": 40, "end": 52, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "improvements", "start": 65, "end": 77, "i_start": 7, "i_end": 7}}], "id": 4755}, {"sent": "to address these aforementioned limitations , several works have been proposed to generate images based on object keypoint .", "tokens": ["to", "address", "these", "aforementioned", "limitations", ",", "several", "works", "have", "been", "proposed", "to", "generate", "images", "based", "on", "object", "keypoint", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "several works", "start": 46, "end": 59, "i_start": 6, "i_end": 7}, "verb": {"text": "have been proposed", "start": 60, "end": 78, "i_start": 8, "i_end": 10}}], "id": 4756}, {"sent": "the first one is connected to the displacement of poles in the giant cusp .", "tokens": ["the", "first", "one", "is", "connected", "to", "the", "displacement", "of", "poles", "in", "the", "giant", "cusp", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the first one", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is connected", "start": 14, "end": 26, "i_start": 3, "i_end": 4}}], "id": 4757}, {"sent": "they further explored distributed representations of sentences and documents and showed that variable-length pieces of texts can be represented by a dense fixed-length vector .", "tokens": ["they", "further", "explored", "distributed", "representations", "of", "sentences", "and", "documents", "and", "showed", "that", "variable", "-", "length", "pieces", "of", "texts", "can", "be", "represented", "by", "a", "dense", "fixed", "-", "length", "vector", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "explored", "start": 13, "end": 21, "i_start": 2, "i_end": 2}}, {"subject": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "showed", "start": 81, "end": 87, "i_start": 10, "i_end": 10}}, {"character": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "explored", "start": 13, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "they", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 81, "end": 87, "i_start": 10, "i_end": 10}}], "id": 4758}, {"sent": "this remarkable relation is called the rank-size duality .", "tokens": ["this", "remarkable", "relation", "is", "called", "the", "rank", "-", "size", "duality", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this remarkable relation", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 25, "end": 34, "i_start": 3, "i_end": 4}}], "id": 4759}, {"sent": "are effective in several computer vision tasks such as image segmentation , among others .", "tokens": ["are", "effective", "in", "several", "computer", "vision", "tasks", "such", "as", "image", "segmentation", ",", "among", "others", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4760}, {"sent": "the single and double solid lines represent the propagators of the bare and renormalized fermions , respectively .", "tokens": ["the", "single", "and", "double", "solid", "lines", "represent", "the", "propagators", "of", "the", "bare", "and", "renormalized", "fermions", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the single and double solid lines", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "represent", "start": 34, "end": 43, "i_start": 6, "i_end": 6}}, {"subject": {"text": "the single and double solid lines", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "renormalized", "start": 76, "end": 88, "i_start": 13, "i_end": 13}}, {"character": {"text": "lines", "start": 28, "end": 33, "i_start": 5, "i_end": 5}, "action": {"text": "represent", "start": 34, "end": 43, "i_start": 6, "i_end": 6}}], "id": 4761}, {"sent": "data reduction was carried out within the image reduction and analysis facility software .", "tokens": ["data", "reduction", "was", "carried", "out", "within", "the", "image", "reduction", "and", "analysis", "facility", "software", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "data reduction", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "was carried out", "start": 15, "end": 30, "i_start": 2, "i_end": 4}}], "id": 4762}, {"sent": "since analytical solutions are obtained in this paper , we can apply them to check the accuracy of multi-dimensional relativistic mhd codes .", "tokens": ["since", "analytical", "solutions", "are", "obtained", "in", "this", "paper", ",", "we", "can", "apply", "them", "to", "check", "the", "accuracy", "of", "multi", "-", "dimensional", "relativistic", "mhd", "codes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 56, "end": 58, "i_start": 9, "i_end": 9}, "verb": {"text": "can apply", "start": 59, "end": 68, "i_start": 10, "i_end": 11}}, {"character": {"text": "we", "start": 56, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "apply", "start": 63, "end": 68, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 56, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "check", "start": 77, "end": 82, "i_start": 14, "i_end": 14}}], "id": 4763}, {"sent": "this foliation is the cr-lagrangian foliation associated with the minimal realization .", "tokens": ["this", "foliation", "is", "the", "cr", "-", "lagrangian", "foliation", "associated", "with", "the", "minimal", "realization", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this foliation", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}], "id": 4764}, {"sent": "in recent years , convolutional neural networks s have emerged as the most powerful technique for image classification .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "s", "have", "emerged", "as", "the", "most", "powerful", "technique", "for", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks s", "start": 18, "end": 49, "i_start": 4, "i_end": 7}, "verb": {"text": "have emerged", "start": 50, "end": 62, "i_start": 8, "i_end": 9}}, {"character": {"text": "networks", "start": 39, "end": 47, "i_start": 6, "i_end": 6}, "action": {"text": "emerged", "start": 55, "end": 62, "i_start": 9, "i_end": 9}}], "id": 4765}, {"sent": "recently , deep neural networks achieve excellent performance on difficult problems such as speech recognition .", "tokens": ["recently", ",", "deep", "neural", "networks", "achieve", "excellent", "performance", "on", "difficult", "problems", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "achieve", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "achieve", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "performance", "start": 50, "end": 61, "i_start": 7, "i_end": 7}}], "id": 4766}, {"sent": "the complete prolog translation of the happy problem .", "tokens": ["the", "complete", "prolog", "translation", "of", "the", "happy", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4767}, {"sent": "thus we immediately deduce the following result .", "tokens": ["thus", "we", "immediately", "deduce", "the", "following", "result", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "deduce", "start": 20, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "deduce", "start": 20, "end": 26, "i_start": 3, "i_end": 3}}], "id": 4768}, {"sent": "other methods , such as generative adversarial network , jointly train generative and discriminative models .", "tokens": ["other", "methods", ",", "such", "as", "generative", "adversarial", "network", ",", "jointly", "train", "generative", "and", "discriminative", "models", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "other methods", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "train", "start": 65, "end": 70, "i_start": 10, "i_end": 10}}, {"character": {"text": "methods", "start": 6, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "train", "start": 65, "end": 70, "i_start": 10, "i_end": 10}}, {"character": {"text": "models", "start": 101, "end": 107, "i_start": 14, "i_end": 14}, "action": {"text": "discriminative", "start": 86, "end": 100, "i_start": 13, "i_end": 13}}], "id": 4769}, {"sent": "the ellipses denote terms that are subleading relative to this term .", "tokens": ["the", "ellipses", "denote", "terms", "that", "are", "subleading", "relative", "to", "this", "term", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ellipses", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "denote", "start": 13, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "ellipses", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 13, "end": 19, "i_start": 2, "i_end": 2}}], "id": 4770}, {"sent": "convolutional neural networks have witnessed great improvement on a series of vision tasks such as object classification .", "tokens": ["convolutional", "neural", "networks", "have", "witnessed", "great", "improvement", "on", "a", "series", "of", "vision", "tasks", "such", "as", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have witnessed", "start": 30, "end": 44, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "witnessed", "start": 35, "end": 44, "i_start": 4, "i_end": 4}}], "id": 4771}, {"sent": "fortunately , the degeneracy is resolved when informations from the far detector is combined .", "tokens": ["fortunately", ",", "the", "degeneracy", "is", "resolved", "when", "informations", "from", "the", "far", "detector", "is", "combined", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the degeneracy", "start": 14, "end": 28, "i_start": 2, "i_end": 3}, "verb": {"text": "is resolved", "start": 29, "end": 40, "i_start": 4, "i_end": 5}}], "id": 4772}, {"sent": "for the svm and other experiments , we used the implementation from scikit-learn .", "tokens": ["for", "the", "svm", "and", "other", "experiments", ",", "we", "used", "the", "implementation", "from", "scikit", "-", "learn", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 36, "end": 38, "i_start": 7, "i_end": 7}, "verb": {"text": "used", "start": 39, "end": 43, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 36, "end": 38, "i_start": 7, "i_end": 7}, "action": {"text": "used", "start": 39, "end": 43, "i_start": 8, "i_end": 8}}], "id": 4773}, {"sent": "thus we have given methods to construct non-associative birings .", "tokens": ["thus", "we", "have", "given", "methods", "to", "construct", "non", "-", "associative", "birings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "have given", "start": 8, "end": 18, "i_start": 2, "i_end": 3}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "given", "start": 13, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "construct", "start": 30, "end": 39, "i_start": 6, "i_end": 6}}], "id": 4774}, {"sent": "the rgb image of the object is fed into a feature extraction layers based on resnet-50 .", "tokens": ["the", "rgb", "image", "of", "the", "object", "is", "fed", "into", "a", "feature", "extraction", "layers", "based", "on", "resnet-50", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the rgb image of the object", "start": 0, "end": 27, "i_start": 0, "i_end": 5}, "verb": {"text": "is fed", "start": 28, "end": 34, "i_start": 6, "i_end": 7}}], "id": 4775}, {"sent": "an alternative is the dataset of , but it only consists of 54 images and only few of the images contain objects .", "tokens": ["an", "alternative", "is", "the", "dataset", "of", ",", "but", "it", "only", "consists", "of", "54", "images", "and", "only", "few", "of", "the", "images", "contain", "objects", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an alternative", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "it", "start": 39, "end": 41, "i_start": 8, "i_end": 8}, "verb": {"text": "consists", "start": 47, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "images", "start": 89, "end": 95, "i_start": 19, "i_end": 19}, "action": {"text": "contain", "start": 96, "end": 103, "i_start": 20, "i_end": 20}}], "id": 4776}, {"sent": "the trainable parameters are initialized using the glorot algorithm .", "tokens": ["the", "trainable", "parameters", "are", "initialized", "using", "the", "glorot", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the trainable parameters", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "are initialized", "start": 25, "end": 40, "i_start": 3, "i_end": 4}}], "id": 4777}, {"sent": "however , this approach causes the exposure bias , which results in error accumulation during generation at test time , since the model has never been exposed to its own predictions .", "tokens": ["however", ",", "this", "approach", "causes", "the", "exposure", "bias", ",", "which", "results", "in", "error", "accumulation", "during", "generation", "at", "test", "time", ",", "since", "the", "model", "has", "never", "been", "exposed", "to", "its", "own", "predictions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this approach", "start": 10, "end": 23, "i_start": 2, "i_end": 3}, "verb": {"text": "causes", "start": 24, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "approach", "start": 15, "end": 23, "i_start": 3, "i_end": 3}, "action": {"text": "causes", "start": 24, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "model", "start": 130, "end": 135, "i_start": 22, "i_end": 22}, "action": {"text": "predictions", "start": 170, "end": 181, "i_start": 30, "i_end": 30}}], "id": 4778}, {"sent": "generally , the real life networks are inhomogeneous .", "tokens": ["generally", ",", "the", "real", "life", "networks", "are", "inhomogeneous", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the real life networks", "start": 12, "end": 34, "i_start": 2, "i_end": 5}, "verb": {"text": "are", "start": 35, "end": 38, "i_start": 6, "i_end": 6}}], "id": 4779}, {"sent": "a cnn feature based lstm model for action recognition is presented in .", "tokens": ["a", "cnn", "feature", "based", "lstm", "model", "for", "action", "recognition", "is", "presented", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a cnn feature based lstm model for action recognition", "start": 0, "end": 53, "i_start": 0, "i_end": 8}, "verb": {"text": "is presented", "start": 54, "end": 66, "i_start": 9, "i_end": 10}}], "id": 4780}, {"sent": "hinton et al proposed deep belief networks with a learning algorithm that trains one layer at a time .", "tokens": ["hinton", "et", "al", "proposed", "deep", "belief", "networks", "with", "a", "learning", "algorithm", "that", "trains", "one", "layer", "at", "a", "time", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hinton et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "hinton", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 13, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithm", "start": 59, "end": 68, "i_start": 10, "i_end": 10}, "action": {"text": "learning", "start": 50, "end": 58, "i_start": 9, "i_end": 9}}, {"character": {"text": "algorithm", "start": 59, "end": 68, "i_start": 10, "i_end": 10}, "action": {"text": "trains", "start": 74, "end": 80, "i_start": 12, "i_end": 12}}], "id": 4781}, {"sent": "this is not surprising , indeed , as the analysis in is an extension of the berger-tung problem .", "tokens": ["this", "is", "not", "surprising", ",", "indeed", ",", "as", "the", "analysis", "in", "is", "an", "extension", "of", "the", "berger", "-", "tung", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is not", "start": 5, "end": 11, "i_start": 1, "i_end": 2}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "not surprising", "start": 8, "end": 22, "i_start": 2, "i_end": 3}}, {"character": {"text": "analysis", "start": 41, "end": 49, "i_start": 9, "i_end": 9}, "action": {"text": "extension", "start": 59, "end": 68, "i_start": 13, "i_end": 13}}], "id": 4782}, {"sent": "dashed lines refers to the lower unstable branches of the splay state .", "tokens": ["dashed", "lines", "refers", "to", "the", "lower", "unstable", "branches", "of", "the", "splay", "state", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "dashed lines", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "refers", "start": 13, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "lines", "start": 7, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "refers", "start": 13, "end": 19, "i_start": 2, "i_end": 2}}], "id": 4783}, {"sent": "we will consider only the case of zero magnetic field .", "tokens": ["we", "will", "consider", "only", "the", "case", "of", "zero", "magnetic", "field", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will consider", "start": 3, "end": 16, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "consider", "start": 8, "end": 16, "i_start": 2, "i_end": 2}}], "id": 4784}, {"sent": "the most common approach to quantifying privacy guarantees in this setting is through -differential privacy .", "tokens": ["the", "most", "common", "approach", "to", "quantifying", "privacy", "guarantees", "in", "this", "setting", "is", "through", "-differential", "privacy", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the most common approach to quantifying privacy guarantees in this setting", "start": 0, "end": 74, "i_start": 0, "i_end": 10}, "verb": {"text": "is", "start": 75, "end": 77, "i_start": 11, "i_end": 11}}], "id": 4785}, {"sent": "neural networks have enjoyed great success in many practical applications .", "tokens": ["neural", "networks", "have", "enjoyed", "great", "success", "in", "many", "practical", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have enjoyed", "start": 16, "end": 28, "i_start": 2, "i_end": 3}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "enjoyed", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "success", "start": 35, "end": 42, "i_start": 5, "i_end": 5}}], "id": 4786}, {"sent": "in variational inference , the update for a latent variable depends on the variational expectation of terms in the joint distribution where that variable appears .", "tokens": ["in", "variational", "inference", ",", "the", "update", "for", "a", "latent", "variable", "depends", "on", "the", "variational", "expectation", "of", "terms", "in", "the", "joint", "distribution", "where", "that", "variable", "appears", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the update for a latent variable", "start": 27, "end": 59, "i_start": 4, "i_end": 9}, "verb": {"text": "depends", "start": 60, "end": 67, "i_start": 10, "i_end": 10}}, {"character": {"text": "update", "start": 31, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "depends", "start": 60, "end": 67, "i_start": 10, "i_end": 10}}], "id": 4787}, {"sent": "van dam and haemers conjectured that almost all graphs are determined by their spectra .", "tokens": ["van", "dam", "and", "haemers", "conjectured", "that", "almost", "all", "graphs", "are", "determined", "by", "their", "spectra", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "van dam and haemers", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "conjectured", "start": 20, "end": 31, "i_start": 4, "i_end": 4}}, {"subject": {"text": "almost all graphs", "start": 37, "end": 54, "i_start": 6, "i_end": 8}, "verb": {"text": "determined", "start": 59, "end": 69, "i_start": 10, "i_end": 10}}, {"character": {"text": "van dam", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "action": {"text": "conjectured", "start": 20, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "haemers", "start": 12, "end": 19, "i_start": 3, "i_end": 3}, "action": {"text": "conjectured", "start": 20, "end": 31, "i_start": 4, "i_end": 4}}, {"character": {"text": "spectra", "start": 79, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "determined", "start": 59, "end": 69, "i_start": 10, "i_end": 10}}], "id": 4788}, {"sent": "the acquisition of this training data is a painstaking process that requires long hours of manual labor and there is thus a strong interest in developing methods that require less groundtruth data .", "tokens": ["the", "acquisition", "of", "this", "training", "data", "is", "a", "painstaking", "process", "that", "requires", "long", "hours", "of", "manual", "labor", "and", "there", "is", "thus", "a", "strong", "interest", "in", "developing", "methods", "that", "require", "less", "groundtruth", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the acquisition of this training data", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "process", "start": 55, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "requires", "start": 68, "end": 76, "i_start": 11, "i_end": 11}}, {"character": {"text": "methods", "start": 154, "end": 161, "i_start": 26, "i_end": 26}, "action": {"text": "require", "start": 167, "end": 174, "i_start": 28, "i_end": 28}}], "id": 4789}, {"sent": "stefanescu , jk hwang , xl che , sj zhu , pm gore , ef jones , d .", "tokens": ["stefanescu", ",", "jk", "hwang", ",", "xl", "che", ",", "sj", "zhu", ",", "pm", "gore", ",", "ef", "jones", ",", "d", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4790}, {"sent": "our models are trained using stochastic gradient descent with adam .", "tokens": ["our", "models", "are", "trained", "using", "stochastic", "gradient", "descent", "with", "adam", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our models", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "are trained", "start": 11, "end": 22, "i_start": 2, "i_end": 3}}], "id": 4791}, {"sent": "exchange and correlation were treated within the generalized gradient approximation using the parametrization of perdew , burke , and ernzerhof .", "tokens": ["exchange", "and", "correlation", "were", "treated", "within", "the", "generalized", "gradient", "approximation", "using", "the", "parametrization", "of", "perdew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "exchange and correlation", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "were treated", "start": 25, "end": 37, "i_start": 3, "i_end": 4}}], "id": 4792}, {"sent": "the resulting magnetization profiles were studied in various integrable spin models such as the xx chain , the transverse ising .", "tokens": ["the", "resulting", "magnetization", "profiles", "were", "studied", "in", "various", "integrable", "spin", "models", "such", "as", "the", "xx", "chain", ",", "the", "transverse", "ising", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the resulting magnetization profiles", "start": 0, "end": 36, "i_start": 0, "i_end": 3}, "verb": {"text": "were studied", "start": 37, "end": 49, "i_start": 4, "i_end": 5}}], "id": 4793}, {"sent": "deep convolutional neural networks have seen great success in a range of computer vision tasks , including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "seen", "great", "success", "in", "a", "range", "of", "computer", "vision", "tasks", ",", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have seen", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "seen", "start": 40, "end": 44, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 51, "end": 58, "i_start": 7, "i_end": 7}}], "id": 4794}, {"sent": "since the advent of quantum key distribution by bennett and brassard , a variety of other secure quantum communication protocols has emerged .", "tokens": ["since", "the", "advent", "of", "quantum", "key", "distribution", "by", "bennett", "and", "brassard", ",", "a", "variety", "of", "other", "secure", "quantum", "communication", "protocols", "has", "emerged", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "a variety of other secure quantum communication protocols", "start": 71, "end": 128, "i_start": 12, "i_end": 19}, "verb": {"text": "has emerged", "start": 129, "end": 140, "i_start": 20, "i_end": 21}}, {"character": {"text": "protocols", "start": 119, "end": 128, "i_start": 19, "i_end": 19}, "action": {"text": "emerged", "start": 133, "end": 140, "i_start": 21, "i_end": 21}}, {"character": {"text": "bennett", "start": 48, "end": 55, "i_start": 8, "i_end": 8}, "action": {"text": "distribution", "start": 32, "end": 44, "i_start": 6, "i_end": 6}}, {"character": {"text": "brassard", "start": 60, "end": 68, "i_start": 10, "i_end": 10}, "action": {"text": "distribution", "start": 32, "end": 44, "i_start": 6, "i_end": 6}}], "id": 4795}, {"sent": "we implement our egocam cnn using a popular resnet-101 architecture .", "tokens": ["we", "implement", "our", "egocam", "cnn", "using", "a", "popular", "resnet-101", "architecture", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 28, "end": 33, "i_start": 5, "i_end": 5}}], "id": 4796}, {"sent": "the unitary fermi gas , consisting of non-relativistic fermionic particles of two species with equal mass , has been studied intensively during the last decade .", "tokens": ["the", "unitary", "fermi", "gas", ",", "consisting", "of", "non", "-", "relativistic", "fermionic", "particles", "of", "two", "species", "with", "equal", "mass", ",", "has", "been", "studied", "intensively", "during", "the", "last", "decade", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the unitary fermi gas", "start": 0, "end": 21, "i_start": 0, "i_end": 3}, "verb": {"text": "has been studied", "start": 108, "end": 124, "i_start": 19, "i_end": 21}}], "id": 4797}, {"sent": "the following example makes this more explicit .", "tokens": ["the", "following", "example", "makes", "this", "more", "explicit", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the following example", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "makes", "start": 22, "end": 27, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the following example", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "explicit", "start": 38, "end": 46, "i_start": 6, "i_end": 6}}, {"character": {"text": "example", "start": 14, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "makes", "start": 22, "end": 27, "i_start": 3, "i_end": 3}}], "id": 4798}, {"sent": "the interest in such channels has been rising since the seminal work of koetter and kschischang , which connects finite-field matrix channels to the problem of error control in noncoherent network coding .", "tokens": ["the", "interest", "in", "such", "channels", "has", "been", "rising", "since", "the", "seminal", "work", "of", "koetter", "and", "kschischang", ",", "which", "connects", "finite", "-", "field", "matrix", "channels", "to", "the", "problem", "of", "error", "control", "in", "noncoherent", "network", "coding", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the interest in such channels", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "has been rising", "start": 30, "end": 45, "i_start": 5, "i_end": 7}}, {"character": {"text": "koetter", "start": 72, "end": 79, "i_start": 13, "i_end": 13}, "action": {"text": "work", "start": 64, "end": 68, "i_start": 11, "i_end": 11}}, {"character": {"text": "kschischang", "start": 84, "end": 95, "i_start": 15, "i_end": 15}, "action": {"text": "work", "start": 64, "end": 68, "i_start": 11, "i_end": 11}}, {"character": {"text": "work", "start": 64, "end": 68, "i_start": 11, "i_end": 11}, "action": {"text": "connects", "start": 104, "end": 112, "i_start": 18, "i_end": 18}}], "id": 4799}, {"sent": "the world-sheet is a direct extension of the concept of the world line in the case of a point particle .", "tokens": ["the", "world", "-", "sheet", "is", "a", "direct", "extension", "of", "the", "concept", "of", "the", "world", "line", "in", "the", "case", "of", "a", "point", "particle", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the world-sheet", "start": 0, "end": 15, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 4, "i_end": 4}}], "id": 4800}, {"sent": "for the second , we need soft magnetic materials or superconducting shields .", "tokens": ["for", "the", "second", ",", "we", "need", "soft", "magnetic", "materials", "or", "superconducting", "shields", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 17, "end": 19, "i_start": 4, "i_end": 4}, "verb": {"text": "need", "start": 20, "end": 24, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 17, "end": 19, "i_start": 4, "i_end": 4}, "action": {"text": "need", "start": 20, "end": 24, "i_start": 5, "i_end": 5}}], "id": 4801}, {"sent": "goodfellow et al introduced the fast gradient sign method to find adversarial perturbations .", "tokens": ["goodfellow", "et", "al", "introduced", "the", "fast", "gradient", "sign", "method", "to", "find", "adversarial", "perturbations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "goodfellow et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "introduced", "start": 17, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "goodfellow", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 17, "end": 27, "i_start": 3, "i_end": 3}}], "id": 4802}, {"sent": "recent achievements of deep neural networks make them an attractive choice in many computer vision applications including image classification .", "tokens": ["recent", "achievements", "of", "deep", "neural", "networks", "make", "them", "an", "attractive", "choice", "in", "many", "computer", "vision", "applications", "including", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent achievements of deep neural networks", "start": 0, "end": 43, "i_start": 0, "i_end": 5}, "verb": {"text": "make", "start": 44, "end": 48, "i_start": 6, "i_end": 6}}, {"character": {"text": "achievements", "start": 7, "end": 19, "i_start": 1, "i_end": 1}, "action": {"text": "make", "start": 44, "end": 48, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 35, "end": 43, "i_start": 5, "i_end": 5}, "action": {"text": "achievements", "start": 7, "end": 19, "i_start": 1, "i_end": 1}}], "id": 4803}, {"sent": "in this section we demonstrate experimentally how the proposed method improves preliminary clustering results by sparse subspace clustering .", "tokens": ["in", "this", "section", "we", "demonstrate", "experimentally", "how", "the", "proposed", "method", "improves", "preliminary", "clustering", "results", "by", "sparse", "subspace", "clustering", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "demonstrate", "start": 19, "end": 30, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the proposed method", "start": 50, "end": 69, "i_start": 7, "i_end": 9}, "verb": {"text": "improves", "start": 70, "end": 78, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "demonstrate", "start": 19, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "method", "start": 63, "end": 69, "i_start": 9, "i_end": 9}, "action": {"text": "improves", "start": 70, "end": 78, "i_start": 10, "i_end": 10}}], "id": 4804}, {"sent": "in fact , as blecher showed , the inner product can be recovered from the module and banach space structures .", "tokens": ["in", "fact", ",", "as", "blecher", "showed", ",", "the", "inner", "product", "can", "be", "recovered", "from", "the", "module", "and", "banach", "space", "structures", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the inner product", "start": 30, "end": 47, "i_start": 7, "i_end": 9}, "verb": {"text": "can be recovered", "start": 48, "end": 64, "i_start": 10, "i_end": 12}}, {"character": {"text": "blecher", "start": 13, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "showed", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}], "id": 4805}, {"sent": "the other geodesic is the reflection of this one along \u03b3 , according to the laws of geometric optics .", "tokens": ["the", "other", "geodesic", "is", "the", "reflection", "of", "this", "one", "along", "\u03b3", ",", "according", "to", "the", "laws", "of", "geometric", "optics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the other geodesic", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 4806}, {"sent": "when the distance scale under consideration is much larger than the length scale given by the coordinate noncommutativity , the effects of the latter should be negligible .", "tokens": ["when", "the", "distance", "scale", "under", "consideration", "is", "much", "larger", "than", "the", "length", "scale", "given", "by", "the", "coordinate", "noncommutativity", ",", "the", "effects", "of", "the", "latter", "should", "be", "negligible", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the effects of the latter", "start": 124, "end": 149, "i_start": 19, "i_end": 23}, "verb": {"text": "should be", "start": 150, "end": 159, "i_start": 24, "i_end": 25}}, {"character": {"text": "noncommutativity", "start": 105, "end": 121, "i_start": 17, "i_end": 17}, "action": {"text": "given", "start": 81, "end": 86, "i_start": 13, "i_end": 13}}], "id": 4807}, {"sent": "for a geometric treatment of the cohen-macaulay property , we refer the reader to the excellent book of eisenbud .", "tokens": ["for", "a", "geometric", "treatment", "of", "the", "cohen", "-", "macaulay", "property", ",", "we", "refer", "the", "reader", "to", "the", "excellent", "book", "of", "eisenbud", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 59, "end": 61, "i_start": 11, "i_end": 11}, "verb": {"text": "refer", "start": 62, "end": 67, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 59, "end": 61, "i_start": 11, "i_end": 11}, "action": {"text": "refer", "start": 62, "end": 67, "i_start": 12, "i_end": 12}}], "id": 4808}, {"sent": "the genus of m is the minimal genus required for a splitting surface of m .", "tokens": ["the", "genus", "of", "m", "is", "the", "minimal", "genus", "required", "for", "a", "splitting", "surface", "of", "m", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the genus of m", "start": 0, "end": 14, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 4, "i_end": 4}}, {"character": {"text": "surface", "start": 61, "end": 68, "i_start": 12, "i_end": 12}, "action": {"text": "required", "start": 36, "end": 44, "i_start": 8, "i_end": 8}}], "id": 4809}, {"sent": "convolutional neural networks have achieved roughly human-level or better performance on vision tasks , particularly classification .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "roughly", "human", "-", "level", "or", "better", "performance", "on", "vision", "tasks", ",", "particularly", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 35, "end": 43, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 74, "end": 85, "i_start": 11, "i_end": 11}}], "id": 4810}, {"sent": "the geometrical relaxations are carried out within the framework of density-functional theory , as implemented in the vienna ab initio simulation package code .", "tokens": ["the", "geometrical", "relaxations", "are", "carried", "out", "within", "the", "framework", "of", "density", "-", "functional", "theory", ",", "as", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "code", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the geometrical relaxations", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "are carried out", "start": 28, "end": 43, "i_start": 3, "i_end": 5}}], "id": 4811}, {"sent": "adam is used as our optimizer with a learning rate of 1e-5 and a batch size of 32 or 16 .", "tokens": ["adam", "is", "used", "as", "our", "optimizer", "with", "a", "learning", "rate", "of", "1e-5", "and", "a", "batch", "size", "of", "32", "or", "16", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "adam", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is used", "start": 5, "end": 12, "i_start": 1, "i_end": 2}}, {"character": {"text": "adam", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "optimizer", "start": 20, "end": 29, "i_start": 5, "i_end": 5}}], "id": 4812}, {"sent": "for instance , bloom have applied commutator theory to give a compactness characterization of hankel operators on holomorphic hardy spacesh 2 , where d is a bounded , strictly pseudoconvex domain in c n .", "tokens": ["for", "instance", ",", "bloom", "have", "applied", "commutator", "theory", "to", "give", "a", "compactness", "characterization", "of", "hankel", "operators", "on", "holomorphic", "hardy", "spacesh", "2", ",", "where", "d", "is", "a", "bounded", ",", "strictly", "pseudoconvex", "domain", "in", "c", "n", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "bloom", "start": 15, "end": 20, "i_start": 3, "i_end": 3}, "verb": {"text": "have applied", "start": 21, "end": 33, "i_start": 4, "i_end": 5}}, {"character": {"text": "compactness", "start": 62, "end": 73, "i_start": 11, "i_end": 11}, "action": {"text": "applied", "start": 26, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "compactness", "start": 62, "end": 73, "i_start": 11, "i_end": 11}, "action": {"text": "characterization", "start": 74, "end": 90, "i_start": 12, "i_end": 12}}], "id": 4813}, {"sent": "a landmark paper has shown that certain nonlinear binary codes with excellent error-correcting capabilities can be identified as images of linear codes over z 4 under the gray map .", "tokens": ["a", "landmark", "paper", "has", "shown", "that", "certain", "nonlinear", "binary", "codes", "with", "excellent", "error", "-", "correcting", "capabilities", "can", "be", "identified", "as", "images", "of", "linear", "codes", "over", "z", "4", "under", "the", "gray", "map", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a landmark paper", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "has shown", "start": 17, "end": 26, "i_start": 3, "i_end": 4}}, {"subject": {"text": "certain nonlinear binary codes with excellent error-correcting capabilities", "start": 32, "end": 107, "i_start": 6, "i_end": 15}, "verb": {"text": "identified", "start": 115, "end": 125, "i_start": 18, "i_end": 18}}, {"character": {"text": "paper", "start": 11, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 21, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "codes", "start": 57, "end": 62, "i_start": 9, "i_end": 9}, "action": {"text": "has", "start": 17, "end": 20, "i_start": 3, "i_end": 3}}], "id": 4814}, {"sent": "the authors of the paper has shown that if the number of rf chains is twice the multiplexing order , then the hybrid beamformer is capable of implementing any fully digital beamformer .", "tokens": ["the", "authors", "of", "the", "paper", "has", "shown", "that", "if", "the", "number", "of", "rf", "chains", "is", "twice", "the", "multiplexing", "order", ",", "then", "the", "hybrid", "beamformer", "is", "capable", "of", "implementing", "any", "fully", "digital", "beamformer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors of the paper", "start": 0, "end": 24, "i_start": 0, "i_end": 4}, "verb": {"text": "has shown", "start": 25, "end": 34, "i_start": 5, "i_end": 6}}, {"subject": {"text": "the authors of the paper", "start": 0, "end": 24, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 128, "end": 130, "i_start": 24, "i_end": 24}}, {"character": {"text": "beamformer", "start": 117, "end": 127, "i_start": 23, "i_end": 23}, "action": {"text": "implementing", "start": 142, "end": 154, "i_start": 27, "i_end": 27}}], "id": 4815}, {"sent": "pathak et al address the image inpainting problem which predicts missing pixels in an image , by training a context en- coder .", "tokens": ["pathak", "et", "al", "address", "the", "image", "inpainting", "problem", "which", "predicts", "missing", "pixels", "in", "an", "image", ",", "by", "training", "a", "context", "en-", "coder", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "pathak et al", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "address", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "pathak", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "address", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "problem", "start": 42, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "predicts", "start": 56, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "pathak", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "training", "start": 97, "end": 105, "i_start": 17, "i_end": 17}}], "id": 4816}, {"sent": "polar codes were introduced by arikan and provided a scheme for achieving the symmetric capacity of binary memoryless channels with polynomial encoding and decoding complexity .", "tokens": ["polar", "codes", "were", "introduced", "by", "arikan", "and", "provided", "a", "scheme", "for", "achieving", "the", "symmetric", "capacity", "of", "binary", "memoryless", "channels", "with", "polynomial", "encoding", "and", "decoding", "complexity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "polar codes", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "were introduced", "start": 12, "end": 27, "i_start": 2, "i_end": 3}}, {"subject": {"text": "polar codes", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "provided", "start": 42, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "arikan", "start": 31, "end": 37, "i_start": 5, "i_end": 5}, "action": {"text": "introduced", "start": 17, "end": 27, "i_start": 3, "i_end": 3}}, {"character": {"text": "codes", "start": 6, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "provided", "start": 42, "end": 50, "i_start": 7, "i_end": 7}}], "id": 4817}, {"sent": "pardoux , stochastic calculus with anticipating integrands .", "tokens": ["pardoux", ",", "stochastic", "calculus", "with", "anticipating", "integrands", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4818}, {"sent": "recently , deep convolutional neural networks have attracted much research attention in visual recognition , largely due to their excellent performance .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "attracted", "much", "research", "attention", "in", "visual", "recognition", ",", "largely", "due", "to", "their", "excellent", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have attracted", "start": 46, "end": 60, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "attracted", "start": 51, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 140, "end": 151, "i_start": 20, "i_end": 20}}], "id": 4819}, {"sent": "one popular architecture for learning such an embedding is word2vec .", "tokens": ["one", "popular", "architecture", "for", "learning", "such", "an", "embedding", "is", "word2vec", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one popular architecture for learning such an embedding", "start": 0, "end": 55, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 56, "end": 58, "i_start": 8, "i_end": 8}}], "id": 4820}, {"sent": "jerrum , sinclair , and vigoda in a breakthrough obtained a fully polynomial time randomized approximation scheme for the permanent of matrices with nonnegative entries .", "tokens": ["jerrum", ",", "sinclair", ",", "and", "vigoda", "in", "a", "breakthrough", "obtained", "a", "fully", "polynomial", "time", "randomized", "approximation", "scheme", "for", "the", "permanent", "of", "matrices", "with", "nonnegative", "entries", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "jerrum", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "obtained", "start": 49, "end": 57, "i_start": 9, "i_end": 9}}, {"character": {"text": "jerrum", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "obtained", "start": 49, "end": 57, "i_start": 9, "i_end": 9}}, {"character": {"text": "sinclair", "start": 9, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "obtained", "start": 49, "end": 57, "i_start": 9, "i_end": 9}}, {"character": {"text": "vigoda", "start": 24, "end": 30, "i_start": 5, "i_end": 5}, "action": {"text": "obtained", "start": 49, "end": 57, "i_start": 9, "i_end": 9}}], "id": 4821}, {"sent": "but showed , using numerical experiments , that this statement is not true in general .", "tokens": ["but", "showed", ",", "using", "numerical", "experiments", ",", "that", "this", "statement", "is", "not", "true", "in", "general", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4822}, {"sent": "we follow the standard evaluation protocol by and perform recognition on only the words containing only alphanumeric characters and at least three characters .", "tokens": ["we", "follow", "the", "standard", "evaluation", "protocol", "by", "and", "perform", "recognition", "on", "only", "the", "words", "containing", "only", "alphanumeric", "characters", "and", "at", "least", "three", "characters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "perform", "start": 50, "end": 57, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "recognition", "start": 58, "end": 69, "i_start": 9, "i_end": 9}}, {"character": {"text": "words", "start": 82, "end": 87, "i_start": 13, "i_end": 13}, "action": {"text": "containing", "start": 88, "end": 98, "i_start": 14, "i_end": 14}}], "id": 4823}, {"sent": "a matroid is a lattice path matroid if and only if it is transversal and some presentation is an antichain of intervals in a linear order on the ground set .", "tokens": ["a", "matroid", "is", "a", "lattice", "path", "matroid", "if", "and", "only", "if", "it", "is", "transversal", "and", "some", "presentation", "is", "an", "antichain", "of", "intervals", "in", "a", "linear", "order", "on", "the", "ground", "set", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a matroid", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}], "id": 4824}, {"sent": "in this section , we focus on proving the following lemma .", "tokens": ["in", "this", "section", ",", "we", "focus", "on", "proving", "the", "following", "lemma", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "focus", "start": 21, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "focus", "start": 21, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "proving", "start": 30, "end": 37, "i_start": 7, "i_end": 7}}], "id": 4825}, {"sent": "recent successes of deep neural networks have spanned many domains , from computer vision and many other tasks .", "tokens": ["recent", "successes", "of", "deep", "neural", "networks", "have", "spanned", "many", "domains", ",", "from", "computer", "vision", "and", "many", "other", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent successes of deep neural networks", "start": 0, "end": 40, "i_start": 0, "i_end": 5}, "verb": {"text": "have spanned", "start": 41, "end": 53, "i_start": 6, "i_end": 7}}, {"character": {"text": "successes", "start": 7, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "spanned", "start": 46, "end": 53, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "successes", "start": 7, "end": 16, "i_start": 1, "i_end": 1}}], "id": 4826}, {"sent": "saturation is the effect of decrease of the amplification coefficient of the pmt for high light intensities .", "tokens": ["saturation", "is", "the", "effect", "of", "decrease", "of", "the", "amplification", "coefficient", "of", "the", "pmt", "for", "high", "light", "intensities", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "saturation", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 1, "i_end": 1}}], "id": 4827}, {"sent": "notably , we showed cold condensations allow to reconstruct the sky maps very accurately , in spite of the large amount of self-correlated noise present in the timelines .", "tokens": ["notably", ",", "we", "showed", "cold", "condensations", "allow", "to", "reconstruct", "the", "sky", "maps", "very", "accurately", ",", "in", "spite", "of", "the", "large", "amount", "of", "self", "-", "correlated", "noise", "present", "in", "the", "timelines", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "showed", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "cold condensations", "start": 20, "end": 38, "i_start": 4, "i_end": 5}, "verb": {"text": "allow", "start": 39, "end": 44, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "showed", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "condensations", "start": 25, "end": 38, "i_start": 5, "i_end": 5}, "action": {"text": "allow", "start": 39, "end": 44, "i_start": 6, "i_end": 6}}], "id": 4828}, {"sent": "the exchange correlation effect was described using the perdew-burkeernzerhof within generalized gradient approximation .", "tokens": ["the", "exchange", "correlation", "effect", "was", "described", "using", "the", "perdew", "-", "burkeernzerhof", "within", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange correlation effect", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "was described", "start": 32, "end": 45, "i_start": 4, "i_end": 5}}], "id": 4829}, {"sent": "deep neural networks perform impressively well in classic machine learning areas such as image classification , segmentation , speech recognition and language translation .", "tokens": ["deep", "neural", "networks", "perform", "impressively", "well", "in", "classic", "machine", "learning", "areas", "such", "as", "image", "classification", ",", "segmentation", ",", "speech", "recognition", "and", "language", "translation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "perform", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "perform", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}], "id": 4830}, {"sent": "the field fp is the algebraic closure of the field of p elements for the prime p .", "tokens": ["the", "field", "fp", "is", "the", "algebraic", "closure", "of", "the", "field", "of", "p", "elements", "for", "the", "prime", "p", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the field fp", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 3, "i_end": 3}}], "id": 4831}, {"sent": "the photon selected is the most energetic one in the events .", "tokens": ["the", "photon", "selected", "is", "the", "most", "energetic", "one", "in", "the", "events", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the photon selected", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 4832}, {"sent": "the category c is defined to be the category of symmetric t-spectra in cpx , with the stable model structure defined in .", "tokens": ["the", "category", "c", "is", "defined", "to", "be", "the", "category", "of", "symmetric", "t", "-", "spectra", "in", "cpx", ",", "with", "the", "stable", "model", "structure", "defined", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the category c", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "is defined", "start": 15, "end": 25, "i_start": 3, "i_end": 4}}], "id": 4833}, {"sent": "the data were reduced using the herschel interactive processing environment and the hermes smap package .", "tokens": ["the", "data", "were", "reduced", "using", "the", "herschel", "interactive", "processing", "environment", "and", "the", "hermes", "smap", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the data", "start": 0, "end": 8, "i_start": 0, "i_end": 1}, "verb": {"text": "were reduced", "start": 9, "end": 21, "i_start": 2, "i_end": 3}}], "id": 4834}, {"sent": "we adopt two different methods to estimate the energy that can possibly be released by the internal magnetic fields of the cmes .", "tokens": ["we", "adopt", "two", "different", "methods", "to", "estimate", "the", "energy", "that", "can", "possibly", "be", "released", "by", "the", "internal", "magnetic", "fields", "of", "the", "cmes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "estimate", "start": 34, "end": 42, "i_start": 6, "i_end": 6}}, {"character": {"text": "fields", "start": 109, "end": 115, "i_start": 18, "i_end": 18}, "action": {"text": "released", "start": 75, "end": 83, "i_start": 13, "i_end": 13}}], "id": 4835}, {"sent": "we will illustrate these by suitable examples .", "tokens": ["we", "will", "illustrate", "these", "by", "suitable", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will illustrate", "start": 3, "end": 18, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "illustrate", "start": 8, "end": 18, "i_start": 2, "i_end": 2}}], "id": 4836}, {"sent": "deep neural networks with great success have been applied to many practical problems in computer vision .", "tokens": ["deep", "neural", "networks", "with", "great", "success", "have", "been", "applied", "to", "many", "practical", "problems", "in", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks with great success", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "have been applied", "start": 40, "end": 57, "i_start": 6, "i_end": 8}}], "id": 4837}, {"sent": "mackenzie , general theory of lie groupoids and lie algebroids , london math .", "tokens": ["mackenzie", ",", "general", "theory", "of", "lie", "groupoids", "and", "lie", "algebroids", ",", "london", "math", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4838}, {"sent": "instead , we use the bag of words representation to describe each brain region , which calculates the histogram of representative patterns over all patches in this region .", "tokens": ["instead", ",", "we", "use", "the", "bag", "of", "words", "representation", "to", "describe", "each", "brain", "region", ",", "which", "calculates", "the", "histogram", "of", "representative", "patterns", "over", "all", "patches", "in", "this", "region", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "use", "start": 13, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 13, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "bag", "start": 21, "end": 24, "i_start": 5, "i_end": 5}, "action": {"text": "representation", "start": 34, "end": 48, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "describe", "start": 52, "end": 60, "i_start": 10, "i_end": 10}}, {"character": {"text": "region", "start": 72, "end": 78, "i_start": 13, "i_end": 13}, "action": {"text": "calculates", "start": 87, "end": 97, "i_start": 16, "i_end": 16}}, {"character": {"text": "patterns", "start": 130, "end": 138, "i_start": 21, "i_end": 21}, "action": {"text": "representative", "start": 115, "end": 129, "i_start": 20, "i_end": 20}}], "id": 4839}, {"sent": "in recent years , deep neural networks based models have demonstrated a significant improvement in state-ofthe-art results for several vision tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "based", "models", "have", "demonstrated", "a", "significant", "improvement", "in", "state", "-", "ofthe", "-", "art", "results", "for", "several", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks based models", "start": 18, "end": 51, "i_start": 4, "i_end": 8}, "verb": {"text": "have demonstrated", "start": 52, "end": 69, "i_start": 9, "i_end": 10}}, {"character": {"text": "models", "start": 45, "end": 51, "i_start": 8, "i_end": 8}, "action": {"text": "demonstrated", "start": 57, "end": 69, "i_start": 10, "i_end": 10}}, {"character": {"text": "models", "start": 45, "end": 51, "i_start": 8, "i_end": 8}, "action": {"text": "improvement", "start": 84, "end": 95, "i_start": 13, "i_end": 13}}], "id": 4840}, {"sent": "in this section , we will discuss moduli spaces of maps from caps to the plumbing of two cotangent bundles .", "tokens": ["in", "this", "section", ",", "we", "will", "discuss", "moduli", "spaces", "of", "maps", "from", "caps", "to", "the", "plumbing", "of", "two", "cotangent", "bundles", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "will discuss", "start": 21, "end": 33, "i_start": 5, "i_end": 6}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "discuss", "start": 26, "end": 33, "i_start": 6, "i_end": 6}}], "id": 4841}, {"sent": "an optimal approach for reducing interference in manets is called interference alignment , which achieves the number of degrees of freedom equal to half of the number of interference links for high signal-to-noise ratios .", "tokens": ["an", "optimal", "approach", "for", "reducing", "interference", "in", "manets", "is", "called", "interference", "alignment", ",", "which", "achieves", "the", "number", "of", "degrees", "of", "freedom", "equal", "to", "half", "of", "the", "number", "of", "interference", "links", "for", "high", "signal", "-", "to", "-", "noise", "ratios", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an optimal approach for reducing interference in manets", "start": 0, "end": 55, "i_start": 0, "i_end": 7}, "verb": {"text": "is called", "start": 56, "end": 65, "i_start": 8, "i_end": 9}}, {"character": {"text": "alignment", "start": 79, "end": 88, "i_start": 11, "i_end": 11}, "action": {"text": "achieves", "start": 97, "end": 105, "i_start": 14, "i_end": 14}}, {"character": {"text": "links", "start": 183, "end": 188, "i_start": 29, "i_end": 29}, "action": {"text": "interference", "start": 66, "end": 78, "i_start": 10, "i_end": 10}}], "id": 4842}, {"sent": "many popular cryptosystems such as rsa are public-key cryptosystems .", "tokens": ["many", "popular", "cryptosystems", "such", "as", "rsa", "are", "public", "-", "key", "cryptosystems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "many popular cryptosystems such as rsa", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "are", "start": 39, "end": 42, "i_start": 6, "i_end": 6}}], "id": 4843}, {"sent": "the support of such p polynomial p is called the newton polytope of p .", "tokens": ["the", "support", "of", "such", "p", "polynomial", "p", "is", "called", "the", "newton", "polytope", "of", "p", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the support of such p polynomial p", "start": 0, "end": 34, "i_start": 0, "i_end": 6}, "verb": {"text": "is called", "start": 35, "end": 44, "i_start": 7, "i_end": 8}}, {"character": {"text": "polytope", "start": 56, "end": 64, "i_start": 11, "i_end": 11}, "action": {"text": "support", "start": 4, "end": 11, "i_start": 1, "i_end": 1}}], "id": 4844}, {"sent": "the hidden sector consists of nine 8-plets under each so , we need to realize the breaking by an additional wilsonline like vector .", "tokens": ["the", "hidden", "sector", "consists", "of", "nine", "8", "-", "plets", "under", "each", "so", ",", "we", "need", "to", "realize", "the", "breaking", "by", "an", "additional", "wilsonline", "like", "vector", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 59, "end": 61, "i_start": 13, "i_end": 13}, "verb": {"text": "need", "start": 62, "end": 66, "i_start": 14, "i_end": 14}}, {"subject": {"text": "the hidden sector", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 59, "end": 61, "i_start": 13, "i_end": 13}, "action": {"text": "need", "start": 62, "end": 66, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 59, "end": 61, "i_start": 13, "i_end": 13}, "action": {"text": "realize", "start": 70, "end": 77, "i_start": 16, "i_end": 16}}], "id": 4845}, {"sent": "the deep features come from convolutional neural networks based on the alexnet architectures .", "tokens": ["the", "deep", "features", "come", "from", "convolutional", "neural", "networks", "based", "on", "the", "alexnet", "architectures", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the deep features", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "come", "start": 18, "end": 22, "i_start": 3, "i_end": 3}}], "id": 4846}, {"sent": "the latter three terms all depend on the difference between the spectrum at some frequency and the high frequency limit .", "tokens": ["the", "latter", "three", "terms", "all", "depend", "on", "the", "difference", "between", "the", "spectrum", "at", "some", "frequency", "and", "the", "high", "frequency", "limit", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the latter three terms all", "start": 0, "end": 26, "i_start": 0, "i_end": 4}, "verb": {"text": "depend", "start": 27, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "three terms", "start": 11, "end": 22, "i_start": 2, "i_end": 3}, "action": {"text": "depend", "start": 27, "end": 33, "i_start": 5, "i_end": 5}}], "id": 4847}, {"sent": "an important example is that of n d3-branes at the singularity of the conifold .", "tokens": ["an", "important", "example", "is", "that", "of", "n", "d3", "-", "branes", "at", "the", "singularity", "of", "the", "conifold", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "an important example", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 3, "i_end": 3}}], "id": 4848}, {"sent": "in this section , we show that the canonical coordinates of the 1st kind of are carnot coordinates .", "tokens": ["in", "this", "section", ",", "we", "show", "that", "the", "canonical", "coordinates", "of", "the", "1st", "kind", "of", "are", "carnot", "coordinates", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "show", "start": 21, "end": 25, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "are", "start": 76, "end": 79, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "show", "start": 21, "end": 25, "i_start": 5, "i_end": 5}}], "id": 4849}, {"sent": "we first illustrate this situation by the following example .", "tokens": ["we", "first", "illustrate", "this", "situation", "by", "the", "following", "example", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "illustrate", "start": 9, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "illustrate", "start": 9, "end": 19, "i_start": 2, "i_end": 2}}], "id": 4850}, {"sent": "in , the authors compared the minimum size of advice required to solve two information dissemination problems using a linear number of messages .", "tokens": ["in", ",", "the", "authors", "compared", "the", "minimum", "size", "of", "advice", "required", "to", "solve", "two", "information", "dissemination", "problems", "using", "a", "linear", "number", "of", "messages", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 5, "end": 16, "i_start": 2, "i_end": 3}, "verb": {"text": "compared", "start": 17, "end": 25, "i_start": 4, "i_end": 4}}, {"character": {"text": "solve", "start": 65, "end": 70, "i_start": 12, "i_end": 12}, "action": {"text": "required", "start": 53, "end": 61, "i_start": 10, "i_end": 10}}], "id": 4851}, {"sent": "this means the complex curvature operator of the dual metric of the wp metric is positive .", "tokens": ["this", "means", "the", "complex", "curvature", "operator", "of", "the", "dual", "metric", "of", "the", "wp", "metric", "is", "positive", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "means", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 78, "end": 80, "i_start": 14, "i_end": 14}}], "id": 4852}, {"sent": "the videos are divided into validation set and test set , but only video in the test set have spatial annotations provided by .", "tokens": ["the", "videos", "are", "divided", "into", "validation", "set", "and", "test", "set", ",", "but", "only", "video", "in", "the", "test", "set", "have", "spatial", "annotations", "provided", "by", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the videos", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "are divided", "start": 11, "end": 22, "i_start": 2, "i_end": 3}}, {"subject": {"text": "only video in the test set", "start": 62, "end": 88, "i_start": 12, "i_end": 17}, "verb": {"text": "have", "start": 89, "end": 93, "i_start": 18, "i_end": 18}}], "id": 4853}, {"sent": "the quantum computer is a device which work should be described .", "tokens": ["the", "quantum", "computer", "is", "a", "device", "which", "work", "should", "be", "described", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quantum computer", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 3, "i_end": 3}}], "id": 4854}, {"sent": "faster r-cnn is one of the most popular methods for object detection .", "tokens": ["faster", "r", "-", "cnn", "is", "one", "of", "the", "most", "popular", "methods", "for", "object", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "-cnn", "start": 8, "end": 12, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 4, "i_end": 4}}], "id": 4855}, {"sent": "although there are some upper bounds on a q and analysis of subspace designs in the topic was hardly considered .", "tokens": ["although", "there", "are", "some", "upper", "bounds", "on", "a", "q", "and", "analysis", "of", "subspace", "designs", "in", "the", "topic", "was", "hardly", "considered", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4856}, {"sent": "this means that the vacuum structure has no singularity at the massless limit .", "tokens": ["this", "means", "that", "the", "vacuum", "structure", "has", "no", "singularity", "at", "the", "massless", "limit", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "means", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the vacuum structure", "start": 16, "end": 36, "i_start": 3, "i_end": 5}, "verb": {"text": "has", "start": 37, "end": 40, "i_start": 6, "i_end": 6}}, {"character": {"text": "structure", "start": 27, "end": 36, "i_start": 5, "i_end": 5}, "action": {"text": "has no", "start": 37, "end": 43, "i_start": 6, "i_end": 7}}], "id": 4857}, {"sent": "deep neural networks have been widely adopted in many applications such as computer vision .", "tokens": ["deep", "neural", "networks", "have", "been", "widely", "adopted", "in", "many", "applications", "such", "as", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "adopted", "start": 38, "end": 45, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}], "id": 4858}, {"sent": "a scheme for efficient quantum computation with linear optics .", "tokens": ["a", "scheme", "for", "efficient", "quantum", "computation", "with", "linear", "optics", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4859}, {"sent": "we adopt the resnet-101 as the encoder e and use the feature activations from the conv4-23layer as our feature map .", "tokens": ["we", "adopt", "the", "resnet-101", "as", "the", "encoder", "e", "and", "use", "the", "feature", "activations", "from", "the", "conv4", "-", "23layer", "as", "our", "feature", "map", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 45, "end": 48, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "adopt", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 45, "end": 48, "i_start": 9, "i_end": 9}}], "id": 4860}, {"sent": "to demonstrate the performance of our proposed algorithm , we first compare to the recent rpca algorithms on corrupted static camera videos .", "tokens": ["to", "demonstrate", "the", "performance", "of", "our", "proposed", "algorithm", ",", "we", "first", "compare", "to", "the", "recent", "rpca", "algorithms", "on", "corrupted", "static", "camera", "videos", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 59, "end": 61, "i_start": 9, "i_end": 9}, "verb": {"text": "compare", "start": 68, "end": 75, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 59, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "compare", "start": 68, "end": 75, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 59, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "demonstrate", "start": 3, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "algorithms", "start": 95, "end": 105, "i_start": 16, "i_end": 16}, "action": {"text": "performance", "start": 19, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 59, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "proposed", "start": 38, "end": 46, "i_start": 6, "i_end": 6}}], "id": 4861}, {"sent": "backstepping has proved itself to be an ubiquitous method for pde control , with many other applications including , among others , flow control .", "tokens": ["backstepping", "has", "proved", "itself", "to", "be", "an", "ubiquitous", "method", "for", "pde", "control", ",", "with", "many", "other", "applications", "including", ",", "among", "others", ",", "flow", "control", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "backstepping", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "has proved", "start": 13, "end": 23, "i_start": 1, "i_end": 2}}, {"subject": {"text": "backstepping", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "verb": {"text": "be", "start": 34, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "backstepping", "start": 0, "end": 12, "i_start": 0, "i_end": 0}, "action": {"text": "proved", "start": 17, "end": 23, "i_start": 2, "i_end": 2}}], "id": 4862}, {"sent": "the analysis of linear partial differential operators .", "tokens": ["the", "analysis", "of", "linear", "partial", "differential", "operators", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4863}, {"sent": "the parti-game algorithm for variable resolution reinforcement learning in multidimensional state-spaces .", "tokens": ["the", "parti", "-", "game", "algorithm", "for", "variable", "resolution", "reinforcement", "learning", "in", "multidimensional", "state", "-", "spaces", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4864}, {"sent": "for the backbone network , we use resnet50 as the building foundation for feature map extraction .", "tokens": ["for", "the", "backbone", "network", ",", "we", "use", "resnet50", "as", "the", "building", "foundation", "for", "feature", "map", "extraction", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 27, "end": 29, "i_start": 5, "i_end": 5}, "verb": {"text": "use", "start": 30, "end": 33, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 27, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "use", "start": 30, "end": 33, "i_start": 6, "i_end": 6}}], "id": 4865}, {"sent": "in recent years , deep learning has achieved extraordinary success in many domains , from image classification , speech recognition to game playing .", "tokens": ["in", "recent", "years", ",", "deep", "learning", "has", "achieved", "extraordinary", "success", "in", "many", "domains", ",", "from", "image", "classification", ",", "speech", "recognition", "to", "game", "playing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 18, "end": 31, "i_start": 4, "i_end": 5}, "verb": {"text": "has achieved", "start": 32, "end": 44, "i_start": 6, "i_end": 7}}, {"character": {"text": "learning", "start": 23, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 36, "end": 44, "i_start": 7, "i_end": 7}}, {"character": {"text": "learning", "start": 23, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 9, "i_end": 9}}], "id": 4866}, {"sent": "the free energy is the start ing point for many theories dealing with metastability or spinodal decomposition .", "tokens": ["the", "free", "energy", "is", "the", "start", "ing", "point", "for", "many", "theories", "dealing", "with", "metastability", "or", "spinodal", "decomposition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the free energy", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "theories", "start": 48, "end": 56, "i_start": 10, "i_end": 10}, "action": {"text": "dealing", "start": 57, "end": 64, "i_start": 11, "i_end": 11}}], "id": 4867}, {"sent": "if the higgs boson is a composite particle , a proton collider with very high energies may be a unique instrument to search for its constituents .", "tokens": ["if", "the", "higgs", "boson", "is", "a", "composite", "particle", ",", "a", "proton", "collider", "with", "very", "high", "energies", "may", "be", "a", "unique", "instrument", "to", "search", "for", "its", "constituents", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a proton collider with very high energies", "start": 45, "end": 86, "i_start": 9, "i_end": 15}, "verb": {"text": "may be", "start": 87, "end": 93, "i_start": 16, "i_end": 17}}, {"character": {"text": "collider", "start": 54, "end": 62, "i_start": 11, "i_end": 11}, "action": {"text": "search", "start": 117, "end": 123, "i_start": 22, "i_end": 22}}], "id": 4868}, {"sent": "a recent approach for computing complexity in continuous quantum-many body systems that exploited gaussian states to derive the timedependent complexity in the cft for a free scalar field theory , and this likewise led to similar results .", "tokens": ["a", "recent", "approach", "for", "computing", "complexity", "in", "continuous", "quantum", "-", "many", "body", "systems", "that", "exploited", "gaussian", "states", "to", "derive", "the", "timedependent", "complexity", "in", "the", "cft", "for", "a", "free", "scalar", "field", "theory", ",", "and", "this", "likewise", "led", "to", "similar", "results", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "approach", "start": 9, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "exploited", "start": 88, "end": 97, "i_start": 14, "i_end": 14}}, {"character": {"text": "computing", "start": 22, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "derive", "start": 117, "end": 123, "i_start": 18, "i_end": 18}}], "id": 4869}, {"sent": "the syntax of curry is close to haskell but also allows free variables in conditions and righthand sides of rules .", "tokens": ["the", "syntax", "of", "curry", "is", "close", "to", "haskell", "but", "also", "allows", "free", "variables", "in", "conditions", "and", "righthand", "sides", "of", "rules", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the syntax of curry", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the syntax of curry", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "allows", "start": 49, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "syntax", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "allows", "start": 49, "end": 55, "i_start": 10, "i_end": 10}}], "id": 4870}, {"sent": "mrk 279 mrk 279 is a seyfert 1 residing in a moderately inclined host .", "tokens": ["mrk", "279", "mrk", "279", "is", "a", "seyfert", "1", "residing", "in", "a", "moderately", "inclined", "host", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "279", "start": 12, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 4, "i_end": 4}}], "id": 4871}, {"sent": "the synthesis results in were carried out in 65 nm technology but reported in 90 nm technology .", "tokens": ["the", "synthesis", "results", "in", "were", "carried", "out", "in", "65", "nm", "technology", "but", "reported", "in", "90", "nm", "technology", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the synthesis results in", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "were carried out", "start": 25, "end": 41, "i_start": 4, "i_end": 6}}, {"subject": {"text": "the synthesis results in", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "reported", "start": 66, "end": 74, "i_start": 12, "i_end": 12}}], "id": 4872}, {"sent": "deep neural networks have been shown to outperform shallow learning algorithms in applications such as computer vision .", "tokens": ["deep", "neural", "networks", "have", "been", "shown", "to", "outperform", "shallow", "learning", "algorithms", "in", "applications", "such", "as", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been shown", "start": 21, "end": 36, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "outperform", "start": 40, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "algorithms", "start": 68, "end": 78, "i_start": 10, "i_end": 10}, "action": {"text": "learning", "start": 59, "end": 67, "i_start": 9, "i_end": 9}}], "id": 4873}, {"sent": "then the total energy-momentum tensor can be written as the sum .", "tokens": ["then", "the", "total", "energy", "-", "momentum", "tensor", "can", "be", "written", "as", "the", "sum", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the total energy-momentum tensor", "start": 5, "end": 37, "i_start": 1, "i_end": 6}, "verb": {"text": "can be written", "start": 38, "end": 52, "i_start": 7, "i_end": 9}}], "id": 4874}, {"sent": "the exchange and correlation effects were taken into account within the generalized gradient approximation .", "tokens": ["the", "exchange", "and", "correlation", "effects", "were", "taken", "into", "account", "within", "the", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange and correlation effects", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "were taken", "start": 37, "end": 47, "i_start": 5, "i_end": 6}}], "id": 4875}, {"sent": "here the superscripts on t denote the order of the coupling constant in the expansion .", "tokens": ["here", "the", "superscripts", "on", "t", "denote", "the", "order", "of", "the", "coupling", "constant", "in", "the", "expansion", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the superscripts on t", "start": 5, "end": 26, "i_start": 1, "i_end": 4}, "verb": {"text": "denote", "start": 27, "end": 33, "i_start": 5, "i_end": 5}}, {"subject": {"text": "the superscripts on t", "start": 5, "end": 26, "i_start": 1, "i_end": 4}, "verb": {"text": "constant", "start": 60, "end": 68, "i_start": 11, "i_end": 11}}, {"character": {"text": "superscripts", "start": 9, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "denote", "start": 27, "end": 33, "i_start": 5, "i_end": 5}}], "id": 4876}, {"sent": "in extended networks , the proposed approach is based in part on the characteristics at power-limited regimes shown in .", "tokens": ["in", "extended", "networks", ",", "the", "proposed", "approach", "is", "based", "in", "part", "on", "the", "characteristics", "at", "power", "-", "limited", "regimes", "shown", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the proposed approach", "start": 23, "end": 44, "i_start": 4, "i_end": 6}, "verb": {"text": "is based", "start": 45, "end": 53, "i_start": 7, "i_end": 8}}, {"character": {"text": "power", "start": 88, "end": 93, "i_start": 15, "i_end": 15}, "action": {"text": "limited", "start": 94, "end": 101, "i_start": 17, "i_end": 17}}], "id": 4877}, {"sent": "in other cases , the images may be closer to the reciprocal critical curve .", "tokens": ["in", "other", "cases", ",", "the", "images", "may", "be", "closer", "to", "the", "reciprocal", "critical", "curve", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the images", "start": 17, "end": 27, "i_start": 4, "i_end": 5}, "verb": {"text": "may be", "start": 28, "end": 34, "i_start": 6, "i_end": 7}}], "id": 4878}, {"sent": "in fact , deep learning has already brought about breakthroughs in computer vision , speech recognition , natural language processing and many other fields .", "tokens": ["in", "fact", ",", "deep", "learning", "has", "already", "brought", "about", "breakthroughs", "in", "computer", "vision", ",", "speech", "recognition", ",", "natural", "language", "processing", "and", "many", "other", "fields", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 10, "end": 23, "i_start": 3, "i_end": 4}, "verb": {"text": "brought about", "start": 36, "end": 49, "i_start": 7, "i_end": 8}}, {"subject": {"text": "deep learning", "start": 10, "end": 23, "i_start": 3, "i_end": 4}, "verb": {"text": "has", "start": 24, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "learning", "start": 15, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "brought", "start": 36, "end": 43, "i_start": 7, "i_end": 7}}], "id": 4879}, {"sent": "a computer-generated hologram is imprinted on slm 1 to generate hg modes in the first diffraction order .", "tokens": ["a", "computer", "-", "generated", "hologram", "is", "imprinted", "on", "slm", "1", "to", "generate", "hg", "modes", "in", "the", "first", "diffraction", "order", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "a computer-generated hologram", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "is imprinted", "start": 30, "end": 42, "i_start": 5, "i_end": 6}}, {"character": {"text": "computer", "start": 2, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "generated", "start": 11, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "hologram", "start": 21, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "generate", "start": 55, "end": 63, "i_start": 11, "i_end": 11}}], "id": 4880}, {"sent": "the conv feature map is the output of the conv4 layer from resnet-101 pre-trained on the imagenet .", "tokens": ["the", "conv", "feature", "map", "is", "the", "output", "of", "the", "conv4", "layer", "from", "resnet-101", "pre", "-", "trained", "on", "the", "imagenet", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the conv feature map", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 21, "end": 23, "i_start": 4, "i_end": 4}}], "id": 4881}, {"sent": "we use the scikit-learn implementation of a linear svm with default parameters .", "tokens": ["we", "use", "the", "scikit", "-", "learn", "implementation", "of", "a", "linear", "svm", "with", "default", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 4882}, {"sent": "the extensive applications of synchrotron radiation in a wide variety of experiments and in many disciplines , motivate the importance of investigations for various mechanisms of controlling the radiation parameters .", "tokens": ["the", "extensive", "applications", "of", "synchrotron", "radiation", "in", "a", "wide", "variety", "of", "experiments", "and", "in", "many", "disciplines", ",", "motivate", "the", "importance", "of", "investigations", "for", "various", "mechanisms", "of", "controlling", "the", "radiation", "parameters", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the extensive applications of synchrotron radiation in a wide variety of experiments and", "start": 0, "end": 88, "i_start": 0, "i_end": 12}, "verb": {"text": "motivate", "start": 111, "end": 119, "i_start": 17, "i_end": 17}}, {"character": {"text": "applications", "start": 14, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "motivate", "start": 111, "end": 119, "i_start": 17, "i_end": 17}}, {"character": {"text": "synchrotron", "start": 30, "end": 41, "i_start": 4, "i_end": 4}, "action": {"text": "radiation", "start": 42, "end": 51, "i_start": 5, "i_end": 5}}], "id": 4883}, {"sent": "the monoid m is a group if and only if each mapping in m is a bijection .", "tokens": ["the", "monoid", "m", "is", "a", "group", "if", "and", "only", "if", "each", "mapping", "in", "m", "is", "a", "bijection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the monoid m", "start": 0, "end": 12, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 3, "i_end": 3}}], "id": 4884}, {"sent": "all simulations were performed in an nvt ensemble at a constant temperature of 298 k by using v-rescale thermostat .", "tokens": ["all", "simulations", "were", "performed", "in", "an", "nvt", "ensemble", "at", "a", "constant", "temperature", "of", "298", "k", "by", "using", "v", "-", "rescale", "thermostat", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all simulations", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "were performed", "start": 16, "end": 30, "i_start": 2, "i_end": 3}}], "id": 4885}, {"sent": "since every 2-natural isomorphism is a pseudonatural equivalence , a pseudolimit , if it exists , is also a bilimit .", "tokens": ["since", "every", "2", "-", "natural", "isomorphism", "is", "a", "pseudonatural", "equivalence", ",", "a", "pseudolimit", ",", "if", "it", "exists", ",", "is", "also", "a", "bilimit", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "equivalence", "start": 53, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "if", "start": 83, "end": 85, "i_start": 14, "i_end": 14}}], "id": 4886}, {"sent": "the reader is referred to for an introduction on the ltl framework .", "tokens": ["the", "reader", "is", "referred", "to", "for", "an", "introduction", "on", "the", "ltl", "framework", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the reader", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "is referred", "start": 11, "end": 22, "i_start": 2, "i_end": 3}}], "id": 4887}, {"sent": "silicon is the only species included in this calculation .", "tokens": ["silicon", "is", "the", "only", "species", "included", "in", "this", "calculation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "silicon", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}], "id": 4888}, {"sent": "despite its advantages , the iif method is labour intensive and time consuming .", "tokens": ["despite", "its", "advantages", ",", "the", "iif", "method", "is", "labour", "intensive", "and", "time", "consuming", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the iif method", "start": 25, "end": 39, "i_start": 4, "i_end": 6}, "verb": {"text": "is", "start": 40, "end": 42, "i_start": 7, "i_end": 7}}, {"character": {"text": "method", "start": 33, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "consuming", "start": 69, "end": 78, "i_start": 12, "i_end": 12}}], "id": 4889}, {"sent": "to make good use of global image-level priors , zhao et al proposed to use the pyramid pooling module to collet levels of information from multiple scales .", "tokens": ["to", "make", "good", "use", "of", "global", "image", "-", "level", "priors", ",", "zhao", "et", "al", "proposed", "to", "use", "the", "pyramid", "pooling", "module", "to", "collet", "levels", "of", "information", "from", "multiple", "scales", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "zhao et al", "start": 48, "end": 58, "i_start": 11, "i_end": 13}, "verb": {"text": "proposed", "start": 59, "end": 67, "i_start": 14, "i_end": 14}}, {"character": {"text": "zhao", "start": 48, "end": 52, "i_start": 11, "i_end": 11}, "action": {"text": "proposed", "start": 59, "end": 67, "i_start": 14, "i_end": 14}}, {"character": {"text": "zhao", "start": 48, "end": 52, "i_start": 11, "i_end": 11}, "action": {"text": "use", "start": 13, "end": 16, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhao", "start": 48, "end": 52, "i_start": 11, "i_end": 11}, "action": {"text": "use", "start": 71, "end": 74, "i_start": 16, "i_end": 16}}], "id": 4890}, {"sent": "she is pursuing her phd programme in the dept .", "tokens": ["she", "is", "pursuing", "her", "phd", "programme", "in", "the", "dept", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "she", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "is pursuing", "start": 4, "end": 15, "i_start": 1, "i_end": 2}}, {"character": {"text": "she", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "pursuing", "start": 7, "end": 15, "i_start": 2, "i_end": 2}}], "id": 4891}, {"sent": "prior work has shown that ssc gives a subspace-preserving solution if the subspaces are independent .", "tokens": ["prior", "work", "has", "shown", "that", "ssc", "gives", "a", "subspace", "-", "preserving", "solution", "if", "the", "subspaces", "are", "independent", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "prior work", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "has shown", "start": 11, "end": 20, "i_start": 2, "i_end": 3}}, {"subject": {"text": "ssc", "start": 26, "end": 29, "i_start": 5, "i_end": 5}, "verb": {"text": "gives", "start": 30, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "work", "start": 6, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "shown", "start": 15, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "solution", "start": 58, "end": 66, "i_start": 11, "i_end": 11}, "action": {"text": "preserving", "start": 47, "end": 57, "i_start": 10, "i_end": 10}}], "id": 4892}, {"sent": "the red and blue lines represent two types of states , corresponding to the two types of nfe states , respectively .", "tokens": ["the", "red", "and", "blue", "lines", "represent", "two", "types", "of", "states", ",", "corresponding", "to", "the", "two", "types", "of", "nfe", "states", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the red and blue lines", "start": 0, "end": 22, "i_start": 0, "i_end": 4}, "verb": {"text": "represent", "start": 23, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "lines", "start": 17, "end": 22, "i_start": 4, "i_end": 4}, "action": {"text": "represent", "start": 23, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "blue", "start": 12, "end": 16, "i_start": 3, "i_end": 3}, "action": {"text": "represent", "start": 23, "end": 32, "i_start": 5, "i_end": 5}}], "id": 4893}, {"sent": "another well-known sufficient condition is based on the restricted isometry property .", "tokens": ["another", "well", "-", "known", "sufficient", "condition", "is", "based", "on", "the", "restricted", "isometry", "property", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "another well-known sufficient condition", "start": 0, "end": 39, "i_start": 0, "i_end": 5}, "verb": {"text": "is based", "start": 40, "end": 48, "i_start": 6, "i_end": 7}}, {"character": {"text": "condition", "start": 30, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "sufficient", "start": 19, "end": 29, "i_start": 4, "i_end": 4}}], "id": 4894}, {"sent": "deep learning is widely used in machine learning for various tasks .", "tokens": ["deep", "learning", "is", "widely", "used", "in", "machine", "learning", "for", "various", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "used", "start": 24, "end": 28, "i_start": 4, "i_end": 4}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 4895}, {"sent": "in other words , v-duality holds for om theory as well .", "tokens": ["in", "other", "words", ",", "v", "-", "duality", "holds", "for", "om", "theory", "as", "well", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "v-duality", "start": 17, "end": 26, "i_start": 4, "i_end": 6}, "verb": {"text": "holds", "start": 27, "end": 32, "i_start": 7, "i_end": 7}}], "id": 4896}, {"sent": "we also used the extended stochastic gradient descent adam algorithm to optimize the loss function .", "tokens": ["we", "also", "used", "the", "extended", "stochastic", "gradient", "descent", "adam", "algorithm", "to", "optimize", "the", "loss", "function", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimize", "start": 72, "end": 80, "i_start": 11, "i_end": 11}}], "id": 4897}, {"sent": "we may solve it , for example , via the interior-point method .", "tokens": ["we", "may", "solve", "it", ",", "for", "example", ",", "via", "the", "interior", "-", "point", "method", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "may solve", "start": 3, "end": 12, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "solve", "start": 7, "end": 12, "i_start": 2, "i_end": 2}}], "id": 4898}, {"sent": "we believe that these two metrics are also equivalent to the above metrics .", "tokens": ["we", "believe", "that", "these", "two", "metrics", "are", "also", "equivalent", "to", "the", "above", "metrics", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "believe", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 34, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "believe", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 4899}, {"sent": "in the strong coupling ads dual , wilson loops are described by macroscopic strings .", "tokens": ["in", "the", "strong", "coupling", "ads", "dual", ",", "wilson", "loops", "are", "described", "by", "macroscopic", "strings", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "wilson loops", "start": 34, "end": 46, "i_start": 7, "i_end": 8}, "verb": {"text": "are described", "start": 47, "end": 60, "i_start": 9, "i_end": 10}}, {"character": {"text": "strings", "start": 76, "end": 83, "i_start": 13, "i_end": 13}, "action": {"text": "described", "start": 51, "end": 60, "i_start": 10, "i_end": 10}}], "id": 4900}, {"sent": "initial roadm based node architectures for costeffectively supporting flexible sdn networks have been presented in .", "tokens": ["initial", "roadm", "based", "node", "architectures", "for", "costeffectively", "supporting", "flexible", "sdn", "networks", "have", "been", "presented", "in", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "initial roadm based node architectures for costeffectively supporting flexible sdn networks", "start": 0, "end": 91, "i_start": 0, "i_end": 10}, "verb": {"text": "have been presented", "start": 92, "end": 111, "i_start": 11, "i_end": 13}}, {"character": {"text": "architectures", "start": 25, "end": 38, "i_start": 4, "i_end": 4}, "action": {"text": "supporting", "start": 59, "end": 69, "i_start": 7, "i_end": 7}}], "id": 4901}, {"sent": "in parentheses is the significance followed by the number of sn included in the fit .", "tokens": ["in", "parentheses", "is", "the", "significance", "followed", "by", "the", "number", "of", "sn", "included", "in", "the", "fit", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4902}, {"sent": "we also show the densities of ir and uv monopole clusters which do not belong to p-vortices .", "tokens": ["we", "also", "show", "the", "densities", "of", "ir", "and", "uv", "monopole", "clusters", "which", "do", "not", "belong", "to", "p", "-", "vortices", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "clusters", "start": 49, "end": 57, "i_start": 10, "i_end": 10}, "action": {"text": "not belong", "start": 67, "end": 77, "i_start": 13, "i_end": 14}}], "id": 4903}, {"sent": "this is qualitatively different from the collapsar model .", "tokens": ["this", "is", "qualitatively", "different", "from", "the", "collapsar", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 5, "end": 7, "i_start": 1, "i_end": 1}}], "id": 4904}, {"sent": "during the last decade , deep learning algorithms , especially convolutional neural networks have achieved remarkable progress on numerous practical vision tasks .", "tokens": ["during", "the", "last", "decade", ",", "deep", "learning", "algorithms", ",", "especially", "convolutional", "neural", "networks", "have", "achieved", "remarkable", "progress", "on", "numerous", "practical", "vision", "tasks", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep learning algorithms", "start": 25, "end": 49, "i_start": 5, "i_end": 7}, "verb": {"text": "have achieved", "start": 93, "end": 106, "i_start": 13, "i_end": 14}}, {"character": {"text": "algorithms", "start": 39, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "achieved", "start": 98, "end": 106, "i_start": 14, "i_end": 14}}, {"character": {"text": "algorithms", "start": 39, "end": 49, "i_start": 7, "i_end": 7}, "action": {"text": "learning", "start": 30, "end": 38, "i_start": 6, "i_end": 6}}], "id": 4905}, {"sent": "the expectation maximization algorithm is a widely used clustering approach .", "tokens": ["the", "expectation", "maximization", "algorithm", "is", "a", "widely", "used", "clustering", "approach", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the expectation maximization algorithm", "start": 0, "end": 38, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 4, "i_end": 4}}], "id": 4906}, {"sent": "deep convolutional neural networks have led to a series of breakthrough for visual tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "led", "to", "a", "series", "of", "breakthrough", "for", "visual", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have led", "start": 35, "end": 43, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "led", "start": 40, "end": 43, "i_start": 5, "i_end": 5}}], "id": 4907}, {"sent": "blood flow in the coronary artery may be affected by a single or multiple coronary artery stenoses .", "tokens": ["blood", "flow", "in", "the", "coronary", "artery", "may", "be", "affected", "by", "a", "single", "or", "multiple", "coronary", "artery", "stenoses", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "blood flow in the coronary artery", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "may be affected", "start": 34, "end": 49, "i_start": 6, "i_end": 8}}, {"character": {"text": "or", "start": 62, "end": 64, "i_start": 12, "i_end": 12}, "action": {"text": "affected", "start": 41, "end": 49, "i_start": 8, "i_end": 8}}], "id": 4908}, {"sent": "orthogonal language constructs for agent oriented logic programming .", "tokens": ["orthogonal", "language", "constructs", "for", "agent", "oriented", "logic", "programming", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4909}, {"sent": "we use both plain stochastic gradient-ascent and the adam optimiser with default parameter values .", "tokens": ["we", "use", "both", "plain", "stochastic", "gradient", "-", "ascent", "and", "the", "adam", "optimiser", "with", "default", "parameter", "values", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 4910}, {"sent": "we then use a slightly modified version of the well-known bellman-ford algorithm to find this minimum-weight path and thus the optimal leader set .", "tokens": ["we", "then", "use", "a", "slightly", "modified", "version", "of", "the", "well", "-", "known", "bellman", "-", "ford", "algorithm", "to", "find", "this", "minimum", "-", "weight", "path", "and", "thus", "the", "optimal", "leader", "set", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 84, "end": 88, "i_start": 17, "i_end": 17}}], "id": 4911}, {"sent": "five-channel boxcar smoothing is applied and polynomial fits to the baseline are shown .", "tokens": ["five", "-", "channel", "boxcar", "smoothing", "is", "applied", "and", "polynomial", "fits", "to", "the", "baseline", "are", "shown", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "five-channel boxcar smoothing", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "are shown", "start": 77, "end": 86, "i_start": 13, "i_end": 14}}, {"subject": {"text": "five-channel boxcar smoothing", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "applied", "start": 33, "end": 40, "i_start": 6, "i_end": 6}}], "id": 4912}, {"sent": "all subsequent data reduction and calibration was performed with the miriad software .", "tokens": ["all", "subsequent", "data", "reduction", "and", "calibration", "was", "performed", "with", "the", "miriad", "software", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all subsequent data reduction and calibration", "start": 0, "end": 45, "i_start": 0, "i_end": 5}, "verb": {"text": "was performed", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}], "id": 4913}, {"sent": "this phenomenon has been partly mentioned in daamen and hoogendoorn , 2012 .", "tokens": ["this", "phenomenon", "has", "been", "partly", "mentioned", "in", "daamen", "and", "hoogendoorn", ",", "2012", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this phenomenon", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "mentioned", "start": 32, "end": 41, "i_start": 5, "i_end": 5}}, {"subject": {"text": "this phenomenon", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "has been", "start": 16, "end": 24, "i_start": 2, "i_end": 3}}], "id": 4914}, {"sent": "deep neural networks have shown remarkable success in many domains , such as computer vision .", "tokens": ["deep", "neural", "networks", "have", "shown", "remarkable", "success", "in", "many", "domains", ",", "such", "as", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}], "id": 4915}, {"sent": "deep learning techniques , especially the convolutional neural network architectures have achieved remarkable breakthroughs in learning image representation for classification .", "tokens": ["deep", "learning", "techniques", ",", "especially", "the", "convolutional", "neural", "network", "architectures", "have", "achieved", "remarkable", "breakthroughs", "in", "learning", "image", "representation", "for", "classification", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "deep learning techniques", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 85, "end": 98, "i_start": 10, "i_end": 11}}, {"character": {"text": "techniques", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 90, "end": 98, "i_start": 11, "i_end": 11}}], "id": 4916}, {"sent": "in kapovich and ziller classified biquotients with singly generated rational cohomology .", "tokens": ["in", "kapovich", "and", "ziller", "classified", "biquotients", "with", "singly", "generated", "rational", "cohomology", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4917}, {"sent": "similar to the multiplex application , we use a u-net-like architecture with label super resolution losses .", "tokens": ["similar", "to", "the", "multiplex", "application", ",", "we", "use", "a", "u", "-", "net", "-", "like", "architecture", "with", "label", "super", "resolution", "losses", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 39, "end": 41, "i_start": 6, "i_end": 6}, "verb": {"text": "use", "start": 42, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 39, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "use", "start": 42, "end": 45, "i_start": 7, "i_end": 7}}], "id": 4918}, {"sent": "the nucleus itself is a composite of neutrons and protons and further progress in science has revealed that even the neutrons and protons have a substructure .", "tokens": ["the", "nucleus", "itself", "is", "a", "composite", "of", "neutrons", "and", "protons", "and", "further", "progress", "in", "science", "has", "revealed", "that", "even", "the", "neutrons", "and", "protons", "have", "a", "substructure", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the nucleus itself", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the nucleus itself", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "revealed", "start": 94, "end": 102, "i_start": 16, "i_end": 16}}, {"character": {"text": "progress", "start": 70, "end": 78, "i_start": 12, "i_end": 12}, "action": {"text": "revealed", "start": 94, "end": 102, "i_start": 16, "i_end": 16}}, {"character": {"text": "neutrons", "start": 37, "end": 45, "i_start": 7, "i_end": 7}, "action": {"text": "has", "start": 90, "end": 93, "i_start": 15, "i_end": 15}}, {"character": {"text": "protons", "start": 50, "end": 57, "i_start": 9, "i_end": 9}, "action": {"text": "has", "start": 90, "end": 93, "i_start": 15, "i_end": 15}}, {"character": {"text": "even", "start": 108, "end": 112, "i_start": 18, "i_end": 18}, "action": {"text": "has", "start": 90, "end": 93, "i_start": 15, "i_end": 15}}], "id": 4919}, {"sent": "in recent years , deep neural networks have achieved great success in a variety of machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "achieved", "great", "success", "in", "a", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}], "id": 4920}, {"sent": "the methods were built using scikit-learn library .", "tokens": ["the", "methods", "were", "built", "using", "scikit", "-", "learn", "library", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the methods", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "were built", "start": 12, "end": 22, "i_start": 2, "i_end": 3}}], "id": 4921}, {"sent": "deep neural networks have recently led to significant improvements in many fields , such as image classification .", "tokens": ["deep", "neural", "networks", "have", "recently", "led", "to", "significant", "improvements", "in", "many", "fields", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "led", "start": 35, "end": 38, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "led", "start": 35, "end": 38, "i_start": 5, "i_end": 5}}], "id": 4922}, {"sent": "gravity is the only long range force that can not be screened .", "tokens": ["gravity", "is", "the", "only", "long", "range", "force", "that", "can", "not", "be", "screened", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "gravity", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}], "id": 4923}, {"sent": "recently , convolutional neural networks have achieved remarkable success on many vision tasks such as object recognition .", "tokens": ["recently", ",", "convolutional", "neural", "networks", "have", "achieved", "remarkable", "success", "on", "many", "vision", "tasks", "such", "as", "object", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 11, "end": 40, "i_start": 2, "i_end": 4}, "verb": {"text": "have achieved", "start": 41, "end": 54, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 46, "end": 54, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "success", "start": 66, "end": 73, "i_start": 8, "i_end": 8}}], "id": 4924}, {"sent": "thus , in this model , the perturbations must be dominated by the adiabatic component from the inflaton .", "tokens": ["thus", ",", "in", "this", "model", ",", "the", "perturbations", "must", "be", "dominated", "by", "the", "adiabatic", "component", "from", "the", "inflaton", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the perturbations", "start": 23, "end": 40, "i_start": 6, "i_end": 7}, "verb": {"text": "must be dominated", "start": 41, "end": 58, "i_start": 8, "i_end": 10}}, {"character": {"text": "component", "start": 76, "end": 85, "i_start": 14, "i_end": 14}, "action": {"text": "dominated", "start": 49, "end": 58, "i_start": 10, "i_end": 10}}], "id": 4925}, {"sent": "in , lopez , sanz and sobottka introduced an extended concept of duality and give general results about ergodicity .", "tokens": ["in", ",", "lopez", ",", "sanz", "and", "sobottka", "introduced", "an", "extended", "concept", "of", "duality", "and", "give", "general", "results", "about", "ergodicity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "lopez", "start": 5, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "introduced", "start": 31, "end": 41, "i_start": 7, "i_end": 7}}, {"subject": {"text": "lopez", "start": 5, "end": 10, "i_start": 2, "i_end": 2}, "verb": {"text": "give", "start": 77, "end": 81, "i_start": 14, "i_end": 14}}, {"character": {"text": "lopez", "start": 5, "end": 10, "i_start": 2, "i_end": 2}, "action": {"text": "introduced", "start": 31, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "sanz", "start": 13, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "introduced", "start": 31, "end": 41, "i_start": 7, "i_end": 7}}, {"character": {"text": "sobottka", "start": 22, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "introduced", "start": 31, "end": 41, "i_start": 7, "i_end": 7}}], "id": 4926}, {"sent": "especially , it follows from the famous perron-frobenius theorem for nonnegative matrices that for any m-matrix a , all real eigenvalues of a are positive .", "tokens": ["especially", ",", "it", "follows", "from", "the", "famous", "perron", "-", "frobenius", "theorem", "for", "nonnegative", "matrices", "that", "for", "any", "m", "-", "matrix", "a", ",", "all", "real", "eigenvalues", "of", "a", "are", "positive", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 13, "end": 15, "i_start": 2, "i_end": 2}, "verb": {"text": "follows", "start": 16, "end": 23, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 13, "end": 15, "i_start": 2, "i_end": 2}, "verb": {"text": "are", "start": 142, "end": 145, "i_start": 27, "i_end": 27}}, {"character": {"text": "it", "start": 13, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "follows", "start": 16, "end": 23, "i_start": 3, "i_end": 3}}], "id": 4927}, {"sent": "deep convolutional neural networks have been successfully applied to a wide range of image classification tasks .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successfully", "applied", "to", "a", "wide", "range", "of", "image", "classification", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "applied", "start": 58, "end": 65, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}], "id": 4928}, {"sent": "higher gauge theory is a generalization which describes how strings and membranes change as they move through spacetime .", "tokens": ["higher", "gauge", "theory", "is", "a", "generalization", "which", "describes", "how", "strings", "and", "membranes", "change", "as", "they", "move", "through", "spacetime", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "higher gauge theory", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "theory", "start": 13, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "describes", "start": 46, "end": 55, "i_start": 7, "i_end": 7}}], "id": 4929}, {"sent": "it is also observed that the position of the anti-resonant state on the energy scale is independent of the molecule-to-electrode coupling strength .", "tokens": ["it", "is", "also", "observed", "that", "the", "position", "of", "the", "anti", "-", "resonant", "state", "on", "the", "energy", "scale", "is", "independent", "of", "the", "molecule", "-", "to", "-", "electrode", "coupling", "strength", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "observed", "start": 11, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 85, "end": 87, "i_start": 17, "i_end": 17}}, {"character": {"text": "position", "start": 29, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "-resonant state on the energy scale is independent", "start": 49, "end": 99, "i_start": 10, "i_end": 18}}, {"character": {"text": "state", "start": 59, "end": 64, "i_start": 12, "i_end": 12}, "action": {"text": "anti", "start": 45, "end": 49, "i_start": 9, "i_end": 9}}], "id": 4930}, {"sent": "given a circle configuration c , any saturated circle configuration containing c is called a saturation of c .", "tokens": ["given", "a", "circle", "configuration", "c", ",", "any", "saturated", "circle", "configuration", "containing", "c", "is", "called", "a", "saturation", "of", "c", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "any saturated circle configuration containing c", "start": 33, "end": 80, "i_start": 6, "i_end": 11}, "verb": {"text": "is called", "start": 81, "end": 90, "i_start": 12, "i_end": 13}}, {"character": {"text": "configuration", "start": 15, "end": 28, "i_start": 3, "i_end": 3}, "action": {"text": "containing", "start": 68, "end": 78, "i_start": 10, "i_end": 10}}], "id": 4931}, {"sent": "the converse for the joint secrecy region follows using the standard techniques and procedures used in for less noisy channels .", "tokens": ["the", "converse", "for", "the", "joint", "secrecy", "region", "follows", "using", "the", "standard", "techniques", "and", "procedures", "used", "in", "for", "less", "noisy", "channels", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the converse for the joint secrecy region", "start": 0, "end": 41, "i_start": 0, "i_end": 6}, "verb": {"text": "follows", "start": 42, "end": 49, "i_start": 7, "i_end": 7}}], "id": 4932}, {"sent": "to create this video dataset , we extracted video scenes from movies selected either according to similar studies , or from recent famous movies .", "tokens": ["to", "create", "this", "video", "dataset", ",", "we", "extracted", "video", "scenes", "from", "movies", "selected", "either", "according", "to", "similar", "studies", ",", "or", "from", "recent", "famous", "movies", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 31, "end": 33, "i_start": 6, "i_end": 6}, "verb": {"text": "extracted", "start": 34, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 6, "i_end": 6}, "action": {"text": "extracted", "start": 34, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 31, "end": 33, "i_start": 6, "i_end": 6}, "action": {"text": "create", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 4933}, {"sent": "deep convolutional neural networks have achieved great success on many tasks across a variety of domains , such as vision .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "on", "many", "tasks", "across", "a", "variety", "of", "domains", ",", "such", "as", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}], "id": 4934}, {"sent": "over the last decade it has turned out that networks corresponding to realistic systems can be highly non-trivial , characterized by a low average distance combined with a high average clustering coefficient .", "tokens": ["over", "the", "last", "decade", "it", "has", "turned", "out", "that", "networks", "corresponding", "to", "realistic", "systems", "can", "be", "highly", "non", "-", "trivial", ",", "characterized", "by", "a", "low", "average", "distance", "combined", "with", "a", "high", "average", "clustering", "coefficient", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "has turned out", "start": 24, "end": 38, "i_start": 5, "i_end": 7}}, {"subject": {"text": "it", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "be", "start": 92, "end": 94, "i_start": 15, "i_end": 15}}], "id": 4935}, {"sent": "zhu et al propose the automatic exploration of the co-occurrence of discriminative skeleton joints in an lstm network using group sparse regularization .", "tokens": ["zhu", "et", "al", "propose", "the", "automatic", "exploration", "of", "the", "co", "-", "occurrence", "of", "discriminative", "skeleton", "joints", "in", "an", "lstm", "network", "using", "group", "sparse", "regularization", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhu et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 10, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhu", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 10, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "joints", "start": 92, "end": 98, "i_start": 15, "i_end": 15}, "action": {"text": "discriminative", "start": 68, "end": 82, "i_start": 13, "i_end": 13}}, {"character": {"text": "joints", "start": 92, "end": 98, "i_start": 15, "i_end": 15}, "action": {"text": "using", "start": 118, "end": 123, "i_start": 20, "i_end": 20}}], "id": 4936}, {"sent": "the expectation-maximization algorithm is one of the most widely used heuristics for maximizing likelihood in statistical models with latent variables .", "tokens": ["the", "expectation", "-", "maximization", "algorithm", "is", "one", "of", "the", "most", "widely", "used", "heuristics", "for", "maximizing", "likelihood", "in", "statistical", "models", "with", "latent", "variables", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the expectation-maximization algorithm", "start": 0, "end": 38, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 39, "end": 41, "i_start": 5, "i_end": 5}}], "id": 4937}, {"sent": "this sub-space consists of the simultaneous eigenstates of the cashmir operators for each i .", "tokens": ["this", "sub", "-", "space", "consists", "of", "the", "simultaneous", "eigenstates", "of", "the", "cashmir", "operators", "for", "each", "i", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4938}, {"sent": "in the implementation , we use the machine learning libraries provided by scikit-learn .", "tokens": ["in", "the", "implementation", ",", "we", "use", "the", "machine", "learning", "libraries", "provided", "by", "scikit", "-", "learn", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 24, "end": 26, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 27, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 24, "end": 26, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 27, "end": 30, "i_start": 5, "i_end": 5}}], "id": 4939}, {"sent": "deep neural networks have achieved great success across a broad range of domains , such as computer vision , speech processing and natural language processing .", "tokens": ["deep", "neural", "networks", "have", "achieved", "great", "success", "across", "a", "broad", "range", "of", "domains", ",", "such", "as", "computer", "vision", ",", "speech", "processing", "and", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 21, "end": 34, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 26, "end": 34, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 41, "end": 48, "i_start": 6, "i_end": 6}}], "id": 4940}, {"sent": "for both variants , we use a resnet-50 until the final convolutional layer of the 4-th stage .", "tokens": ["for", "both", "variants", ",", "we", "use", "a", "resnet-50", "until", "the", "final", "convolutional", "layer", "of", "the", "4", "-", "th", "stage", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 20, "end": 22, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 23, "end": 26, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 20, "end": 22, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 23, "end": 26, "i_start": 5, "i_end": 5}}], "id": 4941}, {"sent": "a large flare occurred during the last third of the rgs observations .", "tokens": ["a", "large", "flare", "occurred", "during", "the", "last", "third", "of", "the", "rgs", "observations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a large flare", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "occurred", "start": 14, "end": 22, "i_start": 3, "i_end": 3}}], "id": 4942}, {"sent": "in this way , the gauge symmetry and the matter content of the resulting models can be derived from the geometric and topological data of the internal manifolds .", "tokens": ["in", "this", "way", ",", "the", "gauge", "symmetry", "and", "the", "matter", "content", "of", "the", "resulting", "models", "can", "be", "derived", "from", "the", "geometric", "and", "topological", "data", "of", "the", "internal", "manifolds", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the gauge symmetry and the matter content of the resulting models", "start": 14, "end": 79, "i_start": 4, "i_end": 14}, "verb": {"text": "can be derived", "start": 80, "end": 94, "i_start": 15, "i_end": 17}}], "id": 4943}, {"sent": "the analysis in the lq setting has attracted substantial interest due to its appealing analytical structure .", "tokens": ["the", "analysis", "in", "the", "lq", "setting", "has", "attracted", "substantial", "interest", "due", "to", "its", "appealing", "analytical", "structure", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the analysis in the lq setting", "start": 0, "end": 30, "i_start": 0, "i_end": 5}, "verb": {"text": "has attracted", "start": 31, "end": 44, "i_start": 6, "i_end": 7}}, {"character": {"text": "analysis", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "attracted", "start": 35, "end": 44, "i_start": 7, "i_end": 7}}, {"character": {"text": "structure", "start": 98, "end": 107, "i_start": 15, "i_end": 15}, "action": {"text": "appealing", "start": 77, "end": 86, "i_start": 13, "i_end": 13}}], "id": 4944}, {"sent": "deep neural networks have been evolved to powerful predictive models with remarkable performance on computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "been", "evolved", "to", "powerful", "predictive", "models", "with", "remarkable", "performance", "on", "computer", "vision", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been evolved", "start": 21, "end": 38, "i_start": 3, "i_end": 5}}, {"character": {"text": "models", "start": 62, "end": 68, "i_start": 9, "i_end": 9}, "action": {"text": "predictive", "start": 51, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "models", "start": 62, "end": 68, "i_start": 9, "i_end": 9}, "action": {"text": "performance", "start": 85, "end": 96, "i_start": 12, "i_end": 12}}], "id": 4945}, {"sent": "more recently , convolutional neural networks have achieved unprecedented performance in a wide range of image classification problems .", "tokens": ["more", "recently", ",", "convolutional", "neural", "networks", "have", "achieved", "unprecedented", "performance", "in", "a", "wide", "range", "of", "image", "classification", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 16, "end": 45, "i_start": 3, "i_end": 5}, "verb": {"text": "have achieved", "start": 46, "end": 59, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "achieved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "performance", "start": 74, "end": 85, "i_start": 9, "i_end": 9}}], "id": 4946}, {"sent": "the above condition is called g - invariance .", "tokens": ["the", "above", "condition", "is", "called", "g", "-", "invariance", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the above condition", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 20, "end": 29, "i_start": 3, "i_end": 4}}], "id": 4947}, {"sent": "convolutional neural networks establish state-ofthe-art performance for many computer vision applications .", "tokens": ["convolutional", "neural", "networks", "establish", "state", "-", "ofthe", "-", "art", "performance", "for", "many", "computer", "vision", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "establish", "start": 30, "end": 39, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "establish", "start": 30, "end": 39, "i_start": 3, "i_end": 3}}, {"character": {"text": "applications", "start": 93, "end": 105, "i_start": 14, "i_end": 14}, "action": {"text": "performance", "start": 56, "end": 67, "i_start": 9, "i_end": 9}}], "id": 4948}, {"sent": "for a proper introduction to symplectic geometry we refer to for contact geometry .", "tokens": ["for", "a", "proper", "introduction", "to", "symplectic", "geometry", "we", "refer", "to", "for", "contact", "geometry", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 49, "end": 51, "i_start": 7, "i_end": 7}, "action": {"text": "refer", "start": 52, "end": 57, "i_start": 8, "i_end": 8}}], "id": 4949}, {"sent": "such a collapse is the principle route by which a rotating black hole forms in nature .", "tokens": ["such", "a", "collapse", "is", "the", "principle", "route", "by", "which", "a", "rotating", "black", "hole", "forms", "in", "nature", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "such a collapse", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 4950}, {"sent": "for this we use both the point signal-to-noise ratio and the structural similarity index measure .", "tokens": ["for", "this", "we", "use", "both", "the", "point", "signal", "-", "to", "-", "noise", "ratio", "and", "the", "structural", "similarity", "index", "measure", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "verb": {"text": "use", "start": 12, "end": 15, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 9, "end": 11, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 12, "end": 15, "i_start": 3, "i_end": 3}}], "id": 4951}, {"sent": "the ordinate is the integrated time during which the detector exchange threshold has been lower than ht .", "tokens": ["the", "ordinate", "is", "the", "integrated", "time", "during", "which", "the", "detector", "exchange", "threshold", "has", "been", "lower", "than", "ht", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ordinate", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 13, "end": 15, "i_start": 2, "i_end": 2}}], "id": 4952}, {"sent": "in recent years , neural networks have been effectively applied in various problems such as voice recognition .", "tokens": ["in", "recent", "years", ",", "neural", "networks", "have", "been", "effectively", "applied", "in", "various", "problems", "such", "as", "voice", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 18, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "applied", "start": 56, "end": 63, "i_start": 9, "i_end": 9}}, {"subject": {"text": "neural networks", "start": 18, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "have been", "start": 34, "end": 43, "i_start": 6, "i_end": 7}}], "id": 4953}, {"sent": "to analyze the data and obtain the phase diagram , we use the bruce-wilding fss techniques outlined here .", "tokens": ["to", "analyze", "the", "data", "and", "obtain", "the", "phase", "diagram", ",", "we", "use", "the", "bruce", "-", "wilding", "fss", "techniques", "outlined", "here", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "verb": {"text": "use", "start": 54, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "use", "start": 54, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "analyze", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "obtain", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}], "id": 4954}, {"sent": "elliptic curve cryptography was presented independently by koblitz in the 1980s .", "tokens": ["elliptic", "curve", "cryptography", "was", "presented", "independently", "by", "koblitz", "in", "the", "1980s", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "elliptic curve cryptography", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "was presented", "start": 28, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "koblitz", "start": 59, "end": 66, "i_start": 7, "i_end": 7}, "action": {"text": "presented", "start": 32, "end": 41, "i_start": 4, "i_end": 4}}], "id": 4955}, {"sent": "the full distribution over the som clusters is not shown , but in each histogram bar the som defined cluster class is in green .", "tokens": ["the", "full", "distribution", "over", "the", "som", "clusters", "is", "not", "shown", ",", "but", "in", "each", "histogram", "bar", "the", "som", "defined", "cluster", "class", "is", "in", "green", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the full distribution over the som clusters", "start": 0, "end": 43, "i_start": 0, "i_end": 6}, "verb": {"text": "is not shown", "start": 44, "end": 56, "i_start": 7, "i_end": 9}}], "id": 4956}, {"sent": "batch normalization is used for all convolutional layers .", "tokens": ["batch", "normalization", "is", "used", "for", "all", "convolutional", "layers", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "batch normalization", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is used", "start": 20, "end": 27, "i_start": 2, "i_end": 3}}], "id": 4957}, {"sent": "the average waiting time ratio over periods .", "tokens": ["the", "average", "waiting", "time", "ratio", "over", "periods", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4958}, {"sent": "for the non-radial solutions , duyckaerts , holmer , and roudenko proved that the solutions in the above blow-up region blow up in finite time or grow up at infinite time .", "tokens": ["for", "the", "non", "-", "radial", "solutions", ",", "duyckaerts", ",", "holmer", ",", "and", "roudenko", "proved", "that", "the", "solutions", "in", "the", "above", "blow", "-", "up", "region", "blow", "up", "in", "finite", "time", "or", "grow", "up", "at", "infinite", "time", "."], "score": [1, 0, 1, 1, 0], "labels": [{"subject": {"text": "the solutions in the above blow-up region", "start": 78, "end": 119, "i_start": 15, "i_end": 23}, "verb": {"text": "proved", "start": 66, "end": 72, "i_start": 13, "i_end": 13}}, {"subject": {"text": "the solutions in the above blow-up region", "start": 78, "end": 119, "i_start": 15, "i_end": 23}, "verb": {"text": "blow", "start": 120, "end": 124, "i_start": 24, "i_end": 24}}, {"character": {"text": "duyckaerts", "start": 31, "end": 41, "i_start": 7, "i_end": 7}, "action": {"text": "proved", "start": 66, "end": 72, "i_start": 13, "i_end": 13}}, {"character": {"text": "holmer", "start": 44, "end": 50, "i_start": 9, "i_end": 9}, "action": {"text": "proved", "start": 66, "end": 72, "i_start": 13, "i_end": 13}}, {"character": {"text": "roudenko", "start": 57, "end": 65, "i_start": 12, "i_end": 12}, "action": {"text": "proved", "start": 66, "end": 72, "i_start": 13, "i_end": 13}}], "id": 4959}, {"sent": "so , in obtaining the analytic expressions of above potentials and hereafter , we expand the corresponding functions , as defined in the appendix , in \u03bb and keep only the leading term .", "tokens": ["so", ",", "in", "obtaining", "the", "analytic", "expressions", "of", "above", "potentials", "and", "hereafter", ",", "we", "expand", "the", "corresponding", "functions", ",", "as", "defined", "in", "the", "appendix", ",", "in", "\u03bb", "and", "keep", "only", "the", "leading", "term", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 79, "end": 81, "i_start": 13, "i_end": 13}, "verb": {"text": "expand", "start": 82, "end": 88, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 79, "end": 81, "i_start": 13, "i_end": 13}, "action": {"text": "expand", "start": 82, "end": 88, "i_start": 14, "i_end": 14}}, {"character": {"text": "appendix", "start": 137, "end": 145, "i_start": 23, "i_end": 23}, "action": {"text": "defined", "start": 122, "end": 129, "i_start": 20, "i_end": 20}}, {"character": {"text": "we", "start": 79, "end": 81, "i_start": 13, "i_end": 13}, "action": {"text": "keep", "start": 157, "end": 161, "i_start": 28, "i_end": 28}}, {"character": {"text": "term", "start": 179, "end": 183, "i_start": 32, "i_end": 32}, "action": {"text": "leading", "start": 171, "end": 178, "i_start": 31, "i_end": 31}}, {"character": {"text": "we", "start": 79, "end": 81, "i_start": 13, "i_end": 13}, "action": {"text": "obtaining", "start": 8, "end": 17, "i_start": 3, "i_end": 3}}], "id": 4960}, {"sent": "in the past few years , deep convolutional neural networks have shown promising results on object detection .", "tokens": ["in", "the", "past", "few", "years", ",", "deep", "convolutional", "neural", "networks", "have", "shown", "promising", "results", "on", "object", "detection", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 24, "end": 58, "i_start": 6, "i_end": 9}, "verb": {"text": "have shown", "start": 59, "end": 69, "i_start": 10, "i_end": 11}}, {"character": {"text": "networks", "start": 50, "end": 58, "i_start": 9, "i_end": 9}, "action": {"text": "shown", "start": 64, "end": 69, "i_start": 11, "i_end": 11}}, {"character": {"text": "results", "start": 80, "end": 87, "i_start": 13, "i_end": 13}, "action": {"text": "promising", "start": 70, "end": 79, "i_start": 12, "i_end": 12}}], "id": 4961}, {"sent": "deep convolutional neural networks have achieved great success in various computer vision tasks , including object classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "various", "computer", "vision", "tasks", ",", "including", "object", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}], "id": 4962}, {"sent": "neural networks have made remarkable progress in achieving encouraging results in digital image processing .", "tokens": ["neural", "networks", "have", "made", "remarkable", "progress", "in", "achieving", "encouraging", "results", "in", "digital", "image", "processing", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have made", "start": 16, "end": 25, "i_start": 2, "i_end": 3}}, {"character": {"text": "networks", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "achieving", "start": 49, "end": 58, "i_start": 7, "i_end": 7}}, {"character": {"text": "results", "start": 71, "end": 78, "i_start": 9, "i_end": 9}, "action": {"text": "encouraging", "start": 59, "end": 70, "i_start": 8, "i_end": 8}}], "id": 4963}, {"sent": "since the superpotential is the addition of these two contributions it vanishes .", "tokens": ["since", "the", "superpotential", "is", "the", "addition", "of", "these", "two", "contributions", "it", "vanishes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the superpotential", "start": 6, "end": 24, "i_start": 1, "i_end": 2}, "verb": {"text": "is", "start": 25, "end": 27, "i_start": 3, "i_end": 3}}], "id": 4964}, {"sent": "transport and anderson localization in disordered two-dimensional photonic lattices .", "tokens": ["transport", "and", "anderson", "localization", "in", "disordered", "two", "-", "dimensional", "photonic", "lattices", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4965}, {"sent": "as earlier , since the results are very close to the ones given in as well as those obtained through the mechanism presented in the above theorem .", "tokens": ["as", "earlier", ",", "since", "the", "results", "are", "very", "close", "to", "the", "ones", "given", "in", "as", "well", "as", "those", "obtained", "through", "the", "mechanism", "presented", "in", "the", "above", "theorem", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4966}, {"sent": "deep learning techniques have achieved significant success in computer vision , speech recognition and natural language processing .", "tokens": ["deep", "learning", "techniques", "have", "achieved", "significant", "success", "in", "computer", "vision", ",", "speech", "recognition", "and", "natural", "language", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning techniques", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 25, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "techniques", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "achieved", "start": 30, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "techniques", "start": 14, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 51, "end": 58, "i_start": 6, "i_end": 6}}], "id": 4967}, {"sent": "approximate sr have been introduced in the control community as a generalization of sr in order to enlarge the class of systems which admit finite abstractions .", "tokens": ["approximate", "sr", "have", "been", "introduced", "in", "the", "control", "community", "as", "a", "generalization", "of", "sr", "in", "order", "to", "enlarge", "the", "class", "of", "systems", "which", "admit", "finite", "abstractions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "approximate sr", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "have been introduced", "start": 15, "end": 35, "i_start": 2, "i_end": 4}}, {"character": {"text": "community", "start": 51, "end": 60, "i_start": 8, "i_end": 8}, "action": {"text": "control", "start": 43, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "systems", "start": 120, "end": 127, "i_start": 21, "i_end": 21}, "action": {"text": "admit", "start": 134, "end": 139, "i_start": 23, "i_end": 23}}], "id": 4968}, {"sent": "for faster convergence , batch normalization is applied on every conv layer .", "tokens": ["for", "faster", "convergence", ",", "batch", "normalization", "is", "applied", "on", "every", "conv", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "batch normalization", "start": 25, "end": 44, "i_start": 4, "i_end": 5}, "verb": {"text": "is applied", "start": 45, "end": 55, "i_start": 6, "i_end": 7}}], "id": 4969}, {"sent": "we implement the resnet-101 deep architecture as the base network for the deeplab model .", "tokens": ["we", "implement", "the", "resnet-101", "deep", "architecture", "as", "the", "base", "network", "for", "the", "deeplab", "model", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "implement", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}], "id": 4970}, {"sent": "the present paper deals with the noncommutative extension of the duality between ymcs theory and non-abelian sd model .", "tokens": ["the", "present", "paper", "deals", "with", "the", "noncommutative", "extension", "of", "the", "duality", "between", "ymcs", "theory", "and", "non", "-", "abelian", "sd", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "paper", "start": 12, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "deals", "start": 18, "end": 23, "i_start": 3, "i_end": 3}}], "id": 4971}, {"sent": "we see that the von neumann entropy is a monotonically increasing function of perimeter .", "tokens": ["we", "see", "that", "the", "von", "neumann", "entropy", "is", "a", "monotonically", "increasing", "function", "of", "perimeter", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "see", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 36, "end": 38, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "see", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "perimeter", "start": 78, "end": 87, "i_start": 13, "i_end": 13}, "action": {"text": "function", "start": 66, "end": 74, "i_start": 11, "i_end": 11}}], "id": 4972}, {"sent": "some recent studies have shown that deep learning algorithms are successfully used for medical imaging applications .", "tokens": ["some", "recent", "studies", "have", "shown", "that", "deep", "learning", "algorithms", "are", "successfully", "used", "for", "medical", "imaging", "applications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "some recent studies", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 20, "end": 30, "i_start": 3, "i_end": 4}}, {"subject": {"text": "deep learning algorithms", "start": 36, "end": 60, "i_start": 6, "i_end": 8}, "verb": {"text": "used", "start": 78, "end": 82, "i_start": 11, "i_end": 11}}, {"character": {"text": "studies", "start": 12, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 25, "end": 30, "i_start": 4, "i_end": 4}}], "id": 4973}, {"sent": "reinforcement learning is a learning paradigm that an agent learns from the interactions with the environment through sequential exploration and exploitation .", "tokens": ["reinforcement", "learning", "is", "a", "learning", "paradigm", "that", "an", "agent", "learns", "from", "the", "interactions", "with", "the", "environment", "through", "sequential", "exploration", "and", "exploitation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "reinforcement learning", "start": 0, "end": 22, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 23, "end": 25, "i_start": 2, "i_end": 2}}, {"character": {"text": "agent", "start": 54, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "exploration", "start": 129, "end": 140, "i_start": 18, "i_end": 18}}, {"character": {"text": "agent", "start": 54, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "exploitation", "start": 145, "end": 157, "i_start": 20, "i_end": 20}}], "id": 4974}, {"sent": "we use the faster r-cnn from for object detection and recognition .", "tokens": ["we", "use", "the", "faster", "r", "-", "cnn", "from", "for", "object", "detection", "and", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 4975}, {"sent": "we chose the adam optimizer to minimize the mean squared error loss function .", "tokens": ["we", "chose", "the", "adam", "optimizer", "to", "minimize", "the", "mean", "squared", "error", "loss", "function", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "chose", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "chose", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "optimizer", "start": 18, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "minimize", "start": 31, "end": 39, "i_start": 6, "i_end": 6}}], "id": 4976}, {"sent": "iii , we have derived cosmological constraints on the holographic ricci dark energy model from the joint analysis of snia , cmb , and bao observations .", "tokens": ["iii", ",", "we", "have", "derived", "cosmological", "constraints", "on", "the", "holographic", "ricci", "dark", "energy", "model", "from", "the", "joint", "analysis", "of", "snia", ",", "cmb", ",", "and", "bao", "observations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "verb": {"text": "have derived", "start": 9, "end": 21, "i_start": 3, "i_end": 4}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 2, "i_end": 2}, "action": {"text": "iii , we have derived", "start": 0, "end": 21, "i_start": 0, "i_end": 4}}, {"character": {"text": "snia", "start": 117, "end": 121, "i_start": 19, "i_end": 19}, "action": {"text": "observations", "start": 138, "end": 150, "i_start": 25, "i_end": 25}}, {"character": {"text": "cmb", "start": 124, "end": 127, "i_start": 21, "i_end": 21}, "action": {"text": "observations", "start": 138, "end": 150, "i_start": 25, "i_end": 25}}, {"character": {"text": "bao", "start": 134, "end": 137, "i_start": 24, "i_end": 24}, "action": {"text": "observations", "start": 138, "end": 150, "i_start": 25, "i_end": 25}}], "id": 4977}, {"sent": "chen et al introduced an attention mechanism into the segmentation network , which learns to weight the importance of features at different scales and positions .", "tokens": ["chen", "et", "al", "introduced", "an", "attention", "mechanism", "into", "the", "segmentation", "network", ",", "which", "learns", "to", "weight", "the", "importance", "of", "features", "at", "different", "scales", "and", "positions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "chen et al", "start": 0, "end": 10, "i_start": 0, "i_end": 2}, "verb": {"text": "introduced", "start": 11, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "chen", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 11, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "network", "start": 67, "end": 74, "i_start": 10, "i_end": 10}, "action": {"text": "segmentation", "start": 54, "end": 66, "i_start": 9, "i_end": 9}}, {"character": {"text": "network", "start": 67, "end": 74, "i_start": 10, "i_end": 10}, "action": {"text": "learns", "start": 83, "end": 89, "i_start": 13, "i_end": 13}}, {"character": {"text": "network", "start": 67, "end": 74, "i_start": 10, "i_end": 10}, "action": {"text": "weight", "start": 93, "end": 99, "i_start": 15, "i_end": 15}}], "id": 4978}, {"sent": "moreover , virtual links are in one-toone correspondence with abstract links on oriented surfaces .", "tokens": ["moreover", ",", "virtual", "links", "are", "in", "one", "-", "toone", "correspondence", "with", "abstract", "links", "on", "oriented", "surfaces", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "virtual links", "start": 11, "end": 24, "i_start": 2, "i_end": 3}, "verb": {"text": "are", "start": 25, "end": 28, "i_start": 4, "i_end": 4}}, {"character": {"text": "links", "start": 19, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "correspondence", "start": 42, "end": 56, "i_start": 9, "i_end": 9}}], "id": 4979}, {"sent": "we use a pretrained vgg19 network as the encoder , taking the output from relu4 to define f enc .", "tokens": ["we", "use", "a", "pretrained", "vgg19", "network", "as", "the", "encoder", ",", "taking", "the", "output", "from", "relu4", "to", "define", "f", "enc", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "taking", "start": 51, "end": 57, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "define", "start": 83, "end": 89, "i_start": 16, "i_end": 16}}], "id": 4980}, {"sent": "construction of the minimal representation .", "tokens": ["construction", "of", "the", "minimal", "representation", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4981}, {"sent": "dispersion of recovered properties of artificial clusters , assuming availability of ubvrijh magnitudes and varying observational errors , as indicated in the legend .", "tokens": ["dispersion", "of", "recovered", "properties", "of", "artificial", "clusters", ",", "assuming", "availability", "of", "ubvrijh", "magnitudes", "and", "varying", "observational", "errors", ",", "as", "indicated", "in", "the", "legend", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4982}, {"sent": "deep convolutional neural networks have achieved huge success in solving problems related to computer vision , such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "huge", "success", "in", "solving", "problems", "related", "to", "computer", "vision", ",", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 54, "end": 61, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "solving", "start": 65, "end": 72, "i_start": 9, "i_end": 9}}], "id": 4983}, {"sent": "recently , deep neural networks have led to significant improvement in several machine learning domains , from speech recognition to computer vision and machine translation .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "led", "to", "significant", "improvement", "in", "several", "machine", "learning", "domains", ",", "from", "speech", "recognition", "to", "computer", "vision", "and", "machine", "translation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have led", "start": 32, "end": 40, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "led", "start": 37, "end": 40, "i_start": 6, "i_end": 6}}], "id": 4984}, {"sent": "in 1980 , guth proposed the inflationary universe scenario to solve the horizon and flatness problems .", "tokens": ["in", "1980", ",", "guth", "proposed", "the", "inflationary", "universe", "scenario", "to", "solve", "the", "horizon", "and", "flatness", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "guth", "start": 10, "end": 14, "i_start": 3, "i_end": 3}, "verb": {"text": "proposed", "start": 15, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "guth", "start": 10, "end": 14, "i_start": 3, "i_end": 3}, "action": {"text": "proposed", "start": 15, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "guth", "start": 10, "end": 14, "i_start": 3, "i_end": 3}, "action": {"text": "solve", "start": 62, "end": 67, "i_start": 10, "i_end": 10}}], "id": 4985}, {"sent": "real-world networks , and social ones in particular , are reported to have some notable characteristics such as edge sparsity , power-law and scale-free degree distributions etc .", "tokens": ["real", "-", "world", "networks", ",", "and", "social", "ones", "in", "particular", ",", "are", "reported", "to", "have", "some", "notable", "characteristics", "such", "as", "edge", "sparsity", ",", "power", "-", "law", "and", "scale", "-", "free", "degree", "distributions", "etc", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "real-world networks", "start": 0, "end": 19, "i_start": 0, "i_end": 3}, "verb": {"text": "are reported", "start": 54, "end": 66, "i_start": 11, "i_end": 12}}], "id": 4986}, {"sent": "recently , it has been found that copositive tensors have important applications in vacuum stability of a general scalar potential .", "tokens": ["recently", ",", "it", "has", "been", "found", "that", "copositive", "tensors", "have", "important", "applications", "in", "vacuum", "stability", "of", "a", "general", "scalar", "potential", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 11, "end": 13, "i_start": 2, "i_end": 2}, "verb": {"text": "has been found", "start": 14, "end": 28, "i_start": 3, "i_end": 5}}, {"subject": {"text": "copositive tensors", "start": 34, "end": 52, "i_start": 7, "i_end": 8}, "verb": {"text": "have", "start": 53, "end": 57, "i_start": 9, "i_end": 9}}], "id": 4987}, {"sent": "explicit hilbert spaces for certain unipotent representations .", "tokens": ["explicit", "hilbert", "spaces", "for", "certain", "unipotent", "representations", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4988}, {"sent": "from the perspective of modern particle physics , gr can be treated as a unique theory of a massless spin-2 graviton .", "tokens": ["from", "the", "perspective", "of", "modern", "particle", "physics", ",", "gr", "can", "be", "treated", "as", "a", "unique", "theory", "of", "a", "massless", "spin-2", "graviton", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "gr", "start": 50, "end": 52, "i_start": 8, "i_end": 8}, "verb": {"text": "can be treated", "start": 53, "end": 67, "i_start": 9, "i_end": 11}}], "id": 4989}, {"sent": "among the observables which would be changed is the power spectrum of the primordial quantum fluctuations .", "tokens": ["among", "the", "observables", "which", "would", "be", "changed", "is", "the", "power", "spectrum", "of", "the", "primordial", "quantum", "fluctuations", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 4990}, {"sent": "in , the authors show that at high signal to noise ratios , the feedback rate required per user must grow linearly with the snr in order to obtain the full mimo bc multiplexing gain .", "tokens": ["in", ",", "the", "authors", "show", "that", "at", "high", "signal", "to", "noise", "ratios", ",", "the", "feedback", "rate", "required", "per", "user", "must", "grow", "linearly", "with", "the", "snr", "in", "order", "to", "obtain", "the", "full", "mimo", "bc", "multiplexing", "gain", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the authors", "start": 5, "end": 16, "i_start": 2, "i_end": 3}, "verb": {"text": "show", "start": 17, "end": 21, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the feedback rate required per user", "start": 60, "end": 95, "i_start": 13, "i_end": 18}, "verb": {"text": "grow", "start": 101, "end": 105, "i_start": 20, "i_end": 20}}], "id": 4991}, {"sent": "merlin is a national facility operated by the university of manchester at jodrell bank observatory on behalf of pparc .", "tokens": ["merlin", "is", "a", "national", "facility", "operated", "by", "the", "university", "of", "manchester", "at", "jodrell", "bank", "observatory", "on", "behalf", "of", "pparc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "merlin", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 7, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "university", "start": 46, "end": 56, "i_start": 8, "i_end": 8}, "action": {"text": "operated", "start": 30, "end": 38, "i_start": 5, "i_end": 5}}], "id": 4992}, {"sent": "in this study , the vienna ab initio simulation package is used , with the generalized gradient approximation along with the perdewburke-ernzerhof prescription .", "tokens": ["in", "this", "study", ",", "the", "vienna", "ab", "initio", "simulation", "package", "is", "used", ",", "with", "the", "generalized", "gradient", "approximation", "along", "with", "the", "perdewburke", "-", "ernzerhof", "prescription", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the vienna ab initio simulation package", "start": 16, "end": 55, "i_start": 4, "i_end": 9}, "verb": {"text": "is used", "start": 56, "end": 63, "i_start": 10, "i_end": 11}}], "id": 4993}, {"sent": "since string theory is a proposed fundamental theory of quantum gravity , one may expect that stringy corrections to the low energy effective theory resolve causality violations .", "tokens": ["since", "string", "theory", "is", "a", "proposed", "fundamental", "theory", "of", "quantum", "gravity", ",", "one", "may", "expect", "that", "stringy", "corrections", "to", "the", "low", "energy", "effective", "theory", "resolve", "causality", "violations", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "one", "start": 74, "end": 77, "i_start": 12, "i_end": 12}, "verb": {"text": "may expect", "start": 78, "end": 88, "i_start": 13, "i_end": 14}}, {"subject": {"text": "one", "start": 74, "end": 77, "i_start": 12, "i_end": 12}, "verb": {"text": "stringy", "start": 94, "end": 101, "i_start": 16, "i_end": 16}}, {"subject": {"text": "one", "start": 74, "end": 77, "i_start": 12, "i_end": 12}, "verb": {"text": "resolve", "start": 149, "end": 156, "i_start": 24, "i_end": 24}}, {"character": {"text": "one", "start": 74, "end": 77, "i_start": 12, "i_end": 12}, "action": {"text": "expect", "start": 82, "end": 88, "i_start": 14, "i_end": 14}}, {"character": {"text": "corrections", "start": 102, "end": 113, "i_start": 17, "i_end": 17}, "action": {"text": "resolve", "start": 149, "end": 156, "i_start": 24, "i_end": 24}}, {"character": {"text": "theory", "start": 13, "end": 19, "i_start": 2, "i_end": 2}, "action": {"text": "effective", "start": 132, "end": 141, "i_start": 22, "i_end": 22}}], "id": 4994}, {"sent": "the theory of stability conditions on triangulated categories is introduced by bridgeland on the stability of bps d-branes .", "tokens": ["the", "theory", "of", "stability", "conditions", "on", "triangulated", "categories", "is", "introduced", "by", "bridgeland", "on", "the", "stability", "of", "bps", "d", "-", "branes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the theory of stability conditions on triangulated categories", "start": 0, "end": 61, "i_start": 0, "i_end": 7}, "verb": {"text": "is introduced", "start": 62, "end": 75, "i_start": 8, "i_end": 9}}], "id": 4995}, {"sent": "generally , the free energy is a difficult quantity to evaluate .", "tokens": ["generally", ",", "the", "free", "energy", "is", "a", "difficult", "quantity", "to", "evaluate", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the free energy", "start": 12, "end": 27, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 5, "i_end": 5}}], "id": 4996}, {"sent": "the recent advanced ligo-virgo observations of coalescing binary black holes have initiated the era of gravitationalwave astronomy .", "tokens": ["the", "recent", "advanced", "ligo", "-", "virgo", "observations", "of", "coalescing", "binary", "black", "holes", "have", "initiated", "the", "era", "of", "gravitationalwave", "astronomy", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the recent advanced ligo-virgo observations of coalescing binary black holes", "start": 0, "end": 76, "i_start": 0, "i_end": 11}, "verb": {"text": "have initiated", "start": 77, "end": 91, "i_start": 12, "i_end": 13}}, {"character": {"text": "observations", "start": 31, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "initiated", "start": 82, "end": 91, "i_start": 13, "i_end": 13}}], "id": 4997}, {"sent": "learning techniques have shown significant improvements in robustness and performance , particularly in the computer vision field .", "tokens": ["learning", "techniques", "have", "shown", "significant", "improvements", "in", "robustness", "and", "performance", ",", "particularly", "in", "the", "computer", "vision", "field", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "learning techniques", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "have shown", "start": 20, "end": 30, "i_start": 2, "i_end": 3}}, {"character": {"text": "techniques", "start": 9, "end": 19, "i_start": 1, "i_end": 1}, "action": {"text": "shown", "start": 25, "end": 30, "i_start": 3, "i_end": 3}}], "id": 4998}, {"sent": "generative adversarial networks exploit the discriminative power of deep neural networks for the task of generative modeling .", "tokens": ["generative", "adversarial", "networks", "exploit", "the", "discriminative", "power", "of", "deep", "neural", "networks", "for", "the", "task", "of", "generative", "modeling", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "generative adversarial networks", "start": 0, "end": 31, "i_start": 0, "i_end": 2}, "verb": {"text": "exploit", "start": 32, "end": 39, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 2, "i_end": 2}, "action": {"text": "exploit", "start": 32, "end": 39, "i_start": 3, "i_end": 3}}, {"character": {"text": "power", "start": 59, "end": 64, "i_start": 6, "i_end": 6}, "action": {"text": "discriminative", "start": 44, "end": 58, "i_start": 5, "i_end": 5}}], "id": 4999}]