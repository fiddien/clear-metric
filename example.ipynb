{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Usage\n",
    "\n",
    "Notebook version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\Documents\\Coursework\\clear-metric\\env2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "c:\\Users\\Hp\\Documents\\Coursework\\clear-metric\\env2\\lib\\site-packages\\torch\\distributions\\distribution.py:51: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n"
     ]
    }
   ],
   "source": [
    "sents = [\n",
    "    \"I have a dream.\",\n",
    "    \"The ball is flying high.\",\n",
    "]\n",
    "scores, sents = run_parsing(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0], [1, 1, 0, 0, 0]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence     : I have a dream.\n",
      "  Structures :\n",
      "    S - V    : I - have\n",
      "  Stories    :\n",
      "    C - A    : I - have\n",
      "    C - A    : I - dream\n",
      "\n",
      "Sentence     : The ball is flying high.\n",
      "  Structures :\n",
      "    S - V    : The ball - is flying\n",
      "  Stories    :\n",
      "    None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ::snt The ball is flying high.\n",
      "# ::tokens [\"The\", \"ball\", \"is\", \"flying\", \"high\", \".\"]\n",
      "# ::ner_tags [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]\n",
      "# ::ner_iob [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]\n",
      "# ::pos_tags [\"DT\", \"NN\", \"VBZ\", \"VBG\", \"JJ\", \".\"]\n",
      "# ::lemmas [\"the\", \"ball\", \"be\", \"fly\", \"high\", \".\"]\n",
      "# ::alignments 1-1.1 3-1 4-1.2\n",
      "(f / fly-01~e.3\n",
      "   :ARG2 (b / ball~e.1)\n",
      "   :ARG1-of (h / high-02~e.4))\n"
     ]
    }
   ],
   "source": [
    "import penman\n",
    "penman_graph = penman.encode(sents.amrs.graphs[1])\n",
    "print(penman_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'example_sentences.txt'\n",
    "output_file = 'example_results.txt'\n",
    "start = 0\n",
    "end = 10\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence 0 to 3\n",
      "Elapsed time: 53.658206939697266\n",
      "Processing sentence 4 to 7\n",
      "Elapsed time: 23.70387077331543\n",
      "Processing sentence 8 to 9\n",
      "Elapsed time: 24.019585847854614\n"
     ]
    }
   ],
   "source": [
    "for batch, i, j in sents_iter(start, end, batch_size, input_file):\n",
    "    start_time = time()\n",
    "    print(\"Processing sentence {} to {}\".format(i, j))\n",
    "    scores, descriptions = run_parsing(batch)\n",
    "    save_results(scores, descriptions, output_file, i, batch_size)\n",
    "    print('Elapsed time:', time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Post-process the output file\n",
    "with open(output_file, 'r') as infile, \\\n",
    "    open(output_file.split('.')[0]+'.json', 'w') as outfile:\n",
    "    data = infile.read()\n",
    "    data = data.replace(\"][\", \",\")\n",
    "    outfile.write(data)\n",
    "os.remove(output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
