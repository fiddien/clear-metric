[{"sent": "zhang and parker proposed a new bio-inspired predictive orientation decomposition representation , which was inspired by the biological research in human anatomy .", "tokens": ["zhang", "and", "parker", "proposed", "a", "new", "bio", "-", "inspired", "predictive", "orientation", "decomposition", "representation", ",", "which", "was", "inspired", "by", "the", "biological", "research", "in", "human", "anatomy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhang and parker", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "parker", "start": 10, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "bio", "start": 32, "end": 35, "i_start": 6, "i_end": 6}, "action": {"text": "inspired", "start": 36, "end": 44, "i_start": 8, "i_end": 8}}, {"character": {"text": "research", "start": 136, "end": 144, "i_start": 20, "i_end": 20}, "action": {"text": "inspired", "start": 109, "end": 117, "i_start": 16, "i_end": 16}}], "id": 0}, {"sent": "transfer learning is a machine learning technique proposed to alleviate the distribution discrepancy issue .", "tokens": ["transfer", "learning", "is", "a", "machine", "learning", "technique", "proposed", "to", "alleviate", "the", "distribution", "discrepancy", "issue", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "transfer learning", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "learning", "start": 31, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "alleviate", "start": 62, "end": 71, "i_start": 9, "i_end": 9}}, {"character": {"text": "discrepancy", "start": 89, "end": 100, "i_start": 12, "i_end": 12}, "action": {"text": "issue", "start": 101, "end": 106, "i_start": 13, "i_end": 13}}], "id": 1}, {"sent": "this may suggest that this late time behavior can also be used as a criterion of chaotic nature of a given quantum field theory , in addition to the existing arguments on the lyapunov exponent .", "tokens": ["this", "may", "suggest", "that", "this", "late", "time", "behavior", "can", "also", "be", "used", "as", "a", "criterion", "of", "chaotic", "nature", "of", "a", "given", "quantum", "field", "theory", ",", "in", "addition", "to", "the", "existing", "arguments", "on", "the", "lyapunov", "exponent", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "may suggest", "start": 5, "end": 16, "i_start": 1, "i_end": 2}}, {"subject": {"text": "this late time behavior", "start": 22, "end": 45, "i_start": 4, "i_end": 7}, "verb": {"text": "used", "start": 58, "end": 62, "i_start": 11, "i_end": 11}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "suggest", "start": 9, "end": 16, "i_start": 2, "i_end": 2}}], "id": 2}, {"sent": "while most of research is related to marketing , the problem has been generalized to ranking nodes for target set selection in the domain of combinatorial optimization of theoretical computer science .", "tokens": ["while", "most", "of", "research", "is", "related", "to", "marketing", ",", "the", "problem", "has", "been", "generalized", "to", "ranking", "nodes", "for", "target", "set", "selection", "in", "the", "domain", "of", "combinatorial", "optimization", "of", "theoretical", "computer", "science", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the problem", "start": 49, "end": 60, "i_start": 9, "i_end": 10}, "verb": {"text": "has been generalized", "start": 61, "end": 81, "i_start": 11, "i_end": 13}}], "id": 3}, {"sent": "if we give up consistency only , then the system-environment correlations can be of the classical form .", "tokens": ["if", "we", "give", "up", "consistency", "only", ",", "then", "the", "system", "-", "environment", "correlations", "can", "be", "of", "the", "classical", "form", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the system-environment correlations", "start": 38, "end": 73, "i_start": 8, "i_end": 12}, "verb": {"text": "can be", "start": 74, "end": 80, "i_start": 13, "i_end": 14}}], "id": 4}, {"sent": "in the plane of the film and perpendicular to the long axis of the wire .", "tokens": ["in", "the", "plane", "of", "the", "film", "and", "perpendicular", "to", "the", "long", "axis", "of", "the", "wire", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 5}, {"sent": "are single-valued whereas fermion-based representationstf erm .", "tokens": ["are", "single", "-", "valued", "whereas", "fermion", "-", "based", "representations"], "score": [0, 0, 0, 0, 0], "labels": [], "id": 6}, {"sent": "hence the grand partition function \u03be contains the ionic interactions and zero frequency van der waals contributions in the system .", "tokens": ["hence", "the", "grand", "partition", "function", "\u03be", "contains", "the", "ionic", "interactions", "and", "zero", "frequency", "van", "der", "waals", "contributions", "in", "the", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hence the grand partition function \u03be", "start": 0, "end": 36, "i_start": 0, "i_end": 5}, "verb": {"text": "contains", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "function", "start": 26, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "contains", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}], "id": 7}, {"sent": "the abscissa and ordinate denote the superhump phase and magnitude , respectively .", "tokens": ["the", "abscissa", "and", "ordinate", "denote", "the", "superhump", "phase", "and", "magnitude", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the abscissa and ordinate", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "denote", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "abscissa", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "ordinate", "start": 17, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "denote", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}], "id": 8}, {"sent": "some general properties of the strong geodesic problem , in particular with respect to the diameter , and a solution for balanced complete bipartite graphs has been very recently reported in .", "tokens": ["some", "general", "properties", "of", "the", "strong", "geodesic", "problem", ",", "in", "particular", "with", "respect", "to", "the", "diameter", ",", "and", "a", "solution", "for", "balanced", "complete", "bipartite", "graphs", "has", "been", "very", "recently", "reported", "in", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "some general properties of the strong geodesic problem", "start": 0, "end": 54, "i_start": 0, "i_end": 7}, "verb": {"text": "reported", "start": 179, "end": 187, "i_start": 29, "i_end": 29}}, {"subject": {"text": "some general properties of the strong geodesic problem", "start": 0, "end": 54, "i_start": 0, "i_end": 7}, "verb": {"text": "has been", "start": 156, "end": 164, "i_start": 25, "i_end": 26}}], "id": 9}, {"sent": "mahjourian et al in addition to image alignment enforce alignment of the geometric scene structure in the loss function .", "tokens": ["mahjourian", "et", "al", "in", "addition", "to", "image", "alignment", "enforce", "alignment", "of", "the", "geometric", "scene", "structure", "in", "the", "loss", "function", "."], "score": [0, 0, 0, 0, 0], "labels": [{"character": {"text": "mahjourian", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "enforce", "start": 48, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "alignment", "start": 38, "end": 47, "i_start": 7, "i_end": 7}, "action": {"text": "enforce", "start": 48, "end": 55, "i_start": 8, "i_end": 8}}], "id": 10}, {"sent": "the key difference between our model and most existing literature is the possibility of obtaining resource through the cheaper but uncertain approach of spectrum sensing .", "tokens": ["the", "key", "difference", "between", "our", "model", "and", "most", "existing", "literature", "is", "the", "possibility", "of", "obtaining", "resource", "through", "the", "cheaper", "but", "uncertain", "approach", "of", "spectrum", "sensing", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the key difference between our model and most existing literature", "start": 0, "end": 65, "i_start": 0, "i_end": 9}, "verb": {"text": "is", "start": 66, "end": 68, "i_start": 10, "i_end": 10}}], "id": 11}, {"sent": "historically the first one is the harmonic analysis in right ascension , see for a recent application .", "tokens": ["historically", "the", "first", "one", "is", "the", "harmonic", "analysis", "in", "right", "ascension", ",", "see", "for", "a", "recent", "application", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the first one", "start": 13, "end": 26, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 4, "i_end": 4}}], "id": 12}, {"sent": "to find the local neighborhoods , we follow the idea of using both their approximations .", "tokens": ["to", "find", "the", "local", "neighborhoods", ",", "we", "follow", "the", "idea", "of", "using", "both", "their", "approximations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "verb": {"text": "follow", "start": 37, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "follow", "start": 37, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "using", "start": 56, "end": 61, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 13}, {"sent": "we also calculate the coupling of the annihilation process , which is useful for an appropriate model building to give the desired dark matter relic density .", "tokens": ["we", "also", "calculate", "the", "coupling", "of", "the", "annihilation", "process", ",", "which", "is", "useful", "for", "an", "appropriate", "model", "building", "to", "give", "the", "desired", "dark", "matter", "relic", "density", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "calculate", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "calculate", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "calculate", "start": 8, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "useful", "start": 70, "end": 76, "i_start": 12, "i_end": 12}}, {"character": {"text": "building", "start": 102, "end": 110, "i_start": 17, "i_end": 17}, "action": {"text": "give", "start": 114, "end": 118, "i_start": 19, "i_end": 19}}], "id": 14}, {"sent": "the dft description here is provided by the local density approximation of perdew-zunger .", "tokens": ["the", "dft", "description", "here", "is", "provided", "by", "the", "local", "density", "approximation", "of", "perdew", "-", "zunger", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the dft description here", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "is provided", "start": 25, "end": 36, "i_start": 4, "i_end": 5}}, {"character": {"text": "approximation", "start": 58, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "provided", "start": 28, "end": 36, "i_start": 5, "i_end": 5}}], "id": 15}, {"sent": "we refer the reader to and the references therein for general survey of the euler equations .", "tokens": ["we", "refer", "the", "reader", "to", "and", "the", "references", "therein", "for", "general", "survey", "of", "the", "euler", "equations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 16}, {"sent": "orthogonal frequency division multiplexing has become quite popular in both wired and wireless communications .", "tokens": ["orthogonal", "frequency", "division", "multiplexing", "has", "become", "quite", "popular", "in", "both", "wired", "and", "wireless", "communications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "orthogonal frequency division multiplexing", "start": 0, "end": 42, "i_start": 0, "i_end": 3}, "verb": {"text": "has become", "start": 43, "end": 53, "i_start": 4, "i_end": 5}}], "id": 17}, {"sent": "in this section , we calculate the susy algebra in the following wess-zumino model for simplicity .", "tokens": ["in", "this", "section", ",", "we", "calculate", "the", "susy", "algebra", "in", "the", "following", "wess", "-", "zumino", "model", "for", "simplicity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "calculate", "start": 21, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "calculate", "start": 21, "end": 30, "i_start": 5, "i_end": 5}}], "id": 18}, {"sent": "we trained a neural network to control the cart-pole using proximal policy optimization algorithms with 100k training episodes .", "tokens": ["we", "trained", "a", "neural", "network", "to", "control", "the", "cart", "-", "pole", "using", "proximal", "policy", "optimization", "algorithms", "with", "100k", "training", "episodes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "trained", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "trained", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "network", "start": 20, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "control", "start": 31, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "network", "start": 20, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "using", "start": 53, "end": 58, "i_start": 11, "i_end": 11}}], "id": 19}, {"sent": "linnik , on the least prime in an arithmetic progression ii , the deuringheilbronn phenomenon rec .", "tokens": ["linnik", ",", "on", "the", "least", "prime", "in", "an", "arithmetic", "progression", "ii", ",", "the", "deuringheilbronn", "phenomenon", "rec", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 20}, {"sent": "for normalization purposes , weights need to be between 0 and 1 , where larger weights are assigned to generalized items comprised of items that are more semantically distant , since such generalized items are more harmful to data utility .", "tokens": ["for", "normalization", "purposes", ",", "weights", "need", "to", "be", "between", "0", "and", "1", ",", "where", "larger", "weights", "are", "assigned", "to", "generalized", "items", "comprised", "of", "items", "that", "are", "more", "semantically", "distant", ",", "since", "such", "generalized", "items", "are", "more", "harmful", "to", "data", "utility", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "weights", "start": 29, "end": 36, "i_start": 4, "i_end": 4}, "verb": {"text": "need", "start": 37, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "items", "start": 115, "end": 120, "i_start": 20, "i_end": 20}, "action": {"text": "harmful", "start": 215, "end": 222, "i_start": 36, "i_end": 36}}], "id": 21}, {"sent": "we have applied the sso algorithm to 19 functions whose results have been compared to those produced by the particle swarm optimization method and the artificial bee colony algorithm .", "tokens": ["we", "have", "applied", "the", "sso", "algorithm", "to", "19", "functions", "whose", "results", "have", "been", "compared", "to", "those", "produced", "by", "the", "particle", "swarm", "optimization", "method", "and", "the", "artificial", "bee", "colony", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have applied", "start": 3, "end": 15, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "applied", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "method", "start": 136, "end": 142, "i_start": 22, "i_end": 22}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "optimization", "start": 123, "end": 135, "i_start": 21, "i_end": 21}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "particle", "start": 108, "end": 116, "i_start": 19, "i_end": 19}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "algorithm", "start": 173, "end": 182, "i_start": 28, "i_end": 28}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "colony", "start": 166, "end": 172, "i_start": 27, "i_end": 27}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "artificial", "start": 151, "end": 161, "i_start": 25, "i_end": 25}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "bee", "start": 162, "end": 165, "i_start": 26, "i_end": 26}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}], "id": 22}, {"sent": "it makes rydberg atoms promising for applications such as quantum information processing .", "tokens": ["it", "makes", "rydberg", "atoms", "promising", "for", "applications", "such", "as", "quantum", "information", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "makes", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "rydberg atoms", "start": 9, "end": 22, "i_start": 2, "i_end": 3}, "verb": {"text": "promising", "start": 23, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "makes", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "atoms", "start": 17, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "promising", "start": 23, "end": 32, "i_start": 4, "i_end": 4}}], "id": 23}, {"sent": "this brings the ability to target users based on their past behavior , which is typically referred to as ad targeting .", "tokens": ["this", "brings", "the", "ability", "to", "target", "users", "based", "on", "their", "past", "behavior", ",", "which", "is", "typically", "referred", "to", "as", "ad", "targeting", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "brings", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "brings", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}], "id": 24}, {"sent": "an early research extended virtualization solutions to support rich and effective policies for active power management which had not been done before .", "tokens": ["an", "early", "research", "extended", "virtualization", "solutions", "to", "support", "rich", "and", "effective", "policies", "for", "active", "power", "management", "which", "had", "not", "been", "done", "before", "."], "score": [0, 0, 0, 0, 0], "labels": [{"character": {"text": "research", "start": 9, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "extended", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "solutions", "start": 42, "end": 51, "i_start": 5, "i_end": 5}, "action": {"text": "support", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}, {"character": {"text": "policies", "start": 82, "end": 90, "i_start": 11, "i_end": 11}, "action": {"text": "effective", "start": 72, "end": 81, "i_start": 10, "i_end": 10}}], "id": 25}, {"sent": "the needlets bispectrum , electronic journal of statistics , vol .", "tokens": ["the", "needlets", "bispectrum", ",", "electronic", "journal", "of", "statistics", ",", "vol", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 26}, {"sent": "we will derive in this letter three families of exactly solvable models based on the pairing interaction for fermion systems as well as for boson systems .", "tokens": ["we", "will", "derive", "in", "this", "letter", "three", "families", "of", "exactly", "solvable", "models", "based", "on", "the", "pairing", "interaction", "for", "fermion", "systems", "as", "well", "as", "for", "boson", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will derive", "start": 3, "end": 14, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "derive", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}], "id": 27}, {"sent": "we will now discuss the symmetry operators related to such spectral mirror symmetries .", "tokens": ["we", "will", "now", "discuss", "the", "symmetry", "operators", "related", "to", "such", "spectral", "mirror", "symmetries", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "discuss", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "discuss", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}], "id": 28}, {"sent": "the magnetization bands increase with x .", "tokens": ["the", "magnetization", "bands", "increase", "with", "x", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the magnetization bands", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "increase", "start": 24, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "bands", "start": 18, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "magnetization", "start": 4, "end": 17, "i_start": 1, "i_end": 1}}], "id": 29}, {"sent": "since the diffusion coefficient is a well defined concept , this estimate might ultimately be compared to lattice qcd calculations , confirming or rejecting the paradigm of qgp formation in relativistic heavy ion collisions .", "tokens": ["since", "the", "diffusion", "coefficient", "is", "a", "well", "defined", "concept", ",", "this", "estimate", "might", "ultimately", "be", "compared", "to", "lattice", "qcd", "calculations", ",", "confirming", "or", "rejecting", "the", "paradigm", "of", "qgp", "formation", "in", "relativistic", "heavy", "ion", "collisions", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "this estimate", "start": 60, "end": 73, "i_start": 10, "i_end": 11}, "verb": {"text": "be compared", "start": 91, "end": 102, "i_start": 14, "i_end": 15}}, {"subject": {"text": "this estimate", "start": 60, "end": 73, "i_start": 10, "i_end": 11}, "verb": {"text": "might", "start": 74, "end": 79, "i_start": 12, "i_end": 12}}], "id": 30}, {"sent": "a closed-form expression for the probability of los is also provided in .", "tokens": ["a", "closed", "-", "form", "expression", "for", "the", "probability", "of", "los", "is", "also", "provided", "in", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "a closed-form expression for the probability of los", "start": 0, "end": 51, "i_start": 0, "i_end": 9}, "verb": {"text": "provided", "start": 60, "end": 68, "i_start": 12, "i_end": 12}}, {"subject": {"text": "a closed-form expression for the probability of los", "start": 0, "end": 51, "i_start": 0, "i_end": 9}, "verb": {"text": "is", "start": 52, "end": 54, "i_start": 10, "i_end": 10}}], "id": 31}, {"sent": "the most related in this line is where each user lies in an cluster that can be described by low-dimensional vector , with 2 separation across clusters .", "tokens": ["the", "most", "related", "in", "this", "line", "is", "where", "each", "user", "lies", "in", "an", "cluster", "that", "can", "be", "described", "by", "low", "-", "dimensional", "vector", ",", "with", "2", "separation", "across", "clusters", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most related in this line", "start": 0, "end": 29, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 6, "i_end": 6}}, {"subject": {"text": "each user", "start": 39, "end": 48, "i_start": 8, "i_end": 9}, "verb": {"text": "lies", "start": 49, "end": 53, "i_start": 10, "i_end": 10}}, {"character": {"text": "vector", "start": 109, "end": 115, "i_start": 22, "i_end": 22}, "action": {"text": "described", "start": 80, "end": 89, "i_start": 17, "i_end": 17}}], "id": 32}, {"sent": "we also show that the lp formulation of the smooth rectangle bound coincides with its natural definition as described above .", "tokens": ["we", "also", "show", "that", "the", "lp", "formulation", "of", "the", "smooth", "rectangle", "bound", "coincides", "with", "its", "natural", "definition", "as", "described", "above", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}], "id": 33}, {"sent": "current schemes for classifying protein structure often rely on manually curated hierarchies such as that are not able to cleanly capture all possible variations .", "tokens": ["current", "schemes", "for", "classifying", "protein", "structure", "often", "rely", "on", "manually", "curated", "hierarchies", "such", "as", "that", "are", "not", "able", "to", "cleanly", "capture", "all", "possible", "variations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "current schemes for classifying protein structure", "start": 0, "end": 49, "i_start": 0, "i_end": 5}, "verb": {"text": "rely", "start": 56, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "schemes", "start": 8, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "rely", "start": 56, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "hierarchies", "start": 81, "end": 92, "i_start": 11, "i_end": 11}, "action": {"text": "capture", "start": 130, "end": 137, "i_start": 20, "i_end": 20}}], "id": 34}, {"sent": "we use the training set and test set of the bsds500 database for training , and its validation set for validation .", "tokens": ["we", "use", "the", "training", "set", "and", "test", "set", "of", "the", "bsds500", "database", "for", "training", ",", "and", "its", "validation", "set", "for", "validation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 35}, {"sent": "generalizations of these equations for arbitrary root systems were constructed by cherednik .", "tokens": ["generalizations", "of", "these", "equations", "for", "arbitrary", "root", "systems", "were", "constructed", "by", "cherednik", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "generalizations of these equations for arbitrary root systems", "start": 0, "end": 61, "i_start": 0, "i_end": 7}, "verb": {"text": "were constructed", "start": 62, "end": 78, "i_start": 8, "i_end": 9}}, {"character": {"text": "cherednik", "start": 82, "end": 91, "i_start": 11, "i_end": 11}, "action": {"text": "constructed", "start": 67, "end": 78, "i_start": 9, "i_end": 9}}], "id": 36}, {"sent": "millimeter waves , for cellular communications , is among the most striking technological innovations brought by fifth generation wireless networks .", "tokens": ["millimeter", "waves", ",", "for", "cellular", "communications", ",", "is", "among", "the", "most", "striking", "technological", "innovations", "brought", "by", "fifth", "generation", "wireless", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "millimeter waves", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 49, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 139, "end": 147, "i_start": 19, "i_end": 19}, "action": {"text": "brought", "start": 102, "end": 109, "i_start": 14, "i_end": 14}}, {"character": {"text": "innovations", "start": 90, "end": 101, "i_start": 13, "i_end": 13}, "action": {"text": "striking", "start": 67, "end": 75, "i_start": 11, "i_end": 11}}], "id": 37}, {"sent": "a reaction with chemi- and physi- sorbed glycerol would account for the prompt and the slow hole decay , respectively .", "tokens": ["a", "reaction", "with", "chemi-", "and", "physi-", "sorbed", "glycerol", "would", "account", "for", "the", "prompt", "and", "the", "slow", "hole", "decay", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a reaction with chemi- and physi- sorbed glycerol", "start": 0, "end": 49, "i_start": 0, "i_end": 7}, "verb": {"text": "would account", "start": 50, "end": 63, "i_start": 8, "i_end": 9}}, {"character": {"text": "reaction", "start": 2, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "account", "start": 56, "end": 63, "i_start": 9, "i_end": 9}}], "id": 38}, {"sent": "during the outflow of liquid stream under the reposing liquid level .", "tokens": ["during", "the", "outflow", "of", "liquid", "stream", "under", "the", "reposing", "liquid", "level", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 39}, {"sent": "now we define when are these na-quad rings , smarandache quad rings .", "tokens": ["now", "we", "define", "when", "are", "these", "na", "-", "quad", "rings", ",", "smarandache", "quad", "rings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "define", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}], "id": 40}, {"sent": "to analyze the data and obtain the phase diagram , we use the bruce-wilding fss techniques outlined here .", "tokens": ["to", "analyze", "the", "data", "and", "obtain", "the", "phase", "diagram", ",", "we", "use", "the", "bruce", "-", "wilding", "fss", "techniques", "outlined", "here", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "verb": {"text": "use", "start": 54, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "use", "start": 54, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "analyze", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "obtain", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}], "id": 41}, {"sent": "the momentum equation is discretised using the symmetric interior penalty method for the elliptic term and otherwise using the fluxes from cockburn et al .", "tokens": ["the", "momentum", "equation", "is", "discretised", "using", "the", "symmetric", "interior", "penalty", "method", "for", "the", "elliptic", "term", "and", "otherwise", "using", "the", "fluxes", "from", "cockburn", "et", "al", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "the momentum equation", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is discretised", "start": 22, "end": 36, "i_start": 3, "i_end": 4}}, {"subject": {"text": "the momentum equation", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "using", "start": 117, "end": 122, "i_start": 17, "i_end": 17}}], "id": 42}, {"sent": "spectrum sharing is a well-studied subject in general , for example in the context of cognitive radios .", "tokens": ["spectrum", "sharing", "is", "a", "well", "-", "studied", "subject", "in", "general", ",", "for", "example", "in", "the", "context", "of", "cognitive", "radios", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "spectrum sharing", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}], "id": 43}, {"sent": "a combination of two different mechanisms yields , good quantitative and qualitative agreement between the experimentally derived and the simulated eley-rideal abstraction cross sections and surface configurations .", "tokens": ["a", "combination", "of", "two", "different", "mechanisms", "yields", ",", "good", "quantitative", "and", "qualitative", "agreement", "between", "the", "experimentally", "derived", "and", "the", "simulated", "eley", "-", "rideal", "abstraction", "cross", "sections", "and", "surface", "configurations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"character": {"text": "combination", "start": 2, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "yields", "start": 42, "end": 48, "i_start": 6, "i_end": 6}}], "id": 44}, {"sent": "to our knowledge , all known problem-pairs with a zero duality gap , also known as strong duality , are polynomially solvable .", "tokens": ["to", "our", "knowledge", ",", "all", "known", "problem", "-", "pairs", "with", "a", "zero", "duality", "gap", ",", "also", "known", "as", "strong", "duality", ",", "are", "polynomially", "solvable", "."], "score": [0, 0, 1, 0, 1], "labels": [{"subject": {"text": "all known problem-pairs with a zero duality gap", "start": 19, "end": 66, "i_start": 4, "i_end": 13}, "verb": {"text": "are", "start": 100, "end": 103, "i_start": 21, "i_end": 21}}], "id": 45}, {"sent": "the detector current decreases upon transition of the electron from the lower to the upper dot .", "tokens": ["the", "detector", "current", "decreases", "upon", "transition", "of", "the", "electron", "from", "the", "lower", "to", "the", "upper", "dot", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 46}, {"sent": "several studies for dnn-based image completion have presented demonstrations of face appearance manipulation by filling the parts of an input image with their dnns .", "tokens": ["several", "studies", "for", "dnn", "-", "based", "image", "completion", "have", "presented", "demonstrations", "of", "face", "appearance", "manipulation", "by", "filling", "the", "parts", "of", "an", "input", "image", "with", "their", "dnns", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "several studies for dnn-based image completion", "start": 0, "end": 46, "i_start": 0, "i_end": 7}, "verb": {"text": "have presented", "start": 47, "end": 61, "i_start": 8, "i_end": 9}}, {"character": {"text": "studies", "start": 8, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "demonstrations", "start": 62, "end": 76, "i_start": 10, "i_end": 10}}], "id": 47}, {"sent": "this observation is somewhat surprising , since this is not the case for qeccs .", "tokens": ["this", "observation", "is", "somewhat", "surprising", ",", "since", "this", "is", "not", "the", "case", "for", "qeccs", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this observation", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "observation", "start": 5, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "surprising", "start": 29, "end": 39, "i_start": 4, "i_end": 4}}], "id": 48}, {"sent": "this implies that r and the multiplication map are local homeomorphisms and that .", "tokens": ["this", "implies", "that", "r", "and", "the", "multiplication", "map", "are", "local", "homeomorphisms", "and", "that", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "implies", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 47, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "implies", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}], "id": 49}, {"sent": "we are able to solve the above problems for the case of probabilistic transformations too .", "tokens": ["we", "are", "able", "to", "solve", "the", "above", "problems", "for", "the", "case", "of", "probabilistic", "transformations", "too", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "solve", "start": 15, "end": 20, "i_start": 4, "i_end": 4}}], "id": 50}, {"sent": "in this section , we define non-commutative toric varieties and describe some of their most basic properties .", "tokens": ["in", "this", "section", ",", "we", "define", "non", "-", "commutative", "toric", "varieties", "and", "describe", "some", "of", "their", "most", "basic", "properties", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "define", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "describe", "start": 64, "end": 72, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "define", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "describe", "start": 64, "end": 72, "i_start": 12, "i_end": 12}}], "id": 51}, {"sent": "a client that browses to a website through an or network will have their traffic relayed before it reaches its destination .", "tokens": ["a", "client", "that", "browses", "to", "a", "website", "through", "an", "or", "network", "will", "have", "their", "traffic", "relayed", "before", "it", "reaches", "its", "destination", "."], "score": [0, 1, 1, 1, 0], "labels": [{"subject": {"text": "a client that browses to a website through an or network", "start": 0, "end": 56, "i_start": 0, "i_end": 10}, "verb": {"text": "will have", "start": 57, "end": 66, "i_start": 11, "i_end": 12}}, {"subject": {"text": "their traffic", "start": 67, "end": 80, "i_start": 13, "i_end": 14}, "verb": {"text": "relayed", "start": 81, "end": 88, "i_start": 15, "i_end": 15}}, {"character": {"text": "client", "start": 2, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "browses", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "traffic", "start": 73, "end": 80, "i_start": 14, "i_end": 14}, "action": {"text": "reaches", "start": 99, "end": 106, "i_start": 18, "i_end": 18}}], "id": 52}, {"sent": "to obtain the branes of the corresponding open-string wzw orbifolds .", "tokens": ["to", "obtain", "the", "branes", "of", "the", "corresponding", "open", "-", "string", "wzw", "orbifolds", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 53}, {"sent": "the change of sign of the effect with respect of the change \u03b4 \u03b4 and the substitution of neutrinos by antineutrinos is clearly visible .", "tokens": ["the", "change", "of", "sign", "of", "the", "effect", "with", "respect", "of", "the", "change", "\u03b4", "\u03b4", "and", "the", "substitution", "of", "neutrinos", "by", "antineutrinos", "is", "clearly", "visible", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the change of sign of the effect with respect of the change \u03b4 \u03b4 and the substitution of neutrinos by antineutrinos", "start": 0, "end": 114, "i_start": 0, "i_end": 20}, "verb": {"text": "is", "start": 115, "end": 117, "i_start": 21, "i_end": 21}}], "id": 54}, {"sent": "although the time complexity of this problem is exponential in the size of the input , this does not deny the existence of a fast algorithm .", "tokens": ["although", "the", "time", "complexity", "of", "this", "problem", "is", "exponential", "in", "the", "size", "of", "the", "input", ",", "this", "does", "not", "deny", "the", "existence", "of", "a", "fast", "algorithm", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "this", "start": 87, "end": 91, "i_start": 16, "i_end": 16}, "verb": {"text": "does not deny", "start": 92, "end": 105, "i_start": 17, "i_end": 19}}, {"character": {"text": "exponential", "start": 48, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "not deny", "start": 97, "end": 105, "i_start": 18, "i_end": 19}}], "id": 55}, {"sent": "we verify the safety of the control algorithm modeled as a hybrid program in model 2 , using a formal proof calculus for dl .", "tokens": ["we", "verify", "the", "safety", "of", "the", "control", "algorithm", "modeled", "as", "a", "hybrid", "program", "in", "model", "2", ",", "using", "a", "formal", "proof", "calculus", "for", "dl", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "verify", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "verify", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 87, "end": 92, "i_start": 17, "i_end": 17}}], "id": 56}, {"sent": "a u-net based encoder-decoder neural network was used for root segmentation .", "tokens": ["a", "u", "-", "net", "based", "encoder", "-", "decoder", "neural", "network", "was", "used", "for", "root", "segmentation", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "a u-net based encoder-decoder neural network", "start": 0, "end": 44, "i_start": 0, "i_end": 9}, "verb": {"text": "was used", "start": 45, "end": 53, "i_start": 10, "i_end": 11}}, {"character": {"text": "network", "start": 37, "end": 44, "i_start": 9, "i_end": 9}, "action": {"text": "decoder", "start": 22, "end": 29, "i_start": 7, "i_end": 7}}], "id": 57}, {"sent": "the nonflatness of the base metric for 3-charge microstate geometries was already noted in the particular solution of , and it had remained until now a largely unexplained phenomenon .", "tokens": ["the", "nonflatness", "of", "the", "base", "metric", "for", "3", "-", "charge", "microstate", "geometries", "was", "already", "noted", "in", "the", "particular", "solution", "of", ",", "and", "it", "had", "remained", "until", "now", "a", "largely", "unexplained", "phenomenon", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "it", "start": 124, "end": 126, "i_start": 22, "i_end": 22}, "verb": {"text": "noted", "start": 82, "end": 87, "i_start": 14, "i_end": 14}}, {"subject": {"text": "the nonflatness of the base metric for 3-charge microstate geometries", "start": 0, "end": 69, "i_start": 0, "i_end": 11}, "verb": {"text": "was", "start": 70, "end": 73, "i_start": 12, "i_end": 12}}, {"subject": {"text": "the nonflatness of the base metric for 3-charge microstate geometries", "start": 0, "end": 69, "i_start": 0, "i_end": 11}, "verb": {"text": "remained", "start": 131, "end": 139, "i_start": 24, "i_end": 24}}], "id": 58}, {"sent": "in this paper , we consider a uplink single-cell massive mimo system with m antennas at the bs and n single-antenna users .", "tokens": ["in", "this", "paper", ",", "we", "consider", "a", "uplink", "single", "-", "cell", "massive", "mimo", "system", "with", "m", "antennas", "at", "the", "bs", "and", "n", "single", "-", "antenna", "users", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "consider", "start": 19, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "consider", "start": 19, "end": 27, "i_start": 5, "i_end": 5}}], "id": 59}, {"sent": "for the numerical experiments in this paper we implemented a new variant of the cross3d method -schur-cross3d which has better asymptotic complexity in r than the method described in .", "tokens": ["for", "the", "numerical", "experiments", "in", "this", "paper", "we", "implemented", "a", "new", "variant", "of", "the", "cross3d", "method", "-schur", "-", "cross3d", "which", "has", "better", "asymptotic", "complexity", "in", "r", "than", "the", "method", "described", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 44, "end": 46, "i_start": 7, "i_end": 7}, "verb": {"text": "implemented", "start": 47, "end": 58, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 44, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "implemented", "start": 47, "end": 58, "i_start": 8, "i_end": 8}}, {"character": {"text": "method", "start": 88, "end": 94, "i_start": 15, "i_end": 15}, "action": {"text": "has", "start": 116, "end": 119, "i_start": 20, "i_end": 20}}], "id": 60}, {"sent": "flow chart showing the procedure for obtaining the pdf .", "tokens": ["flow", "chart", "showing", "the", "procedure", "for", "obtaining", "the", "pdf", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "flow chart", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "showing", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "chart", "start": 5, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "showing", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}], "id": 61}, {"sent": "more recently , the resource optimization in orthogonal frequency division multiplexing based single-user single-relay systems was considered in .", "tokens": ["more", "recently", ",", "the", "resource", "optimization", "in", "orthogonal", "frequency", "division", "multiplexing", "based", "single", "-", "user", "single", "-", "relay", "systems", "was", "considered", "in", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the resource optimization in orthogonal frequency division multiplexing based single-user single-relay systems", "start": 16, "end": 126, "i_start": 3, "i_end": 18}, "verb": {"text": "was considered", "start": 127, "end": 141, "i_start": 19, "i_end": 20}}], "id": 62}, {"sent": "the robustness of this method has been verified for calculating primordial spectra in k-inflation .", "tokens": ["the", "robustness", "of", "this", "method", "has", "been", "verified", "for", "calculating", "primordial", "spectra", "in", "k", "-", "inflation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the robustness of this method", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "has been verified", "start": 30, "end": 47, "i_start": 5, "i_end": 7}}], "id": 63}, {"sent": "we calculate the critical temperatures and angular dependence of the order parameters .", "tokens": ["we", "calculate", "the", "critical", "temperatures", "and", "angular", "dependence", "of", "the", "order", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "calculate", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "calculate", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "parameters", "start": 75, "end": 85, "i_start": 11, "i_end": 11}, "action": {"text": "dependence", "start": 51, "end": 61, "i_start": 7, "i_end": 7}}], "id": 64}, {"sent": "the addition of salt is known to reduce the effective surface area per head group , leading to the stabilization of the cylindrical shape .", "tokens": ["the", "addition", "of", "salt", "is", "known", "to", "reduce", "the", "effective", "surface", "area", "per", "head", "group", ",", "leading", "to", "the", "stabilization", "of", "the", "cylindrical", "shape", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the addition of salt", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "is known", "start": 21, "end": 29, "i_start": 4, "i_end": 5}}, {"character": {"text": "reduce", "start": 33, "end": 39, "i_start": 7, "i_end": 7}, "action": {"text": "leading", "start": 84, "end": 91, "i_start": 16, "i_end": 16}}], "id": 65}, {"sent": "yau , embedded minimal surfaces , exotic spheres , and mani folds with positie ricci curvature , ann .", "tokens": ["yau", ",", "embedded", "minimal", "surfaces", ",", "exotic", "spheres", ",", "and", "mani", "folds", "with", "positie", "ricci", "curvature", ",", "ann", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 66}, {"sent": "furthermore , there is no obvious functoriality for the tame fundamental group .", "tokens": ["furthermore", ",", "there", "is", "no", "obvious", "functoriality", "for", "the", "tame", "fundamental", "group", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 14, "end": 19, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 67}, {"sent": "regardless of the quality of multiclass pixel classifier output , the algorithms in do not distinguish between regions of one sub-structure from those of another at the superpixel level .", "tokens": ["regardless", "of", "the", "quality", "of", "multiclass", "pixel", "classifier", "output", ",", "the", "algorithms", "in", "do", "not", "distinguish", "between", "regions", "of", "one", "sub", "-", "structure", "from", "those", "of", "another", "at", "the", "superpixel", "level", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "the algorithms in", "start": 66, "end": 83, "i_start": 10, "i_end": 12}, "verb": {"text": "do not distinguish", "start": 84, "end": 102, "i_start": 13, "i_end": 15}}, {"character": {"text": "algorithms", "start": 70, "end": 80, "i_start": 11, "i_end": 11}, "action": {"text": "not distinguish", "start": 87, "end": 102, "i_start": 14, "i_end": 15}}], "id": 68}, {"sent": "we start with the definition of a cluster algebra a .", "tokens": ["we", "start", "with", "the", "definition", "of", "a", "cluster", "algebra", "a", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "start", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "start", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 69}, {"sent": "in this section we discuss the relationship between our approach and the effective field theory of large scale structure approach of .", "tokens": ["in", "this", "section", "we", "discuss", "the", "relationship", "between", "our", "approach", "and", "the", "effective", "field", "theory", "of", "large", "scale", "structure", "approach", "of", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "discuss", "start": 19, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "discuss", "start": 19, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "approach", "start": 56, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "relationship", "start": 31, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "approach", "start": 56, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "theory", "start": 89, "end": 95, "i_start": 14, "i_end": 14}, "action": {"text": "effective", "start": 73, "end": 82, "i_start": 12, "i_end": 12}}], "id": 70}, {"sent": "for outdoor links we assume the itu-r model for line-of-sight propagation within street canyons and the itu-r non-line-of-sight model for over roof-top propagation .", "tokens": ["for", "outdoor", "links", "we", "assume", "the", "itu", "-", "r", "model", "for", "line", "-", "of", "-", "sight", "propagation", "within", "street", "canyons", "and", "the", "itu", "-", "r", "non", "-", "line", "-", "of", "-", "sight", "model", "for", "over", "roof", "-", "top", "propagation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 3, "i_end": 3}, "verb": {"text": "assume", "start": 21, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "assume", "start": 21, "end": 27, "i_start": 4, "i_end": 4}}], "id": 71}, {"sent": "similar improved thresholds were achieved in , where the concept of spatial coupling was applied to csa .", "tokens": ["similar", "improved", "thresholds", "were", "achieved", "in", ",", "where", "the", "concept", "of", "spatial", "coupling", "was", "applied", "to", "csa", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "similar improved thresholds", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "were achieved", "start": 28, "end": 41, "i_start": 3, "i_end": 4}}], "id": 72}, {"sent": "given a bspp , several first-order methods with attractive convergence properties have been introduced .", "tokens": ["given", "a", "bspp", ",", "several", "first", "-", "order", "methods", "with", "attractive", "convergence", "properties", "have", "been", "introduced", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "several first-order methods with attractive convergence properties", "start": 15, "end": 81, "i_start": 4, "i_end": 12}, "verb": {"text": "have been introduced", "start": 82, "end": 102, "i_start": 13, "i_end": 15}}, {"character": {"text": "methods", "start": 35, "end": 42, "i_start": 8, "i_end": 8}, "action": {"text": "attractive", "start": 48, "end": 58, "i_start": 10, "i_end": 10}}], "id": 73}, {"sent": "the vertical axis is time , the horizontal one is physical distance .", "tokens": ["the", "vertical", "axis", "is", "time", ",", "the", "horizontal", "one", "is", "physical", "distance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the horizontal one", "start": 28, "end": 46, "i_start": 6, "i_end": 8}, "verb": {"text": "is", "start": 47, "end": 49, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the horizontal one", "start": 28, "end": 46, "i_start": 6, "i_end": 8}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}], "id": 74}, {"sent": "however , there exist control systems which are small-time locally controllable from x 0 , but one can not check their smalltime local controllability using classical control variations constructed by the iterated family of lie brackets .", "tokens": ["however", ",", "there", "exist", "control", "systems", "which", "are", "small", "-", "time", "locally", "controllable", "from", "x", "0", ",", "but", "one", "can", "not", "check", "their", "smalltime", "local", "controllability", "using", "classical", "control", "variations", "constructed", "by", "the", "iterated", "family", "of", "lie", "brackets", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "there", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "verb": {"text": "exist", "start": 16, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "one", "start": 95, "end": 98, "i_start": 18, "i_end": 18}, "verb": {"text": "check", "start": 107, "end": 112, "i_start": 21, "i_end": 21}}, {"character": {"text": "one", "start": 95, "end": 98, "i_start": 18, "i_end": 18}, "action": {"text": "check", "start": 107, "end": 112, "i_start": 21, "i_end": 21}}, {"character": {"text": "family", "start": 214, "end": 220, "i_start": 34, "i_end": 34}, "action": {"text": "constructed", "start": 186, "end": 197, "i_start": 30, "i_end": 30}}], "id": 75}, {"sent": "the lattice boltzmann algorithm has proven to be an extremely interesting method for the solution of navier-stokes flows because of its simplicity , extreme parallelizability and accuracy .", "tokens": ["the", "lattice", "boltzmann", "algorithm", "has", "proven", "to", "be", "an", "extremely", "interesting", "method", "for", "the", "solution", "of", "navier", "-", "stokes", "flows", "because", "of", "its", "simplicity", ",", "extreme", "parallelizability", "and", "accuracy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the lattice boltzmann algorithm", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "has proven", "start": 32, "end": 42, "i_start": 4, "i_end": 5}}], "id": 76}, {"sent": "using the classical three-field notation in scheduling , the problem can be denoted as p , r j , d j , t , .", "tokens": ["using", "the", "classical", "three", "-", "field", "notation", "in", "scheduling", ",", "the", "problem", "can", "be", "denoted", "as", "p", ",", "r", "j", ",", "d", "j", ",", "t", ",", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the problem", "start": 57, "end": 68, "i_start": 10, "i_end": 11}, "verb": {"text": "can be denoted", "start": 69, "end": 83, "i_start": 12, "i_end": 14}}], "id": 77}, {"sent": "we have also quantitatively discussed how inappropriate it is to use the original distribution instead of the escort distribution in nonextensive statistical mechanics .", "tokens": ["we", "have", "also", "quantitatively", "discussed", "how", "inappropriate", "it", "is", "to", "use", "the", "original", "distribution", "instead", "of", "the", "escort", "distribution", "in", "nonextensive", "statistical", "mechanics", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "discussed", "start": 28, "end": 37, "i_start": 4, "i_end": 4}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 59, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "discussed", "start": 28, "end": 37, "i_start": 4, "i_end": 4}}], "id": 78}, {"sent": "measures in the space of density matrices a .", "tokens": ["measures", "in", "the", "space", "of", "density", "matrices", "a", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 79}, {"sent": "the supersymmetry transformations are not modified by the moyal product since they are linear in the fields .", "tokens": ["the", "supersymmetry", "transformations", "are", "not", "modified", "by", "the", "moyal", "product", "since", "they", "are", "linear", "in", "the", "fields", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the supersymmetry transformations", "start": 0, "end": 33, "i_start": 0, "i_end": 2}, "verb": {"text": "are not modified", "start": 34, "end": 50, "i_start": 3, "i_end": 5}}, {"character": {"text": "product", "start": 64, "end": 71, "i_start": 9, "i_end": 9}, "action": {"text": "not modified", "start": 38, "end": 50, "i_start": 4, "i_end": 5}}], "id": 80}, {"sent": "we use the official split of data , where 249 scenes are used for training and we sample 50k images out of the training set with the same manner as .", "tokens": ["we", "use", "the", "official", "split", "of", "data", ",", "where", "249", "scenes", "are", "used", "for", "training", "and", "we", "sample", "50k", "images", "out", "of", "the", "training", "set", "with", "the", "same", "manner", "as", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 79, "end": 81, "i_start": 16, "i_end": 16}, "verb": {"text": "sample", "start": 82, "end": 88, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "sample", "start": 82, "end": 88, "i_start": 17, "i_end": 17}}], "id": 81}, {"sent": "this completes the proof that a is a derivation relative to \u03c3m .", "tokens": ["this", "completes", "the", "proof", "that", "a", "is", "a", "derivation", "relative", "to", "\u03c3m", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "completes", "start": 5, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "completes", "start": 5, "end": 14, "i_start": 1, "i_end": 1}}], "id": 82}, {"sent": "the systematic study of truncated toeplitz operators was initiated by sarason .", "tokens": ["the", "systematic", "study", "of", "truncated", "toeplitz", "operators", "was", "initiated", "by", "sarason", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the systematic study of truncated toeplitz operators", "start": 0, "end": 52, "i_start": 0, "i_end": 6}, "verb": {"text": "was initiated", "start": 53, "end": 66, "i_start": 7, "i_end": 8}}, {"character": {"text": "sarason", "start": 70, "end": 77, "i_start": 10, "i_end": 10}, "action": {"text": "initiated", "start": 57, "end": 66, "i_start": 8, "i_end": 8}}], "id": 83}, {"sent": "the minimum of this potential corresponds to the monopole condensate .", "tokens": ["the", "minimum", "of", "this", "potential", "corresponds", "to", "the", "monopole", "condensate", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the minimum of this potential", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "corresponds", "start": 30, "end": 41, "i_start": 5, "i_end": 5}}], "id": 84}, {"sent": "the type iib matrix model was proposed as a possible nonperturbative formulation of superstring theory in 1996 .", "tokens": ["the", "type", "iib", "matrix", "model", "was", "proposed", "as", "a", "possible", "nonperturbative", "formulation", "of", "superstring", "theory", "in", "1996", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the type iib matrix model", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "was proposed", "start": 26, "end": 38, "i_start": 5, "i_end": 6}}], "id": 85}, {"sent": "the ability to detect small alterations in brain tissue is a key factor when developing biomarkers for early stages of neurodegenerative diseases .", "tokens": ["the", "ability", "to", "detect", "small", "alterations", "in", "brain", "tissue", "is", "a", "key", "factor", "when", "developing", "biomarkers", "for", "early", "stages", "of", "neurodegenerative", "diseases", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the ability to detect small alterations in brain tissue", "start": 0, "end": 55, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 56, "end": 58, "i_start": 9, "i_end": 9}}], "id": 86}, {"sent": "according to the usual notion of consensus , the network nodes should converge , asymptotically or in a finite time , to an equilibrium point where all the nodes have the same value lying somewhere between the minimum and maximum of their initial values .", "tokens": ["according", "to", "the", "usual", "notion", "of", "consensus", ",", "the", "network", "nodes", "should", "converge", ",", "asymptotically", "or", "in", "a", "finite", "time", ",", "to", "an", "equilibrium", "point", "where", "all", "the", "nodes", "have", "the", "same", "value", "lying", "somewhere", "between", "the", "minimum", "and", "maximum", "of", "their", "initial", "values", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the network nodes", "start": 45, "end": 62, "i_start": 8, "i_end": 10}, "verb": {"text": "should converge", "start": 63, "end": 78, "i_start": 11, "i_end": 12}}], "id": 87}, {"sent": "in the open phase , a sends the procedure for revealing the hidden commitment at time t 3 and b use this .", "tokens": ["in", "the", "open", "phase", ",", "a", "sends", "the", "procedure", "for", "revealing", "the", "hidden", "commitment", "at", "time", "t", "3", "and", "b", "use", "this", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a", "start": 20, "end": 21, "i_start": 5, "i_end": 5}, "verb": {"text": "sends", "start": 22, "end": 27, "i_start": 6, "i_end": 6}}], "id": 88}, {"sent": "floating-point arithmetics has became wide spread in many applications such as 3d graphics , scientific computing and signal processing .", "tokens": ["floating", "-", "point", "arithmetics", "has", "became", "wide", "spread", "in", "many", "applications", "such", "as", "3d", "graphics", ",", "scientific", "computing", "and", "signal", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "floating-point arithmetics", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "has became", "start": 27, "end": 37, "i_start": 4, "i_end": 5}}], "id": 89}, {"sent": "however , in these strayfield-coupled multilayers , the large dipolar fields can dominate the dmi and stabilise skyrmions with hybrid chiralities across the film thickness .", "tokens": ["however", ",", "in", "these", "strayfield", "-", "coupled", "multilayers", ",", "the", "large", "dipolar", "fields", "can", "dominate", "the", "dmi", "and", "stabilise", "skyrmions", "with", "hybrid", "chiralities", "across", "the", "film", "thickness", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the large dipolar fields", "start": 52, "end": 76, "i_start": 9, "i_end": 12}, "verb": {"text": "can dominate", "start": 77, "end": 89, "i_start": 13, "i_end": 14}}, {"character": {"text": "fields", "start": 70, "end": 76, "i_start": 12, "i_end": 12}, "action": {"text": "dominate", "start": 81, "end": 89, "i_start": 14, "i_end": 14}}, {"character": {"text": "fields", "start": 70, "end": 76, "i_start": 12, "i_end": 12}, "action": {"text": "stabilise", "start": 102, "end": 111, "i_start": 18, "i_end": 18}}], "id": 90}, {"sent": "this interesting spatiotemporal behavior was first observed by kuramoto and bottogtokh in a network of nonlocally coupled ginzburg-landau oscillators with exponential coupling functions .", "tokens": ["this", "interesting", "spatiotemporal", "behavior", "was", "first", "observed", "by", "kuramoto", "and", "bottogtokh", "in", "a", "network", "of", "nonlocally", "coupled", "ginzburg", "-", "landau", "oscillators", "with", "exponential", "coupling", "functions", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this interesting spatiotemporal behavior", "start": 0, "end": 40, "i_start": 0, "i_end": 3}, "verb": {"text": "observed", "start": 51, "end": 59, "i_start": 6, "i_end": 6}}, {"subject": {"text": "this interesting spatiotemporal behavior", "start": 0, "end": 40, "i_start": 0, "i_end": 3}, "verb": {"text": "was", "start": 41, "end": 44, "i_start": 4, "i_end": 4}}, {"character": {"text": "kuramoto", "start": 63, "end": 71, "i_start": 8, "i_end": 8}, "action": {"text": "observed", "start": 51, "end": 59, "i_start": 6, "i_end": 6}}, {"character": {"text": "bottogtokh", "start": 76, "end": 86, "i_start": 10, "i_end": 10}, "action": {"text": "observed", "start": 51, "end": 59, "i_start": 6, "i_end": 6}}], "id": 91}, {"sent": "in doing so , we extensively use average weight spectra derived for ensemble bin and for ensemble ain .", "tokens": ["in", "doing", "so", ",", "we", "extensively", "use", "average", "weight", "spectra", "derived", "for", "ensemble", "bin", "and", "for", "ensemble", "ain", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 29, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 29, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "doing", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 92}, {"sent": "inst-name ist menge aller instanzbezeichnungen .", "tokens": ["inst", "-", "name", "ist", "menge", "aller", "instanzbezeichnungen", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 93}, {"sent": "in this work , we adopt the loopy belief propagation algorithm which was shown to perform well for various problems .", "tokens": ["in", "this", "work", ",", "we", "adopt", "the", "loopy", "belief", "propagation", "algorithm", "which", "was", "shown", "to", "perform", "well", "for", "various", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "adopt", "start": 18, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "adopt", "start": 18, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "algorithm", "start": 53, "end": 62, "i_start": 10, "i_end": 10}, "action": {"text": "perform", "start": 82, "end": 89, "i_start": 15, "i_end": 15}}], "id": 94}, {"sent": "in fact , our definition admits cyclic directed graphs , and there may be no nodes with in-degree zero .", "tokens": ["in", "fact", ",", "our", "definition", "admits", "cyclic", "directed", "graphs", ",", "and", "there", "may", "be", "no", "nodes", "with", "in", "-", "degree", "zero", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our definition", "start": 10, "end": 24, "i_start": 3, "i_end": 4}, "verb": {"text": "admits", "start": 25, "end": 31, "i_start": 5, "i_end": 5}}], "id": 95}, {"sent": "the boundary lagrangian is manifestly gauge-invariant .", "tokens": ["the", "boundary", "lagrangian", "is", "manifestly", "gauge", "-", "invariant", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the boundary lagrangian", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}], "id": 96}, {"sent": "e-nose is a multi-sensor system comprised of a sensor array with partial specificity coupled with pattern recognition algorithm , which can also be recognized as cost-sensitive problem .", "tokens": ["e", "-", "nose", "is", "a", "multi", "-", "sensor", "system", "comprised", "of", "a", "sensor", "array", "with", "partial", "specificity", "coupled", "with", "pattern", "recognition", "algorithm", ",", "which", "can", "also", "be", "recognized", "as", "cost", "-", "sensitive", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "e-nose", "start": 0, "end": 6, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 7, "end": 9, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithm", "start": 118, "end": 127, "i_start": 21, "i_end": 21}, "action": {"text": "recognized", "start": 148, "end": 158, "i_start": 27, "i_end": 27}}, {"character": {"text": "problem", "start": 177, "end": 184, "i_start": 32, "i_end": 32}, "action": {"text": "sensitive", "start": 167, "end": 176, "i_start": 31, "i_end": 31}}], "id": 97}, {"sent": "a closely related research area is available bandwidth estimation , eg , that injects artificial test traffic into the network .", "tokens": ["a", "closely", "related", "research", "area", "is", "available", "bandwidth", "estimation", ",", "eg", ",", "that", "injects", "artificial", "test", "traffic", "into", "the", "network", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "a closely related research area", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 5, "i_end": 5}}, {"subject": {"text": "that", "start": 73, "end": 77, "i_start": 12, "i_end": 12}, "verb": {"text": "injects", "start": 78, "end": 85, "i_start": 13, "i_end": 13}}, {"character": {"text": "estimation", "start": 55, "end": 65, "i_start": 8, "i_end": 8}, "action": {"text": "injects", "start": 78, "end": 85, "i_start": 13, "i_end": 13}}], "id": 98}, {"sent": "the large n path integral over these fields can then always be performed exactly , using standard techniques for large n vector models .", "tokens": ["the", "large", "n", "path", "integral", "over", "these", "fields", "can", "then", "always", "be", "performed", "exactly", ",", "using", "standard", "techniques", "for", "large", "n", "vector", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the large n path integral over these fields", "start": 0, "end": 43, "i_start": 0, "i_end": 7}, "verb": {"text": "be performed", "start": 60, "end": 72, "i_start": 11, "i_end": 12}}, {"subject": {"text": "the large n path integral over these fields", "start": 0, "end": 43, "i_start": 0, "i_end": 7}, "verb": {"text": "can", "start": 44, "end": 47, "i_start": 8, "i_end": 8}}], "id": 99}]