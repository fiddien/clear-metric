[{"sent": "zhang and parker implemented a bio-inspired predictive orientation decomposition using mid-level features to construct representations of people from 3d skeleton trajectories , which is inspired by biological research in human anatomy .", "tokens": ["zhang", "and", "parker", "implemented", "a", "bio", "-", "inspired", "predictive", "orientation", "decomposition", "using", "mid", "-", "level", "features", "to", "construct", "representations", "of", "people", "from", "3d", "skeleton", "trajectories", ",", "which", "is", "inspired", "by", "biological", "research", "in", "human", "anatomy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhang and parker", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "implemented", "start": 17, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "implemented", "start": 17, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "parker", "start": 10, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "implemented", "start": 17, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "bio", "start": 31, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "inspired", "start": 35, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "decomposition", "start": 67, "end": 80, "i_start": 10, "i_end": 10}, "action": {"text": "using", "start": 81, "end": 86, "i_start": 11, "i_end": 11}}, {"character": {"text": "zhang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "construct", "start": 109, "end": 118, "i_start": 17, "i_end": 17}}, {"character": {"text": "parker", "start": 10, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "construct", "start": 109, "end": 118, "i_start": 17, "i_end": 17}}, {"character": {"text": "research", "start": 209, "end": 217, "i_start": 31, "i_end": 31}, "action": {"text": "inspired", "start": 186, "end": 194, "i_start": 28, "i_end": 28}}], "id": 0}, {"sent": "transfer learning is a learning paradigm that uses data in relevant tasks to help the target machine learning tasks .", "tokens": ["transfer", "learning", "is", "a", "learning", "paradigm", "that", "uses", "data", "in", "relevant", "tasks", "to", "help", "the", "target", "machine", "learning", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "transfer learning", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "paradigm", "start": 32, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "uses", "start": 46, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "learning", "start": 9, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "help", "start": 77, "end": 81, "i_start": 13, "i_end": 13}}], "id": 1}, {"sent": "it has been conjectured that the exponential behavior of this quantity should be an indicator of quantum chaos , the exponential rate being associated with the classical lyapunov exponent .", "tokens": ["it", "has", "been", "conjectured", "that", "the", "exponential", "behavior", "of", "this", "quantity", "should", "be", "an", "indicator", "of", "quantum", "chaos", ",", "the", "exponential", "rate", "being", "associated", "with", "the", "classical", "lyapunov", "exponent", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has been conjectured", "start": 3, "end": 23, "i_start": 1, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "be", "start": 78, "end": 80, "i_start": 12, "i_end": 12}}, {"character": {"text": "behavior", "start": 45, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "indicator", "start": 84, "end": 93, "i_start": 14, "i_end": 14}}, {"character": {"text": "quantity", "start": 62, "end": 70, "i_start": 10, "i_end": 10}, "action": {"text": "behavior", "start": 45, "end": 53, "i_start": 7, "i_end": 7}}], "id": 2}, {"sent": "while most of research is related to marketing , the problem has been generalized to target set selection in the domain of combinatorial optimization of theoretical computer science .", "tokens": ["while", "most", "of", "research", "is", "related", "to", "marketing", ",", "the", "problem", "has", "been", "generalized", "to", "target", "set", "selection", "in", "the", "domain", "of", "combinatorial", "optimization", "of", "theoretical", "computer", "science", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the problem", "start": 49, "end": 60, "i_start": 9, "i_end": 10}, "verb": {"text": "has been generalized", "start": 61, "end": 81, "i_start": 11, "i_end": 13}}], "id": 3}, {"sent": "finally , if we give up positivity only , we can get quantum correlations for the system-environment state .", "tokens": ["finally", ",", "if", "we", "give", "up", "positivity", "only", ",", "we", "can", "get", "quantum", "correlations", "for", "the", "system", "-", "environment", "state", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 42, "end": 44, "i_start": 9, "i_end": 9}, "verb": {"text": "can get", "start": 45, "end": 52, "i_start": 10, "i_end": 11}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "get", "start": 49, "end": 52, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "give", "start": 16, "end": 20, "i_start": 4, "i_end": 4}}], "id": 4}, {"sent": "in the plane of the wires and perpendicular to their length .", "tokens": ["in", "the", "plane", "of", "the", "wires", "and", "perpendicular", "to", "their", "length", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 5}, {"sent": "are global representations , whereas tf erm .", "tokens": ["are", "global", "representations", ",", "whereas", "tf", "erm", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 6}, {"sent": "as mentioned previously , in the formulation here , the zero frequency lifshitz and ionic components are treated together in the grand partition function \u03be .", "tokens": ["as", "mentioned", "previously", ",", "in", "the", "formulation", "here", ",", "the", "zero", "frequency", "lifshitz", "and", "ionic", "components", "are", "treated", "together", "in", "the", "grand", "partition", "function", "\u03be", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the zero frequency lifshitz and ionic components", "start": 52, "end": 100, "i_start": 9, "i_end": 15}, "verb": {"text": "are treated", "start": 101, "end": 112, "i_start": 16, "i_end": 17}}], "id": 7}, {"sent": "the abscissa and ordinate denote the time in jd and the magnitude , respectively .", "tokens": ["the", "abscissa", "and", "ordinate", "denote", "the", "time", "in", "jd", "and", "the", "magnitude", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"character": {"text": "abscissa", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "ordinate", "start": 17, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "denote", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}], "id": 8}, {"sent": "additional properties , in particular with respect to the diameter , and a solution for balanced complete bipartite graphs were reported in .", "tokens": ["additional", "properties", ",", "in", "particular", "with", "respect", "to", "the", "diameter", ",", "and", "a", "solution", "for", "balanced", "complete", "bipartite", "graphs", "were", "reported", "in", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "additional properties , in particular with respect to the diameter , and a solution for balanced complete bipartite graphs", "start": 0, "end": 122, "i_start": 0, "i_end": 18}, "verb": {"text": "were reported", "start": 123, "end": 136, "i_start": 19, "i_end": 20}}], "id": 9}, {"sent": "mahjourian et al employ geometric constraints of the scene by enforcing an approximate icp based matching loss .", "tokens": ["mahjourian", "et", "al", "employ", "geometric", "constraints", "of", "the", "scene", "by", "enforcing", "an", "approximate", "icp", "based", "matching", "loss", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "mahjourian et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "employ", "start": 17, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "mahjourian", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 17, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "mahjourian", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "constraints", "start": 34, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "mahjourian", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "enforcing", "start": 62, "end": 71, "i_start": 10, "i_end": 10}}], "id": 10}, {"sent": "the key difference between our model and most previous models is the possibility of obtaining resource through the cheaper but less reliable approach of spectrum sensing .", "tokens": ["the", "key", "difference", "between", "our", "model", "and", "most", "previous", "models", "is", "the", "possibility", "of", "obtaining", "resource", "through", "the", "cheaper", "but", "less", "reliable", "approach", "of", "spectrum", "sensing", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the key difference between our model and most previous models", "start": 0, "end": 61, "i_start": 0, "i_end": 9}, "verb": {"text": "is", "start": 62, "end": 64, "i_start": 10, "i_end": 10}}], "id": 11}, {"sent": "historically the first one is a harmonic analysis in right ascension , see for a recent application .", "tokens": ["historically", "the", "first", "one", "is", "a", "harmonic", "analysis", "in", "right", "ascension", ",", "see", "for", "a", "recent", "application", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the first one", "start": 13, "end": 26, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 4, "i_end": 4}}], "id": 12}, {"sent": "to find the local neighborhoods , we follow the idea of revaud et al using both of their approximations .", "tokens": ["to", "find", "the", "local", "neighborhoods", ",", "we", "follow", "the", "idea", "of", "revaud", "et", "al", "using", "both", "of", "their", "approximations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "verb": {"text": "follow", "start": 37, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "follow", "start": 37, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "using", "start": 69, "end": 74, "i_start": 14, "i_end": 14}}, {"character": {"text": "revaud", "start": 56, "end": 62, "i_start": 11, "i_end": 11}, "action": {"text": "approximations", "start": 89, "end": 103, "i_start": 18, "i_end": 18}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 13}, {"sent": "in terms of the observed dark matter abundance , we calculate the coupling of the annihilation process for the whole resonance parameter space .", "tokens": ["in", "terms", "of", "the", "observed", "dark", "matter", "abundance", ",", "we", "calculate", "the", "coupling", "of", "the", "annihilation", "process", "for", "the", "whole", "resonance", "parameter", "space", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "verb": {"text": "calculate", "start": 52, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "action": {"text": "calculate", "start": 52, "end": 61, "i_start": 10, "i_end": 10}}], "id": 14}, {"sent": "we use the local density approximation of perdew and zunger , and a double zeta plus double polarization basis set of the siesta type .", "tokens": ["we", "use", "the", "local", "density", "approximation", "of", "perdew", "and", "zunger", ",", "and", "a", "double", "zeta", "plus", "double", "polarization", "basis", "set", "of", "the", "siesta", "type", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 15}, {"sent": "for surveys of the known mathematical theories of the equations we refer to .", "tokens": ["for", "surveys", "of", "the", "known", "mathematical", "theories", "of", "the", "equations", "we", "refer", "to", "."], "score": [0, 0, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 64, "end": 66, "i_start": 10, "i_end": 10}, "action": {"text": "refer", "start": 67, "end": 72, "i_start": 11, "i_end": 11}}], "id": 16}, {"sent": "orthogonal frequency-division multiplexing is an attractive and well-established way of dealing with frequencyselective channels .", "tokens": ["orthogonal", "frequency", "-", "division", "multiplexing", "is", "an", "attractive", "and", "well", "-", "established", "way", "of", "dealing", "with", "frequencyselective", "channels", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "orthogonal frequency-division multiplexing", "start": 0, "end": 42, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 43, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "way", "start": 81, "end": 84, "i_start": 12, "i_end": 12}, "action": {"text": "attractive", "start": 49, "end": 59, "i_start": 7, "i_end": 7}}], "id": 17}, {"sent": "since we consider the case of the susy breaking , we describe the susy algebra in the local form .", "tokens": ["since", "we", "consider", "the", "case", "of", "the", "susy", "breaking", ",", "we", "describe", "the", "susy", "algebra", "in", "the", "local", "form", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 50, "end": 52, "i_start": 10, "i_end": 10}, "verb": {"text": "describe", "start": 53, "end": 61, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "describe", "start": 53, "end": 61, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "consider", "start": 9, "end": 17, "i_start": 2, "i_end": 2}}], "id": 18}, {"sent": "we trained a neural network policy for solving the humanoid locomotion task using proximal policy optimization and different planning horizons .", "tokens": ["we", "trained", "a", "neural", "network", "policy", "for", "solving", "the", "humanoid", "locomotion", "task", "using", "proximal", "policy", "optimization", "and", "different", "planning", "horizons", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "trained", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "trained", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "policy", "start": 28, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "solving", "start": 39, "end": 46, "i_start": 7, "i_end": 7}}], "id": 19}, {"sent": "linnik , on the least prime in an arithmetic progression i , the basis theorem rec .", "tokens": ["linnik", ",", "on", "the", "least", "prime", "in", "an", "arithmetic", "progression", "i", ",", "the", "basis", "theorem", "rec", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 20}, {"sent": "weights need to be between 0 and 1 for normalization purposes , where larger weights are assigned to generalized items comprised of items that are more semantically distant , since such generalized items harm data utility more .", "tokens": ["weights", "need", "to", "be", "between", "0", "and", "1", "for", "normalization", "purposes", ",", "where", "larger", "weights", "are", "assigned", "to", "generalized", "items", "comprised", "of", "items", "that", "are", "more", "semantically", "distant", ",", "since", "such", "generalized", "items", "harm", "data", "utility", "more", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "weights", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "need", "start": 8, "end": 12, "i_start": 1, "i_end": 1}}], "id": 21}, {"sent": "we have applied the sms algorithm to 24 functions whose results have been compared to those produced by the gravitational search algorithm , the particle swarm optimization method and the differential evolution algorithm .", "tokens": ["we", "have", "applied", "the", "sms", "algorithm", "to", "24", "functions", "whose", "results", "have", "been", "compared", "to", "those", "produced", "by", "the", "gravitational", "search", "algorithm", ",", "the", "particle", "swarm", "optimization", "method", "and", "the", "differential", "evolution", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have applied", "start": 3, "end": 15, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "applied", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "algorithm", "start": 129, "end": 138, "i_start": 21, "i_end": 21}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "search", "start": 122, "end": 128, "i_start": 20, "i_end": 20}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "gravitational", "start": 108, "end": 121, "i_start": 19, "i_end": 19}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "method", "start": 173, "end": 179, "i_start": 27, "i_end": 27}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "optimization", "start": 160, "end": 172, "i_start": 26, "i_end": 26}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "swarm", "start": 154, "end": 159, "i_start": 25, "i_end": 25}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "particle", "start": 145, "end": 153, "i_start": 24, "i_end": 24}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "algorithm", "start": 211, "end": 220, "i_start": 32, "i_end": 32}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "evolution", "start": 201, "end": 210, "i_start": 31, "i_end": 31}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "differential", "start": 188, "end": 200, "i_start": 30, "i_end": 30}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}], "id": 22}, {"sent": "it makes rydberg atoms promising for applications such as quantum information .", "tokens": ["it", "makes", "rydberg", "atoms", "promising", "for", "applications", "such", "as", "quantum", "information", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "makes", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "rydberg atoms", "start": 9, "end": 22, "i_start": 2, "i_end": 3}, "verb": {"text": "promising", "start": 23, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "makes", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "atoms", "start": 17, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "promising", "start": 23, "end": 32, "i_start": 4, "i_end": 4}}], "id": 23}, {"sent": "this allows for targeting of users based on their behavior , which is typically referred to as ad targeting .", "tokens": ["this", "allows", "for", "targeting", "of", "users", "based", "on", "their", "behavior", ",", "which", "is", "typically", "referred", "to", "as", "ad", "targeting", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "allows", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "allows", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}], "id": 24}, {"sent": "an early study extended virtualization solutions to support rich and effective policies for active power management , which had not been done before .", "tokens": ["an", "early", "study", "extended", "virtualization", "solutions", "to", "support", "rich", "and", "effective", "policies", "for", "active", "power", "management", ",", "which", "had", "not", "been", "done", "before", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "an early study", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "extended", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "study", "start": 9, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "extended", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "solutions", "start": 39, "end": 48, "i_start": 5, "i_end": 5}, "action": {"text": "support", "start": 52, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "policies", "start": 79, "end": 87, "i_start": 11, "i_end": 11}, "action": {"text": "effective", "start": 69, "end": 78, "i_start": 10, "i_end": 10}}], "id": 25}, {"sent": "spin needlets spectral estimation , electronic journal of statistics , vol .", "tokens": ["spin", "needlets", "spectral", "estimation", ",", "electronic", "journal", "of", "statistics", ",", "vol", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 26}, {"sent": "in summary , we have presented three families of new exactly solvable models based on the pairing interaction for fermion and boson systems .", "tokens": ["in", "summary", ",", "we", "have", "presented", "three", "families", "of", "new", "exactly", "solvable", "models", "based", "on", "the", "pairing", "interaction", "for", "fermion", "and", "boson", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "have presented", "start": 16, "end": 30, "i_start": 4, "i_end": 5}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "presented", "start": 21, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "systems", "start": 132, "end": 139, "i_start": 22, "i_end": 22}, "action": {"text": "interaction", "start": 98, "end": 109, "i_start": 17, "i_end": 17}}], "id": 27}, {"sent": "we will be interested in the two simplest correlation functions and their fourier transforms .", "tokens": ["we", "will", "be", "interested", "in", "the", "two", "simplest", "correlation", "functions", "and", "their", "fourier", "transforms", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will be", "start": 3, "end": 10, "i_start": 1, "i_end": 2}}], "id": 28}, {"sent": "the gap of the insulating phase strongly decreases with x .", "tokens": ["the", "gap", "of", "the", "insulating", "phase", "strongly", "decreases", "with", "x", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the gap of the insulating phase", "start": 0, "end": 31, "i_start": 0, "i_end": 5}, "verb": {"text": "decreases", "start": 41, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "phase", "start": 26, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "insulating", "start": 15, "end": 25, "i_start": 4, "i_end": 4}}], "id": 29}, {"sent": "the diffusion coefficient in eq 9 is a tensor with symmetry about the local axis of the magnetization whereas in zlf the diffusion coefficient is a scalar .", "tokens": ["the", "diffusion", "coefficient", "in", "eq", "9", "is", "a", "tensor", "with", "symmetry", "about", "the", "local", "axis", "of", "the", "magnetization", "whereas", "in", "zlf", "the", "diffusion", "coefficient", "is", "a", "scalar", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the diffusion coefficient in eq 9", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "tensor", "start": 39, "end": 45, "i_start": 8, "i_end": 8}, "action": {"text": "symmetry", "start": 51, "end": 59, "i_start": 10, "i_end": 10}}], "id": 30}, {"sent": "a closed form expression for the probability of los between drones and ues is developed in .", "tokens": ["a", "closed", "form", "expression", "for", "the", "probability", "of", "los", "between", "drones", "and", "ues", "is", "developed", "in", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "a closed form expression for the probability of los between drones and ues", "start": 0, "end": 74, "i_start": 0, "i_end": 12}, "verb": {"text": "is developed", "start": 75, "end": 87, "i_start": 13, "i_end": 14}}], "id": 31}, {"sent": "the most related in this line is where each user lies in an cluster that can be described by a low-dimensional vector , with 2 separation across clusters .", "tokens": ["the", "most", "related", "in", "this", "line", "is", "where", "each", "user", "lies", "in", "an", "cluster", "that", "can", "be", "described", "by", "a", "low", "-", "dimensional", "vector", ",", "with", "2", "separation", "across", "clusters", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most related in this line", "start": 0, "end": 29, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 6, "i_end": 6}}, {"subject": {"text": "each user", "start": 39, "end": 48, "i_start": 8, "i_end": 9}, "verb": {"text": "lies", "start": 49, "end": 53, "i_start": 10, "i_end": 10}}, {"character": {"text": "vector", "start": 111, "end": 117, "i_start": 23, "i_end": 23}, "action": {"text": "described", "start": 80, "end": 89, "i_start": 17, "i_end": 17}}], "id": 32}, {"sent": "we then proceed to show that our lower bound method subsumes all the other bounds mentioned above .", "tokens": ["we", "then", "proceed", "to", "show", "that", "our", "lower", "bound", "method", "subsumes", "all", "the", "other", "bounds", "mentioned", "above", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "proceed", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proceed", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 19, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "bound", "start": 39, "end": 44, "i_start": 8, "i_end": 8}}], "id": 33}, {"sent": "current schemes for classifying protein structure often rely on manually curated hierarchies that are not able to cleanly capture all possible variations .", "tokens": ["current", "schemes", "for", "classifying", "protein", "structure", "often", "rely", "on", "manually", "curated", "hierarchies", "that", "are", "not", "able", "to", "cleanly", "capture", "all", "possible", "variations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "current schemes for classifying protein structure", "start": 0, "end": 49, "i_start": 0, "i_end": 5}, "verb": {"text": "rely", "start": 56, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "schemes", "start": 8, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "rely", "start": 56, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "hierarchies", "start": 81, "end": 92, "i_start": 11, "i_end": 11}, "action": {"text": "capture", "start": 122, "end": 129, "i_start": 18, "i_end": 18}}], "id": 34}, {"sent": "we use the training and validation portions of the bsds500 dataset as training images .", "tokens": ["we", "use", "the", "training", "and", "validation", "portions", "of", "the", "bsds500", "dataset", "as", "training", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 35}, {"sent": "the qkz equations for arbitrary root system were obtained by cherednik .", "tokens": ["the", "qkz", "equations", "for", "arbitrary", "root", "system", "were", "obtained", "by", "cherednik", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the qkz equations for arbitrary root system", "start": 0, "end": 43, "i_start": 0, "i_end": 6}, "verb": {"text": "were obtained", "start": 44, "end": 57, "i_start": 7, "i_end": 8}}, {"character": {"text": "cherednik", "start": 61, "end": 70, "i_start": 10, "i_end": 10}, "action": {"text": "obtained", "start": 49, "end": 57, "i_start": 8, "i_end": 8}}], "id": 36}, {"sent": "millimeter waves , for cellular communications , is one of the main technological innovations brought by fifth generation wireless networks .", "tokens": ["millimeter", "waves", ",", "for", "cellular", "communications", ",", "is", "one", "of", "the", "main", "technological", "innovations", "brought", "by", "fifth", "generation", "wireless", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "millimeter waves", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 49, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 131, "end": 139, "i_start": 19, "i_end": 19}, "action": {"text": "brought", "start": 94, "end": 101, "i_start": 14, "i_end": 14}}], "id": 37}, {"sent": "a reaction with chemi- and physi- sorbed glycerol can account for the prompt and the slow hole decay , respectively .", "tokens": ["a", "reaction", "with", "chemi-", "and", "physi-", "sorbed", "glycerol", "can", "account", "for", "the", "prompt", "and", "the", "slow", "hole", "decay", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a reaction with chemi- and physi- sorbed glycerol", "start": 0, "end": 49, "i_start": 0, "i_end": 7}, "verb": {"text": "can account", "start": 50, "end": 61, "i_start": 8, "i_end": 9}}, {"character": {"text": "reaction", "start": 2, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "account", "start": 54, "end": 61, "i_start": 9, "i_end": 9}}], "id": 38}, {"sent": "during the outflow of liquid stream to an atmosphere .", "tokens": ["during", "the", "outflow", "of", "liquid", "stream", "to", "an", "atmosphere", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 39}, {"sent": "now we define smarandache mixed direct product of rings .", "tokens": ["now", "we", "define", "smarandache", "mixed", "direct", "product", "of", "rings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "define", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}], "id": 40}, {"sent": "to analyze the data and obtain the phase diagram , we use the bruce-wilding finite-size scaling techniques , to compile the phase diagram of this system .", "tokens": ["to", "analyze", "the", "data", "and", "obtain", "the", "phase", "diagram", ",", "we", "use", "the", "bruce", "-", "wilding", "finite", "-", "size", "scaling", "techniques", ",", "to", "compile", "the", "phase", "diagram", "of", "this", "system", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "verb": {"text": "use", "start": 54, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "use", "start": 54, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "compile", "start": 112, "end": 119, "i_start": 23, "i_end": 23}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "analyze", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "obtain", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}], "id": 41}, {"sent": "the momentum equation is discretised using the sip method for the elliptic term and otherwise using the fluxes from cockburn et al .", "tokens": ["the", "momentum", "equation", "is", "discretised", "using", "the", "sip", "method", "for", "the", "elliptic", "term", "and", "otherwise", "using", "the", "fluxes", "from", "cockburn", "et", "al", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "the momentum equation", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is discretised", "start": 22, "end": 36, "i_start": 3, "i_end": 4}}, {"subject": {"text": "the momentum equation", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "using", "start": 94, "end": 99, "i_start": 15, "i_end": 15}}], "id": 42}, {"sent": "note that the similar idea of spectrum cooperation can be found in the context of cognitive radio networks .", "tokens": ["note", "that", "the", "similar", "idea", "of", "spectrum", "cooperation", "can", "be", "found", "in", "the", "context", "of", "cognitive", "radio", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the similar idea of spectrum cooperation", "start": 10, "end": 50, "i_start": 2, "i_end": 7}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "the similar idea of spectrum cooperation", "start": 10, "end": 50, "i_start": 2, "i_end": 7}, "verb": {"text": "found", "start": 58, "end": 63, "i_start": 10, "i_end": 10}}], "id": 43}, {"sent": "good quantitative and qualitative agreement between the experimentally derived and the simulated eley-rideal abstraction cross sections are found if two different eley-rideal abstraction mechanisms are included .", "tokens": ["good", "quantitative", "and", "qualitative", "agreement", "between", "the", "experimentally", "derived", "and", "the", "simulated", "eley", "-", "rideal", "abstraction", "cross", "sections", "are", "found", "if", "two", "different", "eley", "-", "rideal", "abstraction", "mechanisms", "are", "included", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "good quantitative and qualitative agreement between the experimentally derived and the simulated eley-rideal abstraction cross sections", "start": 0, "end": 135, "i_start": 0, "i_end": 17}, "verb": {"text": "are found", "start": 136, "end": 145, "i_start": 18, "i_end": 19}}], "id": 44}, {"sent": "this remarkable relation is called the rank-size duality .", "tokens": ["this", "remarkable", "relation", "is", "called", "the", "rank", "-", "size", "duality", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this remarkable relation", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 25, "end": 34, "i_start": 3, "i_end": 4}}], "id": 45}, {"sent": "again , the detector current increases when the electron leaves the quantum dot .", "tokens": ["again", ",", "the", "detector", "current", "increases", "when", "the", "electron", "leaves", "the", "quantum", "dot", "."], "score": [0, 0, 0, 0, 0], "labels": [{"character": {"text": "electron", "start": 48, "end": 56, "i_start": 8, "i_end": 8}, "action": {"text": "leaves", "start": 57, "end": 63, "i_start": 9, "i_end": 9}}], "id": 46}, {"sent": "several studies for dnn-based image completion have presented demos of manipulating face appearances by filling the parts of an input image with the dnn .", "tokens": ["several", "studies", "for", "dnn", "-", "based", "image", "completion", "have", "presented", "demos", "of", "manipulating", "face", "appearances", "by", "filling", "the", "parts", "of", "an", "input", "image", "with", "the", "dnn", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "several studies for dnn-based image completion", "start": 0, "end": 46, "i_start": 0, "i_end": 7}, "verb": {"text": "have presented", "start": 47, "end": 61, "i_start": 8, "i_end": 9}}, {"character": {"text": "studies", "start": 8, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "presented", "start": 52, "end": 61, "i_start": 9, "i_end": 9}}], "id": 47}, {"sent": "this fact is quite surprising , since it is definitely not the case for qeccs .", "tokens": ["this", "fact", "is", "quite", "surprising", ",", "since", "it", "is", "definitely", "not", "the", "case", "for", "qeccs", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this fact", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "fact", "start": 5, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "surprising", "start": 19, "end": 29, "i_start": 4, "i_end": 4}}], "id": 48}, {"sent": "this implies that r and the multiplication map are local homeomorphisms and that g is open in g .", "tokens": ["this", "implies", "that", "r", "and", "the", "multiplication", "map", "are", "local", "homeomorphisms", "and", "that", "g", "is", "open", "in", "g", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "implies", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 47, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "implies", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}], "id": 49}, {"sent": "our results can be generalized to probabilistic transformations .", "tokens": ["our", "results", "can", "be", "generalized", "to", "probabilistic", "transformations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our results", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "can be generalized", "start": 12, "end": 30, "i_start": 2, "i_end": 4}}], "id": 50}, {"sent": "in this section , we will describe the aspects of the theory that we need most for the definition of non-commutative toric varieties .", "tokens": ["in", "this", "section", ",", "we", "will", "describe", "the", "aspects", "of", "the", "theory", "that", "we", "need", "most", "for", "the", "definition", "of", "non", "-", "commutative", "toric", "varieties", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "will describe", "start": 21, "end": 34, "i_start": 5, "i_end": 6}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "describe", "start": 26, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "need", "start": 69, "end": 73, "i_start": 14, "i_end": 14}}], "id": 51}, {"sent": "a client that browses to a website through an onion routing network will have their traffic relayed before it reaches its destination .", "tokens": ["a", "client", "that", "browses", "to", "a", "website", "through", "an", "onion", "routing", "network", "will", "have", "their", "traffic", "relayed", "before", "it", "reaches", "its", "destination", "."], "score": [0, 1, 1, 1, 0], "labels": [{"subject": {"text": "a client that browses to a website through an onion routing network", "start": 0, "end": 67, "i_start": 0, "i_end": 11}, "verb": {"text": "will have", "start": 68, "end": 77, "i_start": 12, "i_end": 13}}, {"subject": {"text": "their traffic", "start": 78, "end": 91, "i_start": 14, "i_end": 15}, "verb": {"text": "relayed", "start": 92, "end": 99, "i_start": 16, "i_end": 16}}, {"character": {"text": "client", "start": 2, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "browses", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "network", "start": 60, "end": 67, "i_start": 11, "i_end": 11}, "action": {"text": "routing", "start": 52, "end": 59, "i_start": 10, "i_end": 10}}, {"character": {"text": "traffic", "start": 84, "end": 91, "i_start": 15, "i_end": 15}, "action": {"text": "reaches", "start": 110, "end": 117, "i_start": 19, "i_end": 19}}], "id": 52}, {"sent": "to obtain the twisted kz systems of the corresponding open-string wzw orbifolds .", "tokens": ["to", "obtain", "the", "twisted", "kz", "systems", "of", "the", "corresponding", "open", "-", "string", "wzw", "orbifolds", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 53}, {"sent": "the change of sign of the effect with respect to the substitution of neutrinos by antineutrinos is clearly visible .", "tokens": ["the", "change", "of", "sign", "of", "the", "effect", "with", "respect", "to", "the", "substitution", "of", "neutrinos", "by", "antineutrinos", "is", "clearly", "visible", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the change of sign of the effect with respect to the substitution of neutrinos by antineutrinos", "start": 0, "end": 95, "i_start": 0, "i_end": 15}, "verb": {"text": "is", "start": 96, "end": 98, "i_start": 16, "i_end": 16}}], "id": 54}, {"sent": "it is obvious that the time complexity of this problem is exponential in the size of n , but this does not deny the existence of a fast algorithm .", "tokens": ["it", "is", "obvious", "that", "the", "time", "complexity", "of", "this", "problem", "is", "exponential", "in", "the", "size", "of", "n", ",", "but", "this", "does", "not", "deny", "the", "existence", "of", "a", "fast", "algorithm", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "this", "start": 93, "end": 97, "i_start": 19, "i_end": 19}, "verb": {"text": "is", "start": 55, "end": 57, "i_start": 10, "i_end": 10}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "deny", "start": 107, "end": 111, "i_start": 22, "i_end": 22}}], "id": 55}, {"sent": "we verify the acceleration and orientation choices as modeled in model 1 above are safe , using a formal proof calculus for dl .", "tokens": ["we", "verify", "the", "acceleration", "and", "orientation", "choices", "as", "modeled", "in", "model", "1", "above", "are", "safe", ",", "using", "a", "formal", "proof", "calculus", "for", "dl", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "verify", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "verify", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "model 1", "start": 65, "end": 72, "i_start": 10, "i_end": 11}, "action": {"text": "modeled", "start": 54, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 90, "end": 95, "i_start": 16, "i_end": 16}}], "id": 56}, {"sent": "for the segmentation task , a 3d extension of the u-net architecture was employed .", "tokens": ["for", "the", "segmentation", "task", ",", "a", "3d", "extension", "of", "the", "u", "-", "net", "architecture", "was", "employed", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a 3d extension of the u-net architecture", "start": 28, "end": 68, "i_start": 5, "i_end": 13}, "verb": {"text": "was employed", "start": 69, "end": 81, "i_start": 14, "i_end": 15}}], "id": 57}, {"sent": "the non-flatness of the base metric for 3-charge microstate geometries was previously observed in the particular solution of , but had remained until now largely unexplained .", "tokens": ["the", "non", "-", "flatness", "of", "the", "base", "metric", "for", "3", "-", "charge", "microstate", "geometries", "was", "previously", "observed", "in", "the", "particular", "solution", "of", ",", "but", "had", "remained", "until", "now", "largely", "unexplained", "."], "score": [0, 0, 1, 0, 1], "labels": [{"subject": {"text": "the non-flatness of the base metric for 3-charge microstate geometries", "start": 0, "end": 70, "i_start": 0, "i_end": 13}, "verb": {"text": "observed", "start": 86, "end": 94, "i_start": 16, "i_end": 16}}, {"subject": {"text": "the non-flatness of the base metric for 3-charge microstate geometries", "start": 0, "end": 70, "i_start": 0, "i_end": 13}, "verb": {"text": "was", "start": 71, "end": 74, "i_start": 14, "i_end": 14}}, {"subject": {"text": "the non-flatness of the base metric for 3-charge microstate geometries", "start": 0, "end": 70, "i_start": 0, "i_end": 13}, "verb": {"text": "remained", "start": 135, "end": 143, "i_start": 25, "i_end": 25}}], "id": 58}, {"sent": "in , in this paper , we propose a multiple-input-multipleoutput sr backscatter system , where the transmitter , the receiver and the bd are equipped with multiple antennas .", "tokens": ["in", ",", "in", "this", "paper", ",", "we", "propose", "a", "multiple", "-", "input", "-", "multipleoutput", "sr", "backscatter", "system", ",", "where", "the", "transmitter", ",", "the", "receiver", "and", "the", "bd", "are", "equipped", "with", "multiple", "antennas", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 6, "i_end": 6}, "verb": {"text": "propose", "start": 24, "end": 31, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 6, "i_end": 6}, "action": {"text": "propose", "start": 24, "end": 31, "i_start": 7, "i_end": 7}}], "id": 59}, {"sent": "for the numerical experiments in this paper we implemented a new variant of the cross-3d method which has better asymptotic complexity in r than the method described in .", "tokens": ["for", "the", "numerical", "experiments", "in", "this", "paper", "we", "implemented", "a", "new", "variant", "of", "the", "cross-3d", "method", "which", "has", "better", "asymptotic", "complexity", "in", "r", "than", "the", "method", "described", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 44, "end": 46, "i_start": 7, "i_end": 7}, "verb": {"text": "implemented", "start": 47, "end": 58, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 44, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "implemented", "start": 47, "end": 58, "i_start": 8, "i_end": 8}}, {"character": {"text": "method", "start": 89, "end": 95, "i_start": 15, "i_end": 15}, "action": {"text": "has", "start": 102, "end": 105, "i_start": 17, "i_end": 17}}], "id": 60}, {"sent": "flow chart showing the procedure for obtaining the second spectrum .", "tokens": ["flow", "chart", "showing", "the", "procedure", "for", "obtaining", "the", "second", "spectrum", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "flow chart", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "showing", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "chart", "start": 5, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "showing", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}], "id": 61}, {"sent": "the resource optimization in orthogonal frequency division multiplexing based single-user single-relay systems was considered in .", "tokens": ["the", "resource", "optimization", "in", "orthogonal", "frequency", "division", "multiplexing", "based", "single", "-", "user", "single", "-", "relay", "systems", "was", "considered", "in", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the resource optimization in orthogonal frequency division multiplexing based single-user single-relay systems", "start": 0, "end": 110, "i_start": 0, "i_end": 15}, "verb": {"text": "was considered", "start": 111, "end": 125, "i_start": 16, "i_end": 17}}], "id": 62}, {"sent": "the robustness of this method has been verified for calculating primordial spectra in k-inflation , .", "tokens": ["the", "robustness", "of", "this", "method", "has", "been", "verified", "for", "calculating", "primordial", "spectra", "in", "k", "-", "inflation", ",", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the robustness of this method", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "has been verified", "start": 30, "end": 47, "i_start": 5, "i_end": 7}}], "id": 63}, {"sent": "we also calculate the critical temperatures and the angular dependence of order parameters .", "tokens": ["we", "also", "calculate", "the", "critical", "temperatures", "and", "the", "angular", "dependence", "of", "order", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "calculate", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "calculate", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "parameters", "start": 80, "end": 90, "i_start": 12, "i_end": 12}, "action": {"text": "dependence", "start": 60, "end": 70, "i_start": 9, "i_end": 9}}], "id": 64}, {"sent": "the addition of electrolyte to an aqueous solution of surfactant micelles is known empirically to preferentially stabilize the cylindrical shape .", "tokens": ["the", "addition", "of", "electrolyte", "to", "an", "aqueous", "solution", "of", "surfactant", "micelles", "is", "known", "empirically", "to", "preferentially", "stabilize", "the", "cylindrical", "shape", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the addition of electrolyte to an aqueous solution of surfactant micelles", "start": 0, "end": 73, "i_start": 0, "i_end": 10}, "verb": {"text": "is known", "start": 74, "end": 82, "i_start": 11, "i_end": 12}}], "id": 65}, {"sent": "yau , existence of incompressible minimal surfaces and the topology of three-dimensional manifolds with non-negative scalar curvature , ann .", "tokens": ["yau", ",", "existence", "of", "incompressible", "minimal", "surfaces", "and", "the", "topology", "of", "three", "-", "dimensional", "manifolds", "with", "non", "-", "negative", "scalar", "curvature", ",", "ann", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 66}, {"sent": "with the obvious modifications , the same also holds for the tame fundamental group .", "tokens": ["with", "the", "obvious", "modifications", ",", "the", "same", "also", "holds", "for", "the", "tame", "fundamental", "group", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the same", "start": 33, "end": 41, "i_start": 5, "i_end": 6}, "verb": {"text": "holds", "start": 47, "end": 52, "i_start": 8, "i_end": 8}}], "id": 67}, {"sent": "regardless of the quality of the multiclass pixel classifier , the algorithms in do not distinguish between regions of one sub-structure to those of another in the superpixel level .", "tokens": ["regardless", "of", "the", "quality", "of", "the", "multiclass", "pixel", "classifier", ",", "the", "algorithms", "in", "do", "not", "distinguish", "between", "regions", "of", "one", "sub", "-", "structure", "to", "those", "of", "another", "in", "the", "superpixel", "level", "."], "score": [0, 0, 0, 0, 0], "labels": [{"character": {"text": "algorithms", "start": 67, "end": 77, "i_start": 11, "i_end": 11}, "action": {"text": "not distinguish", "start": 84, "end": 99, "i_start": 14, "i_end": 15}}], "id": 68}, {"sent": "we start by reformulating the definition of a cluster algebra a .", "tokens": ["we", "start", "by", "reformulating", "the", "definition", "of", "a", "cluster", "algebra", "a", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "start", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "start", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "reformulating", "start": 12, "end": 25, "i_start": 3, "i_end": 3}}], "id": 69}, {"sent": "as a warm-up , in this subsection we briefly review the construction of the effective fluid equations for dark matter , .", "tokens": ["as", "a", "warm", "-", "up", ",", "in", "this", "subsection", "we", "briefly", "review", "the", "construction", "of", "the", "effective", "fluid", "equations", "for", "dark", "matter", ",", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 34, "end": 36, "i_start": 9, "i_end": 9}, "verb": {"text": "review", "start": 45, "end": 51, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 9, "i_end": 9}, "action": {"text": "review", "start": 45, "end": 51, "i_start": 11, "i_end": 11}}, {"character": {"text": "equations", "start": 92, "end": 101, "i_start": 18, "i_end": 18}, "action": {"text": "effective", "start": 76, "end": 85, "i_start": 16, "i_end": 16}}], "id": 70}, {"sent": "for the outdoor links we consider the itu-r model for line-of-sight propagation within street canyons and the non-line-of-sight model for over roof-top propagation .", "tokens": ["for", "the", "outdoor", "links", "we", "consider", "the", "itu", "-", "r", "model", "for", "line", "-", "of", "-", "sight", "propagation", "within", "street", "canyons", "and", "the", "non", "-", "line", "-", "of", "-", "sight", "model", "for", "over", "roof", "-", "top", "propagation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 22, "end": 24, "i_start": 4, "i_end": 4}, "verb": {"text": "consider", "start": 25, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "consider", "start": 25, "end": 33, "i_start": 5, "i_end": 5}}], "id": 71}, {"sent": "spatially-coupled csa has been investigated in , where similar improvement of the iterative decoding threshold was observed .", "tokens": ["spatially", "-", "coupled", "csa", "has", "been", "investigated", "in", ",", "where", "similar", "improvement", "of", "the", "iterative", "decoding", "threshold", "was", "observed", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "spatially-coupled csa", "start": 0, "end": 21, "i_start": 0, "i_end": 3}, "verb": {"text": "has been investigated", "start": 22, "end": 43, "i_start": 4, "i_end": 6}}], "id": 72}, {"sent": "several first-order methods with attractive convergence properties have been introduced for bspps .", "tokens": ["several", "first", "-", "order", "methods", "with", "attractive", "convergence", "properties", "have", "been", "introduced", "for", "bspps", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "several first-order methods with attractive convergence properties", "start": 0, "end": 66, "i_start": 0, "i_end": 8}, "verb": {"text": "have been introduced", "start": 67, "end": 87, "i_start": 9, "i_end": 11}}, {"character": {"text": "methods", "start": 20, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "attractive", "start": 33, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "methods", "start": 20, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "have", "start": 67, "end": 71, "i_start": 9, "i_end": 9}}], "id": 73}, {"sent": "the vertical axis is time , the horizontal axis indicates physical length .", "tokens": ["the", "vertical", "axis", "is", "time", ",", "the", "horizontal", "axis", "indicates", "physical", "length", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the horizontal axis", "start": 28, "end": 47, "i_start": 6, "i_end": 8}, "verb": {"text": "indicates", "start": 48, "end": 57, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the horizontal axis", "start": 28, "end": 47, "i_start": 6, "i_end": 8}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "axis", "start": 43, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "indicates", "start": 48, "end": 57, "i_start": 9, "i_end": 9}}], "id": 74}, {"sent": "by constructing appropriate control variations and using a suitable open mapping theorem , one can show that a control system is small-time locally controllable .", "tokens": ["by", "constructing", "appropriate", "control", "variations", "and", "using", "a", "suitable", "open", "mapping", "theorem", ",", "one", "can", "show", "that", "a", "control", "system", "is", "small", "-", "time", "locally", "controllable", "."], "score": [0, 0, 0, 1, 1], "labels": [{"subject": {"text": "one", "start": 91, "end": 94, "i_start": 13, "i_end": 13}, "verb": {"text": "can show", "start": 95, "end": 103, "i_start": 14, "i_end": 15}}, {"subject": {"text": "one", "start": 91, "end": 94, "i_start": 13, "i_end": 13}, "verb": {"text": "is", "start": 126, "end": 128, "i_start": 20, "i_end": 20}}, {"character": {"text": "one", "start": 91, "end": 94, "i_start": 13, "i_end": 13}, "action": {"text": "show", "start": 99, "end": 103, "i_start": 15, "i_end": 15}}, {"character": {"text": "system", "start": 119, "end": 125, "i_start": 19, "i_end": 19}, "action": {"text": "control", "start": 111, "end": 118, "i_start": 18, "i_end": 18}}], "id": 75}, {"sent": "the lbm is a local mesoscopic algorithm , allowing for efficient parallel implementations , and has demonstrated itself as a powerful tool for numerical simulations of fluid flows .", "tokens": ["the", "lbm", "is", "a", "local", "mesoscopic", "algorithm", ",", "allowing", "for", "efficient", "parallel", "implementations", ",", "and", "has", "demonstrated", "itself", "as", "a", "powerful", "tool", "for", "numerical", "simulations", "of", "fluid", "flows", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the lbm", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the lbm", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "demonstrated", "start": 100, "end": 112, "i_start": 16, "i_end": 16}}, {"character": {"text": "algorithm", "start": 30, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "allowing", "start": 42, "end": 50, "i_start": 8, "i_end": 8}}], "id": 76}, {"sent": "in the three-field scheduling notation , this problem is denoted as 1 , pmtn , w j c j .", "tokens": ["in", "the", "three", "-", "field", "scheduling", "notation", ",", "this", "problem", "is", "denoted", "as", "1", ",", "pmtn", ",", "w", "j", "c", "j", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this problem", "start": 41, "end": 53, "i_start": 8, "i_end": 9}, "verb": {"text": "is denoted", "start": 54, "end": 64, "i_start": 10, "i_end": 11}}], "id": 77}, {"sent": "it is also quantitatively discussed how inappropriate it is to use the original distribution instead of the escort distribution for calculating the expectation values of physical quantities in nonextensive statistical mechanics .", "tokens": ["it", "is", "also", "quantitatively", "discussed", "how", "inappropriate", "it", "is", "to", "use", "the", "original", "distribution", "instead", "of", "the", "escort", "distribution", "for", "calculating", "the", "expectation", "values", "of", "physical", "quantities", "in", "nonextensive", "statistical", "mechanics", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "discussed", "start": 26, "end": 35, "i_start": 4, "i_end": 4}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 57, "end": 59, "i_start": 8, "i_end": 8}}], "id": 78}, {"sent": "measures induced by partial tracing of composite systems a .", "tokens": ["measures", "induced", "by", "partial", "tracing", "of", "composite", "systems", "a", "."], "score": [0, 0, 0, 0, 0], "labels": [{"character": {"text": "tracing", "start": 28, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "induced", "start": 9, "end": 16, "i_start": 1, "i_end": 1}}], "id": 79}, {"sent": "also , the supersymmetry transformations are not modified by noncommutativity since they are linear and no moyal products are required .", "tokens": ["also", ",", "the", "supersymmetry", "transformations", "are", "not", "modified", "by", "noncommutativity", "since", "they", "are", "linear", "and", "no", "moyal", "products", "are", "required", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the supersymmetry transformations", "start": 7, "end": 40, "i_start": 2, "i_end": 4}, "verb": {"text": "are not modified", "start": 41, "end": 57, "i_start": 5, "i_end": 7}}, {"character": {"text": "noncommutativity", "start": 61, "end": 77, "i_start": 9, "i_end": 9}, "action": {"text": "not modified", "start": 45, "end": 57, "i_start": 6, "i_end": 7}}], "id": 80}, {"sent": "we use the official split of data , where 249 scenes are used for training and we sample 50k images out of the training similar to .", "tokens": ["we", "use", "the", "official", "split", "of", "data", ",", "where", "249", "scenes", "are", "used", "for", "training", "and", "we", "sample", "50k", "images", "out", "of", "the", "training", "similar", "to", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 79, "end": 81, "i_start": 16, "i_end": 16}, "verb": {"text": "sample", "start": 82, "end": 88, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "sample", "start": 82, "end": 88, "i_start": 17, "i_end": 17}}], "id": 81}, {"sent": "this completes the proof that is a reflecting that ( brownian motion with constant drift on d .", "tokens": ["this", "completes", "the", "proof", "that", "is", "a", "reflecting", "that", "(", "brownian", "motion", "with", "constant", "drift", "on", "d", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "completes", "start": 5, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "completes", "start": 5, "end": 14, "i_start": 1, "i_end": 1}}], "id": 82}, {"sent": "the study of truncated toeplitz operators has been largely motivated by a seminal paper of sarason .", "tokens": ["the", "study", "of", "truncated", "toeplitz", "operators", "has", "been", "largely", "motivated", "by", "a", "seminal", "paper", "of", "sarason", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the study of truncated toeplitz operators", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "motivated", "start": 59, "end": 68, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the study of truncated toeplitz operators", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "has been", "start": 42, "end": 50, "i_start": 6, "i_end": 7}}, {"character": {"text": "paper", "start": 82, "end": 87, "i_start": 13, "i_end": 13}, "action": {"text": "motivated", "start": 59, "end": 68, "i_start": 9, "i_end": 9}}], "id": 83}, {"sent": "the value of the monopole condensate is defined by the minimum of the effective potential .", "tokens": ["the", "value", "of", "the", "monopole", "condensate", "is", "defined", "by", "the", "minimum", "of", "the", "effective", "potential", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the value of the monopole condensate", "start": 0, "end": 36, "i_start": 0, "i_end": 5}, "verb": {"text": "is defined", "start": 37, "end": 47, "i_start": 6, "i_end": 7}}], "id": 84}, {"sent": "the iib matrix model was proposed as a non-perturbative formulation of type iib superstring theory .", "tokens": ["the", "iib", "matrix", "model", "was", "proposed", "as", "a", "non", "-", "perturbative", "formulation", "of", "type", "iib", "superstring", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the iib matrix model", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "was proposed", "start": 21, "end": 33, "i_start": 4, "i_end": 5}}], "id": 85}, {"sent": "the ability to detect small alterations in brain tissue is a key factor when developing biomarkers for early stages in neurodegeneration .", "tokens": ["the", "ability", "to", "detect", "small", "alterations", "in", "brain", "tissue", "is", "a", "key", "factor", "when", "developing", "biomarkers", "for", "early", "stages", "in", "neurodegeneration", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the ability to detect small alterations in brain tissue", "start": 0, "end": 55, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 56, "end": 58, "i_start": 9, "i_end": 9}}], "id": 86}, {"sent": "according to the usual notion of consensus , the network nodes should converge to an equilibrium point where all the nodes have the same value lying somewhere between the minimum and maximum of their initial values .", "tokens": ["according", "to", "the", "usual", "notion", "of", "consensus", ",", "the", "network", "nodes", "should", "converge", "to", "an", "equilibrium", "point", "where", "all", "the", "nodes", "have", "the", "same", "value", "lying", "somewhere", "between", "the", "minimum", "and", "maximum", "of", "their", "initial", "values", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the network nodes", "start": 45, "end": 62, "i_start": 8, "i_end": 10}, "verb": {"text": "should converge", "start": 63, "end": 78, "i_start": 11, "i_end": 12}}], "id": 87}, {"sent": "in the open phase , a sends the procedure for revealing the hidden commitment at time t 3 , and b uses this .", "tokens": ["in", "the", "open", "phase", ",", "a", "sends", "the", "procedure", "for", "revealing", "the", "hidden", "commitment", "at", "time", "t", "3", ",", "and", "b", "uses", "this", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "a", "start": 20, "end": 21, "i_start": 5, "i_end": 5}, "verb": {"text": "sends", "start": 22, "end": 27, "i_start": 6, "i_end": 6}}, {"subject": {"text": "b", "start": 96, "end": 97, "i_start": 20, "i_end": 20}, "verb": {"text": "uses", "start": 98, "end": 102, "i_start": 21, "i_end": 21}}], "id": 88}, {"sent": "floating-point arithmetic has became widely used in many applications such as 3d graphics , scientific computing and signal processing .", "tokens": ["floating", "-", "point", "arithmetic", "has", "became", "widely", "used", "in", "many", "applications", "such", "as", "3d", "graphics", ",", "scientific", "computing", "and", "signal", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "floating-point arithmetic", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "has became", "start": 26, "end": 36, "i_start": 4, "i_end": 5}}], "id": 89}, {"sent": "however , in these stray-field-coupled multilayers , the large dipolar fields can outweigh the dmi and stabilise twisted spin structures with a non-uniform chirality across the film thickness .", "tokens": ["however", ",", "in", "these", "stray", "-", "field", "-", "coupled", "multilayers", ",", "the", "large", "dipolar", "fields", "can", "outweigh", "the", "dmi", "and", "stabilise", "twisted", "spin", "structures", "with", "a", "non", "-", "uniform", "chirality", "across", "the", "film", "thickness", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the large dipolar fields", "start": 53, "end": 77, "i_start": 11, "i_end": 14}, "verb": {"text": "can outweigh", "start": 78, "end": 90, "i_start": 15, "i_end": 16}}, {"character": {"text": "field", "start": 25, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "outweigh", "start": 82, "end": 90, "i_start": 16, "i_end": 16}}, {"character": {"text": "field", "start": 25, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "stabilise", "start": 103, "end": 112, "i_start": 20, "i_end": 20}}, {"character": {"text": "fields", "start": 71, "end": 77, "i_start": 14, "i_end": 14}, "action": {"text": "stray", "start": 19, "end": 24, "i_start": 4, "i_end": 4}}], "id": 90}, {"sent": "this peculiar pattern was first observed and analyzed by kuramoto in simulating the complex ginzburg-landau equation with nonlocal couplings .", "tokens": ["this", "peculiar", "pattern", "was", "first", "observed", "and", "analyzed", "by", "kuramoto", "in", "simulating", "the", "complex", "ginzburg", "-", "landau", "equation", "with", "nonlocal", "couplings", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this peculiar pattern", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "observed", "start": 32, "end": 40, "i_start": 5, "i_end": 5}}, {"subject": {"text": "this peculiar pattern", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "was", "start": 22, "end": 25, "i_start": 3, "i_end": 3}}, {"subject": {"text": "this peculiar pattern", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "analyzed", "start": 45, "end": 53, "i_start": 7, "i_end": 7}}, {"character": {"text": "kuramoto", "start": 57, "end": 65, "i_start": 9, "i_end": 9}, "action": {"text": "observed", "start": 32, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "kuramoto", "start": 57, "end": 65, "i_start": 9, "i_end": 9}, "action": {"text": "analyzed", "start": 45, "end": 53, "i_start": 7, "i_end": 7}}, {"character": {"text": "kuramoto", "start": 57, "end": 65, "i_start": 9, "i_end": 9}, "action": {"text": "simulating", "start": 69, "end": 79, "i_start": 11, "i_end": 11}}], "id": 91}, {"sent": "in doing so , we extensively use the average weight spectra derived for the ensemble bin and for ensemble ain .", "tokens": ["in", "doing", "so", ",", "we", "extensively", "use", "the", "average", "weight", "spectra", "derived", "for", "the", "ensemble", "bin", "and", "for", "ensemble", "ain", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 29, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 29, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "doing", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 92}, {"sent": "sie setzen sich aus modulnamen und instanzbezeichnungen zusammen .", "tokens": ["sie", "setzen", "sich", "aus", "modulnamen", "und", "instanzbezeichnungen", "zusammen", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 93}, {"sent": "in our evaluation , we adopt the loopy belief propagation algorithm which was shown to perform well for various problems .", "tokens": ["in", "our", "evaluation", ",", "we", "adopt", "the", "loopy", "belief", "propagation", "algorithm", "which", "was", "shown", "to", "perform", "well", "for", "various", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 20, "end": 22, "i_start": 4, "i_end": 4}, "verb": {"text": "adopt", "start": 23, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 20, "end": 22, "i_start": 4, "i_end": 4}, "action": {"text": "adopt", "start": 23, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "algorithm", "start": 58, "end": 67, "i_start": 10, "i_end": 10}, "action": {"text": "perform", "start": 87, "end": 94, "i_start": 15, "i_end": 15}}], "id": 94}, {"sent": "in fact , our definition admits cyclic directed graphs with cycles containing source nodes , and there may be no nodes with in-degree zero .", "tokens": ["in", "fact", ",", "our", "definition", "admits", "cyclic", "directed", "graphs", "with", "cycles", "containing", "source", "nodes", ",", "and", "there", "may", "be", "no", "nodes", "with", "in", "-", "degree", "zero", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our definition", "start": 10, "end": 24, "i_start": 3, "i_end": 4}, "verb": {"text": "admits", "start": 25, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "cycles", "start": 60, "end": 66, "i_start": 10, "i_end": 10}, "action": {"text": "containing", "start": 67, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "graphs", "start": 48, "end": 54, "i_start": 8, "i_end": 8}, "action": {"text": "no", "start": 110, "end": 112, "i_start": 19, "i_end": 19}}], "id": 95}, {"sent": "since the vector r-current is non-anomalous , this category is z-graded .", "tokens": ["since", "the", "vector", "r", "-", "current", "is", "non", "-", "anomalous", ",", "this", "category", "is", "z", "-", "graded", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "this category", "start": 46, "end": 59, "i_start": 11, "i_end": 12}, "verb": {"text": "is", "start": 60, "end": 62, "i_start": 13, "i_end": 13}}], "id": 96}, {"sent": "e-nose data analysis e-nose is a multi-sensor system comprised of a sensor array with partial specificity coupled with pattern recognition algorithm , which can also be recognized as cost-sensitive problem .", "tokens": ["e", "-", "nose", "data", "analysis", "e", "-", "nose", "is", "a", "multi", "-", "sensor", "system", "comprised", "of", "a", "sensor", "array", "with", "partial", "specificity", "coupled", "with", "pattern", "recognition", "algorithm", ",", "which", "can", "also", "be", "recognized", "as", "cost", "-", "sensitive", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "e-nose data analysis e-nose", "start": 0, "end": 27, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 8, "i_end": 8}}, {"character": {"text": "algorithm", "start": 139, "end": 148, "i_start": 26, "i_end": 26}, "action": {"text": "recognized", "start": 169, "end": 179, "i_start": 32, "i_end": 32}}, {"character": {"text": "problem", "start": 198, "end": 205, "i_start": 37, "i_end": 37}, "action": {"text": "sensitive", "start": 188, "end": 197, "i_start": 36, "i_end": 36}}], "id": 97}, {"sent": "a closely related research area is available bandwidth estimation that seeks to estimate the long-term average unused capacity of a system or a network .", "tokens": ["a", "closely", "related", "research", "area", "is", "available", "bandwidth", "estimation", "that", "seeks", "to", "estimate", "the", "long", "-", "term", "average", "unused", "capacity", "of", "a", "system", "or", "a", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a closely related research area", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 5, "i_end": 5}}, {"character": {"text": "estimate", "start": 80, "end": 88, "i_start": 12, "i_end": 12}, "action": {"text": "seeks", "start": 71, "end": 76, "i_start": 10, "i_end": 10}}], "id": 98}, {"sent": "as explained in , this integration can always be done exactly at large n , by introducing auxiliary variables .", "tokens": ["as", "explained", "in", ",", "this", "integration", "can", "always", "be", "done", "exactly", "at", "large", "n", ",", "by", "introducing", "auxiliary", "variables", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this integration", "start": 18, "end": 34, "i_start": 4, "i_end": 5}, "verb": {"text": "be done", "start": 46, "end": 53, "i_start": 8, "i_end": 9}}, {"subject": {"text": "this integration", "start": 18, "end": 34, "i_start": 4, "i_end": 5}, "verb": {"text": "can", "start": 35, "end": 38, "i_start": 6, "i_end": 6}}], "id": 99}]