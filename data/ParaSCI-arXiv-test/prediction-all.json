[{"sent": "zhang and parker proposed a new bio-inspired predictive orientation decomposition representation , which was inspired by the biological research in human anatomy .", "tokens": ["zhang", "and", "parker", "proposed", "a", "new", "bio", "-", "inspired", "predictive", "orientation", "decomposition", "representation", ",", "which", "was", "inspired", "by", "the", "biological", "research", "in", "human", "anatomy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhang and parker", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "parker", "start": 10, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "proposed", "start": 17, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "bio", "start": 32, "end": 35, "i_start": 6, "i_end": 6}, "action": {"text": "inspired", "start": 36, "end": 44, "i_start": 8, "i_end": 8}}, {"character": {"text": "research", "start": 136, "end": 144, "i_start": 20, "i_end": 20}, "action": {"text": "inspired", "start": 109, "end": 117, "i_start": 16, "i_end": 16}}], "id": 0}, {"sent": "zhang and parker implemented a bio-inspired predictive orientation decomposition using mid-level features to construct representations of people from 3d skeleton trajectories , which is inspired by biological research in human anatomy .", "tokens": ["zhang", "and", "parker", "implemented", "a", "bio", "-", "inspired", "predictive", "orientation", "decomposition", "using", "mid", "-", "level", "features", "to", "construct", "representations", "of", "people", "from", "3d", "skeleton", "trajectories", ",", "which", "is", "inspired", "by", "biological", "research", "in", "human", "anatomy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "zhang and parker", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "implemented", "start": 17, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "zhang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "implemented", "start": 17, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "parker", "start": 10, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "implemented", "start": 17, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "bio", "start": 31, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "inspired", "start": 35, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "decomposition", "start": 67, "end": 80, "i_start": 10, "i_end": 10}, "action": {"text": "using", "start": 81, "end": 86, "i_start": 11, "i_end": 11}}, {"character": {"text": "zhang", "start": 0, "end": 5, "i_start": 0, "i_end": 0}, "action": {"text": "construct", "start": 109, "end": 118, "i_start": 17, "i_end": 17}}, {"character": {"text": "parker", "start": 10, "end": 16, "i_start": 2, "i_end": 2}, "action": {"text": "construct", "start": 109, "end": 118, "i_start": 17, "i_end": 17}}, {"character": {"text": "research", "start": 209, "end": 217, "i_start": 31, "i_end": 31}, "action": {"text": "inspired", "start": 186, "end": 194, "i_start": 28, "i_end": 28}}], "id": 0}, {"sent": "transfer learning is a machine learning technique proposed to alleviate the distribution discrepancy issue .", "tokens": ["transfer", "learning", "is", "a", "machine", "learning", "technique", "proposed", "to", "alleviate", "the", "distribution", "discrepancy", "issue", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "transfer learning", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "learning", "start": 31, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "alleviate", "start": 62, "end": 71, "i_start": 9, "i_end": 9}}, {"character": {"text": "discrepancy", "start": 89, "end": 100, "i_start": 12, "i_end": 12}, "action": {"text": "issue", "start": 101, "end": 106, "i_start": 13, "i_end": 13}}], "id": 1}, {"sent": "transfer learning is a learning paradigm that uses data in relevant tasks to help the target machine learning tasks .", "tokens": ["transfer", "learning", "is", "a", "learning", "paradigm", "that", "uses", "data", "in", "relevant", "tasks", "to", "help", "the", "target", "machine", "learning", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "transfer learning", "start": 0, "end": 17, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "paradigm", "start": 32, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "uses", "start": 46, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "learning", "start": 9, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "help", "start": 77, "end": 81, "i_start": 13, "i_end": 13}}], "id": 1}, {"sent": "this may suggest that this late time behavior can also be used as a criterion of chaotic nature of a given quantum field theory , in addition to the existing arguments on the lyapunov exponent .", "tokens": ["this", "may", "suggest", "that", "this", "late", "time", "behavior", "can", "also", "be", "used", "as", "a", "criterion", "of", "chaotic", "nature", "of", "a", "given", "quantum", "field", "theory", ",", "in", "addition", "to", "the", "existing", "arguments", "on", "the", "lyapunov", "exponent", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "may suggest", "start": 5, "end": 16, "i_start": 1, "i_end": 2}}, {"subject": {"text": "this late time behavior", "start": 22, "end": 45, "i_start": 4, "i_end": 7}, "verb": {"text": "used", "start": 58, "end": 62, "i_start": 11, "i_end": 11}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "suggest", "start": 9, "end": 16, "i_start": 2, "i_end": 2}}], "id": 2}, {"sent": "it has been conjectured that the exponential behavior of this quantity should be an indicator of quantum chaos , the exponential rate being associated with the classical lyapunov exponent .", "tokens": ["it", "has", "been", "conjectured", "that", "the", "exponential", "behavior", "of", "this", "quantity", "should", "be", "an", "indicator", "of", "quantum", "chaos", ",", "the", "exponential", "rate", "being", "associated", "with", "the", "classical", "lyapunov", "exponent", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has been conjectured", "start": 3, "end": 23, "i_start": 1, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "be", "start": 78, "end": 80, "i_start": 12, "i_end": 12}}, {"character": {"text": "behavior", "start": 45, "end": 53, "i_start": 7, "i_end": 7}, "action": {"text": "indicator", "start": 84, "end": 93, "i_start": 14, "i_end": 14}}, {"character": {"text": "quantity", "start": 62, "end": 70, "i_start": 10, "i_end": 10}, "action": {"text": "behavior", "start": 45, "end": 53, "i_start": 7, "i_end": 7}}], "id": 2}, {"sent": "while most of research is related to marketing , the problem has been generalized to ranking nodes for target set selection in the domain of combinatorial optimization of theoretical computer science .", "tokens": ["while", "most", "of", "research", "is", "related", "to", "marketing", ",", "the", "problem", "has", "been", "generalized", "to", "ranking", "nodes", "for", "target", "set", "selection", "in", "the", "domain", "of", "combinatorial", "optimization", "of", "theoretical", "computer", "science", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the problem", "start": 49, "end": 60, "i_start": 9, "i_end": 10}, "verb": {"text": "has been generalized", "start": 61, "end": 81, "i_start": 11, "i_end": 13}}], "id": 3}, {"sent": "while most of research is related to marketing , the problem has been generalized to target set selection in the domain of combinatorial optimization of theoretical computer science .", "tokens": ["while", "most", "of", "research", "is", "related", "to", "marketing", ",", "the", "problem", "has", "been", "generalized", "to", "target", "set", "selection", "in", "the", "domain", "of", "combinatorial", "optimization", "of", "theoretical", "computer", "science", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the problem", "start": 49, "end": 60, "i_start": 9, "i_end": 10}, "verb": {"text": "has been generalized", "start": 61, "end": 81, "i_start": 11, "i_end": 13}}], "id": 3}, {"sent": "if we give up consistency only , then the system-environment correlations can be of the classical form .", "tokens": ["if", "we", "give", "up", "consistency", "only", ",", "then", "the", "system", "-", "environment", "correlations", "can", "be", "of", "the", "classical", "form", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the system-environment correlations", "start": 38, "end": 73, "i_start": 8, "i_end": 12}, "verb": {"text": "can be", "start": 74, "end": 80, "i_start": 13, "i_end": 14}}], "id": 4}, {"sent": "finally , if we give up positivity only , we can get quantum correlations for the system-environment state .", "tokens": ["finally", ",", "if", "we", "give", "up", "positivity", "only", ",", "we", "can", "get", "quantum", "correlations", "for", "the", "system", "-", "environment", "state", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 42, "end": 44, "i_start": 9, "i_end": 9}, "verb": {"text": "can get", "start": 45, "end": 52, "i_start": 10, "i_end": 11}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "get", "start": 49, "end": 52, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "give", "start": 16, "end": 20, "i_start": 4, "i_end": 4}}], "id": 4}, {"sent": "in the plane of the film and perpendicular to the long axis of the wire .", "tokens": ["in", "the", "plane", "of", "the", "film", "and", "perpendicular", "to", "the", "long", "axis", "of", "the", "wire", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 5}, {"sent": "in the plane of the wires and perpendicular to their length .", "tokens": ["in", "the", "plane", "of", "the", "wires", "and", "perpendicular", "to", "their", "length", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 5}, {"sent": "are single-valued whereas fermion-based representationstf erm .", "tokens": ["are", "single", "-", "valued", "whereas", "fermion", "-", "based", "representations"], "score": [0, 0, 0, 0, 0], "labels": [], "id": 6}, {"sent": "are global representations , whereas tf erm .", "tokens": ["are", "global", "representations", ",", "whereas", "tf", "erm", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 6}, {"sent": "hence the grand partition function \u03be contains the ionic interactions and zero frequency van der waals contributions in the system .", "tokens": ["hence", "the", "grand", "partition", "function", "\u03be", "contains", "the", "ionic", "interactions", "and", "zero", "frequency", "van", "der", "waals", "contributions", "in", "the", "system", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "hence the grand partition function \u03be", "start": 0, "end": 36, "i_start": 0, "i_end": 5}, "verb": {"text": "contains", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "function", "start": 26, "end": 34, "i_start": 4, "i_end": 4}, "action": {"text": "contains", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}], "id": 7}, {"sent": "as mentioned previously , in the formulation here , the zero frequency lifshitz and ionic components are treated together in the grand partition function \u03be .", "tokens": ["as", "mentioned", "previously", ",", "in", "the", "formulation", "here", ",", "the", "zero", "frequency", "lifshitz", "and", "ionic", "components", "are", "treated", "together", "in", "the", "grand", "partition", "function", "\u03be", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the zero frequency lifshitz and ionic components", "start": 52, "end": 100, "i_start": 9, "i_end": 15}, "verb": {"text": "are treated", "start": 101, "end": 112, "i_start": 16, "i_end": 17}}], "id": 7}, {"sent": "the abscissa and ordinate denote the superhump phase and magnitude , respectively .", "tokens": ["the", "abscissa", "and", "ordinate", "denote", "the", "superhump", "phase", "and", "magnitude", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the abscissa and ordinate", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "denote", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "abscissa", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "ordinate", "start": 17, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "denote", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}], "id": 8}, {"sent": "the abscissa and ordinate denote the time in jd and the magnitude , respectively .", "tokens": ["the", "abscissa", "and", "ordinate", "denote", "the", "time", "in", "jd", "and", "the", "magnitude", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"character": {"text": "abscissa", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denote", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "ordinate", "start": 17, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "denote", "start": 26, "end": 32, "i_start": 4, "i_end": 4}}], "id": 8}, {"sent": "some general properties of the strong geodesic problem , in particular with respect to the diameter , and a solution for balanced complete bipartite graphs has been very recently reported in .", "tokens": ["some", "general", "properties", "of", "the", "strong", "geodesic", "problem", ",", "in", "particular", "with", "respect", "to", "the", "diameter", ",", "and", "a", "solution", "for", "balanced", "complete", "bipartite", "graphs", "has", "been", "very", "recently", "reported", "in", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "some general properties of the strong geodesic problem", "start": 0, "end": 54, "i_start": 0, "i_end": 7}, "verb": {"text": "reported", "start": 179, "end": 187, "i_start": 29, "i_end": 29}}, {"subject": {"text": "some general properties of the strong geodesic problem", "start": 0, "end": 54, "i_start": 0, "i_end": 7}, "verb": {"text": "has been", "start": 156, "end": 164, "i_start": 25, "i_end": 26}}], "id": 9}, {"sent": "additional properties , in particular with respect to the diameter , and a solution for balanced complete bipartite graphs were reported in .", "tokens": ["additional", "properties", ",", "in", "particular", "with", "respect", "to", "the", "diameter", ",", "and", "a", "solution", "for", "balanced", "complete", "bipartite", "graphs", "were", "reported", "in", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "additional properties , in particular with respect to the diameter , and a solution for balanced complete bipartite graphs", "start": 0, "end": 122, "i_start": 0, "i_end": 18}, "verb": {"text": "were reported", "start": 123, "end": 136, "i_start": 19, "i_end": 20}}], "id": 9}, {"sent": "mahjourian et al in addition to image alignment enforce alignment of the geometric scene structure in the loss function .", "tokens": ["mahjourian", "et", "al", "in", "addition", "to", "image", "alignment", "enforce", "alignment", "of", "the", "geometric", "scene", "structure", "in", "the", "loss", "function", "."], "score": [0, 0, 0, 0, 0], "labels": [{"character": {"text": "mahjourian", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "enforce", "start": 48, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "alignment", "start": 38, "end": 47, "i_start": 7, "i_end": 7}, "action": {"text": "enforce", "start": 48, "end": 55, "i_start": 8, "i_end": 8}}], "id": 10}, {"sent": "mahjourian et al employ geometric constraints of the scene by enforcing an approximate icp based matching loss .", "tokens": ["mahjourian", "et", "al", "employ", "geometric", "constraints", "of", "the", "scene", "by", "enforcing", "an", "approximate", "icp", "based", "matching", "loss", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "mahjourian et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "employ", "start": 17, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "mahjourian", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "employ", "start": 17, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "mahjourian", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "constraints", "start": 34, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "mahjourian", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "enforcing", "start": 62, "end": 71, "i_start": 10, "i_end": 10}}], "id": 10}, {"sent": "the key difference between our model and most existing literature is the possibility of obtaining resource through the cheaper but uncertain approach of spectrum sensing .", "tokens": ["the", "key", "difference", "between", "our", "model", "and", "most", "existing", "literature", "is", "the", "possibility", "of", "obtaining", "resource", "through", "the", "cheaper", "but", "uncertain", "approach", "of", "spectrum", "sensing", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the key difference between our model and most existing literature", "start": 0, "end": 65, "i_start": 0, "i_end": 9}, "verb": {"text": "is", "start": 66, "end": 68, "i_start": 10, "i_end": 10}}], "id": 11}, {"sent": "the key difference between our model and most previous models is the possibility of obtaining resource through the cheaper but less reliable approach of spectrum sensing .", "tokens": ["the", "key", "difference", "between", "our", "model", "and", "most", "previous", "models", "is", "the", "possibility", "of", "obtaining", "resource", "through", "the", "cheaper", "but", "less", "reliable", "approach", "of", "spectrum", "sensing", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the key difference between our model and most previous models", "start": 0, "end": 61, "i_start": 0, "i_end": 9}, "verb": {"text": "is", "start": 62, "end": 64, "i_start": 10, "i_end": 10}}], "id": 11}, {"sent": "historically the first one is the harmonic analysis in right ascension , see for a recent application .", "tokens": ["historically", "the", "first", "one", "is", "the", "harmonic", "analysis", "in", "right", "ascension", ",", "see", "for", "a", "recent", "application", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the first one", "start": 13, "end": 26, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 4, "i_end": 4}}], "id": 12}, {"sent": "historically the first one is a harmonic analysis in right ascension , see for a recent application .", "tokens": ["historically", "the", "first", "one", "is", "a", "harmonic", "analysis", "in", "right", "ascension", ",", "see", "for", "a", "recent", "application", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the first one", "start": 13, "end": 26, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 4, "i_end": 4}}], "id": 12}, {"sent": "to find the local neighborhoods , we follow the idea of using both their approximations .", "tokens": ["to", "find", "the", "local", "neighborhoods", ",", "we", "follow", "the", "idea", "of", "using", "both", "their", "approximations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "verb": {"text": "follow", "start": 37, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "follow", "start": 37, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "using", "start": 56, "end": 61, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 13}, {"sent": "to find the local neighborhoods , we follow the idea of revaud et al using both of their approximations .", "tokens": ["to", "find", "the", "local", "neighborhoods", ",", "we", "follow", "the", "idea", "of", "revaud", "et", "al", "using", "both", "of", "their", "approximations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "verb": {"text": "follow", "start": 37, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "follow", "start": 37, "end": 43, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "using", "start": 69, "end": 74, "i_start": 14, "i_end": 14}}, {"character": {"text": "revaud", "start": 56, "end": 62, "i_start": 11, "i_end": 11}, "action": {"text": "approximations", "start": 89, "end": 103, "i_start": 18, "i_end": 18}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 13}, {"sent": "we also calculate the coupling of the annihilation process , which is useful for an appropriate model building to give the desired dark matter relic density .", "tokens": ["we", "also", "calculate", "the", "coupling", "of", "the", "annihilation", "process", ",", "which", "is", "useful", "for", "an", "appropriate", "model", "building", "to", "give", "the", "desired", "dark", "matter", "relic", "density", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "calculate", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "calculate", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "calculate", "start": 8, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "useful", "start": 70, "end": 76, "i_start": 12, "i_end": 12}}, {"character": {"text": "building", "start": 102, "end": 110, "i_start": 17, "i_end": 17}, "action": {"text": "give", "start": 114, "end": 118, "i_start": 19, "i_end": 19}}], "id": 14}, {"sent": "in terms of the observed dark matter abundance , we calculate the coupling of the annihilation process for the whole resonance parameter space .", "tokens": ["in", "terms", "of", "the", "observed", "dark", "matter", "abundance", ",", "we", "calculate", "the", "coupling", "of", "the", "annihilation", "process", "for", "the", "whole", "resonance", "parameter", "space", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "verb": {"text": "calculate", "start": 52, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "action": {"text": "calculate", "start": 52, "end": 61, "i_start": 10, "i_end": 10}}], "id": 14}, {"sent": "the dft description here is provided by the local density approximation of perdew-zunger .", "tokens": ["the", "dft", "description", "here", "is", "provided", "by", "the", "local", "density", "approximation", "of", "perdew", "-", "zunger", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the dft description here", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "is provided", "start": 25, "end": 36, "i_start": 4, "i_end": 5}}, {"character": {"text": "approximation", "start": 58, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "provided", "start": 28, "end": 36, "i_start": 5, "i_end": 5}}], "id": 15}, {"sent": "we use the local density approximation of perdew and zunger , and a double zeta plus double polarization basis set of the siesta type .", "tokens": ["we", "use", "the", "local", "density", "approximation", "of", "perdew", "and", "zunger", ",", "and", "a", "double", "zeta", "plus", "double", "polarization", "basis", "set", "of", "the", "siesta", "type", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 15}, {"sent": "we refer the reader to and the references therein for general survey of the euler equations .", "tokens": ["we", "refer", "the", "reader", "to", "and", "the", "references", "therein", "for", "general", "survey", "of", "the", "euler", "equations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "refer", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 16}, {"sent": "for surveys of the known mathematical theories of the equations we refer to .", "tokens": ["for", "surveys", "of", "the", "known", "mathematical", "theories", "of", "the", "equations", "we", "refer", "to", "."], "score": [0, 0, 0, 0, 0], "labels": [{"character": {"text": "we", "start": 64, "end": 66, "i_start": 10, "i_end": 10}, "action": {"text": "refer", "start": 67, "end": 72, "i_start": 11, "i_end": 11}}], "id": 16}, {"sent": "orthogonal frequency division multiplexing has become quite popular in both wired and wireless communications .", "tokens": ["orthogonal", "frequency", "division", "multiplexing", "has", "become", "quite", "popular", "in", "both", "wired", "and", "wireless", "communications", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "orthogonal frequency division multiplexing", "start": 0, "end": 42, "i_start": 0, "i_end": 3}, "verb": {"text": "has become", "start": 43, "end": 53, "i_start": 4, "i_end": 5}}], "id": 17}, {"sent": "orthogonal frequency-division multiplexing is an attractive and well-established way of dealing with frequencyselective channels .", "tokens": ["orthogonal", "frequency", "-", "division", "multiplexing", "is", "an", "attractive", "and", "well", "-", "established", "way", "of", "dealing", "with", "frequencyselective", "channels", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "orthogonal frequency-division multiplexing", "start": 0, "end": 42, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 43, "end": 45, "i_start": 5, "i_end": 5}}, {"character": {"text": "way", "start": 81, "end": 84, "i_start": 12, "i_end": 12}, "action": {"text": "attractive", "start": 49, "end": 59, "i_start": 7, "i_end": 7}}], "id": 17}, {"sent": "in this section , we calculate the susy algebra in the following wess-zumino model for simplicity .", "tokens": ["in", "this", "section", ",", "we", "calculate", "the", "susy", "algebra", "in", "the", "following", "wess", "-", "zumino", "model", "for", "simplicity", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "calculate", "start": 21, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "calculate", "start": 21, "end": 30, "i_start": 5, "i_end": 5}}], "id": 18}, {"sent": "since we consider the case of the susy breaking , we describe the susy algebra in the local form .", "tokens": ["since", "we", "consider", "the", "case", "of", "the", "susy", "breaking", ",", "we", "describe", "the", "susy", "algebra", "in", "the", "local", "form", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 50, "end": 52, "i_start": 10, "i_end": 10}, "verb": {"text": "describe", "start": 53, "end": 61, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "describe", "start": 53, "end": 61, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 6, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "consider", "start": 9, "end": 17, "i_start": 2, "i_end": 2}}], "id": 18}, {"sent": "we trained a neural network to control the cart-pole using proximal policy optimization algorithms with 100k training episodes .", "tokens": ["we", "trained", "a", "neural", "network", "to", "control", "the", "cart", "-", "pole", "using", "proximal", "policy", "optimization", "algorithms", "with", "100k", "training", "episodes", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "trained", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "trained", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "network", "start": 20, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "control", "start": 31, "end": 38, "i_start": 6, "i_end": 6}}, {"character": {"text": "network", "start": 20, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "using", "start": 53, "end": 58, "i_start": 11, "i_end": 11}}], "id": 19}, {"sent": "we trained a neural network policy for solving the humanoid locomotion task using proximal policy optimization and different planning horizons .", "tokens": ["we", "trained", "a", "neural", "network", "policy", "for", "solving", "the", "humanoid", "locomotion", "task", "using", "proximal", "policy", "optimization", "and", "different", "planning", "horizons", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "trained", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "trained", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "policy", "start": 28, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "solving", "start": 39, "end": 46, "i_start": 7, "i_end": 7}}], "id": 19}, {"sent": "linnik , on the least prime in an arithmetic progression ii , the deuringheilbronn phenomenon rec .", "tokens": ["linnik", ",", "on", "the", "least", "prime", "in", "an", "arithmetic", "progression", "ii", ",", "the", "deuringheilbronn", "phenomenon", "rec", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 20}, {"sent": "linnik , on the least prime in an arithmetic progression i , the basis theorem rec .", "tokens": ["linnik", ",", "on", "the", "least", "prime", "in", "an", "arithmetic", "progression", "i", ",", "the", "basis", "theorem", "rec", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 20}, {"sent": "for normalization purposes , weights need to be between 0 and 1 , where larger weights are assigned to generalized items comprised of items that are more semantically distant , since such generalized items are more harmful to data utility .", "tokens": ["for", "normalization", "purposes", ",", "weights", "need", "to", "be", "between", "0", "and", "1", ",", "where", "larger", "weights", "are", "assigned", "to", "generalized", "items", "comprised", "of", "items", "that", "are", "more", "semantically", "distant", ",", "since", "such", "generalized", "items", "are", "more", "harmful", "to", "data", "utility", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "weights", "start": 29, "end": 36, "i_start": 4, "i_end": 4}, "verb": {"text": "need", "start": 37, "end": 41, "i_start": 5, "i_end": 5}}, {"character": {"text": "items", "start": 115, "end": 120, "i_start": 20, "i_end": 20}, "action": {"text": "harmful", "start": 215, "end": 222, "i_start": 36, "i_end": 36}}], "id": 21}, {"sent": "weights need to be between 0 and 1 for normalization purposes , where larger weights are assigned to generalized items comprised of items that are more semantically distant , since such generalized items harm data utility more .", "tokens": ["weights", "need", "to", "be", "between", "0", "and", "1", "for", "normalization", "purposes", ",", "where", "larger", "weights", "are", "assigned", "to", "generalized", "items", "comprised", "of", "items", "that", "are", "more", "semantically", "distant", ",", "since", "such", "generalized", "items", "harm", "data", "utility", "more", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "weights", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "need", "start": 8, "end": 12, "i_start": 1, "i_end": 1}}], "id": 21}, {"sent": "we have applied the sso algorithm to 19 functions whose results have been compared to those produced by the particle swarm optimization method and the artificial bee colony algorithm .", "tokens": ["we", "have", "applied", "the", "sso", "algorithm", "to", "19", "functions", "whose", "results", "have", "been", "compared", "to", "those", "produced", "by", "the", "particle", "swarm", "optimization", "method", "and", "the", "artificial", "bee", "colony", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have applied", "start": 3, "end": 15, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "applied", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "method", "start": 136, "end": 142, "i_start": 22, "i_end": 22}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "optimization", "start": 123, "end": 135, "i_start": 21, "i_end": 21}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "particle", "start": 108, "end": 116, "i_start": 19, "i_end": 19}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "algorithm", "start": 173, "end": 182, "i_start": 28, "i_end": 28}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "colony", "start": 166, "end": 172, "i_start": 27, "i_end": 27}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "artificial", "start": 151, "end": 161, "i_start": 25, "i_end": 25}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "bee", "start": 162, "end": 165, "i_start": 26, "i_end": 26}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}], "id": 22}, {"sent": "we have applied the sms algorithm to 24 functions whose results have been compared to those produced by the gravitational search algorithm , the particle swarm optimization method and the differential evolution algorithm .", "tokens": ["we", "have", "applied", "the", "sms", "algorithm", "to", "24", "functions", "whose", "results", "have", "been", "compared", "to", "those", "produced", "by", "the", "gravitational", "search", "algorithm", ",", "the", "particle", "swarm", "optimization", "method", "and", "the", "differential", "evolution", "algorithm", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have applied", "start": 3, "end": 15, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "applied", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "algorithm", "start": 129, "end": 138, "i_start": 21, "i_end": 21}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "search", "start": 122, "end": 128, "i_start": 20, "i_end": 20}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "gravitational", "start": 108, "end": 121, "i_start": 19, "i_end": 19}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "method", "start": 173, "end": 179, "i_start": 27, "i_end": 27}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "optimization", "start": 160, "end": 172, "i_start": 26, "i_end": 26}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "swarm", "start": 154, "end": 159, "i_start": 25, "i_end": 25}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "particle", "start": 145, "end": 153, "i_start": 24, "i_end": 24}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "algorithm", "start": 211, "end": 220, "i_start": 32, "i_end": 32}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "evolution", "start": 201, "end": 210, "i_start": 31, "i_end": 31}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}, {"character": {"text": "differential", "start": 188, "end": 200, "i_start": 30, "i_end": 30}, "action": {"text": "produced", "start": 92, "end": 100, "i_start": 16, "i_end": 16}}], "id": 22}, {"sent": "it makes rydberg atoms promising for applications such as quantum information processing .", "tokens": ["it", "makes", "rydberg", "atoms", "promising", "for", "applications", "such", "as", "quantum", "information", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "makes", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "rydberg atoms", "start": 9, "end": 22, "i_start": 2, "i_end": 3}, "verb": {"text": "promising", "start": 23, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "makes", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "atoms", "start": 17, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "promising", "start": 23, "end": 32, "i_start": 4, "i_end": 4}}], "id": 23}, {"sent": "it makes rydberg atoms promising for applications such as quantum information .", "tokens": ["it", "makes", "rydberg", "atoms", "promising", "for", "applications", "such", "as", "quantum", "information", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "makes", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "rydberg atoms", "start": 9, "end": 22, "i_start": 2, "i_end": 3}, "verb": {"text": "promising", "start": 23, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "makes", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "atoms", "start": 17, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "promising", "start": 23, "end": 32, "i_start": 4, "i_end": 4}}], "id": 23}, {"sent": "this brings the ability to target users based on their past behavior , which is typically referred to as ad targeting .", "tokens": ["this", "brings", "the", "ability", "to", "target", "users", "based", "on", "their", "past", "behavior", ",", "which", "is", "typically", "referred", "to", "as", "ad", "targeting", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "brings", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "brings", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}], "id": 24}, {"sent": "this allows for targeting of users based on their behavior , which is typically referred to as ad targeting .", "tokens": ["this", "allows", "for", "targeting", "of", "users", "based", "on", "their", "behavior", ",", "which", "is", "typically", "referred", "to", "as", "ad", "targeting", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "allows", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "allows", "start": 5, "end": 11, "i_start": 1, "i_end": 1}}], "id": 24}, {"sent": "an early research extended virtualization solutions to support rich and effective policies for active power management which had not been done before .", "tokens": ["an", "early", "research", "extended", "virtualization", "solutions", "to", "support", "rich", "and", "effective", "policies", "for", "active", "power", "management", "which", "had", "not", "been", "done", "before", "."], "score": [0, 0, 0, 0, 0], "labels": [{"character": {"text": "research", "start": 9, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "extended", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}, {"character": {"text": "solutions", "start": 42, "end": 51, "i_start": 5, "i_end": 5}, "action": {"text": "support", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}, {"character": {"text": "policies", "start": 82, "end": 90, "i_start": 11, "i_end": 11}, "action": {"text": "effective", "start": 72, "end": 81, "i_start": 10, "i_end": 10}}], "id": 25}, {"sent": "an early study extended virtualization solutions to support rich and effective policies for active power management , which had not been done before .", "tokens": ["an", "early", "study", "extended", "virtualization", "solutions", "to", "support", "rich", "and", "effective", "policies", "for", "active", "power", "management", ",", "which", "had", "not", "been", "done", "before", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "an early study", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "extended", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "study", "start": 9, "end": 14, "i_start": 2, "i_end": 2}, "action": {"text": "extended", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "solutions", "start": 39, "end": 48, "i_start": 5, "i_end": 5}, "action": {"text": "support", "start": 52, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "policies", "start": 79, "end": 87, "i_start": 11, "i_end": 11}, "action": {"text": "effective", "start": 69, "end": 78, "i_start": 10, "i_end": 10}}], "id": 25}, {"sent": "the needlets bispectrum , electronic journal of statistics , vol .", "tokens": ["the", "needlets", "bispectrum", ",", "electronic", "journal", "of", "statistics", ",", "vol", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 26}, {"sent": "spin needlets spectral estimation , electronic journal of statistics , vol .", "tokens": ["spin", "needlets", "spectral", "estimation", ",", "electronic", "journal", "of", "statistics", ",", "vol", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 26}, {"sent": "we will derive in this letter three families of exactly solvable models based on the pairing interaction for fermion systems as well as for boson systems .", "tokens": ["we", "will", "derive", "in", "this", "letter", "three", "families", "of", "exactly", "solvable", "models", "based", "on", "the", "pairing", "interaction", "for", "fermion", "systems", "as", "well", "as", "for", "boson", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will derive", "start": 3, "end": 14, "i_start": 1, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "derive", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}], "id": 27}, {"sent": "in summary , we have presented three families of new exactly solvable models based on the pairing interaction for fermion and boson systems .", "tokens": ["in", "summary", ",", "we", "have", "presented", "three", "families", "of", "new", "exactly", "solvable", "models", "based", "on", "the", "pairing", "interaction", "for", "fermion", "and", "boson", "systems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "verb": {"text": "have presented", "start": 16, "end": 30, "i_start": 4, "i_end": 5}}, {"character": {"text": "we", "start": 13, "end": 15, "i_start": 3, "i_end": 3}, "action": {"text": "presented", "start": 21, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "systems", "start": 132, "end": 139, "i_start": 22, "i_end": 22}, "action": {"text": "interaction", "start": 98, "end": 109, "i_start": 17, "i_end": 17}}], "id": 27}, {"sent": "we will now discuss the symmetry operators related to such spectral mirror symmetries .", "tokens": ["we", "will", "now", "discuss", "the", "symmetry", "operators", "related", "to", "such", "spectral", "mirror", "symmetries", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "discuss", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "discuss", "start": 12, "end": 19, "i_start": 3, "i_end": 3}}], "id": 28}, {"sent": "we will be interested in the two simplest correlation functions and their fourier transforms .", "tokens": ["we", "will", "be", "interested", "in", "the", "two", "simplest", "correlation", "functions", "and", "their", "fourier", "transforms", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "will be", "start": 3, "end": 10, "i_start": 1, "i_end": 2}}], "id": 28}, {"sent": "the magnetization bands increase with x .", "tokens": ["the", "magnetization", "bands", "increase", "with", "x", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the magnetization bands", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "increase", "start": 24, "end": 32, "i_start": 3, "i_end": 3}}, {"character": {"text": "bands", "start": 18, "end": 23, "i_start": 2, "i_end": 2}, "action": {"text": "magnetization", "start": 4, "end": 17, "i_start": 1, "i_end": 1}}], "id": 29}, {"sent": "the gap of the insulating phase strongly decreases with x .", "tokens": ["the", "gap", "of", "the", "insulating", "phase", "strongly", "decreases", "with", "x", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the gap of the insulating phase", "start": 0, "end": 31, "i_start": 0, "i_end": 5}, "verb": {"text": "decreases", "start": 41, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "phase", "start": 26, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "insulating", "start": 15, "end": 25, "i_start": 4, "i_end": 4}}], "id": 29}, {"sent": "since the diffusion coefficient is a well defined concept , this estimate might ultimately be compared to lattice qcd calculations , confirming or rejecting the paradigm of qgp formation in relativistic heavy ion collisions .", "tokens": ["since", "the", "diffusion", "coefficient", "is", "a", "well", "defined", "concept", ",", "this", "estimate", "might", "ultimately", "be", "compared", "to", "lattice", "qcd", "calculations", ",", "confirming", "or", "rejecting", "the", "paradigm", "of", "qgp", "formation", "in", "relativistic", "heavy", "ion", "collisions", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "this estimate", "start": 60, "end": 73, "i_start": 10, "i_end": 11}, "verb": {"text": "be compared", "start": 91, "end": 102, "i_start": 14, "i_end": 15}}, {"subject": {"text": "this estimate", "start": 60, "end": 73, "i_start": 10, "i_end": 11}, "verb": {"text": "might", "start": 74, "end": 79, "i_start": 12, "i_end": 12}}], "id": 30}, {"sent": "the diffusion coefficient in eq 9 is a tensor with symmetry about the local axis of the magnetization whereas in zlf the diffusion coefficient is a scalar .", "tokens": ["the", "diffusion", "coefficient", "in", "eq", "9", "is", "a", "tensor", "with", "symmetry", "about", "the", "local", "axis", "of", "the", "magnetization", "whereas", "in", "zlf", "the", "diffusion", "coefficient", "is", "a", "scalar", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the diffusion coefficient in eq 9", "start": 0, "end": 33, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 34, "end": 36, "i_start": 6, "i_end": 6}}, {"character": {"text": "tensor", "start": 39, "end": 45, "i_start": 8, "i_end": 8}, "action": {"text": "symmetry", "start": 51, "end": 59, "i_start": 10, "i_end": 10}}], "id": 30}, {"sent": "a closed-form expression for the probability of los is also provided in .", "tokens": ["a", "closed", "-", "form", "expression", "for", "the", "probability", "of", "los", "is", "also", "provided", "in", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "a closed-form expression for the probability of los", "start": 0, "end": 51, "i_start": 0, "i_end": 9}, "verb": {"text": "provided", "start": 60, "end": 68, "i_start": 12, "i_end": 12}}, {"subject": {"text": "a closed-form expression for the probability of los", "start": 0, "end": 51, "i_start": 0, "i_end": 9}, "verb": {"text": "is", "start": 52, "end": 54, "i_start": 10, "i_end": 10}}], "id": 31}, {"sent": "a closed form expression for the probability of los between drones and ues is developed in .", "tokens": ["a", "closed", "form", "expression", "for", "the", "probability", "of", "los", "between", "drones", "and", "ues", "is", "developed", "in", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "a closed form expression for the probability of los between drones and ues", "start": 0, "end": 74, "i_start": 0, "i_end": 12}, "verb": {"text": "is developed", "start": 75, "end": 87, "i_start": 13, "i_end": 14}}], "id": 31}, {"sent": "the most related in this line is where each user lies in an cluster that can be described by low-dimensional vector , with 2 separation across clusters .", "tokens": ["the", "most", "related", "in", "this", "line", "is", "where", "each", "user", "lies", "in", "an", "cluster", "that", "can", "be", "described", "by", "low", "-", "dimensional", "vector", ",", "with", "2", "separation", "across", "clusters", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most related in this line", "start": 0, "end": 29, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 6, "i_end": 6}}, {"subject": {"text": "each user", "start": 39, "end": 48, "i_start": 8, "i_end": 9}, "verb": {"text": "lies", "start": 49, "end": 53, "i_start": 10, "i_end": 10}}, {"character": {"text": "vector", "start": 109, "end": 115, "i_start": 22, "i_end": 22}, "action": {"text": "described", "start": 80, "end": 89, "i_start": 17, "i_end": 17}}], "id": 32}, {"sent": "the most related in this line is where each user lies in an cluster that can be described by a low-dimensional vector , with 2 separation across clusters .", "tokens": ["the", "most", "related", "in", "this", "line", "is", "where", "each", "user", "lies", "in", "an", "cluster", "that", "can", "be", "described", "by", "a", "low", "-", "dimensional", "vector", ",", "with", "2", "separation", "across", "clusters", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the most related in this line", "start": 0, "end": 29, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 6, "i_end": 6}}, {"subject": {"text": "each user", "start": 39, "end": 48, "i_start": 8, "i_end": 9}, "verb": {"text": "lies", "start": 49, "end": 53, "i_start": 10, "i_end": 10}}, {"character": {"text": "vector", "start": 111, "end": 117, "i_start": 23, "i_end": 23}, "action": {"text": "described", "start": 80, "end": 89, "i_start": 17, "i_end": 17}}], "id": 32}, {"sent": "we also show that the lp formulation of the smooth rectangle bound coincides with its natural definition as described above .", "tokens": ["we", "also", "show", "that", "the", "lp", "formulation", "of", "the", "smooth", "rectangle", "bound", "coincides", "with", "its", "natural", "definition", "as", "described", "above", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}], "id": 33}, {"sent": "we then proceed to show that our lower bound method subsumes all the other bounds mentioned above .", "tokens": ["we", "then", "proceed", "to", "show", "that", "our", "lower", "bound", "method", "subsumes", "all", "the", "other", "bounds", "mentioned", "above", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "proceed", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proceed", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "show", "start": 19, "end": 23, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "bound", "start": 39, "end": 44, "i_start": 8, "i_end": 8}}], "id": 33}, {"sent": "current schemes for classifying protein structure often rely on manually curated hierarchies such as that are not able to cleanly capture all possible variations .", "tokens": ["current", "schemes", "for", "classifying", "protein", "structure", "often", "rely", "on", "manually", "curated", "hierarchies", "such", "as", "that", "are", "not", "able", "to", "cleanly", "capture", "all", "possible", "variations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "current schemes for classifying protein structure", "start": 0, "end": 49, "i_start": 0, "i_end": 5}, "verb": {"text": "rely", "start": 56, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "schemes", "start": 8, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "rely", "start": 56, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "hierarchies", "start": 81, "end": 92, "i_start": 11, "i_end": 11}, "action": {"text": "capture", "start": 130, "end": 137, "i_start": 20, "i_end": 20}}], "id": 34}, {"sent": "current schemes for classifying protein structure often rely on manually curated hierarchies that are not able to cleanly capture all possible variations .", "tokens": ["current", "schemes", "for", "classifying", "protein", "structure", "often", "rely", "on", "manually", "curated", "hierarchies", "that", "are", "not", "able", "to", "cleanly", "capture", "all", "possible", "variations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "current schemes for classifying protein structure", "start": 0, "end": 49, "i_start": 0, "i_end": 5}, "verb": {"text": "rely", "start": 56, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "schemes", "start": 8, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "rely", "start": 56, "end": 60, "i_start": 7, "i_end": 7}}, {"character": {"text": "hierarchies", "start": 81, "end": 92, "i_start": 11, "i_end": 11}, "action": {"text": "capture", "start": 122, "end": 129, "i_start": 18, "i_end": 18}}], "id": 34}, {"sent": "we use the training set and test set of the bsds500 database for training , and its validation set for validation .", "tokens": ["we", "use", "the", "training", "set", "and", "test", "set", "of", "the", "bsds500", "database", "for", "training", ",", "and", "its", "validation", "set", "for", "validation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 35}, {"sent": "we use the training and validation portions of the bsds500 dataset as training images .", "tokens": ["we", "use", "the", "training", "and", "validation", "portions", "of", "the", "bsds500", "dataset", "as", "training", "images", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 35}, {"sent": "generalizations of these equations for arbitrary root systems were constructed by cherednik .", "tokens": ["generalizations", "of", "these", "equations", "for", "arbitrary", "root", "systems", "were", "constructed", "by", "cherednik", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "generalizations of these equations for arbitrary root systems", "start": 0, "end": 61, "i_start": 0, "i_end": 7}, "verb": {"text": "were constructed", "start": 62, "end": 78, "i_start": 8, "i_end": 9}}, {"character": {"text": "cherednik", "start": 82, "end": 91, "i_start": 11, "i_end": 11}, "action": {"text": "constructed", "start": 67, "end": 78, "i_start": 9, "i_end": 9}}], "id": 36}, {"sent": "the qkz equations for arbitrary root system were obtained by cherednik .", "tokens": ["the", "qkz", "equations", "for", "arbitrary", "root", "system", "were", "obtained", "by", "cherednik", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the qkz equations for arbitrary root system", "start": 0, "end": 43, "i_start": 0, "i_end": 6}, "verb": {"text": "were obtained", "start": 44, "end": 57, "i_start": 7, "i_end": 8}}, {"character": {"text": "cherednik", "start": 61, "end": 70, "i_start": 10, "i_end": 10}, "action": {"text": "obtained", "start": 49, "end": 57, "i_start": 8, "i_end": 8}}], "id": 36}, {"sent": "millimeter waves , for cellular communications , is among the most striking technological innovations brought by fifth generation wireless networks .", "tokens": ["millimeter", "waves", ",", "for", "cellular", "communications", ",", "is", "among", "the", "most", "striking", "technological", "innovations", "brought", "by", "fifth", "generation", "wireless", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "millimeter waves", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 49, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 139, "end": 147, "i_start": 19, "i_end": 19}, "action": {"text": "brought", "start": 102, "end": 109, "i_start": 14, "i_end": 14}}, {"character": {"text": "innovations", "start": 90, "end": 101, "i_start": 13, "i_end": 13}, "action": {"text": "striking", "start": 67, "end": 75, "i_start": 11, "i_end": 11}}], "id": 37}, {"sent": "millimeter waves , for cellular communications , is one of the main technological innovations brought by fifth generation wireless networks .", "tokens": ["millimeter", "waves", ",", "for", "cellular", "communications", ",", "is", "one", "of", "the", "main", "technological", "innovations", "brought", "by", "fifth", "generation", "wireless", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "millimeter waves", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 49, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 131, "end": 139, "i_start": 19, "i_end": 19}, "action": {"text": "brought", "start": 94, "end": 101, "i_start": 14, "i_end": 14}}], "id": 37}, {"sent": "a reaction with chemi- and physi- sorbed glycerol would account for the prompt and the slow hole decay , respectively .", "tokens": ["a", "reaction", "with", "chemi-", "and", "physi-", "sorbed", "glycerol", "would", "account", "for", "the", "prompt", "and", "the", "slow", "hole", "decay", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a reaction with chemi- and physi- sorbed glycerol", "start": 0, "end": 49, "i_start": 0, "i_end": 7}, "verb": {"text": "would account", "start": 50, "end": 63, "i_start": 8, "i_end": 9}}, {"character": {"text": "reaction", "start": 2, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "account", "start": 56, "end": 63, "i_start": 9, "i_end": 9}}], "id": 38}, {"sent": "a reaction with chemi- and physi- sorbed glycerol can account for the prompt and the slow hole decay , respectively .", "tokens": ["a", "reaction", "with", "chemi-", "and", "physi-", "sorbed", "glycerol", "can", "account", "for", "the", "prompt", "and", "the", "slow", "hole", "decay", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a reaction with chemi- and physi- sorbed glycerol", "start": 0, "end": 49, "i_start": 0, "i_end": 7}, "verb": {"text": "can account", "start": 50, "end": 61, "i_start": 8, "i_end": 9}}, {"character": {"text": "reaction", "start": 2, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "account", "start": 54, "end": 61, "i_start": 9, "i_end": 9}}], "id": 38}, {"sent": "during the outflow of liquid stream under the reposing liquid level .", "tokens": ["during", "the", "outflow", "of", "liquid", "stream", "under", "the", "reposing", "liquid", "level", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 39}, {"sent": "during the outflow of liquid stream to an atmosphere .", "tokens": ["during", "the", "outflow", "of", "liquid", "stream", "to", "an", "atmosphere", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 39}, {"sent": "now we define when are these na-quad rings , smarandache quad rings .", "tokens": ["now", "we", "define", "when", "are", "these", "na", "-", "quad", "rings", ",", "smarandache", "quad", "rings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "define", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}], "id": 40}, {"sent": "now we define smarandache mixed direct product of rings .", "tokens": ["now", "we", "define", "smarandache", "mixed", "direct", "product", "of", "rings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "verb": {"text": "define", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 4, "end": 6, "i_start": 1, "i_end": 1}, "action": {"text": "define", "start": 7, "end": 13, "i_start": 2, "i_end": 2}}], "id": 40}, {"sent": "to analyze the data and obtain the phase diagram , we use the bruce-wilding fss techniques outlined here .", "tokens": ["to", "analyze", "the", "data", "and", "obtain", "the", "phase", "diagram", ",", "we", "use", "the", "bruce", "-", "wilding", "fss", "techniques", "outlined", "here", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "verb": {"text": "use", "start": 54, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "use", "start": 54, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "analyze", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "obtain", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}], "id": 41}, {"sent": "to analyze the data and obtain the phase diagram , we use the bruce-wilding finite-size scaling techniques , to compile the phase diagram of this system .", "tokens": ["to", "analyze", "the", "data", "and", "obtain", "the", "phase", "diagram", ",", "we", "use", "the", "bruce", "-", "wilding", "finite", "-", "size", "scaling", "techniques", ",", "to", "compile", "the", "phase", "diagram", "of", "this", "system", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "verb": {"text": "use", "start": 54, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "use", "start": 54, "end": 57, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "compile", "start": 112, "end": 119, "i_start": 23, "i_end": 23}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "analyze", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 10, "i_end": 10}, "action": {"text": "obtain", "start": 24, "end": 30, "i_start": 5, "i_end": 5}}], "id": 41}, {"sent": "the momentum equation is discretised using the symmetric interior penalty method for the elliptic term and otherwise using the fluxes from cockburn et al .", "tokens": ["the", "momentum", "equation", "is", "discretised", "using", "the", "symmetric", "interior", "penalty", "method", "for", "the", "elliptic", "term", "and", "otherwise", "using", "the", "fluxes", "from", "cockburn", "et", "al", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "the momentum equation", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is discretised", "start": 22, "end": 36, "i_start": 3, "i_end": 4}}, {"subject": {"text": "the momentum equation", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "using", "start": 117, "end": 122, "i_start": 17, "i_end": 17}}], "id": 42}, {"sent": "the momentum equation is discretised using the sip method for the elliptic term and otherwise using the fluxes from cockburn et al .", "tokens": ["the", "momentum", "equation", "is", "discretised", "using", "the", "sip", "method", "for", "the", "elliptic", "term", "and", "otherwise", "using", "the", "fluxes", "from", "cockburn", "et", "al", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "the momentum equation", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "is discretised", "start": 22, "end": 36, "i_start": 3, "i_end": 4}}, {"subject": {"text": "the momentum equation", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "using", "start": 94, "end": 99, "i_start": 15, "i_end": 15}}], "id": 42}, {"sent": "spectrum sharing is a well-studied subject in general , for example in the context of cognitive radios .", "tokens": ["spectrum", "sharing", "is", "a", "well", "-", "studied", "subject", "in", "general", ",", "for", "example", "in", "the", "context", "of", "cognitive", "radios", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "spectrum sharing", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}], "id": 43}, {"sent": "note that the similar idea of spectrum cooperation can be found in the context of cognitive radio networks .", "tokens": ["note", "that", "the", "similar", "idea", "of", "spectrum", "cooperation", "can", "be", "found", "in", "the", "context", "of", "cognitive", "radio", "networks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the similar idea of spectrum cooperation", "start": 10, "end": 50, "i_start": 2, "i_end": 7}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "the similar idea of spectrum cooperation", "start": 10, "end": 50, "i_start": 2, "i_end": 7}, "verb": {"text": "found", "start": 58, "end": 63, "i_start": 10, "i_end": 10}}], "id": 43}, {"sent": "a combination of two different mechanisms yields , good quantitative and qualitative agreement between the experimentally derived and the simulated eley-rideal abstraction cross sections and surface configurations .", "tokens": ["a", "combination", "of", "two", "different", "mechanisms", "yields", ",", "good", "quantitative", "and", "qualitative", "agreement", "between", "the", "experimentally", "derived", "and", "the", "simulated", "eley", "-", "rideal", "abstraction", "cross", "sections", "and", "surface", "configurations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"character": {"text": "combination", "start": 2, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "yields", "start": 42, "end": 48, "i_start": 6, "i_end": 6}}], "id": 44}, {"sent": "good quantitative and qualitative agreement between the experimentally derived and the simulated eley-rideal abstraction cross sections are found if two different eley-rideal abstraction mechanisms are included .", "tokens": ["good", "quantitative", "and", "qualitative", "agreement", "between", "the", "experimentally", "derived", "and", "the", "simulated", "eley", "-", "rideal", "abstraction", "cross", "sections", "are", "found", "if", "two", "different", "eley", "-", "rideal", "abstraction", "mechanisms", "are", "included", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "good quantitative and qualitative agreement between the experimentally derived and the simulated eley-rideal abstraction cross sections", "start": 0, "end": 135, "i_start": 0, "i_end": 17}, "verb": {"text": "are found", "start": 136, "end": 145, "i_start": 18, "i_end": 19}}], "id": 44}, {"sent": "to our knowledge , all known problem-pairs with a zero duality gap , also known as strong duality , are polynomially solvable .", "tokens": ["to", "our", "knowledge", ",", "all", "known", "problem", "-", "pairs", "with", "a", "zero", "duality", "gap", ",", "also", "known", "as", "strong", "duality", ",", "are", "polynomially", "solvable", "."], "score": [0, 0, 1, 0, 1], "labels": [{"subject": {"text": "all known problem-pairs with a zero duality gap", "start": 19, "end": 66, "i_start": 4, "i_end": 13}, "verb": {"text": "are", "start": 100, "end": 103, "i_start": 21, "i_end": 21}}], "id": 45}, {"sent": "this remarkable relation is called the rank-size duality .", "tokens": ["this", "remarkable", "relation", "is", "called", "the", "rank", "-", "size", "duality", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this remarkable relation", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "is called", "start": 25, "end": 34, "i_start": 3, "i_end": 4}}], "id": 45}, {"sent": "the detector current decreases upon transition of the electron from the lower to the upper dot .", "tokens": ["the", "detector", "current", "decreases", "upon", "transition", "of", "the", "electron", "from", "the", "lower", "to", "the", "upper", "dot", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 46}, {"sent": "again , the detector current increases when the electron leaves the quantum dot .", "tokens": ["again", ",", "the", "detector", "current", "increases", "when", "the", "electron", "leaves", "the", "quantum", "dot", "."], "score": [0, 0, 0, 0, 0], "labels": [{"character": {"text": "electron", "start": 48, "end": 56, "i_start": 8, "i_end": 8}, "action": {"text": "leaves", "start": 57, "end": 63, "i_start": 9, "i_end": 9}}], "id": 46}, {"sent": "several studies for dnn-based image completion have presented demonstrations of face appearance manipulation by filling the parts of an input image with their dnns .", "tokens": ["several", "studies", "for", "dnn", "-", "based", "image", "completion", "have", "presented", "demonstrations", "of", "face", "appearance", "manipulation", "by", "filling", "the", "parts", "of", "an", "input", "image", "with", "their", "dnns", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "several studies for dnn-based image completion", "start": 0, "end": 46, "i_start": 0, "i_end": 7}, "verb": {"text": "have presented", "start": 47, "end": 61, "i_start": 8, "i_end": 9}}, {"character": {"text": "studies", "start": 8, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "demonstrations", "start": 62, "end": 76, "i_start": 10, "i_end": 10}}], "id": 47}, {"sent": "several studies for dnn-based image completion have presented demos of manipulating face appearances by filling the parts of an input image with the dnn .", "tokens": ["several", "studies", "for", "dnn", "-", "based", "image", "completion", "have", "presented", "demos", "of", "manipulating", "face", "appearances", "by", "filling", "the", "parts", "of", "an", "input", "image", "with", "the", "dnn", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "several studies for dnn-based image completion", "start": 0, "end": 46, "i_start": 0, "i_end": 7}, "verb": {"text": "have presented", "start": 47, "end": 61, "i_start": 8, "i_end": 9}}, {"character": {"text": "studies", "start": 8, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "presented", "start": 52, "end": 61, "i_start": 9, "i_end": 9}}], "id": 47}, {"sent": "this observation is somewhat surprising , since this is not the case for qeccs .", "tokens": ["this", "observation", "is", "somewhat", "surprising", ",", "since", "this", "is", "not", "the", "case", "for", "qeccs", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this observation", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 2, "i_end": 2}}, {"character": {"text": "observation", "start": 5, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "surprising", "start": 29, "end": 39, "i_start": 4, "i_end": 4}}], "id": 48}, {"sent": "this fact is quite surprising , since it is definitely not the case for qeccs .", "tokens": ["this", "fact", "is", "quite", "surprising", ",", "since", "it", "is", "definitely", "not", "the", "case", "for", "qeccs", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "this fact", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "fact", "start": 5, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "surprising", "start": 19, "end": 29, "i_start": 4, "i_end": 4}}], "id": 48}, {"sent": "this implies that r and the multiplication map are local homeomorphisms and that .", "tokens": ["this", "implies", "that", "r", "and", "the", "multiplication", "map", "are", "local", "homeomorphisms", "and", "that", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "implies", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 47, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "implies", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}], "id": 49}, {"sent": "this implies that r and the multiplication map are local homeomorphisms and that g is open in g .", "tokens": ["this", "implies", "that", "r", "and", "the", "multiplication", "map", "are", "local", "homeomorphisms", "and", "that", "g", "is", "open", "in", "g", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "implies", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}, {"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 47, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "implies", "start": 5, "end": 12, "i_start": 1, "i_end": 1}}], "id": 49}, {"sent": "we are able to solve the above problems for the case of probabilistic transformations too .", "tokens": ["we", "are", "able", "to", "solve", "the", "above", "problems", "for", "the", "case", "of", "probabilistic", "transformations", "too", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "are", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "solve", "start": 15, "end": 20, "i_start": 4, "i_end": 4}}], "id": 50}, {"sent": "our results can be generalized to probabilistic transformations .", "tokens": ["our", "results", "can", "be", "generalized", "to", "probabilistic", "transformations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our results", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "can be generalized", "start": 12, "end": 30, "i_start": 2, "i_end": 4}}], "id": 50}, {"sent": "in this section , we define non-commutative toric varieties and describe some of their most basic properties .", "tokens": ["in", "this", "section", ",", "we", "define", "non", "-", "commutative", "toric", "varieties", "and", "describe", "some", "of", "their", "most", "basic", "properties", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "define", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "describe", "start": 64, "end": 72, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "define", "start": 21, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "describe", "start": 64, "end": 72, "i_start": 12, "i_end": 12}}], "id": 51}, {"sent": "in this section , we will describe the aspects of the theory that we need most for the definition of non-commutative toric varieties .", "tokens": ["in", "this", "section", ",", "we", "will", "describe", "the", "aspects", "of", "the", "theory", "that", "we", "need", "most", "for", "the", "definition", "of", "non", "-", "commutative", "toric", "varieties", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "verb": {"text": "will describe", "start": 21, "end": 34, "i_start": 5, "i_end": 6}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "describe", "start": 26, "end": 34, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 4, "i_end": 4}, "action": {"text": "need", "start": 69, "end": 73, "i_start": 14, "i_end": 14}}], "id": 51}, {"sent": "a client that browses to a website through an or network will have their traffic relayed before it reaches its destination .", "tokens": ["a", "client", "that", "browses", "to", "a", "website", "through", "an", "or", "network", "will", "have", "their", "traffic", "relayed", "before", "it", "reaches", "its", "destination", "."], "score": [0, 1, 1, 1, 0], "labels": [{"subject": {"text": "a client that browses to a website through an or network", "start": 0, "end": 56, "i_start": 0, "i_end": 10}, "verb": {"text": "will have", "start": 57, "end": 66, "i_start": 11, "i_end": 12}}, {"subject": {"text": "their traffic", "start": 67, "end": 80, "i_start": 13, "i_end": 14}, "verb": {"text": "relayed", "start": 81, "end": 88, "i_start": 15, "i_end": 15}}, {"character": {"text": "client", "start": 2, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "browses", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "traffic", "start": 73, "end": 80, "i_start": 14, "i_end": 14}, "action": {"text": "reaches", "start": 99, "end": 106, "i_start": 18, "i_end": 18}}], "id": 52}, {"sent": "a client that browses to a website through an onion routing network will have their traffic relayed before it reaches its destination .", "tokens": ["a", "client", "that", "browses", "to", "a", "website", "through", "an", "onion", "routing", "network", "will", "have", "their", "traffic", "relayed", "before", "it", "reaches", "its", "destination", "."], "score": [0, 1, 1, 1, 0], "labels": [{"subject": {"text": "a client that browses to a website through an onion routing network", "start": 0, "end": 67, "i_start": 0, "i_end": 11}, "verb": {"text": "will have", "start": 68, "end": 77, "i_start": 12, "i_end": 13}}, {"subject": {"text": "their traffic", "start": 78, "end": 91, "i_start": 14, "i_end": 15}, "verb": {"text": "relayed", "start": 92, "end": 99, "i_start": 16, "i_end": 16}}, {"character": {"text": "client", "start": 2, "end": 8, "i_start": 1, "i_end": 1}, "action": {"text": "browses", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "network", "start": 60, "end": 67, "i_start": 11, "i_end": 11}, "action": {"text": "routing", "start": 52, "end": 59, "i_start": 10, "i_end": 10}}, {"character": {"text": "traffic", "start": 84, "end": 91, "i_start": 15, "i_end": 15}, "action": {"text": "reaches", "start": 110, "end": 117, "i_start": 19, "i_end": 19}}], "id": 52}, {"sent": "to obtain the branes of the corresponding open-string wzw orbifolds .", "tokens": ["to", "obtain", "the", "branes", "of", "the", "corresponding", "open", "-", "string", "wzw", "orbifolds", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 53}, {"sent": "to obtain the twisted kz systems of the corresponding open-string wzw orbifolds .", "tokens": ["to", "obtain", "the", "twisted", "kz", "systems", "of", "the", "corresponding", "open", "-", "string", "wzw", "orbifolds", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 53}, {"sent": "the change of sign of the effect with respect of the change \u03b4 \u03b4 and the substitution of neutrinos by antineutrinos is clearly visible .", "tokens": ["the", "change", "of", "sign", "of", "the", "effect", "with", "respect", "of", "the", "change", "\u03b4", "\u03b4", "and", "the", "substitution", "of", "neutrinos", "by", "antineutrinos", "is", "clearly", "visible", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the change of sign of the effect with respect of the change \u03b4 \u03b4 and the substitution of neutrinos by antineutrinos", "start": 0, "end": 114, "i_start": 0, "i_end": 20}, "verb": {"text": "is", "start": 115, "end": 117, "i_start": 21, "i_end": 21}}], "id": 54}, {"sent": "the change of sign of the effect with respect to the substitution of neutrinos by antineutrinos is clearly visible .", "tokens": ["the", "change", "of", "sign", "of", "the", "effect", "with", "respect", "to", "the", "substitution", "of", "neutrinos", "by", "antineutrinos", "is", "clearly", "visible", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the change of sign of the effect with respect to the substitution of neutrinos by antineutrinos", "start": 0, "end": 95, "i_start": 0, "i_end": 15}, "verb": {"text": "is", "start": 96, "end": 98, "i_start": 16, "i_end": 16}}], "id": 54}, {"sent": "although the time complexity of this problem is exponential in the size of the input , this does not deny the existence of a fast algorithm .", "tokens": ["although", "the", "time", "complexity", "of", "this", "problem", "is", "exponential", "in", "the", "size", "of", "the", "input", ",", "this", "does", "not", "deny", "the", "existence", "of", "a", "fast", "algorithm", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "this", "start": 87, "end": 91, "i_start": 16, "i_end": 16}, "verb": {"text": "does not deny", "start": 92, "end": 105, "i_start": 17, "i_end": 19}}, {"character": {"text": "exponential", "start": 48, "end": 59, "i_start": 8, "i_end": 8}, "action": {"text": "not deny", "start": 97, "end": 105, "i_start": 18, "i_end": 19}}], "id": 55}, {"sent": "it is obvious that the time complexity of this problem is exponential in the size of n , but this does not deny the existence of a fast algorithm .", "tokens": ["it", "is", "obvious", "that", "the", "time", "complexity", "of", "this", "problem", "is", "exponential", "in", "the", "size", "of", "n", ",", "but", "this", "does", "not", "deny", "the", "existence", "of", "a", "fast", "algorithm", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "this", "start": 93, "end": 97, "i_start": 19, "i_end": 19}, "verb": {"text": "is", "start": 55, "end": 57, "i_start": 10, "i_end": 10}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "deny", "start": 107, "end": 111, "i_start": 22, "i_end": 22}}], "id": 55}, {"sent": "we verify the safety of the control algorithm modeled as a hybrid program in model 2 , using a formal proof calculus for dl .", "tokens": ["we", "verify", "the", "safety", "of", "the", "control", "algorithm", "modeled", "as", "a", "hybrid", "program", "in", "model", "2", ",", "using", "a", "formal", "proof", "calculus", "for", "dl", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "verify", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "verify", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 87, "end": 92, "i_start": 17, "i_end": 17}}], "id": 56}, {"sent": "we verify the acceleration and orientation choices as modeled in model 1 above are safe , using a formal proof calculus for dl .", "tokens": ["we", "verify", "the", "acceleration", "and", "orientation", "choices", "as", "modeled", "in", "model", "1", "above", "are", "safe", ",", "using", "a", "formal", "proof", "calculus", "for", "dl", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "verify", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "verify", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "model 1", "start": 65, "end": 72, "i_start": 10, "i_end": 11}, "action": {"text": "modeled", "start": 54, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 90, "end": 95, "i_start": 16, "i_end": 16}}], "id": 56}, {"sent": "a u-net based encoder-decoder neural network was used for root segmentation .", "tokens": ["a", "u", "-", "net", "based", "encoder", "-", "decoder", "neural", "network", "was", "used", "for", "root", "segmentation", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "a u-net based encoder-decoder neural network", "start": 0, "end": 44, "i_start": 0, "i_end": 9}, "verb": {"text": "was used", "start": 45, "end": 53, "i_start": 10, "i_end": 11}}, {"character": {"text": "network", "start": 37, "end": 44, "i_start": 9, "i_end": 9}, "action": {"text": "decoder", "start": 22, "end": 29, "i_start": 7, "i_end": 7}}], "id": 57}, {"sent": "for the segmentation task , a 3d extension of the u-net architecture was employed .", "tokens": ["for", "the", "segmentation", "task", ",", "a", "3d", "extension", "of", "the", "u", "-", "net", "architecture", "was", "employed", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a 3d extension of the u-net architecture", "start": 28, "end": 68, "i_start": 5, "i_end": 13}, "verb": {"text": "was employed", "start": 69, "end": 81, "i_start": 14, "i_end": 15}}], "id": 57}, {"sent": "the nonflatness of the base metric for 3-charge microstate geometries was already noted in the particular solution of , and it had remained until now a largely unexplained phenomenon .", "tokens": ["the", "nonflatness", "of", "the", "base", "metric", "for", "3", "-", "charge", "microstate", "geometries", "was", "already", "noted", "in", "the", "particular", "solution", "of", ",", "and", "it", "had", "remained", "until", "now", "a", "largely", "unexplained", "phenomenon", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "it", "start": 124, "end": 126, "i_start": 22, "i_end": 22}, "verb": {"text": "noted", "start": 82, "end": 87, "i_start": 14, "i_end": 14}}, {"subject": {"text": "the nonflatness of the base metric for 3-charge microstate geometries", "start": 0, "end": 69, "i_start": 0, "i_end": 11}, "verb": {"text": "was", "start": 70, "end": 73, "i_start": 12, "i_end": 12}}, {"subject": {"text": "the nonflatness of the base metric for 3-charge microstate geometries", "start": 0, "end": 69, "i_start": 0, "i_end": 11}, "verb": {"text": "remained", "start": 131, "end": 139, "i_start": 24, "i_end": 24}}], "id": 58}, {"sent": "the non-flatness of the base metric for 3-charge microstate geometries was previously observed in the particular solution of , but had remained until now largely unexplained .", "tokens": ["the", "non", "-", "flatness", "of", "the", "base", "metric", "for", "3", "-", "charge", "microstate", "geometries", "was", "previously", "observed", "in", "the", "particular", "solution", "of", ",", "but", "had", "remained", "until", "now", "largely", "unexplained", "."], "score": [0, 0, 1, 0, 1], "labels": [{"subject": {"text": "the non-flatness of the base metric for 3-charge microstate geometries", "start": 0, "end": 70, "i_start": 0, "i_end": 13}, "verb": {"text": "observed", "start": 86, "end": 94, "i_start": 16, "i_end": 16}}, {"subject": {"text": "the non-flatness of the base metric for 3-charge microstate geometries", "start": 0, "end": 70, "i_start": 0, "i_end": 13}, "verb": {"text": "was", "start": 71, "end": 74, "i_start": 14, "i_end": 14}}, {"subject": {"text": "the non-flatness of the base metric for 3-charge microstate geometries", "start": 0, "end": 70, "i_start": 0, "i_end": 13}, "verb": {"text": "remained", "start": 135, "end": 143, "i_start": 25, "i_end": 25}}], "id": 58}, {"sent": "in this paper , we consider a uplink single-cell massive mimo system with m antennas at the bs and n single-antenna users .", "tokens": ["in", "this", "paper", ",", "we", "consider", "a", "uplink", "single", "-", "cell", "massive", "mimo", "system", "with", "m", "antennas", "at", "the", "bs", "and", "n", "single", "-", "antenna", "users", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "verb": {"text": "consider", "start": 19, "end": 27, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 4, "i_end": 4}, "action": {"text": "consider", "start": 19, "end": 27, "i_start": 5, "i_end": 5}}], "id": 59}, {"sent": "in , in this paper , we propose a multiple-input-multipleoutput sr backscatter system , where the transmitter , the receiver and the bd are equipped with multiple antennas .", "tokens": ["in", ",", "in", "this", "paper", ",", "we", "propose", "a", "multiple", "-", "input", "-", "multipleoutput", "sr", "backscatter", "system", ",", "where", "the", "transmitter", ",", "the", "receiver", "and", "the", "bd", "are", "equipped", "with", "multiple", "antennas", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 6, "i_end": 6}, "verb": {"text": "propose", "start": 24, "end": 31, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 6, "i_end": 6}, "action": {"text": "propose", "start": 24, "end": 31, "i_start": 7, "i_end": 7}}], "id": 59}, {"sent": "for the numerical experiments in this paper we implemented a new variant of the cross3d method -schur-cross3d which has better asymptotic complexity in r than the method described in .", "tokens": ["for", "the", "numerical", "experiments", "in", "this", "paper", "we", "implemented", "a", "new", "variant", "of", "the", "cross3d", "method", "-schur", "-", "cross3d", "which", "has", "better", "asymptotic", "complexity", "in", "r", "than", "the", "method", "described", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 44, "end": 46, "i_start": 7, "i_end": 7}, "verb": {"text": "implemented", "start": 47, "end": 58, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 44, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "implemented", "start": 47, "end": 58, "i_start": 8, "i_end": 8}}, {"character": {"text": "method", "start": 88, "end": 94, "i_start": 15, "i_end": 15}, "action": {"text": "has", "start": 116, "end": 119, "i_start": 20, "i_end": 20}}], "id": 60}, {"sent": "for the numerical experiments in this paper we implemented a new variant of the cross-3d method which has better asymptotic complexity in r than the method described in .", "tokens": ["for", "the", "numerical", "experiments", "in", "this", "paper", "we", "implemented", "a", "new", "variant", "of", "the", "cross-3d", "method", "which", "has", "better", "asymptotic", "complexity", "in", "r", "than", "the", "method", "described", "in", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 44, "end": 46, "i_start": 7, "i_end": 7}, "verb": {"text": "implemented", "start": 47, "end": 58, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 44, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "implemented", "start": 47, "end": 58, "i_start": 8, "i_end": 8}}, {"character": {"text": "method", "start": 89, "end": 95, "i_start": 15, "i_end": 15}, "action": {"text": "has", "start": 102, "end": 105, "i_start": 17, "i_end": 17}}], "id": 60}, {"sent": "flow chart showing the procedure for obtaining the pdf .", "tokens": ["flow", "chart", "showing", "the", "procedure", "for", "obtaining", "the", "pdf", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "flow chart", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "showing", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "chart", "start": 5, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "showing", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}], "id": 61}, {"sent": "flow chart showing the procedure for obtaining the second spectrum .", "tokens": ["flow", "chart", "showing", "the", "procedure", "for", "obtaining", "the", "second", "spectrum", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "flow chart", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "showing", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "chart", "start": 5, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "showing", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}], "id": 61}, {"sent": "more recently , the resource optimization in orthogonal frequency division multiplexing based single-user single-relay systems was considered in .", "tokens": ["more", "recently", ",", "the", "resource", "optimization", "in", "orthogonal", "frequency", "division", "multiplexing", "based", "single", "-", "user", "single", "-", "relay", "systems", "was", "considered", "in", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the resource optimization in orthogonal frequency division multiplexing based single-user single-relay systems", "start": 16, "end": 126, "i_start": 3, "i_end": 18}, "verb": {"text": "was considered", "start": 127, "end": 141, "i_start": 19, "i_end": 20}}], "id": 62}, {"sent": "the resource optimization in orthogonal frequency division multiplexing based single-user single-relay systems was considered in .", "tokens": ["the", "resource", "optimization", "in", "orthogonal", "frequency", "division", "multiplexing", "based", "single", "-", "user", "single", "-", "relay", "systems", "was", "considered", "in", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the resource optimization in orthogonal frequency division multiplexing based single-user single-relay systems", "start": 0, "end": 110, "i_start": 0, "i_end": 15}, "verb": {"text": "was considered", "start": 111, "end": 125, "i_start": 16, "i_end": 17}}], "id": 62}, {"sent": "the robustness of this method has been verified for calculating primordial spectra in k-inflation .", "tokens": ["the", "robustness", "of", "this", "method", "has", "been", "verified", "for", "calculating", "primordial", "spectra", "in", "k", "-", "inflation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the robustness of this method", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "has been verified", "start": 30, "end": 47, "i_start": 5, "i_end": 7}}], "id": 63}, {"sent": "the robustness of this method has been verified for calculating primordial spectra in k-inflation , .", "tokens": ["the", "robustness", "of", "this", "method", "has", "been", "verified", "for", "calculating", "primordial", "spectra", "in", "k", "-", "inflation", ",", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the robustness of this method", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "has been verified", "start": 30, "end": 47, "i_start": 5, "i_end": 7}}], "id": 63}, {"sent": "we calculate the critical temperatures and angular dependence of the order parameters .", "tokens": ["we", "calculate", "the", "critical", "temperatures", "and", "angular", "dependence", "of", "the", "order", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "calculate", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "calculate", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "parameters", "start": 75, "end": 85, "i_start": 11, "i_end": 11}, "action": {"text": "dependence", "start": 51, "end": 61, "i_start": 7, "i_end": 7}}], "id": 64}, {"sent": "we also calculate the critical temperatures and the angular dependence of order parameters .", "tokens": ["we", "also", "calculate", "the", "critical", "temperatures", "and", "the", "angular", "dependence", "of", "order", "parameters", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "calculate", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "calculate", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "parameters", "start": 80, "end": 90, "i_start": 12, "i_end": 12}, "action": {"text": "dependence", "start": 60, "end": 70, "i_start": 9, "i_end": 9}}], "id": 64}, {"sent": "the addition of salt is known to reduce the effective surface area per head group , leading to the stabilization of the cylindrical shape .", "tokens": ["the", "addition", "of", "salt", "is", "known", "to", "reduce", "the", "effective", "surface", "area", "per", "head", "group", ",", "leading", "to", "the", "stabilization", "of", "the", "cylindrical", "shape", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the addition of salt", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "is known", "start": 21, "end": 29, "i_start": 4, "i_end": 5}}, {"character": {"text": "reduce", "start": 33, "end": 39, "i_start": 7, "i_end": 7}, "action": {"text": "leading", "start": 84, "end": 91, "i_start": 16, "i_end": 16}}], "id": 65}, {"sent": "the addition of electrolyte to an aqueous solution of surfactant micelles is known empirically to preferentially stabilize the cylindrical shape .", "tokens": ["the", "addition", "of", "electrolyte", "to", "an", "aqueous", "solution", "of", "surfactant", "micelles", "is", "known", "empirically", "to", "preferentially", "stabilize", "the", "cylindrical", "shape", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the addition of electrolyte to an aqueous solution of surfactant micelles", "start": 0, "end": 73, "i_start": 0, "i_end": 10}, "verb": {"text": "is known", "start": 74, "end": 82, "i_start": 11, "i_end": 12}}], "id": 65}, {"sent": "yau , embedded minimal surfaces , exotic spheres , and mani folds with positie ricci curvature , ann .", "tokens": ["yau", ",", "embedded", "minimal", "surfaces", ",", "exotic", "spheres", ",", "and", "mani", "folds", "with", "positie", "ricci", "curvature", ",", "ann", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 66}, {"sent": "yau , existence of incompressible minimal surfaces and the topology of three-dimensional manifolds with non-negative scalar curvature , ann .", "tokens": ["yau", ",", "existence", "of", "incompressible", "minimal", "surfaces", "and", "the", "topology", "of", "three", "-", "dimensional", "manifolds", "with", "non", "-", "negative", "scalar", "curvature", ",", "ann", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 66}, {"sent": "furthermore , there is no obvious functoriality for the tame fundamental group .", "tokens": ["furthermore", ",", "there", "is", "no", "obvious", "functoriality", "for", "the", "tame", "fundamental", "group", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 14, "end": 19, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}], "id": 67}, {"sent": "with the obvious modifications , the same also holds for the tame fundamental group .", "tokens": ["with", "the", "obvious", "modifications", ",", "the", "same", "also", "holds", "for", "the", "tame", "fundamental", "group", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the same", "start": 33, "end": 41, "i_start": 5, "i_end": 6}, "verb": {"text": "holds", "start": 47, "end": 52, "i_start": 8, "i_end": 8}}], "id": 67}, {"sent": "regardless of the quality of multiclass pixel classifier output , the algorithms in do not distinguish between regions of one sub-structure from those of another at the superpixel level .", "tokens": ["regardless", "of", "the", "quality", "of", "multiclass", "pixel", "classifier", "output", ",", "the", "algorithms", "in", "do", "not", "distinguish", "between", "regions", "of", "one", "sub", "-", "structure", "from", "those", "of", "another", "at", "the", "superpixel", "level", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "the algorithms in", "start": 66, "end": 83, "i_start": 10, "i_end": 12}, "verb": {"text": "do not distinguish", "start": 84, "end": 102, "i_start": 13, "i_end": 15}}, {"character": {"text": "algorithms", "start": 70, "end": 80, "i_start": 11, "i_end": 11}, "action": {"text": "not distinguish", "start": 87, "end": 102, "i_start": 14, "i_end": 15}}], "id": 68}, {"sent": "regardless of the quality of the multiclass pixel classifier , the algorithms in do not distinguish between regions of one sub-structure to those of another in the superpixel level .", "tokens": ["regardless", "of", "the", "quality", "of", "the", "multiclass", "pixel", "classifier", ",", "the", "algorithms", "in", "do", "not", "distinguish", "between", "regions", "of", "one", "sub", "-", "structure", "to", "those", "of", "another", "in", "the", "superpixel", "level", "."], "score": [0, 0, 0, 0, 0], "labels": [{"character": {"text": "algorithms", "start": 67, "end": 77, "i_start": 11, "i_end": 11}, "action": {"text": "not distinguish", "start": 84, "end": 99, "i_start": 14, "i_end": 15}}], "id": 68}, {"sent": "we start with the definition of a cluster algebra a .", "tokens": ["we", "start", "with", "the", "definition", "of", "a", "cluster", "algebra", "a", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "start", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "start", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 69}, {"sent": "we start by reformulating the definition of a cluster algebra a .", "tokens": ["we", "start", "by", "reformulating", "the", "definition", "of", "a", "cluster", "algebra", "a", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "start", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "start", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "reformulating", "start": 12, "end": 25, "i_start": 3, "i_end": 3}}], "id": 69}, {"sent": "in this section we discuss the relationship between our approach and the effective field theory of large scale structure approach of .", "tokens": ["in", "this", "section", "we", "discuss", "the", "relationship", "between", "our", "approach", "and", "the", "effective", "field", "theory", "of", "large", "scale", "structure", "approach", "of", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "verb": {"text": "discuss", "start": 19, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "discuss", "start": 19, "end": 26, "i_start": 4, "i_end": 4}}, {"character": {"text": "approach", "start": 56, "end": 64, "i_start": 9, "i_end": 9}, "action": {"text": "relationship", "start": 31, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 16, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "approach", "start": 56, "end": 64, "i_start": 9, "i_end": 9}}, {"character": {"text": "theory", "start": 89, "end": 95, "i_start": 14, "i_end": 14}, "action": {"text": "effective", "start": 73, "end": 82, "i_start": 12, "i_end": 12}}], "id": 70}, {"sent": "as a warm-up , in this subsection we briefly review the construction of the effective fluid equations for dark matter , .", "tokens": ["as", "a", "warm", "-", "up", ",", "in", "this", "subsection", "we", "briefly", "review", "the", "construction", "of", "the", "effective", "fluid", "equations", "for", "dark", "matter", ",", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 34, "end": 36, "i_start": 9, "i_end": 9}, "verb": {"text": "review", "start": 45, "end": 51, "i_start": 11, "i_end": 11}}, {"character": {"text": "we", "start": 34, "end": 36, "i_start": 9, "i_end": 9}, "action": {"text": "review", "start": 45, "end": 51, "i_start": 11, "i_end": 11}}, {"character": {"text": "equations", "start": 92, "end": 101, "i_start": 18, "i_end": 18}, "action": {"text": "effective", "start": 76, "end": 85, "i_start": 16, "i_end": 16}}], "id": 70}, {"sent": "for outdoor links we assume the itu-r model for line-of-sight propagation within street canyons and the itu-r non-line-of-sight model for over roof-top propagation .", "tokens": ["for", "outdoor", "links", "we", "assume", "the", "itu", "-", "r", "model", "for", "line", "-", "of", "-", "sight", "propagation", "within", "street", "canyons", "and", "the", "itu", "-", "r", "non", "-", "line", "-", "of", "-", "sight", "model", "for", "over", "roof", "-", "top", "propagation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 18, "end": 20, "i_start": 3, "i_end": 3}, "verb": {"text": "assume", "start": 21, "end": 27, "i_start": 4, "i_end": 4}}, {"character": {"text": "we", "start": 18, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "assume", "start": 21, "end": 27, "i_start": 4, "i_end": 4}}], "id": 71}, {"sent": "for the outdoor links we consider the itu-r model for line-of-sight propagation within street canyons and the non-line-of-sight model for over roof-top propagation .", "tokens": ["for", "the", "outdoor", "links", "we", "consider", "the", "itu", "-", "r", "model", "for", "line", "-", "of", "-", "sight", "propagation", "within", "street", "canyons", "and", "the", "non", "-", "line", "-", "of", "-", "sight", "model", "for", "over", "roof", "-", "top", "propagation", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 22, "end": 24, "i_start": 4, "i_end": 4}, "verb": {"text": "consider", "start": 25, "end": 33, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "consider", "start": 25, "end": 33, "i_start": 5, "i_end": 5}}], "id": 71}, {"sent": "similar improved thresholds were achieved in , where the concept of spatial coupling was applied to csa .", "tokens": ["similar", "improved", "thresholds", "were", "achieved", "in", ",", "where", "the", "concept", "of", "spatial", "coupling", "was", "applied", "to", "csa", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "similar improved thresholds", "start": 0, "end": 27, "i_start": 0, "i_end": 2}, "verb": {"text": "were achieved", "start": 28, "end": 41, "i_start": 3, "i_end": 4}}], "id": 72}, {"sent": "spatially-coupled csa has been investigated in , where similar improvement of the iterative decoding threshold was observed .", "tokens": ["spatially", "-", "coupled", "csa", "has", "been", "investigated", "in", ",", "where", "similar", "improvement", "of", "the", "iterative", "decoding", "threshold", "was", "observed", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "spatially-coupled csa", "start": 0, "end": 21, "i_start": 0, "i_end": 3}, "verb": {"text": "has been investigated", "start": 22, "end": 43, "i_start": 4, "i_end": 6}}], "id": 72}, {"sent": "given a bspp , several first-order methods with attractive convergence properties have been introduced .", "tokens": ["given", "a", "bspp", ",", "several", "first", "-", "order", "methods", "with", "attractive", "convergence", "properties", "have", "been", "introduced", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "several first-order methods with attractive convergence properties", "start": 15, "end": 81, "i_start": 4, "i_end": 12}, "verb": {"text": "have been introduced", "start": 82, "end": 102, "i_start": 13, "i_end": 15}}, {"character": {"text": "methods", "start": 35, "end": 42, "i_start": 8, "i_end": 8}, "action": {"text": "attractive", "start": 48, "end": 58, "i_start": 10, "i_end": 10}}], "id": 73}, {"sent": "several first-order methods with attractive convergence properties have been introduced for bspps .", "tokens": ["several", "first", "-", "order", "methods", "with", "attractive", "convergence", "properties", "have", "been", "introduced", "for", "bspps", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "several first-order methods with attractive convergence properties", "start": 0, "end": 66, "i_start": 0, "i_end": 8}, "verb": {"text": "have been introduced", "start": 67, "end": 87, "i_start": 9, "i_end": 11}}, {"character": {"text": "methods", "start": 20, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "attractive", "start": 33, "end": 43, "i_start": 6, "i_end": 6}}, {"character": {"text": "methods", "start": 20, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "have", "start": 67, "end": 71, "i_start": 9, "i_end": 9}}], "id": 73}, {"sent": "the vertical axis is time , the horizontal one is physical distance .", "tokens": ["the", "vertical", "axis", "is", "time", ",", "the", "horizontal", "one", "is", "physical", "distance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the horizontal one", "start": 28, "end": 46, "i_start": 6, "i_end": 8}, "verb": {"text": "is", "start": 47, "end": 49, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the horizontal one", "start": 28, "end": 46, "i_start": 6, "i_end": 8}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}], "id": 74}, {"sent": "the vertical axis is time , the horizontal axis indicates physical length .", "tokens": ["the", "vertical", "axis", "is", "time", ",", "the", "horizontal", "axis", "indicates", "physical", "length", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the horizontal axis", "start": 28, "end": 47, "i_start": 6, "i_end": 8}, "verb": {"text": "indicates", "start": 48, "end": 57, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the horizontal axis", "start": 28, "end": 47, "i_start": 6, "i_end": 8}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "axis", "start": 43, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "indicates", "start": 48, "end": 57, "i_start": 9, "i_end": 9}}], "id": 74}, {"sent": "however , there exist control systems which are small-time locally controllable from x 0 , but one can not check their smalltime local controllability using classical control variations constructed by the iterated family of lie brackets .", "tokens": ["however", ",", "there", "exist", "control", "systems", "which", "are", "small", "-", "time", "locally", "controllable", "from", "x", "0", ",", "but", "one", "can", "not", "check", "their", "smalltime", "local", "controllability", "using", "classical", "control", "variations", "constructed", "by", "the", "iterated", "family", "of", "lie", "brackets", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "there", "start": 10, "end": 15, "i_start": 2, "i_end": 2}, "verb": {"text": "exist", "start": 16, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "one", "start": 95, "end": 98, "i_start": 18, "i_end": 18}, "verb": {"text": "check", "start": 107, "end": 112, "i_start": 21, "i_end": 21}}, {"character": {"text": "one", "start": 95, "end": 98, "i_start": 18, "i_end": 18}, "action": {"text": "check", "start": 107, "end": 112, "i_start": 21, "i_end": 21}}, {"character": {"text": "family", "start": 214, "end": 220, "i_start": 34, "i_end": 34}, "action": {"text": "constructed", "start": 186, "end": 197, "i_start": 30, "i_end": 30}}], "id": 75}, {"sent": "by constructing appropriate control variations and using a suitable open mapping theorem , one can show that a control system is small-time locally controllable .", "tokens": ["by", "constructing", "appropriate", "control", "variations", "and", "using", "a", "suitable", "open", "mapping", "theorem", ",", "one", "can", "show", "that", "a", "control", "system", "is", "small", "-", "time", "locally", "controllable", "."], "score": [0, 0, 0, 1, 1], "labels": [{"subject": {"text": "one", "start": 91, "end": 94, "i_start": 13, "i_end": 13}, "verb": {"text": "can show", "start": 95, "end": 103, "i_start": 14, "i_end": 15}}, {"subject": {"text": "one", "start": 91, "end": 94, "i_start": 13, "i_end": 13}, "verb": {"text": "is", "start": 126, "end": 128, "i_start": 20, "i_end": 20}}, {"character": {"text": "one", "start": 91, "end": 94, "i_start": 13, "i_end": 13}, "action": {"text": "show", "start": 99, "end": 103, "i_start": 15, "i_end": 15}}, {"character": {"text": "system", "start": 119, "end": 125, "i_start": 19, "i_end": 19}, "action": {"text": "control", "start": 111, "end": 118, "i_start": 18, "i_end": 18}}], "id": 75}, {"sent": "the lattice boltzmann algorithm has proven to be an extremely interesting method for the solution of navier-stokes flows because of its simplicity , extreme parallelizability and accuracy .", "tokens": ["the", "lattice", "boltzmann", "algorithm", "has", "proven", "to", "be", "an", "extremely", "interesting", "method", "for", "the", "solution", "of", "navier", "-", "stokes", "flows", "because", "of", "its", "simplicity", ",", "extreme", "parallelizability", "and", "accuracy", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the lattice boltzmann algorithm", "start": 0, "end": 31, "i_start": 0, "i_end": 3}, "verb": {"text": "has proven", "start": 32, "end": 42, "i_start": 4, "i_end": 5}}], "id": 76}, {"sent": "the lbm is a local mesoscopic algorithm , allowing for efficient parallel implementations , and has demonstrated itself as a powerful tool for numerical simulations of fluid flows .", "tokens": ["the", "lbm", "is", "a", "local", "mesoscopic", "algorithm", ",", "allowing", "for", "efficient", "parallel", "implementations", ",", "and", "has", "demonstrated", "itself", "as", "a", "powerful", "tool", "for", "numerical", "simulations", "of", "fluid", "flows", "."], "score": [1, 1, 0, 0, 1], "labels": [{"subject": {"text": "the lbm", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the lbm", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "demonstrated", "start": 100, "end": 112, "i_start": 16, "i_end": 16}}, {"character": {"text": "algorithm", "start": 30, "end": 39, "i_start": 6, "i_end": 6}, "action": {"text": "allowing", "start": 42, "end": 50, "i_start": 8, "i_end": 8}}], "id": 76}, {"sent": "using the classical three-field notation in scheduling , the problem can be denoted as p , r j , d j , t , .", "tokens": ["using", "the", "classical", "three", "-", "field", "notation", "in", "scheduling", ",", "the", "problem", "can", "be", "denoted", "as", "p", ",", "r", "j", ",", "d", "j", ",", "t", ",", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the problem", "start": 57, "end": 68, "i_start": 10, "i_end": 11}, "verb": {"text": "can be denoted", "start": 69, "end": 83, "i_start": 12, "i_end": 14}}], "id": 77}, {"sent": "in the three-field scheduling notation , this problem is denoted as 1 , pmtn , w j c j .", "tokens": ["in", "the", "three", "-", "field", "scheduling", "notation", ",", "this", "problem", "is", "denoted", "as", "1", ",", "pmtn", ",", "w", "j", "c", "j", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this problem", "start": 41, "end": 53, "i_start": 8, "i_end": 9}, "verb": {"text": "is denoted", "start": 54, "end": 64, "i_start": 10, "i_end": 11}}], "id": 77}, {"sent": "we have also quantitatively discussed how inappropriate it is to use the original distribution instead of the escort distribution in nonextensive statistical mechanics .", "tokens": ["we", "have", "also", "quantitatively", "discussed", "how", "inappropriate", "it", "is", "to", "use", "the", "original", "distribution", "instead", "of", "the", "escort", "distribution", "in", "nonextensive", "statistical", "mechanics", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "discussed", "start": 28, "end": 37, "i_start": 4, "i_end": 4}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "have", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 59, "end": 61, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "discussed", "start": 28, "end": 37, "i_start": 4, "i_end": 4}}], "id": 78}, {"sent": "it is also quantitatively discussed how inappropriate it is to use the original distribution instead of the escort distribution for calculating the expectation values of physical quantities in nonextensive statistical mechanics .", "tokens": ["it", "is", "also", "quantitatively", "discussed", "how", "inappropriate", "it", "is", "to", "use", "the", "original", "distribution", "instead", "of", "the", "escort", "distribution", "for", "calculating", "the", "expectation", "values", "of", "physical", "quantities", "in", "nonextensive", "statistical", "mechanics", "."], "score": [0, 0, 0, 0, 1], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "discussed", "start": 26, "end": 35, "i_start": 4, "i_end": 4}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 57, "end": 59, "i_start": 8, "i_end": 8}}], "id": 78}, {"sent": "measures in the space of density matrices a .", "tokens": ["measures", "in", "the", "space", "of", "density", "matrices", "a", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 79}, {"sent": "measures induced by partial tracing of composite systems a .", "tokens": ["measures", "induced", "by", "partial", "tracing", "of", "composite", "systems", "a", "."], "score": [0, 0, 0, 0, 0], "labels": [{"character": {"text": "tracing", "start": 28, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "induced", "start": 9, "end": 16, "i_start": 1, "i_end": 1}}], "id": 79}, {"sent": "the supersymmetry transformations are not modified by the moyal product since they are linear in the fields .", "tokens": ["the", "supersymmetry", "transformations", "are", "not", "modified", "by", "the", "moyal", "product", "since", "they", "are", "linear", "in", "the", "fields", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the supersymmetry transformations", "start": 0, "end": 33, "i_start": 0, "i_end": 2}, "verb": {"text": "are not modified", "start": 34, "end": 50, "i_start": 3, "i_end": 5}}, {"character": {"text": "product", "start": 64, "end": 71, "i_start": 9, "i_end": 9}, "action": {"text": "not modified", "start": 38, "end": 50, "i_start": 4, "i_end": 5}}], "id": 80}, {"sent": "also , the supersymmetry transformations are not modified by noncommutativity since they are linear and no moyal products are required .", "tokens": ["also", ",", "the", "supersymmetry", "transformations", "are", "not", "modified", "by", "noncommutativity", "since", "they", "are", "linear", "and", "no", "moyal", "products", "are", "required", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the supersymmetry transformations", "start": 7, "end": 40, "i_start": 2, "i_end": 4}, "verb": {"text": "are not modified", "start": 41, "end": 57, "i_start": 5, "i_end": 7}}, {"character": {"text": "noncommutativity", "start": 61, "end": 77, "i_start": 9, "i_end": 9}, "action": {"text": "not modified", "start": 45, "end": 57, "i_start": 6, "i_end": 7}}], "id": 80}, {"sent": "we use the official split of data , where 249 scenes are used for training and we sample 50k images out of the training set with the same manner as .", "tokens": ["we", "use", "the", "official", "split", "of", "data", ",", "where", "249", "scenes", "are", "used", "for", "training", "and", "we", "sample", "50k", "images", "out", "of", "the", "training", "set", "with", "the", "same", "manner", "as", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 79, "end": 81, "i_start": 16, "i_end": 16}, "verb": {"text": "sample", "start": 82, "end": 88, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "sample", "start": 82, "end": 88, "i_start": 17, "i_end": 17}}], "id": 81}, {"sent": "we use the official split of data , where 249 scenes are used for training and we sample 50k images out of the training similar to .", "tokens": ["we", "use", "the", "official", "split", "of", "data", ",", "where", "249", "scenes", "are", "used", "for", "training", "and", "we", "sample", "50k", "images", "out", "of", "the", "training", "similar", "to", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 79, "end": 81, "i_start": 16, "i_end": 16}, "verb": {"text": "sample", "start": 82, "end": 88, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "sample", "start": 82, "end": 88, "i_start": 17, "i_end": 17}}], "id": 81}, {"sent": "this completes the proof that a is a derivation relative to \u03c3m .", "tokens": ["this", "completes", "the", "proof", "that", "a", "is", "a", "derivation", "relative", "to", "\u03c3m", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "completes", "start": 5, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "completes", "start": 5, "end": 14, "i_start": 1, "i_end": 1}}], "id": 82}, {"sent": "this completes the proof that is a reflecting that ( brownian motion with constant drift on d .", "tokens": ["this", "completes", "the", "proof", "that", "is", "a", "reflecting", "that", "(", "brownian", "motion", "with", "constant", "drift", "on", "d", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "completes", "start": 5, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "completes", "start": 5, "end": 14, "i_start": 1, "i_end": 1}}], "id": 82}, {"sent": "the systematic study of truncated toeplitz operators was initiated by sarason .", "tokens": ["the", "systematic", "study", "of", "truncated", "toeplitz", "operators", "was", "initiated", "by", "sarason", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the systematic study of truncated toeplitz operators", "start": 0, "end": 52, "i_start": 0, "i_end": 6}, "verb": {"text": "was initiated", "start": 53, "end": 66, "i_start": 7, "i_end": 8}}, {"character": {"text": "sarason", "start": 70, "end": 77, "i_start": 10, "i_end": 10}, "action": {"text": "initiated", "start": 57, "end": 66, "i_start": 8, "i_end": 8}}], "id": 83}, {"sent": "the study of truncated toeplitz operators has been largely motivated by a seminal paper of sarason .", "tokens": ["the", "study", "of", "truncated", "toeplitz", "operators", "has", "been", "largely", "motivated", "by", "a", "seminal", "paper", "of", "sarason", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the study of truncated toeplitz operators", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "motivated", "start": 59, "end": 68, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the study of truncated toeplitz operators", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "has been", "start": 42, "end": 50, "i_start": 6, "i_end": 7}}, {"character": {"text": "paper", "start": 82, "end": 87, "i_start": 13, "i_end": 13}, "action": {"text": "motivated", "start": 59, "end": 68, "i_start": 9, "i_end": 9}}], "id": 83}, {"sent": "the minimum of this potential corresponds to the monopole condensate .", "tokens": ["the", "minimum", "of", "this", "potential", "corresponds", "to", "the", "monopole", "condensate", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the minimum of this potential", "start": 0, "end": 29, "i_start": 0, "i_end": 4}, "verb": {"text": "corresponds", "start": 30, "end": 41, "i_start": 5, "i_end": 5}}], "id": 84}, {"sent": "the value of the monopole condensate is defined by the minimum of the effective potential .", "tokens": ["the", "value", "of", "the", "monopole", "condensate", "is", "defined", "by", "the", "minimum", "of", "the", "effective", "potential", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the value of the monopole condensate", "start": 0, "end": 36, "i_start": 0, "i_end": 5}, "verb": {"text": "is defined", "start": 37, "end": 47, "i_start": 6, "i_end": 7}}], "id": 84}, {"sent": "the type iib matrix model was proposed as a possible nonperturbative formulation of superstring theory in 1996 .", "tokens": ["the", "type", "iib", "matrix", "model", "was", "proposed", "as", "a", "possible", "nonperturbative", "formulation", "of", "superstring", "theory", "in", "1996", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the type iib matrix model", "start": 0, "end": 25, "i_start": 0, "i_end": 4}, "verb": {"text": "was proposed", "start": 26, "end": 38, "i_start": 5, "i_end": 6}}], "id": 85}, {"sent": "the iib matrix model was proposed as a non-perturbative formulation of type iib superstring theory .", "tokens": ["the", "iib", "matrix", "model", "was", "proposed", "as", "a", "non", "-", "perturbative", "formulation", "of", "type", "iib", "superstring", "theory", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the iib matrix model", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "was proposed", "start": 21, "end": 33, "i_start": 4, "i_end": 5}}], "id": 85}, {"sent": "the ability to detect small alterations in brain tissue is a key factor when developing biomarkers for early stages of neurodegenerative diseases .", "tokens": ["the", "ability", "to", "detect", "small", "alterations", "in", "brain", "tissue", "is", "a", "key", "factor", "when", "developing", "biomarkers", "for", "early", "stages", "of", "neurodegenerative", "diseases", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the ability to detect small alterations in brain tissue", "start": 0, "end": 55, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 56, "end": 58, "i_start": 9, "i_end": 9}}], "id": 86}, {"sent": "the ability to detect small alterations in brain tissue is a key factor when developing biomarkers for early stages in neurodegeneration .", "tokens": ["the", "ability", "to", "detect", "small", "alterations", "in", "brain", "tissue", "is", "a", "key", "factor", "when", "developing", "biomarkers", "for", "early", "stages", "in", "neurodegeneration", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the ability to detect small alterations in brain tissue", "start": 0, "end": 55, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 56, "end": 58, "i_start": 9, "i_end": 9}}], "id": 86}, {"sent": "according to the usual notion of consensus , the network nodes should converge , asymptotically or in a finite time , to an equilibrium point where all the nodes have the same value lying somewhere between the minimum and maximum of their initial values .", "tokens": ["according", "to", "the", "usual", "notion", "of", "consensus", ",", "the", "network", "nodes", "should", "converge", ",", "asymptotically", "or", "in", "a", "finite", "time", ",", "to", "an", "equilibrium", "point", "where", "all", "the", "nodes", "have", "the", "same", "value", "lying", "somewhere", "between", "the", "minimum", "and", "maximum", "of", "their", "initial", "values", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the network nodes", "start": 45, "end": 62, "i_start": 8, "i_end": 10}, "verb": {"text": "should converge", "start": 63, "end": 78, "i_start": 11, "i_end": 12}}], "id": 87}, {"sent": "according to the usual notion of consensus , the network nodes should converge to an equilibrium point where all the nodes have the same value lying somewhere between the minimum and maximum of their initial values .", "tokens": ["according", "to", "the", "usual", "notion", "of", "consensus", ",", "the", "network", "nodes", "should", "converge", "to", "an", "equilibrium", "point", "where", "all", "the", "nodes", "have", "the", "same", "value", "lying", "somewhere", "between", "the", "minimum", "and", "maximum", "of", "their", "initial", "values", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the network nodes", "start": 45, "end": 62, "i_start": 8, "i_end": 10}, "verb": {"text": "should converge", "start": 63, "end": 78, "i_start": 11, "i_end": 12}}], "id": 87}, {"sent": "in the open phase , a sends the procedure for revealing the hidden commitment at time t 3 and b use this .", "tokens": ["in", "the", "open", "phase", ",", "a", "sends", "the", "procedure", "for", "revealing", "the", "hidden", "commitment", "at", "time", "t", "3", "and", "b", "use", "this", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "a", "start": 20, "end": 21, "i_start": 5, "i_end": 5}, "verb": {"text": "sends", "start": 22, "end": 27, "i_start": 6, "i_end": 6}}], "id": 88}, {"sent": "in the open phase , a sends the procedure for revealing the hidden commitment at time t 3 , and b uses this .", "tokens": ["in", "the", "open", "phase", ",", "a", "sends", "the", "procedure", "for", "revealing", "the", "hidden", "commitment", "at", "time", "t", "3", ",", "and", "b", "uses", "this", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "a", "start": 20, "end": 21, "i_start": 5, "i_end": 5}, "verb": {"text": "sends", "start": 22, "end": 27, "i_start": 6, "i_end": 6}}, {"subject": {"text": "b", "start": 96, "end": 97, "i_start": 20, "i_end": 20}, "verb": {"text": "uses", "start": 98, "end": 102, "i_start": 21, "i_end": 21}}], "id": 88}, {"sent": "floating-point arithmetics has became wide spread in many applications such as 3d graphics , scientific computing and signal processing .", "tokens": ["floating", "-", "point", "arithmetics", "has", "became", "wide", "spread", "in", "many", "applications", "such", "as", "3d", "graphics", ",", "scientific", "computing", "and", "signal", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "floating-point arithmetics", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "has became", "start": 27, "end": 37, "i_start": 4, "i_end": 5}}], "id": 89}, {"sent": "floating-point arithmetic has became widely used in many applications such as 3d graphics , scientific computing and signal processing .", "tokens": ["floating", "-", "point", "arithmetic", "has", "became", "widely", "used", "in", "many", "applications", "such", "as", "3d", "graphics", ",", "scientific", "computing", "and", "signal", "processing", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "floating-point arithmetic", "start": 0, "end": 25, "i_start": 0, "i_end": 3}, "verb": {"text": "has became", "start": 26, "end": 36, "i_start": 4, "i_end": 5}}], "id": 89}, {"sent": "however , in these strayfield-coupled multilayers , the large dipolar fields can dominate the dmi and stabilise skyrmions with hybrid chiralities across the film thickness .", "tokens": ["however", ",", "in", "these", "strayfield", "-", "coupled", "multilayers", ",", "the", "large", "dipolar", "fields", "can", "dominate", "the", "dmi", "and", "stabilise", "skyrmions", "with", "hybrid", "chiralities", "across", "the", "film", "thickness", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the large dipolar fields", "start": 52, "end": 76, "i_start": 9, "i_end": 12}, "verb": {"text": "can dominate", "start": 77, "end": 89, "i_start": 13, "i_end": 14}}, {"character": {"text": "fields", "start": 70, "end": 76, "i_start": 12, "i_end": 12}, "action": {"text": "dominate", "start": 81, "end": 89, "i_start": 14, "i_end": 14}}, {"character": {"text": "fields", "start": 70, "end": 76, "i_start": 12, "i_end": 12}, "action": {"text": "stabilise", "start": 102, "end": 111, "i_start": 18, "i_end": 18}}], "id": 90}, {"sent": "however , in these stray-field-coupled multilayers , the large dipolar fields can outweigh the dmi and stabilise twisted spin structures with a non-uniform chirality across the film thickness .", "tokens": ["however", ",", "in", "these", "stray", "-", "field", "-", "coupled", "multilayers", ",", "the", "large", "dipolar", "fields", "can", "outweigh", "the", "dmi", "and", "stabilise", "twisted", "spin", "structures", "with", "a", "non", "-", "uniform", "chirality", "across", "the", "film", "thickness", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the large dipolar fields", "start": 53, "end": 77, "i_start": 11, "i_end": 14}, "verb": {"text": "can outweigh", "start": 78, "end": 90, "i_start": 15, "i_end": 16}}, {"character": {"text": "field", "start": 25, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "outweigh", "start": 82, "end": 90, "i_start": 16, "i_end": 16}}, {"character": {"text": "field", "start": 25, "end": 30, "i_start": 6, "i_end": 6}, "action": {"text": "stabilise", "start": 103, "end": 112, "i_start": 20, "i_end": 20}}, {"character": {"text": "fields", "start": 71, "end": 77, "i_start": 14, "i_end": 14}, "action": {"text": "stray", "start": 19, "end": 24, "i_start": 4, "i_end": 4}}], "id": 90}, {"sent": "this interesting spatiotemporal behavior was first observed by kuramoto and bottogtokh in a network of nonlocally coupled ginzburg-landau oscillators with exponential coupling functions .", "tokens": ["this", "interesting", "spatiotemporal", "behavior", "was", "first", "observed", "by", "kuramoto", "and", "bottogtokh", "in", "a", "network", "of", "nonlocally", "coupled", "ginzburg", "-", "landau", "oscillators", "with", "exponential", "coupling", "functions", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this interesting spatiotemporal behavior", "start": 0, "end": 40, "i_start": 0, "i_end": 3}, "verb": {"text": "observed", "start": 51, "end": 59, "i_start": 6, "i_end": 6}}, {"subject": {"text": "this interesting spatiotemporal behavior", "start": 0, "end": 40, "i_start": 0, "i_end": 3}, "verb": {"text": "was", "start": 41, "end": 44, "i_start": 4, "i_end": 4}}, {"character": {"text": "kuramoto", "start": 63, "end": 71, "i_start": 8, "i_end": 8}, "action": {"text": "observed", "start": 51, "end": 59, "i_start": 6, "i_end": 6}}, {"character": {"text": "bottogtokh", "start": 76, "end": 86, "i_start": 10, "i_end": 10}, "action": {"text": "observed", "start": 51, "end": 59, "i_start": 6, "i_end": 6}}], "id": 91}, {"sent": "this peculiar pattern was first observed and analyzed by kuramoto in simulating the complex ginzburg-landau equation with nonlocal couplings .", "tokens": ["this", "peculiar", "pattern", "was", "first", "observed", "and", "analyzed", "by", "kuramoto", "in", "simulating", "the", "complex", "ginzburg", "-", "landau", "equation", "with", "nonlocal", "couplings", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "this peculiar pattern", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "observed", "start": 32, "end": 40, "i_start": 5, "i_end": 5}}, {"subject": {"text": "this peculiar pattern", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "was", "start": 22, "end": 25, "i_start": 3, "i_end": 3}}, {"subject": {"text": "this peculiar pattern", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "analyzed", "start": 45, "end": 53, "i_start": 7, "i_end": 7}}, {"character": {"text": "kuramoto", "start": 57, "end": 65, "i_start": 9, "i_end": 9}, "action": {"text": "observed", "start": 32, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "kuramoto", "start": 57, "end": 65, "i_start": 9, "i_end": 9}, "action": {"text": "analyzed", "start": 45, "end": 53, "i_start": 7, "i_end": 7}}, {"character": {"text": "kuramoto", "start": 57, "end": 65, "i_start": 9, "i_end": 9}, "action": {"text": "simulating", "start": 69, "end": 79, "i_start": 11, "i_end": 11}}], "id": 91}, {"sent": "in doing so , we extensively use average weight spectra derived for ensemble bin and for ensemble ain .", "tokens": ["in", "doing", "so", ",", "we", "extensively", "use", "average", "weight", "spectra", "derived", "for", "ensemble", "bin", "and", "for", "ensemble", "ain", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 29, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 29, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "doing", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 92}, {"sent": "in doing so , we extensively use the average weight spectra derived for the ensemble bin and for ensemble ain .", "tokens": ["in", "doing", "so", ",", "we", "extensively", "use", "the", "average", "weight", "spectra", "derived", "for", "the", "ensemble", "bin", "and", "for", "ensemble", "ain", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "verb": {"text": "use", "start": 29, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "use", "start": 29, "end": 32, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "action": {"text": "doing", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 92}, {"sent": "inst-name ist menge aller instanzbezeichnungen .", "tokens": ["inst", "-", "name", "ist", "menge", "aller", "instanzbezeichnungen", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 93}, {"sent": "sie setzen sich aus modulnamen und instanzbezeichnungen zusammen .", "tokens": ["sie", "setzen", "sich", "aus", "modulnamen", "und", "instanzbezeichnungen", "zusammen", "."], "score": [0, 0, 0, 0, 0], "labels": [], "id": 93}, {"sent": "in this work , we adopt the loopy belief propagation algorithm which was shown to perform well for various problems .", "tokens": ["in", "this", "work", ",", "we", "adopt", "the", "loopy", "belief", "propagation", "algorithm", "which", "was", "shown", "to", "perform", "well", "for", "various", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "verb": {"text": "adopt", "start": 18, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 4, "i_end": 4}, "action": {"text": "adopt", "start": 18, "end": 23, "i_start": 5, "i_end": 5}}, {"character": {"text": "algorithm", "start": 53, "end": 62, "i_start": 10, "i_end": 10}, "action": {"text": "perform", "start": 82, "end": 89, "i_start": 15, "i_end": 15}}], "id": 94}, {"sent": "in our evaluation , we adopt the loopy belief propagation algorithm which was shown to perform well for various problems .", "tokens": ["in", "our", "evaluation", ",", "we", "adopt", "the", "loopy", "belief", "propagation", "algorithm", "which", "was", "shown", "to", "perform", "well", "for", "various", "problems", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 20, "end": 22, "i_start": 4, "i_end": 4}, "verb": {"text": "adopt", "start": 23, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 20, "end": 22, "i_start": 4, "i_end": 4}, "action": {"text": "adopt", "start": 23, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "algorithm", "start": 58, "end": 67, "i_start": 10, "i_end": 10}, "action": {"text": "perform", "start": 87, "end": 94, "i_start": 15, "i_end": 15}}], "id": 94}, {"sent": "in fact , our definition admits cyclic directed graphs , and there may be no nodes with in-degree zero .", "tokens": ["in", "fact", ",", "our", "definition", "admits", "cyclic", "directed", "graphs", ",", "and", "there", "may", "be", "no", "nodes", "with", "in", "-", "degree", "zero", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "our definition", "start": 10, "end": 24, "i_start": 3, "i_end": 4}, "verb": {"text": "admits", "start": 25, "end": 31, "i_start": 5, "i_end": 5}}], "id": 95}, {"sent": "in fact , our definition admits cyclic directed graphs with cycles containing source nodes , and there may be no nodes with in-degree zero .", "tokens": ["in", "fact", ",", "our", "definition", "admits", "cyclic", "directed", "graphs", "with", "cycles", "containing", "source", "nodes", ",", "and", "there", "may", "be", "no", "nodes", "with", "in", "-", "degree", "zero", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "our definition", "start": 10, "end": 24, "i_start": 3, "i_end": 4}, "verb": {"text": "admits", "start": 25, "end": 31, "i_start": 5, "i_end": 5}}, {"character": {"text": "cycles", "start": 60, "end": 66, "i_start": 10, "i_end": 10}, "action": {"text": "containing", "start": 67, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "graphs", "start": 48, "end": 54, "i_start": 8, "i_end": 8}, "action": {"text": "no", "start": 110, "end": 112, "i_start": 19, "i_end": 19}}], "id": 95}, {"sent": "the boundary lagrangian is manifestly gauge-invariant .", "tokens": ["the", "boundary", "lagrangian", "is", "manifestly", "gauge", "-", "invariant", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the boundary lagrangian", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 24, "end": 26, "i_start": 3, "i_end": 3}}], "id": 96}, {"sent": "since the vector r-current is non-anomalous , this category is z-graded .", "tokens": ["since", "the", "vector", "r", "-", "current", "is", "non", "-", "anomalous", ",", "this", "category", "is", "z", "-", "graded", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "this category", "start": 46, "end": 59, "i_start": 11, "i_end": 12}, "verb": {"text": "is", "start": 60, "end": 62, "i_start": 13, "i_end": 13}}], "id": 96}, {"sent": "e-nose is a multi-sensor system comprised of a sensor array with partial specificity coupled with pattern recognition algorithm , which can also be recognized as cost-sensitive problem .", "tokens": ["e", "-", "nose", "is", "a", "multi", "-", "sensor", "system", "comprised", "of", "a", "sensor", "array", "with", "partial", "specificity", "coupled", "with", "pattern", "recognition", "algorithm", ",", "which", "can", "also", "be", "recognized", "as", "cost", "-", "sensitive", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "e-nose", "start": 0, "end": 6, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 7, "end": 9, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithm", "start": 118, "end": 127, "i_start": 21, "i_end": 21}, "action": {"text": "recognized", "start": 148, "end": 158, "i_start": 27, "i_end": 27}}, {"character": {"text": "problem", "start": 177, "end": 184, "i_start": 32, "i_end": 32}, "action": {"text": "sensitive", "start": 167, "end": 176, "i_start": 31, "i_end": 31}}], "id": 97}, {"sent": "e-nose data analysis e-nose is a multi-sensor system comprised of a sensor array with partial specificity coupled with pattern recognition algorithm , which can also be recognized as cost-sensitive problem .", "tokens": ["e", "-", "nose", "data", "analysis", "e", "-", "nose", "is", "a", "multi", "-", "sensor", "system", "comprised", "of", "a", "sensor", "array", "with", "partial", "specificity", "coupled", "with", "pattern", "recognition", "algorithm", ",", "which", "can", "also", "be", "recognized", "as", "cost", "-", "sensitive", "problem", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "e-nose data analysis e-nose", "start": 0, "end": 27, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 28, "end": 30, "i_start": 8, "i_end": 8}}, {"character": {"text": "algorithm", "start": 139, "end": 148, "i_start": 26, "i_end": 26}, "action": {"text": "recognized", "start": 169, "end": 179, "i_start": 32, "i_end": 32}}, {"character": {"text": "problem", "start": 198, "end": 205, "i_start": 37, "i_end": 37}, "action": {"text": "sensitive", "start": 188, "end": 197, "i_start": 36, "i_end": 36}}], "id": 97}, {"sent": "a closely related research area is available bandwidth estimation , eg , that injects artificial test traffic into the network .", "tokens": ["a", "closely", "related", "research", "area", "is", "available", "bandwidth", "estimation", ",", "eg", ",", "that", "injects", "artificial", "test", "traffic", "into", "the", "network", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "a closely related research area", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 5, "i_end": 5}}, {"subject": {"text": "that", "start": 73, "end": 77, "i_start": 12, "i_end": 12}, "verb": {"text": "injects", "start": 78, "end": 85, "i_start": 13, "i_end": 13}}, {"character": {"text": "estimation", "start": 55, "end": 65, "i_start": 8, "i_end": 8}, "action": {"text": "injects", "start": 78, "end": 85, "i_start": 13, "i_end": 13}}], "id": 98}, {"sent": "a closely related research area is available bandwidth estimation that seeks to estimate the long-term average unused capacity of a system or a network .", "tokens": ["a", "closely", "related", "research", "area", "is", "available", "bandwidth", "estimation", "that", "seeks", "to", "estimate", "the", "long", "-", "term", "average", "unused", "capacity", "of", "a", "system", "or", "a", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a closely related research area", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 32, "end": 34, "i_start": 5, "i_end": 5}}, {"character": {"text": "estimate", "start": 80, "end": 88, "i_start": 12, "i_end": 12}, "action": {"text": "seeks", "start": 71, "end": 76, "i_start": 10, "i_end": 10}}], "id": 98}, {"sent": "the large n path integral over these fields can then always be performed exactly , using standard techniques for large n vector models .", "tokens": ["the", "large", "n", "path", "integral", "over", "these", "fields", "can", "then", "always", "be", "performed", "exactly", ",", "using", "standard", "techniques", "for", "large", "n", "vector", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the large n path integral over these fields", "start": 0, "end": 43, "i_start": 0, "i_end": 7}, "verb": {"text": "be performed", "start": 60, "end": 72, "i_start": 11, "i_end": 12}}, {"subject": {"text": "the large n path integral over these fields", "start": 0, "end": 43, "i_start": 0, "i_end": 7}, "verb": {"text": "can", "start": 44, "end": 47, "i_start": 8, "i_end": 8}}], "id": 99}, {"sent": "as explained in , this integration can always be done exactly at large n , by introducing auxiliary variables .", "tokens": ["as", "explained", "in", ",", "this", "integration", "can", "always", "be", "done", "exactly", "at", "large", "n", ",", "by", "introducing", "auxiliary", "variables", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this integration", "start": 18, "end": 34, "i_start": 4, "i_end": 5}, "verb": {"text": "be done", "start": 46, "end": 53, "i_start": 8, "i_end": 9}}, {"subject": {"text": "this integration", "start": 18, "end": 34, "i_start": 4, "i_end": 5}, "verb": {"text": "can", "start": 35, "end": 38, "i_start": 6, "i_end": 6}}], "id": 99}]