[{"sent": "we find the optimal alignment of the clean and noisy embeddings via procrustes analysis and apply the resulting translational , rotational , and scaling components on the oose points .", "tokens": ["we", "find", "the", "optimal", "alignment", "of", "the", "clean", "and", "noisy", "embeddings", "via", "procrustes", "analysis", "and", "apply", "the", "resulting", "translational", ",", "rotational", ",", "and", "scaling", "components", "on", "the", "oose", "points", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "apply", "start": 92, "end": 97, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "apply", "start": 92, "end": 97, "i_start": 15, "i_end": 15}}], "id": 0},{"sent": "end-to-end neural machine translation has gained increasing popularity in the machine translation community .", "tokens": ["end", "-", "to", "-", "end", "neural", "machine", "translation", "has", "gained", "increasing", "popularity", "in", "the", "machine", "translation", "community", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "end-to-end neural machine translation", "start": 0, "end": 37, "i_start": 0, "i_end": 7}, "verb": {"text": "has gained", "start": 38, "end": 48, "i_start": 8, "i_end": 9}}, {"character": {"text": "translation", "start": 26, "end": 37, "i_start": 7, "i_end": 7}, "action": {"text": "gained", "start": 42, "end": 48, "i_start": 9, "i_end": 9}}, {"character": {"text": "community", "start": 98, "end": 107, "i_start": 16, "i_end": 16}, "action": {"text": "translation", "start": 86, "end": 97, "i_start": 15, "i_end": 15}}], "id": 1},{"sent": "moreover , asymptotically for large k , the sorting operation can be performed with a complexity on the order of o , according to the van emde boas tree .", "tokens": ["moreover", ",", "asymptotically", "for", "large", "k", ",", "the", "sorting", "operation", "can", "be", "performed", "with", "a", "complexity", "on", "the", "order", "of", "o", ",", "according", "to", "the", "van", "emde", "boas", "tree", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the sorting operation", "start": 40, "end": 61, "i_start": 7, "i_end": 9}, "verb": {"text": "can be performed", "start": 62, "end": 78, "i_start": 10, "i_end": 12}}], "id": 2},{"sent": "we build on the recent success of deep learning and use a convolutional neural network to encode image information .", "tokens": ["we", "build", "on", "the", "recent", "success", "of", "deep", "learning", "and", "use", "a", "convolutional", "neural", "network", "to", "encode", "image", "information", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "build", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 52, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "build", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "learning", "start": 39, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "success", "start": 23, "end": 30, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 52, "end": 55, "i_start": 10, "i_end": 10}}, {"character": {"text": "network", "start": 79, "end": 86, "i_start": 14, "i_end": 14}, "action": {"text": "encode", "start": 90, "end": 96, "i_start": 16, "i_end": 16}}], "id": 3},{"sent": "the trainable parameters are initialized using the glorot algorithm .", "tokens": ["the", "trainable", "parameters", "are", "initialized", "using", "the", "glorot", "algorithm", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the trainable parameters", "start": 0, "end": 24, "i_start": 0, "i_end": 2}, "verb": {"text": "are initialized", "start": 25, "end": 40, "i_start": 3, "i_end": 4}}], "id": 4},{"sent": "transductive learning we utilize three standard citation network benchmark datasets-cora , citeseer and pubmed -and closely follow the transductive experimental setup of yang et al .", "tokens": ["transductive", "learning", "we", "utilize", "three", "standard", "citation", "network", "benchmark", "datasets", "-", "cora", ",", "citeseer", "and", "pubmed", "-and", "closely", "follow", "the", "transductive", "experimental", "setup", "of", "yang", "et", "al", "."], "score": [0, 1, 1, 0, 1], "labels": [{"subject": {"text": "transductive learning we utilize three standard citation network benchmark datasets-cora", "start": 0, "end": 88, "i_start": 0, "i_end": 11}, "verb": {"text": "follow", "start": 124, "end": 130, "i_start": 18, "i_end": 18}}, {"character": {"text": "we", "start": 22, "end": 24, "i_start": 2, "i_end": 2}, "action": {"text": "utilize", "start": 25, "end": 32, "i_start": 3, "i_end": 3}}], "id": 5},{"sent": "convolutional neural networks have recently been very successful on a variety of recognition and classification tasks .", "tokens": ["convolutional", "neural", "networks", "have", "recently", "been", "very", "successful", "on", "a", "variety", "of", "recognition", "and", "classification", "tasks", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "been", "start": 44, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 30, "end": 34, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 54, "end": 64, "i_start": 7, "i_end": 7}}], "id": 6},{"sent": "the camera consists of an array of ccds with associated electronics , thermal control and radiation , stray light and contamination shielding .", "tokens": ["the", "camera", "consists", "of", "an", "array", "of", "ccds", "with", "associated", "electronics", ",", "thermal", "control", "and", "radiation", ",", "stray", "light", "and", "contamination", "shielding", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the camera", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the camera", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "stray", "start": 102, "end": 107, "i_start": 17, "i_end": 17}}], "id": 7},{"sent": "in recent years deep convolutional networks have become an integral part of state-of-the-art systems for a diverse set of computer vision problems such as object detection .", "tokens": ["in", "recent", "years", "deep", "convolutional", "networks", "have", "become", "an", "integral", "part", "of", "state", "-", "of", "-", "the", "-", "art", "systems", "for", "a", "diverse", "set", "of", "computer", "vision", "problems", "such", "as", "object", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional networks", "start": 21, "end": 43, "i_start": 4, "i_end": 5}, "verb": {"text": "have become", "start": 44, "end": 55, "i_start": 6, "i_end": 7}}], "id": 8},{"sent": "convolutional neural networks have surpassed many traditional machine learning approaches in solving several computer vision tasks such as classification and others .", "tokens": ["convolutional", "neural", "networks", "have", "surpassed", "many", "traditional", "machine", "learning", "approaches", "in", "solving", "several", "computer", "vision", "tasks", "such", "as", "classification", "and", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have surpassed", "start": 30, "end": 44, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "surpassed", "start": 35, "end": 44, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "solving", "start": 93, "end": 100, "i_start": 11, "i_end": 11}}], "id": 9},{"sent": "however , manual segmentation is tedious , time consuming and prone to intra-and inter-observer variability .", "tokens": ["however", ",", "manual", "segmentation", "is", "tedious", ",", "time", "consuming", "and", "prone", "to", "intra", "-", "and", "inter", "-", "observer", "variability", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "manual segmentation", "start": 10, "end": 29, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "segmentation", "start": 17, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "consuming", "start": 48, "end": 57, "i_start": 8, "i_end": 8}}], "id": 10},{"sent": "recent rapid advances in deep learning are allowing for the learning of complex functions through convolutional neural networks , which have achieved stateof-the-art performances in a plethora of computer vision tasks .", "tokens": ["recent", "rapid", "advances", "in", "deep", "learning", "are", "allowing", "for", "the", "learning", "of", "complex", "functions", "through", "convolutional", "neural", "networks", ",", "which", "have", "achieved", "stateof", "-", "the", "-", "art", "performances", "in", "a", "plethora", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "recent rapid advances in deep learning", "start": 0, "end": 38, "i_start": 0, "i_end": 5}, "verb": {"text": "are allowing", "start": 39, "end": 51, "i_start": 6, "i_end": 7}}, {"character": {"text": "advances", "start": 13, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "allowing", "start": 43, "end": 51, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 119, "end": 127, "i_start": 17, "i_end": 17}, "action": {"text": "achieved", "start": 141, "end": 149, "i_start": 21, "i_end": 21}}], "id": 11},{"sent": "this figure shows how to compute ana followed by copy transformations .", "tokens": ["this", "figure", "shows", "how", "to", "compute", "ana", "followed", "by", "copy", "transformations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this figure", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "shows", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "how to compute ana", "start": 18, "end": 36, "i_start": 3, "i_end": 6}, "verb": {"text": "followed", "start": 37, "end": 45, "i_start": 7, "i_end": 7}}, {"character": {"text": "figure", "start": 5, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "shows", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}], "id": 12},{"sent": "it also arises in string theory , which is the leading candidate to unify gauge and gravitational forces .", "tokens": ["it", "also", "arises", "in", "string", "theory", ",", "which", "is", "the", "leading", "candidate", "to", "unify", "gauge", "and", "gravitational", "forces", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "arises", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "theory", "start": 25, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "candidate", "start": 55, "end": 64, "i_start": 11, "i_end": 11}}, {"character": {"text": "candidate", "start": 55, "end": 64, "i_start": 11, "i_end": 11}, "action": {"text": "leading", "start": 47, "end": 54, "i_start": 10, "i_end": 10}}], "id": 13},{"sent": "in a remarkable work , spielman and srivastava analyzed a spectral sparsification algorithm based on a simple sampling procedure .", "tokens": ["in", "a", "remarkable", "work", ",", "spielman", "and", "srivastava", "analyzed", "a", "spectral", "sparsification", "algorithm", "based", "on", "a", "simple", "sampling", "procedure", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "spielman and srivastava", "start": 23, "end": 46, "i_start": 5, "i_end": 7}, "verb": {"text": "analyzed", "start": 47, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "spielman", "start": 23, "end": 31, "i_start": 5, "i_end": 5}, "action": {"text": "analyzed", "start": 47, "end": 55, "i_start": 8, "i_end": 8}}, {"character": {"text": "srivastava", "start": 36, "end": 46, "i_start": 7, "i_end": 7}, "action": {"text": "analyzed", "start": 47, "end": 55, "i_start": 8, "i_end": 8}}], "id": 14},{"sent": "note that agarwal et al also analyzed this model using m-estimators .", "tokens": ["note", "that", "agarwal", "et", "al", "also", "analyzed", "this", "model", "using", "m", "-", "estimators", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "agarwal et al", "start": 10, "end": 23, "i_start": 2, "i_end": 4}, "verb": {"text": "note", "start": 0, "end": 4, "i_start": 0, "i_end": 0}}, {"subject": {"text": "agarwal et al", "start": 10, "end": 23, "i_start": 2, "i_end": 4}, "verb": {"text": "analyzed", "start": 29, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "agarwal", "start": 10, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "analyzed", "start": 29, "end": 37, "i_start": 6, "i_end": 6}}, {"character": {"text": "agarwal", "start": 10, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "using", "start": 49, "end": 54, "i_start": 9, "i_end": 9}}], "id": 15},{"sent": "we train using the adam optimiser along with an early stopping criterion .", "tokens": ["we", "train", "using", "the", "adam", "optimiser", "along", "with", "an", "early", "stopping", "criterion", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "train", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "using", "start": 9, "end": 14, "i_start": 2, "i_end": 2}}], "id": 16},{"sent": "the classifier was trained using mini-batch sgd , with the learning rate controlled by adam and the mini-batch size set to 32 .", "tokens": ["the", "classifier", "was", "trained", "using", "mini", "-", "batch", "sgd", ",", "with", "the", "learning", "rate", "controlled", "by", "adam", "and", "the", "mini", "-", "batch", "size", "set", "to", "32", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the classifier", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "was trained", "start": 15, "end": 26, "i_start": 2, "i_end": 3}}, {"character": {"text": "adam", "start": 87, "end": 91, "i_start": 16, "i_end": 16}, "action": {"text": "controlled", "start": 73, "end": 83, "i_start": 14, "i_end": 14}}], "id": 17},{"sent": "the calculation was performed within the framework of dft 35 , as implemented in the vienna ab-initio simulation package 36 , 37 .", "tokens": ["the", "calculation", "was", "performed", "within", "the", "framework", "of", "dft", "35", ",", "as", "implemented", "in", "the", "vienna", "ab", "-", "initio", "simulation", "package", "36", ",", "37", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the calculation", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "was performed", "start": 16, "end": 29, "i_start": 2, "i_end": 3}}], "id": 18},{"sent": "unlike prior work with sparsity-aware algorithms , the proposed sils algorithm exploits the possible sparsity of the emse associated with each of the links in an opposite way .", "tokens": ["unlike", "prior", "work", "with", "sparsity", "-", "aware", "algorithms", ",", "the", "proposed", "sils", "algorithm", "exploits", "the", "possible", "sparsity", "of", "the", "emse", "associated", "with", "each", "of", "the", "links", "in", "an", "opposite", "way", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the proposed sils algorithm", "start": 51, "end": 78, "i_start": 9, "i_end": 12}, "verb": {"text": "exploits", "start": 79, "end": 87, "i_start": 13, "i_end": 13}}, {"character": {"text": "algorithms", "start": 38, "end": 48, "i_start": 7, "i_end": 7}, "action": {"text": "exploits", "start": 79, "end": 87, "i_start": 13, "i_end": 13}}], "id": 19},{"sent": "a qubit is a unit vector in the hilbert space c2 .", "tokens": ["a", "qubit", "is", "a", "unit", "vector", "in", "the", "hilbert", "space", "c2", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a qubit", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 2, "i_end": 2}}], "id": 20},{"sent": "for example , one might respond to edges of a particular orientation , or a sweet taste , or something that does not exactly match an established term .", "tokens": ["for", "example", ",", "one", "might", "respond", "to", "edges", "of", "a", "particular", "orientation", ",", "or", "a", "sweet", "taste", ",", "or", "something", "that", "does", "not", "exactly", "match", "an", "established", "term", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 14, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "might respond", "start": 18, "end": 31, "i_start": 4, "i_end": 5}}, {"character": {"text": "one", "start": 14, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "respond", "start": 24, "end": 31, "i_start": 5, "i_end": 5}}], "id": 21},{"sent": "we use the adam optimizer , with gradients clipped with norm value 1 .", "tokens": ["we", "use", "the", "adam", "optimizer", ",", "with", "gradients", "clipped", "with", "norm", "value", "1", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 22},{"sent": "in recent years , neural networks have been effectively applied in various problems such as voice recognition .", "tokens": ["in", "recent", "years", ",", "neural", "networks", "have", "been", "effectively", "applied", "in", "various", "problems", "such", "as", "voice", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 18, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "applied", "start": 56, "end": 63, "i_start": 9, "i_end": 9}}, {"subject": {"text": "neural networks", "start": 18, "end": 33, "i_start": 4, "i_end": 5}, "verb": {"text": "have been", "start": 34, "end": 43, "i_start": 6, "i_end": 7}}], "id": 23},{"sent": "similarly , topic features have been used with either maximum entropy models .", "tokens": ["similarly", ",", "topic", "features", "have", "been", "used", "with", "either", "maximum", "entropy", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "topic features", "start": 12, "end": 26, "i_start": 2, "i_end": 3}, "verb": {"text": "have been used", "start": 27, "end": 41, "i_start": 4, "i_end": 6}}], "id": 24},{"sent": "compressed sensing is a recent signal detection framework which has received considerable attention in the signal processing community .", "tokens": ["compressed", "sensing", "is", "a", "recent", "signal", "detection", "framework", "which", "has", "received", "considerable", "attention", "in", "the", "signal", "processing", "community", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "compressed sensing", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "framework", "start": 48, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "detection", "start": 38, "end": 47, "i_start": 6, "i_end": 6}}, {"character": {"text": "framework", "start": 48, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "received", "start": 68, "end": 76, "i_start": 10, "i_end": 10}}, {"character": {"text": "community", "start": 125, "end": 134, "i_start": 17, "i_end": 17}, "action": {"text": "attention", "start": 90, "end": 99, "i_start": 12, "i_end": 12}}, {"character": {"text": "community", "start": 125, "end": 134, "i_start": 17, "i_end": 17}, "action": {"text": "processing", "start": 114, "end": 124, "i_start": 16, "i_end": 16}}], "id": 25},{"sent": "finally , we perform binarization operation on each attention map with an adaptive threshold , which is obtained by otsu algorithm , and take the bounding box that covers the largest connected area as the discriminative region .", "tokens": ["finally", ",", "we", "perform", "binarization", "operation", "on", "each", "attention", "map", "with", "an", "adaptive", "threshold", ",", "which", "is", "obtained", "by", "otsu", "algorithm", ",", "and", "take", "the", "bounding", "box", "that", "covers", "the", "largest", "connected", "area", "as", "the", "discriminative", "region", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "perform", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "take", "start": 137, "end": 141, "i_start": 23, "i_end": 23}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "perform", "start": 13, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithm", "start": 121, "end": 130, "i_start": 20, "i_end": 20}, "action": {"text": "obtained", "start": 104, "end": 112, "i_start": 17, "i_end": 17}}], "id": 26},{"sent": "parenti , multi-lepton production at hera , these proceedings .", "tokens": ["parenti", ",", "multi", "-", "lepton", "production", "at", "hera", ",", "these", "proceedings", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 27},{"sent": "while models following this paradigm have been found very useful in a number of natural language processing tasks , they do not scale up to the level of phrases or sentences .", "tokens": ["while", "models", "following", "this", "paradigm", "have", "been", "found", "very", "useful", "in", "a", "number", "of", "natural", "language", "processing", "tasks", ",", "they", "do", "not", "scale", "up", "to", "the", "level", "of", "phrases", "or", "sentences", "."], "score": [1, 0, 0, 1, 0], "labels": [{"subject": {"text": "they", "start": 116, "end": 120, "i_start": 19, "i_end": 19}, "verb": {"text": "do not scale up", "start": 121, "end": 136, "i_start": 20, "i_end": 23}}, {"character": {"text": "models", "start": 6, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "not scale", "start": 124, "end": 133, "i_start": 21, "i_end": 22}}], "id": 28},{"sent": "free energy is the fundamental object in statistical mechanics .", "tokens": ["free", "energy", "is", "the", "fundamental", "object", "in", "statistical", "mechanics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "free energy", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 12, "end": 14, "i_start": 2, "i_end": 2}}], "id": 29},{"sent": "this holds in particular , for the local broadcast algorithm of which crucially relies on a very unnatural reversal step to guarantee correctness .", "tokens": ["this", "holds", "in", "particular", ",", "for", "the", "local", "broadcast", "algorithm", "of", "which", "crucially", "relies", "on", "a", "very", "unnatural", "reversal", "step", "to", "guarantee", "correctness", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "holds", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "holds", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "algorithm", "start": 51, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "broadcast", "start": 41, "end": 50, "i_start": 8, "i_end": 8}}, {"character": {"text": "algorithm", "start": 51, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "relies", "start": 80, "end": 86, "i_start": 13, "i_end": 13}}, {"character": {"text": "step", "start": 116, "end": 120, "i_start": 19, "i_end": 19}, "action": {"text": "guarantee", "start": 124, "end": 133, "i_start": 21, "i_end": 21}}], "id": 30},{"sent": "the youtube faces dataset exemplify both unconstrained and controlled video settings .", "tokens": ["the", "youtube", "faces", "dataset", "exemplify", "both", "unconstrained", "and", "controlled", "video", "settings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the youtube", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "faces", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "dataset", "start": 18, "end": 25, "i_start": 3, "i_end": 3}, "verb": {"text": "exemplify", "start": 26, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "dataset", "start": 18, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "exemplify", "start": 26, "end": 35, "i_start": 4, "i_end": 4}}], "id": 31},{"sent": "to carry out our program , we generalize the toric mori theory for non-complete and non-q-factorial varieties .", "tokens": ["to", "carry", "out", "our", "program", ",", "we", "generalize", "the", "toric", "mori", "theory", "for", "non", "-", "complete", "and", "non", "-", "q", "-", "factorial", "varieties", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 27, "end": 29, "i_start": 6, "i_end": 6}, "verb": {"text": "generalize", "start": 30, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 27, "end": 29, "i_start": 6, "i_end": 6}, "action": {"text": "generalize", "start": 30, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 27, "end": 29, "i_start": 6, "i_end": 6}, "action": {"text": "carry", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 32},{"sent": "later , defferrard et al and levie et al proposed spectrum filtering based methods that utilize chebyshev polynomials and cayley polynomials , respectively .", "tokens": ["later", ",", "defferrard", "et", "al", "and", "levie", "et", "al", "proposed", "spectrum", "filtering", "based", "methods", "that", "utilize", "chebyshev", "polynomials", "and", "cayley", "polynomials", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "defferrard et al and levie et al", "start": 8, "end": 40, "i_start": 2, "i_end": 8}, "verb": {"text": "proposed", "start": 41, "end": 49, "i_start": 9, "i_end": 9}}, {"character": {"text": "defferrard et al", "start": 8, "end": 24, "i_start": 2, "i_end": 4}, "action": {"text": "proposed", "start": 41, "end": 49, "i_start": 9, "i_end": 9}}, {"character": {"text": "levie et al", "start": 29, "end": 40, "i_start": 6, "i_end": 8}, "action": {"text": "proposed", "start": 41, "end": 49, "i_start": 9, "i_end": 9}}, {"character": {"text": "methods", "start": 75, "end": 82, "i_start": 13, "i_end": 13}, "action": {"text": "utilize", "start": 88, "end": 95, "i_start": 15, "i_end": 15}}], "id": 33},{"sent": "this posterior is analytically intractable and we resort to variational inference .", "tokens": ["this", "posterior", "is", "analytically", "intractable", "and", "we", "resort", "to", "variational", "inference", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this posterior", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 15, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 47, "end": 49, "i_start": 6, "i_end": 6}, "verb": {"text": "resort", "start": 50, "end": 56, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 47, "end": 49, "i_start": 6, "i_end": 6}, "action": {"text": "resort", "start": 50, "end": 56, "i_start": 7, "i_end": 7}}], "id": 34},{"sent": "the generalized gradient approximation of perdew , burke and ernzerhof was used to describe the exchangecorrelation potential .", "tokens": ["the", "generalized", "gradient", "approximation", "of", "perdew", ",", "burke", "and", "ernzerhof", "was", "used", "to", "describe", "the", "exchangecorrelation", "potential", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation of perdew", "start": 0, "end": 48, "i_start": 0, "i_end": 5}, "verb": {"text": "was used", "start": 71, "end": 79, "i_start": 10, "i_end": 11}}, {"character": {"text": "approximation", "start": 25, "end": 38, "i_start": 3, "i_end": 3}, "action": {"text": "describe", "start": 83, "end": 91, "i_start": 13, "i_end": 13}}], "id": 35},{"sent": "the time component may designate an entire year , a year and a month , or a full date .", "tokens": ["the", "time", "component", "may", "designate", "an", "entire", "year", ",", "a", "year", "and", "a", "month", ",", "or", "a", "full", "date", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the time component", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "may designate", "start": 19, "end": 32, "i_start": 3, "i_end": 4}}, {"character": {"text": "component", "start": 9, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "designate", "start": 23, "end": 32, "i_start": 4, "i_end": 4}}], "id": 36},{"sent": "deep convolutional neural networks have made significant breakthroughs in many visual understanding tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "made", "significant", "breakthroughs", "in", "many", "visual", "understanding", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have made", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "breakthroughs", "start": 57, "end": 70, "i_start": 7, "i_end": 7}}], "id": 37},{"sent": "in recent years , deep neural networks have achieved great success in a variety of machine learning tasks .", "tokens": ["in", "recent", "years", ",", "deep", "neural", "networks", "have", "achieved", "great", "success", "in", "a", "variety", "of", "machine", "learning", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 18, "end": 38, "i_start": 4, "i_end": 6}, "verb": {"text": "have achieved", "start": 39, "end": 52, "i_start": 7, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "achieved", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "networks", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "success", "start": 59, "end": 66, "i_start": 10, "i_end": 10}}], "id": 38},{"sent": "distance of povms from observables in the preceding subsection , we have defined the rootmean-square noise of measurement using the associated indirect measurement model .", "tokens": ["distance", "of", "povms", "from", "observables", "in", "the", "preceding", "subsection", ",", "we", "have", "defined", "the", "rootmean", "-", "square", "noise", "of", "measurement", "using", "the", "associated", "indirect", "measurement", "model", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 65, "end": 67, "i_start": 10, "i_end": 10}, "verb": {"text": "have defined", "start": 68, "end": 80, "i_start": 11, "i_end": 12}}, {"character": {"text": "we", "start": 65, "end": 67, "i_start": 10, "i_end": 10}, "action": {"text": "defined", "start": 73, "end": 80, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 65, "end": 67, "i_start": 10, "i_end": 10}, "action": {"text": "using", "start": 122, "end": 127, "i_start": 20, "i_end": 20}}], "id": 39},{"sent": "filled squares represent the g-sample , open circles the h-sample and crosses nondetections .", "tokens": ["filled", "squares", "represent", "the", "g", "-", "sample", ",", "open", "circles", "the", "h", "-", "sample", "and", "crosses", "nondetections", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "filled squares", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "represent", "start": 15, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "squares", "start": 7, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "represent", "start": 15, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "sample", "start": 31, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "crosses", "start": 70, "end": 77, "i_start": 15, "i_end": 15}}], "id": 40},{"sent": "firstly , hydrogen is the prime fuel for galaxies , when it condenses from the hot ionized halo onto the galactic disks .", "tokens": ["firstly", ",", "hydrogen", "is", "the", "prime", "fuel", "for", "galaxies", ",", "when", "it", "condenses", "from", "the", "hot", "ionized", "halo", "onto", "the", "galactic", "disks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "hydrogen", "start": 10, "end": 18, "i_start": 2, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 41},{"sent": "we evaluate the searched model on cifar-10 and then transfer to imagenet .", "tokens": ["we", "evaluate", "the", "searched", "model", "on", "cifar-10", "and", "then", "transfer", "to", "imagenet", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "transfer", "start": 52, "end": 60, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "evaluate", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "transfer", "start": 52, "end": 60, "i_start": 9, "i_end": 9}}], "id": 42},{"sent": "to reduce the dependency on weight initialization and to accelerate the training process , we add batch normalization layer after each convolution and fully-connected layer .", "tokens": ["to", "reduce", "the", "dependency", "on", "weight", "initialization", "and", "to", "accelerate", "the", "training", "process", ",", "we", "add", "batch", "normalization", "layer", "after", "each", "convolution", "and", "fully", "-", "connected", "layer", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 91, "end": 93, "i_start": 14, "i_end": 14}, "verb": {"text": "add", "start": 94, "end": 97, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 91, "end": 93, "i_start": 14, "i_end": 14}, "action": {"text": "add", "start": 94, "end": 97, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 91, "end": 93, "i_start": 14, "i_end": 14}, "action": {"text": "reduce", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "initialization", "start": 35, "end": 49, "i_start": 6, "i_end": 6}, "action": {"text": "dependency", "start": 14, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 91, "end": 93, "i_start": 14, "i_end": 14}, "action": {"text": "accelerate", "start": 57, "end": 67, "i_start": 9, "i_end": 9}}], "id": 43},{"sent": "we now proceed onto give the following interesting corollary .", "tokens": ["we", "now", "proceed", "onto", "give", "the", "following", "interesting", "corollary", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "proceed", "start": 7, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "give", "start": 20, "end": 24, "i_start": 4, "i_end": 4}}, {"character": {"text": "corollary", "start": 51, "end": 60, "i_start": 8, "i_end": 8}, "action": {"text": "interesting", "start": 39, "end": 50, "i_start": 7, "i_end": 7}}], "id": 44},{"sent": "the meta-meta-model layer defines the language for specifying meta-models .", "tokens": ["the", "meta", "-", "meta", "-", "model", "layer", "defines", "the", "language", "for", "specifying", "meta", "-", "models", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the meta-meta-model layer", "start": 0, "end": 25, "i_start": 0, "i_end": 6}, "verb": {"text": "defines", "start": 26, "end": 33, "i_start": 7, "i_end": 7}}, {"character": {"text": "layer", "start": 20, "end": 25, "i_start": 6, "i_end": 6}, "action": {"text": "defines", "start": 26, "end": 33, "i_start": 7, "i_end": 7}}], "id": 45},{"sent": "this sub-space consists of the simultaneous eigenstates of the cashmir operators for each i .", "tokens": ["this", "sub", "-", "space", "consists", "of", "the", "simultaneous", "eigenstates", "of", "the", "cashmir", "operators", "for", "each", "i", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 46},{"sent": "the exchange-correlation potential was calculated using the generalized gradient approximation as proposed by pedrew , burke , and ernzerhof .", "tokens": ["the", "exchange", "-", "correlation", "potential", "was", "calculated", "using", "the", "generalized", "gradient", "approximation", "as", "proposed", "by", "pedrew", ",", "burke", ",", "and", "ernzerhof", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the exchange-correlation potential", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "was calculated", "start": 35, "end": 49, "i_start": 5, "i_end": 6}}, {"character": {"text": "pedrew", "start": 110, "end": 116, "i_start": 15, "i_end": 15}, "action": {"text": "proposed", "start": 98, "end": 106, "i_start": 13, "i_end": 13}}, {"character": {"text": "burke", "start": 119, "end": 124, "i_start": 17, "i_end": 17}, "action": {"text": "proposed", "start": 98, "end": 106, "i_start": 13, "i_end": 13}}, {"character": {"text": "ernzerhof", "start": 131, "end": 140, "i_start": 20, "i_end": 20}, "action": {"text": "proposed", "start": 98, "end": 106, "i_start": 13, "i_end": 13}}], "id": 47},{"sent": "an automatic binarization method for colour text area in video based on convolutional network is proposed by saidane and garcia .", "tokens": ["an", "automatic", "binarization", "method", "for", "colour", "text", "area", "in", "video", "based", "on", "convolutional", "network", "is", "proposed", "by", "saidane", "and", "garcia", "."], "score": [1, 0, 1, 0, 0], "labels": [{"subject": {"text": "an automatic binarization method for colour text area in video based on convolutional network", "start": 0, "end": 93, "i_start": 0, "i_end": 13}, "verb": {"text": "is proposed", "start": 94, "end": 105, "i_start": 14, "i_end": 15}}, {"character": {"text": "saidane", "start": 109, "end": 116, "i_start": 17, "i_end": 17}, "action": {"text": "proposed", "start": 97, "end": 105, "i_start": 15, "i_end": 15}}, {"character": {"text": "garcia", "start": 121, "end": 127, "i_start": 19, "i_end": 19}, "action": {"text": "proposed", "start": 97, "end": 105, "i_start": 15, "i_end": 15}}], "id": 48},{"sent": "the zb are the zeros of zn ) and are known as the apparent singularities .", "tokens": ["the", "zb", "are", "the", "zeros", "of", "zn", ")", "and", "are", "known", "as", "the", "apparent", "singularities", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the zb", "start": 0, "end": 6, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 7, "end": 10, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the zb", "start": 0, "end": 6, "i_start": 0, "i_end": 1}, "verb": {"text": "known", "start": 37, "end": 42, "i_start": 10, "i_end": 10}}], "id": 49},{"sent": "recently , deep neural networks have achieved impressive results for many image classification tasks .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "achieved", "impressive", "results", "for", "many", "image", "classification", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have achieved", "start": 32, "end": 45, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "achieved", "start": 37, "end": 45, "i_start": 6, "i_end": 6}}, {"character": {"text": "results", "start": 57, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "impressive", "start": 46, "end": 56, "i_start": 7, "i_end": 7}}], "id": 50},{"sent": "in , a dynamic channel-selection for autonomous wireless users is proposed , where each user has a set of actions and strategies .", "tokens": ["in", ",", "a", "dynamic", "channel", "-", "selection", "for", "autonomous", "wireless", "users", "is", "proposed", ",", "where", "each", "user", "has", "a", "set", "of", "actions", "and", "strategies", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a dynamic channel-selection for autonomous wireless users", "start": 5, "end": 62, "i_start": 2, "i_end": 10}, "verb": {"text": "is proposed", "start": 63, "end": 74, "i_start": 11, "i_end": 12}}, {"character": {"text": "each", "start": 83, "end": 87, "i_start": 15, "i_end": 15}, "action": {"text": "has", "start": 93, "end": 96, "i_start": 17, "i_end": 17}}], "id": 51},{"sent": "a singleton letter is a letter whose image , in the remaining three quadrants , is never another letter that appears in the upper left quadrant .", "tokens": ["a", "singleton", "letter", "is", "a", "letter", "whose", "image", ",", "in", "the", "remaining", "three", "quadrants", ",", "is", "never", "another", "letter", "that", "appears", "in", "the", "upper", "left", "quadrant", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a singleton letter", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 52},{"sent": "each lattice site consists of a double well potential .", "tokens": ["each", "lattice", "site", "consists", "of", "a", "double", "well", "potential", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "each lattice site", "start": 0, "end": 17, "i_start": 0, "i_end": 2}, "verb": {"text": "consists", "start": 18, "end": 26, "i_start": 3, "i_end": 3}}], "id": 53},{"sent": "however , the computational complexity of this detection method is very high , and large number of samples are required to exploit the cyclostationarity nature of the received samples .", "tokens": ["however", ",", "the", "computational", "complexity", "of", "this", "detection", "method", "is", "very", "high", ",", "and", "large", "number", "of", "samples", "are", "required", "to", "exploit", "the", "cyclostationarity", "nature", "of", "the", "received", "samples", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the computational complexity of this detection method", "start": 10, "end": 63, "i_start": 2, "i_end": 8}, "verb": {"text": "is", "start": 64, "end": 66, "i_start": 9, "i_end": 9}}, {"subject": {"text": "large number of samples", "start": 83, "end": 106, "i_start": 14, "i_end": 17}, "verb": {"text": "required", "start": 111, "end": 119, "i_start": 19, "i_end": 19}}], "id": 54},{"sent": "we also find that the spin current is a nonlocal function of the spin motive force and can be effectively expressed in terms of nonlocal gilbert damping tensor .", "tokens": ["we", "also", "find", "that", "the", "spin", "current", "is", "a", "nonlocal", "function", "of", "the", "spin", "motive", "force", "and", "can", "be", "effectively", "expressed", "in", "terms", "of", "nonlocal", "gilbert", "damping", "tensor", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 35, "end": 37, "i_start": 7, "i_end": 7}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 8, "end": 12, "i_start": 2, "i_end": 2}}, {"character": {"text": "force", "start": 77, "end": 82, "i_start": 15, "i_end": 15}, "action": {"text": "function", "start": 49, "end": 57, "i_start": 10, "i_end": 10}}, {"character": {"text": "motive", "start": 70, "end": 76, "i_start": 14, "i_end": 14}, "action": {"text": "force", "start": 77, "end": 82, "i_start": 15, "i_end": 15}}], "id": 55},{"sent": "for the reweighted techniques , the h-method estimator provides better energy values than the t-method estimator .", "tokens": ["for", "the", "reweighted", "techniques", ",", "the", "h", "-", "method", "estimator", "provides", "better", "energy", "values", "than", "the", "t", "-", "method", "estimator", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the h-method estimator", "start": 32, "end": 54, "i_start": 5, "i_end": 9}, "verb": {"text": "provides", "start": 55, "end": 63, "i_start": 10, "i_end": 10}}], "id": 56},{"sent": "for a more detailed introduction to fractional sobolev spaces and related results , we refer the readers to .", "tokens": ["for", "a", "more", "detailed", "introduction", "to", "fractional", "sobolev", "spaces", "and", "related", "results", ",", "we", "refer", "the", "readers", "to", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 84, "end": 86, "i_start": 13, "i_end": 13}, "verb": {"text": "refer", "start": 87, "end": 92, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 84, "end": 86, "i_start": 13, "i_end": 13}, "action": {"text": "refer", "start": 87, "end": 92, "i_start": 14, "i_end": 14}}], "id": 57},{"sent": "son et al show that intentional resonant sounds can disrupt the mems gyroscopes and cause drones to crash .", "tokens": ["son", "et", "al", "show", "that", "intentional", "resonant", "sounds", "can", "disrupt", "the", "mems", "gyroscopes", "and", "cause", "drones", "to", "crash", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "son et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "show", "start": 10, "end": 14, "i_start": 3, "i_end": 3}}, {"subject": {"text": "intentional resonant sounds", "start": 20, "end": 47, "i_start": 5, "i_end": 7}, "verb": {"text": "disrupt", "start": 52, "end": 59, "i_start": 9, "i_end": 9}}, {"character": {"text": "sounds", "start": 41, "end": 47, "i_start": 7, "i_end": 7}, "action": {"text": "disrupt", "start": 52, "end": 59, "i_start": 9, "i_end": 9}}, {"character": {"text": "sounds", "start": 41, "end": 47, "i_start": 7, "i_end": 7}, "action": {"text": "cause", "start": 84, "end": 89, "i_start": 14, "i_end": 14}}, {"character": {"text": "sounds", "start": 41, "end": 47, "i_start": 7, "i_end": 7}, "action": {"text": "crash", "start": 100, "end": 105, "i_start": 17, "i_end": 17}}], "id": 58},{"sent": "the set of the proteins used for the parameter refinement is called the training set .", "tokens": ["the", "set", "of", "the", "proteins", "used", "for", "the", "parameter", "refinement", "is", "called", "the", "training", "set", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the set of the proteins used for the parameter refinement", "start": 0, "end": 57, "i_start": 0, "i_end": 9}, "verb": {"text": "is called", "start": 58, "end": 67, "i_start": 10, "i_end": 11}}], "id": 59},{"sent": "the average square amplitude of the island deviations is equal to that of the harmonically oscillating island .", "tokens": ["the", "average", "square", "amplitude", "of", "the", "island", "deviations", "is", "equal", "to", "that", "of", "the", "harmonically", "oscillating", "island", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the average square amplitude of the island deviations", "start": 0, "end": 53, "i_start": 0, "i_end": 7}, "verb": {"text": "is", "start": 54, "end": 56, "i_start": 8, "i_end": 8}}, {"character": {"text": "island", "start": 103, "end": 109, "i_start": 16, "i_end": 16}, "action": {"text": "oscillating", "start": 91, "end": 102, "i_start": 15, "i_end": 15}}], "id": 60},{"sent": "deep neural networks have demonstrated extraordinary success in a variety of fields such as computer vision .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "extraordinary", "success", "in", "a", "variety", "of", "fields", "such", "as", "computer", "vision", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 53, "end": 60, "i_start": 6, "i_end": 6}}], "id": 61},{"sent": "density functional theory calculations were performed using the vienna ab initio simulation package along with the perdew-burke-ernzerhof generalized gradient approximation exchange-correlation functional .", "tokens": ["density", "functional", "theory", "calculations", "were", "performed", "using", "the", "vienna", "ab", "initio", "simulation", "package", "along", "with", "the", "perdew", "-", "burke", "-", "ernzerhof", "generalized", "gradient", "approximation", "exchange", "-", "correlation", "functional", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "density functional theory calculations", "start": 0, "end": 38, "i_start": 0, "i_end": 3}, "verb": {"text": "were performed", "start": 39, "end": 53, "i_start": 4, "i_end": 5}}], "id": 62},{"sent": "improved upper bounds , breaking this barrier slightly , were given in developed a new approach for constructing ldcs , called mv codes , that have much shorter codeword length than polynomial codes .", "tokens": ["improved", "upper", "bounds", ",", "breaking", "this", "barrier", "slightly", ",", "were", "given", "in", "developed", "a", "new", "approach", "for", "constructing", "ldcs", ",", "called", "mv", "codes", ",", "that", "have", "much", "shorter", "codeword", "length", "than", "polynomial", "codes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "bounds", "start": 15, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "breaking", "start": 24, "end": 32, "i_start": 4, "i_end": 4}}], "id": 63},{"sent": "kim et al propose a 20-layer cnn model known as vdsr , which adopts residual learning and adaptive gradient clipping to ease training difficulty .", "tokens": ["kim", "et", "al", "propose", "a", "20", "-", "layer", "cnn", "model", "known", "as", "vdsr", ",", "which", "adopts", "residual", "learning", "and", "adaptive", "gradient", "clipping", "to", "ease", "training", "difficulty", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "kim et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "propose", "start": 10, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "kim", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "propose", "start": 10, "end": 17, "i_start": 3, "i_end": 3}}, {"character": {"text": "model", "start": 33, "end": 38, "i_start": 9, "i_end": 9}, "action": {"text": "adopts", "start": 61, "end": 67, "i_start": 15, "i_end": 15}}, {"character": {"text": "learning", "start": 77, "end": 85, "i_start": 17, "i_end": 17}, "action": {"text": "ease", "start": 120, "end": 124, "i_start": 23, "i_end": 23}}, {"character": {"text": "residual", "start": 68, "end": 76, "i_start": 16, "i_end": 16}, "action": {"text": "ease", "start": 120, "end": 124, "i_start": 23, "i_end": 23}}, {"character": {"text": "clipping", "start": 108, "end": 116, "i_start": 21, "i_end": 21}, "action": {"text": "ease", "start": 120, "end": 124, "i_start": 23, "i_end": 23}}, {"character": {"text": "gradient", "start": 99, "end": 107, "i_start": 20, "i_end": 20}, "action": {"text": "ease", "start": 120, "end": 124, "i_start": 23, "i_end": 23}}], "id": 64},{"sent": "because the method does not involve the movement of any mechanical or optical components during the measurement process , it can be readily applied to fragile fibers .", "tokens": ["because", "the", "method", "does", "not", "involve", "the", "movement", "of", "any", "mechanical", "or", "optical", "components", "during", "the", "measurement", "process", ",", "it", "can", "be", "readily", "applied", "to", "fragile", "fibers", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 122, "end": 124, "i_start": 19, "i_end": 19}, "verb": {"text": "applied", "start": 140, "end": 147, "i_start": 23, "i_end": 23}}, {"subject": {"text": "it", "start": 122, "end": 124, "i_start": 19, "i_end": 19}, "verb": {"text": "can be", "start": 125, "end": 131, "i_start": 20, "i_end": 21}}, {"character": {"text": "not involve", "start": 24, "end": 35, "i_start": 4, "i_end": 5}, "action": {"text": "because", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}], "id": 65},{"sent": "we prove this theorem using a reduction from minimum feedback arc set , a wellknown np-complete problem .", "tokens": ["we", "prove", "this", "theorem", "using", "a", "reduction", "from", "minimum", "feedback", "arc", "set", ",", "a", "wellknown", "np", "-", "complete", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "prove", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "prove", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 66},{"sent": "this bulging of the combined prior starts to resemble the 2 ball , and is in conflict with the geometrical structures known in the community to be necessary to favor sparse solutions .", "tokens": ["this", "bulging", "of", "the", "combined", "prior", "starts", "to", "resemble", "the", "2", "ball", ",", "and", "is", "in", "conflict", "with", "the", "geometrical", "structures", "known", "in", "the", "community", "to", "be", "necessary", "to", "favor", "sparse", "solutions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "bulging", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "starts", "start": 35, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "bulging", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "conflict", "start": 77, "end": 85, "i_start": 16, "i_end": 16}}, {"character": {"text": "bulging", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "favor", "start": 160, "end": 165, "i_start": 29, "i_end": 29}}, {"character": {"text": "community", "start": 131, "end": 140, "i_start": 24, "i_end": 24}, "action": {"text": "known", "start": 118, "end": 123, "i_start": 21, "i_end": 21}}], "id": 67},{"sent": "it means that the approximation ignoring the turbulent fluctuations employed by traditional tran sition theories could overestimate the range where hysteresis is observed and statistical analyses are inevitably needed .", "tokens": ["it", "means", "that", "the", "approximation", "ignoring", "the", "turbulent", "fluctuations", "employed", "by", "traditional", "tran", "sition", "theories", "could", "overestimate", "the", "range", "where", "hysteresis", "is", "observed", "and", "statistical", "analyses", "are", "inevitably", "needed", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "means", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the approximation ignoring the turbulent fluctuations employed by traditional tran sition theories", "start": 14, "end": 112, "i_start": 3, "i_end": 14}, "verb": {"text": "overestimate", "start": 119, "end": 131, "i_start": 16, "i_end": 16}}, {"subject": {"text": "analyses", "start": 187, "end": 195, "i_start": 25, "i_end": 25}, "verb": {"text": "needed", "start": 211, "end": 217, "i_start": 28, "i_end": 28}}, {"character": {"text": "approximation", "start": 18, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "overestimate", "start": 119, "end": 131, "i_start": 16, "i_end": 16}}, {"character": {"text": "approximation", "start": 18, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "ignoring", "start": 32, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "theories", "start": 104, "end": 112, "i_start": 14, "i_end": 14}, "action": {"text": "employed", "start": 68, "end": 76, "i_start": 9, "i_end": 9}}], "id": 68},{"sent": "solubilization of rat brain mitochondrial hexokinase by three .", "tokens": ["solubilization", "of", "rat", "brain", "mitochondrial", "hexokinase", "by", "three", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 69},{"sent": "the shower selection criterion is the triggering of any four adjacent detectors in the course of time gate less than 3 2 ns .", "tokens": ["the", "shower", "selection", "criterion", "is", "the", "triggering", "of", "any", "four", "adjacent", "detectors", "in", "the", "course", "of", "time", "gate", "less", "than", "3", "2", "ns", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the shower selection criterion", "start": 0, "end": 30, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 31, "end": 33, "i_start": 4, "i_end": 4}}, {"character": {"text": "four", "start": 56, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "detectors", "start": 70, "end": 79, "i_start": 11, "i_end": 11}}], "id": 70},{"sent": "the simplex programs take as base region the standard simplex of eq .", "tokens": ["the", "simplex", "programs", "take", "as", "base", "region", "the", "standard", "simplex", "of", "eq", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the simplex programs", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "take", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "programs", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "take", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}], "id": 71},{"sent": "convolutional neural networks have demonstrated impressive performance on computer vision tasks .", "tokens": ["convolutional", "neural", "networks", "have", "demonstrated", "impressive", "performance", "on", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 30, "end": 47, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 35, "end": 47, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 59, "end": 70, "i_start": 6, "i_end": 6}}, {"character": {"text": "performance", "start": 59, "end": 70, "i_start": 6, "i_end": 6}, "action": {"text": "impressive", "start": 48, "end": 58, "i_start": 5, "i_end": 5}}], "id": 72},{"sent": "perplexity is the exponential of the cross entropy , which we will define next .", "tokens": ["perplexity", "is", "the", "exponential", "of", "the", "cross", "entropy", ",", "which", "we", "will", "define", "next", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "perplexity", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 59, "end": 61, "i_start": 10, "i_end": 10}, "action": {"text": "define", "start": 67, "end": 73, "i_start": 12, "i_end": 12}}], "id": 73},{"sent": "jie et al proposed a self-taught learning approach in which alternates between classifier training and online supportive sample harvesting .", "tokens": ["jie", "et", "al", "proposed", "a", "self", "-", "taught", "learning", "approach", "in", "which", "alternates", "between", "classifier", "training", "and", "online", "supportive", "sample", "harvesting", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "jie et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "jie", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "jie", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "taught", "start": 26, "end": 32, "i_start": 7, "i_end": 7}}, {"character": {"text": "approach", "start": 42, "end": 50, "i_start": 9, "i_end": 9}, "action": {"text": "alternates", "start": 60, "end": 70, "i_start": 12, "i_end": 12}}, {"character": {"text": "harvesting", "start": 128, "end": 138, "i_start": 20, "i_end": 20}, "action": {"text": "supportive", "start": 110, "end": 120, "i_start": 18, "i_end": 18}}], "id": 74},{"sent": "other approaches in bipartite graphs include frequent closed itemset mining .", "tokens": ["other", "approaches", "in", "bipartite", "graphs", "include", "frequent", "closed", "itemset", "mining", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "other approaches in bipartite graphs", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "include", "start": 37, "end": 44, "i_start": 5, "i_end": 5}}], "id": 75},{"sent": "a closely related area to our subproblem of choosing coordination leaders is leader election , where a group of agents has to jointly determine a leader .", "tokens": ["a", "closely", "related", "area", "to", "our", "subproblem", "of", "choosing", "coordination", "leaders", "is", "leader", "election", ",", "where", "a", "group", "of", "agents", "has", "to", "jointly", "determine", "a", "leader", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a closely related area to our subproblem of choosing coordination leaders", "start": 0, "end": 73, "i_start": 0, "i_end": 10}, "verb": {"text": "is", "start": 74, "end": 76, "i_start": 11, "i_end": 11}}, {"character": {"text": "group", "start": 103, "end": 108, "i_start": 17, "i_end": 17}, "action": {"text": "determine", "start": 134, "end": 143, "i_start": 23, "i_end": 23}}], "id": 76},{"sent": "massive mimo and small cell are recognized as two key technologies for 5g wireless systems due to their great potential to enhance network capacity .", "tokens": ["massive", "mimo", "and", "small", "cell", "are", "recognized", "as", "two", "key", "technologies", "for", "5", "g", "wireless", "systems", "due", "to", "their", "great", "potential", "to", "enhance", "network", "capacity", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "massive mimo and small cell", "start": 0, "end": 27, "i_start": 0, "i_end": 4}, "verb": {"text": "are recognized", "start": 28, "end": 42, "i_start": 5, "i_end": 6}}, {"character": {"text": "cell", "start": 23, "end": 27, "i_start": 4, "i_end": 4}, "action": {"text": "enhance", "start": 123, "end": 130, "i_start": 22, "i_end": 22}}, {"character": {"text": "massive", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "enhance", "start": 123, "end": 130, "i_start": 22, "i_end": 22}}, {"character": {"text": "small", "start": 17, "end": 22, "i_start": 3, "i_end": 3}, "action": {"text": "enhance", "start": 123, "end": 130, "i_start": 22, "i_end": 22}}], "id": 77},{"sent": "consistently with our bayesian methodology , rather than performing model selection we can account for uncertainty over models by combining them using bayesian model averaging .", "tokens": ["consistently", "with", "our", "bayesian", "methodology", ",", "rather", "than", "performing", "model", "selection", "we", "can", "account", "for", "uncertainty", "over", "models", "by", "combining", "them", "using", "bayesian", "model", "averaging", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 84, "end": 86, "i_start": 11, "i_end": 11}, "verb": {"text": "can account", "start": 87, "end": 98, "i_start": 12, "i_end": 13}}, {"character": {"text": "we", "start": 84, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "account", "start": 91, "end": 98, "i_start": 13, "i_end": 13}}, {"character": {"text": "we", "start": 84, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "combining", "start": 130, "end": 139, "i_start": 19, "i_end": 19}}, {"character": {"text": "we", "start": 84, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "using", "start": 145, "end": 150, "i_start": 21, "i_end": 21}}, {"character": {"text": "we", "start": 84, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "performing", "start": 57, "end": 67, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 84, "end": 86, "i_start": 11, "i_end": 11}, "action": {"text": "selection", "start": 74, "end": 83, "i_start": 10, "i_end": 10}}], "id": 78},{"sent": "convolutional neural networks have achieved great success in grid structure data such as image and video .", "tokens": ["convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "grid", "structure", "data", "such", "as", "image", "and", "video", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have achieved", "start": 30, "end": 43, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 50, "end": 57, "i_start": 6, "i_end": 6}}], "id": 79},{"sent": "complex networks are loosely defined as networks with non-trivial structure and dynamics , appearing in many real-world systems .", "tokens": ["complex", "networks", "are", "loosely", "defined", "as", "networks", "with", "non", "-", "trivial", "structure", "and", "dynamics", ",", "appearing", "in", "many", "real", "-", "world", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "complex networks", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "defined", "start": 29, "end": 36, "i_start": 4, "i_end": 4}}, {"subject": {"text": "complex networks", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 17, "end": 20, "i_start": 2, "i_end": 2}}], "id": 80},{"sent": "rea , published by the investment company institute .", "tokens": ["rea", ",", "published", "by", "the", "investment", "company", "institute", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "company", "start": 34, "end": 41, "i_start": 6, "i_end": 6}, "action": {"text": "investment", "start": 23, "end": 33, "i_start": 5, "i_end": 5}}], "id": 81},{"sent": "community detection in large-scale social networks .", "tokens": ["community", "detection", "in", "large", "-", "scale", "social", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 82},{"sent": "the olympic sports dataset was collected from youtube sequences and contains 16 different sports categories with 50 sequences per class .", "tokens": ["the", "olympic", "sports", "dataset", "was", "collected", "from", "youtube", "sequences", "and", "contains", "16", "different", "sports", "categories", "with", "50", "sequences", "per", "class", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the olympic sports dataset", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "was collected", "start": 27, "end": 40, "i_start": 4, "i_end": 5}}, {"subject": {"text": "the olympic sports dataset", "start": 0, "end": 26, "i_start": 0, "i_end": 3}, "verb": {"text": "contains", "start": 68, "end": 76, "i_start": 10, "i_end": 10}}, {"character": {"text": "collected", "start": 31, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "contains", "start": 68, "end": 76, "i_start": 10, "i_end": 10}}], "id": 83},{"sent": "we optimize using a gradient descent approach starting from a randomly sampled code z .", "tokens": ["we", "optimize", "using", "a", "gradient", "descent", "approach", "starting", "from", "a", "randomly", "sampled", "code", "z", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "optimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "optimize", "start": 3, "end": 11, "i_start": 1, "i_end": 1}}], "id": 84},{"sent": "we use batch normalization for regularization of fully connected layers .", "tokens": ["we", "use", "batch", "normalization", "for", "regularization", "of", "fully", "connected", "layers", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 85},{"sent": "a batch normalization layer are performed after each convolution layer consecutively .", "tokens": ["a", "batch", "normalization", "layer", "are", "performed", "after", "each", "convolution", "layer", "consecutively", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a batch normalization layer", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "are performed", "start": 28, "end": 41, "i_start": 4, "i_end": 5}}], "id": 86},{"sent": "the modules are bonded to an aluminum strong-back that is mounted on the external support .", "tokens": ["the", "modules", "are", "bonded", "to", "an", "aluminum", "strong", "-", "back", "that", "is", "mounted", "on", "the", "external", "support", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the modules", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "are bonded", "start": 12, "end": 22, "i_start": 2, "i_end": 3}}], "id": 87},{"sent": "farabet et al trained a multiscale convolutional network from raw pixels to extract dense features for assigning the label to each pixel .", "tokens": ["farabet", "et", "al", "trained", "a", "multiscale", "convolutional", "network", "from", "raw", "pixels", "to", "extract", "dense", "features", "for", "assigning", "the", "label", "to", "each", "pixel", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "farabet et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "trained", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "farabet", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "trained", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "network", "start": 49, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "extract", "start": 76, "end": 83, "i_start": 12, "i_end": 12}}, {"character": {"text": "network", "start": 49, "end": 56, "i_start": 7, "i_end": 7}, "action": {"text": "assigning", "start": 103, "end": 112, "i_start": 16, "i_end": 16}}], "id": 88},{"sent": "this non-locality is a reflection of the fact that at leading power in \u03bb the total momentum in such interactions is not conserved .", "tokens": ["this", "non", "-", "locality", "is", "a", "reflection", "of", "the", "fact", "that", "at", "leading", "power", "in", "\u03bb", "the", "total", "momentum", "in", "such", "interactions", "is", "not", "conserved", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this non-locality", "start": 0, "end": 17, "i_start": 0, "i_end": 3}, "verb": {"text": "is", "start": 18, "end": 20, "i_start": 4, "i_end": 4}}, {"character": {"text": "power", "start": 62, "end": 67, "i_start": 13, "i_end": 13}, "action": {"text": "leading", "start": 54, "end": 61, "i_start": 12, "i_end": 12}}], "id": 89},{"sent": "for exchange and correlation we applied the gradient corrected approach using the generalized gradient approximation functional following the approach suggested by perdew-burke-ernzerhof .", "tokens": ["for", "exchange", "and", "correlation", "we", "applied", "the", "gradient", "corrected", "approach", "using", "the", "generalized", "gradient", "approximation", "functional", "following", "the", "approach", "suggested", "by", "perdew", "-", "burke", "-", "ernzerhof", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 29, "end": 31, "i_start": 4, "i_end": 4}, "verb": {"text": "applied", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "applied", "start": 32, "end": 39, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 29, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "using", "start": 72, "end": 77, "i_start": 10, "i_end": 10}}, {"character": {"text": "perdew", "start": 164, "end": 170, "i_start": 21, "i_end": 21}, "action": {"text": "suggested", "start": 151, "end": 160, "i_start": 19, "i_end": 19}}], "id": 90},{"sent": "this geometry is a trumpet with curvature singularity at the origin of the coordinate system , and it is dual to the semi-infinite cigar .", "tokens": ["this", "geometry", "is", "a", "trumpet", "with", "curvature", "singularity", "at", "the", "origin", "of", "the", "coordinate", "system", ",", "and", "it", "is", "dual", "to", "the", "semi", "-", "infinite", "cigar", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "this geometry", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}], "id": 91},{"sent": "the interplay between the lhc and lc could be qualitatively rather different in different regions of the mssm parameter space .", "tokens": ["the", "interplay", "between", "the", "lhc", "and", "lc", "could", "be", "qualitatively", "rather", "different", "in", "different", "regions", "of", "the", "mssm", "parameter", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the interplay between the lhc and lc", "start": 0, "end": 36, "i_start": 0, "i_end": 6}, "verb": {"text": "could be", "start": 37, "end": 45, "i_start": 7, "i_end": 8}}], "id": 92},{"sent": "the masslessness of the dirac fermion is protected by the quantum order and the associated psg .", "tokens": ["the", "masslessness", "of", "the", "dirac", "fermion", "is", "protected", "by", "the", "quantum", "order", "and", "the", "associated", "psg", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the masslessness of the dirac fermion", "start": 0, "end": 37, "i_start": 0, "i_end": 5}, "verb": {"text": "is protected", "start": 38, "end": 50, "i_start": 6, "i_end": 7}}, {"character": {"text": "order", "start": 66, "end": 71, "i_start": 11, "i_end": 11}, "action": {"text": "protected", "start": 41, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "quantum", "start": 58, "end": 65, "i_start": 10, "i_end": 10}, "action": {"text": "protected", "start": 41, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "psg", "start": 91, "end": 94, "i_start": 15, "i_end": 15}, "action": {"text": "protected", "start": 41, "end": 50, "i_start": 7, "i_end": 7}}, {"character": {"text": "quantum", "start": 58, "end": 65, "i_start": 10, "i_end": 10}, "action": {"text": "protected", "start": 41, "end": 50, "i_start": 7, "i_end": 7}}], "id": 93},{"sent": "the clump consists of a mixture of red helium burning stars and rgb stars of different ages .", "tokens": ["the", "clump", "consists", "of", "a", "mixture", "of", "red", "helium", "burning", "stars", "and", "rgb", "stars", "of", "different", "ages", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the clump", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 10, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "stars", "start": 54, "end": 59, "i_start": 10, "i_end": 10}, "action": {"text": "burning", "start": 46, "end": 53, "i_start": 9, "i_end": 9}}], "id": 94},{"sent": "deep convolutional neural networks have been successful in many computer vision tasks including image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successful", "in", "many", "computer", "vision", "tasks", "including", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "successful", "start": 45, "end": 55, "i_start": 6, "i_end": 6}}], "id": 95},{"sent": "the ellipsis denotes higher order contributions to vortex interactions .", "tokens": ["the", "ellipsis", "denotes", "higher", "order", "contributions", "to", "vortex", "interactions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the ellipsis", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "denotes", "start": 13, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "ellipsis", "start": 4, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "denotes", "start": 13, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "vortex", "start": 51, "end": 57, "i_start": 7, "i_end": 7}, "action": {"text": "interactions", "start": 58, "end": 70, "i_start": 8, "i_end": 8}}], "id": 96},{"sent": "deep neural networks achieve state-of-the-art performance in a variety of domains including image classification , machine translation , and text-to-speech .", "tokens": ["deep", "neural", "networks", "achieve", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "a", "variety", "of", "domains", "including", "image", "classification", ",", "machine", "translation", ",", "and", "text", "-", "to", "-", "speech", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "achieve", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "achieve", "start": 21, "end": 28, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 46, "end": 57, "i_start": 11, "i_end": 11}}], "id": 97},{"sent": "moreover , residual learning is a powerful technique proposed to train very deep convolutional neural network .", "tokens": ["moreover", ",", "residual", "learning", "is", "a", "powerful", "technique", "proposed", "to", "train", "very", "deep", "convolutional", "neural", "network", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "residual learning", "start": 11, "end": 28, "i_start": 2, "i_end": 3}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 4, "i_end": 4}}], "id": 98},{"sent": "these nanoblocks combine dna grafted particles with more complicated purely dna based constructs .", "tokens": ["these", "nanoblocks", "combine", "dna", "grafted", "particles", "with", "more", "complicated", "purely", "dna", "based", "constructs", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "these nanoblocks", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "combine", "start": 17, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "nanoblocks", "start": 6, "end": 16, "i_start": 1, "i_end": 1}, "action": {"text": "combine", "start": 17, "end": 24, "i_start": 2, "i_end": 2}}], "id": 99},{"sent": "when the target space is a twistor space these deformations are mapped to fluctuations of the metric , ie perturbative states of gravity .", "tokens": ["when", "the", "target", "space", "is", "a", "twistor", "space", "these", "deformations", "are", "mapped", "to", "fluctuations", "of", "the", "metric", ",", "ie", "perturbative", "states", "of", "gravity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the target space", "start": 5, "end": 21, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 22, "end": 24, "i_start": 4, "i_end": 4}}], "id": 100},{"sent": "deep neural networks have demonstrated significant performance improvements in a wide range of computer vision tasks .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "significant", "performance", "improvements", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improvements", "start": 63, "end": 75, "i_start": 7, "i_end": 7}}], "id": 101},{"sent": "it as been proved that this approach is the only one that preserves altitudes of the passes between regions of the segmentation .", "tokens": ["it", "as", "been", "proved", "that", "this", "approach", "is", "the", "only", "one", "that", "preserves", "altitudes", "of", "the", "passes", "between", "regions", "of", "the", "segmentation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "been proved", "start": 6, "end": 17, "i_start": 2, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 37, "end": 39, "i_start": 7, "i_end": 7}}, {"character": {"text": "approach", "start": 28, "end": 36, "i_start": 6, "i_end": 6}, "action": {"text": "preserves", "start": 58, "end": 67, "i_start": 12, "i_end": 12}}], "id": 102},{"sent": "by sharing features between proposal generation and classification , r-c3d reduces computational cost significantly .", "tokens": ["by", "sharing", "features", "between", "proposal", "generation", "and", "classification", ",", "r", "-", "c3d", "reduces", "computational", "cost", "significantly", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "r-c3d", "start": 69, "end": 74, "i_start": 9, "i_end": 11}, "verb": {"text": "reduces", "start": 75, "end": 82, "i_start": 12, "i_end": 12}}], "id": 103},{"sent": "to the extent that these are valid assumptions , we obtain the correct two-photon amplitudes and can obtain the corrected form factors .", "tokens": ["to", "the", "extent", "that", "these", "are", "valid", "assumptions", ",", "we", "obtain", "the", "correct", "two", "-", "photon", "amplitudes", "and", "can", "obtain", "the", "corrected", "form", "factors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "verb": {"text": "obtain", "start": 52, "end": 58, "i_start": 10, "i_end": 10}}, {"subject": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "verb": {"text": "obtain", "start": 101, "end": 107, "i_start": 19, "i_end": 19}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "action": {"text": "obtain", "start": 52, "end": 58, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 49, "end": 51, "i_start": 9, "i_end": 9}, "action": {"text": "obtain", "start": 101, "end": 107, "i_start": 19, "i_end": 19}}], "id": 104},{"sent": "recently , deep neural networks have substantially improved the state-of-the-art performances of various challenging classification tasks , including image based object recognition .", "tokens": ["recently", ",", "deep", "neural", "networks", "have", "substantially", "improved", "the", "state", "-", "of", "-", "the", "-", "art", "performances", "of", "various", "challenging", "classification", "tasks", ",", "including", "image", "based", "object", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "improved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep neural networks", "start": 11, "end": 31, "i_start": 2, "i_end": 4}, "verb": {"text": "have", "start": 32, "end": 36, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "improved", "start": 51, "end": 59, "i_start": 7, "i_end": 7}}, {"character": {"text": "networks", "start": 23, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "performances", "start": 81, "end": 93, "i_start": 16, "i_end": 16}}, {"character": {"text": "tasks", "start": 132, "end": 137, "i_start": 21, "i_end": 21}, "action": {"text": "classification", "start": 117, "end": 131, "i_start": 20, "i_end": 20}}], "id": 105},{"sent": "the parafermion and paraboson fock spaces are characterized by a parameter p , and their explicit construction was given recently in and in .", "tokens": ["the", "parafermion", "and", "paraboson", "fock", "spaces", "are", "characterized", "by", "a", "parameter", "p", ",", "and", "their", "explicit", "construction", "was", "given", "recently", "in", "and", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the parafermion and paraboson fock spaces", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "are characterized", "start": 42, "end": 59, "i_start": 6, "i_end": 7}}, {"subject": {"text": "their explicit construction", "start": 83, "end": 110, "i_start": 14, "i_end": 16}, "verb": {"text": "given", "start": 115, "end": 120, "i_start": 18, "i_end": 18}}], "id": 106},{"sent": "two of the most commonly used and efficient approaches are vae and generative adversarial networks .", "tokens": ["two", "of", "the", "most", "commonly", "used", "and", "efficient", "approaches", "are", "vae", "and", "generative", "adversarial", "networks", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "two of the most commonly used and efficient approaches", "start": 0, "end": 54, "i_start": 0, "i_end": 8}, "verb": {"text": "are", "start": 55, "end": 58, "i_start": 9, "i_end": 9}}], "id": 107},{"sent": "recently , convolutional neural networks are driving advances in computer vision , such as for image classification .", "tokens": ["recently", ",", "convolutional", "neural", "networks", "are", "driving", "advances", "in", "computer", "vision", ",", "such", "as", "for", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 11, "end": 40, "i_start": 2, "i_end": 4}, "verb": {"text": "are driving", "start": 41, "end": 52, "i_start": 5, "i_end": 6}}, {"character": {"text": "networks", "start": 32, "end": 40, "i_start": 4, "i_end": 4}, "action": {"text": "driving", "start": 45, "end": 52, "i_start": 6, "i_end": 6}}], "id": 108},{"sent": "artificial neural networks are a powerful tool in machine learning and have been successfully applied to many problems in fields such as computer vision .", "tokens": ["artificial", "neural", "networks", "are", "a", "powerful", "tool", "in", "machine", "learning", "and", "have", "been", "successfully", "applied", "to", "many", "problems", "in", "fields", "such", "as", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "artificial neural networks", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 27, "end": 30, "i_start": 3, "i_end": 3}}, {"subject": {"text": "artificial neural networks", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "applied", "start": 94, "end": 101, "i_start": 14, "i_end": 14}}], "id": 109},{"sent": "the exact quantum effective superpotential for the glueball field was proposed by dijkgraaf and vafa using a zero-dimensional matrix model .", "tokens": ["the", "exact", "quantum", "effective", "superpotential", "for", "the", "glueball", "field", "was", "proposed", "by", "dijkgraaf", "and", "vafa", "using", "a", "zero", "-", "dimensional", "matrix", "model", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "dijkgraaf", "start": 82, "end": 91, "i_start": 12, "i_end": 12}, "action": {"text": "proposed", "start": 70, "end": 78, "i_start": 10, "i_end": 10}}, {"character": {"text": "vafa", "start": 96, "end": 100, "i_start": 14, "i_end": 14}, "action": {"text": "proposed", "start": 70, "end": 78, "i_start": 10, "i_end": 10}}], "id": 110},{"sent": "information geometry and statistical pattern recognition .", "tokens": ["information", "geometry", "and", "statistical", "pattern", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 111},{"sent": "zou et al designed an intensity-difference measuring function to find the optimal threshold for pavement crack segmentation .", "tokens": ["zou", "et", "al", "designed", "an", "intensity", "-", "difference", "measuring", "function", "to", "find", "the", "optimal", "threshold", "for", "pavement", "crack", "segmentation", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 4, "end": 9, "i_start": 1, "i_end": 2}, "verb": {"text": "designed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "zou", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "designed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "zou", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 65, "end": 69, "i_start": 11, "i_end": 11}}], "id": 112},{"sent": "as for the existence for general pseudoeffective line bundles , now we have the following theorem .", "tokens": ["as", "for", "the", "existence", "for", "general", "pseudoeffective", "line", "bundles", ",", "now", "we", "have", "the", "following", "theorem", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 68, "end": 70, "i_start": 11, "i_end": 11}, "verb": {"text": "have", "start": 71, "end": 75, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 68, "end": 70, "i_start": 11, "i_end": 11}, "action": {"text": "have", "start": 71, "end": 75, "i_start": 12, "i_end": 12}}], "id": 113},{"sent": "convolutional neural networks have proven to be effective models for tackling a variety of visual tasks .", "tokens": ["convolutional", "neural", "networks", "have", "proven", "to", "be", "effective", "models", "for", "tackling", "a", "variety", "of", "visual", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have proven", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "models", "start": 58, "end": 64, "i_start": 8, "i_end": 8}, "action": {"text": "effective", "start": 48, "end": 57, "i_start": 7, "i_end": 7}}], "id": 114},{"sent": "the pioneering work is semantic hashing , which uses stacked rbm models to learn compact binary representations .", "tokens": ["the", "pioneering", "work", "is", "semantic", "hashing", ",", "which", "uses", "stacked", "rbm", "models", "to", "learn", "compact", "binary", "representations", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the pioneering work", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "hashing", "start": 32, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "pioneering", "start": 4, "end": 14, "i_start": 1, "i_end": 1}}, {"character": {"text": "hashing", "start": 32, "end": 39, "i_start": 5, "i_end": 5}, "action": {"text": "uses", "start": 48, "end": 52, "i_start": 8, "i_end": 8}}], "id": 115},{"sent": "the major mechanism of dephasing due to coupling to excitations in helium is scattering of thermal ripplons off an electron .", "tokens": ["the", "major", "mechanism", "of", "dephasing", "due", "to", "coupling", "to", "excitations", "in", "helium", "is", "scattering", "of", "thermal", "ripplons", "off", "an", "electron", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the major mechanism of dephasing due to coupling to excitations in helium", "start": 0, "end": 73, "i_start": 0, "i_end": 11}, "verb": {"text": "is scattering", "start": 74, "end": 87, "i_start": 12, "i_end": 13}}, {"character": {"text": "helium", "start": 67, "end": 73, "i_start": 11, "i_end": 11}, "action": {"text": "excitations", "start": 52, "end": 63, "i_start": 9, "i_end": 9}}], "id": 116},{"sent": "in addition , as demonstrated in , llr clipping , when built into the tree search also allows to tune the detection algorithm in terms of performance versus complexity by adjusting the llr clipping level .", "tokens": ["in", "addition", ",", "as", "demonstrated", "in", ",", "llr", "clipping", ",", "when", "built", "into", "the", "tree", "search", "also", "allows", "to", "tune", "the", "detection", "algorithm", "in", "terms", "of", "performance", "versus", "complexity", "by", "adjusting", "the", "llr", "clipping", "level", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "tune", "start": 97, "end": 101, "i_start": 19, "i_end": 19}, "action": {"text": "allows", "start": 87, "end": 93, "i_start": 17, "i_end": 17}}, {"character": {"text": "algorithm", "start": 116, "end": 125, "i_start": 22, "i_end": 22}, "action": {"text": "detection", "start": 106, "end": 115, "i_start": 21, "i_end": 21}}, {"character": {"text": "clipping", "start": 39, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "demonstrated", "start": 17, "end": 29, "i_start": 4, "i_end": 4}}], "id": 117},{"sent": "sparse recovery is one of the essential issues in many fields of signal processing , including compressive sampling , which is a novel sampling theory .", "tokens": ["sparse", "recovery", "is", "one", "of", "the", "essential", "issues", "in", "many", "fields", "of", "signal", "processing", ",", "including", "compressive", "sampling", ",", "which", "is", "a", "novel", "sampling", "theory", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "sparse recovery", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "recovery", "start": 7, "end": 15, "i_start": 1, "i_end": 1}, "action": {"text": "issues", "start": 40, "end": 46, "i_start": 7, "i_end": 7}}], "id": 118},{"sent": "physical layer security has been recently proposed as a complement to cryptography method to provide secure wireless communications .", "tokens": ["physical", "layer", "security", "has", "been", "recently", "proposed", "as", "a", "complement", "to", "cryptography", "method", "to", "provide", "secure", "wireless", "communications", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "physical layer security", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 42, "end": 50, "i_start": 6, "i_end": 6}}, {"subject": {"text": "physical layer security", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "has been", "start": 24, "end": 32, "i_start": 3, "i_end": 4}}], "id": 119},{"sent": "a recent survey of coordinate descent algorithms and their convergence can be found in .", "tokens": ["a", "recent", "survey", "of", "coordinate", "descent", "algorithms", "and", "their", "convergence", "can", "be", "found", "in", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "a recent survey of coordinate descent algorithms and their convergence", "start": 0, "end": 70, "i_start": 0, "i_end": 9}, "verb": {"text": "can be found", "start": 71, "end": 83, "i_start": 10, "i_end": 12}}, {"character": {"text": "algorithms", "start": 38, "end": 48, "i_start": 6, "i_end": 6}, "action": {"text": "convergence", "start": 59, "end": 70, "i_start": 9, "i_end": 9}}], "id": 120},{"sent": "closure is a well-defined operation on semialgebraic chains .", "tokens": ["closure", "is", "a", "well", "-", "defined", "operation", "on", "semialgebraic", "chains", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "closure", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 1, "i_end": 1}}], "id": 121},{"sent": "convolutional neural networks have shown remarkable performance in domains like vision and nlp .", "tokens": ["convolutional", "neural", "networks", "have", "shown", "remarkable", "performance", "in", "domains", "like", "vision", "and", "nlp", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 30, "end": 40, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "shown", "start": 35, "end": 40, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "performance", "start": 52, "end": 63, "i_start": 6, "i_end": 6}}], "id": 122},{"sent": "papernot et al introduced distillation as a defense to adversarial examples .", "tokens": ["papernot", "et", "al", "introduced", "distillation", "as", "a", "defense", "to", "adversarial", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "papernot et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "introduced", "start": 15, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "papernot", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "introduced", "start": 15, "end": 25, "i_start": 3, "i_end": 3}}], "id": 123},{"sent": "a qubit is a physical entity described by the laws of quantum mechanics .", "tokens": ["a", "qubit", "is", "a", "physical", "entity", "described", "by", "the", "laws", "of", "quantum", "mechanics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a qubit", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 2, "i_end": 2}}, {"character": {"text": "laws", "start": 46, "end": 50, "i_start": 9, "i_end": 9}, "action": {"text": "described", "start": 29, "end": 38, "i_start": 6, "i_end": 6}}], "id": 124},{"sent": "deep neural networks have demonstrated success in many machine learning tasks , including image recognition , speech recognition , and even modelling mathematical learning , among many other domains .", "tokens": ["deep", "neural", "networks", "have", "demonstrated", "success", "in", "many", "machine", "learning", "tasks", ",", "including", "image", "recognition", ",", "speech", "recognition", ",", "and", "even", "modelling", "mathematical", "learning", ",", "among", "many", "other", "domains", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have demonstrated", "start": 21, "end": 38, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "demonstrated", "start": 26, "end": 38, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 39, "end": 46, "i_start": 5, "i_end": 5}}], "id": 125},{"sent": "we used the large scale visual recognition challenge 2012 dataset , which is widely employed and easily accessible .", "tokens": ["we", "used", "the", "large", "scale", "visual", "recognition", "challenge", "2012", "dataset", ",", "which", "is", "widely", "employed", "and", "easily", "accessible", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}], "id": 126},{"sent": "the generalized gradient approximation parameterized by perdew-burkeernzerhof for the exchange-correlation functional was used .", "tokens": ["the", "generalized", "gradient", "approximation", "parameterized", "by", "perdew", "-", "burkeernzerhof", "for", "the", "exchange", "-", "correlation", "functional", "was", "used", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the generalized gradient approximation parameterized by perdew-burkeernzerhof for the exchange-correlation functional", "start": 0, "end": 117, "i_start": 0, "i_end": 14}, "verb": {"text": "was used", "start": 118, "end": 126, "i_start": 15, "i_end": 16}}, {"character": {"text": "perdew", "start": 56, "end": 62, "i_start": 6, "i_end": 6}, "action": {"text": "parameterized", "start": 39, "end": 52, "i_start": 4, "i_end": 4}}], "id": 127},{"sent": "the result particularly helps us to prove the equivalence of the two functions in the previous example , as we can show that they are trace equivalent .", "tokens": ["the", "result", "particularly", "helps", "us", "to", "prove", "the", "equivalence", "of", "the", "two", "functions", "in", "the", "previous", "example", ",", "as", "we", "can", "show", "that", "they", "are", "trace", "equivalent", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the result", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "helps", "start": 24, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "us", "start": 30, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "prove", "start": 36, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "us", "start": 30, "end": 32, "i_start": 4, "i_end": 4}, "action": {"text": "show", "start": 115, "end": 119, "i_start": 21, "i_end": 21}}], "id": 128},{"sent": "the dft calculations were carried out by using the projector augmented wave method implemented in the vienna ab initio simulation package .", "tokens": ["the", "dft", "calculations", "were", "carried", "out", "by", "using", "the", "projector", "augmented", "wave", "method", "implemented", "in", "the", "vienna", "ab", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the dft calculations", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "were carried out", "start": 21, "end": 37, "i_start": 3, "i_end": 5}}, {"character": {"text": "projector", "start": 51, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "augmented", "start": 61, "end": 70, "i_start": 10, "i_end": 10}}], "id": 129},{"sent": "conway-gordon showed that k 6 is intrinsically linked , where k n denotes the complete graph on n vertices .", "tokens": ["conway", "-", "gordon", "showed", "that", "k", "6", "is", "intrinsically", "linked", ",", "where", "k", "n", "denotes", "the", "complete", "graph", "on", "n", "vertices", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "conway-gordon", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 14, "end": 20, "i_start": 3, "i_end": 3}}, {"subject": {"text": "k 6", "start": 26, "end": 29, "i_start": 5, "i_end": 6}, "verb": {"text": "linked", "start": 47, "end": 53, "i_start": 9, "i_end": 9}}, {"character": {"text": "conway", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 14, "end": 20, "i_start": 3, "i_end": 3}}, {"character": {"text": "graph", "start": 87, "end": 92, "i_start": 17, "i_end": 17}, "action": {"text": "denotes", "start": 66, "end": 73, "i_start": 14, "i_end": 14}}], "id": 130},{"sent": "the networks were trained through stochastic gradient descent , using the adam optimizer .", "tokens": ["the", "networks", "were", "trained", "through", "stochastic", "gradient", "descent", ",", "using", "the", "adam", "optimizer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the networks", "start": 0, "end": 12, "i_start": 0, "i_end": 1}, "verb": {"text": "were trained", "start": 13, "end": 25, "i_start": 2, "i_end": 3}}], "id": 131},{"sent": "in this way it seems that the type of temporal description of physical processes we have at the classical level can not be seen as emerging from the quantum level of description .", "tokens": ["in", "this", "way", "it", "seems", "that", "the", "type", "of", "temporal", "description", "of", "physical", "processes", "we", "have", "at", "the", "classical", "level", "can", "not", "be", "seen", "as", "emerging", "from", "the", "quantum", "level", "of", "description", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 12, "end": 14, "i_start": 3, "i_end": 3}, "verb": {"text": "seems", "start": 15, "end": 20, "i_start": 4, "i_end": 4}}, {"subject": {"text": "the type of temporal description of physical processes we have at the classical level", "start": 26, "end": 111, "i_start": 6, "i_end": 19}, "verb": {"text": "seen", "start": 123, "end": 127, "i_start": 23, "i_end": 23}}, {"character": {"text": "description", "start": 47, "end": 58, "i_start": 10, "i_end": 10}, "action": {"text": "emerging", "start": 131, "end": 139, "i_start": 25, "i_end": 25}}, {"character": {"text": "we", "start": 81, "end": 83, "i_start": 14, "i_end": 14}, "action": {"text": "have", "start": 84, "end": 88, "i_start": 15, "i_end": 15}}], "id": 132},{"sent": "in hermitian systems , the winding number has been directly measured by the mean chiral displacement in photonic quantum walks .", "tokens": ["in", "hermitian", "systems", ",", "the", "winding", "number", "has", "been", "directly", "measured", "by", "the", "mean", "chiral", "displacement", "in", "photonic", "quantum", "walks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the winding number", "start": 23, "end": 41, "i_start": 4, "i_end": 6}, "verb": {"text": "measured", "start": 60, "end": 68, "i_start": 10, "i_end": 10}}, {"subject": {"text": "the winding number", "start": 23, "end": 41, "i_start": 4, "i_end": 6}, "verb": {"text": "has been", "start": 42, "end": 50, "i_start": 7, "i_end": 8}}], "id": 133},{"sent": "a robust and widely used method for discovering topics is latent dirichlet allocation .", "tokens": ["a", "robust", "and", "widely", "used", "method", "for", "discovering", "topics", "is", "latent", "dirichlet", "allocation", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a robust and widely used method for discovering topics", "start": 0, "end": 54, "i_start": 0, "i_end": 8}, "verb": {"text": "is", "start": 55, "end": 57, "i_start": 9, "i_end": 9}}], "id": 134},{"sent": "we also use an adversarial loss to approximate the distribution of optical flow .", "tokens": ["we", "also", "use", "an", "adversarial", "loss", "to", "approximate", "the", "distribution", "of", "optical", "flow", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 8, "end": 11, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "approximate", "start": 35, "end": 46, "i_start": 7, "i_end": 7}}], "id": 135},{"sent": "deep learning has increasingly drawn attentions in many research fields , such as speech recognition .", "tokens": ["deep", "learning", "has", "increasingly", "drawn", "attentions", "in", "many", "research", "fields", ",", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "drawn", "start": 31, "end": 36, "i_start": 4, "i_end": 4}}, {"subject": {"text": "deep learning", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "has", "start": 14, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "learning", "start": 5, "end": 13, "i_start": 1, "i_end": 1}, "action": {"text": "drawn", "start": 31, "end": 36, "i_start": 4, "i_end": 4}}], "id": 136},{"sent": "such an effective theory is known as chiral perturbation theory .", "tokens": ["such", "an", "effective", "theory", "is", "known", "as", "chiral", "perturbation", "theory", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "such an effective theory", "start": 0, "end": 24, "i_start": 0, "i_end": 3}, "verb": {"text": "is known", "start": 25, "end": 33, "i_start": 4, "i_end": 5}}, {"character": {"text": "theory", "start": 18, "end": 24, "i_start": 3, "i_end": 3}, "action": {"text": "effective", "start": 8, "end": 17, "i_start": 2, "i_end": 2}}], "id": 137},{"sent": "a fictitious domain method for dirichlet problem and applications .", "tokens": ["a", "fictitious", "domain", "method", "for", "dirichlet", "problem", "and", "applications", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 138},{"sent": "the malcev closure g of \u03b3 is a simply connected nilpotent lie group in which \u03b3 embeds as a uniform lattice .", "tokens": ["the", "malcev", "closure", "g", "of", "\u03b3", "is", "a", "simply", "connected", "nilpotent", "lie", "group", "in", "which", "\u03b3", "embeds", "as", "a", "uniform", "lattice", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the malcev closure g of \u03b3", "start": 0, "end": 25, "i_start": 0, "i_end": 5}, "verb": {"text": "is", "start": 26, "end": 28, "i_start": 6, "i_end": 6}}], "id": 139},{"sent": "to have fair comparisons with the previous methods , we use the pre-trained vgg-16 as visual cnn , respectively .", "tokens": ["to", "have", "fair", "comparisons", "with", "the", "previous", "methods", ",", "we", "use", "the", "pre", "-", "trained", "vgg-16", "as", "visual", "cnn", ",", "respectively", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 53, "end": 55, "i_start": 9, "i_end": 9}, "verb": {"text": "use", "start": 56, "end": 59, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 53, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "use", "start": 56, "end": 59, "i_start": 10, "i_end": 10}}], "id": 140},{"sent": "the outer error bars represent the systematic and model errors .", "tokens": ["the", "outer", "error", "bars", "represent", "the", "systematic", "and", "model", "errors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the outer error bars", "start": 0, "end": 20, "i_start": 0, "i_end": 3}, "verb": {"text": "represent", "start": 21, "end": 30, "i_start": 4, "i_end": 4}}, {"character": {"text": "bars", "start": 16, "end": 20, "i_start": 3, "i_end": 3}, "action": {"text": "represent", "start": 21, "end": 30, "i_start": 4, "i_end": 4}}], "id": 141},{"sent": "for instance , it was shown recently in a group of subjects of different age , that the bold signal standard deviation can be a better predictor of the subject age than the average .", "tokens": ["for", "instance", ",", "it", "was", "shown", "recently", "in", "a", "group", "of", "subjects", "of", "different", "age", ",", "that", "the", "bold", "signal", "standard", "deviation", "can", "be", "a", "better", "predictor", "of", "the", "subject", "age", "than", "the", "average", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "was shown", "start": 18, "end": 27, "i_start": 4, "i_end": 5}}, {"subject": {"text": "it", "start": 15, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "be", "start": 123, "end": 125, "i_start": 23, "i_end": 23}}, {"character": {"text": "standard", "start": 100, "end": 108, "i_start": 20, "i_end": 20}, "action": {"text": "predictor", "start": 135, "end": 144, "i_start": 26, "i_end": 26}}], "id": 142},{"sent": "poisson and symplectic groupoids were introduced by weinstein in in the late eighties .", "tokens": ["poisson", "and", "symplectic", "groupoids", "were", "introduced", "by", "weinstein", "in", "in", "the", "late", "eighties", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "poisson and symplectic groupoids", "start": 0, "end": 32, "i_start": 0, "i_end": 3}, "verb": {"text": "were introduced", "start": 33, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "weinstein", "start": 52, "end": 61, "i_start": 7, "i_end": 7}, "action": {"text": "introduced", "start": 38, "end": 48, "i_start": 5, "i_end": 5}}], "id": 143},{"sent": "we shall also provide new results for the unquenched theory in the same finite-volume regime , but restricted to fixed topology .", "tokens": ["we", "shall", "also", "provide", "new", "results", "for", "the", "unquenched", "theory", "in", "the", "same", "finite", "-", "volume", "regime", ",", "but", "restricted", "to", "fixed", "topology", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "provide", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "shall", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "restricted", "start": 99, "end": 109, "i_start": 19, "i_end": 19}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "provide", "start": 14, "end": 21, "i_start": 3, "i_end": 3}}], "id": 144},{"sent": "images were processed using the miriad 5 software package .", "tokens": ["images", "were", "processed", "using", "the", "miriad", "5", "software", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "images", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "verb": {"text": "were processed", "start": 7, "end": 21, "i_start": 1, "i_end": 2}}], "id": 145},{"sent": "the insets show the shape of the linear modes with highest and lowest frequency .", "tokens": ["the", "insets", "show", "the", "shape", "of", "the", "linear", "modes", "with", "highest", "and", "lowest", "frequency", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the insets", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "show", "start": 11, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "insets", "start": 4, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "show", "start": 11, "end": 15, "i_start": 2, "i_end": 2}}], "id": 146},{"sent": "in the riemannian case we consider an electrostatic spacetime where the einstein equations in vacuum in the approximation of linear fields .", "tokens": ["in", "the", "riemannian", "case", "we", "consider", "an", "electrostatic", "spacetime", "where", "the", "einstein", "equations", "in", "vacuum", "in", "the", "approximation", "of", "linear", "fields", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "verb": {"text": "consider", "start": 26, "end": 34, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 23, "end": 25, "i_start": 4, "i_end": 4}, "action": {"text": "consider", "start": 26, "end": 34, "i_start": 5, "i_end": 5}}], "id": 147},{"sent": "tractable learning of large bayes net structures from sparse data .", "tokens": ["tractable", "learning", "of", "large", "bayes", "net", "structures", "from", "sparse", "data", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 148},{"sent": "a d-brane is a u gauge theory living on a subspace with scalar fields spanning the normal bundle .", "tokens": ["a", "d", "-", "brane", "is", "a", "u", "gauge", "theory", "living", "on", "a", "subspace", "with", "scalar", "fields", "spanning", "the", "normal", "bundle", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "d-brane", "start": 2, "end": 9, "i_start": 1, "i_end": 3}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 4, "i_end": 4}}, {"character": {"text": "fields", "start": 63, "end": 69, "i_start": 15, "i_end": 15}, "action": {"text": "spanning", "start": 70, "end": 78, "i_start": 16, "i_end": 16}}], "id": 149}]