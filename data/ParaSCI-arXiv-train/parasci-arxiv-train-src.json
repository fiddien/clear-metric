[{"sent": "we find the optimal alignment of the original manifold and the oose manifold via procrustes analysis and apply the resulting translational , rotational , and scaling components on the oose manifold .", "tokens": ["we", "find", "the", "optimal", "alignment", "of", "the", "original", "manifold", "and", "the", "oose", "manifold", "via", "procrustes", "analysis", "and", "apply", "the", "resulting", "translational", ",", "rotational", ",", "and", "scaling", "components", "on", "the", "oose", "manifold", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "apply", "start": 105, "end": 110, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "analysis", "start": 92, "end": 100, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "apply", "start": 105, "end": 110, "i_start": 17, "i_end": 17}}], "id": 0},{"sent": "neural machine translation has significantly improved the quality of machine translation in recent years .", "tokens": ["neural", "machine", "translation", "has", "significantly", "improved", "the", "quality", "of", "machine", "translation", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural machine translation", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "improved", "start": 45, "end": 53, "i_start": 5, "i_end": 5}}, {"subject": {"text": "neural machine translation", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "has", "start": 27, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "translation", "start": 15, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "improved", "start": 45, "end": 53, "i_start": 5, "i_end": 5}}], "id": 1},{"sent": "based on the van emde boas tree , the sorting operation can be performed with a complexity on the order of o , .", "tokens": ["based", "on", "the", "van", "emde", "boas", "tree", ",", "the", "sorting", "operation", "can", "be", "performed", "with", "a", "complexity", "on", "the", "order", "of", "o", ",", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the sorting operation", "start": 34, "end": 55, "i_start": 8, "i_end": 10}, "verb": {"text": "can be performed", "start": 56, "end": 72, "i_start": 11, "i_end": 13}}], "id": 2},{"sent": "we follow the recent self-localization paradigm based on a deep convolutional neural network .", "tokens": ["we", "follow", "the", "recent", "self", "-", "localization", "paradigm", "based", "on", "a", "deep", "convolutional", "neural", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 3},{"sent": "we find the optimal alignment of the original manifold and the oose manifold via procrustes analysis and apply the resulting translational , rotational , and scaling components on the oose manifold .", "tokens": ["we", "find", "the", "optimal", "alignment", "of", "the", "original", "manifold", "and", "the", "oose", "manifold", "via", "procrustes", "analysis", "and", "apply", "the", "resulting", "translational", ",", "rotational", ",", "and", "scaling", "components", "on", "the", "oose", "manifold", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "apply", "start": 105, "end": 110, "i_start": 17, "i_end": 17}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "find", "start": 3, "end": 7, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "analysis", "start": 92, "end": 100, "i_start": 15, "i_end": 15}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "apply", "start": 105, "end": 110, "i_start": 17, "i_end": 17}}], "id": 0},{"sent": "neural machine translation has significantly improved the quality of machine translation in recent years .", "tokens": ["neural", "machine", "translation", "has", "significantly", "improved", "the", "quality", "of", "machine", "translation", "in", "recent", "years", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "neural machine translation", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "improved", "start": 45, "end": 53, "i_start": 5, "i_end": 5}}, {"subject": {"text": "neural machine translation", "start": 0, "end": 26, "i_start": 0, "i_end": 2}, "verb": {"text": "has", "start": 27, "end": 30, "i_start": 3, "i_end": 3}}, {"character": {"text": "translation", "start": 15, "end": 26, "i_start": 2, "i_end": 2}, "action": {"text": "improved", "start": 45, "end": 53, "i_start": 5, "i_end": 5}}], "id": 1},{"sent": "based on the van emde boas tree , the sorting operation can be performed with a complexity on the order of o , .", "tokens": ["based", "on", "the", "van", "emde", "boas", "tree", ",", "the", "sorting", "operation", "can", "be", "performed", "with", "a", "complexity", "on", "the", "order", "of", "o", ",", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the sorting operation", "start": 34, "end": 55, "i_start": 8, "i_end": 10}, "verb": {"text": "can be performed", "start": 56, "end": 72, "i_start": 11, "i_end": 13}}], "id": 2},{"sent": "we follow the recent self-localization paradigm based on a deep convolutional neural network .", "tokens": ["we", "follow", "the", "recent", "self", "-", "localization", "paradigm", "based", "on", "a", "deep", "convolutional", "neural", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "follow", "start": 3, "end": 9, "i_start": 1, "i_end": 1}}], "id": 3},{"sent": "the weights are initialized using the xavier initialization glorot and bengio .", "tokens": ["the", "weights", "are", "initialized", "using", "the", "xavier", "initialization", "glorot", "and", "bengio", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the weights", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "are initialized", "start": 12, "end": 27, "i_start": 2, "i_end": 3}}], "id": 4},{"sent": "we utilize three standard citation network benchmark datasets-cora , citeseer and pubmed -and closely follow the transductive experimental setup of yang et al .", "tokens": ["we", "utilize", "three", "standard", "citation", "network", "benchmark", "datasets", "-", "cora", ",", "citeseer", "and", "pubmed", "-and", "closely", "follow", "the", "transductive", "experimental", "setup", "of", "yang", "et", "al", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "utilize", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}, {"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "follow", "start": 102, "end": 108, "i_start": 16, "i_end": 16}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "utilize", "start": 3, "end": 10, "i_start": 1, "i_end": 1}}], "id": 5},{"sent": "deep neural networks have been successfully applied to many areas , including speech .", "tokens": ["deep", "neural", "networks", "have", "been", "successfully", "applied", "to", "many", "areas", ",", "including", "speech", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "applied", "start": 44, "end": 51, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have been", "start": 21, "end": 30, "i_start": 3, "i_end": 4}}], "id": 6},{"sent": "the camera consists of 112 ccds , each 600 2400 pixels , which are arranged in 4 rows by 28 columns .", "tokens": ["the", "camera", "consists", "of", "112", "ccds", ",", "each", "600", "2400", "pixels", ",", "which", "are", "arranged", "in", "4", "rows", "by", "28", "columns", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the camera", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "consists", "start": 11, "end": 19, "i_start": 2, "i_end": 2}}], "id": 7},{"sent": "over the past few years , deep convolutional neural networks have been very successful in a wide range of computer vision tasks such as image classification .", "tokens": ["over", "the", "past", "few", "years", ",", "deep", "convolutional", "neural", "networks", "have", "been", "very", "successful", "in", "a", "wide", "range", "of", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 26, "end": 60, "i_start": 6, "i_end": 9}, "verb": {"text": "have been", "start": 61, "end": 70, "i_start": 10, "i_end": 11}}, {"character": {"text": "networks", "start": 52, "end": 60, "i_start": 9, "i_end": 9}, "action": {"text": "successful", "start": 76, "end": 86, "i_start": 13, "i_end": 13}}], "id": 8},{"sent": "convolutional neural networks have proved their dominating spot in various machine learning tasks , such as speech recognition .", "tokens": ["convolutional", "neural", "networks", "have", "proved", "their", "dominating", "spot", "in", "various", "machine", "learning", "tasks", ",", "such", "as", "speech", "recognition", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have proved", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "proved", "start": 35, "end": 41, "i_start": 4, "i_end": 4}}, {"character": {"text": "spot", "start": 59, "end": 63, "i_start": 7, "i_end": 7}, "action": {"text": "dominating", "start": 48, "end": 58, "i_start": 6, "i_end": 6}}], "id": 9},{"sent": "manual delineation is a time-consuming and tedious task that is also prone to high intra-and inter-observer variability .", "tokens": ["manual", "delineation", "is", "a", "time", "-", "consuming", "and", "tedious", "task", "that", "is", "also", "prone", "to", "high", "intra", "-", "and", "inter", "-", "observer", "variability", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "manual delineation", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}, {"character": {"text": "task", "start": 51, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "consuming", "start": 29, "end": 38, "i_start": 6, "i_end": 6}}], "id": 10},{"sent": "recently , deep convolutional neural networks have led to substantial improvements for numerous computer vision tasks like object detection , often achieving human-level performance .", "tokens": ["recently", ",", "deep", "convolutional", "neural", "networks", "have", "led", "to", "substantial", "improvements", "for", "numerous", "computer", "vision", "tasks", "like", "object", "detection", ",", "often", "achieving", "human", "-", "level", "performance", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 11, "end": 45, "i_start": 2, "i_end": 5}, "verb": {"text": "have led", "start": 46, "end": 54, "i_start": 6, "i_end": 7}}, {"character": {"text": "networks", "start": 37, "end": 45, "i_start": 5, "i_end": 5}, "action": {"text": "led", "start": 51, "end": 54, "i_start": 7, "i_end": 7}}, {"character": {"text": "improvements", "start": 70, "end": 82, "i_start": 10, "i_end": 10}, "action": {"text": "achieving", "start": 148, "end": 157, "i_start": 21, "i_end": 21}}], "id": 11},{"sent": "this figure shows how to implement an distributed control-control-fa gate .", "tokens": ["this", "figure", "shows", "how", "to", "implement", "an", "distributed", "control", "-", "control", "-", "fa", "gate", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this figure", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "shows", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "figure", "start": 5, "end": 11, "i_start": 1, "i_end": 1}, "action": {"text": "shows", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}], "id": 12},{"sent": "string theory is the only possibility at hand , and the transplanckian regime has been discussed in this context by several authors , see eg refs .", "tokens": ["string", "theory", "is", "the", "only", "possibility", "at", "hand", ",", "and", "the", "transplanckian", "regime", "has", "been", "discussed", "in", "this", "context", "by", "several", "authors", ",", "see", "eg", "refs", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "string theory", "start": 0, "end": 13, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 14, "end": 16, "i_start": 2, "i_end": 2}}, {"subject": {"text": "the transplanckian regime", "start": 52, "end": 77, "i_start": 10, "i_end": 12}, "verb": {"text": "discussed", "start": 87, "end": 96, "i_start": 15, "i_end": 15}}, {"character": {"text": "several", "start": 116, "end": 123, "i_start": 20, "i_end": 20}, "action": {"text": "discussed", "start": 87, "end": 96, "i_start": 15, "i_end": 15}}], "id": 13},{"sent": "in their remarkable work , spielman and srivastava analyzed a spectral sparsification algorithm based on a simple sampling procedure .", "tokens": ["in", "their", "remarkable", "work", ",", "spielman", "and", "srivastava", "analyzed", "a", "spectral", "sparsification", "algorithm", "based", "on", "a", "simple", "sampling", "procedure", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "spielman and srivastava", "start": 27, "end": 50, "i_start": 5, "i_end": 7}, "verb": {"text": "analyzed", "start": 51, "end": 59, "i_start": 8, "i_end": 8}}, {"character": {"text": "spielman", "start": 27, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "analyzed", "start": 51, "end": 59, "i_start": 8, "i_end": 8}}, {"character": {"text": "srivastava", "start": 40, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "analyzed", "start": 51, "end": 59, "i_start": 8, "i_end": 8}}, {"character": {"text": "spielman", "start": 27, "end": 35, "i_start": 5, "i_end": 5}, "action": {"text": "work", "start": 20, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "srivastava", "start": 40, "end": 50, "i_start": 7, "i_end": 7}, "action": {"text": "work", "start": 20, "end": 24, "i_start": 3, "i_end": 3}}], "id": 14},{"sent": "moreover , agarwal et al provide a minimax lower bound for this model , and we match it as well .", "tokens": ["moreover", ",", "agarwal", "et", "al", "provide", "a", "minimax", "lower", "bound", "for", "this", "model", ",", "and", "we", "match", "it", "as", "well", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "agarwal et al", "start": 11, "end": 24, "i_start": 2, "i_end": 4}, "verb": {"text": "provide", "start": 25, "end": 32, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 76, "end": 78, "i_start": 15, "i_end": 15}, "verb": {"text": "match", "start": 79, "end": 84, "i_start": 16, "i_end": 16}}, {"character": {"text": "agarwal", "start": 11, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "provide", "start": 25, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 76, "end": 78, "i_start": 15, "i_end": 15}, "action": {"text": "match", "start": 79, "end": 84, "i_start": 16, "i_end": 16}}], "id": 15},{"sent": "we use the adam optimizer and mini-batches of size 2000 during training .", "tokens": ["we", "use", "the", "adam", "optimizer", "and", "mini", "-", "batches", "of", "size", "2000", "during", "training", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 16},{"sent": "the model was trained using mini-batch sgd , with the learning rate controlled by adam and the mini-batch size set to 32 .", "tokens": ["the", "model", "was", "trained", "using", "mini", "-", "batch", "sgd", ",", "with", "the", "learning", "rate", "controlled", "by", "adam", "and", "the", "mini", "-", "batch", "size", "set", "to", "32", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "was trained", "start": 10, "end": 21, "i_start": 2, "i_end": 3}}, {"character": {"text": "adam", "start": 82, "end": 86, "i_start": 16, "i_end": 16}, "action": {"text": "controlled", "start": 68, "end": 78, "i_start": 14, "i_end": 14}}], "id": 17},{"sent": "all calculations were performed using dft as implemented in the vienna ab-initio simulation package .", "tokens": ["all", "calculations", "were", "performed", "using", "dft", "as", "implemented", "in", "the", "vienna", "ab", "-", "initio", "simulation", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "all calculations", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "were performed", "start": 17, "end": 31, "i_start": 2, "i_end": 3}}], "id": 18},{"sent": "unlike prior work with sparsityaware algorithms , the proposed si-lms and si-rls algorithms exploit the possible sparsity of the mse values associated with each of the links in a different way .", "tokens": ["unlike", "prior", "work", "with", "sparsityaware", "algorithms", ",", "the", "proposed", "si", "-", "lms", "and", "si", "-", "rls", "algorithms", "exploit", "the", "possible", "sparsity", "of", "the", "mse", "values", "associated", "with", "each", "of", "the", "links", "in", "a", "different", "way", "."], "score": [0, 0, 1, 0, 0], "labels": [{"subject": {"text": "the proposed si-lms and si-rls algorithms", "start": 50, "end": 91, "i_start": 7, "i_end": 16}, "verb": {"text": "exploit", "start": 92, "end": 99, "i_start": 17, "i_end": 17}}, {"character": {"text": "algorithms", "start": 37, "end": 47, "i_start": 5, "i_end": 5}, "action": {"text": "exploit", "start": 92, "end": 99, "i_start": 17, "i_end": 17}}, {"character": {"text": "algorithms", "start": 81, "end": 91, "i_start": 16, "i_end": 16}, "action": {"text": "exploit", "start": 92, "end": 99, "i_start": 17, "i_end": 17}}], "id": 19},{"sent": "the quantum unit of information is called the qubit .", "tokens": ["the", "quantum", "unit", "of", "information", "is", "called", "the", "qubit", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the quantum unit of information", "start": 0, "end": 31, "i_start": 0, "i_end": 4}, "verb": {"text": "is called", "start": 32, "end": 41, "i_start": 5, "i_end": 6}}], "id": 20},{"sent": "for example , one might respond to a particular shade of red , or a salty taste , or something that does not exactly match an established term .", "tokens": ["for", "example", ",", "one", "might", "respond", "to", "a", "particular", "shade", "of", "red", ",", "or", "a", "salty", "taste", ",", "or", "something", "that", "does", "not", "exactly", "match", "an", "established", "term", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 14, "end": 17, "i_start": 3, "i_end": 3}, "verb": {"text": "might respond", "start": 18, "end": 31, "i_start": 4, "i_end": 5}}, {"character": {"text": "one", "start": 14, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "respond", "start": 24, "end": 31, "i_start": 5, "i_end": 5}}], "id": 21},{"sent": "specifically , we use the adam stochastic gradient optimizer .", "tokens": ["specifically", ",", "we", "use", "the", "adam", "stochastic", "gradient", "optimizer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "verb": {"text": "use", "start": 18, "end": 21, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 15, "end": 17, "i_start": 2, "i_end": 2}, "action": {"text": "use", "start": 18, "end": 21, "i_start": 3, "i_end": 3}}], "id": 22},{"sent": "recently , deep convolution neural networks have been applied to solve the stereo matching problem .", "tokens": ["recently", ",", "deep", "convolution", "neural", "networks", "have", "been", "applied", "to", "solve", "the", "stereo", "matching", "problem", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolution neural networks", "start": 11, "end": 43, "i_start": 2, "i_end": 5}, "verb": {"text": "have been applied", "start": 44, "end": 61, "i_start": 6, "i_end": 8}}, {"character": {"text": "networks", "start": 35, "end": 43, "i_start": 5, "i_end": 5}, "action": {"text": "solve", "start": 65, "end": 70, "i_start": 10, "i_end": 10}}], "id": 23},{"sent": "similarly , topic features have been used with either maximum entropy models or recurrent networks .", "tokens": ["similarly", ",", "topic", "features", "have", "been", "used", "with", "either", "maximum", "entropy", "models", "or", "recurrent", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "topic features", "start": 12, "end": 26, "i_start": 2, "i_end": 3}, "verb": {"text": "have been used", "start": 27, "end": 41, "i_start": 4, "i_end": 6}}], "id": 24},{"sent": "compressed sensing is a recently developed paradigm for the effective acquisition of sparse signals via few nonadaptive , linear measurements .", "tokens": ["compressed", "sensing", "is", "a", "recently", "developed", "paradigm", "for", "the", "effective", "acquisition", "of", "sparse", "signals", "via", "few", "nonadaptive", ",", "linear", "measurements", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "compressed sensing", "start": 0, "end": 18, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 2, "i_end": 2}}], "id": 25},{"sent": "finally we perform binarization operation on the saliency map with a adaptive threshold , which is obtained via otsu algorithm , and take the bounding box that covers the largest connected area as the discriminative region of object .", "tokens": ["finally", "we", "perform", "binarization", "operation", "on", "the", "saliency", "map", "with", "a", "adaptive", "threshold", ",", "which", "is", "obtained", "via", "otsu", "algorithm", ",", "and", "take", "the", "bounding", "box", "that", "covers", "the", "largest", "connected", "area", "as", "the", "discriminative", "region", "of", "object", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "perform", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "verb": {"text": "take", "start": 133, "end": 137, "i_start": 22, "i_end": 22}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "perform", "start": 11, "end": 18, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 8, "end": 10, "i_start": 1, "i_end": 1}, "action": {"text": "take", "start": 133, "end": 137, "i_start": 22, "i_end": 22}}, {"character": {"text": "box", "start": 151, "end": 154, "i_start": 25, "i_end": 25}, "action": {"text": "covers", "start": 160, "end": 166, "i_start": 27, "i_end": 27}}, {"character": {"text": "region", "start": 216, "end": 222, "i_start": 35, "i_end": 35}, "action": {"text": "discriminative", "start": 201, "end": 215, "i_start": 34, "i_end": 34}}], "id": 26},{"sent": "herner , standard model higgs searches at the tevatron , these proceedings .", "tokens": ["herner", ",", "standard", "model", "higgs", "searches", "at", "the", "tevatron", ",", "these", "proceedings", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 27},{"sent": "distributional models of this form have been proved useful in many natural language processing tasks , but in general they do not scale up to larger text constituents such as phrases and sentences .", "tokens": ["distributional", "models", "of", "this", "form", "have", "been", "proved", "useful", "in", "many", "natural", "language", "processing", "tasks", ",", "but", "in", "general", "they", "do", "not", "scale", "up", "to", "larger", "text", "constituents", "such", "as", "phrases", "and", "sentences", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "distributional models of this form", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "have been proved", "start": 35, "end": 51, "i_start": 5, "i_end": 7}}, {"subject": {"text": "they", "start": 118, "end": 122, "i_start": 19, "i_end": 19}, "verb": {"text": "scale", "start": 130, "end": 135, "i_start": 22, "i_end": 22}}], "id": 28},{"sent": "furthermore , the free energy is a concave function of the distance between the defects .", "tokens": ["furthermore", ",", "the", "free", "energy", "is", "a", "concave", "function", "of", "the", "distance", "between", "the", "defects", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the free energy", "start": 14, "end": 29, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "distance", "start": 59, "end": 67, "i_start": 11, "i_end": 11}, "action": {"text": "function", "start": 43, "end": 51, "i_start": 8, "i_end": 8}}], "id": 29},{"sent": "this holds in particular for the local broadcast algorithm of censor-hillel et al , which crucially relies on a very unnatural reversal step to guarantee correctness .", "tokens": ["this", "holds", "in", "particular", "for", "the", "local", "broadcast", "algorithm", "of", "censor", "-", "hillel", "et", "al", ",", "which", "crucially", "relies", "on", "a", "very", "unnatural", "reversal", "step", "to", "guarantee", "correctness", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "verb": {"text": "holds", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "this", "start": 0, "end": 4, "i_start": 0, "i_end": 0}, "action": {"text": "holds", "start": 5, "end": 10, "i_start": 1, "i_end": 1}}, {"character": {"text": "algorithm", "start": 49, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "broadcast", "start": 39, "end": 48, "i_start": 7, "i_end": 7}}, {"character": {"text": "algorithm", "start": 49, "end": 58, "i_start": 8, "i_end": 8}, "action": {"text": "relies", "start": 100, "end": 106, "i_start": 18, "i_end": 18}}, {"character": {"text": "step", "start": 136, "end": 140, "i_start": 24, "i_end": 24}, "action": {"text": "guarantee", "start": 144, "end": 153, "i_start": 26, "i_end": 26}}], "id": 30},{"sent": "the youtube faces dataset exemplify both unconstained and controlled video settings .", "tokens": ["the", "youtube", "faces", "dataset", "exemplify", "both", "unconstained", "and", "controlled", "video", "settings", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the youtube", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "faces", "start": 12, "end": 17, "i_start": 2, "i_end": 2}}, {"subject": {"text": "dataset", "start": 18, "end": 25, "i_start": 3, "i_end": 3}, "verb": {"text": "exemplify", "start": 26, "end": 35, "i_start": 4, "i_end": 4}}, {"character": {"text": "dataset", "start": 18, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "exemplify", "start": 26, "end": 35, "i_start": 4, "i_end": 4}}], "id": 31},{"sent": "for this purpose , we generalize the toric mori theory for non-q-factorial toric varieties .", "tokens": ["for", "this", "purpose", ",", "we", "generalize", "the", "toric", "mori", "theory", "for", "non", "-", "q", "-", "factorial", "toric", "varieties", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "verb": {"text": "generalize", "start": 22, "end": 32, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "generalize", "start": 22, "end": 32, "i_start": 5, "i_end": 5}}], "id": 32},{"sent": "defferrard et al approximates spectral filters with chebyshev polynomials , providing a more efficient filtering algorithm , whose kernel size determines the range of aggregated local k-neighborhoods .", "tokens": ["defferrard", "et", "al", "approximates", "spectral", "filters", "with", "chebyshev", "polynomials", ",", "providing", "a", "more", "efficient", "filtering", "algorithm", ",", "whose", "kernel", "size", "determines", "the", "range", "of", "aggregated", "local", "k", "-", "neighborhoods", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "defferrard et al", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "approximates", "start": 17, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "defferrard", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "action": {"text": "approximates", "start": 17, "end": 29, "i_start": 3, "i_end": 3}}, {"character": {"text": "approximates", "start": 17, "end": 29, "i_start": 3, "i_end": 3}, "action": {"text": "providing", "start": 76, "end": 85, "i_start": 10, "i_end": 10}}, {"character": {"text": "algorithm", "start": 113, "end": 122, "i_start": 15, "i_end": 15}, "action": {"text": "filtering", "start": 103, "end": 112, "i_start": 14, "i_end": 14}}, {"character": {"text": "size", "start": 138, "end": 142, "i_start": 19, "i_end": 19}, "action": {"text": "determines", "start": 143, "end": 153, "i_start": 20, "i_end": 20}}], "id": 33},{"sent": "instead , we resort to variational inference to the intractable posterior p .", "tokens": ["instead", ",", "we", "resort", "to", "variational", "inference", "to", "the", "intractable", "posterior", "p", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "verb": {"text": "resort", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "we", "start": 10, "end": 12, "i_start": 2, "i_end": 2}, "action": {"text": "resort", "start": 13, "end": 19, "i_start": 3, "i_end": 3}}], "id": 34},{"sent": "as exchange-correlation potential the generalized gradient approximation in the formulation of perdew , burke and ernzerhof has been used .", "tokens": ["as", "exchange", "-", "correlation", "potential", "the", "generalized", "gradient", "approximation", "in", "the", "formulation", "of", "perdew", ",", "burke", "and", "ernzerhof", "has", "been", "used", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "as exchange-correlation potential the generalized gradient approximation in the formulation of perdew", "start": 0, "end": 101, "i_start": 0, "i_end": 13}, "verb": {"text": "has been used", "start": 124, "end": 137, "i_start": 18, "i_end": 20}}], "id": 35},{"sent": "its time component is a unit operator that commutes with everything .", "tokens": ["its", "time", "component", "is", "a", "unit", "operator", "that", "commutes", "with", "everything", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "its time component", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 19, "end": 21, "i_start": 3, "i_end": 3}}], "id": 36},{"sent": "rapid development of deep convolutional neural networks has led to promising performance on various computer vision tasks .", "tokens": ["rapid", "development", "of", "deep", "convolutional", "neural", "networks", "has", "led", "to", "promising", "performance", "on", "various", "computer", "vision", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "rapid development of deep convolutional neural networks", "start": 0, "end": 55, "i_start": 0, "i_end": 6}, "verb": {"text": "has led", "start": 56, "end": 63, "i_start": 7, "i_end": 8}}, {"character": {"text": "development", "start": 6, "end": 17, "i_start": 1, "i_end": 1}, "action": {"text": "led", "start": 60, "end": 63, "i_start": 8, "i_end": 8}}, {"character": {"text": "performance", "start": 77, "end": 88, "i_start": 11, "i_end": 11}, "action": {"text": "promising", "start": 67, "end": 76, "i_start": 10, "i_end": 10}}], "id": 37},{"sent": "neural networks have become ubiquitous in applications including computer vision .", "tokens": ["neural", "networks", "have", "become", "ubiquitous", "in", "applications", "including", "computer", "vision", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "have become", "start": 16, "end": 27, "i_start": 2, "i_end": 3}}], "id": 38},{"sent": "model independent definition of disturbance in the preceding subsection , we have defined the rms disturbance of apparatus using the associated indirect measurement model .", "tokens": ["model", "independent", "definition", "of", "disturbance", "in", "the", "preceding", "subsection", ",", "we", "have", "defined", "the", "rms", "disturbance", "of", "apparatus", "using", "the", "associated", "indirect", "measurement", "model", "."], "score": [0, 0, 0, 1, 0], "labels": [{"subject": {"text": "we", "start": 74, "end": 76, "i_start": 10, "i_end": 10}, "verb": {"text": "have defined", "start": 77, "end": 89, "i_start": 11, "i_end": 12}}, {"character": {"text": "we", "start": 74, "end": 76, "i_start": 10, "i_end": 10}, "action": {"text": "defined", "start": 82, "end": 89, "i_start": 12, "i_end": 12}}, {"character": {"text": "we", "start": 74, "end": 76, "i_start": 10, "i_end": 10}, "action": {"text": "using", "start": 123, "end": 128, "i_start": 18, "i_end": 18}}], "id": 39},{"sent": "filled squares represent the g-sample , open circles the h-sample and arrows represent upper-limits from non-detections .", "tokens": ["filled", "squares", "represent", "the", "g", "-", "sample", ",", "open", "circles", "the", "h", "-", "sample", "and", "arrows", "represent", "upper", "-", "limits", "from", "non", "-", "detections", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "filled squares", "start": 0, "end": 14, "i_start": 0, "i_end": 1}, "verb": {"text": "represent", "start": 15, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "squares", "start": 7, "end": 14, "i_start": 1, "i_end": 1}, "action": {"text": "represent", "start": 15, "end": 24, "i_start": 2, "i_end": 2}}, {"character": {"text": "circles", "start": 45, "end": 52, "i_start": 9, "i_end": 9}, "action": {"text": "represent", "start": 77, "end": 86, "i_start": 16, "i_end": 16}}, {"character": {"text": "sample", "start": 59, "end": 65, "i_start": 13, "i_end": 13}, "action": {"text": "represent", "start": 77, "end": 86, "i_start": 16, "i_end": 16}}, {"character": {"text": "arrows", "start": 70, "end": 76, "i_start": 15, "i_end": 15}, "action": {"text": "represent", "start": 77, "end": 86, "i_start": 16, "i_end": 16}}, {"character": {"text": "upper", "start": 87, "end": 92, "i_start": 17, "i_end": 17}, "action": {"text": "represent", "start": 77, "end": 86, "i_start": 16, "i_end": 16}}], "id": 40},{"sent": "hydrogen is a convenient , safe , versatile fuel source that can be easily converted .", "tokens": ["hydrogen", "is", "a", "convenient", ",", "safe", ",", "versatile", "fuel", "source", "that", "can", "be", "easily", "converted", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "hydrogen", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 9, "end": 11, "i_start": 1, "i_end": 1}}, {"character": {"text": "source", "start": 49, "end": 55, "i_start": 9, "i_end": 9}, "action": {"text": "safe", "start": 27, "end": 31, "i_start": 5, "i_end": 5}}], "id": 41},{"sent": "we use a pre-trained model which is trained with imagenet-1k dataset , and then fine-tune the network .", "tokens": ["we", "use", "a", "pre", "-", "trained", "model", "which", "is", "trained", "with", "imagenet-1k", "dataset", ",", "and", "then", "fine", "-", "tune", "the", "network", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "tune", "start": 85, "end": 89, "i_start": 18, "i_end": 18}}], "id": 42},{"sent": "in order to boost the classification performance , we add batch normalization layer between convolutional layer and relu layer .", "tokens": ["in", "order", "to", "boost", "the", "classification", "performance", ",", "we", "add", "batch", "normalization", "layer", "between", "convolutional", "layer", "and", "relu", "layer", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 51, "end": 53, "i_start": 8, "i_end": 8}, "verb": {"text": "add", "start": 54, "end": 57, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "add", "start": 54, "end": 57, "i_start": 9, "i_end": 9}}, {"character": {"text": "we", "start": 51, "end": 53, "i_start": 8, "i_end": 8}, "action": {"text": "boost", "start": 12, "end": 17, "i_start": 3, "i_end": 3}}], "id": 43},{"sent": "we state the following interesting theorem .", "tokens": ["we", "state", "the", "following", "interesting", "theorem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "state", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "state", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"character": {"text": "theorem", "start": 35, "end": 42, "i_start": 5, "i_end": 5}, "action": {"text": "interesting", "start": 23, "end": 34, "i_start": 4, "i_end": 4}}], "id": 44},{"sent": "elements of the meta-meta-model layer are called meta-meta-objects .", "tokens": ["elements", "of", "the", "meta", "-", "meta", "-", "model", "layer", "are", "called", "meta", "-", "meta", "-", "objects", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "elements of the meta-meta-model layer", "start": 0, "end": 37, "i_start": 0, "i_end": 8}, "verb": {"text": "are called", "start": 38, "end": 48, "i_start": 9, "i_end": 10}}], "id": 45},{"sent": "the space spanned by ideal boson-fermion states that are selected with the aid of the above particle number considerations is called the ideal subspace .", "tokens": ["the", "space", "spanned", "by", "ideal", "boson", "-", "fermion", "states", "that", "are", "selected", "with", "the", "aid", "of", "the", "above", "particle", "number", "considerations", "is", "called", "the", "ideal", "subspace", "."], "score": [0, 1, 1, 0, 0], "labels": [{"subject": {"text": "the space spanned by ideal boson-fermion states that are selected with the aid of the above particle number considerations", "start": 0, "end": 122, "i_start": 0, "i_end": 20}, "verb": {"text": "is called", "start": 123, "end": 132, "i_start": 21, "i_end": 22}}, {"character": {"text": "states", "start": 41, "end": 47, "i_start": 8, "i_end": 8}, "action": {"text": "spanned", "start": 10, "end": 17, "i_start": 2, "i_end": 2}}, {"character": {"text": "considerations", "start": 108, "end": 122, "i_start": 20, "i_end": 20}, "action": {"text": "aid", "start": 75, "end": 78, "i_start": 14, "i_end": 14}}], "id": 46},{"sent": "the electron-exchange correlation energy is described by using the functional of perdew , burke , and ernzerhof based within the generalized gradient approximation .", "tokens": ["the", "electron", "-", "exchange", "correlation", "energy", "is", "described", "by", "using", "the", "functional", "of", "perdew", ",", "burke", ",", "and", "ernzerhof", "based", "within", "the", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electron-exchange correlation energy", "start": 0, "end": 40, "i_start": 0, "i_end": 5}, "verb": {"text": "is described", "start": 41, "end": 53, "i_start": 6, "i_end": 7}}, {"character": {"text": "perdew", "start": 81, "end": 87, "i_start": 13, "i_end": 13}, "action": {"text": "functional", "start": 67, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "burke", "start": 90, "end": 95, "i_start": 15, "i_end": 15}, "action": {"text": "functional", "start": 67, "end": 77, "i_start": 11, "i_end": 11}}, {"character": {"text": "ernzerhof", "start": 102, "end": 111, "i_start": 18, "i_end": 18}, "action": {"text": "functional", "start": 67, "end": 77, "i_start": 11, "i_end": 11}}], "id": 47},{"sent": "an automatic binarization method for color text in video images is proposed using convolutional network .", "tokens": ["an", "automatic", "binarization", "method", "for", "color", "text", "in", "video", "images", "is", "proposed", "using", "convolutional", "network", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "an automatic binarization method for color text in video images", "start": 0, "end": 63, "i_start": 0, "i_end": 9}, "verb": {"text": "is proposed", "start": 64, "end": 75, "i_start": 10, "i_end": 11}}], "id": 48},{"sent": "along with these moving poles , the qmf will have other singularities originating from the potential which are called fixed singularities .", "tokens": ["along", "with", "these", "moving", "poles", ",", "the", "qmf", "will", "have", "other", "singularities", "originating", "from", "the", "potential", "which", "are", "called", "fixed", "singularities", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the qmf", "start": 32, "end": 39, "i_start": 6, "i_end": 7}, "verb": {"text": "will have", "start": 40, "end": 49, "i_start": 8, "i_end": 9}}, {"character": {"text": "qmf", "start": 36, "end": 39, "i_start": 7, "i_end": 7}, "action": {"text": "have", "start": 45, "end": 49, "i_start": 9, "i_end": 9}}, {"character": {"text": "poles", "start": 24, "end": 29, "i_start": 4, "i_end": 4}, "action": {"text": "have", "start": 45, "end": 49, "i_start": 9, "i_end": 9}}], "id": 49},{"sent": "deep convolutional neural networks have been successfully applied to several pattern recognition tasks such as image recognition .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "successfully", "applied", "to", "several", "pattern", "recognition", "tasks", "such", "as", "image", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "applied", "start": 58, "end": 65, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been", "start": 35, "end": 44, "i_start": 4, "i_end": 5}}], "id": 50},{"sent": "in , a dynamic channel-selection for autonomous wireless users is proposed , where each user has set of actions and strategies .", "tokens": ["in", ",", "a", "dynamic", "channel", "-", "selection", "for", "autonomous", "wireless", "users", "is", "proposed", ",", "where", "each", "user", "has", "set", "of", "actions", "and", "strategies", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "a dynamic channel-selection for autonomous wireless users", "start": 5, "end": 62, "i_start": 2, "i_end": 10}, "verb": {"text": "is proposed", "start": 63, "end": 74, "i_start": 11, "i_end": 12}}, {"character": {"text": "each", "start": 83, "end": 87, "i_start": 15, "i_end": 15}, "action": {"text": "has", "start": 93, "end": 96, "i_start": 17, "i_end": 17}}], "id": 51},{"sent": "the first type of letter is called a singleton letter .", "tokens": ["the", "first", "type", "of", "letter", "is", "called", "a", "singleton", "letter", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the first type of letter", "start": 0, "end": 24, "i_start": 0, "i_end": 4}, "verb": {"text": "is called", "start": 25, "end": 34, "i_start": 5, "i_end": 6}}], "id": 52},{"sent": "at each lattice site , there is a three-dimensional classical spin of unit length and each spin has a total of 50 interacting neighbors .", "tokens": ["at", "each", "lattice", "site", ",", "there", "is", "a", "three", "-", "dimensional", "classical", "spin", "of", "unit", "length", "and", "each", "spin", "has", "a", "total", "of", "50", "interacting", "neighbors", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "there", "start": 23, "end": 28, "i_start": 5, "i_end": 5}, "verb": {"text": "is", "start": 29, "end": 31, "i_start": 6, "i_end": 6}}, {"subject": {"text": "each spin", "start": 86, "end": 95, "i_start": 17, "i_end": 18}, "verb": {"text": "has", "start": 96, "end": 99, "i_start": 19, "i_end": 19}}, {"character": {"text": "spin", "start": 62, "end": 66, "i_start": 12, "i_end": 12}, "action": {"text": "has", "start": 96, "end": 99, "i_start": 19, "i_end": 19}}, {"character": {"text": "50 interacting neighbors", "start": 111, "end": 135, "i_start": 23, "i_end": 25}, "action": {"text": "interacting", "start": 114, "end": 125, "i_start": 24, "i_end": 24}}], "id": 53},{"sent": "however , the computational complexity of this detection algorithm is high , and large number of samples are required to exploit the cyclostationarity behavior of the received signal .", "tokens": ["however", ",", "the", "computational", "complexity", "of", "this", "detection", "algorithm", "is", "high", ",", "and", "large", "number", "of", "samples", "are", "required", "to", "exploit", "the", "cyclostationarity", "behavior", "of", "the", "received", "signal", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "the computational complexity of this detection algorithm", "start": 10, "end": 66, "i_start": 2, "i_end": 8}, "verb": {"text": "is", "start": 67, "end": 69, "i_start": 9, "i_end": 9}}, {"subject": {"text": "large number of samples", "start": 81, "end": 104, "i_start": 13, "i_end": 16}, "verb": {"text": "required", "start": 109, "end": 117, "i_start": 18, "i_end": 18}}, {"character": {"text": "algorithm", "start": 57, "end": 66, "i_start": 8, "i_end": 8}, "action": {"text": "detection", "start": 47, "end": 56, "i_start": 7, "i_end": 7}}, {"character": {"text": "signal", "start": 176, "end": 182, "i_start": 27, "i_end": 27}, "action": {"text": "behavior", "start": 151, "end": 159, "i_start": 23, "i_end": 23}}], "id": 54},{"sent": "because the spin current is a function of the cavity field amplitude , the spin current also exhibits bistability as function of the amplitude of the driving laser which survives even in the presence of significant variations in the dot sizes and coupling to the cavity field .", "tokens": ["because", "the", "spin", "current", "is", "a", "function", "of", "the", "cavity", "field", "amplitude", ",", "the", "spin", "current", "also", "exhibits", "bistability", "as", "function", "of", "the", "amplitude", "of", "the", "driving", "laser", "which", "survives", "even", "in", "the", "presence", "of", "significant", "variations", "in", "the", "dot", "sizes", "and", "coupling", "to", "the", "cavity", "field", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "the spin current", "start": 71, "end": 87, "i_start": 13, "i_end": 15}, "verb": {"text": "exhibits", "start": 93, "end": 101, "i_start": 17, "i_end": 17}}, {"character": {"text": "function", "start": 30, "end": 38, "i_start": 6, "i_end": 6}, "action": {"text": "because", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}, {"character": {"text": "amplitude", "start": 59, "end": 68, "i_start": 11, "i_end": 11}, "action": {"text": "function", "start": 30, "end": 38, "i_start": 6, "i_end": 6}}], "id": 55},{"sent": "as opposed to the reweigthed techniques , the h-method kinetic estimator is less accurate than the tmethod kinetic energy estimator .", "tokens": ["as", "opposed", "to", "the", "reweigthed", "techniques", ",", "the", "h", "-", "method", "kinetic", "estimator", "is", "less", "accurate", "than", "the", "tmethod", "kinetic", "energy", "estimator", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the h-method kinetic estimator", "start": 42, "end": 72, "i_start": 7, "i_end": 12}, "verb": {"text": "is", "start": 73, "end": 75, "i_start": 13, "i_end": 13}}], "id": 56},{"sent": "for more details about the fractional laplacian operator , we refer the readers to , .", "tokens": ["for", "more", "details", "about", "the", "fractional", "laplacian", "operator", ",", "we", "refer", "the", "readers", "to", ",", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 59, "end": 61, "i_start": 9, "i_end": 9}, "verb": {"text": "refer", "start": 62, "end": 67, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 59, "end": 61, "i_start": 9, "i_end": 9}, "action": {"text": "refer", "start": 62, "end": 67, "i_start": 10, "i_end": 10}}], "id": 57},{"sent": "son et al showed that acoustic interference on mems gyroscopes in drones can cause them to crash .", "tokens": ["son", "et", "al", "showed", "that", "acoustic", "interference", "on", "mems", "gyroscopes", "in", "drones", "can", "cause", "them", "to", "crash", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "son et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 10, "end": 16, "i_start": 3, "i_end": 3}}, {"subject": {"text": "acoustic interference on mems gyroscopes in drones", "start": 22, "end": 72, "i_start": 5, "i_end": 11}, "verb": {"text": "cause", "start": 77, "end": 82, "i_start": 13, "i_end": 13}}, {"character": {"text": "interference", "start": 31, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "cause", "start": 77, "end": 82, "i_start": 13, "i_end": 13}}, {"character": {"text": "interference", "start": 31, "end": 43, "i_start": 6, "i_end": 6}, "action": {"text": "crash", "start": 91, "end": 96, "i_start": 16, "i_end": 16}}], "id": 58},{"sent": "one is the training set and the other is the testing set .", "tokens": ["one", "is", "the", "training", "set", "and", "the", "other", "is", "the", "testing", "set", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "one", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 4, "end": 6, "i_start": 1, "i_end": 1}}], "id": 59},{"sent": "the average square amplitude of the island oscillations are equal for the harmonically oscillating island and the case of thermal equilibrium .", "tokens": ["the", "average", "square", "amplitude", "of", "the", "island", "oscillations", "are", "equal", "for", "the", "harmonically", "oscillating", "island", "and", "the", "case", "of", "thermal", "equilibrium", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the average square amplitude of the island oscillations", "start": 0, "end": 55, "i_start": 0, "i_end": 7}, "verb": {"text": "are", "start": 56, "end": 59, "i_start": 8, "i_end": 8}}], "id": 60},{"sent": "deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification among many others .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "already", "achieved", "tremendous", "success", "on", "a", "variety", "of", "computer", "vision", "tasks", "such", "as", "image", "classification", "among", "many", "others", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "achieved", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}, {"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have", "start": 35, "end": 39, "i_start": 4, "i_end": 4}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 48, "end": 56, "i_start": 6, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 68, "end": 75, "i_start": 8, "i_end": 8}}], "id": 61},{"sent": "enthalpy calculations and structure relaxations were done using density functional theory within the perdew-burke-ernzerhof generalized gradient approximation .", "tokens": ["enthalpy", "calculations", "and", "structure", "relaxations", "were", "done", "using", "density", "functional", "theory", "within", "the", "perdew", "-", "burke", "-", "ernzerhof", "generalized", "gradient", "approximation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "enthalpy calculations and structure relaxations", "start": 0, "end": 47, "i_start": 0, "i_end": 4}, "verb": {"text": "were done", "start": 48, "end": 57, "i_start": 5, "i_end": 6}}], "id": 62},{"sent": "improved upper bounds , breaking this barrier slightly , were given in developed a new approach for constructing ldcs that have much shorter codeword length than polynomial codes .", "tokens": ["improved", "upper", "bounds", ",", "breaking", "this", "barrier", "slightly", ",", "were", "given", "in", "developed", "a", "new", "approach", "for", "constructing", "ldcs", "that", "have", "much", "shorter", "codeword", "length", "than", "polynomial", "codes", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "bounds", "start": 15, "end": 21, "i_start": 2, "i_end": 2}, "action": {"text": "breaking", "start": 24, "end": 32, "i_start": 4, "i_end": 4}}], "id": 63},{"sent": "kim et al proposed vdsr , which used cascaded filters and residual learning to obtain a larger receptive field and accelerate convergence .", "tokens": ["kim", "et", "al", "proposed", "vdsr", ",", "which", "used", "cascaded", "filters", "and", "residual", "learning", "to", "obtain", "a", "larger", "receptive", "field", "and", "accelerate", "convergence", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "kim et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "kim", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}], "id": 64},{"sent": "because the method does not involve the movement of any mechanical or optical components in the measurement process , it can be readily applied to fragile fibers .", "tokens": ["because", "the", "method", "does", "not", "involve", "the", "movement", "of", "any", "mechanical", "or", "optical", "components", "in", "the", "measurement", "process", ",", "it", "can", "be", "readily", "applied", "to", "fragile", "fibers", "."], "score": [1, 1, 0, 1, 0], "labels": [{"subject": {"text": "it", "start": 118, "end": 120, "i_start": 19, "i_end": 19}, "verb": {"text": "applied", "start": 136, "end": 143, "i_start": 23, "i_end": 23}}, {"subject": {"text": "it", "start": 118, "end": 120, "i_start": 19, "i_end": 19}, "verb": {"text": "can be", "start": 121, "end": 127, "i_start": 20, "i_end": 21}}, {"character": {"text": "not involve", "start": 24, "end": 35, "i_start": 4, "i_end": 5}, "action": {"text": "because", "start": 0, "end": 7, "i_start": 0, "i_end": 0}}, {"character": {"text": "method", "start": 12, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "not involve", "start": 24, "end": 35, "i_start": 4, "i_end": 5}}], "id": 65},{"sent": "we can not compute the minimum set of cut variables as this is the np-complete minimum feedback vertex set problem .", "tokens": ["we", "can", "not", "compute", "the", "minimum", "set", "of", "cut", "variables", "as", "this", "is", "the", "np", "-", "complete", "minimum", "feedback", "vertex", "set", "problem", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "can not compute", "start": 3, "end": 18, "i_start": 1, "i_end": 3}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "compute", "start": 11, "end": 18, "i_start": 3, "i_end": 3}}], "id": 66},{"sent": "this bulging of the combined prior starts to resemble the 2 ball , and is in conflict with the geometric structures known to produce sparse solutions .", "tokens": ["this", "bulging", "of", "the", "combined", "prior", "starts", "to", "resemble", "the", "2", "ball", ",", "and", "is", "in", "conflict", "with", "the", "geometric", "structures", "known", "to", "produce", "sparse", "solutions", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "bulging", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "starts", "start": 35, "end": 41, "i_start": 6, "i_end": 6}}, {"character": {"text": "bulging", "start": 5, "end": 12, "i_start": 1, "i_end": 1}, "action": {"text": "conflict", "start": 77, "end": 85, "i_start": 16, "i_end": 16}}, {"character": {"text": "structures", "start": 105, "end": 115, "i_start": 20, "i_end": 20}, "action": {"text": "produce", "start": 125, "end": 132, "i_start": 23, "i_end": 23}}], "id": 67},{"sent": "it means that the approximation ignoring the turbulent fluctuation like the traditional transition theories could overestimate the range of cusp catastrophe .", "tokens": ["it", "means", "that", "the", "approximation", "ignoring", "the", "turbulent", "fluctuation", "like", "the", "traditional", "transition", "theories", "could", "overestimate", "the", "range", "of", "cusp", "catastrophe", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "means", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}, {"subject": {"text": "the approximation ignoring the turbulent fluctuation like the traditional transition theories", "start": 14, "end": 107, "i_start": 3, "i_end": 13}, "verb": {"text": "overestimate", "start": 114, "end": 126, "i_start": 15, "i_end": 15}}, {"character": {"text": "approximation", "start": 18, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "overestimate", "start": 114, "end": 126, "i_start": 15, "i_end": 15}}, {"character": {"text": "approximation", "start": 18, "end": 31, "i_start": 4, "i_end": 4}, "action": {"text": "ignoring", "start": 32, "end": 40, "i_start": 5, "i_end": 5}}], "id": 68},{"sent": "solubilization of rat brain mitochondrial hexokinase activity .", "tokens": ["solubilization", "of", "rat", "brain", "mitochondrial", "hexokinase", "activity", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "brain", "start": 22, "end": 27, "i_start": 3, "i_end": 3}, "action": {"text": "activity", "start": 53, "end": 61, "i_start": 6, "i_end": 6}}], "id": 69},{"sent": "the only selection criterion adopted is the coverage parameter , defined in section 2 .", "tokens": ["the", "only", "selection", "criterion", "adopted", "is", "the", "coverage", "parameter", ",", "defined", "in", "section", "2", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the only selection criterion adopted", "start": 0, "end": 36, "i_start": 0, "i_end": 4}, "verb": {"text": "is", "start": 37, "end": 39, "i_start": 5, "i_end": 5}}], "id": 70},{"sent": "when used as part of the cubetile programs , the base region is the kuhn simplex of eq .", "tokens": ["when", "used", "as", "part", "of", "the", "cubetile", "programs", ",", "the", "base", "region", "is", "the", "kuhn", "simplex", "of", "eq", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the base region", "start": 45, "end": 60, "i_start": 9, "i_end": 11}, "verb": {"text": "is", "start": 61, "end": 63, "i_start": 12, "i_end": 12}}], "id": 71},{"sent": "convolutional neural networks have proven useful for a variety of high-level vision tasks .", "tokens": ["convolutional", "neural", "networks", "have", "proven", "useful", "for", "a", "variety", "of", "high", "-", "level", "vision", "tasks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have proven", "start": 30, "end": 41, "i_start": 3, "i_end": 4}}], "id": 72},{"sent": "perplexity is a standard measure within the speech recognition community for comparing language models .", "tokens": ["perplexity", "is", "a", "standard", "measure", "within", "the", "speech", "recognition", "community", "for", "comparing", "language", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "perplexity", "start": 0, "end": 10, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 11, "end": 13, "i_start": 1, "i_end": 1}}, {"character": {"text": "community", "start": 63, "end": 72, "i_start": 9, "i_end": 9}, "action": {"text": "measure", "start": 25, "end": 32, "i_start": 4, "i_end": 4}}, {"character": {"text": "community", "start": 63, "end": 72, "i_start": 9, "i_end": 9}, "action": {"text": "recognition", "start": 51, "end": 62, "i_start": 8, "i_end": 8}}], "id": 73},{"sent": "jie et al developed a selftaught learning method to select more reliable seed positive proposals .", "tokens": ["jie", "et", "al", "developed", "a", "selftaught", "learning", "method", "to", "select", "more", "reliable", "seed", "positive", "proposals", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "jie et al", "start": 0, "end": 9, "i_start": 0, "i_end": 2}, "verb": {"text": "developed", "start": 10, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "jie", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "developed", "start": 10, "end": 19, "i_start": 3, "i_end": 3}}, {"character": {"text": "jie", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "select", "start": 52, "end": 58, "i_start": 9, "i_end": 9}}], "id": 74},{"sent": "other approaches in the bipartite setting include frequent closed itemset mining .", "tokens": ["other", "approaches", "in", "the", "bipartite", "setting", "include", "frequent", "closed", "itemset", "mining", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "other approaches in the bipartite setting", "start": 0, "end": 41, "i_start": 0, "i_end": 5}, "verb": {"text": "include", "start": 42, "end": 49, "i_start": 6, "i_end": 6}}], "id": 75},{"sent": "closely related to our problem of choosing coordination leaders is leader election , where a group of agents has to jointly determine a leader .", "tokens": ["closely", "related", "to", "our", "problem", "of", "choosing", "coordination", "leaders", "is", "leader", "election", ",", "where", "a", "group", "of", "agents", "has", "to", "jointly", "determine", "a", "leader", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "group", "start": 93, "end": 98, "i_start": 15, "i_end": 15}, "action": {"text": "determine", "start": 124, "end": 133, "i_start": 21, "i_end": 21}}], "id": 76},{"sent": "to this end , massive mimo and small cell are regarded as two key technologies for emerging 5g wireless systems .", "tokens": ["to", "this", "end", ",", "massive", "mimo", "and", "small", "cell", "are", "regarded", "as", "two", "key", "technologies", "for", "emerging", "5", "g", "wireless", "systems", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "massive mimo and small cell", "start": 14, "end": 41, "i_start": 4, "i_end": 8}, "verb": {"text": "are regarded", "start": 42, "end": 54, "i_start": 9, "i_end": 10}}, {"character": {"text": "systems", "start": 104, "end": 111, "i_start": 20, "i_end": 20}, "action": {"text": "emerging", "start": 83, "end": 91, "i_start": 16, "i_end": 16}}], "id": 77},{"sent": "here we follow another approach and we explicitly take into account model uncertainty by combining predictions under different association structures using bayesian model averaging .", "tokens": ["here", "we", "follow", "another", "approach", "and", "we", "explicitly", "take", "into", "account", "model", "uncertainty", "by", "combining", "predictions", "under", "different", "association", "structures", "using", "bayesian", "model", "averaging", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "verb": {"text": "follow", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"subject": {"text": "we", "start": 36, "end": 38, "i_start": 6, "i_end": 6}, "verb": {"text": "take", "start": 50, "end": 54, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "follow", "start": 8, "end": 14, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "take", "start": 50, "end": 54, "i_start": 8, "i_end": 8}}, {"character": {"text": "we", "start": 5, "end": 7, "i_start": 1, "i_end": 1}, "action": {"text": "combining", "start": 89, "end": 98, "i_start": 14, "i_end": 14}}], "id": 78},{"sent": "convolutional neural networks have been shown to be very successful on a variety of computer vision tasks , such as image classification .", "tokens": ["convolutional", "neural", "networks", "have", "been", "shown", "to", "be", "very", "successful", "on", "a", "variety", "of", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 0, "end": 29, "i_start": 0, "i_end": 2}, "verb": {"text": "have been shown", "start": 30, "end": 45, "i_start": 3, "i_end": 5}}, {"character": {"text": "networks", "start": 21, "end": 29, "i_start": 2, "i_end": 2}, "action": {"text": "successful", "start": 57, "end": 67, "i_start": 9, "i_end": 9}}], "id": 79},{"sent": "large numbers of real-world systems can be described as complex networks , which are represented as undirected or directed graphs .", "tokens": ["large", "numbers", "of", "real", "-", "world", "systems", "can", "be", "described", "as", "complex", "networks", ",", "which", "are", "represented", "as", "undirected", "or", "directed", "graphs", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "large numbers of real-world systems", "start": 0, "end": 35, "i_start": 0, "i_end": 6}, "verb": {"text": "can be described", "start": 36, "end": 52, "i_start": 7, "i_end": 9}}], "id": 80},{"sent": "reid , published by the investment company institute .", "tokens": ["reid", ",", "published", "by", "the", "investment", "company", "institute", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "institute", "start": 43, "end": 52, "i_start": 7, "i_end": 7}, "action": {"text": "published", "start": 7, "end": 16, "i_start": 2, "i_end": 2}}, {"character": {"text": "company", "start": 35, "end": 42, "i_start": 6, "i_end": 6}, "action": {"text": "investment", "start": 24, "end": 34, "i_start": 5, "i_end": 5}}], "id": 81},{"sent": "backbone discovery in social networks .", "tokens": ["backbone", "discovery", "in", "social", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 82},{"sent": "olympic sports dataset was collected from youtube sequences and contains 16 different sports categories with 50 videos per class .", "tokens": ["olympic", "sports", "dataset", "was", "collected", "from", "youtube", "sequences", "and", "contains", "16", "different", "sports", "categories", "with", "50", "videos", "per", "class", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "olympic sports dataset", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "was collected", "start": 23, "end": 36, "i_start": 3, "i_end": 4}}, {"subject": {"text": "olympic sports dataset", "start": 0, "end": 22, "i_start": 0, "i_end": 2}, "verb": {"text": "contains", "start": 64, "end": 72, "i_start": 9, "i_end": 9}}, {"character": {"text": "dataset", "start": 15, "end": 22, "i_start": 2, "i_end": 2}, "action": {"text": "contains", "start": 64, "end": 72, "i_start": 9, "i_end": 9}}], "id": 83},{"sent": "we use a gradient descent approach starting from a randomly sampled z .", "tokens": ["we", "use", "a", "gradient", "descent", "approach", "starting", "from", "a", "randomly", "sampled", "z", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}], "id": 84},{"sent": "we always add batch normalization non-linearity after each parametric layer except the output .", "tokens": ["we", "always", "add", "batch", "normalization", "non", "-", "linearity", "after", "each", "parametric", "layer", "except", "the", "output", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "add", "start": 10, "end": 13, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "add", "start": 10, "end": 13, "i_start": 2, "i_end": 2}}], "id": 85},{"sent": "a batch normalization layer is added after each convolution layer .", "tokens": ["a", "batch", "normalization", "layer", "is", "added", "after", "each", "convolution", "layer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a batch normalization layer", "start": 0, "end": 27, "i_start": 0, "i_end": 3}, "verb": {"text": "is added", "start": 28, "end": 36, "i_start": 4, "i_end": 5}}], "id": 86},{"sent": "the crates are mounted with good thermal contact to the water cooled radial support bars .", "tokens": ["the", "crates", "are", "mounted", "with", "good", "thermal", "contact", "to", "the", "water", "cooled", "radial", "support", "bars", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the crates", "start": 0, "end": 10, "i_start": 0, "i_end": 1}, "verb": {"text": "are mounted", "start": 11, "end": 22, "i_start": 2, "i_end": 3}}, {"character": {"text": "bars", "start": 84, "end": 88, "i_start": 14, "i_end": 14}, "action": {"text": "support", "start": 76, "end": 83, "i_start": 13, "i_end": 13}}, {"character": {"text": "water", "start": 56, "end": 61, "i_start": 10, "i_end": 10}, "action": {"text": "cooled", "start": 62, "end": 68, "i_start": 11, "i_end": 11}}], "id": 87},{"sent": "farabet et al used a multi-scale cnn trained from raw pixels to extract dense feature for assigning a label to each pixel .", "tokens": ["farabet", "et", "al", "used", "a", "multi", "-", "scale", "cnn", "trained", "from", "raw", "pixels", "to", "extract", "dense", "feature", "for", "assigning", "a", "label", "to", "each", "pixel", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "farabet et al", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "used", "start": 14, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "farabet", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "used", "start": 14, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "farabet", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "extract", "start": 64, "end": 71, "i_start": 14, "i_end": 14}}, {"character": {"text": "farabet", "start": 0, "end": 7, "i_start": 0, "i_end": 0}, "action": {"text": "assigning", "start": 90, "end": 99, "i_start": 18, "i_end": 18}}], "id": 88},{"sent": "technically , non-locality is a direct consequence of the non-triviality of elko spin sums .", "tokens": ["technically", ",", "non", "-", "locality", "is", "a", "direct", "consequence", "of", "the", "non", "-", "triviality", "of", "elko", "spin", "sums", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "non-locality", "start": 14, "end": 26, "i_start": 2, "i_end": 4}, "verb": {"text": "is", "start": 27, "end": 29, "i_start": 5, "i_end": 5}}], "id": 89},{"sent": "the electronic exchange and correlation effects were treated by the generalized gradient approximation in the perdew , burke , and ernzerhof form .", "tokens": ["the", "electronic", "exchange", "and", "correlation", "effects", "were", "treated", "by", "the", "generalized", "gradient", "approximation", "in", "the", "perdew", ",", "burke", ",", "and", "ernzerhof", "form", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the electronic exchange and correlation effects", "start": 0, "end": 47, "i_start": 0, "i_end": 5}, "verb": {"text": "were treated", "start": 48, "end": 60, "i_start": 6, "i_end": 7}}], "id": 90},{"sent": "such a geometry is the obvious candidate to describe criticality,1 since it does admit an obvious action of the spatial part of the conformal group , which can be preserved at finite temperature .", "tokens": ["such", "a", "geometry", "is", "the", "obvious", "candidate", "to", "describe", "criticality,1", "since", "it", "does", "admit", "an", "obvious", "action", "of", "the", "spatial", "part", "of", "the", "conformal", "group", ",", "which", "can", "be", "preserved", "at", "finite", "temperature", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "such a geometry", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "candidate", "start": 31, "end": 40, "i_start": 6, "i_end": 6}, "action": {"text": "describe", "start": 44, "end": 52, "i_start": 8, "i_end": 8}}, {"character": {"text": "geometry", "start": 7, "end": 15, "i_start": 2, "i_end": 2}, "action": {"text": "admit", "start": 81, "end": 86, "i_start": 13, "i_end": 13}}], "id": 91},{"sent": "it should be kept in mind , however , that the interplay between lhc and lc could be qualitatively very different in different regions of the mssm parameter space .", "tokens": ["it", "should", "be", "kept", "in", "mind", ",", "however", ",", "that", "the", "interplay", "between", "lhc", "and", "lc", "could", "be", "qualitatively", "very", "different", "in", "different", "regions", "of", "the", "mssm", "parameter", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "should be kept", "start": 3, "end": 17, "i_start": 1, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "be", "start": 82, "end": 84, "i_start": 17, "i_end": 17}}], "id": 92},{"sent": "such an invariance will guarantee the existence of massless fermions .", "tokens": ["such", "an", "invariance", "will", "guarantee", "the", "existence", "of", "massless", "fermions", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "such an invariance", "start": 0, "end": 18, "i_start": 0, "i_end": 2}, "verb": {"text": "will guarantee", "start": 19, "end": 33, "i_start": 3, "i_end": 4}}, {"character": {"text": "invariance", "start": 8, "end": 18, "i_start": 2, "i_end": 2}, "action": {"text": "guarantee", "start": 24, "end": 33, "i_start": 4, "i_end": 4}}], "id": 93},{"sent": "the strongest clump is a part of the leading arm of the sgr dwarf tidal tail .", "tokens": ["the", "strongest", "clump", "is", "a", "part", "of", "the", "leading", "arm", "of", "the", "sgr", "dwarf", "tidal", "tail", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the strongest clump", "start": 0, "end": 19, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 3, "i_end": 3}}, {"character": {"text": "arm", "start": 45, "end": 48, "i_start": 9, "i_end": 9}, "action": {"text": "leading", "start": 37, "end": 44, "i_start": 8, "i_end": 8}}], "id": 94},{"sent": "deep neural networks have significantly improved the state of the art on many supervised tasks .", "tokens": ["deep", "neural", "networks", "have", "significantly", "improved", "the", "state", "of", "the", "art", "on", "many", "supervised", "tasks", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have", "start": 21, "end": 25, "i_start": 3, "i_end": 3}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "improved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}], "id": 95},{"sent": "the ellipsis in is a shorthand expression for the full sugra action .", "tokens": ["the", "ellipsis", "in", "is", "a", "shorthand", "expression", "for", "the", "full", "sugra", "action", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the ellipsis in", "start": 0, "end": 15, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 3, "i_end": 3}}], "id": 96},{"sent": "deep neural networks are powerful models that achieve state-of-the-art performance across several domains , such as bioinformatics .", "tokens": ["deep", "neural", "networks", "are", "powerful", "models", "that", "achieve", "state", "-", "of", "-", "the", "-", "art", "performance", "across", "several", "domains", ",", "such", "as", "bioinformatics", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "models", "start": 34, "end": 40, "i_start": 5, "i_end": 5}, "action": {"text": "achieve", "start": 46, "end": 53, "i_start": 7, "i_end": 7}}], "id": 97},{"sent": "the framework of residual learning was introduced by he et al as a strategy to cope with the challenging optimization of deep models .", "tokens": ["the", "framework", "of", "residual", "learning", "was", "introduced", "by", "he", "et", "al", "as", "a", "strategy", "to", "cope", "with", "the", "challenging", "optimization", "of", "deep", "models", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the framework of residual learning", "start": 0, "end": 34, "i_start": 0, "i_end": 4}, "verb": {"text": "was introduced", "start": 35, "end": 49, "i_start": 5, "i_end": 6}}, {"character": {"text": "he", "start": 53, "end": 55, "i_start": 8, "i_end": 8}, "action": {"text": "introduced", "start": 39, "end": 49, "i_start": 6, "i_end": 6}}, {"character": {"text": "he", "start": 53, "end": 55, "i_start": 8, "i_end": 8}, "action": {"text": "cope", "start": 79, "end": 83, "i_start": 15, "i_end": 15}}, {"character": {"text": "optimization", "start": 105, "end": 117, "i_start": 19, "i_end": 19}, "action": {"text": "challenging", "start": 93, "end": 104, "i_start": 18, "i_end": 18}}], "id": 98},{"sent": "these nanoblocks are composite materials which are con structed by combining dna grafted nanoparticles with specially designed dna sequences .", "tokens": ["these", "nanoblocks", "are", "composite", "materials", "which", "are", "con", "structed", "by", "combining", "dna", "grafted", "nanoparticles", "with", "specially", "designed", "dna", "sequences", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "these nanoblocks", "start": 0, "end": 16, "i_start": 0, "i_end": 1}, "verb": {"text": "are", "start": 17, "end": 20, "i_start": 2, "i_end": 2}}], "id": 99},{"sent": "the target space is the kk-melvin times the base space p1 of the k3 , and the modulus of the fiber corresponds to the linear combination of the dilaton and the r-r 0-form at each point of the base space .", "tokens": ["the", "target", "space", "is", "the", "kk", "-", "melvin", "times", "the", "base", "space", "p1", "of", "the", "k3", ",", "and", "the", "modulus", "of", "the", "fiber", "corresponds", "to", "the", "linear", "combination", "of", "the", "dilaton", "and", "the", "r", "-", "r", "0", "-", "form", "at", "each", "point", "of", "the", "base", "space", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the target space", "start": 0, "end": 16, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 17, "end": 19, "i_start": 3, "i_end": 3}}, {"subject": {"text": "the modulus of the fiber", "start": 74, "end": 98, "i_start": 18, "i_end": 22}, "verb": {"text": "corresponds", "start": 99, "end": 110, "i_start": 23, "i_end": 23}}], "id": 100},{"sent": "deep convolutional neural networks have been prevailed in various computer vision tasks , such as objection classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "prevailed", "in", "various", "computer", "vision", "tasks", ",", "such", "as", "objection", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been prevailed", "start": 35, "end": 54, "i_start": 4, "i_end": 6}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "prevailed", "start": 45, "end": 54, "i_start": 6, "i_end": 6}}], "id": 101},{"sent": "it has been proved that this approach is the only one that preserves altitudes of the passes between regions of the segmentation .", "tokens": ["it", "has", "been", "proved", "that", "this", "approach", "is", "the", "only", "one", "that", "preserves", "altitudes", "of", "the", "passes", "between", "regions", "of", "the", "segmentation", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "has been proved", "start": 3, "end": 18, "i_start": 1, "i_end": 3}}, {"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 38, "end": 40, "i_start": 7, "i_end": 7}}, {"character": {"text": "approach", "start": 29, "end": 37, "i_start": 6, "i_end": 6}, "action": {"text": "preserves", "start": 59, "end": 68, "i_start": 12, "i_end": 12}}], "id": 102},{"sent": "r-c3d improves efficiency by sharing convolutional features across proposal generation and classification .", "tokens": ["r", "-", "c3d", "improves", "efficiency", "by", "sharing", "convolutional", "features", "across", "proposal", "generation", "and", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "-c3d", "start": 1, "end": 5, "i_start": 1, "i_end": 2}, "verb": {"text": "improves", "start": 6, "end": 14, "i_start": 3, "i_end": 3}}], "id": 103},{"sent": "given these constraints on the two-photon amplitudes , we can correct ge and gm for two-photon exchange effects , with additional uncertainties associated with these corrections .", "tokens": ["given", "these", "constraints", "on", "the", "two", "-", "photon", "amplitudes", ",", "we", "can", "correct", "ge", "and", "gm", "for", "two", "-", "photon", "exchange", "effects", ",", "with", "additional", "uncertainties", "associated", "with", "these", "corrections", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 55, "end": 57, "i_start": 10, "i_end": 10}, "verb": {"text": "can correct", "start": 58, "end": 69, "i_start": 11, "i_end": 12}}, {"character": {"text": "we", "start": 55, "end": 57, "i_start": 10, "i_end": 10}, "action": {"text": "correct", "start": 62, "end": 69, "i_start": 12, "i_end": 12}}], "id": 104},{"sent": "in recent years , convolutional neural networks have become the de facto standard in many computer vision tasks , such as image classification and object detection .", "tokens": ["in", "recent", "years", ",", "convolutional", "neural", "networks", "have", "become", "the", "de", "facto", "standard", "in", "many", "computer", "vision", "tasks", ",", "such", "as", "image", "classification", "and", "object", "detection", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "convolutional neural networks", "start": 18, "end": 47, "i_start": 4, "i_end": 6}, "verb": {"text": "have become", "start": 48, "end": 59, "i_start": 7, "i_end": 8}}], "id": 105},{"sent": "the important objects , parafermion and paraboson fock spaces are characterized by a parameter p , and their explicit construction was given recently in and in .", "tokens": ["the", "important", "objects", ",", "parafermion", "and", "paraboson", "fock", "spaces", "are", "characterized", "by", "a", "parameter", "p", ",", "and", "their", "explicit", "construction", "was", "given", "recently", "in", "and", "in", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the important objects", "start": 0, "end": 21, "i_start": 0, "i_end": 2}, "verb": {"text": "are characterized", "start": 62, "end": 79, "i_start": 9, "i_end": 10}}, {"subject": {"text": "their explicit construction", "start": 103, "end": 130, "i_start": 17, "i_end": 19}, "verb": {"text": "given", "start": 135, "end": 140, "i_start": 21, "i_end": 21}}], "id": 106},{"sent": "the two most significant types are the variational auto-encoders and generative adversarial networks .", "tokens": ["the", "two", "most", "significant", "types", "are", "the", "variational", "auto", "-", "encoders", "and", "generative", "adversarial", "networks", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the two most significant types", "start": 0, "end": 30, "i_start": 0, "i_end": 4}, "verb": {"text": "are", "start": 31, "end": 34, "i_start": 5, "i_end": 5}}], "id": 107},{"sent": "deep convolutional neural networks have achieved great success in various computer vision tasks such as image classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "achieved", "great", "success", "in", "various", "computer", "vision", "tasks", "such", "as", "image", "classification", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have achieved", "start": 35, "end": 48, "i_start": 4, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "achieved", "start": 40, "end": 48, "i_start": 5, "i_end": 5}}, {"character": {"text": "networks", "start": 26, "end": 34, "i_start": 3, "i_end": 3}, "action": {"text": "success", "start": 55, "end": 62, "i_start": 7, "i_end": 7}}], "id": 108},{"sent": "deep neural networks are powerful machine learning systems , which have been demonstrated in a variety of tasks including image classification among others .", "tokens": ["deep", "neural", "networks", "are", "powerful", "machine", "learning", "systems", ",", "which", "have", "been", "demonstrated", "in", "a", "variety", "of", "tasks", "including", "image", "classification", "among", "others", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "are", "start": 21, "end": 24, "i_start": 3, "i_end": 3}}, {"character": {"text": "systems", "start": 51, "end": 58, "i_start": 7, "i_end": 7}, "action": {"text": "learning", "start": 42, "end": 50, "i_start": 6, "i_end": 6}}], "id": 109},{"sent": "the proposal by dijkgraaf and vafa , links these superpotentials with quantities in random matrix models .", "tokens": ["the", "proposal", "by", "dijkgraaf", "and", "vafa", ",", "links", "these", "superpotentials", "with", "quantities", "in", "random", "matrix", "models", "."], "score": [1, 1, 0, 0, 0], "labels": [{"character": {"text": "dijkgraaf", "start": 16, "end": 25, "i_start": 3, "i_end": 3}, "action": {"text": "proposal", "start": 4, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "vafa", "start": 30, "end": 34, "i_start": 5, "i_end": 5}, "action": {"text": "proposal", "start": 4, "end": 12, "i_start": 1, "i_end": 1}}], "id": 110},{"sent": "statistical decision theory and bayesian analysis .", "tokens": ["statistical", "decision", "theory", "and", "bayesian", "analysis", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 111},{"sent": "zou et al proposed a tree-based algorithm to detect curve-like cracks from pavement images .", "tokens": ["zou", "et", "al", "proposed", "a", "tree", "-", "based", "algorithm", "to", "detect", "curve", "-", "like", "cracks", "from", "pavement", "images", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "et al", "start": 4, "end": 9, "i_start": 1, "i_end": 2}, "verb": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "zou", "start": 0, "end": 3, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 10, "end": 18, "i_start": 3, "i_end": 3}}, {"character": {"text": "algorithm", "start": 32, "end": 41, "i_start": 8, "i_end": 8}, "action": {"text": "detect", "start": 45, "end": 51, "i_start": 10, "i_end": 10}}], "id": 112},{"sent": "by using the intersection theory on smooth divisors , we have the following corollary .", "tokens": ["by", "using", "the", "intersection", "theory", "on", "smooth", "divisors", ",", "we", "have", "the", "following", "corollary", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 54, "end": 56, "i_start": 9, "i_end": 9}, "verb": {"text": "have", "start": 57, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 54, "end": 56, "i_start": 9, "i_end": 9}, "action": {"text": "have", "start": 57, "end": 61, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 54, "end": 56, "i_start": 9, "i_end": 9}, "action": {"text": "using", "start": 3, "end": 8, "i_start": 1, "i_end": 1}}], "id": 113},{"sent": "deep neural networks have shown remarkable success in many domains , such as computer vision .", "tokens": ["deep", "neural", "networks", "have", "shown", "remarkable", "success", "in", "many", "domains", ",", "such", "as", "computer", "vision", "."], "score": [0, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep neural networks", "start": 0, "end": 20, "i_start": 0, "i_end": 2}, "verb": {"text": "have shown", "start": 21, "end": 31, "i_start": 3, "i_end": 4}}, {"character": {"text": "networks", "start": 12, "end": 20, "i_start": 2, "i_end": 2}, "action": {"text": "success", "start": 43, "end": 50, "i_start": 6, "i_end": 6}}], "id": 114},{"sent": "recent work includes the semantic hashing , which designs the hash function using a restricted boltzmann machine .", "tokens": ["recent", "work", "includes", "the", "semantic", "hashing", ",", "which", "designs", "the", "hash", "function", "using", "a", "restricted", "boltzmann", "machine", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "recent work", "start": 0, "end": 11, "i_start": 0, "i_end": 1}, "verb": {"text": "includes", "start": 12, "end": 20, "i_start": 2, "i_end": 2}}, {"character": {"text": "hash", "start": 62, "end": 66, "i_start": 10, "i_end": 10}, "action": {"text": "designs", "start": 50, "end": 57, "i_start": 8, "i_end": 8}}], "id": 115},{"sent": "dephasing is due primarily to scattering of thermally excited ripplons off an electron .", "tokens": ["dephasing", "is", "due", "primarily", "to", "scattering", "of", "thermally", "excited", "ripplons", "off", "an", "electron", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "dephasing", "start": 0, "end": 9, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 10, "end": 12, "i_start": 1, "i_end": 1}}], "id": 116},{"sent": "in addition , as demonstrated in , llr clipping also allows to tune the mimo detection algorithm in terms of complexity versus performance by adjusting the clipping parameter .", "tokens": ["in", "addition", ",", "as", "demonstrated", "in", ",", "llr", "clipping", "also", "allows", "to", "tune", "the", "mimo", "detection", "algorithm", "in", "terms", "of", "complexity", "versus", "performance", "by", "adjusting", "the", "clipping", "parameter", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "llr clipping", "start": 35, "end": 47, "i_start": 7, "i_end": 8}, "verb": {"text": "allows", "start": 53, "end": 59, "i_start": 10, "i_end": 10}}, {"character": {"text": "clipping", "start": 156, "end": 164, "i_start": 26, "i_end": 26}, "action": {"text": "allows", "start": 53, "end": 59, "i_start": 10, "i_end": 10}}, {"character": {"text": "algorithm", "start": 87, "end": 96, "i_start": 16, "i_end": 16}, "action": {"text": "detection", "start": 77, "end": 86, "i_start": 15, "i_end": 15}}], "id": 117},{"sent": "sparse recovery is one of the essential issues in many fields of signal processing , including compressed sampling , which is a novel sampling theory .", "tokens": ["sparse", "recovery", "is", "one", "of", "the", "essential", "issues", "in", "many", "fields", "of", "signal", "processing", ",", "including", "compressed", "sampling", ",", "which", "is", "a", "novel", "sampling", "theory", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "sparse recovery", "start": 0, "end": 15, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 16, "end": 18, "i_start": 2, "i_end": 2}}], "id": 118},{"sent": "physical layer security has been widely regarded as a promising complement to the cryptographic techniques to secure the data transmission over wireless channels .", "tokens": ["physical", "layer", "security", "has", "been", "widely", "regarded", "as", "a", "promising", "complement", "to", "the", "cryptographic", "techniques", "to", "secure", "the", "data", "transmission", "over", "wireless", "channels", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "physical layer security", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "regarded", "start": 40, "end": 48, "i_start": 6, "i_end": 6}}, {"subject": {"text": "physical layer security", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "has been", "start": 24, "end": 32, "i_start": 3, "i_end": 4}}, {"character": {"text": "complement", "start": 64, "end": 74, "i_start": 10, "i_end": 10}, "action": {"text": "promising", "start": 54, "end": 63, "i_start": 9, "i_end": 9}}], "id": 119},{"sent": "an overview of coordinate descent algorithms for various optimization problems with different constraints is presented in .", "tokens": ["an", "overview", "of", "coordinate", "descent", "algorithms", "for", "various", "optimization", "problems", "with", "different", "constraints", "is", "presented", "in", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "an overview of coordinate descent algorithms for various optimization problems with different constraints", "start": 0, "end": 105, "i_start": 0, "i_end": 12}, "verb": {"text": "is presented", "start": 106, "end": 118, "i_start": 13, "i_end": 14}}], "id": 120},{"sent": "the closure a of a is a positive self-adjoint operator .", "tokens": ["the", "closure", "a", "of", "a", "is", "a", "positive", "self", "-", "adjoint", "operator", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 121},{"sent": "deep convolutional neural networks have been proven very useful in various tasks in computer vision including classification .", "tokens": ["deep", "convolutional", "neural", "networks", "have", "been", "proven", "very", "useful", "in", "various", "tasks", "in", "computer", "vision", "including", "classification", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "deep convolutional neural networks", "start": 0, "end": 34, "i_start": 0, "i_end": 3}, "verb": {"text": "have been proven", "start": 35, "end": 51, "i_start": 4, "i_end": 6}}], "id": 122},{"sent": "papernot et al proposed distillation as another possible defense against adversarial examples .", "tokens": ["papernot", "et", "al", "proposed", "distillation", "as", "another", "possible", "defense", "against", "adversarial", "examples", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "papernot et al", "start": 0, "end": 14, "i_start": 0, "i_end": 2}, "verb": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}, {"character": {"text": "papernot", "start": 0, "end": 8, "i_start": 0, "i_end": 0}, "action": {"text": "proposed", "start": 15, "end": 23, "i_start": 3, "i_end": 3}}], "id": 123},{"sent": "a qubit is a two-level quantum system , and possibilites include the spin states of an electron or the polarization states of a photon .", "tokens": ["a", "qubit", "is", "a", "two", "-", "level", "quantum", "system", ",", "and", "possibilites", "include", "the", "spin", "states", "of", "an", "electron", "or", "the", "polarization", "states", "of", "a", "photon", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "a qubit", "start": 0, "end": 7, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 8, "end": 10, "i_start": 2, "i_end": 2}}, {"subject": {"text": "possibilites", "start": 44, "end": 56, "i_start": 11, "i_end": 11}, "verb": {"text": "include", "start": 57, "end": 64, "i_start": 12, "i_end": 12}}], "id": 124},{"sent": "recently , deep learning algorithms have successfully addressed problems in various fields , such as image classification , machine translation , speech recognition , text-to-speech generation and other machine learning related areas .", "tokens": ["recently", ",", "deep", "learning", "algorithms", "have", "successfully", "addressed", "problems", "in", "various", "fields", ",", "such", "as", "image", "classification", ",", "machine", "translation", ",", "speech", "recognition", ",", "text", "-", "to", "-", "speech", "generation", "and", "other", "machine", "learning", "related", "areas", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "deep learning algorithms", "start": 11, "end": 35, "i_start": 2, "i_end": 4}, "verb": {"text": "addressed", "start": 54, "end": 63, "i_start": 7, "i_end": 7}}, {"subject": {"text": "deep learning algorithms", "start": 11, "end": 35, "i_start": 2, "i_end": 4}, "verb": {"text": "have", "start": 36, "end": 40, "i_start": 5, "i_end": 5}}, {"character": {"text": "algorithms", "start": 25, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "addressed", "start": 54, "end": 63, "i_start": 7, "i_end": 7}}, {"character": {"text": "algorithms", "start": 25, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "learning", "start": 211, "end": 219, "i_start": 33, "i_end": 33}}, {"character": {"text": "algorithms", "start": 25, "end": 35, "i_start": 4, "i_end": 4}, "action": {"text": "successfully", "start": 41, "end": 53, "i_start": 6, "i_end": 6}}], "id": 125},{"sent": "for the experiment , we used a visual geometry group 16-layer cnn trained using the imagenet large scale visual recognition challenge 2012 dataset .", "tokens": ["for", "the", "experiment", ",", "we", "used", "a", "visual", "geometry", "group", "16", "-", "layer", "cnn", "trained", "using", "the", "imagenet", "large", "scale", "visual", "recognition", "challenge", "2012", "dataset", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "verb": {"text": "used", "start": 24, "end": 28, "i_start": 5, "i_end": 5}}, {"character": {"text": "we", "start": 21, "end": 23, "i_start": 4, "i_end": 4}, "action": {"text": "used", "start": 24, "end": 28, "i_start": 5, "i_end": 5}}], "id": 126},{"sent": "projector augmentedwave pseudopotentials and perdew-burke-ernzerhof gradient approximation to the exchange-correlation functional were used .", "tokens": ["projector", "augmentedwave", "pseudopotentials", "and", "perdew", "-", "burke", "-", "ernzerhof", "gradient", "approximation", "to", "the", "exchange", "-", "correlation", "functional", "were", "used", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "projector augmentedwave pseudopotentials and perdew-burke-ernzerhof gradient approximation to the exchange-correlation functional", "start": 0, "end": 129, "i_start": 0, "i_end": 16}, "verb": {"text": "were used", "start": 130, "end": 139, "i_start": 17, "i_end": 18}}], "id": 127},{"sent": "with this result , we show that the two functions in the previous example are indeed equivalent in linear contexts .", "tokens": ["with", "this", "result", ",", "we", "show", "that", "the", "two", "functions", "in", "the", "previous", "example", "are", "indeed", "equivalent", "in", "linear", "contexts", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "verb": {"text": "show", "start": 22, "end": 26, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "verb": {"text": "are", "start": 74, "end": 77, "i_start": 14, "i_end": 14}}, {"character": {"text": "we", "start": 19, "end": 21, "i_start": 4, "i_end": 4}, "action": {"text": "show", "start": 22, "end": 26, "i_start": 5, "i_end": 5}}], "id": 128},{"sent": "the scalar-relativistic ab-initio dft calculations were performed using the projector augmented wave .", "tokens": ["the", "scalar", "-", "relativistic", "ab", "-", "initio", "dft", "calculations", "were", "performed", "using", "the", "projector", "augmented", "wave", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "the scalar-relativistic ab-initio dft calculations", "start": 0, "end": 50, "i_start": 0, "i_end": 8}, "verb": {"text": "were performed", "start": 51, "end": 65, "i_start": 9, "i_end": 10}}, {"character": {"text": "projector", "start": 76, "end": 85, "i_start": 13, "i_end": 13}, "action": {"text": "augmented", "start": 86, "end": 95, "i_start": 14, "i_end": 14}}], "id": 129},{"sent": "conway-gordon showed that k 6 is il , where k m denotes the complete graph on m vertices .", "tokens": ["conway", "-", "gordon", "showed", "that", "k", "6", "is", "il", ",", "where", "k", "m", "denotes", "the", "complete", "graph", "on", "m", "vertices", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "conway-gordon", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "showed", "start": 14, "end": 20, "i_start": 3, "i_end": 3}}, {"subject": {"text": "conway-gordon", "start": 0, "end": 13, "i_start": 0, "i_end": 2}, "verb": {"text": "is", "start": 30, "end": 32, "i_start": 7, "i_end": 7}}, {"character": {"text": "conway", "start": 0, "end": 6, "i_start": 0, "i_end": 0}, "action": {"text": "showed", "start": 14, "end": 20, "i_start": 3, "i_end": 3}}], "id": 130},{"sent": "the model was trained end-to-end using the adam optimizer .", "tokens": ["the", "model", "was", "trained", "end", "-", "to", "-", "end", "using", "the", "adam", "optimizer", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the model", "start": 0, "end": 9, "i_start": 0, "i_end": 1}, "verb": {"text": "was trained", "start": 10, "end": 21, "i_start": 2, "i_end": 3}}], "id": 131},{"sent": "in this way , it seems that we might be facing an intrinsically approximate feature in the description of the interaction of radiation and matter at the classical level .", "tokens": ["in", "this", "way", ",", "it", "seems", "that", "we", "might", "be", "facing", "an", "intrinsically", "approximate", "feature", "in", "the", "description", "of", "the", "interaction", "of", "radiation", "and", "matter", "at", "the", "classical", "level", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 14, "end": 16, "i_start": 4, "i_end": 4}, "verb": {"text": "seems", "start": 17, "end": 22, "i_start": 5, "i_end": 5}}, {"subject": {"text": "we", "start": 28, "end": 30, "i_start": 7, "i_end": 7}, "verb": {"text": "facing", "start": 40, "end": 46, "i_start": 10, "i_end": 10}}, {"character": {"text": "we", "start": 28, "end": 30, "i_start": 7, "i_end": 7}, "action": {"text": "facing", "start": 40, "end": 46, "i_start": 10, "i_end": 10}}, {"character": {"text": "radiation", "start": 125, "end": 134, "i_start": 22, "i_end": 22}, "action": {"text": "interaction", "start": 110, "end": 121, "i_start": 20, "i_end": 20}}], "id": 132},{"sent": "for example , the winding number has been directly measured by mean chiral displacement in the photonic quantum walk .", "tokens": ["for", "example", ",", "the", "winding", "number", "has", "been", "directly", "measured", "by", "mean", "chiral", "displacement", "in", "the", "photonic", "quantum", "walk", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "the winding number", "start": 14, "end": 32, "i_start": 3, "i_end": 5}, "verb": {"text": "measured", "start": 51, "end": 59, "i_start": 9, "i_end": 9}}, {"subject": {"text": "the winding number", "start": 14, "end": 32, "i_start": 3, "i_end": 5}, "verb": {"text": "has been", "start": 33, "end": 41, "i_start": 6, "i_end": 7}}], "id": 133},{"sent": "one of the common techniques for finding related topics within unstructured text is the latent dirichlet allocation .", "tokens": ["one", "of", "the", "common", "techniques", "for", "finding", "related", "topics", "within", "unstructured", "text", "is", "the", "latent", "dirichlet", "allocation", "."], "score": [1, 1, 1, 0, 0], "labels": [{"subject": {"text": "one of the common techniques for finding related topics within unstructured text", "start": 0, "end": 80, "i_start": 0, "i_end": 11}, "verb": {"text": "is", "start": 81, "end": 83, "i_start": 12, "i_end": 12}}], "id": 134},{"sent": "we introduce a gan like generative model to capture the distribution of the unknown adversarial perturbations .", "tokens": ["we", "introduce", "a", "gan", "like", "generative", "model", "to", "capture", "the", "distribution", "of", "the", "unknown", "adversarial", "perturbations", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "introduce", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "introduce", "start": 3, "end": 12, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "capture", "start": 44, "end": 51, "i_start": 8, "i_end": 8}}], "id": 135},{"sent": "over the past few years , neural networks has been widely used in some domains , such as large vocabulary continuous speech recognition .", "tokens": ["over", "the", "past", "few", "years", ",", "neural", "networks", "has", "been", "widely", "used", "in", "some", "domains", ",", "such", "as", "large", "vocabulary", "continuous", "speech", "recognition", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "neural networks", "start": 26, "end": 41, "i_start": 6, "i_end": 7}, "verb": {"text": "used", "start": 58, "end": 62, "i_start": 11, "i_end": 11}}, {"subject": {"text": "neural networks", "start": 26, "end": 41, "i_start": 6, "i_end": 7}, "verb": {"text": "has been", "start": 42, "end": 50, "i_start": 8, "i_end": 9}}], "id": 136},{"sent": "perturbation theory is a very powerful method that allows the very precise calculation of many observables within quantum field theory for small couplings \u03bb , eg cross sections , etc .", "tokens": ["perturbation", "theory", "is", "a", "very", "powerful", "method", "that", "allows", "the", "very", "precise", "calculation", "of", "many", "observables", "within", "quantum", "field", "theory", "for", "small", "couplings", "\u03bb", ",", "eg", "cross", "sections", ",", "etc", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "perturbation theory", "start": 0, "end": 19, "i_start": 0, "i_end": 1}, "verb": {"text": "is", "start": 20, "end": 22, "i_start": 2, "i_end": 2}}, {"character": {"text": "method", "start": 39, "end": 45, "i_start": 6, "i_end": 6}, "action": {"text": "allows", "start": 51, "end": 57, "i_start": 8, "i_end": 8}}], "id": 137},{"sent": "a weak galerkin finite element method for second-order elliptic problems .", "tokens": ["a", "weak", "galerkin", "finite", "element", "method", "for", "second", "-", "order", "elliptic", "problems", "."], "score": [1, 1, 0, 0, 0], "labels": [], "id": 138},{"sent": "it is well-known that \u03b3 embeds as a co-compact discrete subgroup of a simply connected nilpotent lie group g , its malcev closure .", "tokens": ["it", "is", "well", "-", "known", "that", "\u03b3", "embeds", "as", "a", "co", "-", "compact", "discrete", "subgroup", "of", "a", "simply", "connected", "nilpotent", "lie", "group", "g", ",", "its", "malcev", "closure", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "is", "start": 3, "end": 5, "i_start": 1, "i_end": 1}}, {"subject": {"text": "\u03b3", "start": 22, "end": 23, "i_start": 6, "i_end": 6}, "verb": {"text": "embeds", "start": 24, "end": 30, "i_start": 7, "i_end": 7}}, {"character": {"text": "embeds", "start": 24, "end": 30, "i_start": 7, "i_end": 7}, "action": {"text": "closure", "start": 122, "end": 129, "i_start": 26, "i_end": 26}}], "id": 139},{"sent": "we use the vgg-16 model in released by its authors as initialization , in order to accelerate the convergence speed .", "tokens": ["we", "use", "the", "vgg-16", "model", "in", "released", "by", "its", "authors", "as", "initialization", ",", "in", "order", "to", "accelerate", "the", "convergence", "speed", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "use", "start": 3, "end": 6, "i_start": 1, "i_end": 1}}, {"character": {"text": "vgg-16", "start": 11, "end": 17, "i_start": 3, "i_end": 3}, "action": {"text": "released", "start": 27, "end": 35, "i_start": 6, "i_end": 6}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "accelerate", "start": 83, "end": 93, "i_start": 16, "i_end": 16}}], "id": 140},{"sent": "the inner and full error bars represent respectively the experimental and total errors .", "tokens": ["the", "inner", "and", "full", "error", "bars", "represent", "respectively", "the", "experimental", "and", "total", "errors", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "the inner and full error bars", "start": 0, "end": 29, "i_start": 0, "i_end": 5}, "verb": {"text": "represent", "start": 30, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "bars", "start": 25, "end": 29, "i_start": 5, "i_end": 5}, "action": {"text": "represent", "start": 30, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "error", "start": 19, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "represent", "start": 30, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "inner", "start": 4, "end": 9, "i_start": 1, "i_end": 1}, "action": {"text": "represent", "start": 30, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "error", "start": 19, "end": 24, "i_start": 4, "i_end": 4}, "action": {"text": "represent", "start": 30, "end": 39, "i_start": 6, "i_end": 6}}, {"character": {"text": "full", "start": 14, "end": 18, "i_start": 3, "i_end": 3}, "action": {"text": "represent", "start": 30, "end": 39, "i_start": 6, "i_end": 6}}], "id": 141},{"sent": "recently it was shown in a group of subjects of different age , that the bold signal variability is a better predictor of the subject age than the average .", "tokens": ["recently", "it", "was", "shown", "in", "a", "group", "of", "subjects", "of", "different", "age", ",", "that", "the", "bold", "signal", "variability", "is", "a", "better", "predictor", "of", "the", "subject", "age", "than", "the", "average", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "it", "start": 9, "end": 11, "i_start": 1, "i_end": 1}, "verb": {"text": "was shown", "start": 12, "end": 21, "i_start": 2, "i_end": 3}}, {"subject": {"text": "it", "start": 9, "end": 11, "i_start": 1, "i_end": 1}, "verb": {"text": "is", "start": 97, "end": 99, "i_start": 18, "i_end": 18}}, {"character": {"text": "variability", "start": 85, "end": 96, "i_start": 17, "i_end": 17}, "action": {"text": "predictor", "start": 109, "end": 118, "i_start": 21, "i_end": 21}}], "id": 142},{"sent": "the more general notion of poisson groupoid was introduced by weinstein .", "tokens": ["the", "more", "general", "notion", "of", "poisson", "groupoid", "was", "introduced", "by", "weinstein", "."], "score": [1, 0, 0, 0, 0], "labels": [{"subject": {"text": "the more general notion of poisson groupoid", "start": 0, "end": 43, "i_start": 0, "i_end": 6}, "verb": {"text": "was introduced", "start": 44, "end": 58, "i_start": 7, "i_end": 8}}, {"character": {"text": "weinstein", "start": 62, "end": 71, "i_start": 10, "i_end": 10}, "action": {"text": "introduced", "start": 48, "end": 58, "i_start": 8, "i_end": 8}}], "id": 143},{"sent": "we also present the corresponding analytical predictions for the unquenched theory at fixed gauge field topology .", "tokens": ["we", "also", "present", "the", "corresponding", "analytical", "predictions", "for", "the", "unquenched", "theory", "at", "fixed", "gauge", "field", "topology", "."], "score": [0, 0, 0, 0, 0], "labels": [{"subject": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "verb": {"text": "present", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}, {"character": {"text": "we", "start": 0, "end": 2, "i_start": 0, "i_end": 0}, "action": {"text": "present", "start": 8, "end": 15, "i_start": 2, "i_end": 2}}], "id": 144},{"sent": "calibration and imaging were done using the miriad data reduction package .", "tokens": ["calibration", "and", "imaging", "were", "done", "using", "the", "miriad", "data", "reduction", "package", "."], "score": [1, 1, 0, 0, 0], "labels": [{"subject": {"text": "calibration and imaging", "start": 0, "end": 23, "i_start": 0, "i_end": 2}, "verb": {"text": "were done", "start": 24, "end": 33, "i_start": 3, "i_end": 4}}, {"character": {"text": "package", "start": 66, "end": 73, "i_start": 10, "i_end": 10}, "action": {"text": "reduction", "start": 56, "end": 65, "i_start": 9, "i_end": 9}}], "id": 145}]